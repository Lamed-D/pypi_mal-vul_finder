Directory,MergedCodeWithoutComments
pip,"from __future__ import annotations

__version__ = ""25.2""


def main(args: list[str] | None = None) -> int:
    
    from pip._internal.utils.entrypoints import _wrapper

    return _wrapper(args)

import os
import sys





if sys.path[0] in ("""", os.getcwd()):
    sys.path.pop(0)



if __package__ == """":
    
    
    
    
    path = os.path.dirname(os.path.dirname(__file__))
    sys.path.insert(0, path)

if __name__ == ""__main__"":
    from pip._internal.cli.main import main as _main

    sys.exit(_main())





import sys


PYTHON_REQUIRES = (3, 9)


def version_str(version):  
    return ""."".join(str(v) for v in version)


if sys.version_info[:2] < PYTHON_REQUIRES:
    raise SystemExit(
        ""This version of pip does not support python {} (requires >={})."".format(
            version_str(sys.version_info[:2]), version_str(PYTHON_REQUIRES)
        )
    )




import runpy  
from importlib.machinery import PathFinder  
from os.path import dirname  

PIP_SOURCES_ROOT = dirname(dirname(__file__))


class PipImportRedirectingFinder:
    @classmethod
    def find_spec(self, fullname, path=None, target=None):  
        if fullname != ""pip"":
            return None

        spec = PathFinder.find_spec(fullname, [PIP_SOURCES_ROOT], target)
        assert spec, (PIP_SOURCES_ROOT, fullname)
        return spec


sys.meta_path.insert(0, PipImportRedirectingFinder())

assert __name__ == ""__main__"", ""Cannot run __pip-runner__.py as a non-main module""
runpy.run_module(""pip"", run_name=""__main__"", alter_sys=True)



from __future__ import annotations

import logging
import os
import pathlib
import site
import sys
import textwrap
from collections import OrderedDict
from collections.abc import Iterable
from types import TracebackType
from typing import TYPE_CHECKING, Protocol

from pip._vendor.packaging.version import Version

from pip import __file__ as pip_location
from pip._internal.cli.spinners import open_spinner
from pip._internal.locations import get_platlib, get_purelib, get_scheme
from pip._internal.metadata import get_default_environment, get_environment
from pip._internal.utils.logging import VERBOSE
from pip._internal.utils.packaging import get_requirement
from pip._internal.utils.subprocess import call_subprocess
from pip._internal.utils.temp_dir import TempDirectory, tempdir_kinds

if TYPE_CHECKING:
    from pip._internal.index.package_finder import PackageFinder
    from pip._internal.req.req_install import InstallRequirement

logger = logging.getLogger(__name__)


def _dedup(a: str, b: str) -> tuple[str] | tuple[str, str]:
    return (a, b) if a != b else (a,)


class _Prefix:
    def __init__(self, path: str) -> None:
        self.path = path
        self.setup = False
        scheme = get_scheme("""", prefix=path)
        self.bin_dir = scheme.scripts
        self.lib_dirs = _dedup(scheme.purelib, scheme.platlib)


def get_runnable_pip() -> str:
    
    source = pathlib.Path(pip_location).resolve().parent

    if not source.is_dir():
        
        
        return str(source)

    return os.fsdecode(source / ""__pip-runner__.py"")


def _get_system_sitepackages() -> set[str]:
    
    if hasattr(site, ""getsitepackages""):
        system_sites = site.getsitepackages()
    else:
        
        
        
        
        system_sites = [get_purelib(), get_platlib()]
    return {os.path.normcase(path) for path in system_sites}


class BuildEnvironmentInstaller(Protocol):
    

    def install(
        self,
        requirements: Iterable[str],
        prefix: _Prefix,
        *,
        kind: str,
        for_req: InstallRequirement | None,
    ) -> None: ...


class SubprocessBuildEnvironmentInstaller:
    

    def __init__(self, finder: PackageFinder) -> None:
        self.finder = finder

    def install(
        self,
        requirements: Iterable[str],
        prefix: _Prefix,
        *,
        kind: str,
        for_req: InstallRequirement | None,
    ) -> None:
        finder = self.finder
        args: list[str] = [
            sys.executable,
            get_runnable_pip(),
            ""install"",
            ""--ignore-installed"",
            ""--no-user"",
            ""--prefix"",
            prefix.path,
            ""--no-warn-script-location"",
            ""--disable-pip-version-check"",
            
            
            
            ""--no-compile"",
            
            
            ""--target"",
            """",
        ]
        if logger.getEffectiveLevel() <= logging.DEBUG:
            args.append(""-vv"")
        elif logger.getEffectiveLevel() <= VERBOSE:
            args.append(""-v"")
        for format_control in (""no_binary"", ""only_binary""):
            formats = getattr(finder.format_control, format_control)
            args.extend(
                (
                    ""--"" + format_control.replace(""_"", ""-""),
                    "","".join(sorted(formats or {"":none:""})),
                )
            )

        index_urls = finder.index_urls
        if index_urls:
            args.extend([""-i"", index_urls[0]])
            for extra_index in index_urls[1:]:
                args.extend([""--extra-index-url"", extra_index])
        else:
            args.append(""--no-index"")
        for link in finder.find_links:
            args.extend([""--find-links"", link])

        if finder.proxy:
            args.extend([""--proxy"", finder.proxy])
        for host in finder.trusted_hosts:
            args.extend([""--trusted-host"", host])
        if finder.custom_cert:
            args.extend([""--cert"", finder.custom_cert])
        if finder.client_cert:
            args.extend([""--client-cert"", finder.client_cert])
        if finder.allow_all_prereleases:
            args.append(""--pre"")
        if finder.prefer_binary:
            args.append(""--prefer-binary"")
        args.append(""--"")
        args.extend(requirements)
        with open_spinner(f""Installing {kind}"") as spinner:
            call_subprocess(
                args,
                command_desc=f""pip subprocess to install {kind}"",
                spinner=spinner,
            )


class BuildEnvironment:
    

    def __init__(self, installer: BuildEnvironmentInstaller) -> None:
        self.installer = installer
        temp_dir = TempDirectory(kind=tempdir_kinds.BUILD_ENV, globally_managed=True)

        self._prefixes = OrderedDict(
            (name, _Prefix(os.path.join(temp_dir.path, name)))
            for name in (""normal"", ""overlay"")
        )

        self._bin_dirs: list[str] = []
        self._lib_dirs: list[str] = []
        for prefix in reversed(list(self._prefixes.values())):
            self._bin_dirs.append(prefix.bin_dir)
            self._lib_dirs.extend(prefix.lib_dirs)

        
        
        
        system_sites = _get_system_sitepackages()

        self._site_dir = os.path.join(temp_dir.path, ""site"")
        if not os.path.exists(self._site_dir):
            os.mkdir(self._site_dir)
        with open(
            os.path.join(self._site_dir, ""sitecustomize.py""), ""w"", encoding=""utf-8""
        ) as fp:
            fp.write(
                textwrap.dedent(
                    
                ).format(system_sites=system_sites, lib_dirs=self._lib_dirs)
            )

    def __enter__(self) -> None:
        self._save_env = {
            name: os.environ.get(name, None)
            for name in (""PATH"", ""PYTHONNOUSERSITE"", ""PYTHONPATH"")
        }

        path = self._bin_dirs[:]
        old_path = self._save_env[""PATH""]
        if old_path:
            path.extend(old_path.split(os.pathsep))

        pythonpath = [self._site_dir]

        os.environ.update(
            {
                ""PATH"": os.pathsep.join(path),
                ""PYTHONNOUSERSITE"": ""1"",
                ""PYTHONPATH"": os.pathsep.join(pythonpath),
            }
        )

    def __exit__(
        self,
        exc_type: type[BaseException] | None,
        exc_val: BaseException | None,
        exc_tb: TracebackType | None,
    ) -> None:
        for varname, old_value in self._save_env.items():
            if old_value is None:
                os.environ.pop(varname, None)
            else:
                os.environ[varname] = old_value

    def check_requirements(
        self, reqs: Iterable[str]
    ) -> tuple[set[tuple[str, str]], set[str]]:
        
        missing = set()
        conflicting = set()
        if reqs:
            env = (
                get_environment(self._lib_dirs)
                if hasattr(self, ""_lib_dirs"")
                else get_default_environment()
            )
            for req_str in reqs:
                req = get_requirement(req_str)
                
                
                if req.marker is not None and not req.marker.evaluate({""extra"": """"}):
                    continue
                dist = env.get_distribution(req.name)
                if not dist:
                    missing.add(req_str)
                    continue
                if isinstance(dist.version, Version):
                    installed_req_str = f""{req.name}=={dist.version}""
                else:
                    installed_req_str = f""{req.name}==={dist.version}""
                if not req.specifier.contains(dist.version, prereleases=True):
                    conflicting.add((installed_req_str, req_str))
                
        return conflicting, missing

    def install_requirements(
        self,
        requirements: Iterable[str],
        prefix_as_string: str,
        *,
        kind: str,
        for_req: InstallRequirement | None = None,
    ) -> None:
        prefix = self._prefixes[prefix_as_string]
        assert not prefix.setup
        prefix.setup = True
        if not requirements:
            return
        self.installer.install(requirements, prefix, kind=kind, for_req=for_req)


class NoOpBuildEnvironment(BuildEnvironment):
    

    def __init__(self) -> None:
        pass

    def __enter__(self) -> None:
        pass

    def __exit__(
        self,
        exc_type: type[BaseException] | None,
        exc_val: BaseException | None,
        exc_tb: TracebackType | None,
    ) -> None:
        pass

    def cleanup(self) -> None:
        pass

    def install_requirements(
        self,
        requirements: Iterable[str],
        prefix_as_string: str,
        *,
        kind: str,
        for_req: InstallRequirement | None = None,
    ) -> None:
        raise NotImplementedError()



from __future__ import annotations

import hashlib
import json
import logging
import os
from pathlib import Path
from typing import Any

from pip._vendor.packaging.tags import Tag, interpreter_name, interpreter_version
from pip._vendor.packaging.utils import canonicalize_name

from pip._internal.exceptions import InvalidWheelFilename
from pip._internal.models.direct_url import DirectUrl
from pip._internal.models.link import Link
from pip._internal.models.wheel import Wheel
from pip._internal.utils.temp_dir import TempDirectory, tempdir_kinds
from pip._internal.utils.urls import path_to_url

logger = logging.getLogger(__name__)

ORIGIN_JSON_NAME = ""origin.json""


def _hash_dict(d: dict[str, str]) -> str:
    
    s = json.dumps(d, sort_keys=True, separators=("","", "":""), ensure_ascii=True)
    return hashlib.sha224(s.encode(""ascii"")).hexdigest()


class Cache:
    

    def __init__(self, cache_dir: str) -> None:
        super().__init__()
        assert not cache_dir or os.path.isabs(cache_dir)
        self.cache_dir = cache_dir or None

    def _get_cache_path_parts(self, link: Link) -> list[str]:
        

        
        
        
        key_parts = {""url"": link.url_without_fragment}
        if link.hash_name is not None and link.hash is not None:
            key_parts[link.hash_name] = link.hash
        if link.subdirectory_fragment:
            key_parts[""subdirectory""] = link.subdirectory_fragment

        
        
        
        
        
        key_parts[""interpreter_name""] = interpreter_name()
        key_parts[""interpreter_version""] = interpreter_version()

        
        
        
        
        hashed = _hash_dict(key_parts)

        
        
        
        parts = [hashed[:2], hashed[2:4], hashed[4:6], hashed[6:]]

        return parts

    def _get_candidates(self, link: Link, canonical_package_name: str) -> list[Any]:
        can_not_cache = not self.cache_dir or not canonical_package_name or not link
        if can_not_cache:
            return []

        path = self.get_path_for_link(link)
        if os.path.isdir(path):
            return [(candidate, path) for candidate in os.listdir(path)]
        return []

    def get_path_for_link(self, link: Link) -> str:
        
        raise NotImplementedError()

    def get(
        self,
        link: Link,
        package_name: str | None,
        supported_tags: list[Tag],
    ) -> Link:
        
        raise NotImplementedError()


class SimpleWheelCache(Cache):
    

    def __init__(self, cache_dir: str) -> None:
        super().__init__(cache_dir)

    def get_path_for_link(self, link: Link) -> str:
        
        parts = self._get_cache_path_parts(link)
        assert self.cache_dir
        
        return os.path.join(self.cache_dir, ""wheels"", *parts)

    def get(
        self,
        link: Link,
        package_name: str | None,
        supported_tags: list[Tag],
    ) -> Link:
        candidates = []

        if not package_name:
            return link

        canonical_package_name = canonicalize_name(package_name)
        for wheel_name, wheel_dir in self._get_candidates(link, canonical_package_name):
            try:
                wheel = Wheel(wheel_name)
            except InvalidWheelFilename:
                continue
            if canonicalize_name(wheel.name) != canonical_package_name:
                logger.debug(
                    ""Ignoring cached wheel %s for %s as it ""
                    ""does not match the expected distribution name %s."",
                    wheel_name,
                    link,
                    package_name,
                )
                continue
            if not wheel.supported(supported_tags):
                
                continue
            candidates.append(
                (
                    wheel.support_index_min(supported_tags),
                    wheel_name,
                    wheel_dir,
                )
            )

        if not candidates:
            return link

        _, wheel_name, wheel_dir = min(candidates)
        return Link(path_to_url(os.path.join(wheel_dir, wheel_name)))


class EphemWheelCache(SimpleWheelCache):
    

    def __init__(self) -> None:
        self._temp_dir = TempDirectory(
            kind=tempdir_kinds.EPHEM_WHEEL_CACHE,
            globally_managed=True,
        )

        super().__init__(self._temp_dir.path)


class CacheEntry:
    def __init__(
        self,
        link: Link,
        persistent: bool,
    ):
        self.link = link
        self.persistent = persistent
        self.origin: DirectUrl | None = None
        origin_direct_url_path = Path(self.link.file_path).parent / ORIGIN_JSON_NAME
        if origin_direct_url_path.exists():
            try:
                self.origin = DirectUrl.from_json(
                    origin_direct_url_path.read_text(encoding=""utf-8"")
                )
            except Exception as e:
                logger.warning(
                    ""Ignoring invalid cache entry origin file %s for %s (%s)"",
                    origin_direct_url_path,
                    link.filename,
                    e,
                )


class WheelCache(Cache):
    

    def __init__(self, cache_dir: str) -> None:
        super().__init__(cache_dir)
        self._wheel_cache = SimpleWheelCache(cache_dir)
        self._ephem_cache = EphemWheelCache()

    def get_path_for_link(self, link: Link) -> str:
        return self._wheel_cache.get_path_for_link(link)

    def get_ephem_path_for_link(self, link: Link) -> str:
        return self._ephem_cache.get_path_for_link(link)

    def get(
        self,
        link: Link,
        package_name: str | None,
        supported_tags: list[Tag],
    ) -> Link:
        cache_entry = self.get_cache_entry(link, package_name, supported_tags)
        if cache_entry is None:
            return link
        return cache_entry.link

    def get_cache_entry(
        self,
        link: Link,
        package_name: str | None,
        supported_tags: list[Tag],
    ) -> CacheEntry | None:
        
        retval = self._wheel_cache.get(
            link=link,
            package_name=package_name,
            supported_tags=supported_tags,
        )
        if retval is not link:
            return CacheEntry(retval, persistent=True)

        retval = self._ephem_cache.get(
            link=link,
            package_name=package_name,
            supported_tags=supported_tags,
        )
        if retval is not link:
            return CacheEntry(retval, persistent=False)

        return None

    @staticmethod
    def record_download_origin(cache_dir: str, download_info: DirectUrl) -> None:
        origin_path = Path(cache_dir) / ORIGIN_JSON_NAME
        if origin_path.exists():
            try:
                origin = DirectUrl.from_json(origin_path.read_text(encoding=""utf-8""))
            except Exception as e:
                logger.warning(
                    ""Could not read origin file %s in cache entry (%s). ""
                    ""Will attempt to overwrite it."",
                    origin_path,
                    e,
                )
            else:
                
                
                if origin.url != download_info.url:
                    logger.warning(
                        ""Origin URL %s in cache entry %s does not match download URL ""
                        ""%s. This is likely a pip bug or a cache corruption issue. ""
                        ""Will overwrite it with the new value."",
                        origin.url,
                        cache_dir,
                        download_info.url,
                    )
        origin_path.write_text(download_info.to_json(), encoding=""utf-8"")



from __future__ import annotations

import configparser
import locale
import os
import sys
from collections.abc import Iterable
from typing import Any, NewType

from pip._internal.exceptions import (
    ConfigurationError,
    ConfigurationFileCouldNotBeLoaded,
)
from pip._internal.utils import appdirs
from pip._internal.utils.compat import WINDOWS
from pip._internal.utils.logging import getLogger
from pip._internal.utils.misc import ensure_dir, enum

RawConfigParser = configparser.RawConfigParser  
Kind = NewType(""Kind"", str)

CONFIG_BASENAME = ""pip.ini"" if WINDOWS else ""pip.conf""
ENV_NAMES_IGNORED = ""version"", ""help""


kinds = enum(
    USER=""user"",  
    GLOBAL=""global"",  
    SITE=""site"",  
    ENV=""env"",  
    ENV_VAR=""env-var"",  
)
OVERRIDE_ORDER = kinds.GLOBAL, kinds.USER, kinds.SITE, kinds.ENV, kinds.ENV_VAR
VALID_LOAD_ONLY = kinds.USER, kinds.GLOBAL, kinds.SITE

logger = getLogger(__name__)



def _normalize_name(name: str) -> str:
    
    name = name.lower().replace(""_"", ""-"")
    if name.startswith(""--""):
        name = name[2:]  
    return name


def _disassemble_key(name: str) -> list[str]:
    if ""."" not in name:
        error_message = (
            ""Key does not contain dot separated section and key. ""
            f""Perhaps you wanted to use 'global.{name}' instead?""
        )
        raise ConfigurationError(error_message)
    return name.split(""."", 1)


def get_configuration_files() -> dict[Kind, list[str]]:
    global_config_files = [
        os.path.join(path, CONFIG_BASENAME) for path in appdirs.site_config_dirs(""pip"")
    ]

    site_config_file = os.path.join(sys.prefix, CONFIG_BASENAME)
    legacy_config_file = os.path.join(
        os.path.expanduser(""~""),
        ""pip"" if WINDOWS else "".pip"",
        CONFIG_BASENAME,
    )
    new_config_file = os.path.join(appdirs.user_config_dir(""pip""), CONFIG_BASENAME)
    return {
        kinds.GLOBAL: global_config_files,
        kinds.SITE: [site_config_file],
        kinds.USER: [legacy_config_file, new_config_file],
    }


class Configuration:
    

    def __init__(self, isolated: bool, load_only: Kind | None = None) -> None:
        super().__init__()

        if load_only is not None and load_only not in VALID_LOAD_ONLY:
            raise ConfigurationError(
                ""Got invalid value for load_only - should be one of {}"".format(
                    "", "".join(map(repr, VALID_LOAD_ONLY))
                )
            )
        self.isolated = isolated
        self.load_only = load_only

        
        self._parsers: dict[Kind, list[tuple[str, RawConfigParser]]] = {
            variant: [] for variant in OVERRIDE_ORDER
        }
        self._config: dict[Kind, dict[str, dict[str, Any]]] = {
            variant: {} for variant in OVERRIDE_ORDER
        }
        self._modified_parsers: list[tuple[str, RawConfigParser]] = []

    def load(self) -> None:
        
        self._load_config_files()
        if not self.isolated:
            self._load_environment_vars()

    def get_file_to_edit(self) -> str | None:
        
        assert self.load_only is not None, ""Need to be specified a file to be editing""

        try:
            return self._get_parser_to_modify()[0]
        except IndexError:
            return None

    def items(self) -> Iterable[tuple[str, Any]]:
        
        return self._dictionary.items()

    def get_value(self, key: str) -> Any:
        
        orig_key = key
        key = _normalize_name(key)
        try:
            clean_config: dict[str, Any] = {}
            for file_values in self._dictionary.values():
                clean_config.update(file_values)
            return clean_config[key]
        except KeyError:
            
            
            _disassemble_key(key)
            raise ConfigurationError(f""No such key - {orig_key}"")

    def set_value(self, key: str, value: Any) -> None:
        
        key = _normalize_name(key)
        self._ensure_have_load_only()

        assert self.load_only
        fname, parser = self._get_parser_to_modify()

        if parser is not None:
            section, name = _disassemble_key(key)

            
            if not parser.has_section(section):
                parser.add_section(section)
            parser.set(section, name, value)

        self._config[self.load_only].setdefault(fname, {})
        self._config[self.load_only][fname][key] = value
        self._mark_as_modified(fname, parser)

    def unset_value(self, key: str) -> None:
        
        orig_key = key
        key = _normalize_name(key)
        self._ensure_have_load_only()

        assert self.load_only
        fname, parser = self._get_parser_to_modify()

        if (
            key not in self._config[self.load_only][fname]
            and key not in self._config[self.load_only]
        ):
            raise ConfigurationError(f""No such key - {orig_key}"")

        if parser is not None:
            section, name = _disassemble_key(key)
            if not (
                parser.has_section(section) and parser.remove_option(section, name)
            ):
                
                raise ConfigurationError(
                    ""Fatal Internal error [id=1]. Please report as a bug.""
                )

            
            if not parser.items(section):
                parser.remove_section(section)
            self._mark_as_modified(fname, parser)
        try:
            del self._config[self.load_only][fname][key]
        except KeyError:
            del self._config[self.load_only][key]

    def save(self) -> None:
        
        self._ensure_have_load_only()

        for fname, parser in self._modified_parsers:
            logger.info(""Writing to %s"", fname)

            
            ensure_dir(os.path.dirname(fname))

            
            try:
                with open(fname, ""w"") as f:
                    parser.write(f)
            except OSError as error:
                raise ConfigurationError(
                    f""An error occurred while writing to the configuration file ""
                    f""{fname}: {error}""
                )

    
    
    

    def _ensure_have_load_only(self) -> None:
        if self.load_only is None:
            raise ConfigurationError(""Needed a specific file to be modifying."")
        logger.debug(""Will be working with %s variant only"", self.load_only)

    @property
    def _dictionary(self) -> dict[str, dict[str, Any]]:
        
        
        
        retval = {}

        for variant in OVERRIDE_ORDER:
            retval.update(self._config[variant])

        return retval

    def _load_config_files(self) -> None:
        
        config_files = dict(self.iter_config_files())
        if config_files[kinds.ENV][0:1] == [os.devnull]:
            logger.debug(
                ""Skipping loading configuration files due to ""
                ""environment's PIP_CONFIG_FILE being os.devnull""
            )
            return

        for variant, files in config_files.items():
            for fname in files:
                
                
                if self.load_only is not None and variant != self.load_only:
                    logger.debug(""Skipping file '%s' (variant: %s)"", fname, variant)
                    continue

                parser = self._load_file(variant, fname)

                
                self._parsers[variant].append((fname, parser))

    def _load_file(self, variant: Kind, fname: str) -> RawConfigParser:
        logger.verbose(""For variant '%s', will try loading '%s'"", variant, fname)
        parser = self._construct_parser(fname)

        for section in parser.sections():
            items = parser.items(section)
            self._config[variant].setdefault(fname, {})
            self._config[variant][fname].update(self._normalized_keys(section, items))

        return parser

    def _construct_parser(self, fname: str) -> RawConfigParser:
        parser = configparser.RawConfigParser()
        
        
        
        
        if os.path.exists(fname):
            locale_encoding = locale.getpreferredencoding(False)
            try:
                parser.read(fname, encoding=locale_encoding)
            except UnicodeDecodeError:
                
                raise ConfigurationFileCouldNotBeLoaded(
                    reason=f""contains invalid {locale_encoding} characters"",
                    fname=fname,
                )
            except configparser.Error as error:
                
                raise ConfigurationFileCouldNotBeLoaded(error=error)
        return parser

    def _load_environment_vars(self) -> None:
        
        self._config[kinds.ENV_VAR].setdefault("":env:"", {})
        self._config[kinds.ENV_VAR]["":env:""].update(
            self._normalized_keys("":env:"", self.get_environ_vars())
        )

    def _normalized_keys(
        self, section: str, items: Iterable[tuple[str, Any]]
    ) -> dict[str, Any]:
        
        normalized = {}
        for name, val in items:
            key = section + ""."" + _normalize_name(name)
            normalized[key] = val
        return normalized

    def get_environ_vars(self) -> Iterable[tuple[str, str]]:
        
        for key, val in os.environ.items():
            if key.startswith(""PIP_""):
                name = key[4:].lower()
                if name not in ENV_NAMES_IGNORED:
                    yield name, val

    
    def iter_config_files(self) -> Iterable[tuple[Kind, list[str]]]:
        
        

        env_config_file = os.environ.get(""PIP_CONFIG_FILE"", None)
        config_files = get_configuration_files()

        yield kinds.GLOBAL, config_files[kinds.GLOBAL]

        
        should_load_user_config = not self.isolated and not (
            env_config_file and os.path.exists(env_config_file)
        )
        if should_load_user_config:
            
            yield kinds.USER, config_files[kinds.USER]

        
        yield kinds.SITE, config_files[kinds.SITE]

        if env_config_file is not None:
            yield kinds.ENV, [env_config_file]
        else:
            yield kinds.ENV, []

    def get_values_in_config(self, variant: Kind) -> dict[str, Any]:
        
        return self._config[variant]

    def _get_parser_to_modify(self) -> tuple[str, RawConfigParser]:
        
        assert self.load_only
        parsers = self._parsers[self.load_only]
        if not parsers:
            
            raise ConfigurationError(
                ""Fatal Internal error [id=2]. Please report as a bug.""
            )

        
        return parsers[-1]

    
    def _mark_as_modified(self, fname: str, parser: RawConfigParser) -> None:
        file_parser_tuple = (fname, parser)
        if file_parser_tuple not in self._modified_parsers:
            self._modified_parsers.append(file_parser_tuple)

    def __repr__(self) -> str:
        return f""{self.__class__.__name__}({self._dictionary!r})""



from __future__ import annotations

import configparser
import contextlib
import locale
import logging
import pathlib
import re
import sys
from collections.abc import Iterator
from itertools import chain, groupby, repeat
from typing import TYPE_CHECKING, Literal

from pip._vendor.packaging.requirements import InvalidRequirement
from pip._vendor.packaging.version import InvalidVersion
from pip._vendor.rich.console import Console, ConsoleOptions, RenderResult
from pip._vendor.rich.markup import escape
from pip._vendor.rich.text import Text

if TYPE_CHECKING:
    from hashlib import _Hash

    from pip._vendor.requests.models import Request, Response

    from pip._internal.metadata import BaseDistribution
    from pip._internal.network.download import _FileDownload
    from pip._internal.req.req_install import InstallRequirement

logger = logging.getLogger(__name__)





def _is_kebab_case(s: str) -> bool:
    return re.match(r""^[a-z]+(-[a-z]+)*$"", s) is not None


def _prefix_with_indent(
    s: Text | str,
    console: Console,
    *,
    prefix: str,
    indent: str,
) -> Text:
    if isinstance(s, Text):
        text = s
    else:
        text = console.render_str(s)

    return console.render_str(prefix, overflow=""ignore"") + console.render_str(
        f""\n{indent}"", overflow=""ignore""
    ).join(text.split(allow_blank=True))


class PipError(Exception):
    


class DiagnosticPipError(PipError):
    

    reference: str

    def __init__(
        self,
        *,
        kind: Literal[""error"", ""warning""] = ""error"",
        reference: str | None = None,
        message: str | Text,
        context: str | Text | None,
        hint_stmt: str | Text | None,
        note_stmt: str | Text | None = None,
        link: str | None = None,
    ) -> None:
        
        if reference is None:
            assert hasattr(self, ""reference""), ""error reference not provided!""
            reference = self.reference
        assert _is_kebab_case(reference), ""error reference must be kebab-case!""

        self.kind = kind
        self.reference = reference

        self.message = message
        self.context = context

        self.note_stmt = note_stmt
        self.hint_stmt = hint_stmt

        self.link = link

        super().__init__(f""<{self.__class__.__name__}: {self.reference}>"")

    def __repr__(self) -> str:
        return (
            f""<{self.__class__.__name__}(""
            f""reference={self.reference!r}, ""
            f""message={self.message!r}, ""
            f""context={self.context!r}, ""
            f""note_stmt={self.note_stmt!r}, ""
            f""hint_stmt={self.hint_stmt!r}""
            "")>""
        )

    def __rich_console__(
        self,
        console: Console,
        options: ConsoleOptions,
    ) -> RenderResult:
        colour = ""red"" if self.kind == ""error"" else ""yellow""

        yield f""[{colour} bold]{self.kind}[/]: [bold]{self.reference}[/]""
        yield """"

        if not options.ascii_only:
            
            if self.context is not None:
                yield _prefix_with_indent(
                    self.message,
                    console,
                    prefix=f""[{colour}]×[/] "",
                    indent=f""[{colour}]│[/] "",
                )
                yield _prefix_with_indent(
                    self.context,
                    console,
                    prefix=f""[{colour}]╰─>[/] "",
                    indent=f""[{colour}]   [/] "",
                )
            else:
                yield _prefix_with_indent(
                    self.message,
                    console,
                    prefix=""[red]×[/] "",
                    indent=""  "",
                )
        else:
            yield self.message
            if self.context is not None:
                yield """"
                yield self.context

        if self.note_stmt is not None or self.hint_stmt is not None:
            yield """"

        if self.note_stmt is not None:
            yield _prefix_with_indent(
                self.note_stmt,
                console,
                prefix=""[magenta bold]note[/]: "",
                indent=""      "",
            )
        if self.hint_stmt is not None:
            yield _prefix_with_indent(
                self.hint_stmt,
                console,
                prefix=""[cyan bold]hint[/]: "",
                indent=""      "",
            )

        if self.link is not None:
            yield """"
            yield f""Link: {self.link}""





class ConfigurationError(PipError):
    


class InstallationError(PipError):
    


class MissingPyProjectBuildRequires(DiagnosticPipError):
    

    reference = ""missing-pyproject-build-system-requires""

    def __init__(self, *, package: str) -> None:
        super().__init__(
            message=f""Can not process {escape(package)}"",
            context=Text(
                ""This package has an invalid pyproject.toml file.\n""
                ""The [build-system] table is missing the mandatory `requires` key.""
            ),
            note_stmt=""This is an issue with the package mentioned above, not pip."",
            hint_stmt=Text(""See PEP 518 for the detailed specification.""),
        )


class InvalidPyProjectBuildRequires(DiagnosticPipError):
    

    reference = ""invalid-pyproject-build-system-requires""

    def __init__(self, *, package: str, reason: str) -> None:
        super().__init__(
            message=f""Can not process {escape(package)}"",
            context=Text(
                ""This package has an invalid `build-system.requires` key in ""
                f""pyproject.toml.\n{reason}""
            ),
            note_stmt=""This is an issue with the package mentioned above, not pip."",
            hint_stmt=Text(""See PEP 518 for the detailed specification.""),
        )


class NoneMetadataError(PipError):
    

    def __init__(
        self,
        dist: BaseDistribution,
        metadata_name: str,
    ) -> None:
        
        self.dist = dist
        self.metadata_name = metadata_name

    def __str__(self) -> str:
        
        
        return f""None {self.metadata_name} metadata found for distribution: {self.dist}""


class UserInstallationInvalid(InstallationError):
    

    def __str__(self) -> str:
        return ""User base directory is not specified""


class InvalidSchemeCombination(InstallationError):
    def __str__(self) -> str:
        before = "", "".join(str(a) for a in self.args[:-1])
        return f""Cannot set {before} and {self.args[-1]} together""


class DistributionNotFound(InstallationError):
    


class RequirementsFileParseError(InstallationError):
    


class BestVersionAlreadyInstalled(PipError):
    


class BadCommand(PipError):
    


class CommandError(PipError):
    


class PreviousBuildDirError(PipError):
    


class NetworkConnectionError(PipError):
    

    def __init__(
        self,
        error_msg: str,
        response: Response | None = None,
        request: Request | None = None,
    ) -> None:
        
        self.response = response
        self.request = request
        self.error_msg = error_msg
        if (
            self.response is not None
            and not self.request
            and hasattr(response, ""request"")
        ):
            self.request = self.response.request
        super().__init__(error_msg, response, request)

    def __str__(self) -> str:
        return str(self.error_msg)


class InvalidWheelFilename(InstallationError):
    


class UnsupportedWheel(InstallationError):
    


class InvalidWheel(InstallationError):
    

    def __init__(self, location: str, name: str):
        self.location = location
        self.name = name

    def __str__(self) -> str:
        return f""Wheel '{self.name}' located at {self.location} is invalid.""


class MetadataInconsistent(InstallationError):
    

    def __init__(
        self, ireq: InstallRequirement, field: str, f_val: str, m_val: str
    ) -> None:
        self.ireq = ireq
        self.field = field
        self.f_val = f_val
        self.m_val = m_val

    def __str__(self) -> str:
        return (
            f""Requested {self.ireq} has inconsistent {self.field}: ""
            f""expected {self.f_val!r}, but metadata has {self.m_val!r}""
        )


class MetadataInvalid(InstallationError):
    

    def __init__(self, ireq: InstallRequirement, error: str) -> None:
        self.ireq = ireq
        self.error = error

    def __str__(self) -> str:
        return f""Requested {self.ireq} has invalid metadata: {self.error}""


class InstallationSubprocessError(DiagnosticPipError, InstallationError):
    

    reference = ""subprocess-exited-with-error""

    def __init__(
        self,
        *,
        command_description: str,
        exit_code: int,
        output_lines: list[str] | None,
    ) -> None:
        if output_lines is None:
            output_prompt = Text(""See above for output."")
        else:
            output_prompt = (
                Text.from_markup(f""[red][{len(output_lines)} lines of output][/]\n"")
                + Text("""".join(output_lines))
                + Text.from_markup(R""[red]\[end of output][/]"")
            )

        super().__init__(
            message=(
                f""[green]{escape(command_description)}[/] did not run successfully.\n""
                f""exit code: {exit_code}""
            ),
            context=output_prompt,
            hint_stmt=None,
            note_stmt=(
                ""This error originates from a subprocess, and is likely not a ""
                ""problem with pip.""
            ),
        )

        self.command_description = command_description
        self.exit_code = exit_code

    def __str__(self) -> str:
        return f""{self.command_description} exited with {self.exit_code}""


class MetadataGenerationFailed(InstallationSubprocessError, InstallationError):
    reference = ""metadata-generation-failed""

    def __init__(
        self,
        *,
        package_details: str,
    ) -> None:
        super(InstallationSubprocessError, self).__init__(
            message=""Encountered error while generating package metadata."",
            context=escape(package_details),
            hint_stmt=""See above for details."",
            note_stmt=""This is an issue with the package mentioned above, not pip."",
        )

    def __str__(self) -> str:
        return ""metadata generation failed""


class HashErrors(InstallationError):
    

    def __init__(self) -> None:
        self.errors: list[HashError] = []

    def append(self, error: HashError) -> None:
        self.errors.append(error)

    def __str__(self) -> str:
        lines = []
        self.errors.sort(key=lambda e: e.order)
        for cls, errors_of_cls in groupby(self.errors, lambda e: e.__class__):
            lines.append(cls.head)
            lines.extend(e.body() for e in errors_of_cls)
        if lines:
            return ""\n"".join(lines)
        return """"

    def __bool__(self) -> bool:
        return bool(self.errors)


class HashError(InstallationError):
    

    req: InstallRequirement | None = None
    head = """"
    order: int = -1

    def body(self) -> str:
        
        return f""    {self._requirement_name()}""

    def __str__(self) -> str:
        return f""{self.head}\n{self.body()}""

    def _requirement_name(self) -> str:
        
        return str(self.req) if self.req else ""unknown package""


class VcsHashUnsupported(HashError):
    

    order = 0
    head = (
        ""Can't verify hashes for these requirements because we don't ""
        ""have a way to hash version control repositories:""
    )


class DirectoryUrlHashUnsupported(HashError):
    

    order = 1
    head = (
        ""Can't verify hashes for these file:// requirements because they ""
        ""point to directories:""
    )


class HashMissing(HashError):
    

    order = 2
    head = (
        ""Hashes are required in --require-hashes mode, but they are ""
        ""missing from some requirements. Here is a list of those ""
        ""requirements along with the hashes their downloaded archives ""
        ""actually had. Add lines like these to your requirements files to ""
        ""prevent tampering. (If you did not enable --require-hashes ""
        ""manually, note that it turns on automatically when any package ""
        ""has a hash.)""
    )

    def __init__(self, gotten_hash: str) -> None:
        
        self.gotten_hash = gotten_hash

    def body(self) -> str:
        
        from pip._internal.utils.hashes import FAVORITE_HASH

        package = None
        if self.req:
            
            
            
            package = (
                self.req.original_link
                if self.req.is_direct
                
                
                else getattr(self.req, ""req"", None)
            )
        return ""    {} --hash={}:{}"".format(
            package or ""unknown package"", FAVORITE_HASH, self.gotten_hash
        )


class HashUnpinned(HashError):
    

    order = 3
    head = (
        ""In --require-hashes mode, all requirements must have their ""
        ""versions pinned with ==. These do not:""
    )


class HashMismatch(HashError):
    

    order = 4
    head = (
        ""THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS ""
        ""FILE. If you have updated the package versions, please update ""
        ""the hashes. Otherwise, examine the package contents carefully; ""
        ""someone may have tampered with them.""
    )

    def __init__(self, allowed: dict[str, list[str]], gots: dict[str, _Hash]) -> None:
        
        self.allowed = allowed
        self.gots = gots

    def body(self) -> str:
        return f""    {self._requirement_name()}:\n{self._hash_comparison()}""

    def _hash_comparison(self) -> str:
        

        def hash_then_or(hash_name: str) -> chain[str]:
            
            
            return chain([hash_name], repeat(""    or""))

        lines: list[str] = []
        for hash_name, expecteds in self.allowed.items():
            prefix = hash_then_or(hash_name)
            lines.extend((f""        Expected {next(prefix)} {e}"") for e in expecteds)
            lines.append(
                f""             Got        {self.gots[hash_name].hexdigest()}\n""
            )
        return ""\n"".join(lines)


class UnsupportedPythonVersion(InstallationError):
    


class ConfigurationFileCouldNotBeLoaded(ConfigurationError):
    

    def __init__(
        self,
        reason: str = ""could not be loaded"",
        fname: str | None = None,
        error: configparser.Error | None = None,
    ) -> None:
        super().__init__(error)
        self.reason = reason
        self.fname = fname
        self.error = error

    def __str__(self) -> str:
        if self.fname is not None:
            message_part = f"" in {self.fname}.""
        else:
            assert self.error is not None
            message_part = f"".\n{self.error}\n""
        return f""Configuration file {self.reason}{message_part}""


_DEFAULT_EXTERNALLY_MANAGED_ERROR = f


class ExternallyManagedEnvironment(DiagnosticPipError):
    

    reference = ""externally-managed-environment""

    def __init__(self, error: str | None) -> None:
        if error is None:
            context = Text(_DEFAULT_EXTERNALLY_MANAGED_ERROR)
        else:
            context = Text(error)
        super().__init__(
            message=""This environment is externally managed"",
            context=context,
            note_stmt=(
                ""If you believe this is a mistake, please contact your ""
                ""Python installation or OS distribution provider. ""
                ""You can override this, at the risk of breaking your Python ""
                ""installation or OS, by passing --break-system-packages.""
            ),
            hint_stmt=Text(""See PEP 668 for the detailed specification.""),
        )

    @staticmethod
    def _iter_externally_managed_error_keys() -> Iterator[str]:
        
        
        
        
        
        try:
            category = locale.LC_MESSAGES
        except AttributeError:
            lang: str | None = None
        else:
            lang, _ = locale.getlocale(category)
        if lang is not None:
            yield f""Error-{lang}""
            for sep in (""-"", ""_""):
                before, found, _ = lang.partition(sep)
                if not found:
                    continue
                yield f""Error-{before}""
        yield ""Error""

    @classmethod
    def from_config(
        cls,
        config: pathlib.Path | str,
    ) -> ExternallyManagedEnvironment:
        parser = configparser.ConfigParser(interpolation=None)
        try:
            parser.read(config, encoding=""utf-8"")
            section = parser[""externally-managed""]
            for key in cls._iter_externally_managed_error_keys():
                with contextlib.suppress(KeyError):
                    return cls(section[key])
        except KeyError:
            pass
        except (OSError, UnicodeDecodeError, configparser.ParsingError):
            from pip._internal.utils._log import VERBOSE

            exc_info = logger.isEnabledFor(VERBOSE)
            logger.warning(""Failed to read %s"", config, exc_info=exc_info)
        return cls(None)


class UninstallMissingRecord(DiagnosticPipError):
    reference = ""uninstall-no-record-file""

    def __init__(self, *, distribution: BaseDistribution) -> None:
        installer = distribution.installer
        if not installer or installer == ""pip"":
            dep = f""{distribution.raw_name}=={distribution.version}""
            hint = Text.assemble(
                ""You might be able to recover from this via: "",
                (f""pip install --force-reinstall --no-deps {dep}"", ""green""),
            )
        else:
            hint = Text(
                f""The package was installed by {installer}. ""
                ""You should check if it can uninstall the package.""
            )

        super().__init__(
            message=Text(f""Cannot uninstall {distribution}""),
            context=(
                ""The package's contents are unknown: ""
                f""no RECORD file was found for {distribution.raw_name}.""
            ),
            hint_stmt=hint,
        )


class LegacyDistutilsInstall(DiagnosticPipError):
    reference = ""uninstall-distutils-installed-package""

    def __init__(self, *, distribution: BaseDistribution) -> None:
        super().__init__(
            message=Text(f""Cannot uninstall {distribution}""),
            context=(
                ""It is a distutils installed project and thus we cannot accurately ""
                ""determine which files belong to it which would lead to only a partial ""
                ""uninstall.""
            ),
            hint_stmt=None,
        )


class InvalidInstalledPackage(DiagnosticPipError):
    reference = ""invalid-installed-package""

    def __init__(
        self,
        *,
        dist: BaseDistribution,
        invalid_exc: InvalidRequirement | InvalidVersion,
    ) -> None:
        installed_location = dist.installed_location

        if isinstance(invalid_exc, InvalidRequirement):
            invalid_type = ""requirement""
        else:
            invalid_type = ""version""

        super().__init__(
            message=Text(
                f""Cannot process installed package {dist} ""
                + (f""in {installed_location!r} "" if installed_location else """")
                + f""because it has an invalid {invalid_type}:\n{invalid_exc.args[0]}""
            ),
            context=(
                ""Starting with pip 24.1, packages with invalid ""
                f""{invalid_type}s can not be processed.""
            ),
            hint_stmt=""To proceed this package must be uninstalled."",
        )


class IncompleteDownloadError(DiagnosticPipError):
    

    reference = ""incomplete-download""

    def __init__(self, download: _FileDownload) -> None:
        
        from pip._internal.utils.misc import format_size

        assert download.size is not None
        download_status = (
            f""{format_size(download.bytes_received)}/{format_size(download.size)}""
        )
        if download.reattempts:
            retry_status = f""after {download.reattempts + 1} attempts ""
            hint = ""Use --resume-retries to configure resume attempt limit.""
        else:
            
            retry_status = """"
            hint = ""Consider using --resume-retries to enable download resumption.""
        message = Text(
            f""Download failed {retry_status}because not enough bytes ""
            f""were received ({download_status})""
        )

        super().__init__(
            message=message,
            context=f""URL: {download.link.redacted_url}"",
            hint_stmt=hint,
            note_stmt=""This is an issue with network connectivity, not pip."",
        )


class ResolutionTooDeepError(DiagnosticPipError):
    

    reference = ""resolution-too-deep""

    def __init__(self) -> None:
        super().__init__(
            message=""Dependency resolution exceeded maximum depth"",
            context=(
                ""Pip cannot resolve the current dependencies as the dependency graph ""
                ""is too complex for pip to solve efficiently.""
            ),
            hint_stmt=(
                ""Try adding lower bounds to constrain your dependencies, ""
                ""for example: 'package>=2.0.0' instead of just 'package'. ""
            ),
            link=""https://pip.pypa.io/en/stable/topics/dependency-resolution/
        )


class InstallWheelBuildError(DiagnosticPipError):
    reference = ""failed-wheel-build-for-install""

    def __init__(self, failed: list[InstallRequirement]) -> None:
        super().__init__(
            message=(
                ""Failed to build installable wheels for some ""
                ""pyproject.toml based projects""
            ),
            context="", "".join(r.name for r in failed),  
            hint_stmt=None,
        )

from __future__ import annotations


def main(args: list[str] | None = None) -> int:
    
    from pip._internal.utils.entrypoints import _wrapper

    return _wrapper(args)

from __future__ import annotations

import importlib.util
import os
from collections import namedtuple
from typing import Any

from pip._vendor.packaging.requirements import InvalidRequirement

from pip._internal.exceptions import (
    InstallationError,
    InvalidPyProjectBuildRequires,
    MissingPyProjectBuildRequires,
)
from pip._internal.utils.compat import tomllib
from pip._internal.utils.packaging import get_requirement


def _is_list_of_str(obj: Any) -> bool:
    return isinstance(obj, list) and all(isinstance(item, str) for item in obj)


def make_pyproject_path(unpacked_source_directory: str) -> str:
    return os.path.join(unpacked_source_directory, ""pyproject.toml"")


BuildSystemDetails = namedtuple(
    ""BuildSystemDetails"", [""requires"", ""backend"", ""check"", ""backend_path""]
)


def load_pyproject_toml(
    use_pep517: bool | None, pyproject_toml: str, setup_py: str, req_name: str
) -> BuildSystemDetails | None:
    
    has_pyproject = os.path.isfile(pyproject_toml)
    has_setup = os.path.isfile(setup_py)

    if not has_pyproject and not has_setup:
        raise InstallationError(
            f""{req_name} does not appear to be a Python project: ""
            f""neither 'setup.py' nor 'pyproject.toml' found.""
        )

    if has_pyproject:
        with open(pyproject_toml, encoding=""utf-8"") as f:
            pp_toml = tomllib.loads(f.read())
        build_system = pp_toml.get(""build-system"")
    else:
        build_system = None

    
    
    
    
    
    
    if has_pyproject and not has_setup:
        if use_pep517 is not None and not use_pep517:
            raise InstallationError(
                ""Disabling PEP 517 processing is invalid: ""
                ""project does not have a setup.py""
            )
        use_pep517 = True
    elif build_system and ""build-backend"" in build_system:
        if use_pep517 is not None and not use_pep517:
            raise InstallationError(
                ""Disabling PEP 517 processing is invalid: ""
                ""project specifies a build backend of {} ""
                ""in pyproject.toml"".format(build_system[""build-backend""])
            )
        use_pep517 = True

    
    
    
    

    
    
    
    
    
    elif use_pep517 is None:
        use_pep517 = (
            has_pyproject
            or not importlib.util.find_spec(""setuptools"")
            or not importlib.util.find_spec(""wheel"")
        )

    
    assert use_pep517 is not None

    
    
    if not use_pep517:
        return None

    if build_system is None:
        
        
        
        
        
        
        

        build_system = {
            ""requires"": [""setuptools>=40.8.0""],
            ""build-backend"": ""setuptools.build_meta:__legacy__"",
        }

    
    
    
    
    assert build_system is not None

    
    

    
    if ""requires"" not in build_system:
        raise MissingPyProjectBuildRequires(package=req_name)

    
    requires = build_system[""requires""]
    if not _is_list_of_str(requires):
        raise InvalidPyProjectBuildRequires(
            package=req_name,
            reason=""It is not a list of strings."",
        )

    
    for requirement in requires:
        try:
            get_requirement(requirement)
        except InvalidRequirement as error:
            raise InvalidPyProjectBuildRequires(
                package=req_name,
                reason=f""It contains an invalid requirement: {requirement!r}"",
            ) from error

    backend = build_system.get(""build-backend"")
    backend_path = build_system.get(""backend-path"", [])
    check: list[str] = []
    if backend is None:
        
        
        
        
        
        
        
        
        
        
        
        backend = ""setuptools.build_meta:__legacy__""
        check = [""setuptools>=40.8.0""]

    return BuildSystemDetails(requires, backend, check, backend_path)

from __future__ import annotations

import datetime
import functools
import hashlib
import json
import logging
import optparse
import os.path
import sys
from dataclasses import dataclass
from typing import Any, Callable

from pip._vendor.packaging.version import Version
from pip._vendor.packaging.version import parse as parse_version
from pip._vendor.rich.console import Group
from pip._vendor.rich.markup import escape
from pip._vendor.rich.text import Text

from pip._internal.index.collector import LinkCollector
from pip._internal.index.package_finder import PackageFinder
from pip._internal.metadata import get_default_environment
from pip._internal.models.selection_prefs import SelectionPreferences
from pip._internal.network.session import PipSession
from pip._internal.utils.compat import WINDOWS
from pip._internal.utils.entrypoints import (
    get_best_invocation_for_this_pip,
    get_best_invocation_for_this_python,
)
from pip._internal.utils.filesystem import adjacent_tmp_file, check_path_owner, replace
from pip._internal.utils.misc import (
    ExternallyManagedEnvironment,
    check_externally_managed,
    ensure_dir,
)

_WEEK = datetime.timedelta(days=7)

logger = logging.getLogger(__name__)


def _get_statefile_name(key: str) -> str:
    key_bytes = key.encode()
    name = hashlib.sha224(key_bytes).hexdigest()
    return name


def _convert_date(isodate: str) -> datetime.datetime:
    
    return datetime.datetime.fromisoformat(isodate.replace(""Z"", ""+00:00""))


class SelfCheckState:
    def __init__(self, cache_dir: str) -> None:
        self._state: dict[str, Any] = {}
        self._statefile_path = None

        
        if cache_dir:
            self._statefile_path = os.path.join(
                cache_dir, ""selfcheck"", _get_statefile_name(self.key)
            )
            try:
                with open(self._statefile_path, encoding=""utf-8"") as statefile:
                    self._state = json.load(statefile)
            except (OSError, ValueError, KeyError):
                
                
                pass

    @property
    def key(self) -> str:
        return sys.prefix

    def get(self, current_time: datetime.datetime) -> str | None:
        
        if not self._state:
            return None

        if ""last_check"" not in self._state:
            return None

        if ""pypi_version"" not in self._state:
            return None

        
        last_check = _convert_date(self._state[""last_check""])
        time_since_last_check = current_time - last_check
        if time_since_last_check > _WEEK:
            return None

        return self._state[""pypi_version""]

    def set(self, pypi_version: str, current_time: datetime.datetime) -> None:
        
        if not self._statefile_path:
            return

        
        if not check_path_owner(os.path.dirname(self._statefile_path)):
            return

        
        
        ensure_dir(os.path.dirname(self._statefile_path))

        state = {
            
            
            ""key"": self.key,
            ""last_check"": current_time.isoformat(),
            ""pypi_version"": pypi_version,
        }

        text = json.dumps(state, sort_keys=True, separators=("","", "":""))

        with adjacent_tmp_file(self._statefile_path) as f:
            f.write(text.encode())

        try:
            
            
            replace(f.name, self._statefile_path)
        except OSError:
            
            pass


@dataclass
class UpgradePrompt:
    old: str
    new: str

    def __rich__(self) -> Group:
        if WINDOWS:
            pip_cmd = f""{get_best_invocation_for_this_python()} -m pip""
        else:
            pip_cmd = get_best_invocation_for_this_pip()

        notice = ""[bold][[reset][blue]notice[reset][bold]][reset]""
        return Group(
            Text(),
            Text.from_markup(
                f""{notice} A new release of pip is available: ""
                f""[red]{self.old}[reset] -> [green]{self.new}[reset]""
            ),
            Text.from_markup(
                f""{notice} To update, run: ""
                f""[green]{escape(pip_cmd)} install --upgrade pip""
            ),
        )


def was_installed_by_pip(pkg: str) -> bool:
    
    dist = get_default_environment().get_distribution(pkg)
    return dist is not None and ""pip"" == dist.installer


def _get_current_remote_pip_version(
    session: PipSession, options: optparse.Values
) -> str | None:
    
    link_collector = LinkCollector.create(
        session,
        options=options,
        suppress_no_index=True,
    )

    
    
    selection_prefs = SelectionPreferences(
        allow_yanked=False,
        allow_all_prereleases=False,  
    )

    finder = PackageFinder.create(
        link_collector=link_collector,
        selection_prefs=selection_prefs,
    )
    best_candidate = finder.find_best_candidate(""pip"").best_candidate
    if best_candidate is None:
        return None

    return str(best_candidate.version)


def _self_version_check_logic(
    *,
    state: SelfCheckState,
    current_time: datetime.datetime,
    local_version: Version,
    get_remote_version: Callable[[], str | None],
) -> UpgradePrompt | None:
    remote_version_str = state.get(current_time)
    if remote_version_str is None:
        remote_version_str = get_remote_version()
        if remote_version_str is None:
            logger.debug(""No remote pip version found"")
            return None
        state.set(remote_version_str, current_time)

    remote_version = parse_version(remote_version_str)
    logger.debug(""Remote version of pip: %s"", remote_version)
    logger.debug(""Local version of pip:  %s"", local_version)

    pip_installed_by_pip = was_installed_by_pip(""pip"")
    logger.debug(""Was pip installed by pip? %s"", pip_installed_by_pip)
    if not pip_installed_by_pip:
        return None  

    local_version_is_older = (
        local_version < remote_version
        and local_version.base_version != remote_version.base_version
    )
    if local_version_is_older:
        return UpgradePrompt(old=str(local_version), new=remote_version_str)

    return None


def pip_self_version_check(session: PipSession, options: optparse.Values) -> None:
    
    installed_dist = get_default_environment().get_distribution(""pip"")
    if not installed_dist:
        return
    try:
        check_externally_managed()
    except ExternallyManagedEnvironment:
        return

    upgrade_prompt = _self_version_check_logic(
        state=SelfCheckState(cache_dir=options.cache_dir),
        current_time=datetime.datetime.now(datetime.timezone.utc),
        local_version=installed_dist.version,
        get_remote_version=functools.partial(
            _get_current_remote_pip_version, session, options
        ),
    )
    if upgrade_prompt is not None:
        logger.warning(""%s"", upgrade_prompt, extra={""rich"": True})



from __future__ import annotations

import logging
import os.path
import re
import shutil
from collections.abc import Iterable

from pip._vendor.packaging.utils import canonicalize_name, canonicalize_version
from pip._vendor.packaging.version import InvalidVersion, Version

from pip._internal.cache import WheelCache
from pip._internal.exceptions import InvalidWheelFilename, UnsupportedWheel
from pip._internal.metadata import FilesystemWheel, get_wheel_distribution
from pip._internal.models.link import Link
from pip._internal.models.wheel import Wheel
from pip._internal.operations.build.wheel import build_wheel_pep517
from pip._internal.operations.build.wheel_editable import build_wheel_editable
from pip._internal.operations.build.wheel_legacy import build_wheel_legacy
from pip._internal.req.req_install import InstallRequirement
from pip._internal.utils.logging import indent_log
from pip._internal.utils.misc import ensure_dir, hash_file
from pip._internal.utils.setuptools_build import make_setuptools_clean_args
from pip._internal.utils.subprocess import call_subprocess
from pip._internal.utils.temp_dir import TempDirectory
from pip._internal.utils.urls import path_to_url
from pip._internal.vcs import vcs

logger = logging.getLogger(__name__)

_egg_info_re = re.compile(r""([a-z0-9_.]+)-([a-z0-9_.!+-]+)"", re.IGNORECASE)

BuildResult = tuple[list[InstallRequirement], list[InstallRequirement]]


def _contains_egg_info(s: str) -> bool:
    
    return bool(_egg_info_re.search(s))


def _should_build(
    req: InstallRequirement,
) -> bool:
    
    assert not req.constraint

    if req.is_wheel:
        return False

    assert req.source_dir

    if req.editable:
        
        return req.supports_pyproject_editable

    return True


def should_build_for_install_command(
    req: InstallRequirement,
) -> bool:
    return _should_build(req)


def _should_cache(
    req: InstallRequirement,
) -> bool | None:
    
    if req.editable or not req.source_dir:
        
        return False

    if req.link and req.link.is_vcs:
        
        
        assert not req.editable
        assert req.source_dir
        vcs_backend = vcs.get_backend_for_scheme(req.link.scheme)
        assert vcs_backend
        if vcs_backend.is_immutable_rev_checkout(req.link.url, req.source_dir):
            return True
        return False

    assert req.link
    base, ext = req.link.splitext()
    if _contains_egg_info(base):
        return True

    
    return False


def _get_cache_dir(
    req: InstallRequirement,
    wheel_cache: WheelCache,
) -> str:
    
    cache_available = bool(wheel_cache.cache_dir)
    assert req.link
    if cache_available and _should_cache(req):
        cache_dir = wheel_cache.get_path_for_link(req.link)
    else:
        cache_dir = wheel_cache.get_ephem_path_for_link(req.link)
    return cache_dir


def _verify_one(req: InstallRequirement, wheel_path: str) -> None:
    canonical_name = canonicalize_name(req.name or """")
    w = Wheel(os.path.basename(wheel_path))
    if canonicalize_name(w.name) != canonical_name:
        raise InvalidWheelFilename(
            f""Wheel has unexpected file name: expected {canonical_name!r}, ""
            f""got {w.name!r}"",
        )
    dist = get_wheel_distribution(FilesystemWheel(wheel_path), canonical_name)
    dist_verstr = str(dist.version)
    if canonicalize_version(dist_verstr) != canonicalize_version(w.version):
        raise InvalidWheelFilename(
            f""Wheel has unexpected file name: expected {dist_verstr!r}, ""
            f""got {w.version!r}"",
        )
    metadata_version_value = dist.metadata_version
    if metadata_version_value is None:
        raise UnsupportedWheel(""Missing Metadata-Version"")
    try:
        metadata_version = Version(metadata_version_value)
    except InvalidVersion:
        msg = f""Invalid Metadata-Version: {metadata_version_value}""
        raise UnsupportedWheel(msg)
    if metadata_version >= Version(""1.2"") and not isinstance(dist.version, Version):
        raise UnsupportedWheel(
            f""Metadata 1.2 mandates PEP 440 version, but {dist_verstr!r} is not""
        )


def _build_one(
    req: InstallRequirement,
    output_dir: str,
    verify: bool,
    build_options: list[str],
    global_options: list[str],
    editable: bool,
) -> str | None:
    
    artifact = ""editable"" if editable else ""wheel""
    try:
        ensure_dir(output_dir)
    except OSError as e:
        logger.warning(
            ""Building %s for %s failed: %s"",
            artifact,
            req.name,
            e,
        )
        return None

    
    with req.build_env:
        wheel_path = _build_one_inside_env(
            req, output_dir, build_options, global_options, editable
        )
    if wheel_path and verify:
        try:
            _verify_one(req, wheel_path)
        except (InvalidWheelFilename, UnsupportedWheel) as e:
            logger.warning(""Built %s for %s is invalid: %s"", artifact, req.name, e)
            return None
    return wheel_path


def _build_one_inside_env(
    req: InstallRequirement,
    output_dir: str,
    build_options: list[str],
    global_options: list[str],
    editable: bool,
) -> str | None:
    with TempDirectory(kind=""wheel"") as temp_dir:
        assert req.name
        if req.use_pep517:
            assert req.metadata_directory
            assert req.pep517_backend
            if global_options:
                logger.warning(
                    ""Ignoring --global-option when building %s using PEP 517"", req.name
                )
            if build_options:
                logger.warning(
                    ""Ignoring --build-option when building %s using PEP 517"", req.name
                )
            if editable:
                wheel_path = build_wheel_editable(
                    name=req.name,
                    backend=req.pep517_backend,
                    metadata_directory=req.metadata_directory,
                    tempd=temp_dir.path,
                )
            else:
                wheel_path = build_wheel_pep517(
                    name=req.name,
                    backend=req.pep517_backend,
                    metadata_directory=req.metadata_directory,
                    tempd=temp_dir.path,
                )
        else:
            wheel_path = build_wheel_legacy(
                name=req.name,
                setup_py_path=req.setup_py_path,
                source_dir=req.unpacked_source_directory,
                global_options=global_options,
                build_options=build_options,
                tempd=temp_dir.path,
            )

        if wheel_path is not None:
            wheel_name = os.path.basename(wheel_path)
            dest_path = os.path.join(output_dir, wheel_name)
            try:
                wheel_hash, length = hash_file(wheel_path)
                shutil.move(wheel_path, dest_path)
                logger.info(
                    ""Created wheel for %s: filename=%s size=%d sha256=%s"",
                    req.name,
                    wheel_name,
                    length,
                    wheel_hash.hexdigest(),
                )
                logger.info(""Stored in directory: %s"", output_dir)
                return dest_path
            except Exception as e:
                logger.warning(
                    ""Building wheel for %s failed: %s"",
                    req.name,
                    e,
                )
        
        if not req.use_pep517:
            _clean_one_legacy(req, global_options)
        return None


def _clean_one_legacy(req: InstallRequirement, global_options: list[str]) -> bool:
    clean_args = make_setuptools_clean_args(
        req.setup_py_path,
        global_options=global_options,
    )

    logger.info(""Running setup.py clean for %s"", req.name)
    try:
        call_subprocess(
            clean_args, command_desc=""python setup.py clean"", cwd=req.source_dir
        )
        return True
    except Exception:
        logger.error(""Failed cleaning build dir for %s"", req.name)
        return False


def build(
    requirements: Iterable[InstallRequirement],
    wheel_cache: WheelCache,
    verify: bool,
    build_options: list[str],
    global_options: list[str],
) -> BuildResult:
    
    if not requirements:
        return [], []

    
    logger.info(
        ""Building wheels for collected packages: %s"",
        "", "".join(req.name for req in requirements),  
    )

    with indent_log():
        build_successes, build_failures = [], []
        for req in requirements:
            assert req.name
            cache_dir = _get_cache_dir(req, wheel_cache)
            wheel_file = _build_one(
                req,
                cache_dir,
                verify,
                build_options,
                global_options,
                req.editable and req.permit_editable_wheels,
            )
            if wheel_file:
                
                if req.download_info is not None:
                    
                    
                    
                    wheel_cache.record_download_origin(cache_dir, req.download_info)
                
                req.link = Link(path_to_url(wheel_file))
                req.local_file_path = req.link.file_path
                assert req.link.is_wheel
                build_successes.append(req)
            else:
                build_failures.append(req)

    
    if build_successes:
        logger.info(
            ""Successfully built %s"",
            "" "".join([req.name for req in build_successes]),  
        )
    if build_failures:
        logger.info(
            ""Failed to build %s"",
            "" "".join([req.name for req in build_failures]),  
        )
    
    return build_successes, build_failures

from __future__ import annotations

from pip._internal.utils import _log



_log.init_logging()


def main(args: list[str] | None = None) -> int:
    
    from pip._internal.utils.entrypoints import _wrapper

    return _wrapper(args)



from __future__ import annotations

import optparse
import os
import sys
from collections.abc import Iterable
from itertools import chain
from typing import Any

from pip._internal.cli.main_parser import create_main_parser
from pip._internal.commands import commands_dict, create_command
from pip._internal.metadata import get_default_environment


def autocomplete() -> None:
    
    
    if ""PIP_AUTO_COMPLETE"" not in os.environ:
        return
    
    
    if not os.environ.get(""COMP_WORDS"") or not os.environ.get(""COMP_CWORD""):
        return
    cwords = os.environ[""COMP_WORDS""].split()[1:]
    cword = int(os.environ[""COMP_CWORD""])
    try:
        current = cwords[cword - 1]
    except IndexError:
        current = """"

    parser = create_main_parser()
    subcommands = list(commands_dict)
    options = []

    
    subcommand_name: str | None = None
    for word in cwords:
        if word in subcommands:
            subcommand_name = word
            break
    
    if subcommand_name is not None:
        
        if subcommand_name == ""help"":
            sys.exit(1)
        
        should_list_installed = not current.startswith(""-"") and subcommand_name in [
            ""show"",
            ""uninstall"",
        ]
        if should_list_installed:
            env = get_default_environment()
            lc = current.lower()
            installed = [
                dist.canonical_name
                for dist in env.iter_installed_distributions(local_only=True)
                if dist.canonical_name.startswith(lc)
                and dist.canonical_name not in cwords[1:]
            ]
            
            if installed:
                for dist in installed:
                    print(dist)
                sys.exit(1)

        should_list_installables = (
            not current.startswith(""-"") and subcommand_name == ""install""
        )
        if should_list_installables:
            for path in auto_complete_paths(current, ""path""):
                print(path)
            sys.exit(1)

        subcommand = create_command(subcommand_name)

        for opt in subcommand.parser.option_list_all:
            if opt.help != optparse.SUPPRESS_HELP:
                options += [
                    (opt_str, opt.nargs) for opt_str in opt._long_opts + opt._short_opts
                ]

        
        prev_opts = [x.split(""="")[0] for x in cwords[1 : cword - 1]]
        options = [(x, v) for (x, v) in options if x not in prev_opts]
        
        options = [(k, v) for k, v in options if k.startswith(current)]
        
        completion_type = get_path_completion_type(
            cwords,
            cword,
            subcommand.parser.option_list_all,
        )
        
        
        if completion_type:
            paths = auto_complete_paths(current, completion_type)
            options = [(path, 0) for path in paths]
        for option in options:
            opt_label = option[0]
            
            if option[1] and option[0][:2] == ""--"":
                opt_label += ""=""
            print(opt_label)

        
        if not any(name in cwords for name in subcommand.handler_map()):
            for handler_name in subcommand.handler_map():
                if handler_name.startswith(current):
                    print(handler_name)
    else:
        

        opts = [i.option_list for i in parser.option_groups]
        opts.append(parser.option_list)
        flattened_opts = chain.from_iterable(opts)
        if current.startswith(""-""):
            for opt in flattened_opts:
                if opt.help != optparse.SUPPRESS_HELP:
                    subcommands += opt._long_opts + opt._short_opts
        else:
            
            completion_type = get_path_completion_type(cwords, cword, flattened_opts)
            if completion_type:
                subcommands = list(auto_complete_paths(current, completion_type))

        print("" "".join([x for x in subcommands if x.startswith(current)]))
    sys.exit(1)


def get_path_completion_type(
    cwords: list[str], cword: int, opts: Iterable[Any]
) -> str | None:
    
    if cword < 2 or not cwords[cword - 2].startswith(""-""):
        return None
    for opt in opts:
        if opt.help == optparse.SUPPRESS_HELP:
            continue
        for o in str(opt).split(""/""):
            if cwords[cword - 2].split(""="")[0] == o:
                if not opt.metavar or any(
                    x in (""path"", ""file"", ""dir"") for x in opt.metavar.split(""/"")
                ):
                    return opt.metavar
    return None


def auto_complete_paths(current: str, completion_type: str) -> Iterable[str]:
    
    directory, filename = os.path.split(current)
    current_path = os.path.abspath(directory)
    
    if not os.access(current_path, os.R_OK):
        return
    filename = os.path.normcase(filename)
    
    file_list = (
        x for x in os.listdir(current_path) if os.path.normcase(x).startswith(filename)
    )
    for f in file_list:
        opt = os.path.join(current_path, f)
        comp_file = os.path.normcase(os.path.join(directory, f))
        
        
        
        if completion_type != ""dir"" and os.path.isfile(opt):
            yield comp_file
        elif os.path.isdir(opt):
            yield os.path.join(comp_file, """")



from __future__ import annotations

import logging
import logging.config
import optparse
import os
import sys
import traceback
from optparse import Values
from typing import Callable

from pip._vendor.rich import reconfigure
from pip._vendor.rich import traceback as rich_traceback

from pip._internal.cli import cmdoptions
from pip._internal.cli.command_context import CommandContextMixIn
from pip._internal.cli.parser import ConfigOptionParser, UpdatingDefaultsHelpFormatter
from pip._internal.cli.status_codes import (
    ERROR,
    PREVIOUS_BUILD_DIR_ERROR,
    UNKNOWN_ERROR,
    VIRTUALENV_NOT_FOUND,
)
from pip._internal.exceptions import (
    BadCommand,
    CommandError,
    DiagnosticPipError,
    InstallationError,
    NetworkConnectionError,
    PreviousBuildDirError,
)
from pip._internal.utils.filesystem import check_path_owner
from pip._internal.utils.logging import BrokenStdoutLoggingError, setup_logging
from pip._internal.utils.misc import get_prog, normalize_path
from pip._internal.utils.temp_dir import TempDirectoryTypeRegistry as TempDirRegistry
from pip._internal.utils.temp_dir import global_tempdir_manager, tempdir_registry
from pip._internal.utils.virtualenv import running_under_virtualenv

__all__ = [""Command""]

logger = logging.getLogger(__name__)


class Command(CommandContextMixIn):
    usage: str = """"
    ignore_require_venv: bool = False

    def __init__(self, name: str, summary: str, isolated: bool = False) -> None:
        super().__init__()

        self.name = name
        self.summary = summary
        self.parser = ConfigOptionParser(
            usage=self.usage,
            prog=f""{get_prog()} {name}"",
            formatter=UpdatingDefaultsHelpFormatter(),
            add_help_option=False,
            name=name,
            description=self.__doc__,
            isolated=isolated,
        )

        self.tempdir_registry: TempDirRegistry | None = None

        
        optgroup_name = f""{self.name.capitalize()} Options""
        self.cmd_opts = optparse.OptionGroup(self.parser, optgroup_name)

        
        gen_opts = cmdoptions.make_option_group(
            cmdoptions.general_group,
            self.parser,
        )
        self.parser.add_option_group(gen_opts)

        self.add_options()

    def add_options(self) -> None:
        pass

    def handle_pip_version_check(self, options: Values) -> None:
        
        
        
        assert not hasattr(options, ""no_index"")

    def run(self, options: Values, args: list[str]) -> int:
        raise NotImplementedError

    def _run_wrapper(self, level_number: int, options: Values, args: list[str]) -> int:
        def _inner_run() -> int:
            try:
                return self.run(options, args)
            finally:
                self.handle_pip_version_check(options)

        if options.debug_mode:
            rich_traceback.install(show_locals=True)
            return _inner_run()

        try:
            status = _inner_run()
            assert isinstance(status, int)
            return status
        except DiagnosticPipError as exc:
            logger.error(""%s"", exc, extra={""rich"": True})
            logger.debug(""Exception information:"", exc_info=True)

            return ERROR
        except PreviousBuildDirError as exc:
            logger.critical(str(exc))
            logger.debug(""Exception information:"", exc_info=True)

            return PREVIOUS_BUILD_DIR_ERROR
        except (
            InstallationError,
            BadCommand,
            NetworkConnectionError,
        ) as exc:
            logger.critical(str(exc))
            logger.debug(""Exception information:"", exc_info=True)

            return ERROR
        except CommandError as exc:
            logger.critical(""%s"", exc)
            logger.debug(""Exception information:"", exc_info=True)

            return ERROR
        except BrokenStdoutLoggingError:
            
            
            print(""ERROR: Pipe to stdout was broken"", file=sys.stderr)
            if level_number <= logging.DEBUG:
                traceback.print_exc(file=sys.stderr)

            return ERROR
        except KeyboardInterrupt:
            logger.critical(""Operation cancelled by user"")
            logger.debug(""Exception information:"", exc_info=True)

            return ERROR
        except BaseException:
            logger.critical(""Exception:"", exc_info=True)

            return UNKNOWN_ERROR

    def parse_args(self, args: list[str]) -> tuple[Values, list[str]]:
        
        return self.parser.parse_args(args)

    def main(self, args: list[str]) -> int:
        try:
            with self.main_context():
                return self._main(args)
        finally:
            logging.shutdown()

    def _main(self, args: list[str]) -> int:
        
        
        
        self.tempdir_registry = self.enter_context(tempdir_registry())
        
        
        self.enter_context(global_tempdir_manager())

        options, args = self.parse_args(args)

        
        self.verbosity = options.verbose - options.quiet
        if options.debug_mode:
            self.verbosity = 2

        if hasattr(options, ""progress_bar"") and options.progress_bar == ""auto"":
            options.progress_bar = ""on"" if self.verbosity >= 0 else ""off""

        reconfigure(no_color=options.no_color)
        level_number = setup_logging(
            verbosity=self.verbosity,
            no_color=options.no_color,
            user_log_file=options.log,
        )

        always_enabled_features = set(options.features_enabled) & set(
            cmdoptions.ALWAYS_ENABLED_FEATURES
        )
        if always_enabled_features:
            logger.warning(
                ""The following features are always enabled: %s. "",
                "", "".join(sorted(always_enabled_features)),
            )

        
        
        
        
        
        if options.python and ""_PIP_RUNNING_IN_SUBPROCESS"" not in os.environ:
            logger.critical(
                ""The --python option must be placed before the pip subcommand name""
            )
            sys.exit(ERROR)

        
        
        

        if options.no_input:
            os.environ[""PIP_NO_INPUT""] = ""1""

        if options.exists_action:
            os.environ[""PIP_EXISTS_ACTION""] = "" "".join(options.exists_action)

        if options.require_venv and not self.ignore_require_venv:
            
            if not running_under_virtualenv():
                logger.critical(""Could not find an activated virtualenv (required)."")
                sys.exit(VIRTUALENV_NOT_FOUND)

        if options.cache_dir:
            options.cache_dir = normalize_path(options.cache_dir)
            if not check_path_owner(options.cache_dir):
                logger.warning(
                    ""The directory '%s' or its parent directory is not owned ""
                    ""or is not writable by the current user. The cache ""
                    ""has been disabled. Check the permissions and owner of ""
                    ""that directory. If executing pip with sudo, you should ""
                    ""use sudo's -H flag."",
                    options.cache_dir,
                )
                options.cache_dir = None

        return self._run_wrapper(level_number, options, args)

    def handler_map(self) -> dict[str, Callable[[Values, list[str]], None]]:
        
        return {}





from __future__ import annotations

import importlib.util
import logging
import os
import pathlib
import textwrap
from functools import partial
from optparse import SUPPRESS_HELP, Option, OptionGroup, OptionParser, Values
from textwrap import dedent
from typing import Any, Callable

from pip._vendor.packaging.utils import canonicalize_name

from pip._internal.cli.parser import ConfigOptionParser
from pip._internal.exceptions import CommandError
from pip._internal.locations import USER_CACHE_DIR, get_src_prefix
from pip._internal.models.format_control import FormatControl
from pip._internal.models.index import PyPI
from pip._internal.models.target_python import TargetPython
from pip._internal.utils.hashes import STRONG_HASHES
from pip._internal.utils.misc import strtobool

logger = logging.getLogger(__name__)


def raise_option_error(parser: OptionParser, option: Option, msg: str) -> None:
    
    msg = f""{option} error: {msg}""
    msg = textwrap.fill("" "".join(msg.split()))
    parser.error(msg)


def make_option_group(group: dict[str, Any], parser: ConfigOptionParser) -> OptionGroup:
    
    option_group = OptionGroup(parser, group[""name""])
    for option in group[""options""]:
        option_group.add_option(option())
    return option_group


def check_dist_restriction(options: Values, check_target: bool = False) -> None:
    
    dist_restriction_set = any(
        [
            options.python_version,
            options.platforms,
            options.abis,
            options.implementation,
        ]
    )

    binary_only = FormatControl(set(), {"":all:""})
    sdist_dependencies_allowed = (
        options.format_control != binary_only and not options.ignore_dependencies
    )

    
    
    
    if dist_restriction_set and sdist_dependencies_allowed:
        raise CommandError(
            ""When restricting platform and interpreter constraints using ""
            ""--python-version, --platform, --abi, or --implementation, ""
            ""either --no-deps must be set, or --only-binary=:all: must be ""
            ""set and --no-binary must not be set (or must be set to ""
            "":none:).""
        )

    if check_target:
        if not options.dry_run and dist_restriction_set and not options.target_dir:
            raise CommandError(
                ""Can not use any platform or abi specific options unless ""
                ""installing via '--target' or using '--dry-run'""
            )


def _path_option_check(option: Option, opt: str, value: str) -> str:
    return os.path.expanduser(value)


def _package_name_option_check(option: Option, opt: str, value: str) -> str:
    return canonicalize_name(value)


class PipOption(Option):
    TYPES = Option.TYPES + (""path"", ""package_name"")
    TYPE_CHECKER = Option.TYPE_CHECKER.copy()
    TYPE_CHECKER[""package_name""] = _package_name_option_check
    TYPE_CHECKER[""path""] = _path_option_check






help_: Callable[..., Option] = partial(
    Option,
    ""-h"",
    ""--help"",
    dest=""help"",
    action=""help"",
    help=""Show help."",
)

debug_mode: Callable[..., Option] = partial(
    Option,
    ""--debug"",
    dest=""debug_mode"",
    action=""store_true"",
    default=False,
    help=(
        ""Let unhandled exceptions propagate outside the main subroutine, ""
        ""instead of logging them to stderr.""
    ),
)

isolated_mode: Callable[..., Option] = partial(
    Option,
    ""--isolated"",
    dest=""isolated_mode"",
    action=""store_true"",
    default=False,
    help=(
        ""Run pip in an isolated mode, ignoring environment variables and user ""
        ""configuration.""
    ),
)

require_virtualenv: Callable[..., Option] = partial(
    Option,
    ""--require-virtualenv"",
    ""--require-venv"",
    dest=""require_venv"",
    action=""store_true"",
    default=False,
    help=(
        ""Allow pip to only run in a virtual environment; ""
        ""exit with an error otherwise.""
    ),
)

override_externally_managed: Callable[..., Option] = partial(
    Option,
    ""--break-system-packages"",
    dest=""override_externally_managed"",
    action=""store_true"",
    help=""Allow pip to modify an EXTERNALLY-MANAGED Python installation"",
)

python: Callable[..., Option] = partial(
    Option,
    ""--python"",
    dest=""python"",
    help=""Run pip with the specified Python interpreter."",
)

verbose: Callable[..., Option] = partial(
    Option,
    ""-v"",
    ""--verbose"",
    dest=""verbose"",
    action=""count"",
    default=0,
    help=""Give more output. Option is additive, and can be used up to 3 times."",
)

no_color: Callable[..., Option] = partial(
    Option,
    ""--no-color"",
    dest=""no_color"",
    action=""store_true"",
    default=False,
    help=""Suppress colored output."",
)

version: Callable[..., Option] = partial(
    Option,
    ""-V"",
    ""--version"",
    dest=""version"",
    action=""store_true"",
    help=""Show version and exit."",
)

quiet: Callable[..., Option] = partial(
    Option,
    ""-q"",
    ""--quiet"",
    dest=""quiet"",
    action=""count"",
    default=0,
    help=(
        ""Give less output. Option is additive, and can be used up to 3""
        "" times (corresponding to WARNING, ERROR, and CRITICAL logging""
        "" levels).""
    ),
)

progress_bar: Callable[..., Option] = partial(
    Option,
    ""--progress-bar"",
    dest=""progress_bar"",
    type=""choice"",
    choices=[""auto"", ""on"", ""off"", ""raw""],
    default=""auto"",
    help=(
        ""Specify whether the progress bar should be used. In 'auto'""
        "" mode, --quiet will suppress all progress bars.""
        "" [auto, on, off, raw] (default: auto)""
    ),
)

log: Callable[..., Option] = partial(
    PipOption,
    ""--log"",
    ""--log-file"",
    ""--local-log"",
    dest=""log"",
    metavar=""path"",
    type=""path"",
    help=""Path to a verbose appending log."",
)

no_input: Callable[..., Option] = partial(
    Option,
    
    ""--no-input"",
    dest=""no_input"",
    action=""store_true"",
    default=False,
    help=""Disable prompting for input."",
)

keyring_provider: Callable[..., Option] = partial(
    Option,
    ""--keyring-provider"",
    dest=""keyring_provider"",
    choices=[""auto"", ""disabled"", ""import"", ""subprocess""],
    default=""auto"",
    help=(
        ""Enable the credential lookup via the keyring library if user input is allowed.""
        "" Specify which mechanism to use [auto, disabled, import, subprocess].""
        "" (default: %default)""
    ),
)

proxy: Callable[..., Option] = partial(
    Option,
    ""--proxy"",
    dest=""proxy"",
    type=""str"",
    default="""",
    help=""Specify a proxy in the form scheme://[user:passwd@]proxy.server:port."",
)

retries: Callable[..., Option] = partial(
    Option,
    ""--retries"",
    dest=""retries"",
    type=""int"",
    default=5,
    help=""Maximum attempts to establish a new HTTP connection. (default: %default)"",
)

resume_retries: Callable[..., Option] = partial(
    Option,
    ""--resume-retries"",
    dest=""resume_retries"",
    type=""int"",
    default=5,
    help=""Maximum attempts to resume or restart an incomplete download. ""
    ""(default: %default)"",
)

timeout: Callable[..., Option] = partial(
    Option,
    ""--timeout"",
    ""--default-timeout"",
    metavar=""sec"",
    dest=""timeout"",
    type=""float"",
    default=15,
    help=""Set the socket timeout (default %default seconds)."",
)


def exists_action() -> Option:
    return Option(
        
        ""--exists-action"",
        dest=""exists_action"",
        type=""choice"",
        choices=[""s"", ""i"", ""w"", ""b"", ""a""],
        default=[],
        action=""append"",
        metavar=""action"",
        help=""Default action when a path already exists: ""
        ""(s)witch, (i)gnore, (w)ipe, (b)ackup, (a)bort."",
    )


cert: Callable[..., Option] = partial(
    PipOption,
    ""--cert"",
    dest=""cert"",
    type=""path"",
    metavar=""path"",
    help=(
        ""Path to PEM-encoded CA certificate bundle. ""
        ""If provided, overrides the default. ""
        ""See 'SSL Certificate Verification' in pip documentation ""
        ""for more information.""
    ),
)

client_cert: Callable[..., Option] = partial(
    PipOption,
    ""--client-cert"",
    dest=""client_cert"",
    type=""path"",
    default=None,
    metavar=""path"",
    help=""Path to SSL client certificate, a single file containing the ""
    ""private key and the certificate in PEM format."",
)

index_url: Callable[..., Option] = partial(
    Option,
    ""-i"",
    ""--index-url"",
    ""--pypi-url"",
    dest=""index_url"",
    metavar=""URL"",
    default=PyPI.simple_url,
    help=""Base URL of the Python Package Index (default %default). ""
    ""This should point to a repository compliant with PEP 503 ""
    ""(the simple repository API) or a local directory laid out ""
    ""in the same format."",
)


def extra_index_url() -> Option:
    return Option(
        ""--extra-index-url"",
        dest=""extra_index_urls"",
        metavar=""URL"",
        action=""append"",
        default=[],
        help=""Extra URLs of package indexes to use in addition to ""
        ""--index-url. Should follow the same rules as ""
        ""--index-url."",
    )


no_index: Callable[..., Option] = partial(
    Option,
    ""--no-index"",
    dest=""no_index"",
    action=""store_true"",
    default=False,
    help=""Ignore package index (only looking at --find-links URLs instead)."",
)


def find_links() -> Option:
    return Option(
        ""-f"",
        ""--find-links"",
        dest=""find_links"",
        action=""append"",
        default=[],
        metavar=""url"",
        help=""If a URL or path to an html file, then parse for links to ""
        ""archives such as sdist (.tar.gz) or wheel (.whl) files. ""
        ""If a local path or file:// URL that's a directory, ""
        ""then look for archives in the directory listing. ""
        ""Links to VCS project URLs are not supported."",
    )


def trusted_host() -> Option:
    return Option(
        ""--trusted-host"",
        dest=""trusted_hosts"",
        action=""append"",
        metavar=""HOSTNAME"",
        default=[],
        help=""Mark this host or host:port pair as trusted, even though it ""
        ""does not have valid or any HTTPS."",
    )


def constraints() -> Option:
    return Option(
        ""-c"",
        ""--constraint"",
        dest=""constraints"",
        action=""append"",
        default=[],
        metavar=""file"",
        help=""Constrain versions using the given constraints file. ""
        ""This option can be used multiple times."",
    )


def requirements() -> Option:
    return Option(
        ""-r"",
        ""--requirement"",
        dest=""requirements"",
        action=""append"",
        default=[],
        metavar=""file"",
        help=""Install from the given requirements file. ""
        ""This option can be used multiple times."",
    )


def editable() -> Option:
    return Option(
        ""-e"",
        ""--editable"",
        dest=""editables"",
        action=""append"",
        default=[],
        metavar=""path/url"",
        help=(
            ""Install a project in editable mode (i.e. setuptools ""
            '""develop mode"") from a local project path or a VCS url.'
        ),
    )


def _handle_src(option: Option, opt_str: str, value: str, parser: OptionParser) -> None:
    value = os.path.abspath(value)
    setattr(parser.values, option.dest, value)


src: Callable[..., Option] = partial(
    PipOption,
    ""--src"",
    ""--source"",
    ""--source-dir"",
    ""--source-directory"",
    dest=""src_dir"",
    type=""path"",
    metavar=""dir"",
    default=get_src_prefix(),
    action=""callback"",
    callback=_handle_src,
    help=""Directory to check out editable projects into. ""
    'The default in a virtualenv is ""<venv path>/src"". '
    'The default for global installs is ""<current dir>/src"".',
)


def _get_format_control(values: Values, option: Option) -> Any:
    
    return getattr(values, option.dest)


def _handle_no_binary(
    option: Option, opt_str: str, value: str, parser: OptionParser
) -> None:
    existing = _get_format_control(parser.values, option)
    FormatControl.handle_mutual_excludes(
        value,
        existing.no_binary,
        existing.only_binary,
    )


def _handle_only_binary(
    option: Option, opt_str: str, value: str, parser: OptionParser
) -> None:
    existing = _get_format_control(parser.values, option)
    FormatControl.handle_mutual_excludes(
        value,
        existing.only_binary,
        existing.no_binary,
    )


def no_binary() -> Option:
    format_control = FormatControl(set(), set())
    return Option(
        ""--no-binary"",
        dest=""format_control"",
        action=""callback"",
        callback=_handle_no_binary,
        type=""str"",
        default=format_control,
        help=""Do not use binary packages. Can be supplied multiple times, and ""
        'each time adds to the existing value. Accepts either "":all:"" to '
        'disable all binary packages, "":none:"" to empty the set (notice '
        ""the colons), or one or more package names with commas between ""
        ""them (no colons). Note that some packages are tricky to compile ""
        ""and may fail to install when this option is used on them."",
    )


def only_binary() -> Option:
    format_control = FormatControl(set(), set())
    return Option(
        ""--only-binary"",
        dest=""format_control"",
        action=""callback"",
        callback=_handle_only_binary,
        type=""str"",
        default=format_control,
        help=""Do not use source packages. Can be supplied multiple times, and ""
        'each time adds to the existing value. Accepts either "":all:"" to '
        'disable all source packages, "":none:"" to empty the set, or one '
        ""or more package names with commas between them. Packages ""
        ""without binary distributions will fail to install when this ""
        ""option is used on them."",
    )


platforms: Callable[..., Option] = partial(
    Option,
    ""--platform"",
    dest=""platforms"",
    metavar=""platform"",
    action=""append"",
    default=None,
    help=(
        ""Only use wheels compatible with <platform>. Defaults to the ""
        ""platform of the running system. Use this option multiple times to ""
        ""specify multiple platforms supported by the target interpreter.""
    ),
)



def _convert_python_version(value: str) -> tuple[tuple[int, ...], str | None]:
    
    if not value:
        
        return (None, None)

    parts = value.split(""."")
    if len(parts) > 3:
        return ((), ""at most three version parts are allowed"")

    if len(parts) == 1:
        
        value = parts[0]
        if len(value) > 1:
            parts = [value[0], value[1:]]

    try:
        version_info = tuple(int(part) for part in parts)
    except ValueError:
        return ((), ""each version part must be an integer"")

    return (version_info, None)


def _handle_python_version(
    option: Option, opt_str: str, value: str, parser: OptionParser
) -> None:
    
    version_info, error_msg = _convert_python_version(value)
    if error_msg is not None:
        msg = f""invalid --python-version value: {value!r}: {error_msg}""
        raise_option_error(parser, option=option, msg=msg)

    parser.values.python_version = version_info


python_version: Callable[..., Option] = partial(
    Option,
    ""--python-version"",
    dest=""python_version"",
    metavar=""python_version"",
    action=""callback"",
    callback=_handle_python_version,
    type=""str"",
    default=None,
    help=dedent(
        
    ),
)


implementation: Callable[..., Option] = partial(
    Option,
    ""--implementation"",
    dest=""implementation"",
    metavar=""implementation"",
    default=None,
    help=(
        ""Only use wheels compatible with Python ""
        ""implementation <implementation>, e.g. 'pp', 'jy', 'cp', ""
        "" or 'ip'. If not specified, then the current ""
        ""interpreter implementation is used.  Use 'py' to force ""
        ""implementation-agnostic wheels.""
    ),
)


abis: Callable[..., Option] = partial(
    Option,
    ""--abi"",
    dest=""abis"",
    metavar=""abi"",
    action=""append"",
    default=None,
    help=(
        ""Only use wheels compatible with Python abi <abi>, e.g. 'pypy_41'. ""
        ""If not specified, then the current interpreter abi tag is used. ""
        ""Use this option multiple times to specify multiple abis supported ""
        ""by the target interpreter. Generally you will need to specify ""
        ""--implementation, --platform, and --python-version when using this ""
        ""option.""
    ),
)


def add_target_python_options(cmd_opts: OptionGroup) -> None:
    cmd_opts.add_option(platforms())
    cmd_opts.add_option(python_version())
    cmd_opts.add_option(implementation())
    cmd_opts.add_option(abis())


def make_target_python(options: Values) -> TargetPython:
    target_python = TargetPython(
        platforms=options.platforms,
        py_version_info=options.python_version,
        abis=options.abis,
        implementation=options.implementation,
    )

    return target_python


def prefer_binary() -> Option:
    return Option(
        ""--prefer-binary"",
        dest=""prefer_binary"",
        action=""store_true"",
        default=False,
        help=(
            ""Prefer binary packages over source packages, even if the ""
            ""source packages are newer.""
        ),
    )


cache_dir: Callable[..., Option] = partial(
    PipOption,
    ""--cache-dir"",
    dest=""cache_dir"",
    default=USER_CACHE_DIR,
    metavar=""dir"",
    type=""path"",
    help=""Store the cache data in <dir>."",
)


def _handle_no_cache_dir(
    option: Option, opt: str, value: str, parser: OptionParser
) -> None:
    
    
    
    
    
    if value is not None:
        
        try:
            strtobool(value)
        except ValueError as exc:
            raise_option_error(parser, option=option, msg=str(exc))

    
    
    
    
    
    
    
    parser.values.cache_dir = False


no_cache: Callable[..., Option] = partial(
    Option,
    ""--no-cache-dir"",
    dest=""cache_dir"",
    action=""callback"",
    callback=_handle_no_cache_dir,
    help=""Disable the cache."",
)

no_deps: Callable[..., Option] = partial(
    Option,
    ""--no-deps"",
    ""--no-dependencies"",
    dest=""ignore_dependencies"",
    action=""store_true"",
    default=False,
    help=""Don't install package dependencies."",
)


def _handle_dependency_group(
    option: Option, opt: str, value: str, parser: OptionParser
) -> None:
    
    path, sep, groupname = value.rpartition("":"")
    if not sep:
        path = ""pyproject.toml""
    else:
        
        if pathlib.PurePath(path).name != ""pyproject.toml"":
            msg = ""group paths use 'pyproject.toml' filenames""
            raise_option_error(parser, option=option, msg=msg)

    parser.values.dependency_groups.append((path, groupname))


dependency_groups: Callable[..., Option] = partial(
    Option,
    ""--group"",
    dest=""dependency_groups"",
    default=[],
    type=str,
    action=""callback"",
    callback=_handle_dependency_group,
    metavar=""[path:]group"",
    help='Install a named dependency-group from a ""pyproject.toml"" file. '
    'If a path is given, the name of the file must be ""pyproject.toml"". '
    'Defaults to using ""pyproject.toml"" in the current directory.',
)

ignore_requires_python: Callable[..., Option] = partial(
    Option,
    ""--ignore-requires-python"",
    dest=""ignore_requires_python"",
    action=""store_true"",
    help=""Ignore the Requires-Python information."",
)

no_build_isolation: Callable[..., Option] = partial(
    Option,
    ""--no-build-isolation"",
    dest=""build_isolation"",
    action=""store_false"",
    default=True,
    help=""Disable isolation when building a modern source distribution. ""
    ""Build dependencies specified by PEP 518 must be already installed ""
    ""if this option is used."",
)

check_build_deps: Callable[..., Option] = partial(
    Option,
    ""--check-build-dependencies"",
    dest=""check_build_deps"",
    action=""store_true"",
    default=False,
    help=""Check the build dependencies when PEP517 is used."",
)


def _handle_no_use_pep517(
    option: Option, opt: str, value: str, parser: OptionParser
) -> None:
    
    
    
    
    
    if value is not None:
        msg = 
        raise_option_error(parser, option=option, msg=msg)

    
    
    packages = (""setuptools"",)
    if not all(importlib.util.find_spec(package) for package in packages):
        msg = (
            f""It is not possible to use --no-use-pep517 ""
            f""without {' and '.join(packages)} installed.""
        )
        raise_option_error(parser, option=option, msg=msg)

    
    parser.values.use_pep517 = False


use_pep517: Any = partial(
    Option,
    ""--use-pep517"",
    dest=""use_pep517"",
    action=""store_true"",
    default=None,
    help=""Use PEP 517 for building source distributions ""
    ""(use --no-use-pep517 to force legacy behaviour)."",
)

no_use_pep517: Any = partial(
    Option,
    ""--no-use-pep517"",
    dest=""use_pep517"",
    action=""callback"",
    callback=_handle_no_use_pep517,
    default=None,
    help=SUPPRESS_HELP,
)


def _handle_config_settings(
    option: Option, opt_str: str, value: str, parser: OptionParser
) -> None:
    key, sep, val = value.partition(""="")
    if sep != ""="":
        parser.error(f""Arguments to {opt_str} must be of the form KEY=VAL"")
    dest = getattr(parser.values, option.dest)
    if dest is None:
        dest = {}
        setattr(parser.values, option.dest, dest)
    if key in dest:
        if isinstance(dest[key], list):
            dest[key].append(val)
        else:
            dest[key] = [dest[key], val]
    else:
        dest[key] = val


config_settings: Callable[..., Option] = partial(
    Option,
    ""-C"",
    ""--config-settings"",
    dest=""config_settings"",
    type=str,
    action=""callback"",
    callback=_handle_config_settings,
    metavar=""settings"",
    help=""Configuration settings to be passed to the PEP 517 build backend. ""
    ""Settings take the form KEY=VALUE. Use multiple --config-settings options ""
    ""to pass multiple keys to the backend."",
)

build_options: Callable[..., Option] = partial(
    Option,
    ""--build-option"",
    dest=""build_options"",
    metavar=""options"",
    action=""append"",
    help=""Extra arguments to be supplied to 'setup.py bdist_wheel'."",
)

global_options: Callable[..., Option] = partial(
    Option,
    ""--global-option"",
    dest=""global_options"",
    action=""append"",
    metavar=""options"",
    help=""Extra global options to be supplied to the setup.py ""
    ""call before the install or bdist_wheel command."",
)

no_clean: Callable[..., Option] = partial(
    Option,
    ""--no-clean"",
    action=""store_true"",
    default=False,
    help=""Don't clean up build directories."",
)

pre: Callable[..., Option] = partial(
    Option,
    ""--pre"",
    action=""store_true"",
    default=False,
    help=""Include pre-release and development versions. By default, ""
    ""pip only finds stable versions."",
)

json: Callable[..., Option] = partial(
    Option,
    ""--json"",
    action=""store_true"",
    default=False,
    help=""Output data in a machine-readable JSON format."",
)

disable_pip_version_check: Callable[..., Option] = partial(
    Option,
    ""--disable-pip-version-check"",
    dest=""disable_pip_version_check"",
    action=""store_true"",
    default=False,
    help=""Don't periodically check PyPI to determine whether a new version ""
    ""of pip is available for download. Implied with --no-index."",
)

root_user_action: Callable[..., Option] = partial(
    Option,
    ""--root-user-action"",
    dest=""root_user_action"",
    default=""warn"",
    choices=[""warn"", ""ignore""],
    help=""Action if pip is run as a root user [warn, ignore] (default: warn)"",
)


def _handle_merge_hash(
    option: Option, opt_str: str, value: str, parser: OptionParser
) -> None:
    
    if not parser.values.hashes:
        parser.values.hashes = {}
    try:
        algo, digest = value.split("":"", 1)
    except ValueError:
        parser.error(
            f""Arguments to {opt_str} must be a hash name ""
            ""followed by a value, like --hash=sha256:""
            ""abcde...""
        )
    if algo not in STRONG_HASHES:
        parser.error(
            ""Allowed hash algorithms for {} are {}."".format(
                opt_str, "", "".join(STRONG_HASHES)
            )
        )
    parser.values.hashes.setdefault(algo, []).append(digest)


hash: Callable[..., Option] = partial(
    Option,
    ""--hash"",
    
    
    dest=""hashes"",
    action=""callback"",
    callback=_handle_merge_hash,
    type=""string"",
    help=""Verify that the package's archive matches this ""
    ""hash before installing. Example: --hash=sha256:abcdef..."",
)


require_hashes: Callable[..., Option] = partial(
    Option,
    ""--require-hashes"",
    dest=""require_hashes"",
    action=""store_true"",
    default=False,
    help=""Require a hash to check each requirement against, for ""
    ""repeatable installs. This option is implied when any package in a ""
    ""requirements file has a --hash option."",
)


list_path: Callable[..., Option] = partial(
    PipOption,
    ""--path"",
    dest=""path"",
    type=""path"",
    action=""append"",
    help=""Restrict to the specified installation path for listing ""
    ""packages (can be used multiple times)."",
)


def check_list_path_option(options: Values) -> None:
    if options.path and (options.user or options.local):
        raise CommandError(""Cannot combine '--path' with '--user' or '--local'"")


list_exclude: Callable[..., Option] = partial(
    PipOption,
    ""--exclude"",
    dest=""excludes"",
    action=""append"",
    metavar=""package"",
    type=""package_name"",
    help=""Exclude specified package from the output"",
)


no_python_version_warning: Callable[..., Option] = partial(
    Option,
    ""--no-python-version-warning"",
    dest=""no_python_version_warning"",
    action=""store_true"",
    default=False,
    help=SUPPRESS_HELP,  
)



ALWAYS_ENABLED_FEATURES = [
    ""truststore"",  
    ""no-binary-enable-wheel-cache"",  
]

use_new_feature: Callable[..., Option] = partial(
    Option,
    ""--use-feature"",
    dest=""features_enabled"",
    metavar=""feature"",
    action=""append"",
    default=[],
    choices=[
        ""fast-deps"",
    ]
    + ALWAYS_ENABLED_FEATURES,
    help=""Enable new functionality, that may be backward incompatible."",
)

use_deprecated_feature: Callable[..., Option] = partial(
    Option,
    ""--use-deprecated"",
    dest=""deprecated_features_enabled"",
    metavar=""feature"",
    action=""append"",
    default=[],
    choices=[
        ""legacy-resolver"",
        ""legacy-certs"",
    ],
    help=(""Enable deprecated functionality, that will be removed in the future.""),
)





general_group: dict[str, Any] = {
    ""name"": ""General Options"",
    ""options"": [
        help_,
        debug_mode,
        isolated_mode,
        require_virtualenv,
        python,
        verbose,
        version,
        quiet,
        log,
        no_input,
        keyring_provider,
        proxy,
        retries,
        timeout,
        exists_action,
        trusted_host,
        cert,
        client_cert,
        cache_dir,
        no_cache,
        disable_pip_version_check,
        no_color,
        no_python_version_warning,
        use_new_feature,
        use_deprecated_feature,
        resume_retries,
    ],
}

index_group: dict[str, Any] = {
    ""name"": ""Package Index Options"",
    ""options"": [
        index_url,
        extra_index_url,
        no_index,
        find_links,
    ],
}

from collections.abc import Generator
from contextlib import AbstractContextManager, ExitStack, contextmanager
from typing import TypeVar

_T = TypeVar(""_T"", covariant=True)


class CommandContextMixIn:
    def __init__(self) -> None:
        super().__init__()
        self._in_main_context = False
        self._main_context = ExitStack()

    @contextmanager
    def main_context(self) -> Generator[None, None, None]:
        assert not self._in_main_context

        self._in_main_context = True
        try:
            with self._main_context:
                yield
        finally:
            self._in_main_context = False

    def enter_context(self, context_provider: AbstractContextManager[_T]) -> _T:
        assert self._in_main_context

        return self._main_context.enter_context(context_provider)



from __future__ import annotations

import logging
import os
import sys
from functools import lru_cache
from optparse import Values
from typing import TYPE_CHECKING

from pip._vendor import certifi

from pip._internal.cli.base_command import Command
from pip._internal.cli.command_context import CommandContextMixIn

if TYPE_CHECKING:
    from ssl import SSLContext

    from pip._internal.network.session import PipSession

logger = logging.getLogger(__name__)


@lru_cache
def _create_truststore_ssl_context() -> SSLContext | None:
    if sys.version_info < (3, 10):
        logger.debug(""Disabling truststore because Python version isn't 3.10+"")
        return None

    try:
        import ssl
    except ImportError:
        logger.warning(""Disabling truststore since ssl support is missing"")
        return None

    try:
        from pip._vendor import truststore
    except ImportError:
        logger.warning(""Disabling truststore because platform isn't supported"")
        return None

    ctx = truststore.SSLContext(ssl.PROTOCOL_TLS_CLIENT)
    ctx.load_verify_locations(certifi.where())
    return ctx


class SessionCommandMixin(CommandContextMixIn):
    

    def __init__(self) -> None:
        super().__init__()
        self._session: PipSession | None = None

    @classmethod
    def _get_index_urls(cls, options: Values) -> list[str] | None:
        
        index_urls = []
        if not getattr(options, ""no_index"", False):
            url = getattr(options, ""index_url"", None)
            if url:
                index_urls.append(url)
        urls = getattr(options, ""extra_index_urls"", None)
        if urls:
            index_urls.extend(urls)
        
        return index_urls or None

    def get_default_session(self, options: Values) -> PipSession:
        
        if self._session is None:
            self._session = self.enter_context(self._build_session(options))
            
            
            
            assert self._session is not None
        return self._session

    def _build_session(
        self,
        options: Values,
        retries: int | None = None,
        timeout: int | None = None,
    ) -> PipSession:
        from pip._internal.network.session import PipSession

        cache_dir = options.cache_dir
        assert not cache_dir or os.path.isabs(cache_dir)

        if ""legacy-certs"" not in options.deprecated_features_enabled:
            ssl_context = _create_truststore_ssl_context()
        else:
            ssl_context = None

        session = PipSession(
            cache=os.path.join(cache_dir, ""http-v2"") if cache_dir else None,
            retries=retries if retries is not None else options.retries,
            trusted_hosts=options.trusted_hosts,
            index_urls=self._get_index_urls(options),
            ssl_context=ssl_context,
        )

        
        if options.cert:
            session.verify = options.cert

        
        if options.client_cert:
            session.cert = options.client_cert

        
        if options.timeout or timeout:
            session.timeout = timeout if timeout is not None else options.timeout

        
        if options.proxy:
            session.proxies = {
                ""http"": options.proxy,
                ""https"": options.proxy,
            }
            session.trust_env = False
            session.pip_proxy = options.proxy

        
        session.auth.prompting = not options.no_input
        session.auth.keyring_provider = options.keyring_provider

        return session


def _pip_self_version_check(session: PipSession, options: Values) -> None:
    from pip._internal.self_outdated_check import pip_self_version_check as check

    check(session, options)


class IndexGroupCommand(Command, SessionCommandMixin):
    

    def handle_pip_version_check(self, options: Values) -> None:
        
        
        assert hasattr(options, ""no_index"")

        if options.disable_pip_version_check or options.no_index:
            return

        try:
            
            session = self._build_session(
                options,
                retries=0,
                timeout=min(5, options.timeout),
            )
            with session:
                _pip_self_version_check(session, options)
        except Exception:
            logger.warning(""There was an error checking the latest version of pip."")
            logger.debug(""See below for error"", exc_info=True)



from __future__ import annotations

import locale
import logging
import os
import sys
import warnings

from pip._internal.cli.autocompletion import autocomplete
from pip._internal.cli.main_parser import parse_command
from pip._internal.commands import create_command
from pip._internal.exceptions import PipError
from pip._internal.utils import deprecation

logger = logging.getLogger(__name__)





























def main(args: list[str] | None = None) -> int:
    if args is None:
        args = sys.argv[1:]

    
    
    
    
    warnings.filterwarnings(
        action=""ignore"", category=DeprecationWarning, module="".*pkg_resources""
    )

    
    deprecation.install_warning_logger()

    autocomplete()

    try:
        cmd_name, cmd_args = parse_command(args)
    except PipError as exc:
        sys.stderr.write(f""ERROR: {exc}"")
        sys.stderr.write(os.linesep)
        sys.exit(1)

    
    
    try:
        locale.setlocale(locale.LC_ALL, """")
    except locale.Error as e:
        
        logger.debug(""Ignoring error %s when setting locale"", e)
    command = create_command(cmd_name, isolated=(""--isolated"" in cmd_args))

    return command.main(cmd_args)



from __future__ import annotations

import os
import subprocess
import sys

from pip._internal.build_env import get_runnable_pip
from pip._internal.cli import cmdoptions
from pip._internal.cli.parser import ConfigOptionParser, UpdatingDefaultsHelpFormatter
from pip._internal.commands import commands_dict, get_similar_commands
from pip._internal.exceptions import CommandError
from pip._internal.utils.misc import get_pip_version, get_prog

__all__ = [""create_main_parser"", ""parse_command""]


def create_main_parser() -> ConfigOptionParser:
    

    parser = ConfigOptionParser(
        usage=""\n%prog <command> [options]"",
        add_help_option=False,
        formatter=UpdatingDefaultsHelpFormatter(),
        name=""global"",
        prog=get_prog(),
    )
    parser.disable_interspersed_args()

    parser.version = get_pip_version()

    
    gen_opts = cmdoptions.make_option_group(cmdoptions.general_group, parser)
    parser.add_option_group(gen_opts)

    
    parser.main = True  

    
    description = [""""] + [
        f""{name:27} {command_info.summary}""
        for name, command_info in commands_dict.items()
    ]
    parser.description = ""\n"".join(description)

    return parser


def identify_python_interpreter(python: str) -> str | None:
    
    
    
    if os.path.exists(python):
        if os.path.isdir(python):
            
            
            for exe in (""bin/python"", ""Scripts/python.exe""):
                py = os.path.join(python, exe)
                if os.path.exists(py):
                    return py
        else:
            return python

    
    return None


def parse_command(args: list[str]) -> tuple[str, list[str]]:
    parser = create_main_parser()

    
    
    
    
    
    
    
    general_options, args_else = parser.parse_args(args)

    
    if general_options.python and ""_PIP_RUNNING_IN_SUBPROCESS"" not in os.environ:
        
        interpreter = identify_python_interpreter(general_options.python)
        if interpreter is None:
            raise CommandError(
                f""Could not locate Python interpreter {general_options.python}""
            )

        pip_cmd = [
            interpreter,
            get_runnable_pip(),
        ]
        pip_cmd.extend(args)

        
        
        os.environ[""_PIP_RUNNING_IN_SUBPROCESS""] = ""1""
        returncode = 0
        try:
            proc = subprocess.run(pip_cmd)
            returncode = proc.returncode
        except (subprocess.SubprocessError, OSError) as exc:
            raise CommandError(f""Failed to run pip under {interpreter}: {exc}"")
        sys.exit(returncode)

    
    if general_options.version:
        sys.stdout.write(parser.version)
        sys.stdout.write(os.linesep)
        sys.exit()

    
    if not args_else or (args_else[0] == ""help"" and len(args_else) == 1):
        parser.print_help()
        sys.exit()

    
    cmd_name = args_else[0]

    if cmd_name not in commands_dict:
        guess = get_similar_commands(cmd_name)

        msg = [f'unknown command ""{cmd_name}""']
        if guess:
            msg.append(f'maybe you meant ""{guess}""')

        raise CommandError("" - "".join(msg))

    
    cmd_args = args[:]
    cmd_args.remove(cmd_name)

    return cmd_name, cmd_args



from __future__ import annotations

import logging
import optparse
import shutil
import sys
import textwrap
from collections.abc import Generator
from contextlib import suppress
from typing import Any, NoReturn

from pip._internal.cli.status_codes import UNKNOWN_ERROR
from pip._internal.configuration import Configuration, ConfigurationError
from pip._internal.utils.misc import redact_auth_from_url, strtobool

logger = logging.getLogger(__name__)


class PrettyHelpFormatter(optparse.IndentedHelpFormatter):
    

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        
        kwargs[""max_help_position""] = 30
        kwargs[""indent_increment""] = 1
        kwargs[""width""] = shutil.get_terminal_size()[0] - 2
        super().__init__(*args, **kwargs)

    def format_option_strings(self, option: optparse.Option) -> str:
        return self._format_option_strings(option)

    def _format_option_strings(
        self, option: optparse.Option, mvarfmt: str = "" <{}>"", optsep: str = "", ""
    ) -> str:
        
        opts = []

        if option._short_opts:
            opts.append(option._short_opts[0])
        if option._long_opts:
            opts.append(option._long_opts[0])
        if len(opts) > 1:
            opts.insert(1, optsep)

        if option.takes_value():
            assert option.dest is not None
            metavar = option.metavar or option.dest.lower()
            opts.append(mvarfmt.format(metavar.lower()))

        return """".join(opts)

    def format_heading(self, heading: str) -> str:
        if heading == ""Options"":
            return """"
        return heading + "":\n""

    def format_usage(self, usage: str) -> str:
        
        msg = ""\nUsage: {}\n"".format(self.indent_lines(textwrap.dedent(usage), ""  ""))
        return msg

    def format_description(self, description: str | None) -> str:
        
        if description:
            if hasattr(self.parser, ""main""):
                label = ""Commands""
            else:
                label = ""Description""
            
            description = description.lstrip(""\n"")
            
            description = description.rstrip()
            
            description = self.indent_lines(textwrap.dedent(description), ""  "")
            description = f""{label}:\n{description}\n""
            return description
        else:
            return """"

    def format_epilog(self, epilog: str | None) -> str:
        
        if epilog:
            return epilog
        else:
            return """"

    def indent_lines(self, text: str, indent: str) -> str:
        new_lines = [indent + line for line in text.split(""\n"")]
        return ""\n"".join(new_lines)


class UpdatingDefaultsHelpFormatter(PrettyHelpFormatter):
    

    def expand_default(self, option: optparse.Option) -> str:
        default_values = None
        if self.parser is not None:
            assert isinstance(self.parser, ConfigOptionParser)
            self.parser._update_defaults(self.parser.defaults)
            assert option.dest is not None
            default_values = self.parser.defaults.get(option.dest)
        help_text = super().expand_default(option)

        if default_values and option.metavar == ""URL"":
            if isinstance(default_values, str):
                default_values = [default_values]

            
            if not isinstance(default_values, list):
                default_values = []

            for val in default_values:
                help_text = help_text.replace(val, redact_auth_from_url(val))

        return help_text


class CustomOptionParser(optparse.OptionParser):
    def insert_option_group(
        self, idx: int, *args: Any, **kwargs: Any
    ) -> optparse.OptionGroup:
        
        group = self.add_option_group(*args, **kwargs)

        self.option_groups.pop()
        self.option_groups.insert(idx, group)

        return group

    @property
    def option_list_all(self) -> list[optparse.Option]:
        
        res = self.option_list[:]
        for i in self.option_groups:
            res.extend(i.option_list)

        return res


class ConfigOptionParser(CustomOptionParser):
    

    def __init__(
        self,
        *args: Any,
        name: str,
        isolated: bool = False,
        **kwargs: Any,
    ) -> None:
        self.name = name
        self.config = Configuration(isolated)

        assert self.name
        super().__init__(*args, **kwargs)

    def check_default(self, option: optparse.Option, key: str, val: Any) -> Any:
        try:
            return option.check_value(key, val)
        except optparse.OptionValueError as exc:
            print(f""An error occurred during configuration: {exc}"")
            sys.exit(3)

    def _get_ordered_configuration_items(
        self,
    ) -> Generator[tuple[str, Any], None, None]:
        
        override_order = [""global"", self.name, "":env:""]

        
        section_items: dict[str, list[tuple[str, Any]]] = {
            name: [] for name in override_order
        }

        for _, value in self.config.items():  
            for section_key, val in value.items():
                
                if not val:
                    logger.debug(
                        ""Ignoring configuration key '%s' as its value is empty."",
                        section_key,
                    )
                    continue

                section, key = section_key.split(""."", 1)
                if section in override_order:
                    section_items[section].append((key, val))

            
            for section in override_order:
                yield from section_items[section]

    def _update_defaults(self, defaults: dict[str, Any]) -> dict[str, Any]:
        

        
        self.values = optparse.Values(self.defaults)
        late_eval = set()
        
        for key, val in self._get_ordered_configuration_items():
            
            option = self.get_option(""--"" + key)

            
            
            
            if option is None:
                continue

            assert option.dest is not None

            if option.action in (""store_true"", ""store_false""):
                try:
                    val = strtobool(val)
                except ValueError:
                    self.error(
                        f""{val} is not a valid value for {key} option, ""
                        ""please specify a boolean value like yes/no, ""
                        ""true/false or 1/0 instead.""
                    )
            elif option.action == ""count"":
                with suppress(ValueError):
                    val = strtobool(val)
                with suppress(ValueError):
                    val = int(val)
                if not isinstance(val, int) or val < 0:
                    self.error(
                        f""{val} is not a valid value for {key} option, ""
                        ""please instead specify either a non-negative integer ""
                        ""or a boolean value like yes/no or false/true ""
                        ""which is equivalent to 1/0.""
                    )
            elif option.action == ""append"":
                val = val.split()
                val = [self.check_default(option, key, v) for v in val]
            elif option.action == ""callback"":
                assert option.callback is not None
                late_eval.add(option.dest)
                opt_str = option.get_opt_string()
                val = option.convert_value(opt_str, val)
                
                args = option.callback_args or ()
                kwargs = option.callback_kwargs or {}
                option.callback(option, opt_str, val, self, *args, **kwargs)
            else:
                val = self.check_default(option, key, val)

            defaults[option.dest] = val

        for key in late_eval:
            defaults[key] = getattr(self.values, key)
        self.values = None
        return defaults

    def get_default_values(self) -> optparse.Values:
        
        if not self.process_default_values:
            
            return optparse.Values(self.defaults)

        
        try:
            self.config.load()
        except ConfigurationError as err:
            self.exit(UNKNOWN_ERROR, str(err))

        defaults = self._update_defaults(self.defaults.copy())  
        for option in self._get_all_options():
            assert option.dest is not None
            default = defaults.get(option.dest)
            if isinstance(default, str):
                opt_str = option.get_opt_string()
                defaults[option.dest] = option.check_value(opt_str, default)
        return optparse.Values(defaults)

    def error(self, msg: str) -> NoReturn:
        self.print_usage(sys.stderr)
        self.exit(UNKNOWN_ERROR, f""{msg}\n"")

from __future__ import annotations

import functools
import sys
from collections.abc import Generator, Iterable, Iterator
from typing import Callable, Literal, TypeVar

from pip._vendor.rich.progress import (
    BarColumn,
    DownloadColumn,
    FileSizeColumn,
    MofNCompleteColumn,
    Progress,
    ProgressColumn,
    SpinnerColumn,
    TextColumn,
    TimeElapsedColumn,
    TimeRemainingColumn,
    TransferSpeedColumn,
)

from pip._internal.cli.spinners import RateLimiter
from pip._internal.req.req_install import InstallRequirement
from pip._internal.utils.logging import get_console, get_indentation

T = TypeVar(""T"")
ProgressRenderer = Callable[[Iterable[T]], Iterator[T]]
BarType = Literal[""on"", ""off"", ""raw""]


def _rich_download_progress_bar(
    iterable: Iterable[bytes],
    *,
    bar_type: BarType,
    size: int | None,
    initial_progress: int | None = None,
) -> Generator[bytes, None, None]:
    assert bar_type == ""on"", ""This should only be used in the default mode.""

    if not size:
        total = float(""inf"")
        columns: tuple[ProgressColumn, ...] = (
            TextColumn(""[progress.description]{task.description}""),
            SpinnerColumn(""line"", speed=1.5),
            FileSizeColumn(),
            TransferSpeedColumn(),
            TimeElapsedColumn(),
        )
    else:
        total = size
        columns = (
            TextColumn(""[progress.description]{task.description}""),
            BarColumn(),
            DownloadColumn(),
            TransferSpeedColumn(),
            TextColumn(""{task.fields[time_description]}""),
            TimeRemainingColumn(elapsed_when_finished=True),
        )

    progress = Progress(*columns, refresh_per_second=5)
    task_id = progress.add_task(
        "" "" * (get_indentation() + 2), total=total, time_description=""eta""
    )
    if initial_progress is not None:
        progress.update(task_id, advance=initial_progress)
    with progress:
        for chunk in iterable:
            yield chunk
            progress.update(task_id, advance=len(chunk))
        progress.update(task_id, time_description="""")


def _rich_install_progress_bar(
    iterable: Iterable[InstallRequirement], *, total: int
) -> Iterator[InstallRequirement]:
    columns = (
        TextColumn(""{task.fields[indent]}""),
        BarColumn(),
        MofNCompleteColumn(),
        TextColumn(""{task.description}""),
    )
    console = get_console()

    bar = Progress(*columns, refresh_per_second=6, console=console, transient=True)
    
    
    task = bar.add_task("""", total=total, indent="" "" * get_indentation(), visible=False)
    with bar:
        for req in iterable:
            bar.update(task, description=rf""\[{req.name}]"", visible=True)
            yield req
            bar.advance(task)


def _raw_progress_bar(
    iterable: Iterable[bytes],
    *,
    size: int | None,
    initial_progress: int | None = None,
) -> Generator[bytes, None, None]:
    def write_progress(current: int, total: int) -> None:
        sys.stdout.write(f""Progress {current} of {total}\n"")
        sys.stdout.flush()

    current = initial_progress or 0
    total = size or 0
    rate_limiter = RateLimiter(0.25)

    write_progress(current, total)
    for chunk in iterable:
        current += len(chunk)
        if rate_limiter.ready() or current == total:
            write_progress(current, total)
            rate_limiter.reset()
        yield chunk


def get_download_progress_renderer(
    *, bar_type: BarType, size: int | None = None, initial_progress: int | None = None
) -> ProgressRenderer[bytes]:
    
    if bar_type == ""on"":
        return functools.partial(
            _rich_download_progress_bar,
            bar_type=bar_type,
            size=size,
            initial_progress=initial_progress,
        )
    elif bar_type == ""raw"":
        return functools.partial(
            _raw_progress_bar,
            size=size,
            initial_progress=initial_progress,
        )
    else:
        return iter  


def get_install_progress_renderer(
    *, bar_type: BarType, total: int
) -> ProgressRenderer[InstallRequirement]:
    
    if bar_type == ""on"":
        return functools.partial(_rich_install_progress_bar, total=total)
    else:
        return iter



from __future__ import annotations

import logging
from functools import partial
from optparse import Values
from typing import Any

from pip._internal.build_env import SubprocessBuildEnvironmentInstaller
from pip._internal.cache import WheelCache
from pip._internal.cli import cmdoptions
from pip._internal.cli.index_command import IndexGroupCommand
from pip._internal.cli.index_command import SessionCommandMixin as SessionCommandMixin
from pip._internal.exceptions import CommandError, PreviousBuildDirError
from pip._internal.index.collector import LinkCollector
from pip._internal.index.package_finder import PackageFinder
from pip._internal.models.selection_prefs import SelectionPreferences
from pip._internal.models.target_python import TargetPython
from pip._internal.network.session import PipSession
from pip._internal.operations.build.build_tracker import BuildTracker
from pip._internal.operations.prepare import RequirementPreparer
from pip._internal.req.constructors import (
    install_req_from_editable,
    install_req_from_line,
    install_req_from_parsed_requirement,
    install_req_from_req_string,
)
from pip._internal.req.req_dependency_group import parse_dependency_groups
from pip._internal.req.req_file import parse_requirements
from pip._internal.req.req_install import InstallRequirement
from pip._internal.resolution.base import BaseResolver
from pip._internal.utils.temp_dir import (
    TempDirectory,
    TempDirectoryTypeRegistry,
    tempdir_kinds,
)

logger = logging.getLogger(__name__)


KEEPABLE_TEMPDIR_TYPES = [
    tempdir_kinds.BUILD_ENV,
    tempdir_kinds.EPHEM_WHEEL_CACHE,
    tempdir_kinds.REQ_BUILD,
]


def with_cleanup(func: Any) -> Any:
    

    def configure_tempdir_registry(registry: TempDirectoryTypeRegistry) -> None:
        for t in KEEPABLE_TEMPDIR_TYPES:
            registry.set_delete(t, False)

    def wrapper(
        self: RequirementCommand, options: Values, args: list[Any]
    ) -> int | None:
        assert self.tempdir_registry is not None
        if options.no_clean:
            configure_tempdir_registry(self.tempdir_registry)

        try:
            return func(self, options, args)
        except PreviousBuildDirError:
            
            
            
            configure_tempdir_registry(self.tempdir_registry)
            raise

    return wrapper


class RequirementCommand(IndexGroupCommand):
    def __init__(self, *args: Any, **kw: Any) -> None:
        super().__init__(*args, **kw)

        self.cmd_opts.add_option(cmdoptions.dependency_groups())
        self.cmd_opts.add_option(cmdoptions.no_clean())

    @staticmethod
    def determine_resolver_variant(options: Values) -> str:
        
        if ""legacy-resolver"" in options.deprecated_features_enabled:
            return ""legacy""

        return ""resolvelib""

    @classmethod
    def make_requirement_preparer(
        cls,
        temp_build_dir: TempDirectory,
        options: Values,
        build_tracker: BuildTracker,
        session: PipSession,
        finder: PackageFinder,
        use_user_site: bool,
        download_dir: str | None = None,
        verbosity: int = 0,
    ) -> RequirementPreparer:
        
        temp_build_dir_path = temp_build_dir.path
        assert temp_build_dir_path is not None
        legacy_resolver = False

        resolver_variant = cls.determine_resolver_variant(options)
        if resolver_variant == ""resolvelib"":
            lazy_wheel = ""fast-deps"" in options.features_enabled
            if lazy_wheel:
                logger.warning(
                    ""pip is using lazily downloaded wheels using HTTP ""
                    ""range requests to obtain dependency information. ""
                    ""This experimental feature is enabled through ""
                    ""--use-feature=fast-deps and it is not ready for ""
                    ""production.""
                )
        else:
            legacy_resolver = True
            lazy_wheel = False
            if ""fast-deps"" in options.features_enabled:
                logger.warning(
                    ""fast-deps has no effect when used with the legacy resolver.""
                )

        return RequirementPreparer(
            build_dir=temp_build_dir_path,
            src_dir=options.src_dir,
            download_dir=download_dir,
            build_isolation=options.build_isolation,
            build_isolation_installer=SubprocessBuildEnvironmentInstaller(finder),
            check_build_deps=options.check_build_deps,
            build_tracker=build_tracker,
            session=session,
            progress_bar=options.progress_bar,
            finder=finder,
            require_hashes=options.require_hashes,
            use_user_site=use_user_site,
            lazy_wheel=lazy_wheel,
            verbosity=verbosity,
            legacy_resolver=legacy_resolver,
            resume_retries=options.resume_retries,
        )

    @classmethod
    def make_resolver(
        cls,
        preparer: RequirementPreparer,
        finder: PackageFinder,
        options: Values,
        wheel_cache: WheelCache | None = None,
        use_user_site: bool = False,
        ignore_installed: bool = True,
        ignore_requires_python: bool = False,
        force_reinstall: bool = False,
        upgrade_strategy: str = ""to-satisfy-only"",
        use_pep517: bool | None = None,
        py_version_info: tuple[int, ...] | None = None,
    ) -> BaseResolver:
        
        make_install_req = partial(
            install_req_from_req_string,
            isolated=options.isolated_mode,
            use_pep517=use_pep517,
        )
        resolver_variant = cls.determine_resolver_variant(options)
        
        
        
        if resolver_variant == ""resolvelib"":
            import pip._internal.resolution.resolvelib.resolver

            return pip._internal.resolution.resolvelib.resolver.Resolver(
                preparer=preparer,
                finder=finder,
                wheel_cache=wheel_cache,
                make_install_req=make_install_req,
                use_user_site=use_user_site,
                ignore_dependencies=options.ignore_dependencies,
                ignore_installed=ignore_installed,
                ignore_requires_python=ignore_requires_python,
                force_reinstall=force_reinstall,
                upgrade_strategy=upgrade_strategy,
                py_version_info=py_version_info,
            )
        import pip._internal.resolution.legacy.resolver

        return pip._internal.resolution.legacy.resolver.Resolver(
            preparer=preparer,
            finder=finder,
            wheel_cache=wheel_cache,
            make_install_req=make_install_req,
            use_user_site=use_user_site,
            ignore_dependencies=options.ignore_dependencies,
            ignore_installed=ignore_installed,
            ignore_requires_python=ignore_requires_python,
            force_reinstall=force_reinstall,
            upgrade_strategy=upgrade_strategy,
            py_version_info=py_version_info,
        )

    def get_requirements(
        self,
        args: list[str],
        options: Values,
        finder: PackageFinder,
        session: PipSession,
    ) -> list[InstallRequirement]:
        
        requirements: list[InstallRequirement] = []
        for filename in options.constraints:
            for parsed_req in parse_requirements(
                filename,
                constraint=True,
                finder=finder,
                options=options,
                session=session,
            ):
                req_to_add = install_req_from_parsed_requirement(
                    parsed_req,
                    isolated=options.isolated_mode,
                    user_supplied=False,
                )
                requirements.append(req_to_add)

        for req in args:
            req_to_add = install_req_from_line(
                req,
                comes_from=None,
                isolated=options.isolated_mode,
                use_pep517=options.use_pep517,
                user_supplied=True,
                config_settings=getattr(options, ""config_settings"", None),
            )
            requirements.append(req_to_add)

        if options.dependency_groups:
            for req in parse_dependency_groups(options.dependency_groups):
                req_to_add = install_req_from_req_string(
                    req,
                    isolated=options.isolated_mode,
                    use_pep517=options.use_pep517,
                    user_supplied=True,
                )
                requirements.append(req_to_add)

        for req in options.editables:
            req_to_add = install_req_from_editable(
                req,
                user_supplied=True,
                isolated=options.isolated_mode,
                use_pep517=options.use_pep517,
                config_settings=getattr(options, ""config_settings"", None),
            )
            requirements.append(req_to_add)

        
        for filename in options.requirements:
            for parsed_req in parse_requirements(
                filename, finder=finder, options=options, session=session
            ):
                req_to_add = install_req_from_parsed_requirement(
                    parsed_req,
                    isolated=options.isolated_mode,
                    use_pep517=options.use_pep517,
                    user_supplied=True,
                    config_settings=(
                        parsed_req.options.get(""config_settings"")
                        if parsed_req.options
                        else None
                    ),
                )
                requirements.append(req_to_add)

        
        if any(req.has_hash_options for req in requirements):
            options.require_hashes = True

        if not (
            args
            or options.editables
            or options.requirements
            or options.dependency_groups
        ):
            opts = {""name"": self.name}
            if options.find_links:
                raise CommandError(
                    ""You must give at least one requirement to {name} ""
                    '(maybe you meant ""pip {name} {links}""?)'.format(
                        **dict(opts, links="" "".join(options.find_links))
                    )
                )
            else:
                raise CommandError(
                    ""You must give at least one requirement to {name} ""
                    '(see ""pip help {name}"")'.format(**opts)
                )

        return requirements

    @staticmethod
    def trace_basic_info(finder: PackageFinder) -> None:
        
        
        search_scope = finder.search_scope
        locations = search_scope.get_formatted_locations()
        if locations:
            logger.info(locations)

    def _build_package_finder(
        self,
        options: Values,
        session: PipSession,
        target_python: TargetPython | None = None,
        ignore_requires_python: bool | None = None,
    ) -> PackageFinder:
        
        link_collector = LinkCollector.create(session, options=options)
        selection_prefs = SelectionPreferences(
            allow_yanked=True,
            format_control=options.format_control,
            allow_all_prereleases=options.pre,
            prefer_binary=options.prefer_binary,
            ignore_requires_python=ignore_requires_python,
        )

        return PackageFinder.create(
            link_collector=link_collector,
            selection_prefs=selection_prefs,
            target_python=target_python,
        )

from __future__ import annotations

import contextlib
import itertools
import logging
import sys
import time
from collections.abc import Generator
from typing import IO, Final

from pip._vendor.rich.console import (
    Console,
    ConsoleOptions,
    RenderableType,
    RenderResult,
)
from pip._vendor.rich.live import Live
from pip._vendor.rich.measure import Measurement
from pip._vendor.rich.text import Text

from pip._internal.utils.compat import WINDOWS
from pip._internal.utils.logging import get_console, get_indentation

logger = logging.getLogger(__name__)

SPINNER_CHARS: Final = r""-\|/""
SPINS_PER_SECOND: Final = 8


class SpinnerInterface:
    def spin(self) -> None:
        raise NotImplementedError()

    def finish(self, final_status: str) -> None:
        raise NotImplementedError()


class InteractiveSpinner(SpinnerInterface):
    def __init__(
        self,
        message: str,
        file: IO[str] | None = None,
        spin_chars: str = SPINNER_CHARS,
        
        min_update_interval_seconds: float = 1 / SPINS_PER_SECOND,
    ):
        self._message = message
        if file is None:
            file = sys.stdout
        self._file = file
        self._rate_limiter = RateLimiter(min_update_interval_seconds)
        self._finished = False

        self._spin_cycle = itertools.cycle(spin_chars)

        self._file.write("" "" * get_indentation() + self._message + "" ... "")
        self._width = 0

    def _write(self, status: str) -> None:
        assert not self._finished
        
        
        backup = ""\b"" * self._width
        self._file.write(backup + "" "" * self._width + backup)
        
        self._file.write(status)
        self._width = len(status)
        self._file.flush()
        self._rate_limiter.reset()

    def spin(self) -> None:
        if self._finished:
            return
        if not self._rate_limiter.ready():
            return
        self._write(next(self._spin_cycle))

    def finish(self, final_status: str) -> None:
        if self._finished:
            return
        self._write(final_status)
        self._file.write(""\n"")
        self._file.flush()
        self._finished = True






class NonInteractiveSpinner(SpinnerInterface):
    def __init__(self, message: str, min_update_interval_seconds: float = 60.0) -> None:
        self._message = message
        self._finished = False
        self._rate_limiter = RateLimiter(min_update_interval_seconds)
        self._update(""started"")

    def _update(self, status: str) -> None:
        assert not self._finished
        self._rate_limiter.reset()
        logger.info(""%s: %s"", self._message, status)

    def spin(self) -> None:
        if self._finished:
            return
        if not self._rate_limiter.ready():
            return
        self._update(""still running..."")

    def finish(self, final_status: str) -> None:
        if self._finished:
            return
        self._update(f""finished with status '{final_status}'"")
        self._finished = True


class RateLimiter:
    def __init__(self, min_update_interval_seconds: float) -> None:
        self._min_update_interval_seconds = min_update_interval_seconds
        self._last_update: float = 0

    def ready(self) -> bool:
        now = time.time()
        delta = now - self._last_update
        return delta >= self._min_update_interval_seconds

    def reset(self) -> None:
        self._last_update = time.time()


@contextlib.contextmanager
def open_spinner(message: str) -> Generator[SpinnerInterface, None, None]:
    
    
    
    
    
    if sys.stdout.isatty() and logger.getEffectiveLevel() <= logging.INFO:
        spinner: SpinnerInterface = InteractiveSpinner(message)
    else:
        spinner = NonInteractiveSpinner(message)
    try:
        with hidden_cursor(sys.stdout):
            yield spinner
    except KeyboardInterrupt:
        spinner.finish(""canceled"")
        raise
    except Exception:
        spinner.finish(""error"")
        raise
    else:
        spinner.finish(""done"")


class _PipRichSpinner:
    

    def __init__(self, label: str) -> None:
        self.label = label
        self._spin_cycle = itertools.cycle(SPINNER_CHARS)
        self._spinner_text = """"
        self._finished = False
        self._indent = get_indentation() * "" ""

    def __rich_console__(
        self, console: Console, options: ConsoleOptions
    ) -> RenderResult:
        yield self.render()

    def __rich_measure__(
        self, console: Console, options: ConsoleOptions
    ) -> Measurement:
        text = self.render()
        return Measurement.get(console, options, text)

    def render(self) -> RenderableType:
        if not self._finished:
            self._spinner_text = next(self._spin_cycle)

        return Text.assemble(self._indent, self.label, "" ... "", self._spinner_text)

    def finish(self, status: str) -> None:
        
        self._spinner_text = status
        self._finished = True


@contextlib.contextmanager
def open_rich_spinner(label: str, console: Console | None = None) -> Generator[None]:
    if not logger.isEnabledFor(logging.INFO):
        
        yield
        return

    console = console or get_console()
    spinner = _PipRichSpinner(label)
    with Live(spinner, refresh_per_second=SPINS_PER_SECOND, console=console):
        try:
            yield
        except KeyboardInterrupt:
            spinner.finish(""canceled"")
            raise
        except Exception:
            spinner.finish(""error"")
            raise
        else:
            spinner.finish(""done"")


HIDE_CURSOR = ""\x1b[?25l""
SHOW_CURSOR = ""\x1b[?25h""


@contextlib.contextmanager
def hidden_cursor(file: IO[str]) -> Generator[None, None, None]:
    
    
    if WINDOWS:
        yield
    
    
    
    elif not file.isatty() or logger.getEffectiveLevel() > logging.INFO:
        yield
    else:
        file.write(HIDE_CURSOR)
        try:
            yield
        finally:
            file.write(SHOW_CURSOR)

SUCCESS = 0
ERROR = 1
UNKNOWN_ERROR = 2
VIRTUALENV_NOT_FOUND = 3
PREVIOUS_BUILD_DIR_ERROR = 4
NO_MATCHES_FOUND = 23





import os
import textwrap
from optparse import Values
from typing import Callable

from pip._internal.cli.base_command import Command
from pip._internal.cli.status_codes import ERROR, SUCCESS
from pip._internal.exceptions import CommandError, PipError
from pip._internal.utils import filesystem
from pip._internal.utils.logging import getLogger
from pip._internal.utils.misc import format_size

logger = getLogger(__name__)


class CacheCommand(Command):
    

    ignore_require_venv = True
    usage = 

    def add_options(self) -> None:
        self.cmd_opts.add_option(
            ""--format"",
            action=""store"",
            dest=""list_format"",
            default=""human"",
            choices=(""human"", ""abspath""),
            help=""Select the output format among: human (default) or abspath"",
        )

        self.parser.insert_option_group(0, self.cmd_opts)

    def handler_map(self) -> dict[str, Callable[[Values, list[str]], None]]:
        return {
            ""dir"": self.get_cache_dir,
            ""info"": self.get_cache_info,
            ""list"": self.list_cache_items,
            ""remove"": self.remove_cache_items,
            ""purge"": self.purge_cache,
        }

    def run(self, options: Values, args: list[str]) -> int:
        handler_map = self.handler_map()

        if not options.cache_dir:
            logger.error(""pip cache commands can not function since cache is disabled."")
            return ERROR

        
        if not args or args[0] not in handler_map:
            logger.error(
                ""Need an action (%s) to perform."",
                "", "".join(sorted(handler_map)),
            )
            return ERROR

        action = args[0]

        
        try:
            handler_map[action](options, args[1:])
        except PipError as e:
            logger.error(e.args[0])
            return ERROR

        return SUCCESS

    def get_cache_dir(self, options: Values, args: list[str]) -> None:
        if args:
            raise CommandError(""Too many arguments"")

        logger.info(options.cache_dir)

    def get_cache_info(self, options: Values, args: list[str]) -> None:
        if args:
            raise CommandError(""Too many arguments"")

        num_http_files = len(self._find_http_files(options))
        num_packages = len(self._find_wheels(options, ""*""))

        http_cache_location = self._cache_dir(options, ""http-v2"")
        old_http_cache_location = self._cache_dir(options, ""http"")
        wheels_cache_location = self._cache_dir(options, ""wheels"")
        http_cache_size = filesystem.format_size(
            filesystem.directory_size(http_cache_location)
            + filesystem.directory_size(old_http_cache_location)
        )
        wheels_cache_size = filesystem.format_directory_size(wheels_cache_location)

        message = (
            textwrap.dedent(
                  
            )
            .format(
                http_cache_location=http_cache_location,
                old_http_cache_location=old_http_cache_location,
                http_cache_size=http_cache_size,
                num_http_files=num_http_files,
                wheels_cache_location=wheels_cache_location,
                package_count=num_packages,
                wheels_cache_size=wheels_cache_size,
            )
            .strip()
        )

        logger.info(message)

    def list_cache_items(self, options: Values, args: list[str]) -> None:
        if len(args) > 1:
            raise CommandError(""Too many arguments"")

        if args:
            pattern = args[0]
        else:
            pattern = ""*""

        files = self._find_wheels(options, pattern)
        if options.list_format == ""human"":
            self.format_for_human(files)
        else:
            self.format_for_abspath(files)

    def format_for_human(self, files: list[str]) -> None:
        if not files:
            logger.info(""No locally built wheels cached."")
            return

        results = []
        for filename in files:
            wheel = os.path.basename(filename)
            size = filesystem.format_file_size(filename)
            results.append(f"" - {wheel} ({size})"")
        logger.info(""Cache contents:\n"")
        logger.info(""\n"".join(sorted(results)))

    def format_for_abspath(self, files: list[str]) -> None:
        if files:
            logger.info(""\n"".join(sorted(files)))

    def remove_cache_items(self, options: Values, args: list[str]) -> None:
        if len(args) > 1:
            raise CommandError(""Too many arguments"")

        if not args:
            raise CommandError(""Please provide a pattern"")

        files = self._find_wheels(options, args[0])

        no_matching_msg = ""No matching packages""
        if args[0] == ""*"":
            
            files += self._find_http_files(options)
        else:
            
            no_matching_msg += f' for pattern ""{args[0]}""'

        if not files:
            logger.warning(no_matching_msg)

        bytes_removed = 0
        for filename in files:
            bytes_removed += os.stat(filename).st_size
            os.unlink(filename)
            logger.verbose(""Removed %s"", filename)
        logger.info(""Files removed: %s (%s)"", len(files), format_size(bytes_removed))

    def purge_cache(self, options: Values, args: list[str]) -> None:
        if args:
            raise CommandError(""Too many arguments"")

        return self.remove_cache_items(options, [""*""])

    def _cache_dir(self, options: Values, subdir: str) -> str:
        return os.path.join(options.cache_dir, subdir)

    def _find_http_files(self, options: Values) -> list[str]:
        old_http_dir = self._cache_dir(options, ""http"")
        new_http_dir = self._cache_dir(options, ""http-v2"")
        return filesystem.find_files(old_http_dir, ""*"") + filesystem.find_files(
            new_http_dir, ""*""
        )

    def _find_wheels(self, options: Values, pattern: str) -> list[str]:
        wheel_dir = self._cache_dir(options, ""wheels"")

        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        pattern = pattern + (""*.whl"" if ""-"" in pattern else ""-*.whl"")

        return filesystem.find_files(wheel_dir, pattern)

import logging
from optparse import Values

from pip._internal.cli.base_command import Command
from pip._internal.cli.status_codes import ERROR, SUCCESS
from pip._internal.metadata import get_default_environment
from pip._internal.operations.check import (
    check_package_set,
    check_unsupported,
    create_package_set_from_installed,
)
from pip._internal.utils.compatibility_tags import get_supported
from pip._internal.utils.misc import write_output

logger = logging.getLogger(__name__)


class CheckCommand(Command):
    

    ignore_require_venv = True
    usage = 

    def run(self, options: Values, args: list[str]) -> int:
        package_set, parsing_probs = create_package_set_from_installed()
        missing, conflicting = check_package_set(package_set)
        unsupported = list(
            check_unsupported(
                get_default_environment().iter_installed_distributions(),
                get_supported(),
            )
        )

        for project_name in missing:
            version = package_set[project_name].version
            for dependency in missing[project_name]:
                write_output(
                    ""%s %s requires %s, which is not installed."",
                    project_name,
                    version,
                    dependency[0],
                )

        for project_name in conflicting:
            version = package_set[project_name].version
            for dep_name, dep_version, req in conflicting[project_name]:
                write_output(
                    ""%s %s has requirement %s, but you have %s %s."",
                    project_name,
                    version,
                    req,
                    dep_name,
                    dep_version,
                )
        for package in unsupported:
            write_output(
                ""%s %s is not supported on this platform"",
                package.raw_name,
                package.version,
            )
        if missing or conflicting or parsing_probs or unsupported:
            return ERROR
        else:
            write_output(""No broken requirements found."")
            return SUCCESS

import sys
import textwrap
from optparse import Values

from pip._internal.cli.base_command import Command
from pip._internal.cli.status_codes import SUCCESS
from pip._internal.utils.misc import get_prog

BASE_COMPLETION = 

COMPLETION_SCRIPTS = {
    ""bash"": ,
    ""zsh"": ,
    ""fish"": ,
    ""powershell"": ,
}


class CompletionCommand(Command):
    

    ignore_require_venv = True

    def add_options(self) -> None:
        self.cmd_opts.add_option(
            ""--bash"",
            ""-b"",
            action=""store_const"",
            const=""bash"",
            dest=""shell"",
            help=""Emit completion code for bash"",
        )
        self.cmd_opts.add_option(
            ""--zsh"",
            ""-z"",
            action=""store_const"",
            const=""zsh"",
            dest=""shell"",
            help=""Emit completion code for zsh"",
        )
        self.cmd_opts.add_option(
            ""--fish"",
            ""-f"",
            action=""store_const"",
            const=""fish"",
            dest=""shell"",
            help=""Emit completion code for fish"",
        )
        self.cmd_opts.add_option(
            ""--powershell"",
            ""-p"",
            action=""store_const"",
            const=""powershell"",
            dest=""shell"",
            help=""Emit completion code for powershell"",
        )

        self.parser.insert_option_group(0, self.cmd_opts)

    def run(self, options: Values, args: list[str]) -> int:
        
        shells = COMPLETION_SCRIPTS.keys()
        shell_options = [""--"" + shell for shell in sorted(shells)]
        if options.shell in shells:
            script = textwrap.dedent(
                COMPLETION_SCRIPTS.get(options.shell, """").format(prog=get_prog())
            )
            print(BASE_COMPLETION.format(script=script, shell=options.shell))
            return SUCCESS
        else:
            sys.stderr.write(
                ""ERROR: You must pass {}\n"".format("" or "".join(shell_options))
            )
            return SUCCESS

from __future__ import annotations

import logging
import os
import subprocess
from optparse import Values
from typing import Any, Callable

from pip._internal.cli.base_command import Command
from pip._internal.cli.status_codes import ERROR, SUCCESS
from pip._internal.configuration import (
    Configuration,
    Kind,
    get_configuration_files,
    kinds,
)
from pip._internal.exceptions import PipError
from pip._internal.utils.logging import indent_log
from pip._internal.utils.misc import get_prog, write_output

logger = logging.getLogger(__name__)


class ConfigurationCommand(Command):
    

    ignore_require_venv = True
    usage = 

    def add_options(self) -> None:
        self.cmd_opts.add_option(
            ""--editor"",
            dest=""editor"",
            action=""store"",
            default=None,
            help=(
                ""Editor to use to edit the file. Uses VISUAL or EDITOR ""
                ""environment variables if not provided.""
            ),
        )

        self.cmd_opts.add_option(
            ""--global"",
            dest=""global_file"",
            action=""store_true"",
            default=False,
            help=""Use the system-wide configuration file only"",
        )

        self.cmd_opts.add_option(
            ""--user"",
            dest=""user_file"",
            action=""store_true"",
            default=False,
            help=""Use the user configuration file only"",
        )

        self.cmd_opts.add_option(
            ""--site"",
            dest=""site_file"",
            action=""store_true"",
            default=False,
            help=""Use the current environment configuration file only"",
        )

        self.parser.insert_option_group(0, self.cmd_opts)

    def handler_map(self) -> dict[str, Callable[[Values, list[str]], None]]:
        return {
            ""list"": self.list_values,
            ""edit"": self.open_in_editor,
            ""get"": self.get_name,
            ""set"": self.set_name_value,
            ""unset"": self.unset_name,
            ""debug"": self.list_config_values,
        }

    def run(self, options: Values, args: list[str]) -> int:
        handler_map = self.handler_map()

        
        if not args or args[0] not in handler_map:
            logger.error(
                ""Need an action (%s) to perform."",
                "", "".join(sorted(handler_map)),
            )
            return ERROR

        action = args[0]

        
        
        try:
            load_only = self._determine_file(
                options, need_value=(action in [""get"", ""set"", ""unset"", ""edit""])
            )
        except PipError as e:
            logger.error(e.args[0])
            return ERROR

        
        self.configuration = Configuration(
            isolated=options.isolated_mode, load_only=load_only
        )
        self.configuration.load()

        
        try:
            handler_map[action](options, args[1:])
        except PipError as e:
            logger.error(e.args[0])
            return ERROR

        return SUCCESS

    def _determine_file(self, options: Values, need_value: bool) -> Kind | None:
        file_options = [
            key
            for key, value in (
                (kinds.USER, options.user_file),
                (kinds.GLOBAL, options.global_file),
                (kinds.SITE, options.site_file),
            )
            if value
        ]

        if not file_options:
            if not need_value:
                return None
            
            elif any(
                os.path.exists(site_config_file)
                for site_config_file in get_configuration_files()[kinds.SITE]
            ):
                return kinds.SITE
            else:
                return kinds.USER
        elif len(file_options) == 1:
            return file_options[0]

        raise PipError(
            ""Need exactly one file to operate upon ""
            ""(--user, --site, --global) to perform.""
        )

    def list_values(self, options: Values, args: list[str]) -> None:
        self._get_n_args(args, ""list"", n=0)

        for key, value in sorted(self.configuration.items()):
            for key, value in sorted(value.items()):
                write_output(""%s=%r"", key, value)

    def get_name(self, options: Values, args: list[str]) -> None:
        key = self._get_n_args(args, ""get [name]"", n=1)
        value = self.configuration.get_value(key)

        write_output(""%s"", value)

    def set_name_value(self, options: Values, args: list[str]) -> None:
        key, value = self._get_n_args(args, ""set [name] [value]"", n=2)
        self.configuration.set_value(key, value)

        self._save_configuration()

    def unset_name(self, options: Values, args: list[str]) -> None:
        key = self._get_n_args(args, ""unset [name]"", n=1)
        self.configuration.unset_value(key)

        self._save_configuration()

    def list_config_values(self, options: Values, args: list[str]) -> None:
        
        self._get_n_args(args, ""debug"", n=0)

        self.print_env_var_values()
        
        
        for variant, files in sorted(self.configuration.iter_config_files()):
            write_output(""%s:"", variant)
            for fname in files:
                with indent_log():
                    file_exists = os.path.exists(fname)
                    write_output(""%s, exists: %r"", fname, file_exists)
                    if file_exists:
                        self.print_config_file_values(variant, fname)

    def print_config_file_values(self, variant: Kind, fname: str) -> None:
        
        for name, value in self.configuration.get_values_in_config(variant).items():
            with indent_log():
                if name == fname:
                    for confname, confvalue in value.items():
                        write_output(""%s: %s"", confname, confvalue)

    def print_env_var_values(self) -> None:
        
        write_output(""%s:"", ""env_var"")
        with indent_log():
            for key, value in sorted(self.configuration.get_environ_vars()):
                env_var = f""PIP_{key.upper()}""
                write_output(""%s=%r"", env_var, value)

    def open_in_editor(self, options: Values, args: list[str]) -> None:
        editor = self._determine_editor(options)

        fname = self.configuration.get_file_to_edit()
        if fname is None:
            raise PipError(""Could not determine appropriate file."")
        elif '""' in fname:
            
            
            raise PipError(
                f'Can not open an editor for a file name containing ""\n{fname}'
            )

        try:
            subprocess.check_call(f'{editor} ""{fname}""', shell=True)
        except FileNotFoundError as e:
            if not e.filename:
                e.filename = editor
            raise
        except subprocess.CalledProcessError as e:
            raise PipError(f""Editor Subprocess exited with exit code {e.returncode}"")

    def _get_n_args(self, args: list[str], example: str, n: int) -> Any:
        
        if len(args) != n:
            msg = (
                f""Got unexpected number of arguments, expected {n}. ""
                f'(example: ""{get_prog()} config {example}"")'
            )
            raise PipError(msg)

        if n == 1:
            return args[0]
        else:
            return args

    def _save_configuration(self) -> None:
        
        
        try:
            self.configuration.save()
        except Exception:
            logger.exception(
                ""Unable to save configuration. Please report this as a bug.""
            )
            raise PipError(""Internal Error."")

    def _determine_editor(self, options: Values) -> str:
        if options.editor is not None:
            return options.editor
        elif ""VISUAL"" in os.environ:
            return os.environ[""VISUAL""]
        elif ""EDITOR"" in os.environ:
            return os.environ[""EDITOR""]
        else:
            raise PipError(""Could not determine editor to use."")

from __future__ import annotations

import locale
import logging
import os
import sys
from optparse import Values
from types import ModuleType
from typing import Any

import pip._vendor
from pip._vendor.certifi import where
from pip._vendor.packaging.version import parse as parse_version

from pip._internal.cli import cmdoptions
from pip._internal.cli.base_command import Command
from pip._internal.cli.cmdoptions import make_target_python
from pip._internal.cli.status_codes import SUCCESS
from pip._internal.configuration import Configuration
from pip._internal.metadata import get_environment
from pip._internal.utils.compat import open_text_resource
from pip._internal.utils.logging import indent_log
from pip._internal.utils.misc import get_pip_version

logger = logging.getLogger(__name__)


def show_value(name: str, value: Any) -> None:
    logger.info(""%s: %s"", name, value)


def show_sys_implementation() -> None:
    logger.info(""sys.implementation:"")
    implementation_name = sys.implementation.name
    with indent_log():
        show_value(""name"", implementation_name)


def create_vendor_txt_map() -> dict[str, str]:
    with open_text_resource(""pip._vendor"", ""vendor.txt"") as f:
        
        
        lines = [
            line.strip().split("" "", 1)[0] for line in f.readlines() if ""=="" in line
        ]

    
    return dict(line.split(""=="", 1) for line in lines)


def get_module_from_module_name(module_name: str) -> ModuleType | None:
    
    module_name = module_name.lower().replace(""-"", ""_"")
    
    if module_name == ""setuptools"":
        module_name = ""pkg_resources""

    try:
        __import__(f""pip._vendor.{module_name}"", globals(), locals(), level=0)
        return getattr(pip._vendor, module_name)
    except ImportError:
        
        
        if module_name == ""truststore"" and sys.version_info < (3, 10):
            return None
        raise


def get_vendor_version_from_module(module_name: str) -> str | None:
    module = get_module_from_module_name(module_name)
    version = getattr(module, ""__version__"", None)

    if module and not version:
        
        assert module.__file__ is not None
        env = get_environment([os.path.dirname(module.__file__)])
        dist = env.get_distribution(module_name)
        if dist:
            version = str(dist.version)

    return version


def show_actual_vendor_versions(vendor_txt_versions: dict[str, str]) -> None:
    
    for module_name, expected_version in vendor_txt_versions.items():
        extra_message = """"
        actual_version = get_vendor_version_from_module(module_name)
        if not actual_version:
            extra_message = (
                "" (Unable to locate actual module version, using""
                "" vendor.txt specified version)""
            )
            actual_version = expected_version
        elif parse_version(actual_version) != parse_version(expected_version):
            extra_message = (
                "" (CONFLICT: vendor.txt suggests version should""
                f"" be {expected_version})""
            )
        logger.info(""%s==%s%s"", module_name, actual_version, extra_message)


def show_vendor_versions() -> None:
    logger.info(""vendored library versions:"")

    vendor_txt_versions = create_vendor_txt_map()
    with indent_log():
        show_actual_vendor_versions(vendor_txt_versions)


def show_tags(options: Values) -> None:
    tag_limit = 10

    target_python = make_target_python(options)
    tags = target_python.get_sorted_tags()

    
    formatted_target = target_python.format_given()
    suffix = """"
    if formatted_target:
        suffix = f"" (target: {formatted_target})""

    msg = f""Compatible tags: {len(tags)}{suffix}""
    logger.info(msg)

    if options.verbose < 1 and len(tags) > tag_limit:
        tags_limited = True
        tags = tags[:tag_limit]
    else:
        tags_limited = False

    with indent_log():
        for tag in tags:
            logger.info(str(tag))

        if tags_limited:
            msg = f""...\n[First {tag_limit} tags shown. Pass --verbose to show all.]""
            logger.info(msg)


def ca_bundle_info(config: Configuration) -> str:
    levels = {key.split(""."", 1)[0] for key, _ in config.items()}
    if not levels:
        return ""Not specified""

    levels_that_override_global = [""install"", ""wheel"", ""download""]
    global_overriding_level = [
        level for level in levels if level in levels_that_override_global
    ]
    if not global_overriding_level:
        return ""global""

    if ""global"" in levels:
        levels.remove(""global"")
    return "", "".join(levels)


class DebugCommand(Command):
    

    usage = 
    ignore_require_venv = True

    def add_options(self) -> None:
        cmdoptions.add_target_python_options(self.cmd_opts)
        self.parser.insert_option_group(0, self.cmd_opts)
        self.parser.config.load()

    def run(self, options: Values, args: list[str]) -> int:
        logger.warning(
            ""This command is only meant for debugging. ""
            ""Do not use this with automation for parsing and getting these ""
            ""details, since the output and options of this command may ""
            ""change without notice.""
        )
        show_value(""pip version"", get_pip_version())
        show_value(""sys.version"", sys.version)
        show_value(""sys.executable"", sys.executable)
        show_value(""sys.getdefaultencoding"", sys.getdefaultencoding())
        show_value(""sys.getfilesystemencoding"", sys.getfilesystemencoding())
        show_value(
            ""locale.getpreferredencoding"",
            locale.getpreferredencoding(),
        )
        show_value(""sys.platform"", sys.platform)
        show_sys_implementation()

        show_value(""'cert' config value"", ca_bundle_info(self.parser.config))
        show_value(""REQUESTS_CA_BUNDLE"", os.environ.get(""REQUESTS_CA_BUNDLE""))
        show_value(""CURL_CA_BUNDLE"", os.environ.get(""CURL_CA_BUNDLE""))
        show_value(""pip._vendor.certifi.where()"", where())
        show_value(""pip._vendor.DEBUNDLED"", pip._vendor.DEBUNDLED)

        show_vendor_versions()

        show_tags(options)

        return SUCCESS

import logging
import os
from optparse import Values

from pip._internal.cli import cmdoptions
from pip._internal.cli.cmdoptions import make_target_python
from pip._internal.cli.req_command import RequirementCommand, with_cleanup
from pip._internal.cli.status_codes import SUCCESS
from pip._internal.operations.build.build_tracker import get_build_tracker
from pip._internal.req.req_install import check_legacy_setup_py_options
from pip._internal.utils.misc import ensure_dir, normalize_path, write_output
from pip._internal.utils.temp_dir import TempDirectory

logger = logging.getLogger(__name__)


class DownloadCommand(RequirementCommand):
    

    usage = 

    def add_options(self) -> None:
        self.cmd_opts.add_option(cmdoptions.constraints())
        self.cmd_opts.add_option(cmdoptions.requirements())
        self.cmd_opts.add_option(cmdoptions.no_deps())
        self.cmd_opts.add_option(cmdoptions.global_options())
        self.cmd_opts.add_option(cmdoptions.no_binary())
        self.cmd_opts.add_option(cmdoptions.only_binary())
        self.cmd_opts.add_option(cmdoptions.prefer_binary())
        self.cmd_opts.add_option(cmdoptions.src())
        self.cmd_opts.add_option(cmdoptions.pre())
        self.cmd_opts.add_option(cmdoptions.require_hashes())
        self.cmd_opts.add_option(cmdoptions.progress_bar())
        self.cmd_opts.add_option(cmdoptions.no_build_isolation())
        self.cmd_opts.add_option(cmdoptions.use_pep517())
        self.cmd_opts.add_option(cmdoptions.no_use_pep517())
        self.cmd_opts.add_option(cmdoptions.check_build_deps())
        self.cmd_opts.add_option(cmdoptions.ignore_requires_python())

        self.cmd_opts.add_option(
            ""-d"",
            ""--dest"",
            ""--destination-dir"",
            ""--destination-directory"",
            dest=""download_dir"",
            metavar=""dir"",
            default=os.curdir,
            help=""Download packages into <dir>."",
        )

        cmdoptions.add_target_python_options(self.cmd_opts)

        index_opts = cmdoptions.make_option_group(
            cmdoptions.index_group,
            self.parser,
        )

        self.parser.insert_option_group(0, index_opts)
        self.parser.insert_option_group(0, self.cmd_opts)

    @with_cleanup
    def run(self, options: Values, args: list[str]) -> int:
        options.ignore_installed = True
        
        
        options.editables = []

        cmdoptions.check_dist_restriction(options)

        options.download_dir = normalize_path(options.download_dir)
        ensure_dir(options.download_dir)

        session = self.get_default_session(options)

        target_python = make_target_python(options)
        finder = self._build_package_finder(
            options=options,
            session=session,
            target_python=target_python,
            ignore_requires_python=options.ignore_requires_python,
        )

        build_tracker = self.enter_context(get_build_tracker())

        directory = TempDirectory(
            delete=not options.no_clean,
            kind=""download"",
            globally_managed=True,
        )

        reqs = self.get_requirements(args, options, finder, session)
        check_legacy_setup_py_options(options, reqs)

        preparer = self.make_requirement_preparer(
            temp_build_dir=directory,
            options=options,
            build_tracker=build_tracker,
            session=session,
            finder=finder,
            download_dir=options.download_dir,
            use_user_site=False,
            verbosity=self.verbosity,
        )

        resolver = self.make_resolver(
            preparer=preparer,
            finder=finder,
            options=options,
            ignore_requires_python=options.ignore_requires_python,
            use_pep517=options.use_pep517,
            py_version_info=options.python_version,
        )

        self.trace_basic_info(finder)

        requirement_set = resolver.resolve(reqs, check_supported_wheels=True)

        downloaded: list[str] = []
        for req in requirement_set.requirements.values():
            if req.satisfied_by is None:
                assert req.name is not None
                preparer.save_linked_requirement(req)
                downloaded.append(req.name)

        preparer.prepare_linked_requirements_more(requirement_set.requirements.values())

        if downloaded:
            write_output(""Successfully downloaded %s"", "" "".join(downloaded))

        return SUCCESS

import sys
from optparse import Values

from pip._internal.cli import cmdoptions
from pip._internal.cli.base_command import Command
from pip._internal.cli.status_codes import SUCCESS
from pip._internal.operations.freeze import freeze
from pip._internal.utils.compat import stdlib_pkgs


def _should_suppress_build_backends() -> bool:
    return sys.version_info < (3, 12)


def _dev_pkgs() -> set[str]:
    pkgs = {""pip""}

    if _should_suppress_build_backends():
        pkgs |= {""setuptools"", ""distribute"", ""wheel""}

    return pkgs


class FreezeCommand(Command):
    

    ignore_require_venv = True
    usage = 

    def add_options(self) -> None:
        self.cmd_opts.add_option(
            ""-r"",
            ""--requirement"",
            dest=""requirements"",
            action=""append"",
            default=[],
            metavar=""file"",
            help=(
                ""Use the order in the given requirements file and its ""
                ""comments when generating output. This option can be ""
                ""used multiple times.""
            ),
        )
        self.cmd_opts.add_option(
            ""-l"",
            ""--local"",
            dest=""local"",
            action=""store_true"",
            default=False,
            help=(
                ""If in a virtualenv that has global access, do not output ""
                ""globally-installed packages.""
            ),
        )
        self.cmd_opts.add_option(
            ""--user"",
            dest=""user"",
            action=""store_true"",
            default=False,
            help=""Only output packages installed in user-site."",
        )
        self.cmd_opts.add_option(cmdoptions.list_path())
        self.cmd_opts.add_option(
            ""--all"",
            dest=""freeze_all"",
            action=""store_true"",
            help=(
                ""Do not skip these packages in the output:""
                "" {}"".format("", "".join(_dev_pkgs()))
            ),
        )
        self.cmd_opts.add_option(
            ""--exclude-editable"",
            dest=""exclude_editable"",
            action=""store_true"",
            help=""Exclude editable package from output."",
        )
        self.cmd_opts.add_option(cmdoptions.list_exclude())

        self.parser.insert_option_group(0, self.cmd_opts)

    def run(self, options: Values, args: list[str]) -> int:
        skip = set(stdlib_pkgs)
        if not options.freeze_all:
            skip.update(_dev_pkgs())

        if options.excludes:
            skip.update(options.excludes)

        cmdoptions.check_list_path_option(options)

        for line in freeze(
            requirement=options.requirements,
            local_only=options.local,
            user_only=options.user,
            paths=options.path,
            isolated=options.isolated_mode,
            skip=skip,
            exclude_editable=options.exclude_editable,
        ):
            sys.stdout.write(line + ""\n"")
        return SUCCESS

import hashlib
import logging
import sys
from optparse import Values

from pip._internal.cli.base_command import Command
from pip._internal.cli.status_codes import ERROR, SUCCESS
from pip._internal.utils.hashes import FAVORITE_HASH, STRONG_HASHES
from pip._internal.utils.misc import read_chunks, write_output

logger = logging.getLogger(__name__)


class HashCommand(Command):
    

    usage = ""%prog [options] <file> ...""
    ignore_require_venv = True

    def add_options(self) -> None:
        self.cmd_opts.add_option(
            ""-a"",
            ""--algorithm"",
            dest=""algorithm"",
            choices=STRONG_HASHES,
            action=""store"",
            default=FAVORITE_HASH,
            help=""The hash algorithm to use: one of {}"".format(
                "", "".join(STRONG_HASHES)
            ),
        )
        self.parser.insert_option_group(0, self.cmd_opts)

    def run(self, options: Values, args: list[str]) -> int:
        if not args:
            self.parser.print_usage(sys.stderr)
            return ERROR

        algorithm = options.algorithm
        for path in args:
            write_output(
                ""%s:\n--hash=%s:%s"", path, algorithm, _hash_of_file(path, algorithm)
            )
        return SUCCESS


def _hash_of_file(path: str, algorithm: str) -> str:
    
    with open(path, ""rb"") as archive:
        hash = hashlib.new(algorithm)
        for chunk in read_chunks(archive):
            hash.update(chunk)
    return hash.hexdigest()

from optparse import Values

from pip._internal.cli.base_command import Command
from pip._internal.cli.status_codes import SUCCESS
from pip._internal.exceptions import CommandError


class HelpCommand(Command):
    

    usage = 
    ignore_require_venv = True

    def run(self, options: Values, args: list[str]) -> int:
        from pip._internal.commands import (
            commands_dict,
            create_command,
            get_similar_commands,
        )

        try:
            
            cmd_name = args[0]  
        except IndexError:
            return SUCCESS

        if cmd_name not in commands_dict:
            guess = get_similar_commands(cmd_name)

            msg = [f'unknown command ""{cmd_name}""']
            if guess:
                msg.append(f'maybe you meant ""{guess}""')

            raise CommandError("" - "".join(msg))

        command = create_command(cmd_name)
        command.parser.print_help()

        return SUCCESS

from __future__ import annotations

import json
import logging
from collections.abc import Iterable
from optparse import Values
from typing import Any, Callable

from pip._vendor.packaging.version import Version

from pip._internal.cli import cmdoptions
from pip._internal.cli.req_command import IndexGroupCommand
from pip._internal.cli.status_codes import ERROR, SUCCESS
from pip._internal.commands.search import (
    get_installed_distribution,
    print_dist_installation_info,
)
from pip._internal.exceptions import CommandError, DistributionNotFound, PipError
from pip._internal.index.collector import LinkCollector
from pip._internal.index.package_finder import PackageFinder
from pip._internal.models.selection_prefs import SelectionPreferences
from pip._internal.models.target_python import TargetPython
from pip._internal.network.session import PipSession
from pip._internal.utils.misc import write_output

logger = logging.getLogger(__name__)


class IndexCommand(IndexGroupCommand):
    

    ignore_require_venv = True
    usage = 

    def add_options(self) -> None:
        cmdoptions.add_target_python_options(self.cmd_opts)

        self.cmd_opts.add_option(cmdoptions.ignore_requires_python())
        self.cmd_opts.add_option(cmdoptions.pre())
        self.cmd_opts.add_option(cmdoptions.json())
        self.cmd_opts.add_option(cmdoptions.no_binary())
        self.cmd_opts.add_option(cmdoptions.only_binary())

        index_opts = cmdoptions.make_option_group(
            cmdoptions.index_group,
            self.parser,
        )

        self.parser.insert_option_group(0, index_opts)
        self.parser.insert_option_group(0, self.cmd_opts)

    def handler_map(self) -> dict[str, Callable[[Values, list[str]], None]]:
        return {
            ""versions"": self.get_available_package_versions,
        }

    def run(self, options: Values, args: list[str]) -> int:
        handler_map = self.handler_map()

        
        if not args or args[0] not in handler_map:
            logger.error(
                ""Need an action (%s) to perform."",
                "", "".join(sorted(handler_map)),
            )
            return ERROR

        action = args[0]

        
        try:
            handler_map[action](options, args[1:])
        except PipError as e:
            logger.error(e.args[0])
            return ERROR

        return SUCCESS

    def _build_package_finder(
        self,
        options: Values,
        session: PipSession,
        target_python: TargetPython | None = None,
        ignore_requires_python: bool | None = None,
    ) -> PackageFinder:
        
        link_collector = LinkCollector.create(session, options=options)

        
        selection_prefs = SelectionPreferences(
            allow_yanked=False,
            allow_all_prereleases=options.pre,
            ignore_requires_python=ignore_requires_python,
        )

        return PackageFinder.create(
            link_collector=link_collector,
            selection_prefs=selection_prefs,
            target_python=target_python,
        )

    def get_available_package_versions(self, options: Values, args: list[Any]) -> None:
        if len(args) != 1:
            raise CommandError(""You need to specify exactly one argument"")

        target_python = cmdoptions.make_target_python(options)
        query = args[0]

        with self._build_session(options) as session:
            finder = self._build_package_finder(
                options=options,
                session=session,
                target_python=target_python,
                ignore_requires_python=options.ignore_requires_python,
            )

            versions: Iterable[Version] = (
                candidate.version for candidate in finder.find_all_candidates(query)
            )

            if not options.pre:
                
                versions = (
                    version for version in versions if not version.is_prerelease
                )
            versions = set(versions)

            if not versions:
                raise DistributionNotFound(
                    f""No matching distribution found for {query}""
                )

            formatted_versions = [str(ver) for ver in sorted(versions, reverse=True)]
            latest = formatted_versions[0]

        dist = get_installed_distribution(query)

        if options.json:
            structured_output = {
                ""name"": query,
                ""versions"": formatted_versions,
                ""latest"": latest,
            }

            if dist is not None:
                structured_output[""installed_version""] = str(dist.version)

            write_output(json.dumps(structured_output))

        else:
            write_output(f""{query} ({latest})"")
            write_output(""Available versions: {}"".format("", "".join(formatted_versions)))
            print_dist_installation_info(latest, dist)

import logging
from optparse import Values
from typing import Any

from pip._vendor.packaging.markers import default_environment
from pip._vendor.rich import print_json

from pip import __version__
from pip._internal.cli import cmdoptions
from pip._internal.cli.base_command import Command
from pip._internal.cli.status_codes import SUCCESS
from pip._internal.metadata import BaseDistribution, get_environment
from pip._internal.utils.compat import stdlib_pkgs
from pip._internal.utils.urls import path_to_url

logger = logging.getLogger(__name__)


class InspectCommand(Command):
    

    ignore_require_venv = True
    usage = 

    def add_options(self) -> None:
        self.cmd_opts.add_option(
            ""--local"",
            action=""store_true"",
            default=False,
            help=(
                ""If in a virtualenv that has global access, do not list ""
                ""globally-installed packages.""
            ),
        )
        self.cmd_opts.add_option(
            ""--user"",
            dest=""user"",
            action=""store_true"",
            default=False,
            help=""Only output packages installed in user-site."",
        )
        self.cmd_opts.add_option(cmdoptions.list_path())
        self.parser.insert_option_group(0, self.cmd_opts)

    def run(self, options: Values, args: list[str]) -> int:
        cmdoptions.check_list_path_option(options)
        dists = get_environment(options.path).iter_installed_distributions(
            local_only=options.local,
            user_only=options.user,
            skip=set(stdlib_pkgs),
        )
        output = {
            ""version"": ""1"",
            ""pip_version"": __version__,
            ""installed"": [self._dist_to_dict(dist) for dist in dists],
            ""environment"": default_environment(),
            
        }
        print_json(data=output)
        return SUCCESS

    def _dist_to_dict(self, dist: BaseDistribution) -> dict[str, Any]:
        res: dict[str, Any] = {
            ""metadata"": dist.metadata_dict,
            ""metadata_location"": dist.info_location,
        }
        
        
        direct_url = dist.direct_url
        if direct_url is not None:
            res[""direct_url""] = direct_url.to_dict()
        else:
            
            editable_project_location = dist.editable_project_location
            if editable_project_location is not None:
                res[""direct_url""] = {
                    ""url"": path_to_url(editable_project_location),
                    ""dir_info"": {
                        ""editable"": True,
                    },
                }
        
        installer = dist.installer
        if dist.installer:
            res[""installer""] = installer
        
        if dist.installed_with_dist_info:
            res[""requested""] = dist.requested
        return res

from __future__ import annotations

import errno
import json
import operator
import os
import shutil
import site
from optparse import SUPPRESS_HELP, Values
from pathlib import Path

from pip._vendor.packaging.utils import canonicalize_name
from pip._vendor.requests.exceptions import InvalidProxyURL
from pip._vendor.rich import print_json







import pip._internal.self_outdated_check  
from pip._internal.cache import WheelCache
from pip._internal.cli import cmdoptions
from pip._internal.cli.cmdoptions import make_target_python
from pip._internal.cli.req_command import (
    RequirementCommand,
    with_cleanup,
)
from pip._internal.cli.status_codes import ERROR, SUCCESS
from pip._internal.exceptions import (
    CommandError,
    InstallationError,
    InstallWheelBuildError,
)
from pip._internal.locations import get_scheme
from pip._internal.metadata import get_environment
from pip._internal.models.installation_report import InstallationReport
from pip._internal.operations.build.build_tracker import get_build_tracker
from pip._internal.operations.check import ConflictDetails, check_install_conflicts
from pip._internal.req import install_given_reqs
from pip._internal.req.req_install import (
    InstallRequirement,
    check_legacy_setup_py_options,
)
from pip._internal.utils.compat import WINDOWS
from pip._internal.utils.filesystem import test_writable_dir
from pip._internal.utils.logging import getLogger
from pip._internal.utils.misc import (
    check_externally_managed,
    ensure_dir,
    get_pip_version,
    protect_pip_from_modification_on_windows,
    warn_if_run_as_root,
    write_output,
)
from pip._internal.utils.temp_dir import TempDirectory
from pip._internal.utils.virtualenv import (
    running_under_virtualenv,
    virtualenv_no_global,
)
from pip._internal.wheel_builder import build, should_build_for_install_command

logger = getLogger(__name__)


class InstallCommand(RequirementCommand):
    

    usage = 

    def add_options(self) -> None:
        self.cmd_opts.add_option(cmdoptions.requirements())
        self.cmd_opts.add_option(cmdoptions.constraints())
        self.cmd_opts.add_option(cmdoptions.no_deps())
        self.cmd_opts.add_option(cmdoptions.pre())

        self.cmd_opts.add_option(cmdoptions.editable())
        self.cmd_opts.add_option(
            ""--dry-run"",
            action=""store_true"",
            dest=""dry_run"",
            default=False,
            help=(
                ""Don't actually install anything, just print what would be. ""
                ""Can be used in combination with --ignore-installed ""
                ""to 'resolve' the requirements.""
            ),
        )
        self.cmd_opts.add_option(
            ""-t"",
            ""--target"",
            dest=""target_dir"",
            metavar=""dir"",
            default=None,
            help=(
                ""Install packages into <dir>. ""
                ""By default this will not replace existing files/folders in ""
                ""<dir>. Use --upgrade to replace existing packages in <dir> ""
                ""with new versions.""
            ),
        )
        cmdoptions.add_target_python_options(self.cmd_opts)

        self.cmd_opts.add_option(
            ""--user"",
            dest=""use_user_site"",
            action=""store_true"",
            help=(
                ""Install to the Python user install directory for your ""
                ""platform. Typically ~/.local/, or %APPDATA%\\Python on ""
                ""Windows. (See the Python documentation for site.USER_BASE ""
                ""for full details.)""
            ),
        )
        self.cmd_opts.add_option(
            ""--no-user"",
            dest=""use_user_site"",
            action=""store_false"",
            help=SUPPRESS_HELP,
        )
        self.cmd_opts.add_option(
            ""--root"",
            dest=""root_path"",
            metavar=""dir"",
            default=None,
            help=""Install everything relative to this alternate root directory."",
        )
        self.cmd_opts.add_option(
            ""--prefix"",
            dest=""prefix_path"",
            metavar=""dir"",
            default=None,
            help=(
                ""Installation prefix where lib, bin and other top-level ""
                ""folders are placed. Note that the resulting installation may ""
                ""contain scripts and other resources which reference the ""
                ""Python interpreter of pip, and not that of ``--prefix``. ""
                ""See also the ``--python`` option if the intention is to ""
                ""install packages into another (possibly pip-free) ""
                ""environment.""
            ),
        )

        self.cmd_opts.add_option(cmdoptions.src())

        self.cmd_opts.add_option(
            ""-U"",
            ""--upgrade"",
            dest=""upgrade"",
            action=""store_true"",
            help=(
                ""Upgrade all specified packages to the newest available ""
                ""version. The handling of dependencies depends on the ""
                ""upgrade-strategy used.""
            ),
        )

        self.cmd_opts.add_option(
            ""--upgrade-strategy"",
            dest=""upgrade_strategy"",
            default=""only-if-needed"",
            choices=[""only-if-needed"", ""eager""],
            help=(
                ""Determines how dependency upgrading should be handled ""
                ""[default: %default]. ""
                '""eager"" - dependencies are upgraded regardless of '
                ""whether the currently installed version satisfies the ""
                ""requirements of the upgraded package(s). ""
                '""only-if-needed"" -  are upgraded only when they do not '
                ""satisfy the requirements of the upgraded package(s).""
            ),
        )

        self.cmd_opts.add_option(
            ""--force-reinstall"",
            dest=""force_reinstall"",
            action=""store_true"",
            help=""Reinstall all packages even if they are already up-to-date."",
        )

        self.cmd_opts.add_option(
            ""-I"",
            ""--ignore-installed"",
            dest=""ignore_installed"",
            action=""store_true"",
            help=(
                ""Ignore the installed packages, overwriting them. ""
                ""This can break your system if the existing package ""
                ""is of a different version or was installed ""
                ""with a different package manager!""
            ),
        )

        self.cmd_opts.add_option(cmdoptions.ignore_requires_python())
        self.cmd_opts.add_option(cmdoptions.no_build_isolation())
        self.cmd_opts.add_option(cmdoptions.use_pep517())
        self.cmd_opts.add_option(cmdoptions.no_use_pep517())
        self.cmd_opts.add_option(cmdoptions.check_build_deps())
        self.cmd_opts.add_option(cmdoptions.override_externally_managed())

        self.cmd_opts.add_option(cmdoptions.config_settings())
        self.cmd_opts.add_option(cmdoptions.global_options())

        self.cmd_opts.add_option(
            ""--compile"",
            action=""store_true"",
            dest=""compile"",
            default=True,
            help=""Compile Python source files to bytecode"",
        )

        self.cmd_opts.add_option(
            ""--no-compile"",
            action=""store_false"",
            dest=""compile"",
            help=""Do not compile Python source files to bytecode"",
        )

        self.cmd_opts.add_option(
            ""--no-warn-script-location"",
            action=""store_false"",
            dest=""warn_script_location"",
            default=True,
            help=""Do not warn when installing scripts outside PATH"",
        )
        self.cmd_opts.add_option(
            ""--no-warn-conflicts"",
            action=""store_false"",
            dest=""warn_about_conflicts"",
            default=True,
            help=""Do not warn about broken dependencies"",
        )
        self.cmd_opts.add_option(cmdoptions.no_binary())
        self.cmd_opts.add_option(cmdoptions.only_binary())
        self.cmd_opts.add_option(cmdoptions.prefer_binary())
        self.cmd_opts.add_option(cmdoptions.require_hashes())
        self.cmd_opts.add_option(cmdoptions.progress_bar())
        self.cmd_opts.add_option(cmdoptions.root_user_action())

        index_opts = cmdoptions.make_option_group(
            cmdoptions.index_group,
            self.parser,
        )

        self.parser.insert_option_group(0, index_opts)
        self.parser.insert_option_group(0, self.cmd_opts)

        self.cmd_opts.add_option(
            ""--report"",
            dest=""json_report_file"",
            metavar=""file"",
            default=None,
            help=(
                ""Generate a JSON file describing what pip did to install ""
                ""the provided requirements. ""
                ""Can be used in combination with --dry-run and --ignore-installed ""
                ""to 'resolve' the requirements. ""
                ""When - is used as file name it writes to stdout. ""
                ""When writing to stdout, please combine with the --quiet option ""
                ""to avoid mixing pip logging output with JSON output.""
            ),
        )

    @with_cleanup
    def run(self, options: Values, args: list[str]) -> int:
        if options.use_user_site and options.target_dir is not None:
            raise CommandError(""Can not combine '--user' and '--target'"")

        
        
        
        
        
        installing_into_current_environment = (
            not (options.dry_run and options.json_report_file)
            and options.root_path is None
            and options.target_dir is None
            and options.prefix_path is None
        )
        if (
            installing_into_current_environment
            and not options.override_externally_managed
        ):
            check_externally_managed()

        upgrade_strategy = ""to-satisfy-only""
        if options.upgrade:
            upgrade_strategy = options.upgrade_strategy

        cmdoptions.check_dist_restriction(options, check_target=True)

        logger.verbose(""Using %s"", get_pip_version())
        options.use_user_site = decide_user_install(
            options.use_user_site,
            prefix_path=options.prefix_path,
            target_dir=options.target_dir,
            root_path=options.root_path,
            isolated_mode=options.isolated_mode,
        )

        target_temp_dir: TempDirectory | None = None
        target_temp_dir_path: str | None = None
        if options.target_dir:
            options.ignore_installed = True
            options.target_dir = os.path.abspath(options.target_dir)
            if (
                
                os.path.exists(options.target_dir) and
                not os.path.isdir(options.target_dir)
                
            ):
                raise CommandError(
                    ""Target path exists but is not a directory, will not continue.""
                )

            
            target_temp_dir = TempDirectory(kind=""target"")
            target_temp_dir_path = target_temp_dir.path
            self.enter_context(target_temp_dir)

        global_options = options.global_options or []

        session = self.get_default_session(options)

        target_python = make_target_python(options)
        finder = self._build_package_finder(
            options=options,
            session=session,
            target_python=target_python,
            ignore_requires_python=options.ignore_requires_python,
        )
        build_tracker = self.enter_context(get_build_tracker())

        directory = TempDirectory(
            delete=not options.no_clean,
            kind=""install"",
            globally_managed=True,
        )

        try:
            reqs = self.get_requirements(args, options, finder, session)
            check_legacy_setup_py_options(options, reqs)

            wheel_cache = WheelCache(options.cache_dir)

            
            
            
            for req in reqs:
                req.permit_editable_wheels = True

            preparer = self.make_requirement_preparer(
                temp_build_dir=directory,
                options=options,
                build_tracker=build_tracker,
                session=session,
                finder=finder,
                use_user_site=options.use_user_site,
                verbosity=self.verbosity,
            )
            resolver = self.make_resolver(
                preparer=preparer,
                finder=finder,
                options=options,
                wheel_cache=wheel_cache,
                use_user_site=options.use_user_site,
                ignore_installed=options.ignore_installed,
                ignore_requires_python=options.ignore_requires_python,
                force_reinstall=options.force_reinstall,
                upgrade_strategy=upgrade_strategy,
                use_pep517=options.use_pep517,
                py_version_info=options.python_version,
            )

            self.trace_basic_info(finder)

            requirement_set = resolver.resolve(
                reqs, check_supported_wheels=not options.target_dir
            )

            if options.json_report_file:
                report = InstallationReport(requirement_set.requirements_to_install)
                if options.json_report_file == ""-"":
                    print_json(data=report.to_dict())
                else:
                    with open(options.json_report_file, ""w"", encoding=""utf-8"") as f:
                        json.dump(report.to_dict(), f, indent=2, ensure_ascii=False)

            if options.dry_run:
                would_install_items = sorted(
                    (r.metadata[""name""], r.metadata[""version""])
                    for r in requirement_set.requirements_to_install
                )
                if would_install_items:
                    write_output(
                        ""Would install %s"",
                        "" "".join(""-"".join(item) for item in would_install_items),
                    )
                return SUCCESS

            try:
                pip_req = requirement_set.get_requirement(""pip"")
            except KeyError:
                modifying_pip = False
            else:
                
                
                modifying_pip = pip_req.satisfied_by is None
            protect_pip_from_modification_on_windows(modifying_pip=modifying_pip)

            reqs_to_build = [
                r
                for r in requirement_set.requirements_to_install
                if should_build_for_install_command(r)
            ]

            _, build_failures = build(
                reqs_to_build,
                wheel_cache=wheel_cache,
                verify=True,
                build_options=[],
                global_options=global_options,
            )

            if build_failures:
                raise InstallWheelBuildError(build_failures)

            to_install = resolver.get_installation_order(requirement_set)

            
            conflicts: ConflictDetails | None = None
            should_warn_about_conflicts = (
                not options.ignore_dependencies and options.warn_about_conflicts
            )
            if should_warn_about_conflicts:
                conflicts = self._determine_conflicts(to_install)

            
            
            warn_script_location = options.warn_script_location
            if options.target_dir or options.prefix_path:
                warn_script_location = False

            installed = install_given_reqs(
                to_install,
                global_options,
                root=options.root_path,
                home=target_temp_dir_path,
                prefix=options.prefix_path,
                warn_script_location=warn_script_location,
                use_user_site=options.use_user_site,
                pycompile=options.compile,
                progress_bar=options.progress_bar,
            )

            lib_locations = get_lib_location_guesses(
                user=options.use_user_site,
                home=target_temp_dir_path,
                root=options.root_path,
                prefix=options.prefix_path,
                isolated=options.isolated_mode,
            )
            env = get_environment(lib_locations)

            
            
            installed.sort(key=operator.attrgetter(""name""))
            summary = []
            installed_versions = {}
            for distribution in env.iter_all_distributions():
                installed_versions[distribution.canonical_name] = distribution.version
            for package in installed:
                display_name = package.name
                version = installed_versions.get(canonicalize_name(display_name), None)
                if version:
                    text = f""{display_name}-{version}""
                else:
                    text = display_name
                summary.append(text)

            if conflicts is not None:
                self._warn_about_conflicts(
                    conflicts,
                    resolver_variant=self.determine_resolver_variant(options),
                )

            installed_desc = "" "".join(summary)
            if installed_desc:
                write_output(
                    ""Successfully installed %s"",
                    installed_desc,
                )
        except OSError as error:
            show_traceback = self.verbosity >= 1

            message = create_os_error_message(
                error,
                show_traceback,
                options.use_user_site,
            )
            logger.error(message, exc_info=show_traceback)

            return ERROR

        if options.target_dir:
            assert target_temp_dir
            self._handle_target_dir(
                options.target_dir, target_temp_dir, options.upgrade
            )
        if options.root_user_action == ""warn"":
            warn_if_run_as_root()
        return SUCCESS

    def _handle_target_dir(
        self, target_dir: str, target_temp_dir: TempDirectory, upgrade: bool
    ) -> None:
        ensure_dir(target_dir)

        
        
        lib_dir_list = []

        
        
        scheme = get_scheme("""", home=target_temp_dir.path)
        purelib_dir = scheme.purelib
        platlib_dir = scheme.platlib
        data_dir = scheme.data

        if os.path.exists(purelib_dir):
            lib_dir_list.append(purelib_dir)
        if os.path.exists(platlib_dir) and platlib_dir != purelib_dir:
            lib_dir_list.append(platlib_dir)
        if os.path.exists(data_dir):
            lib_dir_list.append(data_dir)

        for lib_dir in lib_dir_list:
            for item in os.listdir(lib_dir):
                if lib_dir == data_dir:
                    ddir = os.path.join(data_dir, item)
                    if any(s.startswith(ddir) for s in lib_dir_list[:-1]):
                        continue
                target_item_dir = os.path.join(target_dir, item)
                if os.path.exists(target_item_dir):
                    if not upgrade:
                        logger.warning(
                            ""Target directory %s already exists. Specify ""
                            ""--upgrade to force replacement."",
                            target_item_dir,
                        )
                        continue
                    if os.path.islink(target_item_dir):
                        logger.warning(
                            ""Target directory %s already exists and is ""
                            ""a link. pip will not automatically replace ""
                            ""links, please remove if replacement is ""
                            ""desired."",
                            target_item_dir,
                        )
                        continue
                    if os.path.isdir(target_item_dir):
                        shutil.rmtree(target_item_dir)
                    else:
                        os.remove(target_item_dir)

                shutil.move(os.path.join(lib_dir, item), target_item_dir)

    def _determine_conflicts(
        self, to_install: list[InstallRequirement]
    ) -> ConflictDetails | None:
        try:
            return check_install_conflicts(to_install)
        except Exception:
            logger.exception(
                ""Error while checking for conflicts. Please file an issue on ""
                ""pip's issue tracker: https://github.com/pypa/pip/issues/new""
            )
            return None

    def _warn_about_conflicts(
        self, conflict_details: ConflictDetails, resolver_variant: str
    ) -> None:
        package_set, (missing, conflicting) = conflict_details
        if not missing and not conflicting:
            return

        parts: list[str] = []
        if resolver_variant == ""legacy"":
            parts.append(
                ""pip's legacy dependency resolver does not consider dependency ""
                ""conflicts when selecting packages. This behaviour is the ""
                ""source of the following dependency conflicts.""
            )
        else:
            assert resolver_variant == ""resolvelib""
            parts.append(
                ""pip's dependency resolver does not currently take into account ""
                ""all the packages that are installed. This behaviour is the ""
                ""source of the following dependency conflicts.""
            )

        
        for project_name in missing:
            version = package_set[project_name][0]
            for dependency in missing[project_name]:
                message = (
                    f""{project_name} {version} requires {dependency[1]}, ""
                    ""which is not installed.""
                )
                parts.append(message)

        for project_name in conflicting:
            version = package_set[project_name][0]
            for dep_name, dep_version, req in conflicting[project_name]:
                message = (
                    ""{name} {version} requires {requirement}, but {you} have ""
                    ""{dep_name} {dep_version} which is incompatible.""
                ).format(
                    name=project_name,
                    version=version,
                    requirement=req,
                    dep_name=dep_name,
                    dep_version=dep_version,
                    you=(""you"" if resolver_variant == ""resolvelib"" else ""you'll""),
                )
                parts.append(message)

        logger.critical(""\n"".join(parts))


def get_lib_location_guesses(
    user: bool = False,
    home: str | None = None,
    root: str | None = None,
    isolated: bool = False,
    prefix: str | None = None,
) -> list[str]:
    scheme = get_scheme(
        """",
        user=user,
        home=home,
        root=root,
        isolated=isolated,
        prefix=prefix,
    )
    return [scheme.purelib, scheme.platlib]


def site_packages_writable(root: str | None, isolated: bool) -> bool:
    return all(
        test_writable_dir(d)
        for d in set(get_lib_location_guesses(root=root, isolated=isolated))
    )


def decide_user_install(
    use_user_site: bool | None,
    prefix_path: str | None = None,
    target_dir: str | None = None,
    root_path: str | None = None,
    isolated_mode: bool = False,
) -> bool:
    
    
    
    if (use_user_site is not None) and (not use_user_site):
        logger.debug(""Non-user install by explicit request"")
        return False

    if use_user_site:
        if prefix_path:
            raise CommandError(
                ""Can not combine '--user' and '--prefix' as they imply ""
                ""different installation locations""
            )
        if virtualenv_no_global():
            raise InstallationError(
                ""Can not perform a '--user' install. User site-packages ""
                ""are not visible in this virtualenv.""
            )
        logger.debug(""User install by explicit request"")
        return True

    
    assert use_user_site is None

    
    if prefix_path or target_dir:
        logger.debug(""Non-user install due to --prefix or --target option"")
        return False

    
    if not site.ENABLE_USER_SITE:
        logger.debug(""Non-user install because user site-packages disabled"")
        return False

    
    
    if site_packages_writable(root=root_path, isolated=isolated_mode):
        logger.debug(""Non-user install because site-packages writeable"")
        return False

    logger.info(
        ""Defaulting to user installation because normal site-packages ""
        ""is not writeable""
    )
    return True


def create_os_error_message(
    error: OSError, show_traceback: bool, using_user_site: bool
) -> str:
    
    parts = []

    
    parts.append(""Could not install packages due to an OSError"")
    if not show_traceback:
        parts.append("": "")
        parts.append(str(error))
    else:
        parts.append(""."")

    
    parts[-1] += ""\n""

    
    
    if error.errno == errno.EACCES:
        user_option_part = ""Consider using the `--user` option""
        permissions_part = ""Check the permissions""

        if not running_under_virtualenv() and not using_user_site:
            parts.extend(
                [
                    user_option_part,
                    "" or "",
                    permissions_part.lower(),
                ]
            )
        else:
            parts.append(permissions_part)
        parts.append("".\n"")

    
    if type(error) is InvalidProxyURL:
        parts.append(
            'Consider checking your local proxy configuration with ""pip config debug""'
        )
        parts.append("".\n"")

    
    
    
    

    if WINDOWS and error.errno in (errno.EINVAL, errno.ENOENT) and error.filename:
        if any(len(part) > 255 for part in Path(error.filename).parts):
            parts.append(
                ""HINT: This error might be caused by a file or folder name exceeding ""
                ""255 characters, which is a Windows limitation even if long paths ""
                ""are enabled.\n ""
            )
        if len(error.filename) > 260:
            parts.append(
                ""HINT: This error might have occurred since ""
                ""this system does not have Windows Long Path ""
                ""support enabled. You can find information on ""
                ""how to enable this at ""
                ""https://pip.pypa.io/warnings/enable-long-paths\n""
            )
    return """".join(parts).strip() + ""\n""

from __future__ import annotations

import json
import logging
from collections.abc import Generator, Sequence
from email.parser import Parser
from optparse import Values
from typing import TYPE_CHECKING, cast

from pip._vendor.packaging.utils import canonicalize_name
from pip._vendor.packaging.version import InvalidVersion, Version

from pip._internal.cli import cmdoptions
from pip._internal.cli.index_command import IndexGroupCommand
from pip._internal.cli.status_codes import SUCCESS
from pip._internal.exceptions import CommandError
from pip._internal.metadata import BaseDistribution, get_environment
from pip._internal.models.selection_prefs import SelectionPreferences
from pip._internal.utils.compat import stdlib_pkgs
from pip._internal.utils.misc import tabulate, write_output

if TYPE_CHECKING:
    from pip._internal.index.package_finder import PackageFinder
    from pip._internal.network.session import PipSession

    class _DistWithLatestInfo(BaseDistribution):
        

        latest_version: Version
        latest_filetype: str

    _ProcessedDists = Sequence[_DistWithLatestInfo]


logger = logging.getLogger(__name__)


class ListCommand(IndexGroupCommand):
    

    ignore_require_venv = True
    usage = 

    def add_options(self) -> None:
        self.cmd_opts.add_option(
            ""-o"",
            ""--outdated"",
            action=""store_true"",
            default=False,
            help=""List outdated packages"",
        )
        self.cmd_opts.add_option(
            ""-u"",
            ""--uptodate"",
            action=""store_true"",
            default=False,
            help=""List uptodate packages"",
        )
        self.cmd_opts.add_option(
            ""-e"",
            ""--editable"",
            action=""store_true"",
            default=False,
            help=""List editable projects."",
        )
        self.cmd_opts.add_option(
            ""-l"",
            ""--local"",
            action=""store_true"",
            default=False,
            help=(
                ""If in a virtualenv that has global access, do not list ""
                ""globally-installed packages.""
            ),
        )
        self.cmd_opts.add_option(
            ""--user"",
            dest=""user"",
            action=""store_true"",
            default=False,
            help=""Only output packages installed in user-site."",
        )
        self.cmd_opts.add_option(cmdoptions.list_path())
        self.cmd_opts.add_option(
            ""--pre"",
            action=""store_true"",
            default=False,
            help=(
                ""Include pre-release and development versions. By default, ""
                ""pip only finds stable versions.""
            ),
        )

        self.cmd_opts.add_option(
            ""--format"",
            action=""store"",
            dest=""list_format"",
            default=""columns"",
            choices=(""columns"", ""freeze"", ""json""),
            help=(
                ""Select the output format among: columns (default), freeze, or json. ""
                ""The 'freeze' format cannot be used with the --outdated option.""
            ),
        )

        self.cmd_opts.add_option(
            ""--not-required"",
            action=""store_true"",
            dest=""not_required"",
            help=""List packages that are not dependencies of installed packages."",
        )

        self.cmd_opts.add_option(
            ""--exclude-editable"",
            action=""store_false"",
            dest=""include_editable"",
            help=""Exclude editable package from output."",
        )
        self.cmd_opts.add_option(
            ""--include-editable"",
            action=""store_true"",
            dest=""include_editable"",
            help=""Include editable package in output."",
            default=True,
        )
        self.cmd_opts.add_option(cmdoptions.list_exclude())
        index_opts = cmdoptions.make_option_group(cmdoptions.index_group, self.parser)

        self.parser.insert_option_group(0, index_opts)
        self.parser.insert_option_group(0, self.cmd_opts)

    def handle_pip_version_check(self, options: Values) -> None:
        if options.outdated or options.uptodate:
            super().handle_pip_version_check(options)

    def _build_package_finder(
        self, options: Values, session: PipSession
    ) -> PackageFinder:
        
        
        from pip._internal.index.collector import LinkCollector
        from pip._internal.index.package_finder import PackageFinder

        link_collector = LinkCollector.create(session, options=options)

        
        selection_prefs = SelectionPreferences(
            allow_yanked=False,
            allow_all_prereleases=options.pre,
        )

        return PackageFinder.create(
            link_collector=link_collector,
            selection_prefs=selection_prefs,
        )

    def run(self, options: Values, args: list[str]) -> int:
        if options.outdated and options.uptodate:
            raise CommandError(""Options --outdated and --uptodate cannot be combined."")

        if options.outdated and options.list_format == ""freeze"":
            raise CommandError(
                ""List format 'freeze' cannot be used with the --outdated option.""
            )

        cmdoptions.check_list_path_option(options)

        skip = set(stdlib_pkgs)
        if options.excludes:
            skip.update(canonicalize_name(n) for n in options.excludes)

        packages: _ProcessedDists = [
            cast(""_DistWithLatestInfo"", d)
            for d in get_environment(options.path).iter_installed_distributions(
                local_only=options.local,
                user_only=options.user,
                editables_only=options.editable,
                include_editables=options.include_editable,
                skip=skip,
            )
        ]

        
        
        
        
        if options.not_required:
            packages = self.get_not_required(packages, options)

        if options.outdated:
            packages = self.get_outdated(packages, options)
        elif options.uptodate:
            packages = self.get_uptodate(packages, options)

        self.output_package_listing(packages, options)
        return SUCCESS

    def get_outdated(
        self, packages: _ProcessedDists, options: Values
    ) -> _ProcessedDists:
        return [
            dist
            for dist in self.iter_packages_latest_infos(packages, options)
            if dist.latest_version > dist.version
        ]

    def get_uptodate(
        self, packages: _ProcessedDists, options: Values
    ) -> _ProcessedDists:
        return [
            dist
            for dist in self.iter_packages_latest_infos(packages, options)
            if dist.latest_version == dist.version
        ]

    def get_not_required(
        self, packages: _ProcessedDists, options: Values
    ) -> _ProcessedDists:
        dep_keys = {
            canonicalize_name(dep.name)
            for dist in packages
            for dep in (dist.iter_dependencies() or ())
        }

        
        
        
        return list({pkg for pkg in packages if pkg.canonical_name not in dep_keys})

    def iter_packages_latest_infos(
        self, packages: _ProcessedDists, options: Values
    ) -> Generator[_DistWithLatestInfo, None, None]:
        with self._build_session(options) as session:
            finder = self._build_package_finder(options, session)

            def latest_info(
                dist: _DistWithLatestInfo,
            ) -> _DistWithLatestInfo | None:
                all_candidates = finder.find_all_candidates(dist.canonical_name)
                if not options.pre:
                    
                    all_candidates = [
                        candidate
                        for candidate in all_candidates
                        if not candidate.version.is_prerelease
                    ]

                evaluator = finder.make_candidate_evaluator(
                    project_name=dist.canonical_name,
                )
                best_candidate = evaluator.sort_best_candidate(all_candidates)
                if best_candidate is None:
                    return None

                remote_version = best_candidate.version
                if best_candidate.link.is_wheel:
                    typ = ""wheel""
                else:
                    typ = ""sdist""
                dist.latest_version = remote_version
                dist.latest_filetype = typ
                return dist

            for dist in map(latest_info, packages):
                if dist is not None:
                    yield dist

    def output_package_listing(
        self, packages: _ProcessedDists, options: Values
    ) -> None:
        packages = sorted(
            packages,
            key=lambda dist: dist.canonical_name,
        )
        if options.list_format == ""columns"" and packages:
            data, header = format_for_columns(packages, options)
            self.output_package_listing_columns(data, header)
        elif options.list_format == ""freeze"":
            for dist in packages:
                try:
                    req_string = f""{dist.raw_name}=={dist.version}""
                except InvalidVersion:
                    req_string = f""{dist.raw_name}==={dist.raw_version}""
                if options.verbose >= 1:
                    write_output(""%s (%s)"", req_string, dist.location)
                else:
                    write_output(req_string)
        elif options.list_format == ""json"":
            write_output(format_for_json(packages, options))

    def output_package_listing_columns(
        self, data: list[list[str]], header: list[str]
    ) -> None:
        
        if len(data) > 0:
            data.insert(0, header)

        pkg_strings, sizes = tabulate(data)

        
        if len(data) > 0:
            pkg_strings.insert(1, "" "".join(""-"" * x for x in sizes))

        for val in pkg_strings:
            write_output(val)


def format_for_columns(
    pkgs: _ProcessedDists, options: Values
) -> tuple[list[list[str]], list[str]]:
    
    header = [""Package"", ""Version""]

    running_outdated = options.outdated
    if running_outdated:
        header.extend([""Latest"", ""Type""])

    def wheel_build_tag(dist: BaseDistribution) -> str | None:
        try:
            wheel_file = dist.read_text(""WHEEL"")
        except FileNotFoundError:
            return None
        return Parser().parsestr(wheel_file).get(""Build"")

    build_tags = [wheel_build_tag(p) for p in pkgs]
    has_build_tags = any(build_tags)
    if has_build_tags:
        header.append(""Build"")

    if options.verbose >= 1:
        header.append(""Location"")
    if options.verbose >= 1:
        header.append(""Installer"")

    has_editables = any(x.editable for x in pkgs)
    if has_editables:
        header.append(""Editable project location"")

    data = []
    for i, proj in enumerate(pkgs):
        
        
        row = [proj.raw_name, proj.raw_version]

        if running_outdated:
            row.append(str(proj.latest_version))
            row.append(proj.latest_filetype)

        if has_build_tags:
            row.append(build_tags[i] or """")

        if has_editables:
            row.append(proj.editable_project_location or """")

        if options.verbose >= 1:
            row.append(proj.location or """")
        if options.verbose >= 1:
            row.append(proj.installer)

        data.append(row)

    return data, header


def format_for_json(packages: _ProcessedDists, options: Values) -> str:
    data = []
    for dist in packages:
        try:
            version = str(dist.version)
        except InvalidVersion:
            version = dist.raw_version
        info = {
            ""name"": dist.raw_name,
            ""version"": version,
        }
        if options.verbose >= 1:
            info[""location""] = dist.location or """"
            info[""installer""] = dist.installer
        if options.outdated:
            info[""latest_version""] = str(dist.latest_version)
            info[""latest_filetype""] = dist.latest_filetype
        editable_project_location = dist.editable_project_location
        if editable_project_location:
            info[""editable_project_location""] = editable_project_location
        data.append(info)
    return json.dumps(data)

import sys
from optparse import Values
from pathlib import Path

from pip._internal.cache import WheelCache
from pip._internal.cli import cmdoptions
from pip._internal.cli.req_command import (
    RequirementCommand,
    with_cleanup,
)
from pip._internal.cli.status_codes import SUCCESS
from pip._internal.models.pylock import Pylock, is_valid_pylock_file_name
from pip._internal.operations.build.build_tracker import get_build_tracker
from pip._internal.req.req_install import (
    check_legacy_setup_py_options,
)
from pip._internal.utils.logging import getLogger
from pip._internal.utils.misc import (
    get_pip_version,
)
from pip._internal.utils.temp_dir import TempDirectory

logger = getLogger(__name__)


class LockCommand(RequirementCommand):
    

    usage = 

    def add_options(self) -> None:
        self.cmd_opts.add_option(
            cmdoptions.PipOption(
                ""--output"",
                ""-o"",
                dest=""output_file"",
                metavar=""path"",
                type=""path"",
                default=""pylock.toml"",
                help=""Lock file name (default=pylock.toml). Use - for stdout."",
            )
        )
        self.cmd_opts.add_option(cmdoptions.requirements())
        self.cmd_opts.add_option(cmdoptions.constraints())
        self.cmd_opts.add_option(cmdoptions.no_deps())
        self.cmd_opts.add_option(cmdoptions.pre())

        self.cmd_opts.add_option(cmdoptions.editable())

        self.cmd_opts.add_option(cmdoptions.src())

        self.cmd_opts.add_option(cmdoptions.ignore_requires_python())
        self.cmd_opts.add_option(cmdoptions.no_build_isolation())
        self.cmd_opts.add_option(cmdoptions.use_pep517())
        self.cmd_opts.add_option(cmdoptions.no_use_pep517())
        self.cmd_opts.add_option(cmdoptions.check_build_deps())

        self.cmd_opts.add_option(cmdoptions.config_settings())

        self.cmd_opts.add_option(cmdoptions.no_binary())
        self.cmd_opts.add_option(cmdoptions.only_binary())
        self.cmd_opts.add_option(cmdoptions.prefer_binary())
        self.cmd_opts.add_option(cmdoptions.require_hashes())
        self.cmd_opts.add_option(cmdoptions.progress_bar())

        index_opts = cmdoptions.make_option_group(
            cmdoptions.index_group,
            self.parser,
        )

        self.parser.insert_option_group(0, index_opts)
        self.parser.insert_option_group(0, self.cmd_opts)

    @with_cleanup
    def run(self, options: Values, args: list[str]) -> int:
        logger.verbose(""Using %s"", get_pip_version())

        logger.warning(
            ""pip lock is currently an experimental command. ""
            ""It may be removed/changed in a future release ""
            ""without prior warning.""
        )

        session = self.get_default_session(options)

        finder = self._build_package_finder(
            options=options,
            session=session,
            ignore_requires_python=options.ignore_requires_python,
        )
        build_tracker = self.enter_context(get_build_tracker())

        directory = TempDirectory(
            delete=not options.no_clean,
            kind=""install"",
            globally_managed=True,
        )

        reqs = self.get_requirements(args, options, finder, session)
        check_legacy_setup_py_options(options, reqs)

        wheel_cache = WheelCache(options.cache_dir)

        
        
        
        for req in reqs:
            req.permit_editable_wheels = True

        preparer = self.make_requirement_preparer(
            temp_build_dir=directory,
            options=options,
            build_tracker=build_tracker,
            session=session,
            finder=finder,
            use_user_site=False,
            verbosity=self.verbosity,
        )
        resolver = self.make_resolver(
            preparer=preparer,
            finder=finder,
            options=options,
            wheel_cache=wheel_cache,
            use_user_site=False,
            ignore_installed=True,
            ignore_requires_python=options.ignore_requires_python,
            upgrade_strategy=""to-satisfy-only"",
            use_pep517=options.use_pep517,
        )

        self.trace_basic_info(finder)

        requirement_set = resolver.resolve(reqs, check_supported_wheels=True)

        if options.output_file == ""-"":
            base_dir = Path.cwd()
        else:
            output_file_path = Path(options.output_file)
            if not is_valid_pylock_file_name(output_file_path):
                logger.warning(
                    ""%s is not a valid lock file name."",
                    output_file_path,
                )
            base_dir = output_file_path.parent
        pylock_toml = Pylock.from_install_requirements(
            requirement_set.requirements.values(), base_dir=base_dir
        ).as_toml()
        if options.output_file == ""-"":
            sys.stdout.write(pylock_toml)
        else:
            output_file_path.write_text(pylock_toml, encoding=""utf-8"")

        return SUCCESS

from __future__ import annotations

import logging
import shutil
import sys
import textwrap
import xmlrpc.client
from collections import OrderedDict
from optparse import Values
from typing import TypedDict

from pip._vendor.packaging.version import parse as parse_version

from pip._internal.cli.base_command import Command
from pip._internal.cli.req_command import SessionCommandMixin
from pip._internal.cli.status_codes import NO_MATCHES_FOUND, SUCCESS
from pip._internal.exceptions import CommandError
from pip._internal.metadata import get_default_environment
from pip._internal.metadata.base import BaseDistribution
from pip._internal.models.index import PyPI
from pip._internal.network.xmlrpc import PipXmlrpcTransport
from pip._internal.utils.logging import indent_log
from pip._internal.utils.misc import write_output


class TransformedHit(TypedDict):
    name: str
    summary: str
    versions: list[str]


logger = logging.getLogger(__name__)


class SearchCommand(Command, SessionCommandMixin):
    

    usage = 
    ignore_require_venv = True

    def add_options(self) -> None:
        self.cmd_opts.add_option(
            ""-i"",
            ""--index"",
            dest=""index"",
            metavar=""URL"",
            default=PyPI.pypi_url,
            help=""Base URL of Python Package Index (default %default)"",
        )

        self.parser.insert_option_group(0, self.cmd_opts)

    def run(self, options: Values, args: list[str]) -> int:
        if not args:
            raise CommandError(""Missing required argument (search query)."")
        query = args
        pypi_hits = self.search(query, options)
        hits = transform_hits(pypi_hits)

        terminal_width = None
        if sys.stdout.isatty():
            terminal_width = shutil.get_terminal_size()[0]

        print_results(hits, terminal_width=terminal_width)
        if pypi_hits:
            return SUCCESS
        return NO_MATCHES_FOUND

    def search(self, query: list[str], options: Values) -> list[dict[str, str]]:
        index_url = options.index

        session = self.get_default_session(options)

        transport = PipXmlrpcTransport(index_url, session)
        pypi = xmlrpc.client.ServerProxy(index_url, transport)
        try:
            hits = pypi.search({""name"": query, ""summary"": query}, ""or"")
        except xmlrpc.client.Fault as fault:
            message = (
                f""XMLRPC request failed [code: {fault.faultCode}]\n{fault.faultString}""
            )
            raise CommandError(message)
        assert isinstance(hits, list)
        return hits


def transform_hits(hits: list[dict[str, str]]) -> list[TransformedHit]:
    
    packages: dict[str, TransformedHit] = OrderedDict()
    for hit in hits:
        name = hit[""name""]
        summary = hit[""summary""]
        version = hit[""version""]

        if name not in packages.keys():
            packages[name] = {
                ""name"": name,
                ""summary"": summary,
                ""versions"": [version],
            }
        else:
            packages[name][""versions""].append(version)

            
            if version == highest_version(packages[name][""versions""]):
                packages[name][""summary""] = summary

    return list(packages.values())


def print_dist_installation_info(latest: str, dist: BaseDistribution | None) -> None:
    if dist is not None:
        with indent_log():
            if dist.version == latest:
                write_output(""INSTALLED: %s (latest)"", dist.version)
            else:
                write_output(""INSTALLED: %s"", dist.version)
                if parse_version(latest).pre:
                    write_output(
                        ""LATEST:    %s (pre-release; install""
                        "" with `pip install --pre`)"",
                        latest,
                    )
                else:
                    write_output(""LATEST:    %s"", latest)


def get_installed_distribution(name: str) -> BaseDistribution | None:
    env = get_default_environment()
    return env.get_distribution(name)


def print_results(
    hits: list[TransformedHit],
    name_column_width: int | None = None,
    terminal_width: int | None = None,
) -> None:
    if not hits:
        return
    if name_column_width is None:
        name_column_width = (
            max(
                [
                    len(hit[""name""]) + len(highest_version(hit.get(""versions"", [""-""])))
                    for hit in hits
                ]
            )
            + 4
        )

    for hit in hits:
        name = hit[""name""]
        summary = hit[""summary""] or """"
        latest = highest_version(hit.get(""versions"", [""-""]))
        if terminal_width is not None:
            target_width = terminal_width - name_column_width - 5
            if target_width > 10:
                
                summary_lines = textwrap.wrap(summary, target_width)
                summary = (""\n"" + "" "" * (name_column_width + 3)).join(summary_lines)

        name_latest = f""{name} ({latest})""
        line = f""{name_latest:{name_column_width}} - {summary}""
        try:
            write_output(line)
            dist = get_installed_distribution(name)
            print_dist_installation_info(latest, dist)
        except UnicodeEncodeError:
            pass


def highest_version(versions: list[str]) -> str:
    return max(versions, key=parse_version)

from __future__ import annotations

import logging
import string
from collections.abc import Generator, Iterable, Iterator
from optparse import Values
from typing import NamedTuple

from pip._vendor.packaging.requirements import InvalidRequirement
from pip._vendor.packaging.utils import canonicalize_name

from pip._internal.cli.base_command import Command
from pip._internal.cli.status_codes import ERROR, SUCCESS
from pip._internal.metadata import BaseDistribution, get_default_environment
from pip._internal.utils.misc import write_output

logger = logging.getLogger(__name__)


def normalize_project_url_label(label: str) -> str:
    
    chars_to_remove = string.punctuation + string.whitespace
    removal_map = str.maketrans("""", """", chars_to_remove)
    return label.translate(removal_map).lower()


class ShowCommand(Command):
    

    usage = 
    ignore_require_venv = True

    def add_options(self) -> None:
        self.cmd_opts.add_option(
            ""-f"",
            ""--files"",
            dest=""files"",
            action=""store_true"",
            default=False,
            help=""Show the full list of installed files for each package."",
        )

        self.parser.insert_option_group(0, self.cmd_opts)

    def run(self, options: Values, args: list[str]) -> int:
        if not args:
            logger.warning(""ERROR: Please provide a package name or names."")
            return ERROR
        query = args

        results = search_packages_info(query)
        if not print_results(
            results, list_files=options.files, verbose=options.verbose
        ):
            return ERROR
        return SUCCESS


class _PackageInfo(NamedTuple):
    name: str
    version: str
    location: str
    editable_project_location: str | None
    requires: list[str]
    required_by: list[str]
    installer: str
    metadata_version: str
    classifiers: list[str]
    summary: str
    homepage: str
    project_urls: list[str]
    author: str
    author_email: str
    license: str
    license_expression: str
    entry_points: list[str]
    files: list[str] | None


def search_packages_info(query: list[str]) -> Generator[_PackageInfo, None, None]:
    
    env = get_default_environment()

    installed = {dist.canonical_name: dist for dist in env.iter_all_distributions()}
    query_names = [canonicalize_name(name) for name in query]
    missing = sorted(
        [name for name, pkg in zip(query, query_names) if pkg not in installed]
    )
    if missing:
        logger.warning(""Package(s) not found: %s"", "", "".join(missing))

    def _get_requiring_packages(current_dist: BaseDistribution) -> Iterator[str]:
        return (
            dist.metadata[""Name""] or ""UNKNOWN""
            for dist in installed.values()
            if current_dist.canonical_name
            in {canonicalize_name(d.name) for d in dist.iter_dependencies()}
        )

    for query_name in query_names:
        try:
            dist = installed[query_name]
        except KeyError:
            continue

        try:
            requires = sorted(
                
                {req.name for req in dist.iter_dependencies()},
                key=str.lower,
            )
        except InvalidRequirement:
            requires = sorted(dist.iter_raw_dependencies(), key=str.lower)

        try:
            required_by = sorted(_get_requiring_packages(dist), key=str.lower)
        except InvalidRequirement:
            required_by = [""

        try:
            entry_points_text = dist.read_text(""entry_points.txt"")
            entry_points = entry_points_text.splitlines(keepends=False)
        except FileNotFoundError:
            entry_points = []

        files_iter = dist.iter_declared_entries()
        if files_iter is None:
            files: list[str] | None = None
        else:
            files = sorted(files_iter)

        metadata = dist.metadata

        project_urls = metadata.get_all(""Project-URL"", [])
        homepage = metadata.get(""Home-page"", """")
        if not homepage:
            
            
            for url in project_urls:
                url_label, url = url.split("","", maxsplit=1)
                normalized_label = normalize_project_url_label(url_label)
                if normalized_label == ""homepage"":
                    homepage = url.strip()
                    break

        yield _PackageInfo(
            name=dist.raw_name,
            version=dist.raw_version,
            location=dist.location or """",
            editable_project_location=dist.editable_project_location,
            requires=requires,
            required_by=required_by,
            installer=dist.installer,
            metadata_version=dist.metadata_version or """",
            classifiers=metadata.get_all(""Classifier"", []),
            summary=metadata.get(""Summary"", """"),
            homepage=homepage,
            project_urls=project_urls,
            author=metadata.get(""Author"", """"),
            author_email=metadata.get(""Author-email"", """"),
            license=metadata.get(""License"", """"),
            license_expression=metadata.get(""License-Expression"", """"),
            entry_points=entry_points,
            files=files,
        )


def print_results(
    distributions: Iterable[_PackageInfo],
    list_files: bool,
    verbose: bool,
) -> bool:
    
    results_printed = False
    for i, dist in enumerate(distributions):
        results_printed = True
        if i > 0:
            write_output(""---"")

        metadata_version_tuple = tuple(map(int, dist.metadata_version.split(""."")))

        write_output(""Name: %s"", dist.name)
        write_output(""Version: %s"", dist.version)
        write_output(""Summary: %s"", dist.summary)
        write_output(""Home-page: %s"", dist.homepage)
        write_output(""Author: %s"", dist.author)
        write_output(""Author-email: %s"", dist.author_email)
        if metadata_version_tuple >= (2, 4) and dist.license_expression:
            write_output(""License-Expression: %s"", dist.license_expression)
        else:
            write_output(""License: %s"", dist.license)
        write_output(""Location: %s"", dist.location)
        if dist.editable_project_location is not None:
            write_output(
                ""Editable project location: %s"", dist.editable_project_location
            )
        write_output(""Requires: %s"", "", "".join(dist.requires))
        write_output(""Required-by: %s"", "", "".join(dist.required_by))

        if verbose:
            write_output(""Metadata-Version: %s"", dist.metadata_version)
            write_output(""Installer: %s"", dist.installer)
            write_output(""Classifiers:"")
            for classifier in dist.classifiers:
                write_output(""  %s"", classifier)
            write_output(""Entry-points:"")
            for entry in dist.entry_points:
                write_output(""  %s"", entry.strip())
            write_output(""Project-URLs:"")
            for project_url in dist.project_urls:
                write_output(""  %s"", project_url)
        if list_files:
            write_output(""Files:"")
            if dist.files is None:
                write_output(""Cannot locate RECORD or installed-files.txt"")
            else:
                for line in dist.files:
                    write_output(""  %s"", line.strip())
    return results_printed

import logging
from optparse import Values

from pip._vendor.packaging.utils import canonicalize_name

from pip._internal.cli import cmdoptions
from pip._internal.cli.base_command import Command
from pip._internal.cli.index_command import SessionCommandMixin
from pip._internal.cli.status_codes import SUCCESS
from pip._internal.exceptions import InstallationError
from pip._internal.req import parse_requirements
from pip._internal.req.constructors import (
    install_req_from_line,
    install_req_from_parsed_requirement,
)
from pip._internal.utils.misc import (
    check_externally_managed,
    protect_pip_from_modification_on_windows,
    warn_if_run_as_root,
)

logger = logging.getLogger(__name__)


class UninstallCommand(Command, SessionCommandMixin):
    

    usage = 

    def add_options(self) -> None:
        self.cmd_opts.add_option(
            ""-r"",
            ""--requirement"",
            dest=""requirements"",
            action=""append"",
            default=[],
            metavar=""file"",
            help=(
                ""Uninstall all the packages listed in the given requirements ""
                ""file.  This option can be used multiple times.""
            ),
        )
        self.cmd_opts.add_option(
            ""-y"",
            ""--yes"",
            dest=""yes"",
            action=""store_true"",
            help=""Don't ask for confirmation of uninstall deletions."",
        )
        self.cmd_opts.add_option(cmdoptions.root_user_action())
        self.cmd_opts.add_option(cmdoptions.override_externally_managed())
        self.parser.insert_option_group(0, self.cmd_opts)

    def run(self, options: Values, args: list[str]) -> int:
        session = self.get_default_session(options)

        reqs_to_uninstall = {}
        for name in args:
            req = install_req_from_line(
                name,
                isolated=options.isolated_mode,
            )
            if req.name:
                reqs_to_uninstall[canonicalize_name(req.name)] = req
            else:
                logger.warning(
                    ""Invalid requirement: %r ignored -""
                    "" the uninstall command expects named""
                    "" requirements."",
                    name,
                )
        for filename in options.requirements:
            for parsed_req in parse_requirements(
                filename, options=options, session=session
            ):
                req = install_req_from_parsed_requirement(
                    parsed_req, isolated=options.isolated_mode
                )
                if req.name:
                    reqs_to_uninstall[canonicalize_name(req.name)] = req
        if not reqs_to_uninstall:
            raise InstallationError(
                f""You must give at least one requirement to {self.name} (see ""
                f'""pip help {self.name}"")'
            )

        if not options.override_externally_managed:
            check_externally_managed()

        protect_pip_from_modification_on_windows(
            modifying_pip=""pip"" in reqs_to_uninstall
        )

        for req in reqs_to_uninstall.values():
            uninstall_pathset = req.uninstall(
                auto_confirm=options.yes,
                verbose=self.verbosity > 0,
            )
            if uninstall_pathset:
                uninstall_pathset.commit()
        if options.root_user_action == ""warn"":
            warn_if_run_as_root()
        return SUCCESS

import logging
import os
import shutil
from optparse import Values

from pip._internal.cache import WheelCache
from pip._internal.cli import cmdoptions
from pip._internal.cli.req_command import RequirementCommand, with_cleanup
from pip._internal.cli.status_codes import SUCCESS
from pip._internal.exceptions import CommandError
from pip._internal.operations.build.build_tracker import get_build_tracker
from pip._internal.req.req_install import (
    InstallRequirement,
    check_legacy_setup_py_options,
)
from pip._internal.utils.misc import ensure_dir, normalize_path
from pip._internal.utils.temp_dir import TempDirectory
from pip._internal.wheel_builder import build

logger = logging.getLogger(__name__)


class WheelCommand(RequirementCommand):
    

    usage = 

    def add_options(self) -> None:
        self.cmd_opts.add_option(
            ""-w"",
            ""--wheel-dir"",
            dest=""wheel_dir"",
            metavar=""dir"",
            default=os.curdir,
            help=(
                ""Build wheels into <dir>, where the default is the ""
                ""current working directory.""
            ),
        )
        self.cmd_opts.add_option(cmdoptions.no_binary())
        self.cmd_opts.add_option(cmdoptions.only_binary())
        self.cmd_opts.add_option(cmdoptions.prefer_binary())
        self.cmd_opts.add_option(cmdoptions.no_build_isolation())
        self.cmd_opts.add_option(cmdoptions.use_pep517())
        self.cmd_opts.add_option(cmdoptions.no_use_pep517())
        self.cmd_opts.add_option(cmdoptions.check_build_deps())
        self.cmd_opts.add_option(cmdoptions.constraints())
        self.cmd_opts.add_option(cmdoptions.editable())
        self.cmd_opts.add_option(cmdoptions.requirements())
        self.cmd_opts.add_option(cmdoptions.src())
        self.cmd_opts.add_option(cmdoptions.ignore_requires_python())
        self.cmd_opts.add_option(cmdoptions.no_deps())
        self.cmd_opts.add_option(cmdoptions.progress_bar())

        self.cmd_opts.add_option(
            ""--no-verify"",
            dest=""no_verify"",
            action=""store_true"",
            default=False,
            help=""Don't verify if built wheel is valid."",
        )

        self.cmd_opts.add_option(cmdoptions.config_settings())
        self.cmd_opts.add_option(cmdoptions.build_options())
        self.cmd_opts.add_option(cmdoptions.global_options())

        self.cmd_opts.add_option(
            ""--pre"",
            action=""store_true"",
            default=False,
            help=(
                ""Include pre-release and development versions. By default, ""
                ""pip only finds stable versions.""
            ),
        )

        self.cmd_opts.add_option(cmdoptions.require_hashes())

        index_opts = cmdoptions.make_option_group(
            cmdoptions.index_group,
            self.parser,
        )

        self.parser.insert_option_group(0, index_opts)
        self.parser.insert_option_group(0, self.cmd_opts)

    @with_cleanup
    def run(self, options: Values, args: list[str]) -> int:
        session = self.get_default_session(options)

        finder = self._build_package_finder(options, session)

        options.wheel_dir = normalize_path(options.wheel_dir)
        ensure_dir(options.wheel_dir)

        build_tracker = self.enter_context(get_build_tracker())

        directory = TempDirectory(
            delete=not options.no_clean,
            kind=""wheel"",
            globally_managed=True,
        )

        reqs = self.get_requirements(args, options, finder, session)
        check_legacy_setup_py_options(options, reqs)

        wheel_cache = WheelCache(options.cache_dir)

        preparer = self.make_requirement_preparer(
            temp_build_dir=directory,
            options=options,
            build_tracker=build_tracker,
            session=session,
            finder=finder,
            download_dir=options.wheel_dir,
            use_user_site=False,
            verbosity=self.verbosity,
        )

        resolver = self.make_resolver(
            preparer=preparer,
            finder=finder,
            options=options,
            wheel_cache=wheel_cache,
            ignore_requires_python=options.ignore_requires_python,
            use_pep517=options.use_pep517,
        )

        self.trace_basic_info(finder)

        requirement_set = resolver.resolve(reqs, check_supported_wheels=True)

        reqs_to_build: list[InstallRequirement] = []
        for req in requirement_set.requirements.values():
            if req.is_wheel:
                preparer.save_linked_requirement(req)
            else:
                reqs_to_build.append(req)

        preparer.prepare_linked_requirements_more(requirement_set.requirements.values())

        
        build_successes, build_failures = build(
            reqs_to_build,
            wheel_cache=wheel_cache,
            verify=(not options.no_verify),
            build_options=options.build_options or [],
            global_options=options.global_options or [],
        )
        for req in build_successes:
            assert req.link and req.link.is_wheel
            assert req.local_file_path
            
            try:
                shutil.copy(req.local_file_path, options.wheel_dir)
            except OSError as e:
                logger.warning(
                    ""Building wheel for %s failed: %s"",
                    req.name,
                    e,
                )
                build_failures.append(req)
        if len(build_failures) != 0:
            raise CommandError(""Failed to build one or more wheels"")

        return SUCCESS



from __future__ import annotations

import importlib
from collections import namedtuple
from typing import Any

from pip._internal.cli.base_command import Command

CommandInfo = namedtuple(""CommandInfo"", ""module_path, class_name, summary"")








commands_dict: dict[str, CommandInfo] = {
    ""install"": CommandInfo(
        ""pip._internal.commands.install"",
        ""InstallCommand"",
        ""Install packages."",
    ),
    ""lock"": CommandInfo(
        ""pip._internal.commands.lock"",
        ""LockCommand"",
        ""Generate a lock file."",
    ),
    ""download"": CommandInfo(
        ""pip._internal.commands.download"",
        ""DownloadCommand"",
        ""Download packages."",
    ),
    ""uninstall"": CommandInfo(
        ""pip._internal.commands.uninstall"",
        ""UninstallCommand"",
        ""Uninstall packages."",
    ),
    ""freeze"": CommandInfo(
        ""pip._internal.commands.freeze"",
        ""FreezeCommand"",
        ""Output installed packages in requirements format."",
    ),
    ""inspect"": CommandInfo(
        ""pip._internal.commands.inspect"",
        ""InspectCommand"",
        ""Inspect the python environment."",
    ),
    ""list"": CommandInfo(
        ""pip._internal.commands.list"",
        ""ListCommand"",
        ""List installed packages."",
    ),
    ""show"": CommandInfo(
        ""pip._internal.commands.show"",
        ""ShowCommand"",
        ""Show information about installed packages."",
    ),
    ""check"": CommandInfo(
        ""pip._internal.commands.check"",
        ""CheckCommand"",
        ""Verify installed packages have compatible dependencies."",
    ),
    ""config"": CommandInfo(
        ""pip._internal.commands.configuration"",
        ""ConfigurationCommand"",
        ""Manage local and global configuration."",
    ),
    ""search"": CommandInfo(
        ""pip._internal.commands.search"",
        ""SearchCommand"",
        ""Search PyPI for packages."",
    ),
    ""cache"": CommandInfo(
        ""pip._internal.commands.cache"",
        ""CacheCommand"",
        ""Inspect and manage pip's wheel cache."",
    ),
    ""index"": CommandInfo(
        ""pip._internal.commands.index"",
        ""IndexCommand"",
        ""Inspect information available from package indexes."",
    ),
    ""wheel"": CommandInfo(
        ""pip._internal.commands.wheel"",
        ""WheelCommand"",
        ""Build wheels from your requirements."",
    ),
    ""hash"": CommandInfo(
        ""pip._internal.commands.hash"",
        ""HashCommand"",
        ""Compute hashes of package archives."",
    ),
    ""completion"": CommandInfo(
        ""pip._internal.commands.completion"",
        ""CompletionCommand"",
        ""A helper command used for command completion."",
    ),
    ""debug"": CommandInfo(
        ""pip._internal.commands.debug"",
        ""DebugCommand"",
        ""Show information useful for debugging."",
    ),
    ""help"": CommandInfo(
        ""pip._internal.commands.help"",
        ""HelpCommand"",
        ""Show help for commands."",
    ),
}


def create_command(name: str, **kwargs: Any) -> Command:
    
    module_path, class_name, summary = commands_dict[name]
    module = importlib.import_module(module_path)
    command_class = getattr(module, class_name)
    command = command_class(name=name, summary=summary, **kwargs)

    return command


def get_similar_commands(name: str) -> str | None:
    
    from difflib import get_close_matches

    name = name.lower()

    close_commands = get_close_matches(name, commands_dict.keys())

    if close_commands:
        return close_commands[0]
    else:
        return None

from __future__ import annotations

import abc
from typing import TYPE_CHECKING

from pip._internal.metadata.base import BaseDistribution
from pip._internal.req import InstallRequirement

if TYPE_CHECKING:
    from pip._internal.build_env import BuildEnvironmentInstaller


class AbstractDistribution(metaclass=abc.ABCMeta):
    

    def __init__(self, req: InstallRequirement) -> None:
        super().__init__()
        self.req = req

    @abc.abstractproperty
    def build_tracker_id(self) -> str | None:
        
        raise NotImplementedError()

    @abc.abstractmethod
    def get_metadata_distribution(self) -> BaseDistribution:
        raise NotImplementedError()

    @abc.abstractmethod
    def prepare_distribution_metadata(
        self,
        build_env_installer: BuildEnvironmentInstaller,
        build_isolation: bool,
        check_build_deps: bool,
    ) -> None:
        raise NotImplementedError()

from __future__ import annotations

from typing import TYPE_CHECKING

from pip._internal.distributions.base import AbstractDistribution
from pip._internal.metadata import BaseDistribution

if TYPE_CHECKING:
    from pip._internal.build_env import BuildEnvironmentInstaller


class InstalledDistribution(AbstractDistribution):
    

    @property
    def build_tracker_id(self) -> str | None:
        return None

    def get_metadata_distribution(self) -> BaseDistribution:
        assert self.req.satisfied_by is not None, ""not actually installed""
        return self.req.satisfied_by

    def prepare_distribution_metadata(
        self,
        build_env_installer: BuildEnvironmentInstaller,
        build_isolation: bool,
        check_build_deps: bool,
    ) -> None:
        pass

from __future__ import annotations

import logging
from collections.abc import Iterable
from typing import TYPE_CHECKING

from pip._internal.build_env import BuildEnvironment
from pip._internal.distributions.base import AbstractDistribution
from pip._internal.exceptions import InstallationError
from pip._internal.metadata import BaseDistribution
from pip._internal.utils.subprocess import runner_with_spinner_message

if TYPE_CHECKING:
    from pip._internal.build_env import BuildEnvironmentInstaller

logger = logging.getLogger(__name__)


class SourceDistribution(AbstractDistribution):
    

    @property
    def build_tracker_id(self) -> str | None:
        
        assert self.req.link
        return self.req.link.url_without_fragment

    def get_metadata_distribution(self) -> BaseDistribution:
        return self.req.get_dist()

    def prepare_distribution_metadata(
        self,
        build_env_installer: BuildEnvironmentInstaller,
        build_isolation: bool,
        check_build_deps: bool,
    ) -> None:
        
        self.req.load_pyproject_toml()

        
        should_isolate = self.req.use_pep517 and build_isolation
        if should_isolate:
            
            
            self._prepare_build_backend(build_env_installer)
            
            
            
            
            
            
            
            self.req.isolated_editable_sanity_check()
            
            self._install_build_reqs(build_env_installer)
        
        should_check_deps = self.req.use_pep517 and check_build_deps
        if should_check_deps:
            pyproject_requires = self.req.pyproject_requires
            assert pyproject_requires is not None
            conflicting, missing = self.req.build_env.check_requirements(
                pyproject_requires
            )
            if conflicting:
                self._raise_conflicts(""the backend dependencies"", conflicting)
            if missing:
                self._raise_missing_reqs(missing)
        self.req.prepare_metadata()

    def _prepare_build_backend(
        self, build_env_installer: BuildEnvironmentInstaller
    ) -> None:
        
        
        pyproject_requires = self.req.pyproject_requires
        assert pyproject_requires is not None

        self.req.build_env = BuildEnvironment(build_env_installer)
        self.req.build_env.install_requirements(
            pyproject_requires, ""overlay"", kind=""build dependencies"", for_req=self.req
        )
        conflicting, missing = self.req.build_env.check_requirements(
            self.req.requirements_to_check
        )
        if conflicting:
            self._raise_conflicts(""PEP 517/518 supported requirements"", conflicting)
        if missing:
            logger.warning(
                ""Missing build requirements in pyproject.toml for %s."",
                self.req,
            )
            logger.warning(
                ""The project does not specify a build backend, and ""
                ""pip cannot fall back to setuptools without %s."",
                "" and "".join(map(repr, sorted(missing))),
            )

    def _get_build_requires_wheel(self) -> Iterable[str]:
        with self.req.build_env:
            runner = runner_with_spinner_message(""Getting requirements to build wheel"")
            backend = self.req.pep517_backend
            assert backend is not None
            with backend.subprocess_runner(runner):
                return backend.get_requires_for_build_wheel()

    def _get_build_requires_editable(self) -> Iterable[str]:
        with self.req.build_env:
            runner = runner_with_spinner_message(
                ""Getting requirements to build editable""
            )
            backend = self.req.pep517_backend
            assert backend is not None
            with backend.subprocess_runner(runner):
                return backend.get_requires_for_build_editable()

    def _install_build_reqs(
        self, build_env_installer: BuildEnvironmentInstaller
    ) -> None:
        
        
        
        if (
            self.req.editable
            and self.req.permit_editable_wheels
            and self.req.supports_pyproject_editable
        ):
            build_reqs = self._get_build_requires_editable()
        else:
            build_reqs = self._get_build_requires_wheel()
        conflicting, missing = self.req.build_env.check_requirements(build_reqs)
        if conflicting:
            self._raise_conflicts(""the backend dependencies"", conflicting)
        self.req.build_env.install_requirements(
            missing, ""normal"", kind=""backend dependencies"", for_req=self.req
        )

    def _raise_conflicts(
        self, conflicting_with: str, conflicting_reqs: set[tuple[str, str]]
    ) -> None:
        format_string = (
            ""Some build dependencies for {requirement} ""
            ""conflict with {conflicting_with}: {description}.""
        )
        error_message = format_string.format(
            requirement=self.req,
            conflicting_with=conflicting_with,
            description="", "".join(
                f""{installed} is incompatible with {wanted}""
                for installed, wanted in sorted(conflicting_reqs)
            ),
        )
        raise InstallationError(error_message)

    def _raise_missing_reqs(self, missing: set[str]) -> None:
        format_string = (
            ""Some build dependencies for {requirement} are missing: {missing}.""
        )
        error_message = format_string.format(
            requirement=self.req, missing="", "".join(map(repr, sorted(missing)))
        )
        raise InstallationError(error_message)

from __future__ import annotations

from typing import TYPE_CHECKING

from pip._vendor.packaging.utils import canonicalize_name

from pip._internal.distributions.base import AbstractDistribution
from pip._internal.metadata import (
    BaseDistribution,
    FilesystemWheel,
    get_wheel_distribution,
)

if TYPE_CHECKING:
    from pip._internal.build_env import BuildEnvironmentInstaller


class WheelDistribution(AbstractDistribution):
    

    @property
    def build_tracker_id(self) -> str | None:
        return None

    def get_metadata_distribution(self) -> BaseDistribution:
        
        assert self.req.local_file_path, ""Set as part of preparation during download""
        assert self.req.name, ""Wheels are never unnamed""
        wheel = FilesystemWheel(self.req.local_file_path)
        return get_wheel_distribution(wheel, canonicalize_name(self.req.name))

    def prepare_distribution_metadata(
        self,
        build_env_installer: BuildEnvironmentInstaller,
        build_isolation: bool,
        check_build_deps: bool,
    ) -> None:
        pass

from pip._internal.distributions.base import AbstractDistribution
from pip._internal.distributions.sdist import SourceDistribution
from pip._internal.distributions.wheel import WheelDistribution
from pip._internal.req.req_install import InstallRequirement


def make_distribution_for_install_requirement(
    install_req: InstallRequirement,
) -> AbstractDistribution:
    
    
    
    if install_req.editable:
        return SourceDistribution(install_req)

    
    if install_req.is_wheel:
        return WheelDistribution(install_req)

    
    return SourceDistribution(install_req)



from __future__ import annotations

import collections
import email.message
import functools
import itertools
import json
import logging
import os
import urllib.parse
import urllib.request
from collections.abc import Iterable, MutableMapping, Sequence
from dataclasses import dataclass
from html.parser import HTMLParser
from optparse import Values
from typing import (
    Callable,
    NamedTuple,
    Protocol,
)

from pip._vendor import requests
from pip._vendor.requests import Response
from pip._vendor.requests.exceptions import RetryError, SSLError

from pip._internal.exceptions import NetworkConnectionError
from pip._internal.models.link import Link
from pip._internal.models.search_scope import SearchScope
from pip._internal.network.session import PipSession
from pip._internal.network.utils import raise_for_status
from pip._internal.utils.filetypes import is_archive_file
from pip._internal.utils.misc import redact_auth_from_url
from pip._internal.vcs import vcs

from .sources import CandidatesFromPage, LinkSource, build_source

logger = logging.getLogger(__name__)

ResponseHeaders = MutableMapping[str, str]


def _match_vcs_scheme(url: str) -> str | None:
    
    for scheme in vcs.schemes:
        if url.lower().startswith(scheme) and url[len(scheme)] in ""+:"":
            return scheme
    return None


class _NotAPIContent(Exception):
    def __init__(self, content_type: str, request_desc: str) -> None:
        super().__init__(content_type, request_desc)
        self.content_type = content_type
        self.request_desc = request_desc


def _ensure_api_header(response: Response) -> None:
    
    content_type = response.headers.get(""Content-Type"", ""Unknown"")

    content_type_l = content_type.lower()
    if content_type_l.startswith(
        (
            ""text/html"",
            ""application/vnd.pypi.simple.v1+html"",
            ""application/vnd.pypi.simple.v1+json"",
        )
    ):
        return

    raise _NotAPIContent(content_type, response.request.method)


class _NotHTTP(Exception):
    pass


def _ensure_api_response(url: str, session: PipSession) -> None:
    
    scheme, netloc, path, query, fragment = urllib.parse.urlsplit(url)
    if scheme not in {""http"", ""https""}:
        raise _NotHTTP()

    resp = session.head(url, allow_redirects=True)
    raise_for_status(resp)

    _ensure_api_header(resp)


def _get_simple_response(url: str, session: PipSession) -> Response:
    
    if is_archive_file(Link(url).filename):
        _ensure_api_response(url, session=session)

    logger.debug(""Getting page %s"", redact_auth_from_url(url))

    resp = session.get(
        url,
        headers={
            ""Accept"": "", "".join(
                [
                    ""application/vnd.pypi.simple.v1+json"",
                    ""application/vnd.pypi.simple.v1+html; q=0.1"",
                    ""text/html; q=0.01"",
                ]
            ),
            
            
            
            
            
            
            
            
            
            
            
            
            
            ""Cache-Control"": ""max-age=0"",
        },
    )
    raise_for_status(resp)

    
    
    
    
    
    
    _ensure_api_header(resp)

    logger.debug(
        ""Fetched page %s as %s"",
        redact_auth_from_url(url),
        resp.headers.get(""Content-Type"", ""Unknown""),
    )

    return resp


def _get_encoding_from_headers(headers: ResponseHeaders) -> str | None:
    
    if headers and ""Content-Type"" in headers:
        m = email.message.Message()
        m[""content-type""] = headers[""Content-Type""]
        charset = m.get_param(""charset"")
        if charset:
            return str(charset)
    return None


class CacheablePageContent:
    def __init__(self, page: IndexContent) -> None:
        assert page.cache_link_parsing
        self.page = page

    def __eq__(self, other: object) -> bool:
        return isinstance(other, type(self)) and self.page.url == other.page.url

    def __hash__(self) -> int:
        return hash(self.page.url)


class ParseLinks(Protocol):
    def __call__(self, page: IndexContent) -> Iterable[Link]: ...


def with_cached_index_content(fn: ParseLinks) -> ParseLinks:
    

    @functools.cache
    def wrapper(cacheable_page: CacheablePageContent) -> list[Link]:
        return list(fn(cacheable_page.page))

    @functools.wraps(fn)
    def wrapper_wrapper(page: IndexContent) -> list[Link]:
        if page.cache_link_parsing:
            return wrapper(CacheablePageContent(page))
        return list(fn(page))

    return wrapper_wrapper


@with_cached_index_content
def parse_links(page: IndexContent) -> Iterable[Link]:
    

    content_type_l = page.content_type.lower()
    if content_type_l.startswith(""application/vnd.pypi.simple.v1+json""):
        data = json.loads(page.content)
        for file in data.get(""files"", []):
            link = Link.from_json(file, page.url)
            if link is None:
                continue
            yield link
        return

    parser = HTMLLinkParser(page.url)
    encoding = page.encoding or ""utf-8""
    parser.feed(page.content.decode(encoding))

    url = page.url
    base_url = parser.base_url or url
    for anchor in parser.anchors:
        link = Link.from_element(anchor, page_url=url, base_url=base_url)
        if link is None:
            continue
        yield link


@dataclass(frozen=True)
class IndexContent:
    

    content: bytes
    content_type: str
    encoding: str | None
    url: str
    cache_link_parsing: bool = True

    def __str__(self) -> str:
        return redact_auth_from_url(self.url)


class HTMLLinkParser(HTMLParser):
    

    def __init__(self, url: str) -> None:
        super().__init__(convert_charrefs=True)

        self.url: str = url
        self.base_url: str | None = None
        self.anchors: list[dict[str, str | None]] = []

    def handle_starttag(self, tag: str, attrs: list[tuple[str, str | None]]) -> None:
        if tag == ""base"" and self.base_url is None:
            href = self.get_href(attrs)
            if href is not None:
                self.base_url = href
        elif tag == ""a"":
            self.anchors.append(dict(attrs))

    def get_href(self, attrs: list[tuple[str, str | None]]) -> str | None:
        for name, value in attrs:
            if name == ""href"":
                return value
        return None


def _handle_get_simple_fail(
    link: Link,
    reason: str | Exception,
    meth: Callable[..., None] | None = None,
) -> None:
    if meth is None:
        meth = logger.debug
    meth(""Could not fetch URL %s: %s - skipping"", link, reason)


def _make_index_content(
    response: Response, cache_link_parsing: bool = True
) -> IndexContent:
    encoding = _get_encoding_from_headers(response.headers)
    return IndexContent(
        response.content,
        response.headers[""Content-Type""],
        encoding=encoding,
        url=response.url,
        cache_link_parsing=cache_link_parsing,
    )


def _get_index_content(link: Link, *, session: PipSession) -> IndexContent | None:
    url = link.url.split(""

    
    vcs_scheme = _match_vcs_scheme(url)
    if vcs_scheme:
        logger.warning(
            ""Cannot look at %s URL %s because it does not support lookup as web pages."",
            vcs_scheme,
            link,
        )
        return None

    
    scheme, _, path, _, _, _ = urllib.parse.urlparse(url)
    if scheme == ""file"" and os.path.isdir(urllib.request.url2pathname(path)):
        
        
        if not url.endswith(""/""):
            url += ""/""
        
        
        
        
        url = urllib.parse.urljoin(url, ""index.html"")
        logger.debug("" file: URL is directory, getting %s"", url)

    try:
        resp = _get_simple_response(url, session=session)
    except _NotHTTP:
        logger.warning(
            ""Skipping page %s because it looks like an archive, and cannot ""
            ""be checked by a HTTP HEAD request."",
            link,
        )
    except _NotAPIContent as exc:
        logger.warning(
            ""Skipping page %s because the %s request got Content-Type: %s. ""
            ""The only supported Content-Types are application/vnd.pypi.simple.v1+json, ""
            ""application/vnd.pypi.simple.v1+html, and text/html"",
            link,
            exc.request_desc,
            exc.content_type,
        )
    except NetworkConnectionError as exc:
        _handle_get_simple_fail(link, exc)
    except RetryError as exc:
        _handle_get_simple_fail(link, exc)
    except SSLError as exc:
        reason = ""There was a problem confirming the ssl certificate: ""
        reason += str(exc)
        _handle_get_simple_fail(link, reason, meth=logger.info)
    except requests.ConnectionError as exc:
        _handle_get_simple_fail(link, f""connection error: {exc}"")
    except requests.Timeout:
        _handle_get_simple_fail(link, ""timed out"")
    else:
        return _make_index_content(resp, cache_link_parsing=link.cache_link_parsing)
    return None


class CollectedSources(NamedTuple):
    find_links: Sequence[LinkSource | None]
    index_urls: Sequence[LinkSource | None]


class LinkCollector:
    

    def __init__(
        self,
        session: PipSession,
        search_scope: SearchScope,
    ) -> None:
        self.search_scope = search_scope
        self.session = session

    @classmethod
    def create(
        cls,
        session: PipSession,
        options: Values,
        suppress_no_index: bool = False,
    ) -> LinkCollector:
        
        index_urls = [options.index_url] + options.extra_index_urls
        if options.no_index and not suppress_no_index:
            logger.debug(
                ""Ignoring indexes: %s"",
                "","".join(redact_auth_from_url(url) for url in index_urls),
            )
            index_urls = []

        
        find_links = options.find_links or []

        search_scope = SearchScope.create(
            find_links=find_links,
            index_urls=index_urls,
            no_index=options.no_index,
        )
        link_collector = LinkCollector(
            session=session,
            search_scope=search_scope,
        )
        return link_collector

    @property
    def find_links(self) -> list[str]:
        return self.search_scope.find_links

    def fetch_response(self, location: Link) -> IndexContent | None:
        
        return _get_index_content(location, session=self.session)

    def collect_sources(
        self,
        project_name: str,
        candidates_from_page: CandidatesFromPage,
    ) -> CollectedSources:
        
        index_url_sources = collections.OrderedDict(
            build_source(
                loc,
                candidates_from_page=candidates_from_page,
                page_validator=self.session.is_secure_origin,
                expand_dir=False,
                cache_link_parsing=False,
                project_name=project_name,
            )
            for loc in self.search_scope.get_index_urls_locations(project_name)
        ).values()
        find_links_sources = collections.OrderedDict(
            build_source(
                loc,
                candidates_from_page=candidates_from_page,
                page_validator=self.session.is_secure_origin,
                expand_dir=True,
                cache_link_parsing=True,
                project_name=project_name,
            )
            for loc in self.find_links
        ).values()

        if logger.isEnabledFor(logging.DEBUG):
            lines = [
                f""* {s.link}""
                for s in itertools.chain(find_links_sources, index_url_sources)
                if s is not None and s.link is not None
            ]
            lines = [
                f""{len(lines)} location(s) to search ""
                f""for versions of {project_name}:""
            ] + lines
            logger.debug(""\n"".join(lines))

        return CollectedSources(
            find_links=list(find_links_sources),
            index_urls=list(index_url_sources),
        )



from __future__ import annotations

import enum
import functools
import itertools
import logging
import re
from collections.abc import Iterable
from dataclasses import dataclass
from typing import (
    TYPE_CHECKING,
    Optional,
    Union,
)

from pip._vendor.packaging import specifiers
from pip._vendor.packaging.tags import Tag
from pip._vendor.packaging.utils import canonicalize_name
from pip._vendor.packaging.version import InvalidVersion, _BaseVersion
from pip._vendor.packaging.version import parse as parse_version

from pip._internal.exceptions import (
    BestVersionAlreadyInstalled,
    DistributionNotFound,
    InvalidWheelFilename,
    UnsupportedWheel,
)
from pip._internal.index.collector import LinkCollector, parse_links
from pip._internal.models.candidate import InstallationCandidate
from pip._internal.models.format_control import FormatControl
from pip._internal.models.link import Link
from pip._internal.models.search_scope import SearchScope
from pip._internal.models.selection_prefs import SelectionPreferences
from pip._internal.models.target_python import TargetPython
from pip._internal.models.wheel import Wheel
from pip._internal.req import InstallRequirement
from pip._internal.utils._log import getLogger
from pip._internal.utils.filetypes import WHEEL_EXTENSION
from pip._internal.utils.hashes import Hashes
from pip._internal.utils.logging import indent_log
from pip._internal.utils.misc import build_netloc
from pip._internal.utils.packaging import check_requires_python
from pip._internal.utils.unpacking import SUPPORTED_EXTENSIONS

if TYPE_CHECKING:
    from typing_extensions import TypeGuard

__all__ = [""FormatControl"", ""BestCandidateResult"", ""PackageFinder""]


logger = getLogger(__name__)

BuildTag = Union[tuple[()], tuple[int, str]]
CandidateSortingKey = tuple[int, int, int, _BaseVersion, Optional[int], BuildTag]


def _check_link_requires_python(
    link: Link,
    version_info: tuple[int, int, int],
    ignore_requires_python: bool = False,
) -> bool:
    
    try:
        is_compatible = check_requires_python(
            link.requires_python,
            version_info=version_info,
        )
    except specifiers.InvalidSpecifier:
        logger.debug(
            ""Ignoring invalid Requires-Python (%r) for link: %s"",
            link.requires_python,
            link,
        )
    else:
        if not is_compatible:
            version = ""."".join(map(str, version_info))
            if not ignore_requires_python:
                logger.verbose(
                    ""Link requires a different Python (%s not in: %r): %s"",
                    version,
                    link.requires_python,
                    link,
                )
                return False

            logger.debug(
                ""Ignoring failed Requires-Python check (%s not in: %r) for link: %s"",
                version,
                link.requires_python,
                link,
            )

    return True


class LinkType(enum.Enum):
    candidate = enum.auto()
    different_project = enum.auto()
    yanked = enum.auto()
    format_unsupported = enum.auto()
    format_invalid = enum.auto()
    platform_mismatch = enum.auto()
    requires_python_mismatch = enum.auto()


class LinkEvaluator:
    

    _py_version_re = re.compile(r""-py([123]\.?[0-9]?)$"")

    
    
    
    
    def __init__(
        self,
        project_name: str,
        canonical_name: str,
        formats: frozenset[str],
        target_python: TargetPython,
        allow_yanked: bool,
        ignore_requires_python: bool | None = None,
    ) -> None:
        
        if ignore_requires_python is None:
            ignore_requires_python = False

        self._allow_yanked = allow_yanked
        self._canonical_name = canonical_name
        self._ignore_requires_python = ignore_requires_python
        self._formats = formats
        self._target_python = target_python

        self.project_name = project_name

    def evaluate_link(self, link: Link) -> tuple[LinkType, str]:
        
        version = None
        if link.is_yanked and not self._allow_yanked:
            reason = link.yanked_reason or ""<none given>""
            return (LinkType.yanked, f""yanked for reason: {reason}"")

        if link.egg_fragment:
            egg_info = link.egg_fragment
            ext = link.ext
        else:
            egg_info, ext = link.splitext()
            if not ext:
                return (LinkType.format_unsupported, ""not a file"")
            if ext not in SUPPORTED_EXTENSIONS:
                return (
                    LinkType.format_unsupported,
                    f""unsupported archive format: {ext}"",
                )
            if ""binary"" not in self._formats and ext == WHEEL_EXTENSION:
                reason = f""No binaries permitted for {self.project_name}""
                return (LinkType.format_unsupported, reason)
            if ""macosx10"" in link.path and ext == "".zip"":
                return (LinkType.format_unsupported, ""macosx10 one"")
            if ext == WHEEL_EXTENSION:
                try:
                    wheel = Wheel(link.filename)
                except InvalidWheelFilename:
                    return (
                        LinkType.format_invalid,
                        ""invalid wheel filename"",
                    )
                if canonicalize_name(wheel.name) != self._canonical_name:
                    reason = f""wrong project name (not {self.project_name})""
                    return (LinkType.different_project, reason)

                supported_tags = self._target_python.get_unsorted_tags()
                if not wheel.supported(supported_tags):
                    
                    
                    file_tags = "", "".join(wheel.get_formatted_file_tags())
                    reason = (
                        f""none of the wheel's tags ({file_tags}) are compatible ""
                        f""(run pip debug --verbose to show compatible tags)""
                    )
                    return (LinkType.platform_mismatch, reason)

                version = wheel.version

        
        if ""source"" not in self._formats and ext != WHEEL_EXTENSION:
            reason = f""No sources permitted for {self.project_name}""
            return (LinkType.format_unsupported, reason)

        if not version:
            version = _extract_version_from_fragment(
                egg_info,
                self._canonical_name,
            )
        if not version:
            reason = f""Missing project version for {self.project_name}""
            return (LinkType.format_invalid, reason)

        match = self._py_version_re.search(version)
        if match:
            version = version[: match.start()]
            py_version = match.group(1)
            if py_version != self._target_python.py_version:
                return (
                    LinkType.platform_mismatch,
                    ""Python version is incorrect"",
                )

        supports_python = _check_link_requires_python(
            link,
            version_info=self._target_python.py_version_info,
            ignore_requires_python=self._ignore_requires_python,
        )
        if not supports_python:
            requires_python = link.requires_python
            if requires_python:

                def get_version_sort_key(v: str) -> tuple[int, ...]:
                    return tuple(int(s) for s in v.split(""."") if s.isdigit())

                requires_python = "","".join(
                    sorted(
                        (str(s) for s in specifiers.SpecifierSet(requires_python)),
                        key=get_version_sort_key,
                    )
                )
            reason = f""{version} Requires-Python {requires_python}""
            return (LinkType.requires_python_mismatch, reason)

        logger.debug(""Found link %s, version: %s"", link, version)

        return (LinkType.candidate, version)


def filter_unallowed_hashes(
    candidates: list[InstallationCandidate],
    hashes: Hashes | None,
    project_name: str,
) -> list[InstallationCandidate]:
    
    if not hashes:
        logger.debug(
            ""Given no hashes to check %s links for project %r: ""
            ""discarding no candidates"",
            len(candidates),
            project_name,
        )
        
        return list(candidates)

    matches_or_no_digest = []
    
    non_matches = []
    match_count = 0
    for candidate in candidates:
        link = candidate.link
        if not link.has_hash:
            pass
        elif link.is_hash_allowed(hashes=hashes):
            match_count += 1
        else:
            non_matches.append(candidate)
            continue

        matches_or_no_digest.append(candidate)

    if match_count:
        filtered = matches_or_no_digest
    else:
        
        filtered = list(candidates)

    if len(filtered) == len(candidates):
        discard_message = ""discarding no candidates""
    else:
        discard_message = ""discarding {} non-matches:\n  {}"".format(
            len(non_matches),
            ""\n  "".join(str(candidate.link) for candidate in non_matches),
        )

    logger.debug(
        ""Checked %s links for project %r against %s hashes ""
        ""(%s matches, %s no digest): %s"",
        len(candidates),
        project_name,
        hashes.digest_count,
        match_count,
        len(matches_or_no_digest) - match_count,
        discard_message,
    )

    return filtered


@dataclass
class CandidatePreferences:
    

    prefer_binary: bool = False
    allow_all_prereleases: bool = False


@dataclass(frozen=True)
class BestCandidateResult:
    

    all_candidates: list[InstallationCandidate]
    applicable_candidates: list[InstallationCandidate]
    best_candidate: InstallationCandidate | None

    def __post_init__(self) -> None:
        assert set(self.applicable_candidates) <= set(self.all_candidates)

        if self.best_candidate is None:
            assert not self.applicable_candidates
        else:
            assert self.best_candidate in self.applicable_candidates


class CandidateEvaluator:
    

    @classmethod
    def create(
        cls,
        project_name: str,
        target_python: TargetPython | None = None,
        prefer_binary: bool = False,
        allow_all_prereleases: bool = False,
        specifier: specifiers.BaseSpecifier | None = None,
        hashes: Hashes | None = None,
    ) -> CandidateEvaluator:
        
        if target_python is None:
            target_python = TargetPython()
        if specifier is None:
            specifier = specifiers.SpecifierSet()

        supported_tags = target_python.get_sorted_tags()

        return cls(
            project_name=project_name,
            supported_tags=supported_tags,
            specifier=specifier,
            prefer_binary=prefer_binary,
            allow_all_prereleases=allow_all_prereleases,
            hashes=hashes,
        )

    def __init__(
        self,
        project_name: str,
        supported_tags: list[Tag],
        specifier: specifiers.BaseSpecifier,
        prefer_binary: bool = False,
        allow_all_prereleases: bool = False,
        hashes: Hashes | None = None,
    ) -> None:
        
        self._allow_all_prereleases = allow_all_prereleases
        self._hashes = hashes
        self._prefer_binary = prefer_binary
        self._project_name = project_name
        self._specifier = specifier
        self._supported_tags = supported_tags
        
        
        
        self._wheel_tag_preferences = {
            tag: idx for idx, tag in enumerate(supported_tags)
        }

    def get_applicable_candidates(
        self,
        candidates: list[InstallationCandidate],
    ) -> list[InstallationCandidate]:
        
        
        allow_prereleases = self._allow_all_prereleases or None
        specifier = self._specifier

        
        
        
        
        
        
        
        candidates_and_versions = [(c, str(c.version)) for c in candidates]
        versions = set(
            specifier.filter(
                (v for _, v in candidates_and_versions),
                prereleases=allow_prereleases,
            )
        )

        applicable_candidates = [c for c, v in candidates_and_versions if v in versions]
        filtered_applicable_candidates = filter_unallowed_hashes(
            candidates=applicable_candidates,
            hashes=self._hashes,
            project_name=self._project_name,
        )

        return sorted(filtered_applicable_candidates, key=self._sort_key)

    def _sort_key(self, candidate: InstallationCandidate) -> CandidateSortingKey:
        
        valid_tags = self._supported_tags
        support_num = len(valid_tags)
        build_tag: BuildTag = ()
        binary_preference = 0
        link = candidate.link
        if link.is_wheel:
            
            wheel = Wheel(link.filename)
            try:
                pri = -(
                    wheel.find_most_preferred_tag(
                        valid_tags, self._wheel_tag_preferences
                    )
                )
            except ValueError:
                raise UnsupportedWheel(
                    f""{wheel.filename} is not a supported wheel for this platform. It ""
                    ""can't be sorted.""
                )
            if self._prefer_binary:
                binary_preference = 1
            build_tag = wheel.build_tag
        else:  
            pri = -(support_num)
        has_allowed_hash = int(link.is_hash_allowed(self._hashes))
        yank_value = -1 * int(link.is_yanked)  
        return (
            has_allowed_hash,
            yank_value,
            binary_preference,
            candidate.version,
            pri,
            build_tag,
        )

    def sort_best_candidate(
        self,
        candidates: list[InstallationCandidate],
    ) -> InstallationCandidate | None:
        
        if not candidates:
            return None
        best_candidate = max(candidates, key=self._sort_key)
        return best_candidate

    def compute_best_candidate(
        self,
        candidates: list[InstallationCandidate],
    ) -> BestCandidateResult:
        
        applicable_candidates = self.get_applicable_candidates(candidates)

        best_candidate = self.sort_best_candidate(applicable_candidates)

        return BestCandidateResult(
            candidates,
            applicable_candidates=applicable_candidates,
            best_candidate=best_candidate,
        )


class PackageFinder:
    

    def __init__(
        self,
        link_collector: LinkCollector,
        target_python: TargetPython,
        allow_yanked: bool,
        format_control: FormatControl | None = None,
        candidate_prefs: CandidatePreferences | None = None,
        ignore_requires_python: bool | None = None,
    ) -> None:
        
        if candidate_prefs is None:
            candidate_prefs = CandidatePreferences()

        format_control = format_control or FormatControl(set(), set())

        self._allow_yanked = allow_yanked
        self._candidate_prefs = candidate_prefs
        self._ignore_requires_python = ignore_requires_python
        self._link_collector = link_collector
        self._target_python = target_python

        self.format_control = format_control

        
        self._logged_links: set[tuple[Link, LinkType, str]] = set()

        
        self._all_candidates: dict[str, list[InstallationCandidate]] = {}
        self._best_candidates: dict[
            tuple[str, specifiers.BaseSpecifier | None, Hashes | None],
            BestCandidateResult,
        ] = {}

    
    
    
    
    @classmethod
    def create(
        cls,
        link_collector: LinkCollector,
        selection_prefs: SelectionPreferences,
        target_python: TargetPython | None = None,
    ) -> PackageFinder:
        
        if target_python is None:
            target_python = TargetPython()

        candidate_prefs = CandidatePreferences(
            prefer_binary=selection_prefs.prefer_binary,
            allow_all_prereleases=selection_prefs.allow_all_prereleases,
        )

        return cls(
            candidate_prefs=candidate_prefs,
            link_collector=link_collector,
            target_python=target_python,
            allow_yanked=selection_prefs.allow_yanked,
            format_control=selection_prefs.format_control,
            ignore_requires_python=selection_prefs.ignore_requires_python,
        )

    @property
    def target_python(self) -> TargetPython:
        return self._target_python

    @property
    def search_scope(self) -> SearchScope:
        return self._link_collector.search_scope

    @search_scope.setter
    def search_scope(self, search_scope: SearchScope) -> None:
        self._link_collector.search_scope = search_scope

    @property
    def find_links(self) -> list[str]:
        return self._link_collector.find_links

    @property
    def index_urls(self) -> list[str]:
        return self.search_scope.index_urls

    @property
    def proxy(self) -> str | None:
        return self._link_collector.session.pip_proxy

    @property
    def trusted_hosts(self) -> Iterable[str]:
        for host_port in self._link_collector.session.pip_trusted_origins:
            yield build_netloc(*host_port)

    @property
    def custom_cert(self) -> str | None:
        
        
        
        verify = self._link_collector.session.verify
        return verify if isinstance(verify, str) else None

    @property
    def client_cert(self) -> str | None:
        cert = self._link_collector.session.cert
        assert not isinstance(cert, tuple), ""pip only supports PEM client certs""
        return cert

    @property
    def allow_all_prereleases(self) -> bool:
        return self._candidate_prefs.allow_all_prereleases

    def set_allow_all_prereleases(self) -> None:
        self._candidate_prefs.allow_all_prereleases = True

    @property
    def prefer_binary(self) -> bool:
        return self._candidate_prefs.prefer_binary

    def set_prefer_binary(self) -> None:
        self._candidate_prefs.prefer_binary = True

    def requires_python_skipped_reasons(self) -> list[str]:
        reasons = {
            detail
            for _, result, detail in self._logged_links
            if result == LinkType.requires_python_mismatch
        }
        return sorted(reasons)

    def make_link_evaluator(self, project_name: str) -> LinkEvaluator:
        canonical_name = canonicalize_name(project_name)
        formats = self.format_control.get_allowed_formats(canonical_name)

        return LinkEvaluator(
            project_name=project_name,
            canonical_name=canonical_name,
            formats=formats,
            target_python=self._target_python,
            allow_yanked=self._allow_yanked,
            ignore_requires_python=self._ignore_requires_python,
        )

    def _sort_links(self, links: Iterable[Link]) -> list[Link]:
        
        eggs, no_eggs = [], []
        seen: set[Link] = set()
        for link in links:
            if link not in seen:
                seen.add(link)
                if link.egg_fragment:
                    eggs.append(link)
                else:
                    no_eggs.append(link)
        return no_eggs + eggs

    def _log_skipped_link(self, link: Link, result: LinkType, detail: str) -> None:
        entry = (link, result, detail)
        if entry not in self._logged_links:
            
            
            logger.debug(""Skipping link: %s: %s"", detail, link)
            self._logged_links.add(entry)

    def get_install_candidate(
        self, link_evaluator: LinkEvaluator, link: Link
    ) -> InstallationCandidate | None:
        
        result, detail = link_evaluator.evaluate_link(link)
        if result != LinkType.candidate:
            self._log_skipped_link(link, result, detail)
            return None

        try:
            return InstallationCandidate(
                name=link_evaluator.project_name,
                link=link,
                version=detail,
            )
        except InvalidVersion:
            return None

    def evaluate_links(
        self, link_evaluator: LinkEvaluator, links: Iterable[Link]
    ) -> list[InstallationCandidate]:
        
        candidates = []
        for link in self._sort_links(links):
            candidate = self.get_install_candidate(link_evaluator, link)
            if candidate is not None:
                candidates.append(candidate)

        return candidates

    def process_project_url(
        self, project_url: Link, link_evaluator: LinkEvaluator
    ) -> list[InstallationCandidate]:
        logger.debug(
            ""Fetching project page and analyzing links: %s"",
            project_url,
        )
        index_response = self._link_collector.fetch_response(project_url)
        if index_response is None:
            return []

        page_links = list(parse_links(index_response))

        with indent_log():
            package_links = self.evaluate_links(
                link_evaluator,
                links=page_links,
            )

        return package_links

    def find_all_candidates(self, project_name: str) -> list[InstallationCandidate]:
        
        if project_name in self._all_candidates:
            return self._all_candidates[project_name]

        link_evaluator = self.make_link_evaluator(project_name)

        collected_sources = self._link_collector.collect_sources(
            project_name=project_name,
            candidates_from_page=functools.partial(
                self.process_project_url,
                link_evaluator=link_evaluator,
            ),
        )

        page_candidates_it = itertools.chain.from_iterable(
            source.page_candidates()
            for sources in collected_sources
            for source in sources
            if source is not None
        )
        page_candidates = list(page_candidates_it)

        file_links_it = itertools.chain.from_iterable(
            source.file_links()
            for sources in collected_sources
            for source in sources
            if source is not None
        )
        file_candidates = self.evaluate_links(
            link_evaluator,
            sorted(file_links_it, reverse=True),
        )

        if logger.isEnabledFor(logging.DEBUG) and file_candidates:
            paths = []
            for candidate in file_candidates:
                assert candidate.link.url  
                try:
                    paths.append(candidate.link.file_path)
                except Exception:
                    paths.append(candidate.link.url)  

            logger.debug(""Local files found: %s"", "", "".join(paths))

        
        self._all_candidates[project_name] = file_candidates + page_candidates

        return self._all_candidates[project_name]

    def make_candidate_evaluator(
        self,
        project_name: str,
        specifier: specifiers.BaseSpecifier | None = None,
        hashes: Hashes | None = None,
    ) -> CandidateEvaluator:
        
        candidate_prefs = self._candidate_prefs
        return CandidateEvaluator.create(
            project_name=project_name,
            target_python=self._target_python,
            prefer_binary=candidate_prefs.prefer_binary,
            allow_all_prereleases=candidate_prefs.allow_all_prereleases,
            specifier=specifier,
            hashes=hashes,
        )

    def find_best_candidate(
        self,
        project_name: str,
        specifier: specifiers.BaseSpecifier | None = None,
        hashes: Hashes | None = None,
    ) -> BestCandidateResult:
        
        if (project_name, specifier, hashes) in self._best_candidates:
            return self._best_candidates[project_name, specifier, hashes]

        candidates = self.find_all_candidates(project_name)
        candidate_evaluator = self.make_candidate_evaluator(
            project_name=project_name,
            specifier=specifier,
            hashes=hashes,
        )
        self._best_candidates[project_name, specifier, hashes] = (
            candidate_evaluator.compute_best_candidate(candidates)
        )

        return self._best_candidates[project_name, specifier, hashes]

    def find_requirement(
        self, req: InstallRequirement, upgrade: bool
    ) -> InstallationCandidate | None:
        
        name = req.name
        assert name is not None, ""find_requirement() called with no name""

        hashes = req.hashes(trust_internet=False)
        best_candidate_result = self.find_best_candidate(
            name,
            specifier=req.specifier,
            hashes=hashes,
        )
        best_candidate = best_candidate_result.best_candidate

        installed_version: _BaseVersion | None = None
        if req.satisfied_by is not None:
            installed_version = req.satisfied_by.version

        def _format_versions(cand_iter: Iterable[InstallationCandidate]) -> str:
            
            
            
            
            return (
                "", "".join(
                    sorted(
                        {str(c.version) for c in cand_iter},
                        key=parse_version,
                    )
                )
                or ""none""
            )

        if installed_version is None and best_candidate is None:
            logger.critical(
                ""Could not find a version that satisfies the requirement %s ""
                ""(from versions: %s)"",
                req,
                _format_versions(best_candidate_result.all_candidates),
            )

            raise DistributionNotFound(f""No matching distribution found for {req}"")

        def _should_install_candidate(
            candidate: InstallationCandidate | None,
        ) -> TypeGuard[InstallationCandidate]:
            if installed_version is None:
                return True
            if best_candidate is None:
                return False
            return best_candidate.version > installed_version

        if not upgrade and installed_version is not None:
            if _should_install_candidate(best_candidate):
                logger.debug(
                    ""Existing installed version (%s) satisfies requirement ""
                    ""(most up-to-date version is %s)"",
                    installed_version,
                    best_candidate.version,
                )
            else:
                logger.debug(
                    ""Existing installed version (%s) is most up-to-date and ""
                    ""satisfies requirement"",
                    installed_version,
                )
            return None

        if _should_install_candidate(best_candidate):
            logger.debug(
                ""Using version %s (newest of versions: %s)"",
                best_candidate.version,
                _format_versions(best_candidate_result.applicable_candidates),
            )
            return best_candidate

        
        logger.debug(
            ""Installed version (%s) is most up-to-date (past versions: %s)"",
            installed_version,
            _format_versions(best_candidate_result.applicable_candidates),
        )
        raise BestVersionAlreadyInstalled


def _find_name_version_sep(fragment: str, canonical_name: str) -> int:
    
    
    
    
    for i, c in enumerate(fragment):
        if c != ""-"":
            continue
        if canonicalize_name(fragment[:i]) == canonical_name:
            return i
    raise ValueError(f""{fragment} does not match {canonical_name}"")


def _extract_version_from_fragment(fragment: str, canonical_name: str) -> str | None:
    
    try:
        version_start = _find_name_version_sep(fragment, canonical_name) + 1
    except ValueError:
        return None
    version = fragment[version_start:]
    if not version:
        return None
    return version

from __future__ import annotations

import logging
import mimetypes
import os
from collections import defaultdict
from collections.abc import Iterable
from typing import Callable

from pip._vendor.packaging.utils import (
    InvalidSdistFilename,
    InvalidWheelFilename,
    canonicalize_name,
    parse_sdist_filename,
    parse_wheel_filename,
)

from pip._internal.models.candidate import InstallationCandidate
from pip._internal.models.link import Link
from pip._internal.utils.urls import path_to_url, url_to_path
from pip._internal.vcs import is_url

logger = logging.getLogger(__name__)

FoundCandidates = Iterable[InstallationCandidate]
FoundLinks = Iterable[Link]
CandidatesFromPage = Callable[[Link], Iterable[InstallationCandidate]]
PageValidator = Callable[[Link], bool]


class LinkSource:
    @property
    def link(self) -> Link | None:
        
        raise NotImplementedError()

    def page_candidates(self) -> FoundCandidates:
        
        raise NotImplementedError()

    def file_links(self) -> FoundLinks:
        
        raise NotImplementedError()


def _is_html_file(file_url: str) -> bool:
    return mimetypes.guess_type(file_url, strict=False)[0] == ""text/html""


class _FlatDirectoryToUrls:
    

    def __init__(self, path: str) -> None:
        self._path = path
        self._page_candidates: list[str] = []
        self._project_name_to_urls: dict[str, list[str]] = defaultdict(list)
        self._scanned_directory = False

    def _scan_directory(self) -> None:
        
        for entry in os.scandir(self._path):
            url = path_to_url(entry.path)
            if _is_html_file(url):
                self._page_candidates.append(url)
                continue

            
            
            try:
                project_filename = parse_wheel_filename(entry.name)[0]
            except InvalidWheelFilename:
                try:
                    project_filename = parse_sdist_filename(entry.name)[0]
                except InvalidSdistFilename:
                    continue

            self._project_name_to_urls[project_filename].append(url)
        self._scanned_directory = True

    @property
    def page_candidates(self) -> list[str]:
        if not self._scanned_directory:
            self._scan_directory()

        return self._page_candidates

    @property
    def project_name_to_urls(self) -> dict[str, list[str]]:
        if not self._scanned_directory:
            self._scan_directory()

        return self._project_name_to_urls


class _FlatDirectorySource(LinkSource):
    

    _paths_to_urls: dict[str, _FlatDirectoryToUrls] = {}

    def __init__(
        self,
        candidates_from_page: CandidatesFromPage,
        path: str,
        project_name: str,
    ) -> None:
        self._candidates_from_page = candidates_from_page
        self._project_name = canonicalize_name(project_name)

        
        if path in self._paths_to_urls:
            self._path_to_urls = self._paths_to_urls[path]
        else:
            self._path_to_urls = _FlatDirectoryToUrls(path=path)
            self._paths_to_urls[path] = self._path_to_urls

    @property
    def link(self) -> Link | None:
        return None

    def page_candidates(self) -> FoundCandidates:
        for url in self._path_to_urls.page_candidates:
            yield from self._candidates_from_page(Link(url))

    def file_links(self) -> FoundLinks:
        for url in self._path_to_urls.project_name_to_urls[self._project_name]:
            yield Link(url)


class _LocalFileSource(LinkSource):
    

    def __init__(
        self,
        candidates_from_page: CandidatesFromPage,
        link: Link,
    ) -> None:
        self._candidates_from_page = candidates_from_page
        self._link = link

    @property
    def link(self) -> Link | None:
        return self._link

    def page_candidates(self) -> FoundCandidates:
        if not _is_html_file(self._link.url):
            return
        yield from self._candidates_from_page(self._link)

    def file_links(self) -> FoundLinks:
        if _is_html_file(self._link.url):
            return
        yield self._link


class _RemoteFileSource(LinkSource):
    

    def __init__(
        self,
        candidates_from_page: CandidatesFromPage,
        page_validator: PageValidator,
        link: Link,
    ) -> None:
        self._candidates_from_page = candidates_from_page
        self._page_validator = page_validator
        self._link = link

    @property
    def link(self) -> Link | None:
        return self._link

    def page_candidates(self) -> FoundCandidates:
        if not self._page_validator(self._link):
            return
        yield from self._candidates_from_page(self._link)

    def file_links(self) -> FoundLinks:
        yield self._link


class _IndexDirectorySource(LinkSource):
    

    def __init__(
        self,
        candidates_from_page: CandidatesFromPage,
        link: Link,
    ) -> None:
        self._candidates_from_page = candidates_from_page
        self._link = link

    @property
    def link(self) -> Link | None:
        return self._link

    def page_candidates(self) -> FoundCandidates:
        yield from self._candidates_from_page(self._link)

    def file_links(self) -> FoundLinks:
        return ()


def build_source(
    location: str,
    *,
    candidates_from_page: CandidatesFromPage,
    page_validator: PageValidator,
    expand_dir: bool,
    cache_link_parsing: bool,
    project_name: str,
) -> tuple[str | None, LinkSource | None]:
    path: str | None = None
    url: str | None = None
    if os.path.exists(location):  
        url = path_to_url(location)
        path = location
    elif location.startswith(""file:""):  
        url = location
        path = url_to_path(location)
    elif is_url(location):
        url = location

    if url is None:
        msg = (
            ""Location '%s' is ignored: ""
            ""it is either a non-existing path or lacks a specific scheme.""
        )
        logger.warning(msg, location)
        return (None, None)

    if path is None:
        source: LinkSource = _RemoteFileSource(
            candidates_from_page=candidates_from_page,
            page_validator=page_validator,
            link=Link(url, cache_link_parsing=cache_link_parsing),
        )
        return (url, source)

    if os.path.isdir(path):
        if expand_dir:
            source = _FlatDirectorySource(
                candidates_from_page=candidates_from_page,
                path=path,
                project_name=project_name,
            )
        else:
            source = _IndexDirectorySource(
                candidates_from_page=candidates_from_page,
                link=Link(url, cache_link_parsing=cache_link_parsing),
            )
        return (url, source)
    elif os.path.isfile(path):
        source = _LocalFileSource(
            candidates_from_page=candidates_from_page,
            link=Link(url, cache_link_parsing=cache_link_parsing),
        )
        return (url, source)
    logger.warning(
        ""Location '%s' is ignored: it is neither a file nor a directory."",
        location,
    )
    return (url, None)



from __future__ import annotations

import functools
import os
import site
import sys
import sysconfig

from pip._internal.exceptions import InstallationError
from pip._internal.utils import appdirs
from pip._internal.utils.virtualenv import running_under_virtualenv


USER_CACHE_DIR = appdirs.user_cache_dir(""pip"")


site_packages: str = sysconfig.get_path(""purelib"")


def get_major_minor_version() -> str:
    
    return ""{}.{}"".format(*sys.version_info)


def change_root(new_root: str, pathname: str) -> str:
    
    if os.name == ""posix"":
        if not os.path.isabs(pathname):
            return os.path.join(new_root, pathname)
        else:
            return os.path.join(new_root, pathname[1:])

    elif os.name == ""nt"":
        (drive, path) = os.path.splitdrive(pathname)
        if path[0] == ""\\"":
            path = path[1:]
        return os.path.join(new_root, path)

    else:
        raise InstallationError(
            f""Unknown platform: {os.name}\n""
            ""Can not change root path prefix on unknown platform.""
        )


def get_src_prefix() -> str:
    if running_under_virtualenv():
        src_prefix = os.path.join(sys.prefix, ""src"")
    else:
        
        try:
            src_prefix = os.path.join(os.getcwd(), ""src"")
        except OSError:
            
            sys.exit(""The folder you are executing pip from can no longer be found."")

    
    
    return os.path.abspath(src_prefix)


try:
    
    
    user_site: str | None = site.getusersitepackages()
except AttributeError:
    user_site = site.USER_SITE


@functools.cache
def is_osx_framework() -> bool:
    return bool(sysconfig.get_config_var(""PYTHONFRAMEWORK""))












from __future__ import annotations

try:
    __import__(""_distutils_hack"").remove_shim()
except (ImportError, AttributeError):
    pass

import logging
import os
import sys
from distutils.cmd import Command as DistutilsCommand
from distutils.command.install import SCHEME_KEYS
from distutils.command.install import install as distutils_install_command
from distutils.sysconfig import get_python_lib

from pip._internal.models.scheme import Scheme
from pip._internal.utils.compat import WINDOWS
from pip._internal.utils.virtualenv import running_under_virtualenv

from .base import get_major_minor_version

logger = logging.getLogger(__name__)


def distutils_scheme(
    dist_name: str,
    user: bool = False,
    home: str | None = None,
    root: str | None = None,
    isolated: bool = False,
    prefix: str | None = None,
    *,
    ignore_config_files: bool = False,
) -> dict[str, str]:
    
    from distutils.dist import Distribution

    dist_args: dict[str, str | list[str]] = {""name"": dist_name}
    if isolated:
        dist_args[""script_args""] = [""--no-user-cfg""]

    d = Distribution(dist_args)
    if not ignore_config_files:
        try:
            d.parse_config_files()
        except UnicodeDecodeError:
            paths = d.find_config_files()
            logger.warning(
                ""Ignore distutils configs in %s due to encoding errors."",
                "", "".join(os.path.basename(p) for p in paths),
            )
    obj: DistutilsCommand | None = None
    obj = d.get_command_obj(""install"", create=True)
    assert obj is not None
    i: distutils_install_command = obj
    
    
    
    assert not (user and prefix), f""user={user} prefix={prefix}""
    assert not (home and prefix), f""home={home} prefix={prefix}""
    i.user = user or i.user
    if user or home:
        i.prefix = """"
    i.prefix = prefix or i.prefix
    i.home = home or i.home
    i.root = root or i.root
    i.finalize_options()

    scheme: dict[str, str] = {}
    for key in SCHEME_KEYS:
        scheme[key] = getattr(i, ""install_"" + key)

    
    
    
    
    
    if ""install_lib"" in d.get_option_dict(""install""):
        scheme.update({""purelib"": i.install_lib, ""platlib"": i.install_lib})

    if running_under_virtualenv():
        if home:
            prefix = home
        elif user:
            prefix = i.install_userbase
        else:
            prefix = i.prefix
        scheme[""headers""] = os.path.join(
            prefix,
            ""include"",
            ""site"",
            f""python{get_major_minor_version()}"",
            dist_name,
        )

        if root is not None:
            path_no_drive = os.path.splitdrive(os.path.abspath(scheme[""headers""]))[1]
            scheme[""headers""] = os.path.join(root, path_no_drive[1:])

    return scheme


def get_scheme(
    dist_name: str,
    user: bool = False,
    home: str | None = None,
    root: str | None = None,
    isolated: bool = False,
    prefix: str | None = None,
) -> Scheme:
    
    scheme = distutils_scheme(dist_name, user, home, root, isolated, prefix)
    return Scheme(
        platlib=scheme[""platlib""],
        purelib=scheme[""purelib""],
        headers=scheme[""headers""],
        scripts=scheme[""scripts""],
        data=scheme[""data""],
    )


def get_bin_prefix() -> str:
    
    
    prefix = os.path.normpath(sys.prefix)
    if WINDOWS:
        bin_py = os.path.join(prefix, ""Scripts"")
        
        if not os.path.exists(bin_py):
            bin_py = os.path.join(prefix, ""bin"")
        return bin_py
    
    
    if sys.platform[:6] == ""darwin"" and prefix[:16] == ""/System/Library/"":
        return ""/usr/local/bin""
    return os.path.join(prefix, ""bin"")


def get_purelib() -> str:
    return get_python_lib(plat_specific=False)


def get_platlib() -> str:
    return get_python_lib(plat_specific=True)

from __future__ import annotations

import logging
import os
import sys
import sysconfig

from pip._internal.exceptions import InvalidSchemeCombination, UserInstallationInvalid
from pip._internal.models.scheme import SCHEME_KEYS, Scheme
from pip._internal.utils.virtualenv import running_under_virtualenv

from .base import change_root, get_major_minor_version, is_osx_framework

logger = logging.getLogger(__name__)










_AVAILABLE_SCHEMES = set(sysconfig.get_scheme_names())

_PREFERRED_SCHEME_API = getattr(sysconfig, ""get_preferred_scheme"", None)


def _should_use_osx_framework_prefix() -> bool:
    
    return (
        ""osx_framework_library"" in _AVAILABLE_SCHEMES
        and not running_under_virtualenv()
        and is_osx_framework()
    )


def _infer_prefix() -> str:
    
    if _PREFERRED_SCHEME_API:
        return _PREFERRED_SCHEME_API(""prefix"")
    if _should_use_osx_framework_prefix():
        return ""osx_framework_library""
    implementation_suffixed = f""{sys.implementation.name}_{os.name}""
    if implementation_suffixed in _AVAILABLE_SCHEMES:
        return implementation_suffixed
    if sys.implementation.name in _AVAILABLE_SCHEMES:
        return sys.implementation.name
    suffixed = f""{os.name}_prefix""
    if suffixed in _AVAILABLE_SCHEMES:
        return suffixed
    if os.name in _AVAILABLE_SCHEMES:  
        return os.name
    return ""posix_prefix""


def _infer_user() -> str:
    
    if _PREFERRED_SCHEME_API:
        return _PREFERRED_SCHEME_API(""user"")
    if is_osx_framework() and not running_under_virtualenv():
        suffixed = ""osx_framework_user""
    else:
        suffixed = f""{os.name}_user""
    if suffixed in _AVAILABLE_SCHEMES:
        return suffixed
    if ""posix_user"" not in _AVAILABLE_SCHEMES:  
        raise UserInstallationInvalid()
    return ""posix_user""


def _infer_home() -> str:
    
    if _PREFERRED_SCHEME_API:
        return _PREFERRED_SCHEME_API(""home"")
    suffixed = f""{os.name}_home""
    if suffixed in _AVAILABLE_SCHEMES:
        return suffixed
    return ""posix_home""



_HOME_KEYS = [
    ""installed_base"",
    ""base"",
    ""installed_platbase"",
    ""platbase"",
    ""prefix"",
    ""exec_prefix"",
]
if sysconfig.get_config_var(""userbase"") is not None:
    _HOME_KEYS.append(""userbase"")


def get_scheme(
    dist_name: str,
    user: bool = False,
    home: str | None = None,
    root: str | None = None,
    isolated: bool = False,
    prefix: str | None = None,
) -> Scheme:
    
    if user and prefix:
        raise InvalidSchemeCombination(""--user"", ""--prefix"")
    if home and prefix:
        raise InvalidSchemeCombination(""--home"", ""--prefix"")

    if home is not None:
        scheme_name = _infer_home()
    elif user:
        scheme_name = _infer_user()
    else:
        scheme_name = _infer_prefix()

    
    
    
    if prefix is not None and scheme_name == ""osx_framework_library"":
        scheme_name = ""posix_prefix""

    if home is not None:
        variables = {k: home for k in _HOME_KEYS}
    elif prefix is not None:
        variables = {k: prefix for k in _HOME_KEYS}
    else:
        variables = {}

    paths = sysconfig.get_paths(scheme=scheme_name, vars=variables)

    
    
    
    
    
    if running_under_virtualenv():
        if user:
            base = variables.get(""userbase"", sys.prefix)
        else:
            base = variables.get(""base"", sys.prefix)
        python_xy = f""python{get_major_minor_version()}""
        paths[""include""] = os.path.join(base, ""include"", ""site"", python_xy)
    elif not dist_name:
        dist_name = ""UNKNOWN""

    scheme = Scheme(
        platlib=paths[""platlib""],
        purelib=paths[""purelib""],
        headers=os.path.join(paths[""include""], dist_name),
        scripts=paths[""scripts""],
        data=paths[""data""],
    )
    if root is not None:
        converted_keys = {}
        for key in SCHEME_KEYS:
            converted_keys[key] = change_root(root, getattr(scheme, key))
        scheme = Scheme(**converted_keys)
    return scheme


def get_bin_prefix() -> str:
    
    if sys.platform[:6] == ""darwin"" and sys.prefix[:16] == ""/System/Library/"":
        return ""/usr/local/bin""
    return sysconfig.get_paths()[""scripts""]


def get_purelib() -> str:
    return sysconfig.get_paths()[""purelib""]


def get_platlib() -> str:
    return sysconfig.get_paths()[""platlib""]

from __future__ import annotations

import functools
import logging
import os
import pathlib
import sys
import sysconfig
from typing import Any

from pip._internal.models.scheme import SCHEME_KEYS, Scheme
from pip._internal.utils.compat import WINDOWS
from pip._internal.utils.deprecation import deprecated
from pip._internal.utils.virtualenv import running_under_virtualenv

from . import _sysconfig
from .base import (
    USER_CACHE_DIR,
    get_major_minor_version,
    get_src_prefix,
    is_osx_framework,
    site_packages,
    user_site,
)

__all__ = [
    ""USER_CACHE_DIR"",
    ""get_bin_prefix"",
    ""get_bin_user"",
    ""get_major_minor_version"",
    ""get_platlib"",
    ""get_purelib"",
    ""get_scheme"",
    ""get_src_prefix"",
    ""site_packages"",
    ""user_site"",
]


logger = logging.getLogger(__name__)


_PLATLIBDIR: str = getattr(sys, ""platlibdir"", ""lib"")

_USE_SYSCONFIG_DEFAULT = sys.version_info >= (3, 10)


def _should_use_sysconfig() -> bool:
    
    return bool(getattr(sysconfig, ""_PIP_USE_SYSCONFIG"", _USE_SYSCONFIG_DEFAULT))


_USE_SYSCONFIG = _should_use_sysconfig()

if not _USE_SYSCONFIG:
    
    
    
    from . import _distutils



if _USE_SYSCONFIG_DEFAULT and not _USE_SYSCONFIG:
    _MISMATCH_LEVEL = logging.WARNING
else:
    _MISMATCH_LEVEL = logging.DEBUG


def _looks_like_bpo_44860() -> bool:
    
    from distutils.command.install import INSTALL_SCHEMES

    try:
        unix_user_platlib = INSTALL_SCHEMES[""unix_user""][""platlib""]
    except KeyError:
        return False
    return unix_user_platlib == ""$usersite""


def _looks_like_red_hat_patched_platlib_purelib(scheme: dict[str, str]) -> bool:
    platlib = scheme[""platlib""]
    if ""/$platlibdir/"" in platlib:
        platlib = platlib.replace(""/$platlibdir/"", f""/{_PLATLIBDIR}/"")
    if ""/lib64/"" not in platlib:
        return False
    unpatched = platlib.replace(""/lib64/"", ""/lib/"")
    return unpatched.replace(""$platbase/"", ""$base/"") == scheme[""purelib""]


@functools.cache
def _looks_like_red_hat_lib() -> bool:
    
    from distutils.command.install import INSTALL_SCHEMES

    return all(
        k in INSTALL_SCHEMES
        and _looks_like_red_hat_patched_platlib_purelib(INSTALL_SCHEMES[k])
        for k in (""unix_prefix"", ""unix_home"")
    )


@functools.cache
def _looks_like_debian_scheme() -> bool:
    
    from distutils.command.install import INSTALL_SCHEMES

    return ""deb_system"" in INSTALL_SCHEMES and ""unix_local"" in INSTALL_SCHEMES


@functools.cache
def _looks_like_red_hat_scheme() -> bool:
    
    from distutils.command.install import install
    from distutils.dist import Distribution

    cmd: Any = install(Distribution())
    cmd.finalize_options()
    return (
        cmd.exec_prefix == f""{os.path.normpath(sys.exec_prefix)}/local""
        and cmd.prefix == f""{os.path.normpath(sys.prefix)}/local""
    )


@functools.cache
def _looks_like_slackware_scheme() -> bool:
    
    if user_site is None:  
        return False
    try:
        paths = sysconfig.get_paths(scheme=""posix_user"", expand=False)
    except KeyError:  
        return False
    return ""/lib64/"" in paths[""purelib""] and ""/lib64/"" not in user_site


@functools.cache
def _looks_like_msys2_mingw_scheme() -> bool:
    
    paths = sysconfig.get_paths(""nt"", expand=False)
    return all(
        ""Lib"" not in p and ""lib"" in p and not p.endswith(""site-packages"")
        for p in (paths[key] for key in (""platlib"", ""purelib""))
    )


@functools.cache
def _warn_mismatched(old: pathlib.Path, new: pathlib.Path, *, key: str) -> None:
    issue_url = ""https://github.com/pypa/pip/issues/10151""
    message = (
        ""Value for %s does not match. Please report this to <%s>""
        ""\ndistutils: %s""
        ""\nsysconfig: %s""
    )
    logger.log(_MISMATCH_LEVEL, message, key, issue_url, old, new)


def _warn_if_mismatch(old: pathlib.Path, new: pathlib.Path, *, key: str) -> bool:
    if old == new:
        return False
    _warn_mismatched(old, new, key=key)
    return True


@functools.cache
def _log_context(
    *,
    user: bool = False,
    home: str | None = None,
    root: str | None = None,
    prefix: str | None = None,
) -> None:
    parts = [
        ""Additional context:"",
        ""user = %r"",
        ""home = %r"",
        ""root = %r"",
        ""prefix = %r"",
    ]

    logger.log(_MISMATCH_LEVEL, ""\n"".join(parts), user, home, root, prefix)


def get_scheme(
    dist_name: str,
    user: bool = False,
    home: str | None = None,
    root: str | None = None,
    isolated: bool = False,
    prefix: str | None = None,
) -> Scheme:
    new = _sysconfig.get_scheme(
        dist_name,
        user=user,
        home=home,
        root=root,
        isolated=isolated,
        prefix=prefix,
    )
    if _USE_SYSCONFIG:
        return new

    old = _distutils.get_scheme(
        dist_name,
        user=user,
        home=home,
        root=root,
        isolated=isolated,
        prefix=prefix,
    )

    warning_contexts = []
    for k in SCHEME_KEYS:
        old_v = pathlib.Path(getattr(old, k))
        new_v = pathlib.Path(getattr(new, k))

        if old_v == new_v:
            continue

        
        
        
        
        skip_pypy_special_case = (
            sys.implementation.name == ""pypy""
            and home is not None
            and k in (""platlib"", ""purelib"")
            and old_v.parent == new_v.parent
            and old_v.name.startswith(""python"")
            and new_v.name.startswith(""pypy"")
        )
        if skip_pypy_special_case:
            continue

        
        
        
        skip_osx_framework_user_special_case = (
            user
            and is_osx_framework()
            and k == ""headers""
            and old_v.parent.parent == new_v.parent
            and old_v.parent.name.startswith(""python"")
        )
        if skip_osx_framework_user_special_case:
            continue

        
        
        if k == ""platlib"" and _looks_like_red_hat_lib():
            continue

        
        
        
        
        skip_bpo_44860 = (
            user
            and k == ""platlib""
            and not WINDOWS
            and _PLATLIBDIR != ""lib""
            and _looks_like_bpo_44860()
        )
        if skip_bpo_44860:
            continue

        
        
        skip_slackware_user_scheme = (
            user
            and k in (""platlib"", ""purelib"")
            and not WINDOWS
            and _looks_like_slackware_scheme()
        )
        if skip_slackware_user_scheme:
            continue

        
        
        
        skip_linux_system_special_case = (
            not (user or home or prefix or running_under_virtualenv())
            and old_v.parts[1:3] == (""usr"", ""local"")
            and len(new_v.parts) > 1
            and new_v.parts[1] == ""usr""
            and (len(new_v.parts) < 3 or new_v.parts[2] != ""local"")
            and (_looks_like_red_hat_scheme() or _looks_like_debian_scheme())
        )
        if skip_linux_system_special_case:
            continue

        
        
        skip_msys2_mingw_bug = (
            WINDOWS and k in (""platlib"", ""purelib"") and _looks_like_msys2_mingw_scheme()
        )
        if skip_msys2_mingw_bug:
            continue

        
        
        
        
        skip_cpython_build = (
            sysconfig.is_python_build(check_home=True)
            and not WINDOWS
            and k in (""headers"", ""include"", ""platinclude"")
        )
        if skip_cpython_build:
            continue

        warning_contexts.append((old_v, new_v, f""scheme.{k}""))

    if not warning_contexts:
        return old

    
    
    
    default_old = _distutils.distutils_scheme(
        dist_name,
        user,
        home,
        root,
        isolated,
        prefix,
        ignore_config_files=True,
    )
    if any(default_old[k] != getattr(old, k) for k in SCHEME_KEYS):
        deprecated(
            reason=(
                ""Configuring installation scheme with distutils config files ""
                ""is deprecated and will no longer work in the near future. If you ""
                ""are using a Homebrew or Linuxbrew Python, please see discussion ""
                ""at https://github.com/Homebrew/homebrew-core/issues/76621""
            ),
            replacement=None,
            gone_in=None,
        )
        return old

    
    for old_v, new_v, key in warning_contexts:
        _warn_mismatched(old_v, new_v, key=key)
    _log_context(user=user, home=home, root=root, prefix=prefix)

    return old


def get_bin_prefix() -> str:
    new = _sysconfig.get_bin_prefix()
    if _USE_SYSCONFIG:
        return new

    old = _distutils.get_bin_prefix()
    if _warn_if_mismatch(pathlib.Path(old), pathlib.Path(new), key=""bin_prefix""):
        _log_context()
    return old


def get_bin_user() -> str:
    return _sysconfig.get_scheme("""", user=True).scripts


def _looks_like_deb_system_dist_packages(value: str) -> bool:
    
    if not _looks_like_debian_scheme():
        return False
    if value == ""/usr/lib/python3/dist-packages"":
        return True
    return False


def get_purelib() -> str:
    
    new = _sysconfig.get_purelib()
    if _USE_SYSCONFIG:
        return new

    old = _distutils.get_purelib()
    if _looks_like_deb_system_dist_packages(old):
        return old
    if _warn_if_mismatch(pathlib.Path(old), pathlib.Path(new), key=""purelib""):
        _log_context()
    return old


def get_platlib() -> str:
    
    new = _sysconfig.get_platlib()
    if _USE_SYSCONFIG:
        return new

    from . import _distutils

    old = _distutils.get_platlib()
    if _looks_like_deb_system_dist_packages(old):
        return old
    if _warn_if_mismatch(pathlib.Path(old), pathlib.Path(new), key=""platlib""):
        _log_context()
    return old

from __future__ import annotations

import csv
import email.message
import functools
import json
import logging
import pathlib
import re
import zipfile
from collections.abc import Collection, Container, Iterable, Iterator
from typing import (
    IO,
    Any,
    NamedTuple,
    Protocol,
    Union,
)

from pip._vendor.packaging.requirements import Requirement
from pip._vendor.packaging.specifiers import InvalidSpecifier, SpecifierSet
from pip._vendor.packaging.utils import NormalizedName, canonicalize_name
from pip._vendor.packaging.version import Version

from pip._internal.exceptions import NoneMetadataError
from pip._internal.locations import site_packages, user_site
from pip._internal.models.direct_url import (
    DIRECT_URL_METADATA_NAME,
    DirectUrl,
    DirectUrlValidationError,
)
from pip._internal.utils.compat import stdlib_pkgs  
from pip._internal.utils.egg_link import egg_link_path_from_sys_path
from pip._internal.utils.misc import is_local, normalize_path
from pip._internal.utils.urls import url_to_path

from ._json import msg_to_json

InfoPath = Union[str, pathlib.PurePath]

logger = logging.getLogger(__name__)


class BaseEntryPoint(Protocol):
    @property
    def name(self) -> str:
        raise NotImplementedError()

    @property
    def value(self) -> str:
        raise NotImplementedError()

    @property
    def group(self) -> str:
        raise NotImplementedError()


def _convert_installed_files_path(
    entry: tuple[str, ...],
    info: tuple[str, ...],
) -> str:
    
    while entry and entry[0] == "".."":
        if not info or info[-1] == "".."":
            info += ("".."",)
        else:
            info = info[:-1]
        entry = entry[1:]
    return str(pathlib.Path(*info, *entry))


class RequiresEntry(NamedTuple):
    requirement: str
    extra: str
    marker: str


class BaseDistribution(Protocol):
    @classmethod
    def from_directory(cls, directory: str) -> BaseDistribution:
        
        raise NotImplementedError()

    @classmethod
    def from_metadata_file_contents(
        cls,
        metadata_contents: bytes,
        filename: str,
        project_name: str,
    ) -> BaseDistribution:
        
        raise NotImplementedError()

    @classmethod
    def from_wheel(cls, wheel: Wheel, name: str) -> BaseDistribution:
        
        raise NotImplementedError()

    def __repr__(self) -> str:
        return f""{self.raw_name} {self.raw_version} ({self.location})""

    def __str__(self) -> str:
        return f""{self.raw_name} {self.raw_version}""

    @property
    def location(self) -> str | None:
        
        raise NotImplementedError()

    @property
    def editable_project_location(self) -> str | None:
        
        
        direct_url = self.direct_url
        if direct_url:
            if direct_url.is_local_editable():
                return url_to_path(direct_url.url)
        else:
            
            
            egg_link_path = egg_link_path_from_sys_path(self.raw_name)
            if egg_link_path:
                
                
                return self.location
        return None

    @property
    def installed_location(self) -> str | None:
        
        raise NotImplementedError()

    @property
    def info_location(self) -> str | None:
        
        raise NotImplementedError()

    @property
    def installed_by_distutils(self) -> bool:
        
        info_location = self.info_location
        if not info_location:
            return False
        return pathlib.Path(info_location).is_file()

    @property
    def installed_as_egg(self) -> bool:
        
        location = self.location
        if not location:
            return False
        
        
        return pathlib.Path(location).suffix == "".egg""

    @property
    def installed_with_setuptools_egg_info(self) -> bool:
        
        info_location = self.info_location
        if not info_location:
            return False
        if not info_location.endswith("".egg-info""):
            return False
        return pathlib.Path(info_location).is_dir()

    @property
    def installed_with_dist_info(self) -> bool:
        
        info_location = self.info_location
        if not info_location:
            return False
        if not info_location.endswith("".dist-info""):
            return False
        return pathlib.Path(info_location).is_dir()

    @property
    def canonical_name(self) -> NormalizedName:
        raise NotImplementedError()

    @property
    def version(self) -> Version:
        raise NotImplementedError()

    @property
    def raw_version(self) -> str:
        raise NotImplementedError()

    @property
    def setuptools_filename(self) -> str:
        
        return self.raw_name.replace(""-"", ""_"")

    @property
    def direct_url(self) -> DirectUrl | None:
        
        try:
            content = self.read_text(DIRECT_URL_METADATA_NAME)
        except FileNotFoundError:
            return None
        try:
            return DirectUrl.from_json(content)
        except (
            UnicodeDecodeError,
            json.JSONDecodeError,
            DirectUrlValidationError,
        ) as e:
            logger.warning(
                ""Error parsing %s for %s: %s"",
                DIRECT_URL_METADATA_NAME,
                self.canonical_name,
                e,
            )
            return None

    @property
    def installer(self) -> str:
        try:
            installer_text = self.read_text(""INSTALLER"")
        except (OSError, ValueError, NoneMetadataError):
            return """"  
        for line in installer_text.splitlines():
            cleaned_line = line.strip()
            if cleaned_line:
                return cleaned_line
        return """"

    @property
    def requested(self) -> bool:
        return self.is_file(""REQUESTED"")

    @property
    def editable(self) -> bool:
        return bool(self.editable_project_location)

    @property
    def local(self) -> bool:
        
        if self.installed_location is None:
            return False
        return is_local(self.installed_location)

    @property
    def in_usersite(self) -> bool:
        if self.installed_location is None or user_site is None:
            return False
        return self.installed_location.startswith(normalize_path(user_site))

    @property
    def in_site_packages(self) -> bool:
        if self.installed_location is None or site_packages is None:
            return False
        return self.installed_location.startswith(normalize_path(site_packages))

    def is_file(self, path: InfoPath) -> bool:
        
        raise NotImplementedError()

    def iter_distutils_script_names(self) -> Iterator[str]:
        
        raise NotImplementedError()

    def read_text(self, path: InfoPath) -> str:
        
        raise NotImplementedError()

    def iter_entry_points(self) -> Iterable[BaseEntryPoint]:
        raise NotImplementedError()

    def _metadata_impl(self) -> email.message.Message:
        raise NotImplementedError()

    @functools.cached_property
    def metadata(self) -> email.message.Message:
        
        metadata = self._metadata_impl()
        self._add_egg_info_requires(metadata)
        return metadata

    @property
    def metadata_dict(self) -> dict[str, Any]:
        
        return msg_to_json(self.metadata)

    @property
    def metadata_version(self) -> str | None:
        
        return self.metadata.get(""Metadata-Version"")

    @property
    def raw_name(self) -> str:
        
        
        
        return self.metadata.get(""Name"", self.canonical_name)

    @property
    def requires_python(self) -> SpecifierSet:
        
        value = self.metadata.get(""Requires-Python"")
        if value is None:
            return SpecifierSet()
        try:
            
            spec = SpecifierSet(str(value))
        except InvalidSpecifier as e:
            message = ""Package %r has an invalid Requires-Python: %s""
            logger.warning(message, self.raw_name, e)
            return SpecifierSet()
        return spec

    def iter_dependencies(self, extras: Collection[str] = ()) -> Iterable[Requirement]:
        
        raise NotImplementedError()

    def iter_raw_dependencies(self) -> Iterable[str]:
        
        return self.metadata.get_all(""Requires-Dist"", [])

    def iter_provided_extras(self) -> Iterable[NormalizedName]:
        
        raise NotImplementedError()

    def _iter_declared_entries_from_record(self) -> Iterator[str] | None:
        try:
            text = self.read_text(""RECORD"")
        except FileNotFoundError:
            return None
        
        return (str(pathlib.Path(row[0])) for row in csv.reader(text.splitlines()))

    def _iter_declared_entries_from_legacy(self) -> Iterator[str] | None:
        try:
            text = self.read_text(""installed-files.txt"")
        except FileNotFoundError:
            return None
        paths = (p for p in text.splitlines(keepends=False) if p)
        root = self.location
        info = self.info_location
        if root is None or info is None:
            return paths
        try:
            info_rel = pathlib.Path(info).relative_to(root)
        except ValueError:  
            return paths
        if not info_rel.parts:  
            return paths
        return (
            _convert_installed_files_path(pathlib.Path(p).parts, info_rel.parts)
            for p in paths
        )

    def iter_declared_entries(self) -> Iterator[str] | None:
        
        return (
            self._iter_declared_entries_from_record()
            or self._iter_declared_entries_from_legacy()
        )

    def _iter_requires_txt_entries(self) -> Iterator[RequiresEntry]:
        
        try:
            content = self.read_text(""requires.txt"")
        except FileNotFoundError:
            return
        extra = marker = """"  
        for line in content.splitlines():
            line = line.strip()
            if not line or line.startswith(""
                continue
            if line.startswith(""["") and line.endswith(""]""):  
                extra, _, marker = line.strip(""[]"").partition("":"")
                continue
            yield RequiresEntry(requirement=line, extra=extra, marker=marker)

    def _iter_egg_info_extras(self) -> Iterable[str]:
        
        known_extras = {""""}
        for entry in self._iter_requires_txt_entries():
            extra = canonicalize_name(entry.extra)
            if extra in known_extras:
                continue
            known_extras.add(extra)
            yield extra

    def _iter_egg_info_dependencies(self) -> Iterable[str]:
        
        for entry in self._iter_requires_txt_entries():
            extra = canonicalize_name(entry.extra)
            if extra and entry.marker:
                marker = f'({entry.marker}) and extra == ""{extra}""'
            elif extra:
                marker = f'extra == ""{extra}""'
            elif entry.marker:
                marker = entry.marker
            else:
                marker = """"
            if marker:
                yield f""{entry.requirement} ; {marker}""
            else:
                yield entry.requirement

    def _add_egg_info_requires(self, metadata: email.message.Message) -> None:
        
        if not metadata.get_all(""Requires-Dist""):
            for dep in self._iter_egg_info_dependencies():
                metadata[""Requires-Dist""] = dep
        if not metadata.get_all(""Provides-Extra""):
            for extra in self._iter_egg_info_extras():
                metadata[""Provides-Extra""] = extra


class BaseEnvironment:
    

    @classmethod
    def default(cls) -> BaseEnvironment:
        raise NotImplementedError()

    @classmethod
    def from_paths(cls, paths: list[str] | None) -> BaseEnvironment:
        raise NotImplementedError()

    def get_distribution(self, name: str) -> BaseDistribution | None:
        
        raise NotImplementedError()

    def _iter_distributions(self) -> Iterator[BaseDistribution]:
        
        raise NotImplementedError()

    def iter_all_distributions(self) -> Iterator[BaseDistribution]:
        
        for dist in self._iter_distributions():
            
            
            
            
            project_name_valid = re.match(
                r""^([A-Z0-9]|[A-Z0-9][A-Z0-9._-]*[A-Z0-9])$"",
                dist.canonical_name,
                flags=re.IGNORECASE,
            )
            if not project_name_valid:
                logger.warning(
                    ""Ignoring invalid distribution %s (%s)"",
                    dist.canonical_name,
                    dist.location,
                )
                continue
            yield dist

    def iter_installed_distributions(
        self,
        local_only: bool = True,
        skip: Container[str] = stdlib_pkgs,
        include_editables: bool = True,
        editables_only: bool = False,
        user_only: bool = False,
    ) -> Iterator[BaseDistribution]:
        
        it = self.iter_all_distributions()
        if local_only:
            it = (d for d in it if d.local)
        if not include_editables:
            it = (d for d in it if not d.editable)
        if editables_only:
            it = (d for d in it if d.editable)
        if user_only:
            it = (d for d in it if d.in_usersite)
        return (d for d in it if d.canonical_name not in skip)


class Wheel(Protocol):
    location: str

    def as_zipfile(self) -> zipfile.ZipFile:
        raise NotImplementedError()


class FilesystemWheel(Wheel):
    def __init__(self, location: str) -> None:
        self.location = location

    def as_zipfile(self) -> zipfile.ZipFile:
        return zipfile.ZipFile(self.location, allowZip64=True)


class MemoryWheel(Wheel):
    def __init__(self, location: str, stream: IO[bytes]) -> None:
        self.location = location
        self.stream = stream

    def as_zipfile(self) -> zipfile.ZipFile:
        return zipfile.ZipFile(self.stream, allowZip64=True)

from __future__ import annotations

import email.message
import email.parser
import logging
import os
import zipfile
from collections.abc import Collection, Iterable, Iterator, Mapping
from typing import (
    NamedTuple,
)

from pip._vendor import pkg_resources
from pip._vendor.packaging.requirements import Requirement
from pip._vendor.packaging.utils import NormalizedName, canonicalize_name
from pip._vendor.packaging.version import Version
from pip._vendor.packaging.version import parse as parse_version

from pip._internal.exceptions import InvalidWheel, NoneMetadataError, UnsupportedWheel
from pip._internal.utils.egg_link import egg_link_path_from_location
from pip._internal.utils.misc import display_path, normalize_path
from pip._internal.utils.wheel import parse_wheel, read_wheel_metadata_file

from .base import (
    BaseDistribution,
    BaseEntryPoint,
    BaseEnvironment,
    InfoPath,
    Wheel,
)

__all__ = [""NAME"", ""Distribution"", ""Environment""]

logger = logging.getLogger(__name__)

NAME = ""pkg_resources""


class EntryPoint(NamedTuple):
    name: str
    value: str
    group: str


class InMemoryMetadata:
    

    def __init__(self, metadata: Mapping[str, bytes], wheel_name: str) -> None:
        self._metadata = metadata
        self._wheel_name = wheel_name

    def has_metadata(self, name: str) -> bool:
        return name in self._metadata

    def get_metadata(self, name: str) -> str:
        try:
            return self._metadata[name].decode()
        except UnicodeDecodeError as e:
            
            raise UnsupportedWheel(
                f""Error decoding metadata for {self._wheel_name}: {e} in {name} file""
            )

    def get_metadata_lines(self, name: str) -> Iterable[str]:
        return pkg_resources.yield_lines(self.get_metadata(name))

    def metadata_isdir(self, name: str) -> bool:
        return False

    def metadata_listdir(self, name: str) -> list[str]:
        return []

    def run_script(self, script_name: str, namespace: str) -> None:
        pass


class Distribution(BaseDistribution):
    def __init__(self, dist: pkg_resources.Distribution) -> None:
        self._dist = dist
        
        
        self.__extra_mapping: Mapping[NormalizedName, str] | None = None

    @property
    def _extra_mapping(self) -> Mapping[NormalizedName, str]:
        if self.__extra_mapping is None:
            self.__extra_mapping = {
                canonicalize_name(extra): extra for extra in self._dist.extras
            }

        return self.__extra_mapping

    @classmethod
    def from_directory(cls, directory: str) -> BaseDistribution:
        dist_dir = directory.rstrip(os.sep)

        
        base_dir, dist_dir_name = os.path.split(dist_dir)
        metadata = pkg_resources.PathMetadata(base_dir, dist_dir)

        
        if dist_dir.endswith("".egg-info""):
            dist_cls = pkg_resources.Distribution
            dist_name = os.path.splitext(dist_dir_name)[0]
        else:
            assert dist_dir.endswith("".dist-info"")
            dist_cls = pkg_resources.DistInfoDistribution
            dist_name = os.path.splitext(dist_dir_name)[0].split(""-"")[0]

        dist = dist_cls(base_dir, project_name=dist_name, metadata=metadata)
        return cls(dist)

    @classmethod
    def from_metadata_file_contents(
        cls,
        metadata_contents: bytes,
        filename: str,
        project_name: str,
    ) -> BaseDistribution:
        metadata_dict = {
            ""METADATA"": metadata_contents,
        }
        dist = pkg_resources.DistInfoDistribution(
            location=filename,
            metadata=InMemoryMetadata(metadata_dict, filename),
            project_name=project_name,
        )
        return cls(dist)

    @classmethod
    def from_wheel(cls, wheel: Wheel, name: str) -> BaseDistribution:
        try:
            with wheel.as_zipfile() as zf:
                info_dir, _ = parse_wheel(zf, name)
                metadata_dict = {
                    path.split(""/"", 1)[-1]: read_wheel_metadata_file(zf, path)
                    for path in zf.namelist()
                    if path.startswith(f""{info_dir}/"")
                }
        except zipfile.BadZipFile as e:
            raise InvalidWheel(wheel.location, name) from e
        except UnsupportedWheel as e:
            raise UnsupportedWheel(f""{name} has an invalid wheel, {e}"")
        dist = pkg_resources.DistInfoDistribution(
            location=wheel.location,
            metadata=InMemoryMetadata(metadata_dict, wheel.location),
            project_name=name,
        )
        return cls(dist)

    @property
    def location(self) -> str | None:
        return self._dist.location

    @property
    def installed_location(self) -> str | None:
        egg_link = egg_link_path_from_location(self.raw_name)
        if egg_link:
            location = egg_link
        elif self.location:
            location = self.location
        else:
            return None
        return normalize_path(location)

    @property
    def info_location(self) -> str | None:
        return self._dist.egg_info

    @property
    def installed_by_distutils(self) -> bool:
        
        
        
        try:
            return bool(self._dist._provider.path)
        except AttributeError:
            return False

    @property
    def canonical_name(self) -> NormalizedName:
        return canonicalize_name(self._dist.project_name)

    @property
    def version(self) -> Version:
        return parse_version(self._dist.version)

    @property
    def raw_version(self) -> str:
        return self._dist.version

    def is_file(self, path: InfoPath) -> bool:
        return self._dist.has_metadata(str(path))

    def iter_distutils_script_names(self) -> Iterator[str]:
        yield from self._dist.metadata_listdir(""scripts"")

    def read_text(self, path: InfoPath) -> str:
        name = str(path)
        if not self._dist.has_metadata(name):
            raise FileNotFoundError(name)
        content = self._dist.get_metadata(name)
        if content is None:
            raise NoneMetadataError(self, name)
        return content

    def iter_entry_points(self) -> Iterable[BaseEntryPoint]:
        for group, entries in self._dist.get_entry_map().items():
            for name, entry_point in entries.items():
                name, _, value = str(entry_point).partition(""="")
                yield EntryPoint(name=name.strip(), value=value.strip(), group=group)

    def _metadata_impl(self) -> email.message.Message:
        
        if isinstance(self._dist, pkg_resources.DistInfoDistribution):
            metadata_name = ""METADATA""
        else:
            metadata_name = ""PKG-INFO""
        try:
            metadata = self.read_text(metadata_name)
        except FileNotFoundError:
            if self.location:
                displaying_path = display_path(self.location)
            else:
                displaying_path = repr(self.location)
            logger.warning(""No metadata found in %s"", displaying_path)
            metadata = """"
        feed_parser = email.parser.FeedParser()
        feed_parser.feed(metadata)
        return feed_parser.close()

    def iter_dependencies(self, extras: Collection[str] = ()) -> Iterable[Requirement]:
        if extras:
            relevant_extras = set(self._extra_mapping) & set(
                map(canonicalize_name, extras)
            )
            extras = [self._extra_mapping[extra] for extra in relevant_extras]
        return self._dist.requires(extras)

    def iter_provided_extras(self) -> Iterable[NormalizedName]:
        return self._extra_mapping.keys()


class Environment(BaseEnvironment):
    def __init__(self, ws: pkg_resources.WorkingSet) -> None:
        self._ws = ws

    @classmethod
    def default(cls) -> BaseEnvironment:
        return cls(pkg_resources.working_set)

    @classmethod
    def from_paths(cls, paths: list[str] | None) -> BaseEnvironment:
        return cls(pkg_resources.WorkingSet(paths))

    def _iter_distributions(self) -> Iterator[BaseDistribution]:
        for dist in self._ws:
            yield Distribution(dist)

    def _search_distribution(self, name: str) -> BaseDistribution | None:
        
        canonical_name = canonicalize_name(name)
        for dist in self.iter_all_distributions():
            if dist.canonical_name == canonical_name:
                return dist
        return None

    def get_distribution(self, name: str) -> BaseDistribution | None:
        
        dist = self._search_distribution(name)
        if dist:
            return dist

        
        
        
        
        
        
        
        
        try:
            
            
            self._ws.require(name)
        except pkg_resources.DistributionNotFound:
            return None
        return self._search_distribution(name)


from __future__ import annotations

from email.header import Header, decode_header, make_header
from email.message import Message
from typing import Any, cast

METADATA_FIELDS = [
    
    (""Metadata-Version"", False),
    (""Name"", False),
    (""Version"", False),
    (""Dynamic"", True),
    (""Platform"", True),
    (""Supported-Platform"", True),
    (""Summary"", False),
    (""Description"", False),
    (""Description-Content-Type"", False),
    (""Keywords"", False),
    (""Home-page"", False),
    (""Download-URL"", False),
    (""Author"", False),
    (""Author-email"", False),
    (""Maintainer"", False),
    (""Maintainer-email"", False),
    (""License"", False),
    (""License-Expression"", False),
    (""License-File"", True),
    (""Classifier"", True),
    (""Requires-Dist"", True),
    (""Requires-Python"", False),
    (""Requires-External"", True),
    (""Project-URL"", True),
    (""Provides-Extra"", True),
    (""Provides-Dist"", True),
    (""Obsoletes-Dist"", True),
]


def json_name(field: str) -> str:
    return field.lower().replace(""-"", ""_"")


def msg_to_json(msg: Message) -> dict[str, Any]:
    

    def sanitise_header(h: Header | str) -> str:
        if isinstance(h, Header):
            chunks = []
            for bytes, encoding in decode_header(h):
                if encoding == ""unknown-8bit"":
                    try:
                        
                        bytes.decode(""utf-8"")
                        encoding = ""utf-8""
                    except UnicodeDecodeError:
                        
                        encoding = ""latin1""
                chunks.append((bytes, encoding))
            return str(make_header(chunks))
        return str(h)

    result = {}
    for field, multi in METADATA_FIELDS:
        if field not in msg:
            continue
        key = json_name(field)
        if multi:
            value: str | list[str] = [
                sanitise_header(v) for v in msg.get_all(field)  
            ]
        else:
            value = sanitise_header(msg.get(field))  
            if key == ""keywords"":
                
                
                if "","" in value:
                    value = [v.strip() for v in value.split("","")]
                else:
                    value = value.split()
        result[key] = value

    payload = cast(str, msg.get_payload())
    if payload:
        result[""description""] = payload

    return result

from __future__ import annotations

import contextlib
import functools
import os
import sys
from typing import Literal, Protocol, cast

from pip._internal.utils.deprecation import deprecated
from pip._internal.utils.misc import strtobool

from .base import BaseDistribution, BaseEnvironment, FilesystemWheel, MemoryWheel, Wheel

__all__ = [
    ""BaseDistribution"",
    ""BaseEnvironment"",
    ""FilesystemWheel"",
    ""MemoryWheel"",
    ""Wheel"",
    ""get_default_environment"",
    ""get_environment"",
    ""get_wheel_distribution"",
    ""select_backend"",
]


def _should_use_importlib_metadata() -> bool:
    
    if sys.version_info >= (3, 14):
        
        return True
    with contextlib.suppress(KeyError, ValueError):
        
        return bool(strtobool(os.environ[""_PIP_USE_IMPORTLIB_METADATA""]))
    if sys.version_info < (3, 11):
        
        
        return False
    
    import importlib.metadata

    return bool(getattr(importlib.metadata, ""_PIP_USE_IMPORTLIB_METADATA"", True))


def _emit_pkg_resources_deprecation_if_needed() -> None:
    if sys.version_info < (3, 11):
        
        
        return

    import importlib.metadata

    if hasattr(importlib.metadata, ""_PIP_USE_IMPORTLIB_METADATA""):
        
        
        return

    
    deprecated(
        reason=""Using the pkg_resources metadata backend is deprecated."",
        replacement=(
            ""to use the default importlib.metadata backend, ""
            ""by unsetting the _PIP_USE_IMPORTLIB_METADATA environment variable""
        ),
        gone_in=""26.3"",
        issue=13317,
    )


class Backend(Protocol):
    NAME: Literal[""importlib"", ""pkg_resources""]
    Distribution: type[BaseDistribution]
    Environment: type[BaseEnvironment]


@functools.cache
def select_backend() -> Backend:
    if _should_use_importlib_metadata():
        from . import importlib

        return cast(Backend, importlib)

    _emit_pkg_resources_deprecation_if_needed()

    from . import pkg_resources

    return cast(Backend, pkg_resources)


def get_default_environment() -> BaseEnvironment:
    
    return select_backend().Environment.default()


def get_environment(paths: list[str] | None) -> BaseEnvironment:
    
    return select_backend().Environment.from_paths(paths)


def get_directory_distribution(directory: str) -> BaseDistribution:
    
    return select_backend().Distribution.from_directory(directory)


def get_wheel_distribution(wheel: Wheel, canonical_name: str) -> BaseDistribution:
    
    return select_backend().Distribution.from_wheel(wheel, canonical_name)


def get_metadata_distribution(
    metadata_contents: bytes,
    filename: str,
    canonical_name: str,
) -> BaseDistribution:
    
    return select_backend().Distribution.from_metadata_file_contents(
        metadata_contents,
        filename,
        canonical_name,
    )

from __future__ import annotations

import importlib.metadata
import os
from typing import Any, Protocol, cast

from pip._vendor.packaging.utils import NormalizedName, canonicalize_name


class BadMetadata(ValueError):
    def __init__(self, dist: importlib.metadata.Distribution, *, reason: str) -> None:
        self.dist = dist
        self.reason = reason

    def __str__(self) -> str:
        return f""Bad metadata in {self.dist} ({self.reason})""


class BasePath(Protocol):
    

    @property
    def name(self) -> str:
        raise NotImplementedError()

    @property
    def parent(self) -> BasePath:
        raise NotImplementedError()


def get_info_location(d: importlib.metadata.Distribution) -> BasePath | None:
    
    return getattr(d, ""_path"", None)


def parse_name_and_version_from_info_directory(
    dist: importlib.metadata.Distribution,
) -> tuple[str | None, str | None]:
    
    info_location = get_info_location(dist)
    if info_location is None:
        return None, None

    stem, suffix = os.path.splitext(info_location.name)
    if suffix == "".dist-info"":
        name, sep, version = stem.partition(""-"")
        if sep:
            return name, version

    if suffix == "".egg-info"":
        name = stem.split(""-"", 1)[0]
        return name, None

    return None, None


def get_dist_canonical_name(dist: importlib.metadata.Distribution) -> NormalizedName:
    
    if name := parse_name_and_version_from_info_directory(dist)[0]:
        return canonicalize_name(name)

    name = cast(Any, dist).name
    if not isinstance(name, str):
        raise BadMetadata(dist, reason=""invalid metadata entry 'name'"")
    return canonicalize_name(name)

from __future__ import annotations

import email.message
import importlib.metadata
import pathlib
import zipfile
from collections.abc import Collection, Iterable, Iterator, Mapping, Sequence
from os import PathLike
from typing import (
    cast,
)

from pip._vendor.packaging.requirements import Requirement
from pip._vendor.packaging.utils import NormalizedName, canonicalize_name
from pip._vendor.packaging.version import Version
from pip._vendor.packaging.version import parse as parse_version

from pip._internal.exceptions import InvalidWheel, UnsupportedWheel
from pip._internal.metadata.base import (
    BaseDistribution,
    BaseEntryPoint,
    InfoPath,
    Wheel,
)
from pip._internal.utils.misc import normalize_path
from pip._internal.utils.packaging import get_requirement
from pip._internal.utils.temp_dir import TempDirectory
from pip._internal.utils.wheel import parse_wheel, read_wheel_metadata_file

from ._compat import (
    BasePath,
    get_dist_canonical_name,
    parse_name_and_version_from_info_directory,
)


class WheelDistribution(importlib.metadata.Distribution):
    

    def __init__(
        self,
        files: Mapping[pathlib.PurePosixPath, bytes],
        info_location: pathlib.PurePosixPath,
    ) -> None:
        self._files = files
        self.info_location = info_location

    @classmethod
    def from_zipfile(
        cls,
        zf: zipfile.ZipFile,
        name: str,
        location: str,
    ) -> WheelDistribution:
        info_dir, _ = parse_wheel(zf, name)
        paths = (
            (name, pathlib.PurePosixPath(name.split(""/"", 1)[-1]))
            for name in zf.namelist()
            if name.startswith(f""{info_dir}/"")
        )
        files = {
            relpath: read_wheel_metadata_file(zf, fullpath)
            for fullpath, relpath in paths
        }
        info_location = pathlib.PurePosixPath(location, info_dir)
        return cls(files, info_location)

    def iterdir(self, path: InfoPath) -> Iterator[pathlib.PurePosixPath]:
        
        if pathlib.PurePosixPath(str(path)) in self._files:
            return iter(self._files)
        raise FileNotFoundError(path)

    def read_text(self, filename: str) -> str | None:
        try:
            data = self._files[pathlib.PurePosixPath(filename)]
        except KeyError:
            return None
        try:
            text = data.decode(""utf-8"")
        except UnicodeDecodeError as e:
            wheel = self.info_location.parent
            error = f""Error decoding metadata for {wheel}: {e} in {filename} file""
            raise UnsupportedWheel(error)
        return text

    def locate_file(self, path: str | PathLike[str]) -> pathlib.Path:
        
        
        raise NotImplementedError


class Distribution(BaseDistribution):
    def __init__(
        self,
        dist: importlib.metadata.Distribution,
        info_location: BasePath | None,
        installed_location: BasePath | None,
    ) -> None:
        self._dist = dist
        self._info_location = info_location
        self._installed_location = installed_location

    @classmethod
    def from_directory(cls, directory: str) -> BaseDistribution:
        info_location = pathlib.Path(directory)
        dist = importlib.metadata.Distribution.at(info_location)
        return cls(dist, info_location, info_location.parent)

    @classmethod
    def from_metadata_file_contents(
        cls,
        metadata_contents: bytes,
        filename: str,
        project_name: str,
    ) -> BaseDistribution:
        
        temp_dir = pathlib.Path(
            TempDirectory(kind=""metadata"", globally_managed=True).path
        )
        metadata_path = temp_dir / ""METADATA""
        metadata_path.write_bytes(metadata_contents)
        
        dist = importlib.metadata.Distribution.at(metadata_path.parent)
        return cls(dist, metadata_path.parent, None)

    @classmethod
    def from_wheel(cls, wheel: Wheel, name: str) -> BaseDistribution:
        try:
            with wheel.as_zipfile() as zf:
                dist = WheelDistribution.from_zipfile(zf, name, wheel.location)
        except zipfile.BadZipFile as e:
            raise InvalidWheel(wheel.location, name) from e
        return cls(dist, dist.info_location, pathlib.PurePosixPath(wheel.location))

    @property
    def location(self) -> str | None:
        if self._info_location is None:
            return None
        return str(self._info_location.parent)

    @property
    def info_location(self) -> str | None:
        if self._info_location is None:
            return None
        return str(self._info_location)

    @property
    def installed_location(self) -> str | None:
        if self._installed_location is None:
            return None
        return normalize_path(str(self._installed_location))

    @property
    def canonical_name(self) -> NormalizedName:
        return get_dist_canonical_name(self._dist)

    @property
    def version(self) -> Version:
        if version := parse_name_and_version_from_info_directory(self._dist)[1]:
            return parse_version(version)
        return parse_version(self._dist.version)

    @property
    def raw_version(self) -> str:
        return self._dist.version

    def is_file(self, path: InfoPath) -> bool:
        return self._dist.read_text(str(path)) is not None

    def iter_distutils_script_names(self) -> Iterator[str]:
        
        
        
        if not isinstance(self._info_location, pathlib.Path):
            return
        for child in self._info_location.joinpath(""scripts"").iterdir():
            yield child.name

    def read_text(self, path: InfoPath) -> str:
        content = self._dist.read_text(str(path))
        if content is None:
            raise FileNotFoundError(path)
        return content

    def iter_entry_points(self) -> Iterable[BaseEntryPoint]:
        
        return self._dist.entry_points

    def _metadata_impl(self) -> email.message.Message:
        
        
        
        
        
        return cast(email.message.Message, self._dist.metadata)

    def iter_provided_extras(self) -> Iterable[NormalizedName]:
        return [
            canonicalize_name(extra)
            for extra in self.metadata.get_all(""Provides-Extra"", [])
        ]

    def iter_dependencies(self, extras: Collection[str] = ()) -> Iterable[Requirement]:
        contexts: Sequence[dict[str, str]] = [{""extra"": e} for e in extras]
        for req_string in self.metadata.get_all(""Requires-Dist"", []):
            
            
            req = get_requirement(req_string.strip())
            if not req.marker:
                yield req
            elif not extras and req.marker.evaluate({""extra"": """"}):
                yield req
            elif any(req.marker.evaluate(context) for context in contexts):
                yield req

from __future__ import annotations

import importlib.metadata
import logging
import os
import pathlib
import sys
import zipfile
from collections.abc import Iterator, Sequence
from typing import Optional

from pip._vendor.packaging.utils import (
    InvalidWheelFilename,
    NormalizedName,
    canonicalize_name,
    parse_wheel_filename,
)

from pip._internal.metadata.base import BaseDistribution, BaseEnvironment
from pip._internal.utils.filetypes import WHEEL_EXTENSION

from ._compat import BadMetadata, BasePath, get_dist_canonical_name, get_info_location
from ._dists import Distribution

logger = logging.getLogger(__name__)


def _looks_like_wheel(location: str) -> bool:
    if not location.endswith(WHEEL_EXTENSION):
        return False
    if not os.path.isfile(location):
        return False
    try:
        parse_wheel_filename(os.path.basename(location))
    except InvalidWheelFilename:
        return False
    return zipfile.is_zipfile(location)


class _DistributionFinder:
    

    FoundResult = tuple[importlib.metadata.Distribution, Optional[BasePath]]

    def __init__(self) -> None:
        self._found_names: set[NormalizedName] = set()

    def _find_impl(self, location: str) -> Iterator[FoundResult]:
        
        
        
        
        if _looks_like_wheel(location):
            return
        
        
        for dist in importlib.metadata.distributions(path=[location]):
            info_location = get_info_location(dist)
            try:
                name = get_dist_canonical_name(dist)
            except BadMetadata as e:
                logger.warning(""Skipping %s due to %s"", info_location, e.reason)
                continue
            if name in self._found_names:
                continue
            self._found_names.add(name)
            yield dist, info_location

    def find(self, location: str) -> Iterator[BaseDistribution]:
        
        for dist, info_location in self._find_impl(location):
            if info_location is None:
                installed_location: BasePath | None = None
            else:
                installed_location = info_location.parent
            yield Distribution(dist, info_location, installed_location)

    def find_legacy_editables(self, location: str) -> Iterator[BaseDistribution]:
        
        path = pathlib.Path(location)
        if not path.is_dir():
            return
        for child in path.iterdir():
            if child.suffix != "".egg-link"":
                continue
            with child.open() as f:
                lines = (line.strip() for line in f)
                target_rel = next((line for line in lines if line), """")
            if not target_rel:
                continue
            target_location = str(path.joinpath(target_rel))
            for dist, info_location in self._find_impl(target_location):
                yield Distribution(dist, info_location, path)


class Environment(BaseEnvironment):
    def __init__(self, paths: Sequence[str]) -> None:
        self._paths = paths

    @classmethod
    def default(cls) -> BaseEnvironment:
        return cls(sys.path)

    @classmethod
    def from_paths(cls, paths: list[str] | None) -> BaseEnvironment:
        if paths is None:
            return cls(sys.path)
        return cls(paths)

    def _iter_distributions(self) -> Iterator[BaseDistribution]:
        finder = _DistributionFinder()
        for location in self._paths:
            yield from finder.find(location)
            yield from finder.find_legacy_editables(location)

    def get_distribution(self, name: str) -> BaseDistribution | None:
        canonical_name = canonicalize_name(name)
        matches = (
            distribution
            for distribution in self.iter_all_distributions()
            if distribution.canonical_name == canonical_name
        )
        return next(matches, None)

from ._dists import Distribution
from ._envs import Environment

__all__ = [""NAME"", ""Distribution"", ""Environment""]

NAME = ""importlib""

from dataclasses import dataclass

from pip._vendor.packaging.version import Version
from pip._vendor.packaging.version import parse as parse_version

from pip._internal.models.link import Link


@dataclass(frozen=True)
class InstallationCandidate:
    

    __slots__ = [""name"", ""version"", ""link""]

    name: str
    version: Version
    link: Link

    def __init__(self, name: str, version: str, link: Link) -> None:
        object.__setattr__(self, ""name"", name)
        object.__setattr__(self, ""version"", parse_version(version))
        object.__setattr__(self, ""link"", link)

    def __str__(self) -> str:
        return f""{self.name!r} candidate (version {self.version} at {self.link})""



from __future__ import annotations

import json
import re
import urllib.parse
from collections.abc import Iterable
from dataclasses import dataclass
from typing import Any, ClassVar, TypeVar, Union

__all__ = [
    ""DirectUrl"",
    ""DirectUrlValidationError"",
    ""DirInfo"",
    ""ArchiveInfo"",
    ""VcsInfo"",
]

T = TypeVar(""T"")

DIRECT_URL_METADATA_NAME = ""direct_url.json""
ENV_VAR_RE = re.compile(r""^\$\{[A-Za-z0-9-_]+\}(:\$\{[A-Za-z0-9-_]+\})?$"")


class DirectUrlValidationError(Exception):
    pass


def _get(
    d: dict[str, Any], expected_type: type[T], key: str, default: T | None = None
) -> T | None:
    
    if key not in d:
        return default
    value = d[key]
    if not isinstance(value, expected_type):
        raise DirectUrlValidationError(
            f""{value!r} has unexpected type for {key} (expected {expected_type})""
        )
    return value


def _get_required(
    d: dict[str, Any], expected_type: type[T], key: str, default: T | None = None
) -> T:
    value = _get(d, expected_type, key, default)
    if value is None:
        raise DirectUrlValidationError(f""{key} must have a value"")
    return value


def _exactly_one_of(infos: Iterable[InfoType | None]) -> InfoType:
    infos = [info for info in infos if info is not None]
    if not infos:
        raise DirectUrlValidationError(
            ""missing one of archive_info, dir_info, vcs_info""
        )
    if len(infos) > 1:
        raise DirectUrlValidationError(
            ""more than one of archive_info, dir_info, vcs_info""
        )
    assert infos[0] is not None
    return infos[0]


def _filter_none(**kwargs: Any) -> dict[str, Any]:
    
    return {k: v for k, v in kwargs.items() if v is not None}


@dataclass
class VcsInfo:
    name: ClassVar = ""vcs_info""

    vcs: str
    commit_id: str
    requested_revision: str | None = None

    @classmethod
    def _from_dict(cls, d: dict[str, Any] | None) -> VcsInfo | None:
        if d is None:
            return None
        return cls(
            vcs=_get_required(d, str, ""vcs""),
            commit_id=_get_required(d, str, ""commit_id""),
            requested_revision=_get(d, str, ""requested_revision""),
        )

    def _to_dict(self) -> dict[str, Any]:
        return _filter_none(
            vcs=self.vcs,
            requested_revision=self.requested_revision,
            commit_id=self.commit_id,
        )


class ArchiveInfo:
    name = ""archive_info""

    def __init__(
        self,
        hash: str | None = None,
        hashes: dict[str, str] | None = None,
    ) -> None:
        
        self.hashes = hashes
        self.hash = hash

    @property
    def hash(self) -> str | None:
        return self._hash

    @hash.setter
    def hash(self, value: str | None) -> None:
        if value is not None:
            
            
            try:
                hash_name, hash_value = value.split(""="", 1)
            except ValueError:
                raise DirectUrlValidationError(
                    f""invalid archive_info.hash format: {value!r}""
                )
            if self.hashes is None:
                self.hashes = {hash_name: hash_value}
            elif hash_name not in self.hashes:
                self.hashes = self.hashes.copy()
                self.hashes[hash_name] = hash_value
        self._hash = value

    @classmethod
    def _from_dict(cls, d: dict[str, Any] | None) -> ArchiveInfo | None:
        if d is None:
            return None
        return cls(hash=_get(d, str, ""hash""), hashes=_get(d, dict, ""hashes""))

    def _to_dict(self) -> dict[str, Any]:
        return _filter_none(hash=self.hash, hashes=self.hashes)


@dataclass
class DirInfo:
    name: ClassVar = ""dir_info""

    editable: bool = False

    @classmethod
    def _from_dict(cls, d: dict[str, Any] | None) -> DirInfo | None:
        if d is None:
            return None
        return cls(editable=_get_required(d, bool, ""editable"", default=False))

    def _to_dict(self) -> dict[str, Any]:
        return _filter_none(editable=self.editable or None)


InfoType = Union[ArchiveInfo, DirInfo, VcsInfo]


@dataclass
class DirectUrl:
    url: str
    info: InfoType
    subdirectory: str | None = None

    def _remove_auth_from_netloc(self, netloc: str) -> str:
        if ""@"" not in netloc:
            return netloc
        user_pass, netloc_no_user_pass = netloc.split(""@"", 1)
        if (
            isinstance(self.info, VcsInfo)
            and self.info.vcs == ""git""
            and user_pass == ""git""
        ):
            return netloc
        if ENV_VAR_RE.match(user_pass):
            return netloc
        return netloc_no_user_pass

    @property
    def redacted_url(self) -> str:
        
        purl = urllib.parse.urlsplit(self.url)
        netloc = self._remove_auth_from_netloc(purl.netloc)
        surl = urllib.parse.urlunsplit(
            (purl.scheme, netloc, purl.path, purl.query, purl.fragment)
        )
        return surl

    def validate(self) -> None:
        self.from_dict(self.to_dict())

    @classmethod
    def from_dict(cls, d: dict[str, Any]) -> DirectUrl:
        return DirectUrl(
            url=_get_required(d, str, ""url""),
            subdirectory=_get(d, str, ""subdirectory""),
            info=_exactly_one_of(
                [
                    ArchiveInfo._from_dict(_get(d, dict, ""archive_info"")),
                    DirInfo._from_dict(_get(d, dict, ""dir_info"")),
                    VcsInfo._from_dict(_get(d, dict, ""vcs_info"")),
                ]
            ),
        )

    def to_dict(self) -> dict[str, Any]:
        res = _filter_none(
            url=self.redacted_url,
            subdirectory=self.subdirectory,
        )
        res[self.info.name] = self.info._to_dict()
        return res

    @classmethod
    def from_json(cls, s: str) -> DirectUrl:
        return cls.from_dict(json.loads(s))

    def to_json(self) -> str:
        return json.dumps(self.to_dict(), sort_keys=True)

    def is_local_editable(self) -> bool:
        return isinstance(self.info, DirInfo) and self.info.editable

from __future__ import annotations

from pip._vendor.packaging.utils import canonicalize_name

from pip._internal.exceptions import CommandError


class FormatControl:
    

    __slots__ = [""no_binary"", ""only_binary""]

    def __init__(
        self,
        no_binary: set[str] | None = None,
        only_binary: set[str] | None = None,
    ) -> None:
        if no_binary is None:
            no_binary = set()
        if only_binary is None:
            only_binary = set()

        self.no_binary = no_binary
        self.only_binary = only_binary

    def __eq__(self, other: object) -> bool:
        if not isinstance(other, self.__class__):
            return NotImplemented

        if self.__slots__ != other.__slots__:
            return False

        return all(getattr(self, k) == getattr(other, k) for k in self.__slots__)

    def __repr__(self) -> str:
        return f""{self.__class__.__name__}({self.no_binary}, {self.only_binary})""

    @staticmethod
    def handle_mutual_excludes(value: str, target: set[str], other: set[str]) -> None:
        if value.startswith(""-""):
            raise CommandError(
                ""--no-binary / --only-binary option requires 1 argument.""
            )
        new = value.split("","")
        while "":all:"" in new:
            other.clear()
            target.clear()
            target.add("":all:"")
            del new[: new.index("":all:"") + 1]
            
            if "":none:"" not in new:
                return
        for name in new:
            if name == "":none:"":
                target.clear()
                continue
            name = canonicalize_name(name)
            other.discard(name)
            target.add(name)

    def get_allowed_formats(self, canonical_name: str) -> frozenset[str]:
        result = {""binary"", ""source""}
        if canonical_name in self.only_binary:
            result.discard(""source"")
        elif canonical_name in self.no_binary:
            result.discard(""binary"")
        elif "":all:"" in self.only_binary:
            result.discard(""source"")
        elif "":all:"" in self.no_binary:
            result.discard(""binary"")
        return frozenset(result)

    def disallow_binaries(self) -> None:
        self.handle_mutual_excludes(
            "":all:"",
            self.no_binary,
            self.only_binary,
        )

import urllib.parse


class PackageIndex:
    

    __slots__ = [""url"", ""netloc"", ""simple_url"", ""pypi_url"", ""file_storage_domain""]

    def __init__(self, url: str, file_storage_domain: str) -> None:
        super().__init__()
        self.url = url
        self.netloc = urllib.parse.urlsplit(url).netloc
        self.simple_url = self._url_for_path(""simple"")
        self.pypi_url = self._url_for_path(""pypi"")

        
        
        
        self.file_storage_domain = file_storage_domain

    def _url_for_path(self, path: str) -> str:
        return urllib.parse.urljoin(self.url, path)


PyPI = PackageIndex(""https://pypi.org/"", file_storage_domain=""files.pythonhosted.org"")
TestPyPI = PackageIndex(
    ""https://test.pypi.org/"", file_storage_domain=""test-files.pythonhosted.org""
)

from collections.abc import Sequence
from typing import Any

from pip._vendor.packaging.markers import default_environment

from pip import __version__
from pip._internal.req.req_install import InstallRequirement


class InstallationReport:
    def __init__(self, install_requirements: Sequence[InstallRequirement]):
        self._install_requirements = install_requirements

    @classmethod
    def _install_req_to_dict(cls, ireq: InstallRequirement) -> dict[str, Any]:
        assert ireq.download_info, f""No download_info for {ireq}""
        res = {
            
            
            
            
            ""download_info"": ireq.download_info.to_dict(),
            
            
            
            ""is_direct"": ireq.is_direct,
            
            
            ""is_yanked"": ireq.link.is_yanked if ireq.link else False,
            
            
            
            ""requested"": ireq.user_supplied,
            
            
            ""metadata"": ireq.get_dist().metadata_dict,
        }
        if ireq.user_supplied and ireq.extras:
            
            res[""requested_extras""] = sorted(ireq.extras)
        return res

    def to_dict(self) -> dict[str, Any]:
        return {
            ""version"": ""1"",
            ""pip_version"": __version__,
            ""install"": [
                self._install_req_to_dict(ireq) for ireq in self._install_requirements
            ],
            
            
            
            
            
            
            ""environment"": default_environment(),
        }

from __future__ import annotations

import functools
import itertools
import logging
import os
import posixpath
import re
import urllib.parse
from collections.abc import Mapping
from dataclasses import dataclass
from typing import (
    TYPE_CHECKING,
    Any,
    NamedTuple,
)

from pip._internal.utils.deprecation import deprecated
from pip._internal.utils.filetypes import WHEEL_EXTENSION
from pip._internal.utils.hashes import Hashes
from pip._internal.utils.misc import (
    pairwise,
    redact_auth_from_url,
    split_auth_from_netloc,
    splitext,
)
from pip._internal.utils.urls import path_to_url, url_to_path

if TYPE_CHECKING:
    from pip._internal.index.collector import IndexContent

logger = logging.getLogger(__name__)




_SUPPORTED_HASHES = (""sha512"", ""sha384"", ""sha256"", ""sha224"", ""sha1"", ""md5"")


@dataclass(frozen=True)
class LinkHash:
    

    name: str
    value: str

    _hash_url_fragment_re = re.compile(
        
        
        
        
        
        r""[
            choices=""|"".join(re.escape(hash_name) for hash_name in _SUPPORTED_HASHES)
        ),
    )

    def __post_init__(self) -> None:
        assert self.name in _SUPPORTED_HASHES

    @classmethod
    @functools.cache
    def find_hash_url_fragment(cls, url: str) -> LinkHash | None:
        
        match = cls._hash_url_fragment_re.search(url)
        if match is None:
            return None
        name, value = match.groups()
        return cls(name=name, value=value)

    def as_dict(self) -> dict[str, str]:
        return {self.name: self.value}

    def as_hashes(self) -> Hashes:
        
        return Hashes({self.name: [self.value]})

    def is_hash_allowed(self, hashes: Hashes | None) -> bool:
        
        if hashes is None:
            return False
        return hashes.is_hash_allowed(self.name, hex_digest=self.value)


@dataclass(frozen=True)
class MetadataFile:
    

    hashes: dict[str, str] | None

    def __post_init__(self) -> None:
        if self.hashes is not None:
            assert all(name in _SUPPORTED_HASHES for name in self.hashes)


def supported_hashes(hashes: dict[str, str] | None) -> dict[str, str] | None:
    
    
    if hashes is None:
        return None
    hashes = {n: v for n, v in hashes.items() if n in _SUPPORTED_HASHES}
    if not hashes:
        return None
    return hashes


def _clean_url_path_part(part: str) -> str:
    
    
    return urllib.parse.quote(urllib.parse.unquote(part))


def _clean_file_url_path(part: str) -> str:
    
    
    
    
    
    
    ret = urllib.request.pathname2url(urllib.request.url2pathname(part))
    if ret.startswith(""///""):
        
        ret = ret.removeprefix(""//"")
    return ret



_reserved_chars_re = re.compile(""(@|%2F)"", re.IGNORECASE)


def _clean_url_path(path: str, is_local_path: bool) -> str:
    
    if is_local_path:
        clean_func = _clean_file_url_path
    else:
        clean_func = _clean_url_path_part

    
    
    parts = _reserved_chars_re.split(path)

    cleaned_parts = []
    for to_clean, reserved in pairwise(itertools.chain(parts, [""""])):
        cleaned_parts.append(clean_func(to_clean))
        
        cleaned_parts.append(reserved.upper())

    return """".join(cleaned_parts)


def _ensure_quoted_url(url: str) -> str:
    
    
    
    result = urllib.parse.urlsplit(url)
    
    is_local_path = not result.netloc
    path = _clean_url_path(result.path, is_local_path=is_local_path)
    
    
    ret = urllib.parse.urlunsplit(result._replace(scheme=""file"", path=path))
    ret = result.scheme + ret[4:]  
    return ret


def _absolute_link_url(base_url: str, url: str) -> str:
    
    if url.startswith((""https://"", ""http://"")):
        return url
    else:
        return urllib.parse.urljoin(base_url, url)


@functools.total_ordering
class Link:
    

    __slots__ = [
        ""_parsed_url"",
        ""_url"",
        ""_path"",
        ""_hashes"",
        ""comes_from"",
        ""requires_python"",
        ""yanked_reason"",
        ""metadata_file_data"",
        ""cache_link_parsing"",
        ""egg_fragment"",
    ]

    def __init__(
        self,
        url: str,
        comes_from: str | IndexContent | None = None,
        requires_python: str | None = None,
        yanked_reason: str | None = None,
        metadata_file_data: MetadataFile | None = None,
        cache_link_parsing: bool = True,
        hashes: Mapping[str, str] | None = None,
    ) -> None:
        

        
        
        

        
        if url.startswith(""\\\\""):
            url = path_to_url(url)

        self._parsed_url = urllib.parse.urlsplit(url)
        
        
        self._url = url
        
        self._path = urllib.parse.unquote(self._parsed_url.path)

        link_hash = LinkHash.find_hash_url_fragment(url)
        hashes_from_link = {} if link_hash is None else link_hash.as_dict()
        if hashes is None:
            self._hashes = hashes_from_link
        else:
            self._hashes = {**hashes, **hashes_from_link}

        self.comes_from = comes_from
        self.requires_python = requires_python if requires_python else None
        self.yanked_reason = yanked_reason
        self.metadata_file_data = metadata_file_data

        self.cache_link_parsing = cache_link_parsing
        self.egg_fragment = self._egg_fragment()

    @classmethod
    def from_json(
        cls,
        file_data: dict[str, Any],
        page_url: str,
    ) -> Link | None:
        
        file_url = file_data.get(""url"")
        if file_url is None:
            return None

        url = _ensure_quoted_url(_absolute_link_url(page_url, file_url))
        pyrequire = file_data.get(""requires-python"")
        yanked_reason = file_data.get(""yanked"")
        hashes = file_data.get(""hashes"", {})

        
        
        metadata_info = file_data.get(""core-metadata"")
        if metadata_info is None:
            metadata_info = file_data.get(""dist-info-metadata"")

        
        if isinstance(metadata_info, dict):
            
            metadata_file_data = MetadataFile(supported_hashes(metadata_info))
        elif metadata_info:
            
            metadata_file_data = MetadataFile(None)
        else:
            
            metadata_file_data = None

        
        if yanked_reason and not isinstance(yanked_reason, str):
            yanked_reason = """"
        
        elif not yanked_reason:
            yanked_reason = None

        return cls(
            url,
            comes_from=page_url,
            requires_python=pyrequire,
            yanked_reason=yanked_reason,
            hashes=hashes,
            metadata_file_data=metadata_file_data,
        )

    @classmethod
    def from_element(
        cls,
        anchor_attribs: dict[str, str | None],
        page_url: str,
        base_url: str,
    ) -> Link | None:
        
        href = anchor_attribs.get(""href"")
        if not href:
            return None

        url = _ensure_quoted_url(_absolute_link_url(base_url, href))
        pyrequire = anchor_attribs.get(""data-requires-python"")
        yanked_reason = anchor_attribs.get(""data-yanked"")

        
        
        metadata_info = anchor_attribs.get(""data-core-metadata"")
        if metadata_info is None:
            metadata_info = anchor_attribs.get(""data-dist-info-metadata"")
        
        
        if metadata_info == ""true"":
            
            metadata_file_data = MetadataFile(None)
        elif metadata_info is None:
            
            metadata_file_data = None
        else:
            
            hashname, sep, hashval = metadata_info.partition(""="")
            if sep == ""="":
                metadata_file_data = MetadataFile(supported_hashes({hashname: hashval}))
            else:
                
                logger.debug(
                    ""Index returned invalid data-dist-info-metadata value: %s"",
                    metadata_info,
                )
                metadata_file_data = MetadataFile(None)

        return cls(
            url,
            comes_from=page_url,
            requires_python=pyrequire,
            yanked_reason=yanked_reason,
            metadata_file_data=metadata_file_data,
        )

    def __str__(self) -> str:
        if self.requires_python:
            rp = f"" (requires-python:{self.requires_python})""
        else:
            rp = """"
        if self.comes_from:
            return f""{self.redacted_url} (from {self.comes_from}){rp}""
        else:
            return self.redacted_url

    def __repr__(self) -> str:
        return f""<Link {self}>""

    def __hash__(self) -> int:
        return hash(self.url)

    def __eq__(self, other: Any) -> bool:
        if not isinstance(other, Link):
            return NotImplemented
        return self.url == other.url

    def __lt__(self, other: Any) -> bool:
        if not isinstance(other, Link):
            return NotImplemented
        return self.url < other.url

    @property
    def url(self) -> str:
        return self._url

    @property
    def redacted_url(self) -> str:
        return redact_auth_from_url(self.url)

    @property
    def filename(self) -> str:
        path = self.path.rstrip(""/"")
        name = posixpath.basename(path)
        if not name:
            
            
            netloc, user_pass = split_auth_from_netloc(self.netloc)
            return netloc

        name = urllib.parse.unquote(name)
        assert name, f""URL {self._url!r} produced no filename""
        return name

    @property
    def file_path(self) -> str:
        return url_to_path(self.url)

    @property
    def scheme(self) -> str:
        return self._parsed_url.scheme

    @property
    def netloc(self) -> str:
        
        return self._parsed_url.netloc

    @property
    def path(self) -> str:
        return self._path

    def splitext(self) -> tuple[str, str]:
        return splitext(posixpath.basename(self.path.rstrip(""/"")))

    @property
    def ext(self) -> str:
        return self.splitext()[1]

    @property
    def url_without_fragment(self) -> str:
        scheme, netloc, path, query, fragment = self._parsed_url
        return urllib.parse.urlunsplit((scheme, netloc, path, query, """"))

    _egg_fragment_re = re.compile(r""[

    
    _project_name_re = re.compile(
        r""^([A-Z0-9]|[A-Z0-9][A-Z0-9._-]*[A-Z0-9])$"", re.IGNORECASE
    )

    def _egg_fragment(self) -> str | None:
        match = self._egg_fragment_re.search(self._url)
        if not match:
            return None

        
        
        project_name = match.group(1)
        if not self._project_name_re.match(project_name):
            deprecated(
                reason=f""{self} contains an egg fragment with a non-PEP 508 name."",
                replacement=""to use the req @ url syntax, and remove the egg fragment"",
                gone_in=""25.3"",
                issue=13157,
            )

        return project_name

    _subdirectory_fragment_re = re.compile(r""[

    @property
    def subdirectory_fragment(self) -> str | None:
        match = self._subdirectory_fragment_re.search(self._url)
        if not match:
            return None
        return match.group(1)

    def metadata_link(self) -> Link | None:
        
        if self.metadata_file_data is None:
            return None
        metadata_url = f""{self.url_without_fragment}.metadata""
        if self.metadata_file_data.hashes is None:
            return Link(metadata_url)
        return Link(metadata_url, hashes=self.metadata_file_data.hashes)

    def as_hashes(self) -> Hashes:
        return Hashes({k: [v] for k, v in self._hashes.items()})

    @property
    def hash(self) -> str | None:
        return next(iter(self._hashes.values()), None)

    @property
    def hash_name(self) -> str | None:
        return next(iter(self._hashes), None)

    @property
    def show_url(self) -> str:
        return posixpath.basename(self._url.split(""

    @property
    def is_file(self) -> bool:
        return self.scheme == ""file""

    def is_existing_dir(self) -> bool:
        return self.is_file and os.path.isdir(self.file_path)

    @property
    def is_wheel(self) -> bool:
        return self.ext == WHEEL_EXTENSION

    @property
    def is_vcs(self) -> bool:
        from pip._internal.vcs import vcs

        return self.scheme in vcs.all_schemes

    @property
    def is_yanked(self) -> bool:
        return self.yanked_reason is not None

    @property
    def has_hash(self) -> bool:
        return bool(self._hashes)

    def is_hash_allowed(self, hashes: Hashes | None) -> bool:
        
        if hashes is None:
            return False
        return any(hashes.is_hash_allowed(k, v) for k, v in self._hashes.items())


class _CleanResult(NamedTuple):
    

    parsed: urllib.parse.SplitResult
    query: dict[str, list[str]]
    subdirectory: str
    hashes: dict[str, str]


def _clean_link(link: Link) -> _CleanResult:
    parsed = link._parsed_url
    netloc = parsed.netloc.rsplit(""@"", 1)[-1]
    
    if parsed.scheme == ""file"" and not netloc:
        netloc = ""localhost""
    fragment = urllib.parse.parse_qs(parsed.fragment)
    if ""egg"" in fragment:
        logger.debug(""Ignoring egg= fragment in %s"", link)
    try:
        
        
        subdirectory = fragment[""subdirectory""][0]
    except (IndexError, KeyError):
        subdirectory = """"
    
    
    hashes = {k: fragment[k][0] for k in _SUPPORTED_HASHES if k in fragment}
    return _CleanResult(
        parsed=parsed._replace(netloc=netloc, query="""", fragment=""""),
        query=urllib.parse.parse_qs(parsed.query),
        subdirectory=subdirectory,
        hashes=hashes,
    )


@functools.cache
def links_equivalent(link1: Link, link2: Link) -> bool:
    return _clean_link(link1) == _clean_link(link2)

from __future__ import annotations

import dataclasses
import re
from collections.abc import Iterable
from dataclasses import dataclass
from pathlib import Path
from typing import TYPE_CHECKING, Any

from pip._vendor import tomli_w

from pip._internal.models.direct_url import ArchiveInfo, DirInfo, VcsInfo
from pip._internal.models.link import Link
from pip._internal.req.req_install import InstallRequirement
from pip._internal.utils.urls import url_to_path

if TYPE_CHECKING:
    from typing_extensions import Self

PYLOCK_FILE_NAME_RE = re.compile(r""^pylock\.([^.]+)\.toml$"")


def is_valid_pylock_file_name(path: Path) -> bool:
    return path.name == ""pylock.toml"" or bool(re.match(PYLOCK_FILE_NAME_RE, path.name))


def _toml_dict_factory(data: list[tuple[str, Any]]) -> dict[str, Any]:
    return {key.replace(""_"", ""-""): value for key, value in data if value is not None}


@dataclass
class PackageVcs:
    type: str
    url: str | None
    
    requested_revision: str | None
    commit_id: str
    subdirectory: str | None


@dataclass
class PackageDirectory:
    path: str
    editable: bool | None
    subdirectory: str | None


@dataclass
class PackageArchive:
    url: str | None
    
    
    
    hashes: dict[str, str]
    subdirectory: str | None


@dataclass
class PackageSdist:
    name: str
    
    url: str | None
    
    
    hashes: dict[str, str]


@dataclass
class PackageWheel:
    name: str
    
    url: str | None
    
    
    hashes: dict[str, str]


@dataclass
class Package:
    name: str
    version: str | None = None
    
    
    
    vcs: PackageVcs | None = None
    directory: PackageDirectory | None = None
    archive: PackageArchive | None = None
    
    sdist: PackageSdist | None = None
    wheels: list[PackageWheel] | None = None
    
    

    @classmethod
    def from_install_requirement(cls, ireq: InstallRequirement, base_dir: Path) -> Self:
        base_dir = base_dir.resolve()
        dist = ireq.get_dist()
        download_info = ireq.download_info
        assert download_info
        package = cls(name=dist.canonical_name)
        if ireq.is_direct:
            if isinstance(download_info.info, VcsInfo):
                package.vcs = PackageVcs(
                    type=download_info.info.vcs,
                    url=download_info.url,
                    requested_revision=download_info.info.requested_revision,
                    commit_id=download_info.info.commit_id,
                    subdirectory=download_info.subdirectory,
                )
            elif isinstance(download_info.info, DirInfo):
                package.directory = PackageDirectory(
                    path=(
                        Path(url_to_path(download_info.url))
                        .resolve()
                        .relative_to(base_dir)
                        .as_posix()
                    ),
                    editable=(
                        download_info.info.editable
                        if download_info.info.editable
                        else None
                    ),
                    subdirectory=download_info.subdirectory,
                )
            elif isinstance(download_info.info, ArchiveInfo):
                if not download_info.info.hashes:
                    raise NotImplementedError()
                package.archive = PackageArchive(
                    url=download_info.url,
                    hashes=download_info.info.hashes,
                    subdirectory=download_info.subdirectory,
                )
            else:
                
                raise NotImplementedError()
        else:
            package.version = str(dist.version)
            if isinstance(download_info.info, ArchiveInfo):
                if not download_info.info.hashes:
                    raise NotImplementedError()
                link = Link(download_info.url)
                if link.is_wheel:
                    package.wheels = [
                        PackageWheel(
                            name=link.filename,
                            url=download_info.url,
                            hashes=download_info.info.hashes,
                        )
                    ]
                else:
                    package.sdist = PackageSdist(
                        name=link.filename,
                        url=download_info.url,
                        hashes=download_info.info.hashes,
                    )
            else:
                
                raise NotImplementedError()
        return package


@dataclass
class Pylock:
    lock_version: str = ""1.0""
    
    
    
    
    created_by: str = ""pip""
    packages: list[Package] = dataclasses.field(default_factory=list)
    

    def as_toml(self) -> str:
        return tomli_w.dumps(dataclasses.asdict(self, dict_factory=_toml_dict_factory))

    @classmethod
    def from_install_requirements(
        cls, install_requirements: Iterable[InstallRequirement], base_dir: Path
    ) -> Self:
        return cls(
            packages=sorted(
                (
                    Package.from_install_requirement(ireq, base_dir)
                    for ireq in install_requirements
                ),
                key=lambda p: p.name,
            )
        )



from dataclasses import dataclass

SCHEME_KEYS = [""platlib"", ""purelib"", ""headers"", ""scripts"", ""data""]


@dataclass(frozen=True)
class Scheme:
    

    __slots__ = SCHEME_KEYS

    platlib: str
    purelib: str
    headers: str
    scripts: str
    data: str

import itertools
import logging
import os
import posixpath
import urllib.parse
from dataclasses import dataclass

from pip._vendor.packaging.utils import canonicalize_name

from pip._internal.models.index import PyPI
from pip._internal.utils.compat import has_tls
from pip._internal.utils.misc import normalize_path, redact_auth_from_url

logger = logging.getLogger(__name__)


@dataclass(frozen=True)
class SearchScope:
    

    __slots__ = [""find_links"", ""index_urls"", ""no_index""]

    find_links: list[str]
    index_urls: list[str]
    no_index: bool

    @classmethod
    def create(
        cls,
        find_links: list[str],
        index_urls: list[str],
        no_index: bool,
    ) -> ""SearchScope"":
        
        
        
        
        
        
        built_find_links: list[str] = []
        for link in find_links:
            if link.startswith(""~""):
                new_link = normalize_path(link)
                if os.path.exists(new_link):
                    link = new_link
            built_find_links.append(link)

        
        
        if not has_tls():
            for link in itertools.chain(index_urls, built_find_links):
                parsed = urllib.parse.urlparse(link)
                if parsed.scheme == ""https"":
                    logger.warning(
                        ""pip is configured with locations that require ""
                        ""TLS/SSL, however the ssl module in Python is not ""
                        ""available.""
                    )
                    break

        return cls(
            find_links=built_find_links,
            index_urls=index_urls,
            no_index=no_index,
        )

    def get_formatted_locations(self) -> str:
        lines = []
        redacted_index_urls = []
        if self.index_urls and self.index_urls != [PyPI.simple_url]:
            for url in self.index_urls:
                redacted_index_url = redact_auth_from_url(url)

                
                purl = urllib.parse.urlsplit(redacted_index_url)

                
                
                
                
                
                if not purl.scheme and not purl.netloc:
                    logger.warning(
                        'The index url ""%s"" seems invalid, please provide a scheme.',
                        redacted_index_url,
                    )

                redacted_index_urls.append(redacted_index_url)

            lines.append(
                ""Looking in indexes: {}"".format("", "".join(redacted_index_urls))
            )

        if self.find_links:
            lines.append(
                ""Looking in links: {}"".format(
                    "", "".join(redact_auth_from_url(url) for url in self.find_links)
                )
            )
        return ""\n"".join(lines)

    def get_index_urls_locations(self, project_name: str) -> list[str]:
        

        def mkurl_pypi_url(url: str) -> str:
            loc = posixpath.join(
                url, urllib.parse.quote(canonicalize_name(project_name))
            )
            
            
            
            
            
            if not loc.endswith(""/""):
                loc = loc + ""/""
            return loc

        return [mkurl_pypi_url(url) for url in self.index_urls]

from __future__ import annotations

from pip._internal.models.format_control import FormatControl




class SelectionPreferences:
    

    __slots__ = [
        ""allow_yanked"",
        ""allow_all_prereleases"",
        ""format_control"",
        ""prefer_binary"",
        ""ignore_requires_python"",
    ]

    
    
    
    
    def __init__(
        self,
        allow_yanked: bool,
        allow_all_prereleases: bool = False,
        format_control: FormatControl | None = None,
        prefer_binary: bool = False,
        ignore_requires_python: bool | None = None,
    ) -> None:
        
        if ignore_requires_python is None:
            ignore_requires_python = False

        self.allow_yanked = allow_yanked
        self.allow_all_prereleases = allow_all_prereleases
        self.format_control = format_control
        self.prefer_binary = prefer_binary
        self.ignore_requires_python = ignore_requires_python

from __future__ import annotations

import sys

from pip._vendor.packaging.tags import Tag

from pip._internal.utils.compatibility_tags import get_supported, version_info_to_nodot
from pip._internal.utils.misc import normalize_version_info


class TargetPython:
    

    __slots__ = [
        ""_given_py_version_info"",
        ""abis"",
        ""implementation"",
        ""platforms"",
        ""py_version"",
        ""py_version_info"",
        ""_valid_tags"",
        ""_valid_tags_set"",
    ]

    def __init__(
        self,
        platforms: list[str] | None = None,
        py_version_info: tuple[int, ...] | None = None,
        abis: list[str] | None = None,
        implementation: str | None = None,
    ) -> None:
        
        
        self._given_py_version_info = py_version_info

        if py_version_info is None:
            py_version_info = sys.version_info[:3]
        else:
            py_version_info = normalize_version_info(py_version_info)

        py_version = ""."".join(map(str, py_version_info[:2]))

        self.abis = abis
        self.implementation = implementation
        self.platforms = platforms
        self.py_version = py_version
        self.py_version_info = py_version_info

        
        self._valid_tags: list[Tag] | None = None
        self._valid_tags_set: set[Tag] | None = None

    def format_given(self) -> str:
        
        display_version = None
        if self._given_py_version_info is not None:
            display_version = ""."".join(
                str(part) for part in self._given_py_version_info
            )

        key_values = [
            (""platforms"", self.platforms),
            (""version_info"", display_version),
            (""abis"", self.abis),
            (""implementation"", self.implementation),
        ]
        return "" "".join(
            f""{key}={value!r}"" for key, value in key_values if value is not None
        )

    def get_sorted_tags(self) -> list[Tag]:
        
        if self._valid_tags is None:
            
            
            py_version_info = self._given_py_version_info
            if py_version_info is None:
                version = None
            else:
                version = version_info_to_nodot(py_version_info)

            tags = get_supported(
                version=version,
                platforms=self.platforms,
                abis=self.abis,
                impl=self.implementation,
            )
            self._valid_tags = tags

        return self._valid_tags

    def get_unsorted_tags(self) -> set[Tag]:
        
        if self._valid_tags_set is None:
            self._valid_tags_set = set(self.get_sorted_tags())

        return self._valid_tags_set



from __future__ import annotations

import re
from collections.abc import Iterable

from pip._vendor.packaging.tags import Tag
from pip._vendor.packaging.utils import BuildTag, parse_wheel_filename
from pip._vendor.packaging.utils import (
    InvalidWheelFilename as _PackagingInvalidWheelFilename,
)

from pip._internal.exceptions import InvalidWheelFilename
from pip._internal.utils.deprecation import deprecated


class Wheel:
    

    legacy_wheel_file_re = re.compile(
        r,
        re.VERBOSE,
    )

    def __init__(self, filename: str) -> None:
        self.filename = filename

        
        
        self.name: str
        self._build_tag: BuildTag | None = None

        try:
            wheel_info = parse_wheel_filename(filename)
            self.name, _version, self._build_tag, self.file_tags = wheel_info
            self.version = str(_version)
        except _PackagingInvalidWheelFilename as e:
            
            legacy_wheel_info = self.legacy_wheel_file_re.match(filename)
            if not legacy_wheel_info:
                raise InvalidWheelFilename(e.args[0]) from None

            deprecated(
                reason=(
                    f""Wheel filename {filename!r} is not correctly normalised. ""
                    ""Future versions of pip will raise the following error:\n""
                    f""{e.args[0]}\n\n""
                ),
                replacement=(
                    ""to rename the wheel to use a correctly normalised ""
                    ""name (this may require updating the version in ""
                    ""the project metadata)""
                ),
                gone_in=""25.3"",
                issue=12938,
            )

            self.name = legacy_wheel_info.group(""name"").replace(""_"", ""-"")
            self.version = legacy_wheel_info.group(""ver"").replace(""_"", ""-"")

            
            pyversions = legacy_wheel_info.group(""pyver"").split(""."")
            abis = legacy_wheel_info.group(""abi"").split(""."")
            plats = legacy_wheel_info.group(""plat"").split(""."")
            self.file_tags = frozenset(
                Tag(interpreter=py, abi=abi, platform=plat)
                for py in pyversions
                for abi in abis
                for plat in plats
            )

    @property
    def build_tag(self) -> BuildTag:
        if self._build_tag is not None:
            return self._build_tag

        
        legacy_wheel_info = self.legacy_wheel_file_re.match(self.filename)
        assert legacy_wheel_info is not None, ""guaranteed by filename validation""
        build_tag = legacy_wheel_info.group(""build"")
        match = re.match(r""^(\d+)(.*)$"", build_tag)
        assert match is not None, ""guaranteed by filename validation""
        build_tag_groups = match.groups()
        self._build_tag = (int(build_tag_groups[0]), build_tag_groups[1])

        return self._build_tag

    def get_formatted_file_tags(self) -> list[str]:
        
        return sorted(str(tag) for tag in self.file_tags)

    def support_index_min(self, tags: list[Tag]) -> int:
        
        try:
            return next(i for i, t in enumerate(tags) if t in self.file_tags)
        except StopIteration:
            raise ValueError()

    def find_most_preferred_tag(
        self, tags: list[Tag], tag_to_priority: dict[Tag, int]
    ) -> int:
        
        return min(
            tag_to_priority[tag] for tag in self.file_tags if tag in tag_to_priority
        )

    def supported(self, tags: Iterable[Tag]) -> bool:
        
        return not self.file_tags.isdisjoint(tags)





from __future__ import annotations

import logging
import os
import shutil
import subprocess
import sysconfig
import typing
import urllib.parse
from abc import ABC, abstractmethod
from functools import cache
from os.path import commonprefix
from pathlib import Path
from typing import Any, NamedTuple

from pip._vendor.requests.auth import AuthBase, HTTPBasicAuth
from pip._vendor.requests.models import Request, Response
from pip._vendor.requests.utils import get_netrc_auth

from pip._internal.utils.logging import getLogger
from pip._internal.utils.misc import (
    ask,
    ask_input,
    ask_password,
    remove_auth_from_url,
    split_auth_netloc_from_url,
)
from pip._internal.vcs.versioncontrol import AuthInfo

logger = getLogger(__name__)

KEYRING_DISABLED = False


class Credentials(NamedTuple):
    url: str
    username: str
    password: str


class KeyRingBaseProvider(ABC):
    

    has_keyring: bool

    @abstractmethod
    def get_auth_info(self, url: str, username: str | None) -> AuthInfo | None: ...

    @abstractmethod
    def save_auth_info(self, url: str, username: str, password: str) -> None: ...


class KeyRingNullProvider(KeyRingBaseProvider):
    

    has_keyring = False

    def get_auth_info(self, url: str, username: str | None) -> AuthInfo | None:
        return None

    def save_auth_info(self, url: str, username: str, password: str) -> None:
        return None


class KeyRingPythonProvider(KeyRingBaseProvider):
    

    has_keyring = True

    def __init__(self) -> None:
        import keyring

        self.keyring = keyring

    def get_auth_info(self, url: str, username: str | None) -> AuthInfo | None:
        
        
        
        if hasattr(self.keyring, ""get_credential""):
            logger.debug(""Getting credentials from keyring for %s"", url)
            cred = self.keyring.get_credential(url, username)
            if cred is not None:
                return cred.username, cred.password
            return None

        if username is not None:
            logger.debug(""Getting password from keyring for %s"", url)
            password = self.keyring.get_password(url, username)
            if password:
                return username, password
        return None

    def save_auth_info(self, url: str, username: str, password: str) -> None:
        self.keyring.set_password(url, username, password)


class KeyRingCliProvider(KeyRingBaseProvider):
    

    has_keyring = True

    def __init__(self, cmd: str) -> None:
        self.keyring = cmd

    def get_auth_info(self, url: str, username: str | None) -> AuthInfo | None:
        
        
        if username is not None:
            password = self._get_password(url, username)
            if password is not None:
                return username, password
        return None

    def save_auth_info(self, url: str, username: str, password: str) -> None:
        return self._set_password(url, username, password)

    def _get_password(self, service_name: str, username: str) -> str | None:
        
        if self.keyring is None:
            return None

        cmd = [self.keyring, ""get"", service_name, username]
        env = os.environ.copy()
        env[""PYTHONIOENCODING""] = ""utf-8""
        res = subprocess.run(
            cmd,
            stdin=subprocess.DEVNULL,
            stdout=subprocess.PIPE,
            env=env,
        )
        if res.returncode:
            return None
        return res.stdout.decode(""utf-8"").strip(os.linesep)

    def _set_password(self, service_name: str, username: str, password: str) -> None:
        
        if self.keyring is None:
            return None
        env = os.environ.copy()
        env[""PYTHONIOENCODING""] = ""utf-8""
        subprocess.run(
            [self.keyring, ""set"", service_name, username],
            input=f""{password}{os.linesep}"".encode(),
            env=env,
            check=True,
        )
        return None


@cache
def get_keyring_provider(provider: str) -> KeyRingBaseProvider:
    logger.verbose(""Keyring provider requested: %s"", provider)

    
    if KEYRING_DISABLED:
        provider = ""disabled""
    if provider in [""import"", ""auto""]:
        try:
            impl = KeyRingPythonProvider()
            logger.verbose(""Keyring provider set: import"")
            return impl
        except ImportError:
            pass
        except Exception as exc:
            
            
            msg = ""Installed copy of keyring fails with exception %s""
            if provider == ""auto"":
                msg = msg + "", trying to find a keyring executable as a fallback""
            logger.warning(msg, exc, exc_info=logger.isEnabledFor(logging.DEBUG))
    if provider in [""subprocess"", ""auto""]:
        cli = shutil.which(""keyring"")
        if cli and cli.startswith(sysconfig.get_path(""scripts"")):
            
            @typing.no_type_check
            def PATH_as_shutil_which_determines_it() -> str:
                path = os.environ.get(""PATH"", None)
                if path is None:
                    try:
                        path = os.confstr(""CS_PATH"")
                    except (AttributeError, ValueError):
                        
                        path = os.defpath
                
                

                return path

            scripts = Path(sysconfig.get_path(""scripts""))

            paths = []
            for path in PATH_as_shutil_which_determines_it().split(os.pathsep):
                p = Path(path)
                try:
                    if not p.samefile(scripts):
                        paths.append(path)
                except FileNotFoundError:
                    pass

            path = os.pathsep.join(paths)

            cli = shutil.which(""keyring"", path=path)

        if cli:
            logger.verbose(""Keyring provider set: subprocess with executable %s"", cli)
            return KeyRingCliProvider(cli)

    logger.verbose(""Keyring provider set: disabled"")
    return KeyRingNullProvider()


class MultiDomainBasicAuth(AuthBase):
    def __init__(
        self,
        prompting: bool = True,
        index_urls: list[str] | None = None,
        keyring_provider: str = ""auto"",
    ) -> None:
        self.prompting = prompting
        self.index_urls = index_urls
        self.keyring_provider = keyring_provider
        self.passwords: dict[str, AuthInfo] = {}
        
        
        
        
        
        self._credentials_to_save: Credentials | None = None

    @property
    def keyring_provider(self) -> KeyRingBaseProvider:
        return get_keyring_provider(self._keyring_provider)

    @keyring_provider.setter
    def keyring_provider(self, provider: str) -> None:
        
        
        
        
        self._keyring_provider = provider

    @property
    def use_keyring(self) -> bool:
        
        
        
        return self.prompting or self._keyring_provider not in [""auto"", ""disabled""]

    def _get_keyring_auth(
        self,
        url: str | None,
        username: str | None,
    ) -> AuthInfo | None:
        
        
        if not url:
            return None

        try:
            return self.keyring_provider.get_auth_info(url, username)
        except Exception as exc:
            
            
            logger.debug(""Keyring is skipped due to an exception"", exc_info=True)
            
            logger.warning(
                ""Keyring is skipped due to an exception: %s"",
                str(exc),
            )
            global KEYRING_DISABLED
            KEYRING_DISABLED = True
            get_keyring_provider.cache_clear()
            return None

    def _get_index_url(self, url: str) -> str | None:
        
        if not url or not self.index_urls:
            return None

        url = remove_auth_from_url(url).rstrip(""/"") + ""/""
        parsed_url = urllib.parse.urlsplit(url)

        candidates = []

        for index in self.index_urls:
            index = index.rstrip(""/"") + ""/""
            parsed_index = urllib.parse.urlsplit(remove_auth_from_url(index))
            if parsed_url == parsed_index:
                return index

            if parsed_url.netloc != parsed_index.netloc:
                continue

            candidate = urllib.parse.urlsplit(index)
            candidates.append(candidate)

        if not candidates:
            return None

        candidates.sort(
            reverse=True,
            key=lambda candidate: commonprefix(
                [
                    parsed_url.path,
                    candidate.path,
                ]
            ).rfind(""/""),
        )

        return urllib.parse.urlunsplit(candidates[0])

    def _get_new_credentials(
        self,
        original_url: str,
        *,
        allow_netrc: bool = True,
        allow_keyring: bool = False,
    ) -> AuthInfo:
        
        
        url, netloc, url_user_password = split_auth_netloc_from_url(
            original_url,
        )

        
        username, password = url_user_password
        if username is not None and password is not None:
            logger.debug(""Found credentials in url for %s"", netloc)
            return url_user_password

        
        index_url = self._get_index_url(url)
        if index_url:
            
            index_info = split_auth_netloc_from_url(index_url)
            if index_info:
                index_url, _, index_url_user_password = index_info
                logger.debug(""Found index url %s"", index_url)

        
        if index_url and index_url_user_password[0] is not None:
            username, password = index_url_user_password
            if username is not None and password is not None:
                logger.debug(""Found credentials in index url for %s"", netloc)
                return index_url_user_password

        
        if allow_netrc:
            netrc_auth = get_netrc_auth(original_url)
            if netrc_auth:
                logger.debug(""Found credentials in netrc for %s"", netloc)
                return netrc_auth

        
        if allow_keyring:
            
            
            kr_auth = (
                self._get_keyring_auth(index_url, username) or
                self._get_keyring_auth(netloc, username)
            )
            
            if kr_auth:
                logger.debug(""Found credentials in keyring for %s"", netloc)
                return kr_auth

        return username, password

    def _get_url_and_credentials(
        self, original_url: str
    ) -> tuple[str, str | None, str | None]:
        
        url, netloc, _ = split_auth_netloc_from_url(original_url)

        
        username, password = self._get_new_credentials(original_url)

        
        
        
        
        if (username is None or password is None) and netloc in self.passwords:
            un, pw = self.passwords[netloc]
            
            
            if username is None or username == un:
                username, password = un, pw

        if username is not None or password is not None:
            
            
            
            
            username = username or """"
            password = password or """"

            
            self.passwords[netloc] = (username, password)

        assert (
            
            (username is not None and password is not None)
            
            or (username is None and password is None)
        ), f""Could not load credentials from url: {original_url}""

        return url, username, password

    def __call__(self, req: Request) -> Request:
        
        url, username, password = self._get_url_and_credentials(req.url)

        
        req.url = url

        if username is not None and password is not None:
            
            req = HTTPBasicAuth(username, password)(req)

        
        req.register_hook(""response"", self.handle_401)

        return req

    
    def _prompt_for_password(self, netloc: str) -> tuple[str | None, str | None, bool]:
        username = ask_input(f""User for {netloc}: "") if self.prompting else None
        if not username:
            return None, None, False
        if self.use_keyring:
            auth = self._get_keyring_auth(netloc, username)
            if auth and auth[0] is not None and auth[1] is not None:
                return auth[0], auth[1], False
        password = ask_password(""Password: "")
        return username, password, True

    
    def _should_save_password_to_keyring(self) -> bool:
        if (
            not self.prompting
            or not self.use_keyring
            or not self.keyring_provider.has_keyring
        ):
            return False
        return ask(""Save credentials to keyring [y/N]: "", [""y"", ""n""]) == ""y""

    def handle_401(self, resp: Response, **kwargs: Any) -> Response:
        
        
        if resp.status_code != 401:
            return resp

        username, password = None, None

        
        if self.use_keyring:
            username, password = self._get_new_credentials(
                resp.url,
                allow_netrc=False,
                allow_keyring=True,
            )

        
        if not self.prompting and not username and not password:
            return resp

        parsed = urllib.parse.urlparse(resp.url)

        
        save = False
        if not username and not password:
            username, password, save = self._prompt_for_password(parsed.netloc)

        
        self._credentials_to_save = None
        if username is not None and password is not None:
            self.passwords[parsed.netloc] = (username, password)

            
            if save and self._should_save_password_to_keyring():
                self._credentials_to_save = Credentials(
                    url=parsed.netloc,
                    username=username,
                    password=password,
                )

        
        
        
        
        _ = resp.content
        resp.raw.release_conn()

        
        req = HTTPBasicAuth(username or """", password or """")(resp.request)
        req.register_hook(""response"", self.warn_on_401)

        
        
        
        if self._credentials_to_save:
            req.register_hook(""response"", self.save_credentials)

        
        new_resp = resp.connection.send(req, **kwargs)
        new_resp.history.append(resp)

        return new_resp

    def warn_on_401(self, resp: Response, **kwargs: Any) -> None:
        
        if resp.status_code == 401:
            logger.warning(
                ""401 Error, Credentials not correct for %s"",
                resp.request.url,
            )

    def save_credentials(self, resp: Response, **kwargs: Any) -> None:
        
        assert (
            self.keyring_provider.has_keyring
        ), ""should never reach here without keyring""

        creds = self._credentials_to_save
        self._credentials_to_save = None
        if creds and resp.status_code < 400:
            try:
                logger.info(""Saving credentials to keyring"")
                self.keyring_provider.save_auth_info(
                    creds.url, creds.username, creds.password
                )
            except Exception:
                logger.exception(""Failed to save credentials"")



from __future__ import annotations

import os
import shutil
from collections.abc import Generator
from contextlib import contextmanager
from datetime import datetime
from typing import Any, BinaryIO, Callable

from pip._vendor.cachecontrol.cache import SeparateBodyBaseCache
from pip._vendor.cachecontrol.caches import SeparateBodyFileCache
from pip._vendor.requests.models import Response

from pip._internal.utils.filesystem import adjacent_tmp_file, replace
from pip._internal.utils.misc import ensure_dir


def is_from_cache(response: Response) -> bool:
    return getattr(response, ""from_cache"", False)


@contextmanager
def suppressed_cache_errors() -> Generator[None, None, None]:
    
    try:
        yield
    except OSError:
        pass


class SafeFileCache(SeparateBodyBaseCache):
    

    def __init__(self, directory: str) -> None:
        assert directory is not None, ""Cache directory must not be None.""
        super().__init__()
        self.directory = directory

    def _get_cache_path(self, name: str) -> str:
        
        
        
        hashed = SeparateBodyFileCache.encode(name)
        parts = list(hashed[:5]) + [hashed]
        return os.path.join(self.directory, *parts)

    def get(self, key: str) -> bytes | None:
        
        metadata_path = self._get_cache_path(key)
        body_path = metadata_path + "".body""
        if not (os.path.exists(metadata_path) and os.path.exists(body_path)):
            return None
        with suppressed_cache_errors():
            with open(metadata_path, ""rb"") as f:
                return f.read()

    def _write_to_file(self, path: str, writer_func: Callable[[BinaryIO], Any]) -> None:
        
        with suppressed_cache_errors():
            ensure_dir(os.path.dirname(path))

            with adjacent_tmp_file(path) as f:
                writer_func(f)
                
                
                mode = (
                    os.stat(self.directory).st_mode
                    & 0o666  
                    | 0o600  
                )
                
                if os.chmod in os.supports_fd:
                    os.chmod(f.fileno(), mode)
                elif os.chmod in os.supports_follow_symlinks:
                    os.chmod(f.name, mode, follow_symlinks=False)

            replace(f.name, path)

    def _write(self, path: str, data: bytes) -> None:
        self._write_to_file(path, lambda f: f.write(data))

    def _write_from_io(self, path: str, source_file: BinaryIO) -> None:
        self._write_to_file(path, lambda f: shutil.copyfileobj(source_file, f))

    def set(
        self, key: str, value: bytes, expires: int | datetime | None = None
    ) -> None:
        path = self._get_cache_path(key)
        self._write(path, value)

    def delete(self, key: str) -> None:
        path = self._get_cache_path(key)
        with suppressed_cache_errors():
            os.remove(path)
        with suppressed_cache_errors():
            os.remove(path + "".body"")

    def get_body(self, key: str) -> BinaryIO | None:
        
        metadata_path = self._get_cache_path(key)
        body_path = metadata_path + "".body""
        if not (os.path.exists(metadata_path) and os.path.exists(body_path)):
            return None
        with suppressed_cache_errors():
            return open(body_path, ""rb"")

    def set_body(self, key: str, body: bytes) -> None:
        path = self._get_cache_path(key) + "".body""
        self._write(path, body)

    def set_body_from_io(self, key: str, body_file: BinaryIO) -> None:
        
        path = self._get_cache_path(key) + "".body""
        self._write_from_io(path, body_file)



from __future__ import annotations

import email.message
import logging
import mimetypes
import os
from collections.abc import Iterable, Mapping
from dataclasses import dataclass
from http import HTTPStatus
from typing import BinaryIO

from pip._vendor.requests import PreparedRequest
from pip._vendor.requests.models import Response
from pip._vendor.urllib3 import HTTPResponse as URLlib3Response
from pip._vendor.urllib3._collections import HTTPHeaderDict
from pip._vendor.urllib3.exceptions import ReadTimeoutError

from pip._internal.cli.progress_bars import BarType, get_download_progress_renderer
from pip._internal.exceptions import IncompleteDownloadError, NetworkConnectionError
from pip._internal.models.index import PyPI
from pip._internal.models.link import Link
from pip._internal.network.cache import SafeFileCache, is_from_cache
from pip._internal.network.session import CacheControlAdapter, PipSession
from pip._internal.network.utils import HEADERS, raise_for_status, response_chunks
from pip._internal.utils.misc import format_size, redact_auth_from_url, splitext

logger = logging.getLogger(__name__)


def _get_http_response_size(resp: Response) -> int | None:
    try:
        return int(resp.headers[""content-length""])
    except (ValueError, KeyError, TypeError):
        return None


def _get_http_response_etag_or_last_modified(resp: Response) -> str | None:
    
    return resp.headers.get(""etag"", resp.headers.get(""last-modified""))


def _log_download(
    resp: Response,
    link: Link,
    progress_bar: BarType,
    total_length: int | None,
    range_start: int | None = 0,
) -> Iterable[bytes]:
    if link.netloc == PyPI.file_storage_domain:
        url = link.show_url
    else:
        url = link.url_without_fragment

    logged_url = redact_auth_from_url(url)

    if total_length:
        if range_start:
            logged_url = (
                f""{logged_url} ({format_size(range_start)}/{format_size(total_length)})""
            )
        else:
            logged_url = f""{logged_url} ({format_size(total_length)})""

    if is_from_cache(resp):
        logger.info(""Using cached %s"", logged_url)
    elif range_start:
        logger.info(""Resuming download %s"", logged_url)
    else:
        logger.info(""Downloading %s"", logged_url)

    if logger.getEffectiveLevel() > logging.INFO:
        show_progress = False
    elif is_from_cache(resp):
        show_progress = False
    elif not total_length:
        show_progress = True
    elif total_length > (512 * 1024):
        show_progress = True
    else:
        show_progress = False

    chunks = response_chunks(resp)

    if not show_progress:
        return chunks

    renderer = get_download_progress_renderer(
        bar_type=progress_bar, size=total_length, initial_progress=range_start
    )
    return renderer(chunks)


def sanitize_content_filename(filename: str) -> str:
    
    return os.path.basename(filename)


def parse_content_disposition(content_disposition: str, default_filename: str) -> str:
    
    m = email.message.Message()
    m[""content-type""] = content_disposition
    filename = m.get_param(""filename"")
    if filename:
        
        
        filename = sanitize_content_filename(str(filename))
    return filename or default_filename


def _get_http_response_filename(resp: Response, link: Link) -> str:
    
    filename = link.filename  
    
    content_disposition = resp.headers.get(""content-disposition"")
    if content_disposition:
        filename = parse_content_disposition(content_disposition, filename)
    ext: str | None = splitext(filename)[1]
    if not ext:
        ext = mimetypes.guess_extension(resp.headers.get(""content-type"", """"))
        if ext:
            filename += ext
    if not ext and link.url != resp.url:
        ext = os.path.splitext(resp.url)[1]
        if ext:
            filename += ext
    return filename


@dataclass
class _FileDownload:
    

    link: Link
    output_file: BinaryIO
    size: int | None
    bytes_received: int = 0
    reattempts: int = 0

    def is_incomplete(self) -> bool:
        return bool(self.size is not None and self.bytes_received < self.size)

    def write_chunk(self, data: bytes) -> None:
        self.bytes_received += len(data)
        self.output_file.write(data)

    def reset_file(self) -> None:
        
        self.output_file.seek(0)
        self.output_file.truncate()
        self.bytes_received = 0


class Downloader:
    def __init__(
        self,
        session: PipSession,
        progress_bar: BarType,
        resume_retries: int,
    ) -> None:
        assert (
            resume_retries >= 0
        ), ""Number of max resume retries must be bigger or equal to zero""
        self._session = session
        self._progress_bar = progress_bar
        self._resume_retries = resume_retries

    def batch(
        self, links: Iterable[Link], location: str
    ) -> Iterable[tuple[Link, tuple[str, str]]]:
        
        for link in links:
            filepath, content_type = self(link, location)
            yield link, (filepath, content_type)

    def __call__(self, link: Link, location: str) -> tuple[str, str]:
        
        resp = self._http_get(link)
        download_size = _get_http_response_size(resp)

        filepath = os.path.join(location, _get_http_response_filename(resp, link))
        with open(filepath, ""wb"") as content_file:
            download = _FileDownload(link, content_file, download_size)
            self._process_response(download, resp)
            if download.is_incomplete():
                self._attempt_resumes_or_redownloads(download, resp)

        content_type = resp.headers.get(""Content-Type"", """")
        return filepath, content_type

    def _process_response(self, download: _FileDownload, resp: Response) -> None:
        
        chunks = _log_download(
            resp,
            download.link,
            self._progress_bar,
            download.size,
            range_start=download.bytes_received,
        )
        try:
            for chunk in chunks:
                download.write_chunk(chunk)
        except ReadTimeoutError as e:
            
            if download.size is None:
                raise e

            logger.warning(""Connection timed out while downloading."")

    def _attempt_resumes_or_redownloads(
        self, download: _FileDownload, first_resp: Response
    ) -> None:
        

        while download.reattempts < self._resume_retries and download.is_incomplete():
            assert download.size is not None
            download.reattempts += 1
            logger.warning(
                ""Attempting to resume incomplete download (%s/%s, attempt %d)"",
                format_size(download.bytes_received),
                format_size(download.size),
                download.reattempts,
            )

            try:
                resume_resp = self._http_get_resume(download, should_match=first_resp)
                
                
                
                must_restart = resume_resp.status_code != HTTPStatus.PARTIAL_CONTENT
                if must_restart:
                    download.reset_file()
                    download.size = _get_http_response_size(resume_resp)
                    first_resp = resume_resp

                self._process_response(download, resume_resp)
            except (ConnectionError, ReadTimeoutError, OSError):
                continue

        
        if download.is_incomplete():
            os.remove(download.output_file.name)
            raise IncompleteDownloadError(download)

        
        
        if download.reattempts > 0:
            self._cache_resumed_download(download, first_resp)

    def _cache_resumed_download(
        self, download: _FileDownload, original_response: Response
    ) -> None:
        
        url = download.link.url_without_fragment
        adapter = self._session.get_adapter(url)

        
        if not isinstance(adapter, CacheControlAdapter):
            logger.debug(
                ""Skipping resume download caching: no cache controller for %s"", url
            )
            return

        
        assert isinstance(
            adapter.cache, SafeFileCache
        ), ""separate body cache not in use!""

        synthetic_request = PreparedRequest()
        synthetic_request.prepare(method=""GET"", url=url, headers={})

        synthetic_response_headers = HTTPHeaderDict()
        for key, value in original_response.headers.items():
            if key.lower() not in [""content-range"", ""content-length""]:
                synthetic_response_headers[key] = value
        synthetic_response_headers[""content-length""] = str(download.size)

        synthetic_response = URLlib3Response(
            body="""",
            headers=synthetic_response_headers,
            status=200,
            preload_content=False,
        )

        
        cache_url = adapter.controller.cache_url(url)
        metadata_blob = adapter.controller.serializer.dumps(
            synthetic_request, synthetic_response, b""""
        )
        adapter.cache.set(cache_url, metadata_blob)
        download.output_file.flush()
        with open(download.output_file.name, ""rb"") as f:
            adapter.cache.set_body_from_io(cache_url, f)

        logger.debug(
            ""Cached resumed download as complete response for future use: %s"", url
        )

    def _http_get_resume(
        self, download: _FileDownload, should_match: Response
    ) -> Response:
        
        
        
        headers = HEADERS.copy()
        headers[""Range""] = f""bytes={download.bytes_received}-""
        
        
        if identifier := _get_http_response_etag_or_last_modified(should_match):
            headers[""If-Range""] = identifier
        return self._http_get(download.link, headers)

    def _http_get(self, link: Link, headers: Mapping[str, str] = HEADERS) -> Response:
        target_url = link.url_without_fragment
        try:
            resp = self._session.get(target_url, headers=headers, stream=True)
            raise_for_status(resp)
        except NetworkConnectionError as e:
            assert e.response is not None
            logger.critical(
                ""HTTP error %s while getting %s"", e.response.status_code, link
            )
            raise
        return resp



from __future__ import annotations

__all__ = [""HTTPRangeRequestUnsupported"", ""dist_from_wheel_url""]

from bisect import bisect_left, bisect_right
from collections.abc import Generator
from contextlib import contextmanager
from tempfile import NamedTemporaryFile
from typing import Any
from zipfile import BadZipFile, ZipFile

from pip._vendor.packaging.utils import canonicalize_name
from pip._vendor.requests.models import CONTENT_CHUNK_SIZE, Response

from pip._internal.metadata import BaseDistribution, MemoryWheel, get_wheel_distribution
from pip._internal.network.session import PipSession
from pip._internal.network.utils import HEADERS, raise_for_status, response_chunks


class HTTPRangeRequestUnsupported(Exception):
    pass


def dist_from_wheel_url(name: str, url: str, session: PipSession) -> BaseDistribution:
    
    with LazyZipOverHTTP(url, session) as zf:
        
        
        wheel = MemoryWheel(zf.name, zf)  
        
        
        return get_wheel_distribution(wheel, canonicalize_name(name))


class LazyZipOverHTTP:
    

    def __init__(
        self, url: str, session: PipSession, chunk_size: int = CONTENT_CHUNK_SIZE
    ) -> None:
        head = session.head(url, headers=HEADERS)
        raise_for_status(head)
        assert head.status_code == 200
        self._session, self._url, self._chunk_size = session, url, chunk_size
        self._length = int(head.headers[""Content-Length""])
        self._file = NamedTemporaryFile()
        self.truncate(self._length)
        self._left: list[int] = []
        self._right: list[int] = []
        if ""bytes"" not in head.headers.get(""Accept-Ranges"", ""none""):
            raise HTTPRangeRequestUnsupported(""range request is not supported"")
        self._check_zip()

    @property
    def mode(self) -> str:
        
        return ""rb""

    @property
    def name(self) -> str:
        
        return self._file.name

    def seekable(self) -> bool:
        
        return True

    def close(self) -> None:
        
        self._file.close()

    @property
    def closed(self) -> bool:
        
        return self._file.closed

    def read(self, size: int = -1) -> bytes:
        
        download_size = max(size, self._chunk_size)
        start, length = self.tell(), self._length
        stop = length if size < 0 else min(start + download_size, length)
        start = max(0, stop - download_size)
        self._download(start, stop - 1)
        return self._file.read(size)

    def readable(self) -> bool:
        
        return True

    def seek(self, offset: int, whence: int = 0) -> int:
        
        return self._file.seek(offset, whence)

    def tell(self) -> int:
        
        return self._file.tell()

    def truncate(self, size: int | None = None) -> int:
        
        return self._file.truncate(size)

    def writable(self) -> bool:
        
        return False

    def __enter__(self) -> LazyZipOverHTTP:
        self._file.__enter__()
        return self

    def __exit__(self, *exc: Any) -> None:
        self._file.__exit__(*exc)

    @contextmanager
    def _stay(self) -> Generator[None, None, None]:
        
        pos = self.tell()
        try:
            yield
        finally:
            self.seek(pos)

    def _check_zip(self) -> None:
        
        end = self._length - 1
        for start in reversed(range(0, end, self._chunk_size)):
            self._download(start, end)
            with self._stay():
                try:
                    
                    
                    ZipFile(self)
                except BadZipFile:
                    pass
                else:
                    break

    def _stream_response(
        self, start: int, end: int, base_headers: dict[str, str] = HEADERS
    ) -> Response:
        
        headers = base_headers.copy()
        headers[""Range""] = f""bytes={start}-{end}""
        
        headers[""Cache-Control""] = ""no-cache""
        return self._session.get(self._url, headers=headers, stream=True)

    def _merge(
        self, start: int, end: int, left: int, right: int
    ) -> Generator[tuple[int, int], None, None]:
        
        lslice, rslice = self._left[left:right], self._right[left:right]
        i = start = min([start] + lslice[:1])
        end = max([end] + rslice[-1:])
        for j, k in zip(lslice, rslice):
            if j > i:
                yield i, j - 1
            i = k + 1
        if i <= end:
            yield i, end
        self._left[left:right], self._right[left:right] = [start], [end]

    def _download(self, start: int, end: int) -> None:
        
        with self._stay():
            left = bisect_left(self._right, start)
            right = bisect_right(self._left, end)
            for start, end in self._merge(start, end, left, right):
                response = self._stream_response(start, end)
                response.raise_for_status()
                self.seek(start)
                for chunk in response_chunks(response, self._chunk_size):
                    self._file.write(chunk)



from __future__ import annotations

import email.utils
import functools
import io
import ipaddress
import json
import logging
import mimetypes
import os
import platform
import shutil
import subprocess
import sys
import urllib.parse
import warnings
from collections.abc import Generator, Mapping, Sequence
from typing import (
    TYPE_CHECKING,
    Any,
    Optional,
    Union,
)

from pip._vendor import requests, urllib3
from pip._vendor.cachecontrol import CacheControlAdapter as _BaseCacheControlAdapter
from pip._vendor.requests.adapters import DEFAULT_POOLBLOCK, BaseAdapter
from pip._vendor.requests.adapters import HTTPAdapter as _BaseHTTPAdapter
from pip._vendor.requests.models import PreparedRequest, Response
from pip._vendor.requests.structures import CaseInsensitiveDict
from pip._vendor.urllib3.connectionpool import ConnectionPool
from pip._vendor.urllib3.exceptions import InsecureRequestWarning

from pip import __version__
from pip._internal.metadata import get_default_environment
from pip._internal.models.link import Link
from pip._internal.network.auth import MultiDomainBasicAuth
from pip._internal.network.cache import SafeFileCache


from pip._internal.utils.compat import has_tls
from pip._internal.utils.glibc import libc_ver
from pip._internal.utils.misc import build_url_from_netloc, parse_netloc
from pip._internal.utils.urls import url_to_path

if TYPE_CHECKING:
    from ssl import SSLContext

    from pip._vendor.urllib3.poolmanager import PoolManager
    from pip._vendor.urllib3.proxymanager import ProxyManager


logger = logging.getLogger(__name__)

SecureOrigin = tuple[str, str, Optional[Union[int, str]]]



warnings.filterwarnings(""ignore"", category=InsecureRequestWarning)


SECURE_ORIGINS: list[SecureOrigin] = [
    
    
    (""https"", ""*"", ""*""),
    (""*"", ""localhost"", ""*""),
    (""*"", ""127.0.0.0/8"", ""*""),
    (""*"", ""::1/128"", ""*""),
    (""file"", ""*"", None),
    
    (""ssh"", ""*"", ""*""),
]









CI_ENVIRONMENT_VARIABLES = (
    
    ""BUILD_BUILDID"",
    
    ""BUILD_ID"",
    
    ""CI"",
    
    ""PIP_IS_CI"",
)


def looks_like_ci() -> bool:
    
    
    
    
    return any(name in os.environ for name in CI_ENVIRONMENT_VARIABLES)


@functools.lru_cache(maxsize=1)
def user_agent() -> str:
    
    data: dict[str, Any] = {
        ""installer"": {""name"": ""pip"", ""version"": __version__},
        ""python"": platform.python_version(),
        ""implementation"": {
            ""name"": platform.python_implementation(),
        },
    }

    if data[""implementation""][""name""] == ""CPython"":
        data[""implementation""][""version""] = platform.python_version()
    elif data[""implementation""][""name""] == ""PyPy"":
        pypy_version_info = sys.pypy_version_info  
        if pypy_version_info.releaselevel == ""final"":
            pypy_version_info = pypy_version_info[:3]
        data[""implementation""][""version""] = ""."".join(
            [str(x) for x in pypy_version_info]
        )
    elif data[""implementation""][""name""] == ""Jython"":
        
        data[""implementation""][""version""] = platform.python_version()
    elif data[""implementation""][""name""] == ""IronPython"":
        
        data[""implementation""][""version""] = platform.python_version()

    if sys.platform.startswith(""linux""):
        from pip._vendor import distro

        linux_distribution = distro.name(), distro.version(), distro.codename()
        distro_infos: dict[str, Any] = dict(
            filter(
                lambda x: x[1],
                zip([""name"", ""version"", ""id""], linux_distribution),
            )
        )
        libc = dict(
            filter(
                lambda x: x[1],
                zip([""lib"", ""version""], libc_ver()),
            )
        )
        if libc:
            distro_infos[""libc""] = libc
        if distro_infos:
            data[""distro""] = distro_infos

    if sys.platform.startswith(""darwin"") and platform.mac_ver()[0]:
        data[""distro""] = {""name"": ""macOS"", ""version"": platform.mac_ver()[0]}

    if platform.system():
        data.setdefault(""system"", {})[""name""] = platform.system()

    if platform.release():
        data.setdefault(""system"", {})[""release""] = platform.release()

    if platform.machine():
        data[""cpu""] = platform.machine()

    if has_tls():
        import _ssl as ssl

        data[""openssl_version""] = ssl.OPENSSL_VERSION

    setuptools_dist = get_default_environment().get_distribution(""setuptools"")
    if setuptools_dist is not None:
        data[""setuptools_version""] = str(setuptools_dist.version)

    if shutil.which(""rustc"") is not None:
        
        try:
            rustc_output = subprocess.check_output(
                [""rustc"", ""--version""], stderr=subprocess.STDOUT, timeout=0.5
            )
        except Exception:
            pass
        else:
            if rustc_output.startswith(b""rustc ""):
                
                
                
                data[""rustc_version""] = rustc_output.split(b"" "")[1].decode()

    
    
    
    
    data[""ci""] = True if looks_like_ci() else None

    user_data = os.environ.get(""PIP_USER_AGENT_USER_DATA"")
    if user_data is not None:
        data[""user_data""] = user_data

    return ""{data[installer][name]}/{data[installer][version]} {json}"".format(
        data=data,
        json=json.dumps(data, separators=("","", "":""), sort_keys=True),
    )


class LocalFSAdapter(BaseAdapter):
    def send(
        self,
        request: PreparedRequest,
        stream: bool = False,
        timeout: float | tuple[float, float] | None = None,
        verify: bool | str = True,
        cert: str | tuple[str, str] | None = None,
        proxies: Mapping[str, str] | None = None,
    ) -> Response:
        pathname = url_to_path(request.url)

        resp = Response()
        resp.status_code = 200
        resp.url = request.url

        try:
            stats = os.stat(pathname)
        except OSError as exc:
            
            
            resp.status_code = 404
            resp.reason = type(exc).__name__
            resp.raw = io.BytesIO(f""{resp.reason}: {exc}"".encode())
        else:
            modified = email.utils.formatdate(stats.st_mtime, usegmt=True)
            content_type = mimetypes.guess_type(pathname)[0] or ""text/plain""
            resp.headers = CaseInsensitiveDict(
                {
                    ""Content-Type"": content_type,
                    ""Content-Length"": stats.st_size,
                    ""Last-Modified"": modified,
                }
            )

            resp.raw = open(pathname, ""rb"")
            resp.close = resp.raw.close

        return resp

    def close(self) -> None:
        pass


class _SSLContextAdapterMixin:
    

    def __init__(
        self,
        *,
        ssl_context: SSLContext | None = None,
        **kwargs: Any,
    ) -> None:
        self._ssl_context = ssl_context
        super().__init__(**kwargs)

    def init_poolmanager(
        self,
        connections: int,
        maxsize: int,
        block: bool = DEFAULT_POOLBLOCK,
        **pool_kwargs: Any,
    ) -> PoolManager:
        if self._ssl_context is not None:
            pool_kwargs.setdefault(""ssl_context"", self._ssl_context)
        return super().init_poolmanager(  
            connections=connections,
            maxsize=maxsize,
            block=block,
            **pool_kwargs,
        )

    def proxy_manager_for(self, proxy: str, **proxy_kwargs: Any) -> ProxyManager:
        
        
        if self._ssl_context is not None:
            proxy_kwargs.setdefault(""ssl_context"", self._ssl_context)
        return super().proxy_manager_for(proxy, **proxy_kwargs)  


class HTTPAdapter(_SSLContextAdapterMixin, _BaseHTTPAdapter):
    pass


class CacheControlAdapter(_SSLContextAdapterMixin, _BaseCacheControlAdapter):
    pass


class InsecureHTTPAdapter(HTTPAdapter):
    def cert_verify(
        self,
        conn: ConnectionPool,
        url: str,
        verify: bool | str,
        cert: str | tuple[str, str] | None,
    ) -> None:
        super().cert_verify(conn=conn, url=url, verify=False, cert=cert)


class InsecureCacheControlAdapter(CacheControlAdapter):
    def cert_verify(
        self,
        conn: ConnectionPool,
        url: str,
        verify: bool | str,
        cert: str | tuple[str, str] | None,
    ) -> None:
        super().cert_verify(conn=conn, url=url, verify=False, cert=cert)


class PipSession(requests.Session):
    timeout: int | None = None

    def __init__(
        self,
        *args: Any,
        retries: int = 0,
        cache: str | None = None,
        trusted_hosts: Sequence[str] = (),
        index_urls: list[str] | None = None,
        ssl_context: SSLContext | None = None,
        **kwargs: Any,
    ) -> None:
        
        super().__init__(*args, **kwargs)

        
        
        self.pip_trusted_origins: list[tuple[str, int | None]] = []
        self.pip_proxy = None

        
        self.headers[""User-Agent""] = user_agent()

        
        self.auth = MultiDomainBasicAuth(index_urls=index_urls)

        
        
        retries = urllib3.Retry(
            
            
            total=retries,
            
            
            
            
            
            
            
            status_forcelist=[500, 502, 503, 520, 527],
            
            
            backoff_factor=0.25,
        )  

        
        
        
        
        
        insecure_adapter = InsecureHTTPAdapter(max_retries=retries)

        
        
        
        
        
        if cache:
            secure_adapter = CacheControlAdapter(
                cache=SafeFileCache(cache),
                max_retries=retries,
                ssl_context=ssl_context,
            )
            self._trusted_host_adapter = InsecureCacheControlAdapter(
                cache=SafeFileCache(cache),
                max_retries=retries,
            )
        else:
            secure_adapter = HTTPAdapter(max_retries=retries, ssl_context=ssl_context)
            self._trusted_host_adapter = insecure_adapter

        self.mount(""https://"", secure_adapter)
        self.mount(""http://"", insecure_adapter)

        
        self.mount(""file://"", LocalFSAdapter())

        for host in trusted_hosts:
            self.add_trusted_host(host, suppress_logging=True)

    def update_index_urls(self, new_index_urls: list[str]) -> None:
        
        self.auth.index_urls = new_index_urls

    def add_trusted_host(
        self, host: str, source: str | None = None, suppress_logging: bool = False
    ) -> None:
        
        if not suppress_logging:
            msg = f""adding trusted host: {host!r}""
            if source is not None:
                msg += f"" (from {source})""
            logger.info(msg)

        parsed_host, parsed_port = parse_netloc(host)
        if parsed_host is None:
            raise ValueError(f""Trusted host URL must include a host part: {host!r}"")
        if (parsed_host, parsed_port) not in self.pip_trusted_origins:
            self.pip_trusted_origins.append((parsed_host, parsed_port))

        self.mount(
            build_url_from_netloc(host, scheme=""http"") + ""/"", self._trusted_host_adapter
        )
        self.mount(build_url_from_netloc(host) + ""/"", self._trusted_host_adapter)
        if not parsed_port:
            self.mount(
                build_url_from_netloc(host, scheme=""http"") + "":"",
                self._trusted_host_adapter,
            )
            
            self.mount(build_url_from_netloc(host) + "":"", self._trusted_host_adapter)

    def iter_secure_origins(self) -> Generator[SecureOrigin, None, None]:
        yield from SECURE_ORIGINS
        for host, port in self.pip_trusted_origins:
            yield (""*"", host, ""*"" if port is None else port)

    def is_secure_origin(self, location: Link) -> bool:
        
        parsed = urllib.parse.urlparse(str(location))
        origin_protocol, origin_host, origin_port = (
            parsed.scheme,
            parsed.hostname,
            parsed.port,
        )

        
        
        
        
        origin_protocol = origin_protocol.rsplit(""+"", 1)[-1]

        
        
        
        for secure_origin in self.iter_secure_origins():
            secure_protocol, secure_host, secure_port = secure_origin
            if origin_protocol != secure_protocol and secure_protocol != ""*"":
                continue

            try:
                addr = ipaddress.ip_address(origin_host or """")
                network = ipaddress.ip_network(secure_host)
            except ValueError:
                
                
                if (
                    origin_host
                    and origin_host.lower() != secure_host.lower()
                    and secure_host != ""*""
                ):
                    continue
            else:
                
                
                if addr not in network:
                    continue

            
            if (
                origin_port != secure_port
                and secure_port != ""*""
                and secure_port is not None
            ):
                continue

            
            
            return True

        
        
        
        logger.warning(
            ""The repository located at %s is not a trusted or secure host and ""
            ""is being ignored. If this repository is available via HTTPS we ""
            ""recommend you use HTTPS instead, otherwise you may silence ""
            ""this warning and allow it anyway with '--trusted-host %s'."",
            origin_host,
            origin_host,
        )

        return False

    def request(self, method: str, url: str, *args: Any, **kwargs: Any) -> Response:
        
        kwargs.setdefault(""timeout"", self.timeout)
        
        kwargs.setdefault(""proxies"", self.proxies)

        
        return super().request(method, url, *args, **kwargs)

from collections.abc import Generator

from pip._vendor.requests.models import Response

from pip._internal.exceptions import NetworkConnectionError




















HEADERS: dict[str, str] = {""Accept-Encoding"": ""identity""}

DOWNLOAD_CHUNK_SIZE = 256 * 1024


def raise_for_status(resp: Response) -> None:
    http_error_msg = """"
    if isinstance(resp.reason, bytes):
        
        
        
        
        try:
            reason = resp.reason.decode(""utf-8"")
        except UnicodeDecodeError:
            reason = resp.reason.decode(""iso-8859-1"")
    else:
        reason = resp.reason

    if 400 <= resp.status_code < 500:
        http_error_msg = (
            f""{resp.status_code} Client Error: {reason} for url: {resp.url}""
        )

    elif 500 <= resp.status_code < 600:
        http_error_msg = (
            f""{resp.status_code} Server Error: {reason} for url: {resp.url}""
        )

    if http_error_msg:
        raise NetworkConnectionError(http_error_msg, response=resp)


def response_chunks(
    response: Response, chunk_size: int = DOWNLOAD_CHUNK_SIZE
) -> Generator[bytes, None, None]:
    
    try:
        
        for chunk in response.raw.stream(
            chunk_size,
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            decode_content=False,
        ):
            yield chunk
    except AttributeError:
        
        while True:
            chunk = response.raw.read(chunk_size)
            if not chunk:
                break
            yield chunk



import logging
import urllib.parse
import xmlrpc.client
from typing import TYPE_CHECKING

from pip._internal.exceptions import NetworkConnectionError
from pip._internal.network.session import PipSession
from pip._internal.network.utils import raise_for_status

if TYPE_CHECKING:
    from xmlrpc.client import _HostType, _Marshallable

    from _typeshed import SizedBuffer

logger = logging.getLogger(__name__)


class PipXmlrpcTransport(xmlrpc.client.Transport):
    

    def __init__(
        self, index_url: str, session: PipSession, use_datetime: bool = False
    ) -> None:
        super().__init__(use_datetime)
        index_parts = urllib.parse.urlparse(index_url)
        self._scheme = index_parts.scheme
        self._session = session

    def request(
        self,
        host: ""_HostType"",
        handler: str,
        request_body: ""SizedBuffer"",
        verbose: bool = False,
    ) -> tuple[""_Marshallable"", ...]:
        assert isinstance(host, str)
        parts = (self._scheme, host, handler, None, None, None)
        url = urllib.parse.urlunparse(parts)
        try:
            headers = {""Content-Type"": ""text/xml""}
            response = self._session.post(
                url,
                data=request_body,
                headers=headers,
                stream=True,
            )
            raise_for_status(response)
            self.verbose = verbose
            return self.parse_response(response.raw)
        except NetworkConnectionError as exc:
            assert exc.response
            logger.critical(
                ""HTTP error %s while getting %s"",
                exc.response.status_code,
                url,
            )
            raise





from __future__ import annotations

import logging
from collections.abc import Generator, Iterable
from contextlib import suppress
from email.parser import Parser
from functools import reduce
from typing import (
    Callable,
    NamedTuple,
)

from pip._vendor.packaging.requirements import Requirement
from pip._vendor.packaging.tags import Tag, parse_tag
from pip._vendor.packaging.utils import NormalizedName, canonicalize_name
from pip._vendor.packaging.version import Version

from pip._internal.distributions import make_distribution_for_install_requirement
from pip._internal.metadata import get_default_environment
from pip._internal.metadata.base import BaseDistribution
from pip._internal.req.req_install import InstallRequirement

logger = logging.getLogger(__name__)


class PackageDetails(NamedTuple):
    version: Version
    dependencies: list[Requirement]



PackageSet = dict[NormalizedName, PackageDetails]
Missing = tuple[NormalizedName, Requirement]
Conflicting = tuple[NormalizedName, Version, Requirement]

MissingDict = dict[NormalizedName, list[Missing]]
ConflictingDict = dict[NormalizedName, list[Conflicting]]
CheckResult = tuple[MissingDict, ConflictingDict]
ConflictDetails = tuple[PackageSet, CheckResult]


def create_package_set_from_installed() -> tuple[PackageSet, bool]:
    
    package_set = {}
    problems = False
    env = get_default_environment()
    for dist in env.iter_installed_distributions(local_only=False, skip=()):
        name = dist.canonical_name
        try:
            dependencies = list(dist.iter_dependencies())
            package_set[name] = PackageDetails(dist.version, dependencies)
        except (OSError, ValueError) as e:
            
            logger.warning(""Error parsing dependencies of %s: %s"", name, e)
            problems = True
    return package_set, problems


def check_package_set(
    package_set: PackageSet, should_ignore: Callable[[str], bool] | None = None
) -> CheckResult:
    

    missing = {}
    conflicting = {}

    for package_name, package_detail in package_set.items():
        
        missing_deps: set[Missing] = set()
        conflicting_deps: set[Conflicting] = set()

        if should_ignore and should_ignore(package_name):
            continue

        for req in package_detail.dependencies:
            name = canonicalize_name(req.name)

            
            if name not in package_set:
                missed = True
                if req.marker is not None:
                    missed = req.marker.evaluate({""extra"": """"})
                if missed:
                    missing_deps.add((name, req))
                continue

            
            version = package_set[name].version
            if not req.specifier.contains(version, prereleases=True):
                conflicting_deps.add((name, version, req))

        if missing_deps:
            missing[package_name] = sorted(missing_deps, key=str)
        if conflicting_deps:
            conflicting[package_name] = sorted(conflicting_deps, key=str)

    return missing, conflicting


def check_install_conflicts(to_install: list[InstallRequirement]) -> ConflictDetails:
    
    
    package_set, _ = create_package_set_from_installed()
    
    would_be_installed = _simulate_installation_of(to_install, package_set)

    
    whitelist = _create_whitelist(would_be_installed, package_set)

    return (
        package_set,
        check_package_set(
            package_set, should_ignore=lambda name: name not in whitelist
        ),
    )


def check_unsupported(
    packages: Iterable[BaseDistribution],
    supported_tags: Iterable[Tag],
) -> Generator[BaseDistribution, None, None]:
    for p in packages:
        with suppress(FileNotFoundError):
            wheel_file = p.read_text(""WHEEL"")
            wheel_tags: frozenset[Tag] = reduce(
                frozenset.union,
                map(parse_tag, Parser().parsestr(wheel_file).get_all(""Tag"", [])),
                frozenset(),
            )
            if wheel_tags.isdisjoint(supported_tags):
                yield p


def _simulate_installation_of(
    to_install: list[InstallRequirement], package_set: PackageSet
) -> set[NormalizedName]:
    
    
    installed = set()

    
    for inst_req in to_install:
        abstract_dist = make_distribution_for_install_requirement(inst_req)
        dist = abstract_dist.get_metadata_distribution()
        name = dist.canonical_name
        package_set[name] = PackageDetails(dist.version, list(dist.iter_dependencies()))

        installed.add(name)

    return installed


def _create_whitelist(
    would_be_installed: set[NormalizedName], package_set: PackageSet
) -> set[NormalizedName]:
    packages_affected = set(would_be_installed)

    for package_name in package_set:
        if package_name in packages_affected:
            continue

        for req in package_set[package_name].dependencies:
            if canonicalize_name(req.name) in packages_affected:
                packages_affected.add(package_name)
                break

    return packages_affected

from __future__ import annotations

import collections
import logging
import os
from collections.abc import Container, Generator, Iterable
from dataclasses import dataclass, field
from typing import NamedTuple

from pip._vendor.packaging.utils import NormalizedName, canonicalize_name
from pip._vendor.packaging.version import InvalidVersion

from pip._internal.exceptions import BadCommand, InstallationError
from pip._internal.metadata import BaseDistribution, get_environment
from pip._internal.req.constructors import (
    install_req_from_editable,
    install_req_from_line,
)
from pip._internal.req.req_file import COMMENT_RE
from pip._internal.utils.direct_url_helpers import direct_url_as_pep440_direct_reference

logger = logging.getLogger(__name__)


class _EditableInfo(NamedTuple):
    requirement: str
    comments: list[str]


def freeze(
    requirement: list[str] | None = None,
    local_only: bool = False,
    user_only: bool = False,
    paths: list[str] | None = None,
    isolated: bool = False,
    exclude_editable: bool = False,
    skip: Container[str] = (),
) -> Generator[str, None, None]:
    installations: dict[str, FrozenRequirement] = {}

    dists = get_environment(paths).iter_installed_distributions(
        local_only=local_only,
        skip=(),
        user_only=user_only,
    )
    for dist in dists:
        req = FrozenRequirement.from_dist(dist)
        if exclude_editable and req.editable:
            continue
        installations[req.canonical_name] = req

    if requirement:
        
        
        
        
        emitted_options: set[str] = set()
        
        
        req_files: dict[str, list[str]] = collections.defaultdict(list)
        for req_file_path in requirement:
            with open(req_file_path) as req_file:
                for line in req_file:
                    if (
                        not line.strip()
                        or line.strip().startswith(""
                        or line.startswith(
                            (
                                ""-r"",
                                ""--requirement"",
                                ""-f"",
                                ""--find-links"",
                                ""-i"",
                                ""--index-url"",
                                ""--pre"",
                                ""--trusted-host"",
                                ""--process-dependency-links"",
                                ""--extra-index-url"",
                                ""--use-feature"",
                            )
                        )
                    ):
                        line = line.rstrip()
                        if line not in emitted_options:
                            emitted_options.add(line)
                            yield line
                        continue

                    if line.startswith((""-e"", ""--editable"")):
                        if line.startswith(""-e""):
                            line = line[2:].strip()
                        else:
                            line = line[len(""--editable"") :].strip().lstrip(""="")
                        line_req = install_req_from_editable(
                            line,
                            isolated=isolated,
                        )
                    else:
                        line_req = install_req_from_line(
                            COMMENT_RE.sub("""", line).strip(),
                            isolated=isolated,
                        )

                    if not line_req.name:
                        logger.info(
                            ""Skipping line in requirement file [%s] because ""
                            ""it's not clear what it would install: %s"",
                            req_file_path,
                            line.strip(),
                        )
                        logger.info(
                            ""  (add 
                            "" this warning)""
                        )
                    else:
                        line_req_canonical_name = canonicalize_name(line_req.name)
                        if line_req_canonical_name not in installations:
                            
                            
                            if not req_files[line_req.name]:
                                logger.warning(
                                    ""Requirement file [%s] contains %s, but ""
                                    ""package %r is not installed"",
                                    req_file_path,
                                    COMMENT_RE.sub("""", line).strip(),
                                    line_req.name,
                                )
                            else:
                                req_files[line_req.name].append(req_file_path)
                        else:
                            yield str(installations[line_req_canonical_name]).rstrip()
                            del installations[line_req_canonical_name]
                            req_files[line_req.name].append(req_file_path)

        
        
        for name, files in req_files.items():
            if len(files) > 1:
                logger.warning(
                    ""Requirement %s included multiple times [%s]"",
                    name,
                    "", "".join(sorted(set(files))),
                )

        yield (""
    for installation in sorted(installations.values(), key=lambda x: x.name.lower()):
        if installation.canonical_name not in skip:
            yield str(installation).rstrip()


def _format_as_name_version(dist: BaseDistribution) -> str:
    try:
        dist_version = dist.version
    except InvalidVersion:
        
        return f""{dist.raw_name}==={dist.raw_version}""
    else:
        return f""{dist.raw_name}=={dist_version}""


def _get_editable_info(dist: BaseDistribution) -> _EditableInfo:
    
    editable_project_location = dist.editable_project_location
    assert editable_project_location
    location = os.path.normcase(os.path.abspath(editable_project_location))

    from pip._internal.vcs import RemoteNotFoundError, RemoteNotValidError, vcs

    vcs_backend = vcs.get_backend_for_dir(location)

    if vcs_backend is None:
        display = _format_as_name_version(dist)
        logger.debug(
            'No VCS found for editable requirement ""%s"" in: %r',
            display,
            location,
        )
        return _EditableInfo(
            requirement=location,
            comments=[f""
        )

    vcs_name = type(vcs_backend).__name__

    try:
        req = vcs_backend.get_src_requirement(location, dist.raw_name)
    except RemoteNotFoundError:
        display = _format_as_name_version(dist)
        return _EditableInfo(
            requirement=location,
            comments=[f""
        )
    except RemoteNotValidError as ex:
        display = _format_as_name_version(dist)
        return _EditableInfo(
            requirement=location,
            comments=[
                f""
                f""local remote or invalid URI:"",
                f""
            ],
        )
    except BadCommand:
        logger.warning(
            ""cannot determine version of editable source in %s ""
            ""(%s command not found in path)"",
            location,
            vcs_backend.name,
        )
        return _EditableInfo(requirement=location, comments=[])
    except InstallationError as exc:
        logger.warning(""Error when trying to get requirement for VCS system %s"", exc)
    else:
        return _EditableInfo(requirement=req, comments=[])

    logger.warning(""Could not determine repository location of %s"", location)

    return _EditableInfo(
        requirement=location,
        comments=[""
    )


@dataclass(frozen=True)
class FrozenRequirement:
    name: str
    req: str
    editable: bool
    comments: Iterable[str] = field(default_factory=tuple)

    @property
    def canonical_name(self) -> NormalizedName:
        return canonicalize_name(self.name)

    @classmethod
    def from_dist(cls, dist: BaseDistribution) -> FrozenRequirement:
        editable = dist.editable
        if editable:
            req, comments = _get_editable_info(dist)
        else:
            comments = []
            direct_url = dist.direct_url
            if direct_url:
                
                req = direct_url_as_pep440_direct_reference(direct_url, dist.raw_name)
            else:
                
                req = _format_as_name_version(dist)

        return cls(dist.raw_name, req, editable, comments=comments)

    def __str__(self) -> str:
        req = self.req
        if self.editable:
            req = f""-e {req}""
        return ""\n"".join(list(self.comments) + [str(req)]) + ""\n""





from __future__ import annotations

import mimetypes
import os
import shutil
from collections.abc import Iterable
from dataclasses import dataclass
from pathlib import Path
from typing import TYPE_CHECKING

from pip._vendor.packaging.utils import canonicalize_name

from pip._internal.build_env import BuildEnvironmentInstaller
from pip._internal.distributions import make_distribution_for_install_requirement
from pip._internal.distributions.installed import InstalledDistribution
from pip._internal.exceptions import (
    DirectoryUrlHashUnsupported,
    HashMismatch,
    HashUnpinned,
    InstallationError,
    MetadataInconsistent,
    NetworkConnectionError,
    VcsHashUnsupported,
)
from pip._internal.index.package_finder import PackageFinder
from pip._internal.metadata import BaseDistribution, get_metadata_distribution
from pip._internal.models.direct_url import ArchiveInfo
from pip._internal.models.link import Link
from pip._internal.models.wheel import Wheel
from pip._internal.network.download import Downloader
from pip._internal.network.lazy_wheel import (
    HTTPRangeRequestUnsupported,
    dist_from_wheel_url,
)
from pip._internal.network.session import PipSession
from pip._internal.operations.build.build_tracker import BuildTracker
from pip._internal.req.req_install import InstallRequirement
from pip._internal.utils._log import getLogger
from pip._internal.utils.direct_url_helpers import (
    direct_url_for_editable,
    direct_url_from_link,
)
from pip._internal.utils.hashes import Hashes, MissingHashes
from pip._internal.utils.logging import indent_log
from pip._internal.utils.misc import (
    display_path,
    hash_file,
    hide_url,
    redact_auth_from_requirement,
)
from pip._internal.utils.temp_dir import TempDirectory
from pip._internal.utils.unpacking import unpack_file
from pip._internal.vcs import vcs

if TYPE_CHECKING:
    from pip._internal.cli.progress_bars import BarType

logger = getLogger(__name__)


def _get_prepared_distribution(
    req: InstallRequirement,
    build_tracker: BuildTracker,
    build_env_installer: BuildEnvironmentInstaller,
    build_isolation: bool,
    check_build_deps: bool,
) -> BaseDistribution:
    
    abstract_dist = make_distribution_for_install_requirement(req)
    tracker_id = abstract_dist.build_tracker_id
    if tracker_id is not None:
        with build_tracker.track(req, tracker_id):
            abstract_dist.prepare_distribution_metadata(
                build_env_installer, build_isolation, check_build_deps
            )
    return abstract_dist.get_metadata_distribution()


def unpack_vcs_link(link: Link, location: str, verbosity: int) -> None:
    vcs_backend = vcs.get_backend_for_scheme(link.scheme)
    assert vcs_backend is not None
    vcs_backend.unpack(location, url=hide_url(link.url), verbosity=verbosity)


@dataclass
class File:
    path: str
    content_type: str | None = None

    def __post_init__(self) -> None:
        if self.content_type is None:
            
            
            try:
                self.content_type = mimetypes.guess_type(self.path)[0]
            except OSError:
                pass


def get_http_url(
    link: Link,
    download: Downloader,
    download_dir: str | None = None,
    hashes: Hashes | None = None,
) -> File:
    temp_dir = TempDirectory(kind=""unpack"", globally_managed=True)
    
    already_downloaded_path = None
    if download_dir:
        already_downloaded_path = _check_download_dir(link, download_dir, hashes)

    if already_downloaded_path:
        from_path = already_downloaded_path
        content_type = None
    else:
        
        from_path, content_type = download(link, temp_dir.path)
        if hashes:
            hashes.check_against_path(from_path)

    return File(from_path, content_type)


def get_file_url(
    link: Link, download_dir: str | None = None, hashes: Hashes | None = None
) -> File:
    
    
    already_downloaded_path = None
    if download_dir:
        already_downloaded_path = _check_download_dir(link, download_dir, hashes)

    if already_downloaded_path:
        from_path = already_downloaded_path
    else:
        from_path = link.file_path

    
    
    
    
    
    if hashes:
        hashes.check_against_path(from_path)
    return File(from_path, None)


def unpack_url(
    link: Link,
    location: str,
    download: Downloader,
    verbosity: int,
    download_dir: str | None = None,
    hashes: Hashes | None = None,
) -> File | None:
    
    
    if link.is_vcs:
        unpack_vcs_link(link, location, verbosity=verbosity)
        return None

    assert not link.is_existing_dir()

    
    if link.is_file:
        file = get_file_url(link, download_dir, hashes=hashes)

    
    else:
        file = get_http_url(
            link,
            download,
            download_dir,
            hashes=hashes,
        )

    
    
    if not link.is_wheel:
        unpack_file(file.path, location, file.content_type)

    return file


def _check_download_dir(
    link: Link,
    download_dir: str,
    hashes: Hashes | None,
    warn_on_hash_mismatch: bool = True,
) -> str | None:
    
    download_path = os.path.join(download_dir, link.filename)

    if not os.path.exists(download_path):
        return None

    
    logger.info(""File was already downloaded %s"", download_path)
    if hashes:
        try:
            hashes.check_against_path(download_path)
        except HashMismatch:
            if warn_on_hash_mismatch:
                logger.warning(
                    ""Previously-downloaded file %s has bad hash. Re-downloading."",
                    download_path,
                )
            os.unlink(download_path)
            return None
    return download_path


class RequirementPreparer:
    

    def __init__(  
        self,
        *,
        build_dir: str,
        download_dir: str | None,
        src_dir: str,
        build_isolation: bool,
        build_isolation_installer: BuildEnvironmentInstaller,
        check_build_deps: bool,
        build_tracker: BuildTracker,
        session: PipSession,
        progress_bar: BarType,
        finder: PackageFinder,
        require_hashes: bool,
        use_user_site: bool,
        lazy_wheel: bool,
        verbosity: int,
        legacy_resolver: bool,
        resume_retries: int,
    ) -> None:
        super().__init__()

        self.src_dir = src_dir
        self.build_dir = build_dir
        self.build_tracker = build_tracker
        self._session = session
        self._download = Downloader(session, progress_bar, resume_retries)
        self.finder = finder

        
        
        self.download_dir = download_dir

        
        self.build_isolation = build_isolation
        self.build_env_installer = build_isolation_installer

        
        self.check_build_deps = check_build_deps

        
        self.require_hashes = require_hashes

        
        self.use_user_site = use_user_site

        
        self.use_lazy_wheel = lazy_wheel

        
        self.verbosity = verbosity

        
        self.legacy_resolver = legacy_resolver

        
        self._downloaded: dict[str, str] = {}

        
        self._previous_requirement_header = ("""", """")

    def _log_preparing_link(self, req: InstallRequirement) -> None:
        
        if req.link.is_file and not req.is_wheel_from_cache:
            message = ""Processing %s""
            information = str(display_path(req.link.file_path))
        else:
            message = ""Collecting %s""
            information = redact_auth_from_requirement(req.req) if req.req else str(req)

        
        
        if req.req and req.comes_from:
            if isinstance(req.comes_from, str):
                comes_from: str | None = req.comes_from
            else:
                comes_from = req.comes_from.from_path()
            if comes_from:
                information += f"" (from {comes_from})""

        if (message, information) != self._previous_requirement_header:
            self._previous_requirement_header = (message, information)
            logger.info(message, information)

        if req.is_wheel_from_cache:
            with indent_log():
                logger.info(""Using cached %s"", req.link.filename)

    def _ensure_link_req_src_dir(
        self, req: InstallRequirement, parallel_builds: bool
    ) -> None:
        
        
        if req.link.is_wheel:
            
            
            return
        assert req.source_dir is None
        if req.link.is_existing_dir():
            
            req.source_dir = req.link.file_path
            return

        
        req.ensure_has_source_dir(
            self.build_dir,
            autodelete=True,
            parallel_builds=parallel_builds,
        )
        req.ensure_pristine_source_checkout()

    def _get_linked_req_hashes(self, req: InstallRequirement) -> Hashes:
        
        
        
        
        
        if not self.require_hashes:
            return req.hashes(trust_internet=True)

        
        
        
        
        if req.link.is_vcs:
            raise VcsHashUnsupported()
        if req.link.is_existing_dir():
            raise DirectoryUrlHashUnsupported()

        
        
        
        
        
        if not req.is_direct and not req.is_pinned:
            raise HashUnpinned()

        
        
        
        
        return req.hashes(trust_internet=False) or MissingHashes()

    def _fetch_metadata_only(
        self,
        req: InstallRequirement,
    ) -> BaseDistribution | None:
        if self.legacy_resolver:
            logger.debug(
                ""Metadata-only fetching is not used in the legacy resolver"",
            )
            return None
        if self.require_hashes:
            logger.debug(
                ""Metadata-only fetching is not used as hash checking is required"",
            )
            return None
        
        return self._fetch_metadata_using_link_data_attr(
            req
        ) or self._fetch_metadata_using_lazy_wheel(req.link)

    def _fetch_metadata_using_link_data_attr(
        self,
        req: InstallRequirement,
    ) -> BaseDistribution | None:
        
        
        metadata_link = req.link.metadata_link()
        if metadata_link is None:
            return None
        assert req.req is not None
        logger.verbose(
            ""Obtaining dependency information for %s from %s"",
            req.req,
            metadata_link,
        )
        
        metadata_file = get_http_url(
            metadata_link,
            self._download,
            hashes=metadata_link.as_hashes(),
        )
        with open(metadata_file.path, ""rb"") as f:
            metadata_contents = f.read()
        
        metadata_dist = get_metadata_distribution(
            metadata_contents,
            req.link.filename,
            req.req.name,
        )
        
        
        
        
        
        
        if canonicalize_name(metadata_dist.raw_name) != canonicalize_name(req.req.name):
            raise MetadataInconsistent(
                req, ""Name"", req.req.name, metadata_dist.raw_name
            )
        return metadata_dist

    def _fetch_metadata_using_lazy_wheel(
        self,
        link: Link,
    ) -> BaseDistribution | None:
        
        
        if not self.use_lazy_wheel:
            return None
        if link.is_file or not link.is_wheel:
            logger.debug(
                ""Lazy wheel is not used as %r does not point to a remote wheel"",
                link,
            )
            return None

        wheel = Wheel(link.filename)
        name = canonicalize_name(wheel.name)
        logger.info(
            ""Obtaining dependency information from %s %s"",
            name,
            wheel.version,
        )
        url = link.url.split(""
        try:
            return dist_from_wheel_url(name, url, self._session)
        except HTTPRangeRequestUnsupported:
            logger.debug(""%s does not support range requests"", url)
            return None

    def _complete_partial_requirements(
        self,
        partially_downloaded_reqs: Iterable[InstallRequirement],
        parallel_builds: bool = False,
    ) -> None:
        
        
        
        temp_dir = TempDirectory(kind=""unpack"", globally_managed=True).path

        
        
        
        links_to_fully_download: dict[Link, InstallRequirement] = {}
        for req in partially_downloaded_reqs:
            assert req.link
            links_to_fully_download[req.link] = req

        batch_download = self._download.batch(links_to_fully_download.keys(), temp_dir)
        for link, (filepath, _) in batch_download:
            logger.debug(""Downloading link %s to %s"", link, filepath)
            req = links_to_fully_download[link]
            
            
            req.local_file_path = filepath
            
            
            self._downloaded[req.link.url] = filepath

            
            
            
            
            if not req.is_wheel:
                req.needs_unpacked_archive(Path(filepath))

        
        
        for req in partially_downloaded_reqs:
            self._prepare_linked_requirement(req, parallel_builds)

    def prepare_linked_requirement(
        self, req: InstallRequirement, parallel_builds: bool = False
    ) -> BaseDistribution:
        
        assert req.link
        self._log_preparing_link(req)
        with indent_log():
            
            
            file_path = None
            if self.download_dir is not None and req.link.is_wheel:
                hashes = self._get_linked_req_hashes(req)
                file_path = _check_download_dir(
                    req.link,
                    self.download_dir,
                    hashes,
                    
                    
                    
                    
                    
                    
                    warn_on_hash_mismatch=not req.is_wheel_from_cache,
                )

            if file_path is not None:
                
                self._downloaded[req.link.url] = file_path
            else:
                
                metadata_dist = self._fetch_metadata_only(req)
                if metadata_dist is not None:
                    req.needs_more_preparation = True
                    return metadata_dist

            
            return self._prepare_linked_requirement(req, parallel_builds)

    def prepare_linked_requirements_more(
        self, reqs: Iterable[InstallRequirement], parallel_builds: bool = False
    ) -> None:
        
        reqs = [req for req in reqs if req.needs_more_preparation]
        for req in reqs:
            
            if self.download_dir is not None and req.link.is_wheel:
                hashes = self._get_linked_req_hashes(req)
                file_path = _check_download_dir(req.link, self.download_dir, hashes)
                if file_path is not None:
                    self._downloaded[req.link.url] = file_path
                    req.needs_more_preparation = False

        
        
        partially_downloaded_reqs: list[InstallRequirement] = []
        for req in reqs:
            if req.needs_more_preparation:
                partially_downloaded_reqs.append(req)
            else:
                self._prepare_linked_requirement(req, parallel_builds)

        
        
        self._complete_partial_requirements(
            partially_downloaded_reqs,
            parallel_builds=parallel_builds,
        )

    def _prepare_linked_requirement(
        self, req: InstallRequirement, parallel_builds: bool
    ) -> BaseDistribution:
        assert req.link
        link = req.link

        hashes = self._get_linked_req_hashes(req)

        if hashes and req.is_wheel_from_cache:
            assert req.download_info is not None
            assert link.is_wheel
            assert link.is_file
            
            
            if (
                isinstance(req.download_info.info, ArchiveInfo)
                and req.download_info.info.hashes
                and hashes.has_one_of(req.download_info.info.hashes)
            ):
                
                
                
                
                hashes = None
            else:
                logger.warning(
                    ""The hashes of the source archive found in cache entry ""
                    ""don't match, ignoring cached built wheel ""
                    ""and re-downloading source.""
                )
                req.link = req.cached_wheel_source_link
                link = req.link

        self._ensure_link_req_src_dir(req, parallel_builds)

        if link.is_existing_dir():
            local_file = None
        elif link.url not in self._downloaded:
            try:
                local_file = unpack_url(
                    link,
                    req.source_dir,
                    self._download,
                    self.verbosity,
                    self.download_dir,
                    hashes,
                )
            except NetworkConnectionError as exc:
                raise InstallationError(
                    f""Could not install requirement {req} because of HTTP ""
                    f""error {exc} for URL {link}""
                )
        else:
            file_path = self._downloaded[link.url]
            if hashes:
                hashes.check_against_path(file_path)
            local_file = File(file_path, content_type=None)

        
        if req.download_info is None:
            
            
            assert not req.editable
            req.download_info = direct_url_from_link(link, req.source_dir)
            
            
            
            
            if (
                isinstance(req.download_info.info, ArchiveInfo)
                and not req.download_info.info.hashes
                and local_file
            ):
                hash = hash_file(local_file.path)[0].hexdigest()
                
                
                req.download_info.info.hash = f""sha256={hash}""

        
        
        if local_file:
            req.local_file_path = local_file.path

        dist = _get_prepared_distribution(
            req,
            self.build_tracker,
            self.build_env_installer,
            self.build_isolation,
            self.check_build_deps,
        )
        return dist

    def save_linked_requirement(self, req: InstallRequirement) -> None:
        assert self.download_dir is not None
        assert req.link is not None
        link = req.link
        if link.is_vcs or (link.is_existing_dir() and req.editable):
            
            req.archive(self.download_dir)
            return

        if link.is_existing_dir():
            logger.debug(
                ""Not copying link to destination directory ""
                ""since it is a directory: %s"",
                link,
            )
            return
        if req.local_file_path is None:
            
            return

        download_location = os.path.join(self.download_dir, link.filename)
        if not os.path.exists(download_location):
            shutil.copy(req.local_file_path, download_location)
            download_path = display_path(download_location)
            logger.info(""Saved %s"", download_path)

    def prepare_editable_requirement(
        self,
        req: InstallRequirement,
    ) -> BaseDistribution:
        
        assert req.editable, ""cannot prepare a non-editable req as editable""

        logger.info(""Obtaining %s"", req)

        with indent_log():
            if self.require_hashes:
                raise InstallationError(
                    f""The editable requirement {req} cannot be installed when ""
                    ""requiring hashes, because there is no single file to ""
                    ""hash.""
                )
            req.ensure_has_source_dir(self.src_dir)
            req.update_editable()
            assert req.source_dir
            req.download_info = direct_url_for_editable(req.unpacked_source_directory)

            dist = _get_prepared_distribution(
                req,
                self.build_tracker,
                self.build_env_installer,
                self.build_isolation,
                self.check_build_deps,
            )

            req.check_if_exists(self.use_user_site)

        return dist

    def prepare_installed_requirement(
        self,
        req: InstallRequirement,
        skip_reason: str,
    ) -> BaseDistribution:
        
        assert req.satisfied_by, ""req should have been satisfied but isn't""
        assert skip_reason is not None, (
            ""did not get skip reason skipped but req.satisfied_by ""
            f""is set to {req.satisfied_by}""
        )
        logger.info(
            ""Requirement %s: %s (%s)"", skip_reason, req, req.satisfied_by.version
        )
        with indent_log():
            if self.require_hashes:
                logger.debug(
                    ""Since it is already installed, we are trusting this ""
                    ""package without checking its hash. To ensure a ""
                    ""completely repeatable environment, install into an ""
                    ""empty virtualenv.""
                )
            return InstalledDistribution(req).get_metadata_distribution()


from __future__ import annotations

import contextlib
import hashlib
import logging
import os
from collections.abc import Generator
from types import TracebackType

from pip._internal.req.req_install import InstallRequirement
from pip._internal.utils.temp_dir import TempDirectory

logger = logging.getLogger(__name__)


@contextlib.contextmanager
def update_env_context_manager(**changes: str) -> Generator[None, None, None]:
    target = os.environ

    
    non_existent_marker = object()
    saved_values: dict[str, object | str] = {}
    for name, new_value in changes.items():
        try:
            saved_values[name] = target[name]
        except KeyError:
            saved_values[name] = non_existent_marker
        target[name] = new_value

    try:
        yield
    finally:
        
        for name, original_value in saved_values.items():
            if original_value is non_existent_marker:
                del target[name]
            else:
                assert isinstance(original_value, str)  
                target[name] = original_value


@contextlib.contextmanager
def get_build_tracker() -> Generator[BuildTracker, None, None]:
    root = os.environ.get(""PIP_BUILD_TRACKER"")
    with contextlib.ExitStack() as ctx:
        if root is None:
            root = ctx.enter_context(TempDirectory(kind=""build-tracker"")).path
            ctx.enter_context(update_env_context_manager(PIP_BUILD_TRACKER=root))
            logger.debug(""Initialized build tracking at %s"", root)

        with BuildTracker(root) as tracker:
            yield tracker


class TrackerId(str):
    


class BuildTracker:
    

    def __init__(self, root: str) -> None:
        self._root = root
        self._entries: dict[TrackerId, InstallRequirement] = {}
        logger.debug(""Created build tracker: %s"", self._root)

    def __enter__(self) -> BuildTracker:
        logger.debug(""Entered build tracker: %s"", self._root)
        return self

    def __exit__(
        self,
        exc_type: type[BaseException] | None,
        exc_val: BaseException | None,
        exc_tb: TracebackType | None,
    ) -> None:
        self.cleanup()

    def _entry_path(self, key: TrackerId) -> str:
        hashed = hashlib.sha224(key.encode()).hexdigest()
        return os.path.join(self._root, hashed)

    def add(self, req: InstallRequirement, key: TrackerId) -> None:
        

        
        entry_path = self._entry_path(key)

        
        
        try:
            with open(entry_path) as fp:
                contents = fp.read()
        except FileNotFoundError:
            pass
        else:
            message = f""{req.link} is already being built: {contents}""
            raise LookupError(message)

        
        assert key not in self._entries

        
        with open(entry_path, ""w"", encoding=""utf-8"") as fp:
            fp.write(str(req))
        self._entries[key] = req

        logger.debug(""Added %s to build tracker %r"", req, self._root)

    def remove(self, req: InstallRequirement, key: TrackerId) -> None:
        

        
        os.unlink(self._entry_path(key))
        del self._entries[key]

        logger.debug(""Removed %s from build tracker %r"", req, self._root)

    def cleanup(self) -> None:
        for key, req in list(self._entries.items()):
            self.remove(req, key)

        logger.debug(""Removed build tracker: %r"", self._root)

    @contextlib.contextmanager
    def track(self, req: InstallRequirement, key: str) -> Generator[None, None, None]:
        
        tracker_id = TrackerId(key)
        self.add(req, tracker_id)
        yield
        self.remove(req, tracker_id)



import os

from pip._vendor.pyproject_hooks import BuildBackendHookCaller

from pip._internal.build_env import BuildEnvironment
from pip._internal.exceptions import (
    InstallationSubprocessError,
    MetadataGenerationFailed,
)
from pip._internal.utils.subprocess import runner_with_spinner_message
from pip._internal.utils.temp_dir import TempDirectory


def generate_metadata(
    build_env: BuildEnvironment, backend: BuildBackendHookCaller, details: str
) -> str:
    
    metadata_tmpdir = TempDirectory(kind=""modern-metadata"", globally_managed=True)

    metadata_dir = metadata_tmpdir.path

    with build_env:
        
        
        
        runner = runner_with_spinner_message(""Preparing metadata (pyproject.toml)"")
        with backend.subprocess_runner(runner):
            try:
                distinfo_dir = backend.prepare_metadata_for_build_wheel(metadata_dir)
            except InstallationSubprocessError as error:
                raise MetadataGenerationFailed(package_details=details) from error

    return os.path.join(metadata_dir, distinfo_dir)



import os

from pip._vendor.pyproject_hooks import BuildBackendHookCaller

from pip._internal.build_env import BuildEnvironment
from pip._internal.exceptions import (
    InstallationSubprocessError,
    MetadataGenerationFailed,
)
from pip._internal.utils.subprocess import runner_with_spinner_message
from pip._internal.utils.temp_dir import TempDirectory


def generate_editable_metadata(
    build_env: BuildEnvironment, backend: BuildBackendHookCaller, details: str
) -> str:
    
    metadata_tmpdir = TempDirectory(kind=""modern-metadata"", globally_managed=True)

    metadata_dir = metadata_tmpdir.path

    with build_env:
        
        
        
        runner = runner_with_spinner_message(
            ""Preparing editable metadata (pyproject.toml)""
        )
        with backend.subprocess_runner(runner):
            try:
                distinfo_dir = backend.prepare_metadata_for_build_editable(metadata_dir)
            except InstallationSubprocessError as error:
                raise MetadataGenerationFailed(package_details=details) from error

    assert distinfo_dir is not None
    return os.path.join(metadata_dir, distinfo_dir)



import logging
import os

from pip._internal.build_env import BuildEnvironment
from pip._internal.cli.spinners import open_spinner
from pip._internal.exceptions import (
    InstallationError,
    InstallationSubprocessError,
    MetadataGenerationFailed,
)
from pip._internal.utils.setuptools_build import make_setuptools_egg_info_args
from pip._internal.utils.subprocess import call_subprocess
from pip._internal.utils.temp_dir import TempDirectory

logger = logging.getLogger(__name__)


def _find_egg_info(directory: str) -> str:
    
    filenames = [f for f in os.listdir(directory) if f.endswith("".egg-info"")]

    if not filenames:
        raise InstallationError(f""No .egg-info directory found in {directory}"")

    if len(filenames) > 1:
        raise InstallationError(
            f""More than one .egg-info directory found in {directory}""
        )

    return os.path.join(directory, filenames[0])


def generate_metadata(
    build_env: BuildEnvironment,
    setup_py_path: str,
    source_dir: str,
    isolated: bool,
    details: str,
) -> str:
    
    logger.debug(
        ""Running setup.py (path:%s) egg_info for package %s"",
        setup_py_path,
        details,
    )

    egg_info_dir = TempDirectory(kind=""pip-egg-info"", globally_managed=True).path

    args = make_setuptools_egg_info_args(
        setup_py_path,
        egg_info_dir=egg_info_dir,
        no_user_config=isolated,
    )

    with build_env:
        with open_spinner(""Preparing metadata (setup.py)"") as spinner:
            try:
                call_subprocess(
                    args,
                    cwd=source_dir,
                    command_desc=""python setup.py egg_info"",
                    spinner=spinner,
                )
            except InstallationSubprocessError as error:
                raise MetadataGenerationFailed(package_details=details) from error

    
    return _find_egg_info(egg_info_dir)

from __future__ import annotations

import logging
import os

from pip._vendor.pyproject_hooks import BuildBackendHookCaller

from pip._internal.utils.subprocess import runner_with_spinner_message

logger = logging.getLogger(__name__)


def build_wheel_pep517(
    name: str,
    backend: BuildBackendHookCaller,
    metadata_directory: str,
    tempd: str,
) -> str | None:
    
    assert metadata_directory is not None
    try:
        logger.debug(""Destination directory: %s"", tempd)

        runner = runner_with_spinner_message(
            f""Building wheel for {name} (pyproject.toml)""
        )
        with backend.subprocess_runner(runner):
            wheel_name = backend.build_wheel(
                tempd,
                metadata_directory=metadata_directory,
            )
    except Exception:
        logger.error(""Failed building wheel for %s"", name)
        return None
    return os.path.join(tempd, wheel_name)

from __future__ import annotations

import logging
import os

from pip._vendor.pyproject_hooks import BuildBackendHookCaller, HookMissing

from pip._internal.utils.subprocess import runner_with_spinner_message

logger = logging.getLogger(__name__)


def build_wheel_editable(
    name: str,
    backend: BuildBackendHookCaller,
    metadata_directory: str,
    tempd: str,
) -> str | None:
    
    assert metadata_directory is not None
    try:
        logger.debug(""Destination directory: %s"", tempd)

        runner = runner_with_spinner_message(
            f""Building editable for {name} (pyproject.toml)""
        )
        with backend.subprocess_runner(runner):
            try:
                wheel_name = backend.build_editable(
                    tempd,
                    metadata_directory=metadata_directory,
                )
            except HookMissing as e:
                logger.error(
                    ""Cannot build editable %s because the build ""
                    ""backend does not have the %s hook"",
                    name,
                    e,
                )
                return None
    except Exception:
        logger.error(""Failed building editable for %s"", name)
        return None
    return os.path.join(tempd, wheel_name)

from __future__ import annotations

import logging
import os.path

from pip._internal.cli.spinners import open_spinner
from pip._internal.utils.deprecation import deprecated
from pip._internal.utils.setuptools_build import make_setuptools_bdist_wheel_args
from pip._internal.utils.subprocess import call_subprocess, format_command_args

logger = logging.getLogger(__name__)


def format_command_result(
    command_args: list[str],
    command_output: str,
) -> str:
    
    command_desc = format_command_args(command_args)
    text = f""Command arguments: {command_desc}\n""

    if not command_output:
        text += ""Command output: None""
    elif logger.getEffectiveLevel() > logging.DEBUG:
        text += ""Command output: [use --verbose to show]""
    else:
        if not command_output.endswith(""\n""):
            command_output += ""\n""
        text += f""Command output:\n{command_output}""

    return text


def get_legacy_build_wheel_path(
    names: list[str],
    temp_dir: str,
    name: str,
    command_args: list[str],
    command_output: str,
) -> str | None:
    
    
    names = sorted(names)
    if not names:
        msg = f""Legacy build of wheel for {name!r} created no files.\n""
        msg += format_command_result(command_args, command_output)
        logger.warning(msg)
        return None

    if len(names) > 1:
        msg = (
            f""Legacy build of wheel for {name!r} created more than one file.\n""
            f""Filenames (choosing first): {names}\n""
        )
        msg += format_command_result(command_args, command_output)
        logger.warning(msg)

    return os.path.join(temp_dir, names[0])


def build_wheel_legacy(
    name: str,
    setup_py_path: str,
    source_dir: str,
    global_options: list[str],
    build_options: list[str],
    tempd: str,
) -> str | None:
    
    deprecated(
        reason=(
            f""Building {name!r} using the legacy setup.py bdist_wheel mechanism, ""
            ""which will be removed in a future version.""
        ),
        replacement=(
            ""to use the standardized build interface by ""
            ""setting the `--use-pep517` option, ""
            ""(possibly combined with `--no-build-isolation`), ""
            f""or adding a `pyproject.toml` file to the source tree of {name!r}""
        ),
        gone_in=""25.3"",
        issue=6334,
    )

    wheel_args = make_setuptools_bdist_wheel_args(
        setup_py_path,
        global_options=global_options,
        build_options=build_options,
        destination_dir=tempd,
    )

    spin_message = f""Building wheel for {name} (setup.py)""
    with open_spinner(spin_message) as spinner:
        logger.debug(""Destination directory: %s"", tempd)

        try:
            output = call_subprocess(
                wheel_args,
                command_desc=""python setup.py bdist_wheel"",
                cwd=source_dir,
                spinner=spinner,
            )
        except Exception:
            spinner.finish(""error"")
            logger.error(""Failed building wheel for %s"", name)
            return None

        names = os.listdir(tempd)
        wheel_path = get_legacy_build_wheel_path(
            names=names,
            temp_dir=tempd,
            name=name,
            command_args=wheel_args,
            command_output=output,
        )
        return wheel_path




from __future__ import annotations

import logging
from collections.abc import Sequence

from pip._internal.build_env import BuildEnvironment
from pip._internal.utils.logging import indent_log
from pip._internal.utils.setuptools_build import make_setuptools_develop_args
from pip._internal.utils.subprocess import call_subprocess

logger = logging.getLogger(__name__)


def install_editable(
    *,
    global_options: Sequence[str],
    prefix: str | None,
    home: str | None,
    use_user_site: bool,
    name: str,
    setup_py_path: str,
    isolated: bool,
    build_env: BuildEnvironment,
    unpacked_source_directory: str,
) -> None:
    
    logger.info(""Running setup.py develop for %s"", name)

    args = make_setuptools_develop_args(
        setup_py_path,
        global_options=global_options,
        no_user_config=isolated,
        prefix=prefix,
        home=home,
        use_user_site=use_user_site,
    )

    with indent_log():
        with build_env:
            call_subprocess(
                args,
                command_desc=""python setup.py develop"",
                cwd=unpacked_source_directory,
            )



from __future__ import annotations

import collections
import compileall
import contextlib
import csv
import importlib
import logging
import os.path
import re
import shutil
import sys
import textwrap
import warnings
from base64 import urlsafe_b64encode
from collections.abc import Generator, Iterable, Iterator, Sequence
from email.message import Message
from itertools import chain, filterfalse, starmap
from typing import (
    IO,
    Any,
    BinaryIO,
    Callable,
    NewType,
    Protocol,
    Union,
    cast,
)
from zipfile import ZipFile, ZipInfo

from pip._vendor.distlib.scripts import ScriptMaker
from pip._vendor.distlib.util import get_export_entry
from pip._vendor.packaging.utils import canonicalize_name

from pip._internal.exceptions import InstallationError
from pip._internal.locations import get_major_minor_version
from pip._internal.metadata import (
    BaseDistribution,
    FilesystemWheel,
    get_wheel_distribution,
)
from pip._internal.models.direct_url import DIRECT_URL_METADATA_NAME, DirectUrl
from pip._internal.models.scheme import SCHEME_KEYS, Scheme
from pip._internal.utils.filesystem import adjacent_tmp_file, replace
from pip._internal.utils.misc import StreamWrapper, ensure_dir, hash_file, partition
from pip._internal.utils.unpacking import (
    current_umask,
    is_within_directory,
    set_extracted_file_to_default_mode_plus_executable,
    zip_item_is_executable,
)
from pip._internal.utils.wheel import parse_wheel


class File(Protocol):
    src_record_path: RecordPath
    dest_path: str
    changed: bool

    def save(self) -> None:
        pass


logger = logging.getLogger(__name__)

RecordPath = NewType(""RecordPath"", str)
InstalledCSVRow = tuple[RecordPath, str, Union[int, str]]


def rehash(path: str, blocksize: int = 1 << 20) -> tuple[str, str]:
    
    h, length = hash_file(path, blocksize)
    digest = ""sha256="" + urlsafe_b64encode(h.digest()).decode(""latin1"").rstrip(""="")
    return (digest, str(length))


def csv_io_kwargs(mode: str) -> dict[str, Any]:
    
    return {""mode"": mode, ""newline"": """", ""encoding"": ""utf-8""}


def fix_script(path: str) -> bool:
    
    
    assert os.path.isfile(path)

    with open(path, ""rb"") as script:
        firstline = script.readline()
        if not firstline.startswith(b""
            return False
        exename = sys.executable.encode(sys.getfilesystemencoding())
        firstline = b""
        rest = script.read()
    with open(path, ""wb"") as script:
        script.write(firstline)
        script.write(rest)
    return True


def wheel_root_is_purelib(metadata: Message) -> bool:
    return metadata.get(""Root-Is-Purelib"", """").lower() == ""true""


def get_entrypoints(dist: BaseDistribution) -> tuple[dict[str, str], dict[str, str]]:
    console_scripts = {}
    gui_scripts = {}
    for entry_point in dist.iter_entry_points():
        if entry_point.group == ""console_scripts"":
            console_scripts[entry_point.name] = entry_point.value
        elif entry_point.group == ""gui_scripts"":
            gui_scripts[entry_point.name] = entry_point.value
    return console_scripts, gui_scripts


def message_about_scripts_not_on_PATH(scripts: Sequence[str]) -> str | None:
    
    if not scripts:
        return None

    
    grouped_by_dir: dict[str, set[str]] = collections.defaultdict(set)
    for destfile in scripts:
        parent_dir = os.path.dirname(destfile)
        script_name = os.path.basename(destfile)
        grouped_by_dir[parent_dir].add(script_name)

    
    not_warn_dirs = [
        os.path.normcase(os.path.normpath(i)).rstrip(os.sep)
        for i in os.environ.get(""PATH"", """").split(os.pathsep)
    ]
    
    
    not_warn_dirs.append(
        os.path.normcase(os.path.normpath(os.path.dirname(sys.executable)))
    )
    warn_for: dict[str, set[str]] = {
        parent_dir: scripts
        for parent_dir, scripts in grouped_by_dir.items()
        if os.path.normcase(os.path.normpath(parent_dir)) not in not_warn_dirs
    }
    if not warn_for:
        return None

    
    msg_lines = []
    for parent_dir, dir_scripts in warn_for.items():
        sorted_scripts: list[str] = sorted(dir_scripts)
        if len(sorted_scripts) == 1:
            start_text = f""script {sorted_scripts[0]} is""
        else:
            start_text = ""scripts {} are"".format(
                "", "".join(sorted_scripts[:-1]) + "" and "" + sorted_scripts[-1]
            )

        msg_lines.append(
            f""The {start_text} installed in '{parent_dir}' which is not on PATH.""
        )

    last_line_fmt = (
        ""Consider adding {} to PATH or, if you prefer ""
        ""to suppress this warning, use --no-warn-script-location.""
    )
    if len(msg_lines) == 1:
        msg_lines.append(last_line_fmt.format(""this directory""))
    else:
        msg_lines.append(last_line_fmt.format(""these directories""))

    
    warn_for_tilde = any(
        i[0] == ""~"" for i in os.environ.get(""PATH"", """").split(os.pathsep) if i
    )
    if warn_for_tilde:
        tilde_warning_msg = (
            ""NOTE: The current PATH contains path(s) starting with `~`, ""
            ""which may not be expanded by all applications.""
        )
        msg_lines.append(tilde_warning_msg)

    
    return ""\n"".join(msg_lines)


def _normalized_outrows(
    outrows: Iterable[InstalledCSVRow],
) -> list[tuple[str, str, str]]:
    
    
    
    
    
    
    
    
    
    return sorted(
        (record_path, hash_, str(size)) for record_path, hash_, size in outrows
    )


def _record_to_fs_path(record_path: RecordPath, lib_dir: str) -> str:
    return os.path.join(lib_dir, record_path)


def _fs_to_record_path(path: str, lib_dir: str) -> RecordPath:
    
    
    if os.path.splitdrive(path)[0].lower() == os.path.splitdrive(lib_dir)[0].lower():
        path = os.path.relpath(path, lib_dir)

    path = path.replace(os.path.sep, ""/"")
    return cast(""RecordPath"", path)


def get_csv_rows_for_installed(
    old_csv_rows: list[list[str]],
    installed: dict[RecordPath, RecordPath],
    changed: set[RecordPath],
    generated: list[str],
    lib_dir: str,
) -> list[InstalledCSVRow]:
    
    installed_rows: list[InstalledCSVRow] = []
    for row in old_csv_rows:
        if len(row) > 3:
            logger.warning(""RECORD line has more than three elements: %s"", row)
        old_record_path = cast(""RecordPath"", row[0])
        new_record_path = installed.pop(old_record_path, old_record_path)
        if new_record_path in changed:
            digest, length = rehash(_record_to_fs_path(new_record_path, lib_dir))
        else:
            digest = row[1] if len(row) > 1 else """"
            length = row[2] if len(row) > 2 else """"
        installed_rows.append((new_record_path, digest, length))
    for f in generated:
        path = _fs_to_record_path(f, lib_dir)
        digest, length = rehash(f)
        installed_rows.append((path, digest, length))
    return installed_rows + [
        (installed_record_path, """", """") for installed_record_path in installed.values()
    ]


def get_console_script_specs(console: dict[str, str]) -> list[str]:
    
    
    console = console.copy()

    scripts_to_generate = []

    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    pip_script = console.pop(""pip"", None)
    if pip_script:
        if ""ENSUREPIP_OPTIONS"" not in os.environ:
            scripts_to_generate.append(""pip = "" + pip_script)

        if os.environ.get(""ENSUREPIP_OPTIONS"", """") != ""altinstall"":
            scripts_to_generate.append(f""pip{sys.version_info[0]} = {pip_script}"")

        scripts_to_generate.append(f""pip{get_major_minor_version()} = {pip_script}"")
        
        pip_ep = [k for k in console if re.match(r""pip(\d+(\.\d+)?)?$"", k)]
        for k in pip_ep:
            del console[k]
    easy_install_script = console.pop(""easy_install"", None)
    if easy_install_script:
        if ""ENSUREPIP_OPTIONS"" not in os.environ:
            scripts_to_generate.append(""easy_install = "" + easy_install_script)

        scripts_to_generate.append(
            f""easy_install-{get_major_minor_version()} = {easy_install_script}""
        )
        
        easy_install_ep = [
            k for k in console if re.match(r""easy_install(-\d+\.\d+)?$"", k)
        ]
        for k in easy_install_ep:
            del console[k]

    
    scripts_to_generate.extend(starmap(""{} = {}"".format, console.items()))

    return scripts_to_generate


class ZipBackedFile:
    def __init__(
        self, src_record_path: RecordPath, dest_path: str, zip_file: ZipFile
    ) -> None:
        self.src_record_path = src_record_path
        self.dest_path = dest_path
        self._zip_file = zip_file
        self.changed = False

    def _getinfo(self) -> ZipInfo:
        return self._zip_file.getinfo(self.src_record_path)

    def save(self) -> None:
        
        
        
        
        
        
        
        
        if os.path.exists(self.dest_path):
            os.unlink(self.dest_path)

        zipinfo = self._getinfo()

        
        
        with open(self.dest_path, ""wb"") as dest:
            if zipinfo.file_size > 0:
                with self._zip_file.open(zipinfo) as f:
                    blocksize = min(zipinfo.file_size, 1024 * 1024)
                    shutil.copyfileobj(f, dest, blocksize)

        if zip_item_is_executable(zipinfo):
            set_extracted_file_to_default_mode_plus_executable(self.dest_path)


class ScriptFile:
    def __init__(self, file: File) -> None:
        self._file = file
        self.src_record_path = self._file.src_record_path
        self.dest_path = self._file.dest_path
        self.changed = False

    def save(self) -> None:
        self._file.save()
        self.changed = fix_script(self.dest_path)


class MissingCallableSuffix(InstallationError):
    def __init__(self, entry_point: str) -> None:
        super().__init__(
            f""Invalid script entry point: {entry_point} - A callable ""
            ""suffix is required. See https://packaging.python.org/""
            ""specifications/entry-points/
            ""information.""
        )


def _raise_for_invalid_entrypoint(specification: str) -> None:
    entry = get_export_entry(specification)
    if entry is not None and entry.suffix is None:
        raise MissingCallableSuffix(str(entry))


class PipScriptMaker(ScriptMaker):
    
    
    script_template = textwrap.dedent(
        
    )

    def make(
        self, specification: str, options: dict[str, Any] | None = None
    ) -> list[str]:
        _raise_for_invalid_entrypoint(specification)
        return super().make(specification, options)


def _install_wheel(  
    name: str,
    wheel_zip: ZipFile,
    wheel_path: str,
    scheme: Scheme,
    pycompile: bool = True,
    warn_script_location: bool = True,
    direct_url: DirectUrl | None = None,
    requested: bool = False,
) -> None:
    
    info_dir, metadata = parse_wheel(wheel_zip, name)

    if wheel_root_is_purelib(metadata):
        lib_dir = scheme.purelib
    else:
        lib_dir = scheme.platlib

    
    
    
    
    installed: dict[RecordPath, RecordPath] = {}
    changed: set[RecordPath] = set()
    generated: list[str] = []

    def record_installed(
        srcfile: RecordPath, destfile: str, modified: bool = False
    ) -> None:
        
        newpath = _fs_to_record_path(destfile, lib_dir)
        installed[srcfile] = newpath
        if modified:
            changed.add(newpath)

    def is_dir_path(path: RecordPath) -> bool:
        return path.endswith(""/"")

    def assert_no_path_traversal(dest_dir_path: str, target_path: str) -> None:
        if not is_within_directory(dest_dir_path, target_path):
            message = (
                ""The wheel {!r} has a file {!r} trying to install""
                "" outside the target directory {!r}""
            )
            raise InstallationError(
                message.format(wheel_path, target_path, dest_dir_path)
            )

    def root_scheme_file_maker(
        zip_file: ZipFile, dest: str
    ) -> Callable[[RecordPath], File]:
        def make_root_scheme_file(record_path: RecordPath) -> File:
            normed_path = os.path.normpath(record_path)
            dest_path = os.path.join(dest, normed_path)
            assert_no_path_traversal(dest, dest_path)
            return ZipBackedFile(record_path, dest_path, zip_file)

        return make_root_scheme_file

    def data_scheme_file_maker(
        zip_file: ZipFile, scheme: Scheme
    ) -> Callable[[RecordPath], File]:
        scheme_paths = {key: getattr(scheme, key) for key in SCHEME_KEYS}

        def make_data_scheme_file(record_path: RecordPath) -> File:
            normed_path = os.path.normpath(record_path)
            try:
                _, scheme_key, dest_subpath = normed_path.split(os.path.sep, 2)
            except ValueError:
                message = (
                    f""Unexpected file in {wheel_path}: {record_path!r}. .data directory""
                    "" contents should be named like: '<scheme key>/<path>'.""
                )
                raise InstallationError(message)

            try:
                scheme_path = scheme_paths[scheme_key]
            except KeyError:
                valid_scheme_keys = "", "".join(sorted(scheme_paths))
                message = (
                    f""Unknown scheme key used in {wheel_path}: {scheme_key} ""
                    f""(for file {record_path!r}). .data directory contents ""
                    f""should be in subdirectories named with a valid scheme ""
                    f""key ({valid_scheme_keys})""
                )
                raise InstallationError(message)

            dest_path = os.path.join(scheme_path, dest_subpath)
            assert_no_path_traversal(scheme_path, dest_path)
            return ZipBackedFile(record_path, dest_path, zip_file)

        return make_data_scheme_file

    def is_data_scheme_path(path: RecordPath) -> bool:
        return path.split(""/"", 1)[0].endswith("".data"")

    paths = cast(list[RecordPath], wheel_zip.namelist())
    file_paths = filterfalse(is_dir_path, paths)
    root_scheme_paths, data_scheme_paths = partition(is_data_scheme_path, file_paths)

    make_root_scheme_file = root_scheme_file_maker(wheel_zip, lib_dir)
    files: Iterator[File] = map(make_root_scheme_file, root_scheme_paths)

    def is_script_scheme_path(path: RecordPath) -> bool:
        parts = path.split(""/"", 2)
        return len(parts) > 2 and parts[0].endswith("".data"") and parts[1] == ""scripts""

    other_scheme_paths, script_scheme_paths = partition(
        is_script_scheme_path, data_scheme_paths
    )

    make_data_scheme_file = data_scheme_file_maker(wheel_zip, scheme)
    other_scheme_files = map(make_data_scheme_file, other_scheme_paths)
    files = chain(files, other_scheme_files)

    
    distribution = get_wheel_distribution(
        FilesystemWheel(wheel_path),
        canonicalize_name(name),
    )
    console, gui = get_entrypoints(distribution)

    def is_entrypoint_wrapper(file: File) -> bool:
        
        
        path = file.dest_path
        name = os.path.basename(path)
        if name.lower().endswith("".exe""):
            matchname = name[:-4]
        elif name.lower().endswith(""-script.py""):
            matchname = name[:-10]
        elif name.lower().endswith("".pya""):
            matchname = name[:-4]
        else:
            matchname = name
        
        return matchname in console or matchname in gui

    script_scheme_files: Iterator[File] = map(
        make_data_scheme_file, script_scheme_paths
    )
    script_scheme_files = filterfalse(is_entrypoint_wrapper, script_scheme_files)
    script_scheme_files = map(ScriptFile, script_scheme_files)
    files = chain(files, script_scheme_files)

    existing_parents = set()
    for file in files:
        
        
        
        parent_dir = os.path.dirname(file.dest_path)
        if parent_dir not in existing_parents:
            ensure_dir(parent_dir)
            existing_parents.add(parent_dir)
        file.save()
        record_installed(file.src_record_path, file.dest_path, file.changed)

    def pyc_source_file_paths() -> Generator[str, None, None]:
        
        
        
        
        for installed_path in sorted(set(installed.values())):
            full_installed_path = os.path.join(lib_dir, installed_path)
            if not os.path.isfile(full_installed_path):
                continue
            if not full_installed_path.endswith("".py""):
                continue
            yield full_installed_path

    def pyc_output_path(path: str) -> str:
        
        return importlib.util.cache_from_source(path)

    
    if pycompile:
        with contextlib.redirect_stdout(
            StreamWrapper.from_stream(sys.stdout)
        ) as stdout:
            with warnings.catch_warnings():
                warnings.filterwarnings(""ignore"")
                for path in pyc_source_file_paths():
                    success = compileall.compile_file(path, force=True, quiet=True)
                    if success:
                        pyc_path = pyc_output_path(path)
                        assert os.path.exists(pyc_path)
                        pyc_record_path = cast(
                            ""RecordPath"", pyc_path.replace(os.path.sep, ""/"")
                        )
                        record_installed(pyc_record_path, pyc_path)
        logger.debug(stdout.getvalue())

    maker = PipScriptMaker(None, scheme.scripts)

    
    
    maker.clobber = True

    
    
    
    maker.variants = {""""}

    
    
    
    maker.set_mode = True

    
    scripts_to_generate = get_console_script_specs(console)

    gui_scripts_to_generate = list(starmap(""{} = {}"".format, gui.items()))

    generated_console_scripts = maker.make_multiple(scripts_to_generate)
    generated.extend(generated_console_scripts)

    generated.extend(maker.make_multiple(gui_scripts_to_generate, {""gui"": True}))

    if warn_script_location:
        msg = message_about_scripts_not_on_PATH(generated_console_scripts)
        if msg is not None:
            logger.warning(msg)

    generated_file_mode = 0o666 & ~current_umask()

    @contextlib.contextmanager
    def _generate_file(path: str, **kwargs: Any) -> Generator[BinaryIO, None, None]:
        with adjacent_tmp_file(path, **kwargs) as f:
            yield f
        os.chmod(f.name, generated_file_mode)
        replace(f.name, path)

    dest_info_dir = os.path.join(lib_dir, info_dir)

    
    installer_path = os.path.join(dest_info_dir, ""INSTALLER"")
    with _generate_file(installer_path) as installer_file:
        installer_file.write(b""pip\n"")
    generated.append(installer_path)

    
    if direct_url is not None:
        direct_url_path = os.path.join(dest_info_dir, DIRECT_URL_METADATA_NAME)
        with _generate_file(direct_url_path) as direct_url_file:
            direct_url_file.write(direct_url.to_json().encode(""utf-8""))
        generated.append(direct_url_path)

    
    if requested:
        requested_path = os.path.join(dest_info_dir, ""REQUESTED"")
        with open(requested_path, ""wb""):
            pass
        generated.append(requested_path)

    record_text = distribution.read_text(""RECORD"")
    record_rows = list(csv.reader(record_text.splitlines()))

    rows = get_csv_rows_for_installed(
        record_rows,
        installed=installed,
        changed=changed,
        generated=generated,
        lib_dir=lib_dir,
    )

    
    record_path = os.path.join(dest_info_dir, ""RECORD"")

    with _generate_file(record_path, **csv_io_kwargs(""w"")) as record_file:
        
        
        writer = csv.writer(cast(""IO[str]"", record_file))
        writer.writerows(_normalized_outrows(rows))


@contextlib.contextmanager
def req_error_context(req_description: str) -> Generator[None, None, None]:
    try:
        yield
    except InstallationError as e:
        message = f""For req: {req_description}. {e.args[0]}""
        raise InstallationError(message) from e


def install_wheel(
    name: str,
    wheel_path: str,
    scheme: Scheme,
    req_description: str,
    pycompile: bool = True,
    warn_script_location: bool = True,
    direct_url: DirectUrl | None = None,
    requested: bool = False,
) -> None:
    with ZipFile(wheel_path, allowZip64=True) as z:
        with req_error_context(req_description):
            _install_wheel(
                name=name,
                wheel_zip=z,
                wheel_path=wheel_path,
                scheme=scheme,
                pycompile=pycompile,
                warn_script_location=warn_script_location,
                direct_url=direct_url,
                requested=requested,
            )





from __future__ import annotations

import copy
import logging
import os
import re
from collections.abc import Collection
from dataclasses import dataclass

from pip._vendor.packaging.markers import Marker
from pip._vendor.packaging.requirements import InvalidRequirement, Requirement
from pip._vendor.packaging.specifiers import Specifier

from pip._internal.exceptions import InstallationError
from pip._internal.models.index import PyPI, TestPyPI
from pip._internal.models.link import Link
from pip._internal.models.wheel import Wheel
from pip._internal.req.req_file import ParsedRequirement
from pip._internal.req.req_install import InstallRequirement
from pip._internal.utils.filetypes import is_archive_file
from pip._internal.utils.misc import is_installable_dir
from pip._internal.utils.packaging import get_requirement
from pip._internal.utils.urls import path_to_url
from pip._internal.vcs import is_url, vcs

__all__ = [
    ""install_req_from_editable"",
    ""install_req_from_line"",
    ""parse_editable"",
]

logger = logging.getLogger(__name__)
operators = Specifier._operators.keys()


def _strip_extras(path: str) -> tuple[str, str | None]:
    m = re.match(r""^(.+)(\[[^\]]+\])$"", path)
    extras = None
    if m:
        path_no_extras = m.group(1)
        extras = m.group(2)
    else:
        path_no_extras = path

    return path_no_extras, extras


def convert_extras(extras: str | None) -> set[str]:
    if not extras:
        return set()
    return get_requirement(""placeholder"" + extras.lower()).extras


def _set_requirement_extras(req: Requirement, new_extras: set[str]) -> Requirement:
    
    match: re.Match[str] | None = re.fullmatch(
        
        r""([\w\t .-]+)(\[[^\]]*\])?(.*)"",
        str(req),
        flags=re.ASCII,
    )
    
    assert (
        match is not None
    ), f""regex match on requirement {req} failed, this should never happen""
    pre: str | None = match.group(1)
    post: str | None = match.group(3)
    assert (
        pre is not None and post is not None
    ), f""regex group selection for requirement {req} failed, this should never happen""
    extras: str = ""[{}]"".format("","".join(sorted(new_extras)) if new_extras else """")
    return get_requirement(f""{pre}{extras}{post}"")


def parse_editable(editable_req: str) -> tuple[str | None, str, set[str]]:
    

    url = editable_req

    
    url_no_extras, extras = _strip_extras(url)

    if os.path.isdir(url_no_extras):
        
        url_no_extras = path_to_url(url_no_extras)

    if url_no_extras.lower().startswith(""file:""):
        package_name = Link(url_no_extras).egg_fragment
        if extras:
            return (
                package_name,
                url_no_extras,
                get_requirement(""placeholder"" + extras.lower()).extras,
            )
        else:
            return package_name, url_no_extras, set()

    for version_control in vcs:
        if url.lower().startswith(f""{version_control}:""):
            url = f""{version_control}+{url}""
            break

    link = Link(url)

    if not link.is_vcs:
        backends = "", "".join(vcs.all_schemes)
        raise InstallationError(
            f""{editable_req} is not a valid editable requirement. ""
            f""It should either be a path to a local project or a VCS URL ""
            f""(beginning with {backends}).""
        )

    package_name = link.egg_fragment
    if not package_name:
        raise InstallationError(
            f""Could not detect requirement name for '{editable_req}', ""
            ""please specify one with 
        )
    return package_name, url, set()


def check_first_requirement_in_file(filename: str) -> None:
    
    with open(filename, encoding=""utf-8"", errors=""ignore"") as f:
        
        lines = (
            line
            for line in (line.strip() for line in f)
            if line and not line.startswith(""
        )

        for line in lines:
            
            if "" 
                line = line[: line.find("" 
            
            if line.endswith(""\\""):
                line = line[:-2].strip() + next(lines, """")
            get_requirement(line)
            return


def deduce_helpful_msg(req: str) -> str:
    
    if not os.path.exists(req):
        return f"" File '{req}' does not exist.""
    msg = "" The path does exist. ""
    
    try:
        check_first_requirement_in_file(req)
    except InvalidRequirement:
        logger.debug(""Cannot parse '%s' as requirements file"", req)
    else:
        msg += (
            f""The argument you provided ""
            f""({req}) appears to be a""
            f"" requirements file. If that is the""
            f"" case, use the '-r' flag to install""
            f"" the packages specified within it.""
        )
    return msg


@dataclass(frozen=True)
class RequirementParts:
    requirement: Requirement | None
    link: Link | None
    markers: Marker | None
    extras: set[str]


def parse_req_from_editable(editable_req: str) -> RequirementParts:
    name, url, extras_override = parse_editable(editable_req)

    if name is not None:
        try:
            req: Requirement | None = get_requirement(name)
        except InvalidRequirement as exc:
            raise InstallationError(f""Invalid requirement: {name!r}: {exc}"")
    else:
        req = None

    link = Link(url)

    return RequirementParts(req, link, None, extras_override)





def install_req_from_editable(
    editable_req: str,
    comes_from: InstallRequirement | str | None = None,
    *,
    use_pep517: bool | None = None,
    isolated: bool = False,
    global_options: list[str] | None = None,
    hash_options: dict[str, list[str]] | None = None,
    constraint: bool = False,
    user_supplied: bool = False,
    permit_editable_wheels: bool = False,
    config_settings: dict[str, str | list[str]] | None = None,
) -> InstallRequirement:
    parts = parse_req_from_editable(editable_req)

    return InstallRequirement(
        parts.requirement,
        comes_from=comes_from,
        user_supplied=user_supplied,
        editable=True,
        permit_editable_wheels=permit_editable_wheels,
        link=parts.link,
        constraint=constraint,
        use_pep517=use_pep517,
        isolated=isolated,
        global_options=global_options,
        hash_options=hash_options,
        config_settings=config_settings,
        extras=parts.extras,
    )


def _looks_like_path(name: str) -> bool:
    
    if os.path.sep in name:
        return True
    if os.path.altsep is not None and os.path.altsep in name:
        return True
    if name.startswith("".""):
        return True
    return False


def _get_url_from_path(path: str, name: str) -> str | None:
    
    if _looks_like_path(name) and os.path.isdir(path):
        if is_installable_dir(path):
            return path_to_url(path)
        
        
        raise InstallationError(
            f""Directory {name!r} is not installable. Neither 'setup.py' ""
            ""nor 'pyproject.toml' found.""
        )
    if not is_archive_file(path):
        return None
    if os.path.isfile(path):
        return path_to_url(path)
    urlreq_parts = name.split(""@"", 1)
    if len(urlreq_parts) >= 2 and not _looks_like_path(urlreq_parts[0]):
        
        
        return None
    logger.warning(
        ""Requirement %r looks like a filename, but the file does not exist"",
        name,
    )
    return path_to_url(path)


def parse_req_from_line(name: str, line_source: str | None) -> RequirementParts:
    if is_url(name):
        marker_sep = ""; ""
    else:
        marker_sep = "";""
    if marker_sep in name:
        name, markers_as_string = name.split(marker_sep, 1)
        markers_as_string = markers_as_string.strip()
        if not markers_as_string:
            markers = None
        else:
            markers = Marker(markers_as_string)
    else:
        markers = None
    name = name.strip()
    req_as_string = None
    path = os.path.normpath(os.path.abspath(name))
    link = None
    extras_as_string = None

    if is_url(name):
        link = Link(name)
    else:
        p, extras_as_string = _strip_extras(path)
        url = _get_url_from_path(p, name)
        if url is not None:
            link = Link(url)

    
    if link:
        
        if link.scheme == ""file"" and re.search(r""\.\./"", link.url):
            link = Link(path_to_url(os.path.normpath(os.path.abspath(link.path))))
        
        if link.is_wheel:
            wheel = Wheel(link.filename)  
            req_as_string = f""{wheel.name}=={wheel.version}""
        else:
            
            
            req_as_string = link.egg_fragment

    
    else:
        req_as_string = name

    extras = convert_extras(extras_as_string)

    def with_source(text: str) -> str:
        if not line_source:
            return text
        return f""{text} (from {line_source})""

    def _parse_req_string(req_as_string: str) -> Requirement:
        try:
            return get_requirement(req_as_string)
        except InvalidRequirement as exc:
            if os.path.sep in req_as_string:
                add_msg = ""It looks like a path.""
                add_msg += deduce_helpful_msg(req_as_string)
            elif ""="" in req_as_string and not any(
                op in req_as_string for op in operators
            ):
                add_msg = ""= is not a valid operator. Did you mean == ?""
            else:
                add_msg = """"
            msg = with_source(f""Invalid requirement: {req_as_string!r}: {exc}"")
            if add_msg:
                msg += f""\nHint: {add_msg}""
            raise InstallationError(msg)

    if req_as_string is not None:
        req: Requirement | None = _parse_req_string(req_as_string)
    else:
        req = None

    return RequirementParts(req, link, markers, extras)


def install_req_from_line(
    name: str,
    comes_from: str | InstallRequirement | None = None,
    *,
    use_pep517: bool | None = None,
    isolated: bool = False,
    global_options: list[str] | None = None,
    hash_options: dict[str, list[str]] | None = None,
    constraint: bool = False,
    line_source: str | None = None,
    user_supplied: bool = False,
    config_settings: dict[str, str | list[str]] | None = None,
) -> InstallRequirement:
    
    parts = parse_req_from_line(name, line_source)

    return InstallRequirement(
        parts.requirement,
        comes_from,
        link=parts.link,
        markers=parts.markers,
        use_pep517=use_pep517,
        isolated=isolated,
        global_options=global_options,
        hash_options=hash_options,
        config_settings=config_settings,
        constraint=constraint,
        extras=parts.extras,
        user_supplied=user_supplied,
    )


def install_req_from_req_string(
    req_string: str,
    comes_from: InstallRequirement | None = None,
    isolated: bool = False,
    use_pep517: bool | None = None,
    user_supplied: bool = False,
) -> InstallRequirement:
    try:
        req = get_requirement(req_string)
    except InvalidRequirement as exc:
        raise InstallationError(f""Invalid requirement: {req_string!r}: {exc}"")

    domains_not_allowed = [
        PyPI.file_storage_domain,
        TestPyPI.file_storage_domain,
    ]
    if (
        req.url
        and comes_from
        and comes_from.link
        and comes_from.link.netloc in domains_not_allowed
    ):
        
        raise InstallationError(
            ""Packages installed from PyPI cannot depend on packages ""
            ""which are not also hosted on PyPI.\n""
            f""{comes_from.name} depends on {req} ""
        )

    return InstallRequirement(
        req,
        comes_from,
        isolated=isolated,
        use_pep517=use_pep517,
        user_supplied=user_supplied,
    )


def install_req_from_parsed_requirement(
    parsed_req: ParsedRequirement,
    isolated: bool = False,
    use_pep517: bool | None = None,
    user_supplied: bool = False,
    config_settings: dict[str, str | list[str]] | None = None,
) -> InstallRequirement:
    if parsed_req.is_editable:
        req = install_req_from_editable(
            parsed_req.requirement,
            comes_from=parsed_req.comes_from,
            use_pep517=use_pep517,
            constraint=parsed_req.constraint,
            isolated=isolated,
            user_supplied=user_supplied,
            config_settings=config_settings,
        )

    else:
        req = install_req_from_line(
            parsed_req.requirement,
            comes_from=parsed_req.comes_from,
            use_pep517=use_pep517,
            isolated=isolated,
            global_options=(
                parsed_req.options.get(""global_options"", [])
                if parsed_req.options
                else []
            ),
            hash_options=(
                parsed_req.options.get(""hashes"", {}) if parsed_req.options else {}
            ),
            constraint=parsed_req.constraint,
            line_source=parsed_req.line_source,
            user_supplied=user_supplied,
            config_settings=config_settings,
        )
    return req


def install_req_from_link_and_ireq(
    link: Link, ireq: InstallRequirement
) -> InstallRequirement:
    return InstallRequirement(
        req=ireq.req,
        comes_from=ireq.comes_from,
        editable=ireq.editable,
        link=link,
        markers=ireq.markers,
        use_pep517=ireq.use_pep517,
        isolated=ireq.isolated,
        global_options=ireq.global_options,
        hash_options=ireq.hash_options,
        config_settings=ireq.config_settings,
        user_supplied=ireq.user_supplied,
    )


def install_req_drop_extras(ireq: InstallRequirement) -> InstallRequirement:
    
    return InstallRequirement(
        req=(
            _set_requirement_extras(ireq.req, set()) if ireq.req is not None else None
        ),
        comes_from=ireq,
        editable=ireq.editable,
        link=ireq.link,
        markers=ireq.markers,
        use_pep517=ireq.use_pep517,
        isolated=ireq.isolated,
        global_options=ireq.global_options,
        hash_options=ireq.hash_options,
        constraint=ireq.constraint,
        extras=[],
        config_settings=ireq.config_settings,
        user_supplied=ireq.user_supplied,
        permit_editable_wheels=ireq.permit_editable_wheels,
    )


def install_req_extend_extras(
    ireq: InstallRequirement,
    extras: Collection[str],
) -> InstallRequirement:
    
    result = copy.copy(ireq)
    result.extras = {*ireq.extras, *extras}
    result.req = (
        _set_requirement_extras(ireq.req, result.extras)
        if ireq.req is not None
        else None
    )
    return result

from collections.abc import Iterable, Iterator
from typing import Any

from pip._vendor.dependency_groups import DependencyGroupResolver

from pip._internal.exceptions import InstallationError
from pip._internal.utils.compat import tomllib


def parse_dependency_groups(groups: list[tuple[str, str]]) -> list[str]:
    
    resolvers = _build_resolvers(path for (path, _) in groups)
    return list(_resolve_all_groups(resolvers, groups))


def _resolve_all_groups(
    resolvers: dict[str, DependencyGroupResolver], groups: list[tuple[str, str]]
) -> Iterator[str]:
    
    for path, groupname in groups:
        resolver = resolvers[path]
        try:
            yield from (str(req) for req in resolver.resolve(groupname))
        except (ValueError, TypeError, LookupError) as e:
            raise InstallationError(
                f""[dependency-groups] resolution failed for '{groupname}' ""
                f""from '{path}': {e}""
            ) from e


def _build_resolvers(paths: Iterable[str]) -> dict[str, Any]:
    resolvers = {}
    for path in paths:
        if path in resolvers:
            continue

        pyproject = _load_pyproject(path)
        if ""dependency-groups"" not in pyproject:
            raise InstallationError(
                f""[dependency-groups] table was missing from '{path}'. ""
                ""Cannot resolve '--group' option.""
            )
        raw_dependency_groups = pyproject[""dependency-groups""]
        if not isinstance(raw_dependency_groups, dict):
            raise InstallationError(
                f""[dependency-groups] table was malformed in {path}. ""
                ""Cannot resolve '--group' option.""
            )

        resolvers[path] = DependencyGroupResolver(raw_dependency_groups)
    return resolvers


def _load_pyproject(path: str) -> dict[str, Any]:
    
    try:
        with open(path, ""rb"") as fp:
            return tomllib.load(fp)
    except FileNotFoundError:
        raise InstallationError(f""{path} not found. Cannot resolve '--group' option."")
    except tomllib.TOMLDecodeError as e:
        raise InstallationError(f""Error parsing {path}: {e}"") from e
    except OSError as e:
        raise InstallationError(f""Error reading {path}: {e}"") from e



from __future__ import annotations

import codecs
import locale
import logging
import optparse
import os
import re
import shlex
import sys
import urllib.parse
from collections.abc import Generator, Iterable
from dataclasses import dataclass
from optparse import Values
from typing import (
    TYPE_CHECKING,
    Any,
    Callable,
    NoReturn,
)

from pip._internal.cli import cmdoptions
from pip._internal.exceptions import InstallationError, RequirementsFileParseError
from pip._internal.models.search_scope import SearchScope

if TYPE_CHECKING:
    from pip._internal.index.package_finder import PackageFinder
    from pip._internal.network.session import PipSession

__all__ = [""parse_requirements""]

ReqFileLines = Iterable[tuple[int, str]]

LineParser = Callable[[str], tuple[str, Values]]

SCHEME_RE = re.compile(r""^(http|https|file):"", re.I)
COMMENT_RE = re.compile(r""(^|\s+)





ENV_VAR_RE = re.compile(r""(?P<var>\$\{(?P<name>[A-Z0-9_]+)\})"")

SUPPORTED_OPTIONS: list[Callable[..., optparse.Option]] = [
    cmdoptions.index_url,
    cmdoptions.extra_index_url,
    cmdoptions.no_index,
    cmdoptions.constraints,
    cmdoptions.requirements,
    cmdoptions.editable,
    cmdoptions.find_links,
    cmdoptions.no_binary,
    cmdoptions.only_binary,
    cmdoptions.prefer_binary,
    cmdoptions.require_hashes,
    cmdoptions.pre,
    cmdoptions.trusted_host,
    cmdoptions.use_new_feature,
]


SUPPORTED_OPTIONS_REQ: list[Callable[..., optparse.Option]] = [
    cmdoptions.global_options,
    cmdoptions.hash,
    cmdoptions.config_settings,
]

SUPPORTED_OPTIONS_EDITABLE_REQ: list[Callable[..., optparse.Option]] = [
    cmdoptions.config_settings,
]



SUPPORTED_OPTIONS_REQ_DEST = [str(o().dest) for o in SUPPORTED_OPTIONS_REQ]
SUPPORTED_OPTIONS_EDITABLE_REQ_DEST = [
    str(o().dest) for o in SUPPORTED_OPTIONS_EDITABLE_REQ
]



BOMS: list[tuple[bytes, str]] = [
    (codecs.BOM_UTF8, ""utf-8""),
    (codecs.BOM_UTF32, ""utf-32""),
    (codecs.BOM_UTF32_BE, ""utf-32-be""),
    (codecs.BOM_UTF32_LE, ""utf-32-le""),
    (codecs.BOM_UTF16, ""utf-16""),
    (codecs.BOM_UTF16_BE, ""utf-16-be""),
    (codecs.BOM_UTF16_LE, ""utf-16-le""),
]

PEP263_ENCODING_RE = re.compile(rb""coding[:=]\s*([-\w.]+)"")
DEFAULT_ENCODING = ""utf-8""

logger = logging.getLogger(__name__)


@dataclass(frozen=True)
class ParsedRequirement:
    
    __slots__ = (
        ""requirement"",
        ""is_editable"",
        ""comes_from"",
        ""constraint"",
        ""options"",
        ""line_source"",
    )

    requirement: str
    is_editable: bool
    comes_from: str
    constraint: bool
    options: dict[str, Any] | None
    line_source: str | None


@dataclass(frozen=True)
class ParsedLine:
    __slots__ = (""filename"", ""lineno"", ""args"", ""opts"", ""constraint"")

    filename: str
    lineno: int
    args: str
    opts: Values
    constraint: bool

    @property
    def is_editable(self) -> bool:
        return bool(self.opts.editables)

    @property
    def requirement(self) -> str | None:
        if self.args:
            return self.args
        elif self.is_editable:
            
            return self.opts.editables[0]
        return None


def parse_requirements(
    filename: str,
    session: PipSession,
    finder: PackageFinder | None = None,
    options: optparse.Values | None = None,
    constraint: bool = False,
) -> Generator[ParsedRequirement, None, None]:
    
    line_parser = get_line_parser(finder)
    parser = RequirementsFileParser(session, line_parser)

    for parsed_line in parser.parse(filename, constraint):
        parsed_req = handle_line(
            parsed_line, options=options, finder=finder, session=session
        )
        if parsed_req is not None:
            yield parsed_req


def preprocess(content: str) -> ReqFileLines:
    
    lines_enum: ReqFileLines = enumerate(content.splitlines(), start=1)
    lines_enum = join_lines(lines_enum)
    lines_enum = ignore_comments(lines_enum)
    lines_enum = expand_env_variables(lines_enum)
    return lines_enum


def handle_requirement_line(
    line: ParsedLine,
    options: optparse.Values | None = None,
) -> ParsedRequirement:
    
    line_comes_from = ""{} {} (line {})"".format(
        ""-c"" if line.constraint else ""-r"",
        line.filename,
        line.lineno,
    )

    assert line.requirement is not None

    
    if line.is_editable:
        supported_dest = SUPPORTED_OPTIONS_EDITABLE_REQ_DEST
    else:
        supported_dest = SUPPORTED_OPTIONS_REQ_DEST
    req_options = {}
    for dest in supported_dest:
        if dest in line.opts.__dict__ and line.opts.__dict__[dest]:
            req_options[dest] = line.opts.__dict__[dest]

    line_source = f""line {line.lineno} of {line.filename}""
    return ParsedRequirement(
        requirement=line.requirement,
        is_editable=line.is_editable,
        comes_from=line_comes_from,
        constraint=line.constraint,
        options=req_options,
        line_source=line_source,
    )


def handle_option_line(
    opts: Values,
    filename: str,
    lineno: int,
    finder: PackageFinder | None = None,
    options: optparse.Values | None = None,
    session: PipSession | None = None,
) -> None:
    if opts.hashes:
        logger.warning(
            ""%s line %s has --hash but no requirement, and will be ignored."",
            filename,
            lineno,
        )

    if options:
        
        if opts.require_hashes:
            options.require_hashes = opts.require_hashes
        if opts.features_enabled:
            options.features_enabled.extend(
                f for f in opts.features_enabled if f not in options.features_enabled
            )

    
    if finder:
        find_links = finder.find_links
        index_urls = finder.index_urls
        no_index = finder.search_scope.no_index
        if opts.no_index is True:
            no_index = True
            index_urls = []
        if opts.index_url and not no_index:
            index_urls = [opts.index_url]
        if opts.extra_index_urls and not no_index:
            index_urls.extend(opts.extra_index_urls)
        if opts.find_links:
            
            
            
            value = opts.find_links[0]
            req_dir = os.path.dirname(os.path.abspath(filename))
            relative_to_reqs_file = os.path.join(req_dir, value)
            if os.path.exists(relative_to_reqs_file):
                value = relative_to_reqs_file
            find_links.append(value)

        if session:
            
            session.update_index_urls(index_urls)

        search_scope = SearchScope(
            find_links=find_links,
            index_urls=index_urls,
            no_index=no_index,
        )
        finder.search_scope = search_scope

        if opts.pre:
            finder.set_allow_all_prereleases()

        if opts.prefer_binary:
            finder.set_prefer_binary()

        if session:
            for host in opts.trusted_hosts or []:
                source = f""line {lineno} of {filename}""
                session.add_trusted_host(host, source=source)


def handle_line(
    line: ParsedLine,
    options: optparse.Values | None = None,
    finder: PackageFinder | None = None,
    session: PipSession | None = None,
) -> ParsedRequirement | None:
    

    if line.requirement is not None:
        parsed_req = handle_requirement_line(line, options)
        return parsed_req
    else:
        handle_option_line(
            line.opts,
            line.filename,
            line.lineno,
            finder,
            options,
            session,
        )
        return None


class RequirementsFileParser:
    def __init__(
        self,
        session: PipSession,
        line_parser: LineParser,
    ) -> None:
        self._session = session
        self._line_parser = line_parser

    def parse(
        self, filename: str, constraint: bool
    ) -> Generator[ParsedLine, None, None]:
        
        yield from self._parse_and_recurse(
            filename, constraint, [{os.path.abspath(filename): None}]
        )

    def _parse_and_recurse(
        self,
        filename: str,
        constraint: bool,
        parsed_files_stack: list[dict[str, str | None]],
    ) -> Generator[ParsedLine, None, None]:
        for line in self._parse_file(filename, constraint):
            if line.requirement is None and (
                line.opts.requirements or line.opts.constraints
            ):
                
                if line.opts.requirements:
                    req_path = line.opts.requirements[0]
                    nested_constraint = False
                else:
                    req_path = line.opts.constraints[0]
                    nested_constraint = True

                
                if SCHEME_RE.search(filename):
                    
                    req_path = urllib.parse.urljoin(filename, req_path)
                
                elif not SCHEME_RE.search(req_path):
                    
                    
                    req_path = os.path.abspath(
                        os.path.join(
                            os.path.dirname(filename),
                            req_path,
                        )
                    )
                parsed_files = parsed_files_stack[0]
                if req_path in parsed_files:
                    initial_file = parsed_files[req_path]
                    tail = (
                        f"" and again in {initial_file}""
                        if initial_file is not None
                        else """"
                    )
                    raise RequirementsFileParseError(
                        f""{req_path} recursively references itself in {filename}{tail}""
                    )
                
                new_parsed_files = parsed_files.copy()
                new_parsed_files[req_path] = filename
                yield from self._parse_and_recurse(
                    req_path, nested_constraint, [new_parsed_files, *parsed_files_stack]
                )
            else:
                yield line

    def _parse_file(
        self, filename: str, constraint: bool
    ) -> Generator[ParsedLine, None, None]:
        _, content = get_file_content(filename, self._session)

        lines_enum = preprocess(content)

        for line_number, line in lines_enum:
            try:
                args_str, opts = self._line_parser(line)
            except OptionParsingError as e:
                
                msg = f""Invalid requirement: {line}\n{e.msg}""
                raise RequirementsFileParseError(msg)

            yield ParsedLine(
                filename,
                line_number,
                args_str,
                opts,
                constraint,
            )


def get_line_parser(finder: PackageFinder | None) -> LineParser:
    def parse_line(line: str) -> tuple[str, Values]:
        
        
        parser = build_parser()
        defaults = parser.get_default_values()
        defaults.index_url = None
        if finder:
            defaults.format_control = finder.format_control

        args_str, options_str = break_args_options(line)

        try:
            options = shlex.split(options_str)
        except ValueError as e:
            raise OptionParsingError(f""Could not split options: {options_str}"") from e

        opts, _ = parser.parse_args(options, defaults)

        return args_str, opts

    return parse_line


def break_args_options(line: str) -> tuple[str, str]:
    
    tokens = line.split("" "")
    args = []
    options = tokens[:]
    for token in tokens:
        if token.startswith((""-"", ""--"")):
            break
        else:
            args.append(token)
            options.pop(0)
    return "" "".join(args), "" "".join(options)


class OptionParsingError(Exception):
    def __init__(self, msg: str) -> None:
        self.msg = msg


def build_parser() -> optparse.OptionParser:
    
    parser = optparse.OptionParser(add_help_option=False)

    option_factories = SUPPORTED_OPTIONS + SUPPORTED_OPTIONS_REQ
    for option_factory in option_factories:
        option = option_factory()
        parser.add_option(option)

    
    
    def parser_exit(self: Any, msg: str) -> NoReturn:
        raise OptionParsingError(msg)

    
    
    parser.exit = parser_exit  

    return parser


def join_lines(lines_enum: ReqFileLines) -> ReqFileLines:
    
    primary_line_number = None
    new_line: list[str] = []
    for line_number, line in lines_enum:
        if not line.endswith(""\\"") or COMMENT_RE.match(line):
            if COMMENT_RE.match(line):
                
                line = "" "" + line
            if new_line:
                new_line.append(line)
                assert primary_line_number is not None
                yield primary_line_number, """".join(new_line)
                new_line = []
            else:
                yield line_number, line
        else:
            if not new_line:
                primary_line_number = line_number
            new_line.append(line.strip(""\\""))

    
    if new_line:
        assert primary_line_number is not None
        yield primary_line_number, """".join(new_line)

    


def ignore_comments(lines_enum: ReqFileLines) -> ReqFileLines:
    
    for line_number, line in lines_enum:
        line = COMMENT_RE.sub("""", line)
        line = line.strip()
        if line:
            yield line_number, line


def expand_env_variables(lines_enum: ReqFileLines) -> ReqFileLines:
    
    for line_number, line in lines_enum:
        for env_var, var_name in ENV_VAR_RE.findall(line):
            value = os.getenv(var_name)
            if not value:
                continue

            line = line.replace(env_var, value)

        yield line_number, line


def get_file_content(url: str, session: PipSession) -> tuple[str, str]:
    
    scheme = urllib.parse.urlsplit(url).scheme
    
    if scheme in [""http"", ""https"", ""file""]:
        
        from pip._internal.network.utils import raise_for_status

        resp = session.get(url)
        raise_for_status(resp)
        return resp.url, resp.text

    
    try:
        with open(url, ""rb"") as f:
            raw_content = f.read()
    except OSError as exc:
        raise InstallationError(f""Could not open requirements file: {exc}"")

    content = _decode_req_file(raw_content, url)

    return url, content


def _decode_req_file(data: bytes, url: str) -> str:
    for bom, encoding in BOMS:
        if data.startswith(bom):
            return data[len(bom) :].decode(encoding)

    for line in data.split(b""\n"")[:2]:
        if line[0:1] == b""
            result = PEP263_ENCODING_RE.search(line)
            if result is not None:
                encoding = result.groups()[0].decode(""ascii"")
                return data.decode(encoding)

    try:
        return data.decode(DEFAULT_ENCODING)
    except UnicodeDecodeError:
        locale_encoding = locale.getpreferredencoding(False) or sys.getdefaultencoding()
        logging.warning(
            ""unable to decode data from %s with default encoding %s, ""
            ""falling back to encoding from locale: %s. ""
            ""If this is intentional you should specify the encoding with a ""
            ""PEP-263 style comment, e.g. '
            url,
            DEFAULT_ENCODING,
            locale_encoding,
            locale_encoding,
        )
        return data.decode(locale_encoding)

from __future__ import annotations

import functools
import logging
import os
import shutil
import sys
import uuid
import zipfile
from collections.abc import Collection, Iterable, Sequence
from optparse import Values
from pathlib import Path
from typing import Any

from pip._vendor.packaging.markers import Marker
from pip._vendor.packaging.requirements import Requirement
from pip._vendor.packaging.specifiers import SpecifierSet
from pip._vendor.packaging.utils import canonicalize_name
from pip._vendor.packaging.version import Version
from pip._vendor.packaging.version import parse as parse_version
from pip._vendor.pyproject_hooks import BuildBackendHookCaller

from pip._internal.build_env import BuildEnvironment, NoOpBuildEnvironment
from pip._internal.exceptions import InstallationError, PreviousBuildDirError
from pip._internal.locations import get_scheme
from pip._internal.metadata import (
    BaseDistribution,
    get_default_environment,
    get_directory_distribution,
    get_wheel_distribution,
)
from pip._internal.metadata.base import FilesystemWheel
from pip._internal.models.direct_url import DirectUrl
from pip._internal.models.link import Link
from pip._internal.operations.build.metadata import generate_metadata
from pip._internal.operations.build.metadata_editable import generate_editable_metadata
from pip._internal.operations.build.metadata_legacy import (
    generate_metadata as generate_metadata_legacy,
)
from pip._internal.operations.install.editable_legacy import (
    install_editable as install_editable_legacy,
)
from pip._internal.operations.install.wheel import install_wheel
from pip._internal.pyproject import load_pyproject_toml, make_pyproject_path
from pip._internal.req.req_uninstall import UninstallPathSet
from pip._internal.utils.deprecation import deprecated
from pip._internal.utils.hashes import Hashes
from pip._internal.utils.misc import (
    ConfiguredBuildBackendHookCaller,
    ask_path_exists,
    backup_dir,
    display_path,
    hide_url,
    is_installable_dir,
    redact_auth_from_requirement,
    redact_auth_from_url,
)
from pip._internal.utils.packaging import get_requirement
from pip._internal.utils.subprocess import runner_with_spinner_message
from pip._internal.utils.temp_dir import TempDirectory, tempdir_kinds
from pip._internal.utils.unpacking import unpack_file
from pip._internal.utils.virtualenv import running_under_virtualenv
from pip._internal.vcs import vcs

logger = logging.getLogger(__name__)


class InstallRequirement:
    

    def __init__(
        self,
        req: Requirement | None,
        comes_from: str | InstallRequirement | None,
        editable: bool = False,
        link: Link | None = None,
        markers: Marker | None = None,
        use_pep517: bool | None = None,
        isolated: bool = False,
        *,
        global_options: list[str] | None = None,
        hash_options: dict[str, list[str]] | None = None,
        config_settings: dict[str, str | list[str]] | None = None,
        constraint: bool = False,
        extras: Collection[str] = (),
        user_supplied: bool = False,
        permit_editable_wheels: bool = False,
    ) -> None:
        assert req is None or isinstance(req, Requirement), req
        self.req = req
        self.comes_from = comes_from
        self.constraint = constraint
        self.editable = editable
        self.permit_editable_wheels = permit_editable_wheels

        
        
        
        
        
        self.source_dir: str | None = None
        if self.editable:
            assert link
            if link.is_file:
                self.source_dir = os.path.normpath(os.path.abspath(link.file_path))

        
        
        if link is None and req and req.url:
            
            link = Link(req.url)
        self.link = self.original_link = link

        
        
        
        self.cached_wheel_source_link: Link | None = None

        
        
        self.download_info: DirectUrl | None = None

        
        self.local_file_path: str | None = None
        if self.link and self.link.is_file:
            self.local_file_path = self.link.file_path

        if extras:
            self.extras = extras
        elif req:
            self.extras = req.extras
        else:
            self.extras = set()
        if markers is None and req:
            markers = req.marker
        self.markers = markers

        
        self.satisfied_by: BaseDistribution | None = None
        
        
        self.should_reinstall = False
        
        self._temp_build_dir: TempDirectory | None = None
        
        self.install_succeeded: bool | None = None
        
        self.global_options = global_options if global_options else []
        self.hash_options = hash_options if hash_options else {}
        self.config_settings = config_settings
        
        self.prepared = False
        
        
        
        self.user_supplied = user_supplied

        self.isolated = isolated
        self.build_env: BuildEnvironment = NoOpBuildEnvironment()

        
        
        
        
        self.metadata_directory: str | None = None

        
        self.pyproject_requires: list[str] | None = None

        
        self.requirements_to_check: list[str] = []

        
        self.pep517_backend: BuildBackendHookCaller | None = None

        
        
        
        
        
        self.use_pep517 = use_pep517

        
        if self.config_settings:
            if self.use_pep517 is False:
                logger.warning(
                    ""--no-use-pep517 ignored for %s ""
                    ""because --config-settings are specified."",
                    self,
                )
            self.use_pep517 = True

        
        self.needs_more_preparation = False

        
        self._archive_source: Path | None = None

    def __str__(self) -> str:
        if self.req:
            s = redact_auth_from_requirement(self.req)
            if self.link:
                s += f"" from {redact_auth_from_url(self.link.url)}""
        elif self.link:
            s = redact_auth_from_url(self.link.url)
        else:
            s = ""<InstallRequirement>""
        if self.satisfied_by is not None:
            if self.satisfied_by.location is not None:
                location = display_path(self.satisfied_by.location)
            else:
                location = ""<memory>""
            s += f"" in {location}""
        if self.comes_from:
            if isinstance(self.comes_from, str):
                comes_from: str | None = self.comes_from
            else:
                comes_from = self.comes_from.from_path()
            if comes_from:
                s += f"" (from {comes_from})""
        return s

    def __repr__(self) -> str:
        return (
            f""<{self.__class__.__name__} object: ""
            f""{str(self)} editable={self.editable!r}>""
        )

    def format_debug(self) -> str:
        
        attributes = vars(self)
        names = sorted(attributes)

        state = (f""{attr}={attributes[attr]!r}"" for attr in sorted(names))
        return ""<{name} object: {{{state}}}>"".format(
            name=self.__class__.__name__,
            state="", "".join(state),
        )

    
    @property
    def name(self) -> str | None:
        if self.req is None:
            return None
        return self.req.name

    @functools.cached_property
    def supports_pyproject_editable(self) -> bool:
        if not self.use_pep517:
            return False
        assert self.pep517_backend
        with self.build_env:
            runner = runner_with_spinner_message(
                ""Checking if build backend supports build_editable""
            )
            with self.pep517_backend.subprocess_runner(runner):
                return ""build_editable"" in self.pep517_backend._supported_features()

    @property
    def specifier(self) -> SpecifierSet:
        assert self.req is not None
        return self.req.specifier

    @property
    def is_direct(self) -> bool:
        
        return self.original_link is not None

    @property
    def is_pinned(self) -> bool:
        
        assert self.req is not None
        specifiers = self.req.specifier
        return len(specifiers) == 1 and next(iter(specifiers)).operator in {""=="", ""===""}

    def match_markers(self, extras_requested: Iterable[str] | None = None) -> bool:
        if not extras_requested:
            
            
            extras_requested = ("""",)
        if self.markers is not None:
            return any(
                self.markers.evaluate({""extra"": extra}) for extra in extras_requested
            )
        else:
            return True

    @property
    def has_hash_options(self) -> bool:
        
        return bool(self.hash_options)

    def hashes(self, trust_internet: bool = True) -> Hashes:
        
        good_hashes = self.hash_options.copy()
        if trust_internet:
            link = self.link
        elif self.is_direct and self.user_supplied:
            link = self.original_link
        else:
            link = None
        if link and link.hash:
            assert link.hash_name is not None
            good_hashes.setdefault(link.hash_name, []).append(link.hash)
        return Hashes(good_hashes)

    def from_path(self) -> str | None:
        
        if self.req is None:
            return None
        s = str(self.req)
        if self.comes_from:
            comes_from: str | None
            if isinstance(self.comes_from, str):
                comes_from = self.comes_from
            else:
                comes_from = self.comes_from.from_path()
            if comes_from:
                s += ""->"" + comes_from
        return s

    def ensure_build_location(
        self, build_dir: str, autodelete: bool, parallel_builds: bool
    ) -> str:
        assert build_dir is not None
        if self._temp_build_dir is not None:
            assert self._temp_build_dir.path
            return self._temp_build_dir.path
        if self.req is None:
            
            
            
            self._temp_build_dir = TempDirectory(
                kind=tempdir_kinds.REQ_BUILD, globally_managed=True
            )

            return self._temp_build_dir.path

        
        
        

        
        
        dir_name: str = canonicalize_name(self.req.name)
        if parallel_builds:
            dir_name = f""{dir_name}_{uuid.uuid4().hex}""

        
        
        if not os.path.exists(build_dir):
            logger.debug(""Creating directory %s"", build_dir)
            os.makedirs(build_dir)
        actual_build_dir = os.path.join(build_dir, dir_name)
        
        
        delete_arg = None if autodelete else False
        return TempDirectory(
            path=actual_build_dir,
            delete=delete_arg,
            kind=tempdir_kinds.REQ_BUILD,
            globally_managed=True,
        ).path

    def _set_requirement(self) -> None:
        
        assert self.req is None
        assert self.metadata is not None
        assert self.source_dir is not None

        
        if isinstance(parse_version(self.metadata[""Version""]), Version):
            op = ""==""
        else:
            op = ""===""

        self.req = get_requirement(
            """".join(
                [
                    self.metadata[""Name""],
                    op,
                    self.metadata[""Version""],
                ]
            )
        )

    def warn_on_mismatching_name(self) -> None:
        assert self.req is not None
        metadata_name = canonicalize_name(self.metadata[""Name""])
        if canonicalize_name(self.req.name) == metadata_name:
            
            return

        
        logger.warning(
            ""Generating metadata for package %s ""
            ""produced metadata for project name %s. Fix your ""
            ""
            self.name,
            metadata_name,
            self.name,
        )
        self.req = get_requirement(metadata_name)

    def check_if_exists(self, use_user_site: bool) -> None:
        
        if self.req is None:
            return
        existing_dist = get_default_environment().get_distribution(self.req.name)
        if not existing_dist:
            return

        version_compatible = self.req.specifier.contains(
            existing_dist.version,
            prereleases=True,
        )
        if not version_compatible:
            self.satisfied_by = None
            if use_user_site:
                if existing_dist.in_usersite:
                    self.should_reinstall = True
                elif running_under_virtualenv() and existing_dist.in_site_packages:
                    raise InstallationError(
                        f""Will not install to the user site because it will ""
                        f""lack sys.path precedence to {existing_dist.raw_name} ""
                        f""in {existing_dist.location}""
                    )
            else:
                self.should_reinstall = True
        else:
            if self.editable:
                self.should_reinstall = True
                
                
                self.satisfied_by = None
            else:
                self.satisfied_by = existing_dist

    
    @property
    def is_wheel(self) -> bool:
        if not self.link:
            return False
        return self.link.is_wheel

    @property
    def is_wheel_from_cache(self) -> bool:
        
        
        return self.cached_wheel_source_link is not None

    
    @property
    def unpacked_source_directory(self) -> str:
        assert self.source_dir, f""No source dir for {self}""
        return os.path.join(
            self.source_dir, self.link and self.link.subdirectory_fragment or """"
        )

    @property
    def setup_py_path(self) -> str:
        assert self.source_dir, f""No source dir for {self}""
        setup_py = os.path.join(self.unpacked_source_directory, ""setup.py"")

        return setup_py

    @property
    def setup_cfg_path(self) -> str:
        assert self.source_dir, f""No source dir for {self}""
        setup_cfg = os.path.join(self.unpacked_source_directory, ""setup.cfg"")

        return setup_cfg

    @property
    def pyproject_toml_path(self) -> str:
        assert self.source_dir, f""No source dir for {self}""
        return make_pyproject_path(self.unpacked_source_directory)

    def load_pyproject_toml(self) -> None:
        
        pyproject_toml_data = load_pyproject_toml(
            self.use_pep517, self.pyproject_toml_path, self.setup_py_path, str(self)
        )

        if pyproject_toml_data is None:
            assert not self.config_settings
            self.use_pep517 = False
            return

        self.use_pep517 = True
        requires, backend, check, backend_path = pyproject_toml_data
        self.requirements_to_check = check
        self.pyproject_requires = requires
        self.pep517_backend = ConfiguredBuildBackendHookCaller(
            self,
            self.unpacked_source_directory,
            backend,
            backend_path=backend_path,
        )

    def isolated_editable_sanity_check(self) -> None:
        
        if (
            self.editable
            and self.use_pep517
            and not self.supports_pyproject_editable
            and not os.path.isfile(self.setup_py_path)
            and not os.path.isfile(self.setup_cfg_path)
        ):
            raise InstallationError(
                f""Project {self} has a 'pyproject.toml' and its build ""
                f""backend is missing the 'build_editable' hook. Since it does not ""
                f""have a 'setup.py' nor a 'setup.cfg', ""
                f""it cannot be installed in editable mode. ""
                f""Consider using a build backend that supports PEP 660.""
            )

    def prepare_metadata(self) -> None:
        
        assert self.source_dir, f""No source dir for {self}""
        details = self.name or f""from {self.link}""

        if self.use_pep517:
            assert self.pep517_backend is not None
            if (
                self.editable
                and self.permit_editable_wheels
                and self.supports_pyproject_editable
            ):
                self.metadata_directory = generate_editable_metadata(
                    build_env=self.build_env,
                    backend=self.pep517_backend,
                    details=details,
                )
            else:
                self.metadata_directory = generate_metadata(
                    build_env=self.build_env,
                    backend=self.pep517_backend,
                    details=details,
                )
        else:
            self.metadata_directory = generate_metadata_legacy(
                build_env=self.build_env,
                setup_py_path=self.setup_py_path,
                source_dir=self.unpacked_source_directory,
                isolated=self.isolated,
                details=details,
            )

        
        if not self.name:
            self._set_requirement()
        else:
            self.warn_on_mismatching_name()

        self.assert_source_matches_version()

    @property
    def metadata(self) -> Any:
        if not hasattr(self, ""_metadata""):
            self._metadata = self.get_dist().metadata

        return self._metadata

    def get_dist(self) -> BaseDistribution:
        if self.metadata_directory:
            return get_directory_distribution(self.metadata_directory)
        elif self.local_file_path and self.is_wheel:
            assert self.req is not None
            return get_wheel_distribution(
                FilesystemWheel(self.local_file_path),
                canonicalize_name(self.req.name),
            )
        raise AssertionError(
            f""InstallRequirement {self} has no metadata directory and no wheel: ""
            f""can't make a distribution.""
        )

    def assert_source_matches_version(self) -> None:
        assert self.source_dir, f""No source dir for {self}""
        version = self.metadata[""version""]
        if self.req and self.req.specifier and version not in self.req.specifier:
            logger.warning(
                ""Requested %s, but installing version %s"",
                self,
                version,
            )
        else:
            logger.debug(
                ""Source in %s has version %s, which satisfies requirement %s"",
                display_path(self.source_dir),
                version,
                self,
            )

    
    def ensure_has_source_dir(
        self,
        parent_dir: str,
        autodelete: bool = False,
        parallel_builds: bool = False,
    ) -> None:
        
        if self.source_dir is None:
            self.source_dir = self.ensure_build_location(
                parent_dir,
                autodelete=autodelete,
                parallel_builds=parallel_builds,
            )

    def needs_unpacked_archive(self, archive_source: Path) -> None:
        assert self._archive_source is None
        self._archive_source = archive_source

    def ensure_pristine_source_checkout(self) -> None:
        
        assert self.source_dir is not None
        if self._archive_source is not None:
            unpack_file(str(self._archive_source), self.source_dir)
        elif is_installable_dir(self.source_dir):
            
            
            
            raise PreviousBuildDirError(
                f""pip can't proceed with requirements '{self}' due to a ""
                f""pre-existing build directory ({self.source_dir}). This is likely ""
                ""due to a previous installation that failed . pip is ""
                ""being responsible and not assuming it can delete this. ""
                ""Please delete it and try again.""
            )

    
    def update_editable(self) -> None:
        if not self.link:
            logger.debug(
                ""Cannot update repository at %s; repository location is unknown"",
                self.source_dir,
            )
            return
        assert self.editable
        assert self.source_dir
        if self.link.scheme == ""file"":
            
            return
        vcs_backend = vcs.get_backend_for_scheme(self.link.scheme)
        
        
        assert vcs_backend, f""Unsupported VCS URL {self.link.url}""
        hidden_url = hide_url(self.link.url)
        vcs_backend.obtain(self.source_dir, url=hidden_url, verbosity=0)

    
    def uninstall(
        self, auto_confirm: bool = False, verbose: bool = False
    ) -> UninstallPathSet | None:
        
        assert self.req
        dist = get_default_environment().get_distribution(self.req.name)
        if not dist:
            logger.warning(""Skipping %s as it is not installed."", self.name)
            return None
        logger.info(""Found existing installation: %s"", dist)

        uninstalled_pathset = UninstallPathSet.from_dist(dist)
        uninstalled_pathset.remove(auto_confirm, verbose)
        return uninstalled_pathset

    def _get_archive_name(self, path: str, parentdir: str, rootdir: str) -> str:
        def _clean_zip_name(name: str, prefix: str) -> str:
            assert name.startswith(
                prefix + os.path.sep
            ), f""name {name!r} doesn't start with prefix {prefix!r}""
            name = name[len(prefix) + 1 :]
            name = name.replace(os.path.sep, ""/"")
            return name

        assert self.req is not None
        path = os.path.join(parentdir, path)
        name = _clean_zip_name(path, rootdir)
        return self.req.name + ""/"" + name

    def archive(self, build_dir: str | None) -> None:
        
        assert self.source_dir
        if build_dir is None:
            return

        create_archive = True
        archive_name = ""{}-{}.zip"".format(self.name, self.metadata[""version""])
        archive_path = os.path.join(build_dir, archive_name)

        if os.path.exists(archive_path):
            response = ask_path_exists(
                f""The file {display_path(archive_path)} exists. (i)gnore, (w)ipe, ""
                ""(b)ackup, (a)bort "",
                (""i"", ""w"", ""b"", ""a""),
            )
            if response == ""i"":
                create_archive = False
            elif response == ""w"":
                logger.warning(""Deleting %s"", display_path(archive_path))
                os.remove(archive_path)
            elif response == ""b"":
                dest_file = backup_dir(archive_path)
                logger.warning(
                    ""Backing up %s to %s"",
                    display_path(archive_path),
                    display_path(dest_file),
                )
                shutil.move(archive_path, dest_file)
            elif response == ""a"":
                sys.exit(-1)

        if not create_archive:
            return

        zip_output = zipfile.ZipFile(
            archive_path,
            ""w"",
            zipfile.ZIP_DEFLATED,
            allowZip64=True,
        )
        with zip_output:
            dir = os.path.normcase(os.path.abspath(self.unpacked_source_directory))
            for dirpath, dirnames, filenames in os.walk(dir):
                for dirname in dirnames:
                    dir_arcname = self._get_archive_name(
                        dirname,
                        parentdir=dirpath,
                        rootdir=dir,
                    )
                    zipdir = zipfile.ZipInfo(dir_arcname + ""/"")
                    zipdir.external_attr = 0x1ED << 16  
                    zip_output.writestr(zipdir, """")
                for filename in filenames:
                    file_arcname = self._get_archive_name(
                        filename,
                        parentdir=dirpath,
                        rootdir=dir,
                    )
                    filename = os.path.join(dirpath, filename)
                    zip_output.write(filename, file_arcname)

        logger.info(""Saved %s"", display_path(archive_path))

    def install(
        self,
        global_options: Sequence[str] | None = None,
        root: str | None = None,
        home: str | None = None,
        prefix: str | None = None,
        warn_script_location: bool = True,
        use_user_site: bool = False,
        pycompile: bool = True,
    ) -> None:
        assert self.req is not None
        scheme = get_scheme(
            self.req.name,
            user=use_user_site,
            home=home,
            root=root,
            isolated=self.isolated,
            prefix=prefix,
        )

        if self.editable and not self.is_wheel:
            deprecated(
                reason=(
                    f""Legacy editable install of {self} (setup.py develop) ""
                    ""is deprecated.""
                ),
                replacement=(
                    ""to add a pyproject.toml or enable --use-pep517, ""
                    ""and use setuptools >= 64. ""
                    ""If the resulting installation is not behaving as expected, ""
                    ""try using --config-settings editable_mode=compat. ""
                    ""Please consult the setuptools documentation for more information""
                ),
                gone_in=""25.3"",
                issue=11457,
            )
            if self.config_settings:
                logger.warning(
                    ""--config-settings ignored for legacy editable install of %s. ""
                    ""Consider upgrading to a version of setuptools ""
                    ""that supports PEP 660 (>= 64)."",
                    self,
                )
            install_editable_legacy(
                global_options=global_options if global_options is not None else [],
                prefix=prefix,
                home=home,
                use_user_site=use_user_site,
                name=self.req.name,
                setup_py_path=self.setup_py_path,
                isolated=self.isolated,
                build_env=self.build_env,
                unpacked_source_directory=self.unpacked_source_directory,
            )
            self.install_succeeded = True
            return

        assert self.is_wheel
        assert self.local_file_path

        install_wheel(
            self.req.name,
            self.local_file_path,
            scheme=scheme,
            req_description=str(self.req),
            pycompile=pycompile,
            warn_script_location=warn_script_location,
            direct_url=self.download_info if self.is_direct else None,
            requested=self.user_supplied,
        )
        self.install_succeeded = True


def check_invalid_constraint_type(req: InstallRequirement) -> str:
    
    problem = """"
    if not req.name:
        problem = ""Unnamed requirements are not allowed as constraints""
    elif req.editable:
        problem = ""Editable requirements are not allowed as constraints""
    elif req.extras:
        problem = ""Constraints cannot have extras""

    if problem:
        deprecated(
            reason=(
                ""Constraints are only allowed to take the form of a package ""
                ""name and a version specifier. Other forms were originally ""
                ""permitted as an accident of the implementation, but were ""
                ""undocumented. The new implementation of the resolver no ""
                ""longer supports these forms.""
            ),
            replacement=""replacing the constraint with a requirement"",
            
            gone_in=None,
            issue=8210,
        )

    return problem


def _has_option(options: Values, reqs: list[InstallRequirement], option: str) -> bool:
    if getattr(options, option, None):
        return True
    for req in reqs:
        if getattr(req, option, None):
            return True
    return False


def check_legacy_setup_py_options(
    options: Values,
    reqs: list[InstallRequirement],
) -> None:
    has_build_options = _has_option(options, reqs, ""build_options"")
    has_global_options = _has_option(options, reqs, ""global_options"")
    if has_build_options or has_global_options:
        deprecated(
            reason=""--build-option and --global-option are deprecated."",
            issue=11859,
            replacement=""to use --config-settings"",
            gone_in=""25.3"",
        )
        logger.warning(
            ""Implying --no-binary=:all: due to the presence of ""
            ""--build-option / --global-option. ""
        )
        options.format_control.disallow_binaries()

import logging
from collections import OrderedDict

from pip._vendor.packaging.utils import canonicalize_name

from pip._internal.req.req_install import InstallRequirement

logger = logging.getLogger(__name__)


class RequirementSet:
    def __init__(self, check_supported_wheels: bool = True) -> None:
        

        self.requirements: dict[str, InstallRequirement] = OrderedDict()
        self.check_supported_wheels = check_supported_wheels

        self.unnamed_requirements: list[InstallRequirement] = []

    def __str__(self) -> str:
        requirements = sorted(
            (req for req in self.requirements.values() if not req.comes_from),
            key=lambda req: canonicalize_name(req.name or """"),
        )
        return "" "".join(str(req.req) for req in requirements)

    def __repr__(self) -> str:
        requirements = sorted(
            self.requirements.values(),
            key=lambda req: canonicalize_name(req.name or """"),
        )

        format_string = ""<{classname} object; {count} requirement(s): {reqs}>""
        return format_string.format(
            classname=self.__class__.__name__,
            count=len(requirements),
            reqs="", "".join(str(req.req) for req in requirements),
        )

    def add_unnamed_requirement(self, install_req: InstallRequirement) -> None:
        assert not install_req.name
        self.unnamed_requirements.append(install_req)

    def add_named_requirement(self, install_req: InstallRequirement) -> None:
        assert install_req.name

        project_name = canonicalize_name(install_req.name)
        self.requirements[project_name] = install_req

    def has_requirement(self, name: str) -> bool:
        project_name = canonicalize_name(name)

        return (
            project_name in self.requirements
            and not self.requirements[project_name].constraint
        )

    def get_requirement(self, name: str) -> InstallRequirement:
        project_name = canonicalize_name(name)

        if project_name in self.requirements:
            return self.requirements[project_name]

        raise KeyError(f""No project with the name {name!r}"")

    @property
    def all_requirements(self) -> list[InstallRequirement]:
        return self.unnamed_requirements + list(self.requirements.values())

    @property
    def requirements_to_install(self) -> list[InstallRequirement]:
        
        return [
            install_req
            for install_req in self.all_requirements
            if not install_req.constraint and not install_req.satisfied_by
        ]

from __future__ import annotations

import functools
import os
import sys
import sysconfig
from collections.abc import Generator, Iterable
from importlib.util import cache_from_source
from typing import Any, Callable

from pip._internal.exceptions import LegacyDistutilsInstall, UninstallMissingRecord
from pip._internal.locations import get_bin_prefix, get_bin_user
from pip._internal.metadata import BaseDistribution
from pip._internal.utils.compat import WINDOWS
from pip._internal.utils.egg_link import egg_link_path_from_location
from pip._internal.utils.logging import getLogger, indent_log
from pip._internal.utils.misc import ask, normalize_path, renames, rmtree
from pip._internal.utils.temp_dir import AdjacentTempDirectory, TempDirectory
from pip._internal.utils.virtualenv import running_under_virtualenv

logger = getLogger(__name__)


def _script_names(
    bin_dir: str, script_name: str, is_gui: bool
) -> Generator[str, None, None]:
    
    exe_name = os.path.join(bin_dir, script_name)
    yield exe_name
    if not WINDOWS:
        return
    yield f""{exe_name}.exe""
    yield f""{exe_name}.exe.manifest""
    if is_gui:
        yield f""{exe_name}-script.pyw""
    else:
        yield f""{exe_name}-script.py""


def _unique(
    fn: Callable[..., Generator[Any, None, None]],
) -> Callable[..., Generator[Any, None, None]]:
    @functools.wraps(fn)
    def unique(*args: Any, **kw: Any) -> Generator[Any, None, None]:
        seen: set[Any] = set()
        for item in fn(*args, **kw):
            if item not in seen:
                seen.add(item)
                yield item

    return unique


@_unique
def uninstallation_paths(dist: BaseDistribution) -> Generator[str, None, None]:
    
    location = dist.location
    assert location is not None, ""not installed""

    entries = dist.iter_declared_entries()
    if entries is None:
        raise UninstallMissingRecord(distribution=dist)

    for entry in entries:
        path = os.path.join(location, entry)
        yield path
        if path.endswith("".py""):
            dn, fn = os.path.split(path)
            base = fn[:-3]
            path = os.path.join(dn, base + "".pyc"")
            yield path
            path = os.path.join(dn, base + "".pyo"")
            yield path


def compact(paths: Iterable[str]) -> set[str]:
    

    sep = os.path.sep
    short_paths: set[str] = set()
    for path in sorted(paths, key=len):
        should_skip = any(
            path.startswith(shortpath.rstrip(""*""))
            and path[len(shortpath.rstrip(""*"").rstrip(sep))] == sep
            for shortpath in short_paths
        )
        if not should_skip:
            short_paths.add(path)
    return short_paths


def compress_for_rename(paths: Iterable[str]) -> set[str]:
    
    case_map = {os.path.normcase(p): p for p in paths}
    remaining = set(case_map)
    unchecked = sorted({os.path.split(p)[0] for p in case_map.values()}, key=len)
    wildcards: set[str] = set()

    def norm_join(*a: str) -> str:
        return os.path.normcase(os.path.join(*a))

    for root in unchecked:
        if any(os.path.normcase(root).startswith(w) for w in wildcards):
            
            continue

        all_files: set[str] = set()
        all_subdirs: set[str] = set()
        for dirname, subdirs, files in os.walk(root):
            all_subdirs.update(norm_join(root, dirname, d) for d in subdirs)
            all_files.update(norm_join(root, dirname, f) for f in files)
        
        
        
        if not (all_files - remaining):
            remaining.difference_update(all_files)
            wildcards.add(root + os.sep)

    return set(map(case_map.__getitem__, remaining)) | wildcards


def compress_for_output_listing(paths: Iterable[str]) -> tuple[set[str], set[str]]:
    

    will_remove = set(paths)
    will_skip = set()

    
    folders = set()
    files = set()
    for path in will_remove:
        if path.endswith("".pyc""):
            continue
        if path.endswith(""__init__.py"") or "".dist-info"" in path:
            folders.add(os.path.dirname(path))
        files.add(path)

    _normcased_files = set(map(os.path.normcase, files))

    folders = compact(folders)

    
    
    for folder in folders:
        for dirpath, _, dirfiles in os.walk(folder):
            for fname in dirfiles:
                if fname.endswith("".pyc""):
                    continue

                file_ = os.path.join(dirpath, fname)
                if (
                    os.path.isfile(file_)
                    and os.path.normcase(file_) not in _normcased_files
                ):
                    
                    will_skip.add(file_)

    will_remove = files | {os.path.join(folder, ""*"") for folder in folders}

    return will_remove, will_skip


class StashedUninstallPathSet:
    

    def __init__(self) -> None:
        
        
        self._save_dirs: dict[str, TempDirectory] = {}
        
        
        self._moves: list[tuple[str, str]] = []

    def _get_directory_stash(self, path: str) -> str:
        

        try:
            save_dir: TempDirectory = AdjacentTempDirectory(path)
        except OSError:
            save_dir = TempDirectory(kind=""uninstall"")
        self._save_dirs[os.path.normcase(path)] = save_dir

        return save_dir.path

    def _get_file_stash(self, path: str) -> str:
        
        path = os.path.normcase(path)
        head, old_head = os.path.dirname(path), None
        save_dir = None

        while head != old_head:
            try:
                save_dir = self._save_dirs[head]
                break
            except KeyError:
                pass
            head, old_head = os.path.dirname(head), head
        else:
            
            head = os.path.dirname(path)
            save_dir = TempDirectory(kind=""uninstall"")
            self._save_dirs[head] = save_dir

        relpath = os.path.relpath(path, head)
        if relpath and relpath != os.path.curdir:
            return os.path.join(save_dir.path, relpath)
        return save_dir.path

    def stash(self, path: str) -> str:
        
        path_is_dir = os.path.isdir(path) and not os.path.islink(path)
        if path_is_dir:
            new_path = self._get_directory_stash(path)
        else:
            new_path = self._get_file_stash(path)

        self._moves.append((path, new_path))
        if path_is_dir and os.path.isdir(new_path):
            
            
            
            
            
            os.rmdir(new_path)
        renames(path, new_path)
        return new_path

    def commit(self) -> None:
        
        for save_dir in self._save_dirs.values():
            save_dir.cleanup()
        self._moves = []
        self._save_dirs = {}

    def rollback(self) -> None:
        
        for p in self._moves:
            logger.info(""Moving to %s\n from %s"", *p)

        for new_path, path in self._moves:
            try:
                logger.debug(""Replacing %s from %s"", new_path, path)
                if os.path.isfile(new_path) or os.path.islink(new_path):
                    os.unlink(new_path)
                elif os.path.isdir(new_path):
                    rmtree(new_path)
                renames(path, new_path)
            except OSError as ex:
                logger.error(""Failed to restore %s"", new_path)
                logger.debug(""Exception: %s"", ex)

        self.commit()

    @property
    def can_rollback(self) -> bool:
        return bool(self._moves)


class UninstallPathSet:
    

    def __init__(self, dist: BaseDistribution) -> None:
        self._paths: set[str] = set()
        self._refuse: set[str] = set()
        self._pth: dict[str, UninstallPthEntries] = {}
        self._dist = dist
        self._moved_paths = StashedUninstallPathSet()
        
        
        
        self._normalize_path_cached = functools.lru_cache(normalize_path)

    def _permitted(self, path: str) -> bool:
        
        
        if not running_under_virtualenv():
            return True
        return path.startswith(self._normalize_path_cached(sys.prefix))

    def add(self, path: str) -> None:
        head, tail = os.path.split(path)

        
        
        path = os.path.join(self._normalize_path_cached(head), os.path.normcase(tail))

        if not os.path.exists(path):
            return
        if self._permitted(path):
            self._paths.add(path)
        else:
            self._refuse.add(path)

        
        
        if os.path.splitext(path)[1] == "".py"":
            self.add(cache_from_source(path))

    def add_pth(self, pth_file: str, entry: str) -> None:
        pth_file = self._normalize_path_cached(pth_file)
        if self._permitted(pth_file):
            if pth_file not in self._pth:
                self._pth[pth_file] = UninstallPthEntries(pth_file)
            self._pth[pth_file].add(entry)
        else:
            self._refuse.add(pth_file)

    def remove(self, auto_confirm: bool = False, verbose: bool = False) -> None:
        

        if not self._paths:
            logger.info(
                ""Can't uninstall '%s'. No files were found to uninstall."",
                self._dist.raw_name,
            )
            return

        dist_name_version = f""{self._dist.raw_name}-{self._dist.raw_version}""
        logger.info(""Uninstalling %s:"", dist_name_version)

        with indent_log():
            if auto_confirm or self._allowed_to_proceed(verbose):
                moved = self._moved_paths

                for_rename = compress_for_rename(self._paths)

                for path in sorted(compact(for_rename)):
                    moved.stash(path)
                    logger.verbose(""Removing file or directory %s"", path)

                for pth in self._pth.values():
                    pth.remove()

                logger.info(""Successfully uninstalled %s"", dist_name_version)

    def _allowed_to_proceed(self, verbose: bool) -> bool:
        

        def _display(msg: str, paths: Iterable[str]) -> None:
            if not paths:
                return

            logger.info(msg)
            with indent_log():
                for path in sorted(compact(paths)):
                    logger.info(path)

        if not verbose:
            will_remove, will_skip = compress_for_output_listing(self._paths)
        else:
            
            
            will_remove = set(self._paths)
            will_skip = set()

        _display(""Would remove:"", will_remove)
        _display(""Would not remove (might be manually added):"", will_skip)
        _display(""Would not remove (outside of prefix):"", self._refuse)
        if verbose:
            _display(""Will actually move:"", compress_for_rename(self._paths))

        return ask(""Proceed (Y/n)? "", (""y"", ""n"", """")) != ""n""

    def rollback(self) -> None:
        
        if not self._moved_paths.can_rollback:
            logger.error(
                ""Can't roll back %s; was not uninstalled"",
                self._dist.raw_name,
            )
            return
        logger.info(""Rolling back uninstall of %s"", self._dist.raw_name)
        self._moved_paths.rollback()
        for pth in self._pth.values():
            pth.rollback()

    def commit(self) -> None:
        
        self._moved_paths.commit()

    @classmethod
    def from_dist(cls, dist: BaseDistribution) -> UninstallPathSet:
        dist_location = dist.location
        info_location = dist.info_location
        if dist_location is None:
            logger.info(
                ""Not uninstalling %s since it is not installed"",
                dist.canonical_name,
            )
            return cls(dist)

        normalized_dist_location = normalize_path(dist_location)
        if not dist.local:
            logger.info(
                ""Not uninstalling %s at %s, outside environment %s"",
                dist.canonical_name,
                normalized_dist_location,
                sys.prefix,
            )
            return cls(dist)

        if normalized_dist_location in {
            p
            for p in {sysconfig.get_path(""stdlib""), sysconfig.get_path(""platstdlib"")}
            if p
        }:
            logger.info(
                ""Not uninstalling %s at %s, as it is in the standard library."",
                dist.canonical_name,
                normalized_dist_location,
            )
            return cls(dist)

        paths_to_remove = cls(dist)
        develop_egg_link = egg_link_path_from_location(dist.raw_name)

        
        
        
        setuptools_flat_installation = (
            dist.installed_with_setuptools_egg_info
            and info_location is not None
            and os.path.exists(info_location)
            
            
            and not info_location.endswith(f""{dist.setuptools_filename}.egg-info"")
        )

        
        
        if setuptools_flat_installation:
            if info_location is not None:
                paths_to_remove.add(info_location)
            installed_files = dist.iter_declared_entries()
            if installed_files is not None:
                for installed_file in installed_files:
                    paths_to_remove.add(os.path.join(dist_location, installed_file))
            
            
            
            elif dist.is_file(""top_level.txt""):
                try:
                    namespace_packages = dist.read_text(""namespace_packages.txt"")
                except FileNotFoundError:
                    namespaces = []
                else:
                    namespaces = namespace_packages.splitlines(keepends=False)
                for top_level_pkg in [
                    p
                    for p in dist.read_text(""top_level.txt"").splitlines()
                    if p and p not in namespaces
                ]:
                    path = os.path.join(dist_location, top_level_pkg)
                    paths_to_remove.add(path)
                    paths_to_remove.add(f""{path}.py"")
                    paths_to_remove.add(f""{path}.pyc"")
                    paths_to_remove.add(f""{path}.pyo"")

        elif dist.installed_by_distutils:
            raise LegacyDistutilsInstall(distribution=dist)

        elif dist.installed_as_egg:
            
            
            
            
            
            
            paths_to_remove.add(normalized_dist_location)
            easy_install_egg = os.path.split(normalized_dist_location)[1]
            easy_install_pth = os.path.join(
                os.path.dirname(normalized_dist_location),
                ""easy-install.pth"",
            )
            paths_to_remove.add_pth(easy_install_pth, ""./"" + easy_install_egg)

        elif dist.installed_with_dist_info:
            for path in uninstallation_paths(dist):
                paths_to_remove.add(path)

        elif develop_egg_link:
            
            
            with open(develop_egg_link) as fh:
                link_pointer = os.path.normcase(fh.readline().strip())
                normalized_link_pointer = paths_to_remove._normalize_path_cached(
                    link_pointer
                )
            assert os.path.samefile(
                normalized_link_pointer, normalized_dist_location
            ), (
                f""Egg-link {develop_egg_link} (to {link_pointer}) does not match ""
                f""installed location of {dist.raw_name} (at {dist_location})""
            )
            paths_to_remove.add(develop_egg_link)
            easy_install_pth = os.path.join(
                os.path.dirname(develop_egg_link), ""easy-install.pth""
            )
            paths_to_remove.add_pth(easy_install_pth, dist_location)

        else:
            logger.debug(
                ""Not sure how to uninstall: %s - Check: %s"",
                dist,
                dist_location,
            )

        if dist.in_usersite:
            bin_dir = get_bin_user()
        else:
            bin_dir = get_bin_prefix()

        
        try:
            for script in dist.iter_distutils_script_names():
                paths_to_remove.add(os.path.join(bin_dir, script))
                if WINDOWS:
                    paths_to_remove.add(os.path.join(bin_dir, f""{script}.bat""))
        except (FileNotFoundError, NotADirectoryError):
            pass

        
        def iter_scripts_to_remove(
            dist: BaseDistribution,
            bin_dir: str,
        ) -> Generator[str, None, None]:
            for entry_point in dist.iter_entry_points():
                if entry_point.group == ""console_scripts"":
                    yield from _script_names(bin_dir, entry_point.name, False)
                elif entry_point.group == ""gui_scripts"":
                    yield from _script_names(bin_dir, entry_point.name, True)

        for s in iter_scripts_to_remove(dist, bin_dir):
            paths_to_remove.add(s)

        return paths_to_remove


class UninstallPthEntries:
    def __init__(self, pth_file: str) -> None:
        self.file = pth_file
        self.entries: set[str] = set()
        self._saved_lines: list[bytes] | None = None

    def add(self, entry: str) -> None:
        entry = os.path.normcase(entry)
        
        
        
        
        
        
        
        
        
        if WINDOWS and not os.path.splitdrive(entry)[0]:
            entry = entry.replace(""\\"", ""/"")
        self.entries.add(entry)

    def remove(self) -> None:
        logger.verbose(""Removing pth entries from %s:"", self.file)

        
        if not os.path.isfile(self.file):
            logger.warning(""Cannot remove entries from nonexistent file %s"", self.file)
            return
        with open(self.file, ""rb"") as fh:
            
            lines = fh.readlines()
            self._saved_lines = lines
        if any(b""\r\n"" in line for line in lines):
            endline = ""\r\n""
        else:
            endline = ""\n""
        
        if lines and not lines[-1].endswith(endline.encode(""utf-8"")):
            lines[-1] = lines[-1] + endline.encode(""utf-8"")
        for entry in self.entries:
            try:
                logger.verbose(""Removing entry: %s"", entry)
                lines.remove((entry + endline).encode(""utf-8""))
            except ValueError:
                pass
        with open(self.file, ""wb"") as fh:
            fh.writelines(lines)

    def rollback(self) -> bool:
        if self._saved_lines is None:
            logger.error(""Cannot roll back changes to %s, none were made"", self.file)
            return False
        logger.debug(""Rolling %s back to previous state"", self.file)
        with open(self.file, ""wb"") as fh:
            fh.writelines(self._saved_lines)
        return True

from __future__ import annotations

import collections
import logging
from collections.abc import Generator, Sequence
from dataclasses import dataclass

from pip._internal.cli.progress_bars import BarType, get_install_progress_renderer
from pip._internal.utils.logging import indent_log

from .req_file import parse_requirements
from .req_install import InstallRequirement
from .req_set import RequirementSet

__all__ = [
    ""RequirementSet"",
    ""InstallRequirement"",
    ""parse_requirements"",
    ""install_given_reqs"",
]

logger = logging.getLogger(__name__)


@dataclass(frozen=True)
class InstallationResult:
    name: str


def _validate_requirements(
    requirements: list[InstallRequirement],
) -> Generator[tuple[str, InstallRequirement], None, None]:
    for req in requirements:
        assert req.name, f""invalid to-be-installed requirement: {req}""
        yield req.name, req


def install_given_reqs(
    requirements: list[InstallRequirement],
    global_options: Sequence[str],
    root: str | None,
    home: str | None,
    prefix: str | None,
    warn_script_location: bool,
    use_user_site: bool,
    pycompile: bool,
    progress_bar: BarType,
) -> list[InstallationResult]:
    
    to_install = collections.OrderedDict(_validate_requirements(requirements))

    if to_install:
        logger.info(
            ""Installing collected packages: %s"",
            "", "".join(to_install.keys()),
        )

    installed = []

    show_progress = logger.isEnabledFor(logging.INFO) and len(to_install) > 1

    items = iter(to_install.values())
    if show_progress:
        renderer = get_install_progress_renderer(
            bar_type=progress_bar, total=len(to_install)
        )
        items = renderer(items)

    with indent_log():
        for requirement in items:
            req_name = requirement.name
            assert req_name is not None
            if requirement.should_reinstall:
                logger.info(""Attempting uninstall: %s"", req_name)
                with indent_log():
                    uninstalled_pathset = requirement.uninstall(auto_confirm=True)
            else:
                uninstalled_pathset = None

            try:
                requirement.install(
                    global_options,
                    root=root,
                    home=home,
                    prefix=prefix,
                    warn_script_location=warn_script_location,
                    use_user_site=use_user_site,
                    pycompile=pycompile,
                )
            except Exception:
                
                if uninstalled_pathset and not requirement.install_succeeded:
                    uninstalled_pathset.rollback()
                raise
            else:
                if uninstalled_pathset and requirement.install_succeeded:
                    uninstalled_pathset.commit()

            installed.append(InstallationResult(req_name))

    return installed

from typing import Callable, Optional

from pip._internal.req.req_install import InstallRequirement
from pip._internal.req.req_set import RequirementSet

InstallRequirementProvider = Callable[
    [str, Optional[InstallRequirement]], InstallRequirement
]


class BaseResolver:
    def resolve(
        self, root_reqs: list[InstallRequirement], check_supported_wheels: bool
    ) -> RequirementSet:
        raise NotImplementedError()

    def get_installation_order(
        self, req_set: RequirementSet
    ) -> list[InstallRequirement]:
        raise NotImplementedError()




from __future__ import annotations

import logging
import sys
from collections import defaultdict
from collections.abc import Iterable
from itertools import chain
from typing import Optional

from pip._vendor.packaging import specifiers
from pip._vendor.packaging.requirements import Requirement

from pip._internal.cache import WheelCache
from pip._internal.exceptions import (
    BestVersionAlreadyInstalled,
    DistributionNotFound,
    HashError,
    HashErrors,
    InstallationError,
    NoneMetadataError,
    UnsupportedPythonVersion,
)
from pip._internal.index.package_finder import PackageFinder
from pip._internal.metadata import BaseDistribution
from pip._internal.models.link import Link
from pip._internal.models.wheel import Wheel
from pip._internal.operations.prepare import RequirementPreparer
from pip._internal.req.req_install import (
    InstallRequirement,
    check_invalid_constraint_type,
)
from pip._internal.req.req_set import RequirementSet
from pip._internal.resolution.base import BaseResolver, InstallRequirementProvider
from pip._internal.utils import compatibility_tags
from pip._internal.utils.compatibility_tags import get_supported
from pip._internal.utils.direct_url_helpers import direct_url_from_link
from pip._internal.utils.logging import indent_log
from pip._internal.utils.misc import normalize_version_info
from pip._internal.utils.packaging import check_requires_python

logger = logging.getLogger(__name__)

DiscoveredDependencies = defaultdict[Optional[str], list[InstallRequirement]]


def _check_dist_requires_python(
    dist: BaseDistribution,
    version_info: tuple[int, int, int],
    ignore_requires_python: bool = False,
) -> None:
    
    
    
    
    try:
        requires_python = str(dist.requires_python)
    except FileNotFoundError as e:
        raise NoneMetadataError(dist, str(e))
    try:
        is_compatible = check_requires_python(
            requires_python,
            version_info=version_info,
        )
    except specifiers.InvalidSpecifier as exc:
        logger.warning(
            ""Package %r has an invalid Requires-Python: %s"", dist.raw_name, exc
        )
        return

    if is_compatible:
        return

    version = ""."".join(map(str, version_info))
    if ignore_requires_python:
        logger.debug(
            ""Ignoring failed Requires-Python check for package %r: %s not in %r"",
            dist.raw_name,
            version,
            requires_python,
        )
        return

    raise UnsupportedPythonVersion(
        f""Package {dist.raw_name!r} requires a different Python: ""
        f""{version} not in {requires_python!r}""
    )


class Resolver(BaseResolver):
    

    _allowed_strategies = {""eager"", ""only-if-needed"", ""to-satisfy-only""}

    def __init__(
        self,
        preparer: RequirementPreparer,
        finder: PackageFinder,
        wheel_cache: WheelCache | None,
        make_install_req: InstallRequirementProvider,
        use_user_site: bool,
        ignore_dependencies: bool,
        ignore_installed: bool,
        ignore_requires_python: bool,
        force_reinstall: bool,
        upgrade_strategy: str,
        py_version_info: tuple[int, ...] | None = None,
    ) -> None:
        super().__init__()
        assert upgrade_strategy in self._allowed_strategies

        if py_version_info is None:
            py_version_info = sys.version_info[:3]
        else:
            py_version_info = normalize_version_info(py_version_info)

        self._py_version_info = py_version_info

        self.preparer = preparer
        self.finder = finder
        self.wheel_cache = wheel_cache

        self.upgrade_strategy = upgrade_strategy
        self.force_reinstall = force_reinstall
        self.ignore_dependencies = ignore_dependencies
        self.ignore_installed = ignore_installed
        self.ignore_requires_python = ignore_requires_python
        self.use_user_site = use_user_site
        self._make_install_req = make_install_req

        self._discovered_dependencies: DiscoveredDependencies = defaultdict(list)

    def resolve(
        self, root_reqs: list[InstallRequirement], check_supported_wheels: bool
    ) -> RequirementSet:
        
        requirement_set = RequirementSet(check_supported_wheels=check_supported_wheels)
        for req in root_reqs:
            if req.constraint:
                check_invalid_constraint_type(req)
            self._add_requirement_to_set(requirement_set, req)

        
        
        
        
        discovered_reqs: list[InstallRequirement] = []
        hash_errors = HashErrors()
        for req in chain(requirement_set.all_requirements, discovered_reqs):
            try:
                discovered_reqs.extend(self._resolve_one(requirement_set, req))
            except HashError as exc:
                exc.req = req
                hash_errors.append(exc)

        if hash_errors:
            raise hash_errors

        return requirement_set

    def _add_requirement_to_set(
        self,
        requirement_set: RequirementSet,
        install_req: InstallRequirement,
        parent_req_name: str | None = None,
        extras_requested: Iterable[str] | None = None,
    ) -> tuple[list[InstallRequirement], InstallRequirement | None]:
        
        
        if not install_req.match_markers(extras_requested):
            logger.info(
                ""Ignoring %s: markers '%s' don't match your environment"",
                install_req.name,
                install_req.markers,
            )
            return [], None

        
        
        
        
        if install_req.link and install_req.link.is_wheel:
            wheel = Wheel(install_req.link.filename)
            tags = compatibility_tags.get_supported()
            if requirement_set.check_supported_wheels and not wheel.supported(tags):
                raise InstallationError(
                    f""{wheel.filename} is not a supported wheel on this platform.""
                )

        
        assert (
            not install_req.user_supplied or parent_req_name is None
        ), ""a user supplied req shouldn't have a parent""

        
        
        if not install_req.name:
            requirement_set.add_unnamed_requirement(install_req)
            return [install_req], None

        try:
            existing_req: InstallRequirement | None = requirement_set.get_requirement(
                install_req.name
            )
        except KeyError:
            existing_req = None

        has_conflicting_requirement = (
            parent_req_name is None
            and existing_req
            and not existing_req.constraint
            and existing_req.extras == install_req.extras
            and existing_req.req
            and install_req.req
            and existing_req.req.specifier != install_req.req.specifier
        )
        if has_conflicting_requirement:
            raise InstallationError(
                f""Double requirement given: {install_req} ""
                f""(already in {existing_req}, name={install_req.name!r})""
            )

        
        
        if not existing_req:
            requirement_set.add_named_requirement(install_req)
            
            return [install_req], install_req

        
        
        if install_req.constraint or not existing_req.constraint:
            return [], existing_req

        does_not_satisfy_constraint = install_req.link and not (
            existing_req.link and install_req.link.path == existing_req.link.path
        )
        if does_not_satisfy_constraint:
            raise InstallationError(
                f""Could not satisfy constraints for '{install_req.name}': ""
                ""installation from path or url cannot be ""
                ""constrained to a version""
            )
        
        
        existing_req.constraint = False
        
        
        if install_req.user_supplied:
            existing_req.user_supplied = True
        existing_req.extras = tuple(
            sorted(set(existing_req.extras) | set(install_req.extras))
        )
        logger.debug(
            ""Setting %s extras to: %s"",
            existing_req,
            existing_req.extras,
        )
        
        
        return [existing_req], existing_req

    def _is_upgrade_allowed(self, req: InstallRequirement) -> bool:
        if self.upgrade_strategy == ""to-satisfy-only"":
            return False
        elif self.upgrade_strategy == ""eager"":
            return True
        else:
            assert self.upgrade_strategy == ""only-if-needed""
            return req.user_supplied or req.constraint

    def _set_req_to_reinstall(self, req: InstallRequirement) -> None:
        
        
        
        assert req.satisfied_by is not None
        if not self.use_user_site or req.satisfied_by.in_usersite:
            req.should_reinstall = True
        req.satisfied_by = None

    def _check_skip_installed(self, req_to_install: InstallRequirement) -> str | None:
        
        if self.ignore_installed:
            return None

        req_to_install.check_if_exists(self.use_user_site)
        if not req_to_install.satisfied_by:
            return None

        if self.force_reinstall:
            self._set_req_to_reinstall(req_to_install)
            return None

        if not self._is_upgrade_allowed(req_to_install):
            if self.upgrade_strategy == ""only-if-needed"":
                return ""already satisfied, skipping upgrade""
            return ""already satisfied""

        
        
        
        if not req_to_install.link:
            try:
                self.finder.find_requirement(req_to_install, upgrade=True)
            except BestVersionAlreadyInstalled:
                
                return ""already up-to-date""
            except DistributionNotFound:
                
                
                
                pass

        self._set_req_to_reinstall(req_to_install)
        return None

    def _find_requirement_link(self, req: InstallRequirement) -> Link | None:
        upgrade = self._is_upgrade_allowed(req)
        best_candidate = self.finder.find_requirement(req, upgrade)
        if not best_candidate:
            return None

        
        link = best_candidate.link
        if link.is_yanked:
            reason = link.yanked_reason or ""<none given>""
            msg = (
                
                
                
                ""The candidate selected for download or install is a ""
                f""yanked version: {best_candidate}\n""
                f""Reason for being yanked: {reason}""
            )
            logger.warning(msg)

        return link

    def _populate_link(self, req: InstallRequirement) -> None:
        
        if req.link is None:
            req.link = self._find_requirement_link(req)

        if self.wheel_cache is None or self.preparer.require_hashes:
            return

        assert req.link is not None, ""_find_requirement_link unexpectedly returned None""
        cache_entry = self.wheel_cache.get_cache_entry(
            link=req.link,
            package_name=req.name,
            supported_tags=get_supported(),
        )
        if cache_entry is not None:
            logger.debug(""Using cached wheel link: %s"", cache_entry.link)
            if req.link is req.original_link and cache_entry.persistent:
                req.cached_wheel_source_link = req.link
            if cache_entry.origin is not None:
                req.download_info = cache_entry.origin
            else:
                
                
                req.download_info = direct_url_from_link(
                    req.link, link_is_in_wheel_cache=cache_entry.persistent
                )
            req.link = cache_entry.link

    def _get_dist_for(self, req: InstallRequirement) -> BaseDistribution:
        
        if req.editable:
            return self.preparer.prepare_editable_requirement(req)

        
        
        assert req.satisfied_by is None
        skip_reason = self._check_skip_installed(req)

        if req.satisfied_by:
            return self.preparer.prepare_installed_requirement(req, skip_reason)

        
        self._populate_link(req)
        dist = self.preparer.prepare_linked_requirement(req)

        
        
        
        

        
        
        
        if not self.ignore_installed:
            req.check_if_exists(self.use_user_site)

        if req.satisfied_by:
            should_modify = (
                self.upgrade_strategy != ""to-satisfy-only""
                or self.force_reinstall
                or self.ignore_installed
                or req.link.scheme == ""file""
            )
            if should_modify:
                self._set_req_to_reinstall(req)
            else:
                logger.info(
                    ""Requirement already satisfied (use --upgrade to upgrade): %s"",
                    req,
                )
        return dist

    def _resolve_one(
        self,
        requirement_set: RequirementSet,
        req_to_install: InstallRequirement,
    ) -> list[InstallRequirement]:
        
        
        
        
        if req_to_install.constraint or req_to_install.prepared:
            return []

        req_to_install.prepared = True

        
        dist = self._get_dist_for(req_to_install)
        
        
        _check_dist_requires_python(
            dist,
            version_info=self._py_version_info,
            ignore_requires_python=self.ignore_requires_python,
        )

        more_reqs: list[InstallRequirement] = []

        def add_req(subreq: Requirement, extras_requested: Iterable[str]) -> None:
            
            
            
            sub_install_req = self._make_install_req(str(subreq), req_to_install)
            parent_req_name = req_to_install.name
            to_scan_again, add_to_parent = self._add_requirement_to_set(
                requirement_set,
                sub_install_req,
                parent_req_name=parent_req_name,
                extras_requested=extras_requested,
            )
            if parent_req_name and add_to_parent:
                self._discovered_dependencies[parent_req_name].append(add_to_parent)
            more_reqs.extend(to_scan_again)

        with indent_log():
            
            
            assert req_to_install.name is not None
            if not requirement_set.has_requirement(req_to_install.name):
                
                
                
                assert req_to_install.user_supplied
                self._add_requirement_to_set(
                    requirement_set, req_to_install, parent_req_name=None
                )

            if not self.ignore_dependencies:
                if req_to_install.extras:
                    logger.debug(
                        ""Installing extra requirements: %r"",
                        "","".join(req_to_install.extras),
                    )
                missing_requested = sorted(
                    set(req_to_install.extras) - set(dist.iter_provided_extras())
                )
                for missing in missing_requested:
                    logger.warning(
                        ""%s %s does not provide the extra '%s'"",
                        dist.raw_name,
                        dist.version,
                        missing,
                    )

                available_requested = sorted(
                    set(dist.iter_provided_extras()) & set(req_to_install.extras)
                )
                for subreq in dist.iter_dependencies(available_requested):
                    add_req(subreq, extras_requested=available_requested)

        return more_reqs

    def get_installation_order(
        self, req_set: RequirementSet
    ) -> list[InstallRequirement]:
        
        
        
        
        order = []
        ordered_reqs: set[InstallRequirement] = set()

        def schedule(req: InstallRequirement) -> None:
            if req.satisfied_by or req in ordered_reqs:
                return
            if req.constraint:
                return
            ordered_reqs.add(req)
            for dep in self._discovered_dependencies[req.name]:
                schedule(dep)
            order.append(req)

        for install_req in req_set.requirements.values():
            schedule(install_req)
        return order


from __future__ import annotations

from collections.abc import Iterable
from dataclasses import dataclass
from typing import Optional

from pip._vendor.packaging.specifiers import SpecifierSet
from pip._vendor.packaging.utils import NormalizedName
from pip._vendor.packaging.version import Version

from pip._internal.models.link import Link, links_equivalent
from pip._internal.req.req_install import InstallRequirement
from pip._internal.utils.hashes import Hashes

CandidateLookup = tuple[Optional[""Candidate""], Optional[InstallRequirement]]


def format_name(project: NormalizedName, extras: frozenset[NormalizedName]) -> str:
    if not extras:
        return project
    extras_expr = "","".join(sorted(extras))
    return f""{project}[{extras_expr}]""


@dataclass(frozen=True)
class Constraint:
    specifier: SpecifierSet
    hashes: Hashes
    links: frozenset[Link]

    @classmethod
    def empty(cls) -> Constraint:
        return Constraint(SpecifierSet(), Hashes(), frozenset())

    @classmethod
    def from_ireq(cls, ireq: InstallRequirement) -> Constraint:
        links = frozenset([ireq.link]) if ireq.link else frozenset()
        return Constraint(ireq.specifier, ireq.hashes(trust_internet=False), links)

    def __bool__(self) -> bool:
        return bool(self.specifier) or bool(self.hashes) or bool(self.links)

    def __and__(self, other: InstallRequirement) -> Constraint:
        if not isinstance(other, InstallRequirement):
            return NotImplemented
        specifier = self.specifier & other.specifier
        hashes = self.hashes & other.hashes(trust_internet=False)
        links = self.links
        if other.link:
            links = links.union([other.link])
        return Constraint(specifier, hashes, links)

    def is_satisfied_by(self, candidate: Candidate) -> bool:
        
        if self.links and not all(_match_link(link, candidate) for link in self.links):
            return False
        
        
        
        return self.specifier.contains(candidate.version, prereleases=True)


class Requirement:
    @property
    def project_name(self) -> NormalizedName:
        
        raise NotImplementedError(""Subclass should override"")

    @property
    def name(self) -> str:
        
        raise NotImplementedError(""Subclass should override"")

    def is_satisfied_by(self, candidate: Candidate) -> bool:
        return False

    def get_candidate_lookup(self) -> CandidateLookup:
        raise NotImplementedError(""Subclass should override"")

    def format_for_error(self) -> str:
        raise NotImplementedError(""Subclass should override"")


def _match_link(link: Link, candidate: Candidate) -> bool:
    if candidate.source_link:
        return links_equivalent(link, candidate.source_link)
    return False


class Candidate:
    @property
    def project_name(self) -> NormalizedName:
        
        raise NotImplementedError(""Override in subclass"")

    @property
    def name(self) -> str:
        
        raise NotImplementedError(""Override in subclass"")

    @property
    def version(self) -> Version:
        raise NotImplementedError(""Override in subclass"")

    @property
    def is_installed(self) -> bool:
        raise NotImplementedError(""Override in subclass"")

    @property
    def is_editable(self) -> bool:
        raise NotImplementedError(""Override in subclass"")

    @property
    def source_link(self) -> Link | None:
        raise NotImplementedError(""Override in subclass"")

    def iter_dependencies(self, with_requires: bool) -> Iterable[Requirement | None]:
        raise NotImplementedError(""Override in subclass"")

    def get_install_requirement(self) -> InstallRequirement | None:
        raise NotImplementedError(""Override in subclass"")

    def format_for_error(self) -> str:
        raise NotImplementedError(""Subclass should override"")

from __future__ import annotations

import logging
import sys
from collections.abc import Iterable
from typing import TYPE_CHECKING, Any, Union, cast

from pip._vendor.packaging.requirements import InvalidRequirement
from pip._vendor.packaging.utils import NormalizedName, canonicalize_name
from pip._vendor.packaging.version import Version

from pip._internal.exceptions import (
    HashError,
    InstallationSubprocessError,
    InvalidInstalledPackage,
    MetadataInconsistent,
    MetadataInvalid,
)
from pip._internal.metadata import BaseDistribution
from pip._internal.models.link import Link, links_equivalent
from pip._internal.models.wheel import Wheel
from pip._internal.req.constructors import (
    install_req_from_editable,
    install_req_from_line,
)
from pip._internal.req.req_install import InstallRequirement
from pip._internal.utils.direct_url_helpers import direct_url_from_link
from pip._internal.utils.misc import normalize_version_info

from .base import Candidate, Requirement, format_name

if TYPE_CHECKING:
    from .factory import Factory

logger = logging.getLogger(__name__)

BaseCandidate = Union[
    ""AlreadyInstalledCandidate"",
    ""EditableCandidate"",
    ""LinkCandidate"",
]


REQUIRES_PYTHON_IDENTIFIER = cast(NormalizedName, ""<Python from Requires-Python>"")


def as_base_candidate(candidate: Candidate) -> BaseCandidate | None:
    
    base_candidate_classes = (
        AlreadyInstalledCandidate,
        EditableCandidate,
        LinkCandidate,
    )
    if isinstance(candidate, base_candidate_classes):
        return candidate
    return None


def make_install_req_from_link(
    link: Link, template: InstallRequirement
) -> InstallRequirement:
    assert not template.editable, ""template is editable""
    if template.req:
        line = str(template.req)
    else:
        line = link.url
    ireq = install_req_from_line(
        line,
        user_supplied=template.user_supplied,
        comes_from=template.comes_from,
        use_pep517=template.use_pep517,
        isolated=template.isolated,
        constraint=template.constraint,
        global_options=template.global_options,
        hash_options=template.hash_options,
        config_settings=template.config_settings,
    )
    ireq.original_link = template.original_link
    ireq.link = link
    ireq.extras = template.extras
    return ireq


def make_install_req_from_editable(
    link: Link, template: InstallRequirement
) -> InstallRequirement:
    assert template.editable, ""template not editable""
    ireq = install_req_from_editable(
        link.url,
        user_supplied=template.user_supplied,
        comes_from=template.comes_from,
        use_pep517=template.use_pep517,
        isolated=template.isolated,
        constraint=template.constraint,
        permit_editable_wheels=template.permit_editable_wheels,
        global_options=template.global_options,
        hash_options=template.hash_options,
        config_settings=template.config_settings,
    )
    ireq.extras = template.extras
    return ireq


def _make_install_req_from_dist(
    dist: BaseDistribution, template: InstallRequirement
) -> InstallRequirement:
    if template.req:
        line = str(template.req)
    elif template.link:
        line = f""{dist.canonical_name} @ {template.link.url}""
    else:
        line = f""{dist.canonical_name}=={dist.version}""
    ireq = install_req_from_line(
        line,
        user_supplied=template.user_supplied,
        comes_from=template.comes_from,
        use_pep517=template.use_pep517,
        isolated=template.isolated,
        constraint=template.constraint,
        global_options=template.global_options,
        hash_options=template.hash_options,
        config_settings=template.config_settings,
    )
    ireq.satisfied_by = dist
    return ireq


class _InstallRequirementBackedCandidate(Candidate):
    

    dist: BaseDistribution
    is_installed = False

    def __init__(
        self,
        link: Link,
        source_link: Link,
        ireq: InstallRequirement,
        factory: Factory,
        name: NormalizedName | None = None,
        version: Version | None = None,
    ) -> None:
        self._link = link
        self._source_link = source_link
        self._factory = factory
        self._ireq = ireq
        self._name = name
        self._version = version
        self.dist = self._prepare()
        self._hash: int | None = None

    def __str__(self) -> str:
        return f""{self.name} {self.version}""

    def __repr__(self) -> str:
        return f""{self.__class__.__name__}({str(self._link)!r})""

    def __hash__(self) -> int:
        if self._hash is not None:
            return self._hash

        self._hash = hash((self.__class__, self._link))
        return self._hash

    def __eq__(self, other: Any) -> bool:
        if isinstance(other, self.__class__):
            return links_equivalent(self._link, other._link)
        return False

    @property
    def source_link(self) -> Link | None:
        return self._source_link

    @property
    def project_name(self) -> NormalizedName:
        
        if self._name is None:
            self._name = self.dist.canonical_name
        return self._name

    @property
    def name(self) -> str:
        return self.project_name

    @property
    def version(self) -> Version:
        if self._version is None:
            self._version = self.dist.version
        return self._version

    def format_for_error(self) -> str:
        return (
            f""{self.name} {self.version} ""
            f""(from {self._link.file_path if self._link.is_file else self._link})""
        )

    def _prepare_distribution(self) -> BaseDistribution:
        raise NotImplementedError(""Override in subclass"")

    def _check_metadata_consistency(self, dist: BaseDistribution) -> None:
        
        if self._name is not None and self._name != dist.canonical_name:
            raise MetadataInconsistent(
                self._ireq,
                ""name"",
                self._name,
                dist.canonical_name,
            )
        if self._version is not None and self._version != dist.version:
            raise MetadataInconsistent(
                self._ireq,
                ""version"",
                str(self._version),
                str(dist.version),
            )
        
        
        
        try:
            list(dist.iter_dependencies(list(dist.iter_provided_extras())))
        except InvalidRequirement as e:
            raise MetadataInvalid(self._ireq, str(e))

    def _prepare(self) -> BaseDistribution:
        try:
            dist = self._prepare_distribution()
        except HashError as e:
            
            
            
            e.req = self._ireq
            raise
        except InstallationSubprocessError as exc:
            
            exc.context = ""See above for output.""
            raise

        self._check_metadata_consistency(dist)
        return dist

    def iter_dependencies(self, with_requires: bool) -> Iterable[Requirement | None]:
        
        
        yield self._factory.make_requires_python_requirement(self.dist.requires_python)
        requires = self.dist.iter_dependencies() if with_requires else ()
        for r in requires:
            yield from self._factory.make_requirements_from_spec(str(r), self._ireq)

    def get_install_requirement(self) -> InstallRequirement | None:
        return self._ireq


class LinkCandidate(_InstallRequirementBackedCandidate):
    is_editable = False

    def __init__(
        self,
        link: Link,
        template: InstallRequirement,
        factory: Factory,
        name: NormalizedName | None = None,
        version: Version | None = None,
    ) -> None:
        source_link = link
        cache_entry = factory.get_wheel_cache_entry(source_link, name)
        if cache_entry is not None:
            logger.debug(""Using cached wheel link: %s"", cache_entry.link)
            link = cache_entry.link
        ireq = make_install_req_from_link(link, template)
        assert ireq.link == link
        if ireq.link.is_wheel and not ireq.link.is_file:
            wheel = Wheel(ireq.link.filename)
            wheel_name = canonicalize_name(wheel.name)
            assert name == wheel_name, f""{name!r} != {wheel_name!r} for wheel""
            
            if version is not None:
                wheel_version = Version(wheel.version)
                assert (
                    version == wheel_version
                ), f""{version!r} != {wheel_version!r} for wheel {name}""

        if cache_entry is not None:
            assert ireq.link.is_wheel
            assert ireq.link.is_file
            if cache_entry.persistent and template.link is template.original_link:
                ireq.cached_wheel_source_link = source_link
            if cache_entry.origin is not None:
                ireq.download_info = cache_entry.origin
            else:
                
                
                ireq.download_info = direct_url_from_link(
                    source_link, link_is_in_wheel_cache=cache_entry.persistent
                )

        super().__init__(
            link=link,
            source_link=source_link,
            ireq=ireq,
            factory=factory,
            name=name,
            version=version,
        )

    def _prepare_distribution(self) -> BaseDistribution:
        preparer = self._factory.preparer
        return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)


class EditableCandidate(_InstallRequirementBackedCandidate):
    is_editable = True

    def __init__(
        self,
        link: Link,
        template: InstallRequirement,
        factory: Factory,
        name: NormalizedName | None = None,
        version: Version | None = None,
    ) -> None:
        super().__init__(
            link=link,
            source_link=link,
            ireq=make_install_req_from_editable(link, template),
            factory=factory,
            name=name,
            version=version,
        )

    def _prepare_distribution(self) -> BaseDistribution:
        return self._factory.preparer.prepare_editable_requirement(self._ireq)


class AlreadyInstalledCandidate(Candidate):
    is_installed = True
    source_link = None

    def __init__(
        self,
        dist: BaseDistribution,
        template: InstallRequirement,
        factory: Factory,
    ) -> None:
        self.dist = dist
        self._ireq = _make_install_req_from_dist(dist, template)
        self._factory = factory
        self._version = None

        
        
        
        
        skip_reason = ""already satisfied""
        factory.preparer.prepare_installed_requirement(self._ireq, skip_reason)

    def __str__(self) -> str:
        return str(self.dist)

    def __repr__(self) -> str:
        return f""{self.__class__.__name__}({self.dist!r})""

    def __eq__(self, other: object) -> bool:
        if not isinstance(other, AlreadyInstalledCandidate):
            return NotImplemented
        return self.name == other.name and self.version == other.version

    def __hash__(self) -> int:
        return hash((self.name, self.version))

    @property
    def project_name(self) -> NormalizedName:
        return self.dist.canonical_name

    @property
    def name(self) -> str:
        return self.project_name

    @property
    def version(self) -> Version:
        if self._version is None:
            self._version = self.dist.version
        return self._version

    @property
    def is_editable(self) -> bool:
        return self.dist.editable

    def format_for_error(self) -> str:
        return f""{self.name} {self.version} (Installed)""

    def iter_dependencies(self, with_requires: bool) -> Iterable[Requirement | None]:
        if not with_requires:
            return

        try:
            for r in self.dist.iter_dependencies():
                yield from self._factory.make_requirements_from_spec(str(r), self._ireq)
        except InvalidRequirement as exc:
            raise InvalidInstalledPackage(dist=self.dist, invalid_exc=exc) from None

    def get_install_requirement(self) -> InstallRequirement | None:
        return None


class ExtrasCandidate(Candidate):
    

    def __init__(
        self,
        base: BaseCandidate,
        extras: frozenset[str],
        *,
        comes_from: InstallRequirement | None = None,
    ) -> None:
        
        self.base = base
        self.extras = frozenset(canonicalize_name(e) for e in extras)
        self._comes_from = comes_from if comes_from is not None else self.base._ireq

    def __str__(self) -> str:
        name, rest = str(self.base).split("" "", 1)
        return ""{}[{}] {}"".format(name, "","".join(self.extras), rest)

    def __repr__(self) -> str:
        return f""{self.__class__.__name__}(base={self.base!r}, extras={self.extras!r})""

    def __hash__(self) -> int:
        return hash((self.base, self.extras))

    def __eq__(self, other: Any) -> bool:
        if isinstance(other, self.__class__):
            return self.base == other.base and self.extras == other.extras
        return False

    @property
    def project_name(self) -> NormalizedName:
        return self.base.project_name

    @property
    def name(self) -> str:
        
        return format_name(self.base.project_name, self.extras)

    @property
    def version(self) -> Version:
        return self.base.version

    def format_for_error(self) -> str:
        return ""{} [{}]"".format(
            self.base.format_for_error(), "", "".join(sorted(self.extras))
        )

    @property
    def is_installed(self) -> bool:
        return self.base.is_installed

    @property
    def is_editable(self) -> bool:
        return self.base.is_editable

    @property
    def source_link(self) -> Link | None:
        return self.base.source_link

    def iter_dependencies(self, with_requires: bool) -> Iterable[Requirement | None]:
        factory = self.base._factory

        
        
        yield factory.make_requirement_from_candidate(self.base)
        if not with_requires:
            return

        
        
        valid_extras = self.extras.intersection(self.base.dist.iter_provided_extras())
        invalid_extras = self.extras.difference(self.base.dist.iter_provided_extras())
        for extra in sorted(invalid_extras):
            logger.warning(
                ""%s %s does not provide the extra '%s'"",
                self.base.name,
                self.version,
                extra,
            )

        for r in self.base.dist.iter_dependencies(valid_extras):
            yield from factory.make_requirements_from_spec(
                str(r),
                self._comes_from,
                valid_extras,
            )

    def get_install_requirement(self) -> InstallRequirement | None:
        
        
        
        return None


class RequiresPythonCandidate(Candidate):
    is_installed = False
    source_link = None

    def __init__(self, py_version_info: tuple[int, ...] | None) -> None:
        if py_version_info is not None:
            version_info = normalize_version_info(py_version_info)
        else:
            version_info = sys.version_info[:3]
        self._version = Version(""."".join(str(c) for c in version_info))

    
    
    

    def __str__(self) -> str:
        return f""Python {self._version}""

    def __repr__(self) -> str:
        return f""{self.__class__.__name__}({self._version!r})""

    @property
    def project_name(self) -> NormalizedName:
        return REQUIRES_PYTHON_IDENTIFIER

    @property
    def name(self) -> str:
        return REQUIRES_PYTHON_IDENTIFIER

    @property
    def version(self) -> Version:
        return self._version

    def format_for_error(self) -> str:
        return f""Python {self.version}""

    def iter_dependencies(self, with_requires: bool) -> Iterable[Requirement | None]:
        return ()

    def get_install_requirement(self) -> InstallRequirement | None:
        return None

from __future__ import annotations

import contextlib
import functools
import logging
from collections.abc import Iterable, Iterator, Mapping, Sequence
from typing import (
    TYPE_CHECKING,
    Callable,
    NamedTuple,
    Protocol,
    TypeVar,
    cast,
)

from pip._vendor.packaging.requirements import InvalidRequirement
from pip._vendor.packaging.specifiers import SpecifierSet
from pip._vendor.packaging.utils import NormalizedName, canonicalize_name
from pip._vendor.packaging.version import InvalidVersion, Version
from pip._vendor.resolvelib import ResolutionImpossible

from pip._internal.cache import CacheEntry, WheelCache
from pip._internal.exceptions import (
    DistributionNotFound,
    InstallationError,
    InvalidInstalledPackage,
    MetadataInconsistent,
    MetadataInvalid,
    UnsupportedPythonVersion,
    UnsupportedWheel,
)
from pip._internal.index.package_finder import PackageFinder
from pip._internal.metadata import BaseDistribution, get_default_environment
from pip._internal.models.link import Link
from pip._internal.models.wheel import Wheel
from pip._internal.operations.prepare import RequirementPreparer
from pip._internal.req.constructors import (
    install_req_drop_extras,
    install_req_from_link_and_ireq,
)
from pip._internal.req.req_install import (
    InstallRequirement,
    check_invalid_constraint_type,
)
from pip._internal.resolution.base import InstallRequirementProvider
from pip._internal.utils.compatibility_tags import get_supported
from pip._internal.utils.hashes import Hashes
from pip._internal.utils.packaging import get_requirement
from pip._internal.utils.virtualenv import running_under_virtualenv

from .base import Candidate, Constraint, Requirement
from .candidates import (
    AlreadyInstalledCandidate,
    BaseCandidate,
    EditableCandidate,
    ExtrasCandidate,
    LinkCandidate,
    RequiresPythonCandidate,
    as_base_candidate,
)
from .found_candidates import FoundCandidates, IndexCandidateInfo
from .requirements import (
    ExplicitRequirement,
    RequiresPythonRequirement,
    SpecifierRequirement,
    SpecifierWithoutExtrasRequirement,
    UnsatisfiableRequirement,
)

if TYPE_CHECKING:

    class ConflictCause(Protocol):
        requirement: RequiresPythonRequirement
        parent: Candidate


logger = logging.getLogger(__name__)

C = TypeVar(""C"")
Cache = dict[Link, C]


class CollectedRootRequirements(NamedTuple):
    requirements: list[Requirement]
    constraints: dict[str, Constraint]
    user_requested: dict[str, int]


class Factory:
    def __init__(
        self,
        finder: PackageFinder,
        preparer: RequirementPreparer,
        make_install_req: InstallRequirementProvider,
        wheel_cache: WheelCache | None,
        use_user_site: bool,
        force_reinstall: bool,
        ignore_installed: bool,
        ignore_requires_python: bool,
        py_version_info: tuple[int, ...] | None = None,
    ) -> None:
        self._finder = finder
        self.preparer = preparer
        self._wheel_cache = wheel_cache
        self._python_candidate = RequiresPythonCandidate(py_version_info)
        self._make_install_req_from_spec = make_install_req
        self._use_user_site = use_user_site
        self._force_reinstall = force_reinstall
        self._ignore_requires_python = ignore_requires_python

        self._build_failures: Cache[InstallationError] = {}
        self._link_candidate_cache: Cache[LinkCandidate] = {}
        self._editable_candidate_cache: Cache[EditableCandidate] = {}
        self._installed_candidate_cache: dict[str, AlreadyInstalledCandidate] = {}
        self._extras_candidate_cache: dict[
            tuple[int, frozenset[NormalizedName]], ExtrasCandidate
        ] = {}
        self._supported_tags_cache = get_supported()

        if not ignore_installed:
            env = get_default_environment()
            self._installed_dists = {
                dist.canonical_name: dist
                for dist in env.iter_installed_distributions(local_only=False)
            }
        else:
            self._installed_dists = {}

    @property
    def force_reinstall(self) -> bool:
        return self._force_reinstall

    def _fail_if_link_is_unsupported_wheel(self, link: Link) -> None:
        if not link.is_wheel:
            return
        wheel = Wheel(link.filename)
        if wheel.supported(self._finder.target_python.get_unsorted_tags()):
            return
        msg = f""{link.filename} is not a supported wheel on this platform.""
        raise UnsupportedWheel(msg)

    def _make_extras_candidate(
        self,
        base: BaseCandidate,
        extras: frozenset[str],
        *,
        comes_from: InstallRequirement | None = None,
    ) -> ExtrasCandidate:
        cache_key = (id(base), frozenset(canonicalize_name(e) for e in extras))
        try:
            candidate = self._extras_candidate_cache[cache_key]
        except KeyError:
            candidate = ExtrasCandidate(base, extras, comes_from=comes_from)
            self._extras_candidate_cache[cache_key] = candidate
        return candidate

    def _make_candidate_from_dist(
        self,
        dist: BaseDistribution,
        extras: frozenset[str],
        template: InstallRequirement,
    ) -> Candidate:
        try:
            base = self._installed_candidate_cache[dist.canonical_name]
        except KeyError:
            base = AlreadyInstalledCandidate(dist, template, factory=self)
            self._installed_candidate_cache[dist.canonical_name] = base
        if not extras:
            return base
        return self._make_extras_candidate(base, extras, comes_from=template)

    def _make_candidate_from_link(
        self,
        link: Link,
        extras: frozenset[str],
        template: InstallRequirement,
        name: NormalizedName | None,
        version: Version | None,
    ) -> Candidate | None:
        base: BaseCandidate | None = self._make_base_candidate_from_link(
            link, template, name, version
        )
        if not extras or base is None:
            return base
        return self._make_extras_candidate(base, extras, comes_from=template)

    def _make_base_candidate_from_link(
        self,
        link: Link,
        template: InstallRequirement,
        name: NormalizedName | None,
        version: Version | None,
    ) -> BaseCandidate | None:
        
        

        if link in self._build_failures:
            
            
            return None

        if template.editable:
            if link not in self._editable_candidate_cache:
                try:
                    self._editable_candidate_cache[link] = EditableCandidate(
                        link,
                        template,
                        factory=self,
                        name=name,
                        version=version,
                    )
                except (MetadataInconsistent, MetadataInvalid) as e:
                    logger.info(
                        ""Discarding [blue underline]%s[/]: [yellow]%s[reset]"",
                        link,
                        e,
                        extra={""markup"": True},
                    )
                    self._build_failures[link] = e
                    return None

            return self._editable_candidate_cache[link]
        else:
            if link not in self._link_candidate_cache:
                try:
                    self._link_candidate_cache[link] = LinkCandidate(
                        link,
                        template,
                        factory=self,
                        name=name,
                        version=version,
                    )
                except MetadataInconsistent as e:
                    logger.info(
                        ""Discarding [blue underline]%s[/]: [yellow]%s[reset]"",
                        link,
                        e,
                        extra={""markup"": True},
                    )
                    self._build_failures[link] = e
                    return None
            return self._link_candidate_cache[link]

    def _iter_found_candidates(
        self,
        ireqs: Sequence[InstallRequirement],
        specifier: SpecifierSet,
        hashes: Hashes,
        prefers_installed: bool,
        incompatible_ids: set[int],
    ) -> Iterable[Candidate]:
        if not ireqs:
            return ()

        
        
        
        
        template = ireqs[0]
        assert template.req, ""Candidates found on index must be PEP 508""
        name = canonicalize_name(template.req.name)

        extras: frozenset[str] = frozenset()
        for ireq in ireqs:
            assert ireq.req, ""Candidates found on index must be PEP 508""
            specifier &= ireq.req.specifier
            hashes &= ireq.hashes(trust_internet=False)
            extras |= frozenset(ireq.extras)

        def _get_installed_candidate() -> Candidate | None:
            
            
            
            if self._force_reinstall:
                return None
            try:
                installed_dist = self._installed_dists[name]
            except KeyError:
                return None

            try:
                
                
                if not specifier.contains(installed_dist.version, prereleases=True):
                    return None
            except InvalidVersion as e:
                raise InvalidInstalledPackage(dist=installed_dist, invalid_exc=e)

            candidate = self._make_candidate_from_dist(
                dist=installed_dist,
                extras=extras,
                template=template,
            )
            
            if id(candidate) in incompatible_ids:
                return None
            return candidate

        def iter_index_candidate_infos() -> Iterator[IndexCandidateInfo]:
            result = self._finder.find_best_candidate(
                project_name=name,
                specifier=specifier,
                hashes=hashes,
            )
            icans = result.applicable_candidates

            
            
            
            all_yanked = all(ican.link.is_yanked for ican in icans)

            def is_pinned(specifier: SpecifierSet) -> bool:
                for sp in specifier:
                    if sp.operator == ""==="":
                        return True
                    if sp.operator != ""=="":
                        continue
                    if sp.version.endswith("".*""):
                        continue
                    return True
                return False

            pinned = is_pinned(specifier)

            
            for ican in reversed(icans):
                if not (all_yanked and pinned) and ican.link.is_yanked:
                    continue
                func = functools.partial(
                    self._make_candidate_from_link,
                    link=ican.link,
                    extras=extras,
                    template=template,
                    name=name,
                    version=ican.version,
                )
                yield ican.version, func

        return FoundCandidates(
            iter_index_candidate_infos,
            _get_installed_candidate(),
            prefers_installed,
            incompatible_ids,
        )

    def _iter_explicit_candidates_from_base(
        self,
        base_requirements: Iterable[Requirement],
        extras: frozenset[str],
    ) -> Iterator[Candidate]:
        
        for req in base_requirements:
            lookup_cand, _ = req.get_candidate_lookup()
            if lookup_cand is None:  
                continue
            
            
            base_cand = as_base_candidate(lookup_cand)
            assert base_cand is not None, ""no extras here""
            yield self._make_extras_candidate(base_cand, extras)

    def _iter_candidates_from_constraints(
        self,
        identifier: str,
        constraint: Constraint,
        template: InstallRequirement,
    ) -> Iterator[Candidate]:
        
        for link in constraint.links:
            self._fail_if_link_is_unsupported_wheel(link)
            candidate = self._make_base_candidate_from_link(
                link,
                template=install_req_from_link_and_ireq(link, template),
                name=canonicalize_name(identifier),
                version=None,
            )
            if candidate:
                yield candidate

    def find_candidates(
        self,
        identifier: str,
        requirements: Mapping[str, Iterable[Requirement]],
        incompatibilities: Mapping[str, Iterator[Candidate]],
        constraint: Constraint,
        prefers_installed: bool,
        is_satisfied_by: Callable[[Requirement, Candidate], bool],
    ) -> Iterable[Candidate]:
        
        explicit_candidates: set[Candidate] = set()
        ireqs: list[InstallRequirement] = []
        for req in requirements[identifier]:
            cand, ireq = req.get_candidate_lookup()
            if cand is not None:
                explicit_candidates.add(cand)
            if ireq is not None:
                ireqs.append(ireq)

        
        
        with contextlib.suppress(InvalidRequirement):
            parsed_requirement = get_requirement(identifier)
            if parsed_requirement.name != identifier:
                explicit_candidates.update(
                    self._iter_explicit_candidates_from_base(
                        requirements.get(parsed_requirement.name, ()),
                        frozenset(parsed_requirement.extras),
                    ),
                )
                for req in requirements.get(parsed_requirement.name, []):
                    _, ireq = req.get_candidate_lookup()
                    if ireq is not None:
                        ireqs.append(ireq)

        
        
        
        
        if ireqs:
            try:
                explicit_candidates.update(
                    self._iter_candidates_from_constraints(
                        identifier,
                        constraint,
                        template=ireqs[0],
                    ),
                )
            except UnsupportedWheel:
                
                
                return ()

        
        
        incompat_ids = {id(c) for c in incompatibilities.get(identifier, ())}

        
        
        if not explicit_candidates:
            return self._iter_found_candidates(
                ireqs,
                constraint.specifier,
                constraint.hashes,
                prefers_installed,
                incompat_ids,
            )

        return (
            c
            for c in explicit_candidates
            if id(c) not in incompat_ids
            and constraint.is_satisfied_by(c)
            and all(is_satisfied_by(req, c) for req in requirements[identifier])
        )

    def _make_requirements_from_install_req(
        self, ireq: InstallRequirement, requested_extras: Iterable[str]
    ) -> Iterator[Requirement]:
        
        if not ireq.match_markers(requested_extras):
            logger.info(
                ""Ignoring %s: markers '%s' don't match your environment"",
                ireq.name,
                ireq.markers,
            )
        elif not ireq.link:
            if ireq.extras and ireq.req is not None and ireq.req.specifier:
                yield SpecifierWithoutExtrasRequirement(ireq)
            yield SpecifierRequirement(ireq)
        else:
            self._fail_if_link_is_unsupported_wheel(ireq.link)
            
            
            
            
            cand = self._make_base_candidate_from_link(
                ireq.link,
                template=install_req_drop_extras(ireq) if ireq.extras else ireq,
                name=canonicalize_name(ireq.name) if ireq.name else None,
                version=None,
            )
            if cand is None:
                
                
                
                
                
                
                if not ireq.name:
                    raise self._build_failures[ireq.link]
                yield UnsatisfiableRequirement(canonicalize_name(ireq.name))
            else:
                
                yield self.make_requirement_from_candidate(cand)
                if ireq.extras:
                    
                    yield self.make_requirement_from_candidate(
                        self._make_extras_candidate(cand, frozenset(ireq.extras))
                    )

    def collect_root_requirements(
        self, root_ireqs: list[InstallRequirement]
    ) -> CollectedRootRequirements:
        collected = CollectedRootRequirements([], {}, {})
        for i, ireq in enumerate(root_ireqs):
            if ireq.constraint:
                
                problem = check_invalid_constraint_type(ireq)
                if problem:
                    raise InstallationError(problem)
                if not ireq.match_markers():
                    continue
                assert ireq.name, ""Constraint must be named""
                name = canonicalize_name(ireq.name)
                if name in collected.constraints:
                    collected.constraints[name] &= ireq
                else:
                    collected.constraints[name] = Constraint.from_ireq(ireq)
            else:
                reqs = list(
                    self._make_requirements_from_install_req(
                        ireq,
                        requested_extras=(),
                    )
                )
                if not reqs:
                    continue
                template = reqs[0]
                if ireq.user_supplied and template.name not in collected.user_requested:
                    collected.user_requested[template.name] = i
                collected.requirements.extend(reqs)
        
        
        
        
        
        
        
        
        collected.requirements.sort(key=lambda r: r.name != r.project_name)
        return collected

    def make_requirement_from_candidate(
        self, candidate: Candidate
    ) -> ExplicitRequirement:
        return ExplicitRequirement(candidate)

    def make_requirements_from_spec(
        self,
        specifier: str,
        comes_from: InstallRequirement | None,
        requested_extras: Iterable[str] = (),
    ) -> Iterator[Requirement]:
        
        ireq = self._make_install_req_from_spec(specifier, comes_from)
        return self._make_requirements_from_install_req(ireq, requested_extras)

    def make_requires_python_requirement(
        self,
        specifier: SpecifierSet,
    ) -> Requirement | None:
        if self._ignore_requires_python:
            return None
        
        if not str(specifier):
            return None
        return RequiresPythonRequirement(specifier, self._python_candidate)

    def get_wheel_cache_entry(self, link: Link, name: str | None) -> CacheEntry | None:
        
        if self._wheel_cache is None:
            return None
        return self._wheel_cache.get_cache_entry(
            link=link,
            package_name=name,
            supported_tags=self._supported_tags_cache,
        )

    def get_dist_to_uninstall(self, candidate: Candidate) -> BaseDistribution | None:
        
        dist = self._installed_dists.get(candidate.project_name)
        if dist is None:  
            return None

        
        
        
        if not self._use_user_site:
            return dist

        
        if dist.in_usersite:
            return dist

        
        
        
        
        if running_under_virtualenv() and dist.in_site_packages:
            message = (
                f""Will not install to the user site because it will lack ""
                f""sys.path precedence to {dist.raw_name} in {dist.location}""
            )
            raise InstallationError(message)
        return None

    def _report_requires_python_error(
        self, causes: Sequence[ConflictCause]
    ) -> UnsupportedPythonVersion:
        assert causes, ""Requires-Python error reported with no cause""

        version = self._python_candidate.version

        if len(causes) == 1:
            specifier = str(causes[0].requirement.specifier)
            message = (
                f""Package {causes[0].parent.name!r} requires a different ""
                f""Python: {version} not in {specifier!r}""
            )
            return UnsupportedPythonVersion(message)

        message = f""Packages require a different Python. {version} not in:""
        for cause in causes:
            package = cause.parent.format_for_error()
            specifier = str(cause.requirement.specifier)
            message += f""\n{specifier!r} (required by {package})""
        return UnsupportedPythonVersion(message)

    def _report_single_requirement_conflict(
        self, req: Requirement, parent: Candidate | None
    ) -> DistributionNotFound:
        if parent is None:
            req_disp = str(req)
        else:
            req_disp = f""{req} (from {parent.name})""

        cands = self._finder.find_all_candidates(req.project_name)
        skipped_by_requires_python = self._finder.requires_python_skipped_reasons()

        versions_set: set[Version] = set()
        yanked_versions_set: set[Version] = set()
        for c in cands:
            is_yanked = c.link.is_yanked if c.link else False
            if is_yanked:
                yanked_versions_set.add(c.version)
            else:
                versions_set.add(c.version)

        versions = [str(v) for v in sorted(versions_set)]
        yanked_versions = [str(v) for v in sorted(yanked_versions_set)]

        if yanked_versions:
            
            
            logger.critical(
                ""Ignored the following yanked versions: %s"",
                "", "".join(yanked_versions) or ""none"",
            )
        if skipped_by_requires_python:
            logger.critical(
                ""Ignored the following versions that require a different python ""
                ""version: %s"",
                ""; "".join(skipped_by_requires_python) or ""none"",
            )
        logger.critical(
            ""Could not find a version that satisfies the requirement %s ""
            ""(from versions: %s)"",
            req_disp,
            "", "".join(versions) or ""none"",
        )
        if str(req) == ""requirements.txt"":
            logger.info(
                ""HINT: You are attempting to install a package literally ""
                'named ""requirements.txt"" (which cannot exist). Consider '
                ""using the '-r' flag to install the packages listed in ""
                ""requirements.txt""
            )

        return DistributionNotFound(f""No matching distribution found for {req}"")

    def get_installation_error(
        self,
        e: ResolutionImpossible[Requirement, Candidate],
        constraints: dict[str, Constraint],
    ) -> InstallationError:
        assert e.causes, ""Installation error reported with no cause""

        
        
        requires_python_causes = [
            cause
            for cause in e.causes
            if isinstance(cause.requirement, RequiresPythonRequirement)
            and not cause.requirement.is_satisfied_by(self._python_candidate)
        ]
        if requires_python_causes:
            
            
            return self._report_requires_python_error(
                cast(""Sequence[ConflictCause]"", requires_python_causes),
            )

        
        

        
        
        if len(e.causes) == 1:
            req, parent = next(iter(e.causes))
            if req.name not in constraints:
                return self._report_single_requirement_conflict(req, parent)

        
        

        
        def text_join(parts: list[str]) -> str:
            if len(parts) == 1:
                return parts[0]

            return "", "".join(parts[:-1]) + "" and "" + parts[-1]

        def describe_trigger(parent: Candidate) -> str:
            ireq = parent.get_install_requirement()
            if not ireq or not ireq.comes_from:
                return f""{parent.name}=={parent.version}""
            if isinstance(ireq.comes_from, InstallRequirement):
                return str(ireq.comes_from.name)
            return str(ireq.comes_from)

        triggers = set()
        for req, parent in e.causes:
            if parent is None:
                
                trigger = req.format_for_error()
            else:
                trigger = describe_trigger(parent)
            triggers.add(trigger)

        if triggers:
            info = text_join(sorted(triggers))
        else:
            info = ""the requested packages""

        msg = (
            f""Cannot install {info} because these package versions ""
            ""have conflicting dependencies.""
        )
        logger.critical(msg)
        msg = ""\nThe conflict is caused by:""

        relevant_constraints = set()
        for req, parent in e.causes:
            if req.name in constraints:
                relevant_constraints.add(req.name)
            msg = msg + ""\n    ""
            if parent:
                msg = msg + f""{parent.name} {parent.version} depends on ""
            else:
                msg = msg + ""The user requested ""
            msg = msg + req.format_for_error()
        for key in relevant_constraints:
            spec = constraints[key].specifier
            msg += f""\n    The user requested (constraint) {key}{spec}""

        msg = (
            msg
            + ""\n\n""
            + ""To fix this you could try to:\n""
            + ""1. loosen the range of package versions you've specified\n""
            + ""2. remove package versions to allow pip to attempt to solve ""
            + ""the dependency conflict\n""
        )

        logger.info(msg)

        return DistributionNotFound(
            ""ResolutionImpossible: for help visit ""
            ""https://pip.pypa.io/en/latest/topics/dependency-resolution/""
            ""
        )



from __future__ import annotations

import logging
from collections.abc import Iterator, Sequence
from typing import Any, Callable, Optional

from pip._vendor.packaging.version import _BaseVersion

from pip._internal.exceptions import MetadataInvalid

from .base import Candidate

logger = logging.getLogger(__name__)

IndexCandidateInfo = tuple[_BaseVersion, Callable[[], Optional[Candidate]]]


def _iter_built(infos: Iterator[IndexCandidateInfo]) -> Iterator[Candidate]:
    
    versions_found: set[_BaseVersion] = set()
    for version, func in infos:
        if version in versions_found:
            continue
        try:
            candidate = func()
        except MetadataInvalid as e:
            logger.warning(
                ""Ignoring version %s of %s since it has invalid metadata:\n""
                ""%s\n""
                ""Please use pip<24.1 if you need to use this version."",
                version,
                e.ireq.name,
                e,
            )
            
            
            versions_found.add(version)
        else:
            if candidate is None:
                continue
            yield candidate
            versions_found.add(version)


def _iter_built_with_prepended(
    installed: Candidate, infos: Iterator[IndexCandidateInfo]
) -> Iterator[Candidate]:
    
    yield installed
    versions_found: set[_BaseVersion] = {installed.version}
    for version, func in infos:
        if version in versions_found:
            continue
        candidate = func()
        if candidate is None:
            continue
        yield candidate
        versions_found.add(version)


def _iter_built_with_inserted(
    installed: Candidate, infos: Iterator[IndexCandidateInfo]
) -> Iterator[Candidate]:
    
    versions_found: set[_BaseVersion] = set()
    for version, func in infos:
        if version in versions_found:
            continue
        
        if installed.version >= version:
            yield installed
            versions_found.add(installed.version)
        candidate = func()
        if candidate is None:
            continue
        yield candidate
        versions_found.add(version)

    
    if installed.version not in versions_found:
        yield installed


class FoundCandidates(Sequence[Candidate]):
    

    def __init__(
        self,
        get_infos: Callable[[], Iterator[IndexCandidateInfo]],
        installed: Candidate | None,
        prefers_installed: bool,
        incompatible_ids: set[int],
    ):
        self._get_infos = get_infos
        self._installed = installed
        self._prefers_installed = prefers_installed
        self._incompatible_ids = incompatible_ids
        self._bool: bool | None = None

    def __getitem__(self, index: Any) -> Any:
        
        
        
        raise NotImplementedError(""don't do this"")

    def __iter__(self) -> Iterator[Candidate]:
        infos = self._get_infos()
        if not self._installed:
            iterator = _iter_built(infos)
        elif self._prefers_installed:
            iterator = _iter_built_with_prepended(self._installed, infos)
        else:
            iterator = _iter_built_with_inserted(self._installed, infos)
        return (c for c in iterator if id(c) not in self._incompatible_ids)

    def __len__(self) -> int:
        
        
        
        raise NotImplementedError(""don't do this"")

    def __bool__(self) -> bool:
        if self._bool is not None:
            return self._bool

        if self._prefers_installed and self._installed:
            self._bool = True
            return True

        self._bool = any(self)
        return self._bool

from __future__ import annotations

import math
from collections.abc import Iterable, Iterator, Mapping, Sequence
from functools import cache
from typing import (
    TYPE_CHECKING,
    TypeVar,
)

from pip._vendor.resolvelib.providers import AbstractProvider

from pip._internal.req.req_install import InstallRequirement

from .base import Candidate, Constraint, Requirement
from .candidates import REQUIRES_PYTHON_IDENTIFIER
from .factory import Factory
from .requirements import ExplicitRequirement

if TYPE_CHECKING:
    from pip._vendor.resolvelib.providers import Preference
    from pip._vendor.resolvelib.resolvers import RequirementInformation

    PreferenceInformation = RequirementInformation[Requirement, Candidate]

    _ProviderBase = AbstractProvider[Requirement, Candidate, str]
else:
    _ProviderBase = AbstractProvider




















D = TypeVar(""D"")
V = TypeVar(""V"")


def _get_with_identifier(
    mapping: Mapping[str, V],
    identifier: str,
    default: D,
) -> D | V:
    
    if identifier in mapping:
        return mapping[identifier]
    
    
    
    
    
    name, open_bracket, _ = identifier.partition(""["")
    if open_bracket and name in mapping:
        return mapping[name]
    return default


class PipProvider(_ProviderBase):
    

    def __init__(
        self,
        factory: Factory,
        constraints: dict[str, Constraint],
        ignore_dependencies: bool,
        upgrade_strategy: str,
        user_requested: dict[str, int],
    ) -> None:
        self._factory = factory
        self._constraints = constraints
        self._ignore_dependencies = ignore_dependencies
        self._upgrade_strategy = upgrade_strategy
        self._user_requested = user_requested

    def identify(self, requirement_or_candidate: Requirement | Candidate) -> str:
        return requirement_or_candidate.name

    def narrow_requirement_selection(
        self,
        identifiers: Iterable[str],
        resolutions: Mapping[str, Candidate],
        candidates: Mapping[str, Iterator[Candidate]],
        information: Mapping[str, Iterator[PreferenceInformation]],
        backtrack_causes: Sequence[PreferenceInformation],
    ) -> Iterable[str]:
        
        backtrack_identifiers = set()
        for info in backtrack_causes:
            backtrack_identifiers.add(info.requirement.name)
            if info.parent is not None:
                backtrack_identifiers.add(info.parent.name)

        current_backtrack_causes = []
        for identifier in identifiers:
            
            
            
            if identifier == REQUIRES_PYTHON_IDENTIFIER:
                return [identifier]

            
            if identifier in backtrack_identifiers:
                current_backtrack_causes.append(identifier)
                continue

        if current_backtrack_causes:
            return current_backtrack_causes

        return identifiers

    def get_preference(
        self,
        identifier: str,
        resolutions: Mapping[str, Candidate],
        candidates: Mapping[str, Iterator[Candidate]],
        information: Mapping[str, Iterable[PreferenceInformation]],
        backtrack_causes: Sequence[PreferenceInformation],
    ) -> Preference:
        
        try:
            next(iter(information[identifier]))
        except StopIteration:
            
            
            has_information = False
        else:
            has_information = True

        if not has_information:
            direct = False
            ireqs: tuple[InstallRequirement | None, ...] = ()
        else:
            
            
            
            directs, ireqs = zip(
                *(
                    (isinstance(r, ExplicitRequirement), r.get_candidate_lookup()[1])
                    for r, _ in information[identifier]
                )
            )
            direct = any(directs)

        operators: list[tuple[str, str]] = [
            (specifier.operator, specifier.version)
            for specifier_set in (ireq.specifier for ireq in ireqs if ireq)
            for specifier in specifier_set
        ]

        pinned = any(((op[:2] == ""=="") and (""*"" not in ver)) for op, ver in operators)
        upper_bounded = any(
            ((op in (""<"", ""<="", ""~="")) or (op == ""=="" and ""*"" in ver))
            for op, ver in operators
        )
        unfree = bool(operators)
        requested_order = self._user_requested.get(identifier, math.inf)

        return (
            not direct,
            not pinned,
            not upper_bounded,
            requested_order,
            not unfree,
            identifier,
        )

    def find_matches(
        self,
        identifier: str,
        requirements: Mapping[str, Iterator[Requirement]],
        incompatibilities: Mapping[str, Iterator[Candidate]],
    ) -> Iterable[Candidate]:
        def _eligible_for_upgrade(identifier: str) -> bool:
            
            if self._upgrade_strategy == ""eager"":
                return True
            elif self._upgrade_strategy == ""only-if-needed"":
                user_order = _get_with_identifier(
                    self._user_requested,
                    identifier,
                    default=None,
                )
                return user_order is not None
            return False

        constraint = _get_with_identifier(
            self._constraints,
            identifier,
            default=Constraint.empty(),
        )
        return self._factory.find_candidates(
            identifier=identifier,
            requirements=requirements,
            constraint=constraint,
            prefers_installed=(not _eligible_for_upgrade(identifier)),
            incompatibilities=incompatibilities,
            is_satisfied_by=self.is_satisfied_by,
        )

    @staticmethod
    @cache
    def is_satisfied_by(requirement: Requirement, candidate: Candidate) -> bool:
        return requirement.is_satisfied_by(candidate)

    def get_dependencies(self, candidate: Candidate) -> Iterable[Requirement]:
        with_requires = not self._ignore_dependencies
        
        return (r for r in candidate.iter_dependencies(with_requires) if r is not None)

from __future__ import annotations

from collections import defaultdict
from logging import getLogger
from typing import Any

from pip._vendor.resolvelib.reporters import BaseReporter

from .base import Candidate, Requirement

logger = getLogger(__name__)


class PipReporter(BaseReporter[Requirement, Candidate, str]):
    def __init__(self) -> None:
        self.reject_count_by_package: defaultdict[str, int] = defaultdict(int)

        self._messages_at_reject_count = {
            1: (
                ""pip is looking at multiple versions of {package_name} to ""
                ""determine which version is compatible with other ""
                ""requirements. This could take a while.""
            ),
            8: (
                ""pip is still looking at multiple versions of {package_name} to ""
                ""determine which version is compatible with other ""
                ""requirements. This could take a while.""
            ),
            13: (
                ""This is taking longer than usual. You might need to provide ""
                ""the dependency resolver with stricter constraints to reduce ""
                ""runtime. See https://pip.pypa.io/warnings/backtracking for ""
                ""guidance. If you want to abort this run, press Ctrl + C.""
            ),
        }

    def rejecting_candidate(self, criterion: Any, candidate: Candidate) -> None:
        self.reject_count_by_package[candidate.name] += 1

        count = self.reject_count_by_package[candidate.name]
        if count not in self._messages_at_reject_count:
            return

        message = self._messages_at_reject_count[count]
        logger.info(""INFO: %s"", message.format(package_name=candidate.name))

        msg = ""Will try a different candidate, due to conflict:""
        for req_info in criterion.information:
            req, parent = req_info.requirement, req_info.parent
            
            msg += ""\n    ""
            if parent:
                msg += f""{parent.name} {parent.version} depends on ""
            else:
                msg += ""The user requested ""
            msg += req.format_for_error()
        logger.debug(msg)


class PipDebuggingReporter(BaseReporter[Requirement, Candidate, str]):
    

    def starting(self) -> None:
        logger.info(""Reporter.starting()"")

    def starting_round(self, index: int) -> None:
        logger.info(""Reporter.starting_round(%r)"", index)

    def ending_round(self, index: int, state: Any) -> None:
        logger.info(""Reporter.ending_round(%r, state)"", index)
        logger.debug(""Reporter.ending_round(%r, %r)"", index, state)

    def ending(self, state: Any) -> None:
        logger.info(""Reporter.ending(%r)"", state)

    def adding_requirement(
        self, requirement: Requirement, parent: Candidate | None
    ) -> None:
        logger.info(""Reporter.adding_requirement(%r, %r)"", requirement, parent)

    def rejecting_candidate(self, criterion: Any, candidate: Candidate) -> None:
        logger.info(""Reporter.rejecting_candidate(%r, %r)"", criterion, candidate)

    def pinning(self, candidate: Candidate) -> None:
        logger.info(""Reporter.pinning(%r)"", candidate)

from __future__ import annotations

from typing import Any

from pip._vendor.packaging.specifiers import SpecifierSet
from pip._vendor.packaging.utils import NormalizedName, canonicalize_name

from pip._internal.req.constructors import install_req_drop_extras
from pip._internal.req.req_install import InstallRequirement

from .base import Candidate, CandidateLookup, Requirement, format_name


class ExplicitRequirement(Requirement):
    def __init__(self, candidate: Candidate) -> None:
        self.candidate = candidate

    def __str__(self) -> str:
        return str(self.candidate)

    def __repr__(self) -> str:
        return f""{self.__class__.__name__}({self.candidate!r})""

    def __hash__(self) -> int:
        return hash(self.candidate)

    def __eq__(self, other: Any) -> bool:
        if not isinstance(other, ExplicitRequirement):
            return False
        return self.candidate == other.candidate

    @property
    def project_name(self) -> NormalizedName:
        
        return self.candidate.project_name

    @property
    def name(self) -> str:
        
        return self.candidate.name

    def format_for_error(self) -> str:
        return self.candidate.format_for_error()

    def get_candidate_lookup(self) -> CandidateLookup:
        return self.candidate, None

    def is_satisfied_by(self, candidate: Candidate) -> bool:
        return candidate == self.candidate


class SpecifierRequirement(Requirement):
    def __init__(self, ireq: InstallRequirement) -> None:
        assert ireq.link is None, ""This is a link, not a specifier""
        self._ireq = ireq
        self._equal_cache: str | None = None
        self._hash: int | None = None
        self._extras = frozenset(canonicalize_name(e) for e in self._ireq.extras)

    @property
    def _equal(self) -> str:
        if self._equal_cache is not None:
            return self._equal_cache

        self._equal_cache = str(self._ireq)
        return self._equal_cache

    def __str__(self) -> str:
        return str(self._ireq.req)

    def __repr__(self) -> str:
        return f""{self.__class__.__name__}({str(self._ireq.req)!r})""

    def __eq__(self, other: object) -> bool:
        if not isinstance(other, SpecifierRequirement):
            return NotImplemented
        return self._equal == other._equal

    def __hash__(self) -> int:
        if self._hash is not None:
            return self._hash

        self._hash = hash(self._equal)
        return self._hash

    @property
    def project_name(self) -> NormalizedName:
        assert self._ireq.req, ""Specifier-backed ireq is always PEP 508""
        return canonicalize_name(self._ireq.req.name)

    @property
    def name(self) -> str:
        return format_name(self.project_name, self._extras)

    def format_for_error(self) -> str:
        
        
        
        
        parts = [s.strip() for s in str(self).split("","")]
        if len(parts) == 0:
            return """"
        elif len(parts) == 1:
            return parts[0]

        return "", "".join(parts[:-1]) + "" and "" + parts[-1]

    def get_candidate_lookup(self) -> CandidateLookup:
        return None, self._ireq

    def is_satisfied_by(self, candidate: Candidate) -> bool:
        assert candidate.name == self.name, (
            f""Internal issue: Candidate is not for this requirement ""
            f""{candidate.name} vs {self.name}""
        )
        
        
        
        assert self._ireq.req, ""Specifier-backed ireq is always PEP 508""
        spec = self._ireq.req.specifier
        return spec.contains(candidate.version, prereleases=True)


class SpecifierWithoutExtrasRequirement(SpecifierRequirement):
    

    def __init__(self, ireq: InstallRequirement) -> None:
        assert ireq.link is None, ""This is a link, not a specifier""
        self._ireq = install_req_drop_extras(ireq)
        self._equal_cache: str | None = None
        self._hash: int | None = None
        self._extras = frozenset(canonicalize_name(e) for e in self._ireq.extras)

    @property
    def _equal(self) -> str:
        if self._equal_cache is not None:
            return self._equal_cache

        self._equal_cache = str(self._ireq)
        return self._equal_cache

    def __eq__(self, other: object) -> bool:
        if not isinstance(other, SpecifierWithoutExtrasRequirement):
            return NotImplemented
        return self._equal == other._equal

    def __hash__(self) -> int:
        if self._hash is not None:
            return self._hash

        self._hash = hash(self._equal)
        return self._hash


class RequiresPythonRequirement(Requirement):
    

    def __init__(self, specifier: SpecifierSet, match: Candidate) -> None:
        self.specifier = specifier
        self._specifier_string = str(specifier)  
        self._hash: int | None = None
        self._candidate = match

    def __str__(self) -> str:
        return f""Python {self.specifier}""

    def __repr__(self) -> str:
        return f""{self.__class__.__name__}({str(self.specifier)!r})""

    def __hash__(self) -> int:
        if self._hash is not None:
            return self._hash

        self._hash = hash((self._specifier_string, self._candidate))
        return self._hash

    def __eq__(self, other: Any) -> bool:
        if not isinstance(other, RequiresPythonRequirement):
            return False
        return (
            self._specifier_string == other._specifier_string
            and self._candidate == other._candidate
        )

    @property
    def project_name(self) -> NormalizedName:
        return self._candidate.project_name

    @property
    def name(self) -> str:
        return self._candidate.name

    def format_for_error(self) -> str:
        return str(self)

    def get_candidate_lookup(self) -> CandidateLookup:
        if self.specifier.contains(self._candidate.version, prereleases=True):
            return self._candidate, None
        return None, None

    def is_satisfied_by(self, candidate: Candidate) -> bool:
        assert candidate.name == self._candidate.name, ""Not Python candidate""
        
        
        
        return self.specifier.contains(candidate.version, prereleases=True)


class UnsatisfiableRequirement(Requirement):
    

    def __init__(self, name: NormalizedName) -> None:
        self._name = name

    def __str__(self) -> str:
        return f""{self._name} (unavailable)""

    def __repr__(self) -> str:
        return f""{self.__class__.__name__}({str(self._name)!r})""

    def __eq__(self, other: object) -> bool:
        if not isinstance(other, UnsatisfiableRequirement):
            return NotImplemented
        return self._name == other._name

    def __hash__(self) -> int:
        return hash(self._name)

    @property
    def project_name(self) -> NormalizedName:
        return self._name

    @property
    def name(self) -> str:
        return self._name

    def format_for_error(self) -> str:
        return str(self)

    def get_candidate_lookup(self) -> CandidateLookup:
        return None, None

    def is_satisfied_by(self, candidate: Candidate) -> bool:
        return False

from __future__ import annotations

import contextlib
import functools
import logging
import os
from typing import TYPE_CHECKING, cast

from pip._vendor.packaging.utils import canonicalize_name
from pip._vendor.resolvelib import BaseReporter, ResolutionImpossible, ResolutionTooDeep
from pip._vendor.resolvelib import Resolver as RLResolver
from pip._vendor.resolvelib.structs import DirectedGraph

from pip._internal.cache import WheelCache
from pip._internal.exceptions import ResolutionTooDeepError
from pip._internal.index.package_finder import PackageFinder
from pip._internal.operations.prepare import RequirementPreparer
from pip._internal.req.constructors import install_req_extend_extras
from pip._internal.req.req_install import InstallRequirement
from pip._internal.req.req_set import RequirementSet
from pip._internal.resolution.base import BaseResolver, InstallRequirementProvider
from pip._internal.resolution.resolvelib.provider import PipProvider
from pip._internal.resolution.resolvelib.reporter import (
    PipDebuggingReporter,
    PipReporter,
)
from pip._internal.utils.packaging import get_requirement

from .base import Candidate, Requirement
from .factory import Factory

if TYPE_CHECKING:
    from pip._vendor.resolvelib.resolvers import Result as RLResult

    Result = RLResult[Requirement, Candidate, str]


logger = logging.getLogger(__name__)


class Resolver(BaseResolver):
    _allowed_strategies = {""eager"", ""only-if-needed"", ""to-satisfy-only""}

    def __init__(
        self,
        preparer: RequirementPreparer,
        finder: PackageFinder,
        wheel_cache: WheelCache | None,
        make_install_req: InstallRequirementProvider,
        use_user_site: bool,
        ignore_dependencies: bool,
        ignore_installed: bool,
        ignore_requires_python: bool,
        force_reinstall: bool,
        upgrade_strategy: str,
        py_version_info: tuple[int, ...] | None = None,
    ):
        super().__init__()
        assert upgrade_strategy in self._allowed_strategies

        self.factory = Factory(
            finder=finder,
            preparer=preparer,
            make_install_req=make_install_req,
            wheel_cache=wheel_cache,
            use_user_site=use_user_site,
            force_reinstall=force_reinstall,
            ignore_installed=ignore_installed,
            ignore_requires_python=ignore_requires_python,
            py_version_info=py_version_info,
        )
        self.ignore_dependencies = ignore_dependencies
        self.upgrade_strategy = upgrade_strategy
        self._result: Result | None = None

    def resolve(
        self, root_reqs: list[InstallRequirement], check_supported_wheels: bool
    ) -> RequirementSet:
        collected = self.factory.collect_root_requirements(root_reqs)
        provider = PipProvider(
            factory=self.factory,
            constraints=collected.constraints,
            ignore_dependencies=self.ignore_dependencies,
            upgrade_strategy=self.upgrade_strategy,
            user_requested=collected.user_requested,
        )
        if ""PIP_RESOLVER_DEBUG"" in os.environ:
            reporter: BaseReporter[Requirement, Candidate, str] = PipDebuggingReporter()
        else:
            reporter = PipReporter()
        resolver: RLResolver[Requirement, Candidate, str] = RLResolver(
            provider,
            reporter,
        )

        try:
            limit_how_complex_resolution_can_be = 200000
            result = self._result = resolver.resolve(
                collected.requirements, max_rounds=limit_how_complex_resolution_can_be
            )

        except ResolutionImpossible as e:
            error = self.factory.get_installation_error(
                cast(""ResolutionImpossible[Requirement, Candidate]"", e),
                collected.constraints,
            )
            raise error from e
        except ResolutionTooDeep:
            raise ResolutionTooDeepError from None

        req_set = RequirementSet(check_supported_wheels=check_supported_wheels)
        
        
        
        
        for candidate in sorted(
            result.mapping.values(), key=lambda c: c.name != c.project_name
        ):
            ireq = candidate.get_install_requirement()
            if ireq is None:
                if candidate.name != candidate.project_name:
                    
                    with contextlib.suppress(KeyError):
                        req = req_set.get_requirement(candidate.project_name)
                        req_set.add_named_requirement(
                            install_req_extend_extras(
                                req, get_requirement(candidate.name).extras
                            )
                        )
                continue

            
            
            installed_dist = self.factory.get_dist_to_uninstall(candidate)
            if installed_dist is None:
                
                ireq.should_reinstall = False
            elif self.factory.force_reinstall:
                
                ireq.should_reinstall = True
            elif installed_dist.version != candidate.version:
                
                ireq.should_reinstall = True
            elif candidate.is_editable or installed_dist.editable:
                
                
                ireq.should_reinstall = True
            elif candidate.source_link and candidate.source_link.is_file:
                
                if candidate.source_link.is_wheel:
                    
                    logger.info(
                        ""%s is already installed with the same version as the ""
                        ""provided wheel. Use --force-reinstall to force an ""
                        ""installation of the wheel."",
                        ireq.name,
                    )
                    continue

                
                ireq.should_reinstall = True
            else:
                continue

            link = candidate.source_link
            if link and link.is_yanked:
                
                
                msg = (
                    ""The candidate selected for download or install is a ""
                    ""yanked version: {name!r} candidate (version {version} ""
                    ""at {link})\nReason for being yanked: {reason}""
                ).format(
                    name=candidate.name,
                    version=candidate.version,
                    link=link,
                    reason=link.yanked_reason or ""<none given>"",
                )
                logger.warning(msg)

            req_set.add_named_requirement(ireq)

        reqs = req_set.all_requirements
        self.factory.preparer.prepare_linked_requirements_more(reqs)
        for req in reqs:
            req.prepared = True
            req.needs_more_preparation = False
        return req_set

    def get_installation_order(
        self, req_set: RequirementSet
    ) -> list[InstallRequirement]:
        
        assert self._result is not None, ""must call resolve() first""

        if not req_set.requirements:
            
            return []

        graph = self._result.graph
        weights = get_topological_weights(graph, set(req_set.requirements.keys()))

        sorted_items = sorted(
            req_set.requirements.items(),
            key=functools.partial(_req_set_item_sorter, weights=weights),
            reverse=True,
        )
        return [ireq for _, ireq in sorted_items]


def get_topological_weights(
    graph: DirectedGraph[str | None], requirement_keys: set[str]
) -> dict[str | None, int]:
    
    path: set[str | None] = set()
    weights: dict[str | None, list[int]] = {}

    def visit(node: str | None) -> None:
        if node in path:
            
            return

        
        
        
        
        
        
        
        cur_weights = weights.get(node, [])
        if len(cur_weights) >= 5:
            return

        
        path.add(node)
        for child in graph.iter_children(node):
            visit(child)
        path.remove(node)

        if node not in requirement_keys:
            return

        cur_weights.append(len(path))
        weights[node] = cur_weights

    
    
    
    
    
    while True:
        leaves = set()
        for key in graph:
            if key is None:
                continue
            for _child in graph.iter_children(key):
                
                break
            else:
                
                leaves.add(key)
        if not leaves:
            
            break
        
        weight = len(graph) - 1
        for leaf in leaves:
            if leaf not in requirement_keys:
                continue
            weights[leaf] = [weight]
        
        for leaf in leaves:
            graph.remove(leaf)

    
    
    
    visit(None)

    
    
    difference = set(weights.keys()).difference(requirement_keys)
    assert not difference, difference

    
    
    return {node: max(wgts) for (node, wgts) in weights.items()}


def _req_set_item_sorter(
    item: tuple[str, InstallRequirement],
    weights: dict[str | None, int],
) -> tuple[int, str]:
    
    name = canonicalize_name(item[0])
    return weights[name], name




import os
import sys

from pip._vendor import platformdirs as _appdirs


def user_cache_dir(appname: str) -> str:
    return _appdirs.user_cache_dir(appname, appauthor=False)


def _macos_user_config_dir(appname: str, roaming: bool = True) -> str:
    
    path = _appdirs.user_data_dir(appname, appauthor=False, roaming=roaming)
    if os.path.isdir(path):
        return path

    
    linux_like_path = ""~/.config/""
    if appname:
        linux_like_path = os.path.join(linux_like_path, appname)

    return os.path.expanduser(linux_like_path)


def user_config_dir(appname: str, roaming: bool = True) -> str:
    if sys.platform == ""darwin"":
        return _macos_user_config_dir(appname, roaming)

    return _appdirs.user_config_dir(appname, appauthor=False, roaming=roaming)




def site_config_dirs(appname: str) -> list[str]:
    if sys.platform == ""darwin"":
        dirval = _appdirs.site_data_dir(appname, appauthor=False, multipath=True)
        return dirval.split(os.pathsep)

    dirval = _appdirs.site_config_dir(appname, appauthor=False, multipath=True)
    if sys.platform == ""win32"":
        return [dirval]

    
    return dirval.split(os.pathsep) + [""/etc""]



import importlib.resources
import logging
import os
import sys
from typing import IO

__all__ = [""get_path_uid"", ""stdlib_pkgs"", ""tomllib"", ""WINDOWS""]


logger = logging.getLogger(__name__)


def has_tls() -> bool:
    try:
        import _ssl  

        return True
    except ImportError:
        pass

    from pip._vendor.urllib3.util import IS_PYOPENSSL

    return IS_PYOPENSSL


def get_path_uid(path: str) -> int:
    
    if hasattr(os, ""O_NOFOLLOW""):
        fd = os.open(path, os.O_RDONLY | os.O_NOFOLLOW)
        file_uid = os.fstat(fd).st_uid
        os.close(fd)
    else:  
        
        if not os.path.islink(path):
            
            file_uid = os.stat(path).st_uid
        else:
            
            raise OSError(f""{path} is a symlink; Will not return uid for symlinks"")
    return file_uid




if sys.version_info < (3, 11):
    open_text_resource = importlib.resources.open_text
else:

    def open_text_resource(
        package: str, resource: str, encoding: str = ""utf-8"", errors: str = ""strict""
    ) -> IO[str]:
        return (importlib.resources.files(package) / resource).open(
            ""r"", encoding=encoding, errors=errors
        )


if sys.version_info >= (3, 11):
    import tomllib
else:
    from pip._vendor import tomli as tomllib







stdlib_pkgs = {""python"", ""wsgiref"", ""argparse""}



WINDOWS = sys.platform.startswith(""win"") or (sys.platform == ""cli"" and os.name == ""nt"")



from __future__ import annotations

import re

from pip._vendor.packaging.tags import (
    PythonVersion,
    Tag,
    android_platforms,
    compatible_tags,
    cpython_tags,
    generic_tags,
    interpreter_name,
    interpreter_version,
    ios_platforms,
    mac_platforms,
)

_apple_arch_pat = re.compile(r""(.+)_(\d+)_(\d+)_(.+)"")


def version_info_to_nodot(version_info: tuple[int, ...]) -> str:
    
    return """".join(map(str, version_info[:2]))


def _mac_platforms(arch: str) -> list[str]:
    match = _apple_arch_pat.match(arch)
    if match:
        name, major, minor, actual_arch = match.groups()
        mac_version = (int(major), int(minor))
        arches = [
            
            
            
            
            
            ""{}_{}"".format(name, arch[len(""macosx_"") :])
            for arch in mac_platforms(mac_version, actual_arch)
        ]
    else:
        
        arches = [arch]
    return arches


def _ios_platforms(arch: str) -> list[str]:
    match = _apple_arch_pat.match(arch)
    if match:
        name, major, minor, actual_multiarch = match.groups()
        ios_version = (int(major), int(minor))
        arches = [
            
            
            
            
            
            ""{}_{}"".format(name, arch[len(""ios_"") :])
            for arch in ios_platforms(ios_version, actual_multiarch)
        ]
    else:
        
        arches = [arch]
    return arches


def _android_platforms(arch: str) -> list[str]:
    match = re.fullmatch(r""android_(\d+)_(.+)"", arch)
    if match:
        api_level, abi = match.groups()
        return list(android_platforms(int(api_level), abi))
    else:
        
        return [arch]


def _custom_manylinux_platforms(arch: str) -> list[str]:
    arches = [arch]
    arch_prefix, arch_sep, arch_suffix = arch.partition(""_"")
    if arch_prefix == ""manylinux2014"":
        
        
        
        
        
        if arch_suffix in {""i686"", ""x86_64""}:
            arches.append(""manylinux2010"" + arch_sep + arch_suffix)
            arches.append(""manylinux1"" + arch_sep + arch_suffix)
    elif arch_prefix == ""manylinux2010"":
        
        
        
        
        arches.append(""manylinux1"" + arch_sep + arch_suffix)
    return arches


def _get_custom_platforms(arch: str) -> list[str]:
    arch_prefix, arch_sep, arch_suffix = arch.partition(""_"")
    if arch.startswith(""macosx""):
        arches = _mac_platforms(arch)
    elif arch.startswith(""ios""):
        arches = _ios_platforms(arch)
    elif arch_prefix == ""android"":
        arches = _android_platforms(arch)
    elif arch_prefix in [""manylinux2014"", ""manylinux2010""]:
        arches = _custom_manylinux_platforms(arch)
    else:
        arches = [arch]
    return arches


def _expand_allowed_platforms(platforms: list[str] | None) -> list[str] | None:
    if not platforms:
        return None

    seen = set()
    result = []

    for p in platforms:
        if p in seen:
            continue
        additions = [c for c in _get_custom_platforms(p) if c not in seen]
        seen.update(additions)
        result.extend(additions)

    return result


def _get_python_version(version: str) -> PythonVersion:
    if len(version) > 1:
        return int(version[0]), int(version[1:])
    else:
        return (int(version[0]),)


def _get_custom_interpreter(
    implementation: str | None = None, version: str | None = None
) -> str:
    if implementation is None:
        implementation = interpreter_name()
    if version is None:
        version = interpreter_version()
    return f""{implementation}{version}""


def get_supported(
    version: str | None = None,
    platforms: list[str] | None = None,
    impl: str | None = None,
    abis: list[str] | None = None,
) -> list[Tag]:
    
    supported: list[Tag] = []

    python_version: PythonVersion | None = None
    if version is not None:
        python_version = _get_python_version(version)

    interpreter = _get_custom_interpreter(impl, version)

    platforms = _expand_allowed_platforms(platforms)

    is_cpython = (impl or interpreter_name()) == ""cp""
    if is_cpython:
        supported.extend(
            cpython_tags(
                python_version=python_version,
                abis=abis,
                platforms=platforms,
            )
        )
    else:
        supported.extend(
            generic_tags(
                interpreter=interpreter,
                abis=abis,
                platforms=platforms,
            )
        )
    supported.extend(
        compatible_tags(
            python_version=python_version,
            interpreter=interpreter,
            platforms=platforms,
        )
    )

    return supported



import datetime


def today_is_later_than(year: int, month: int, day: int) -> bool:
    today = datetime.date.today()
    given = datetime.date(year, month, day)

    return today > given



from __future__ import annotations

import logging
import warnings
from typing import Any, TextIO

from pip._vendor.packaging.version import parse

from pip import __version__ as current_version  

DEPRECATION_MSG_PREFIX = ""DEPRECATION: ""


class PipDeprecationWarning(Warning):
    pass


_original_showwarning: Any = None



def _showwarning(
    message: Warning | str,
    category: type[Warning],
    filename: str,
    lineno: int,
    file: TextIO | None = None,
    line: str | None = None,
) -> None:
    if file is not None:
        if _original_showwarning is not None:
            _original_showwarning(message, category, filename, lineno, file, line)
    elif issubclass(category, PipDeprecationWarning):
        
        
        logger = logging.getLogger(""pip._internal.deprecations"")
        logger.warning(message)
    else:
        _original_showwarning(message, category, filename, lineno, file, line)


def install_warning_logger() -> None:
    
    warnings.simplefilter(""default"", PipDeprecationWarning, append=True)

    global _original_showwarning

    if _original_showwarning is None:
        _original_showwarning = warnings.showwarning
        warnings.showwarning = _showwarning


def deprecated(
    *,
    reason: str,
    replacement: str | None,
    gone_in: str | None,
    feature_flag: str | None = None,
    issue: int | None = None,
) -> None:
    

    
    is_gone = gone_in is not None and parse(current_version) >= parse(gone_in)

    message_parts = [
        (reason, f""{DEPRECATION_MSG_PREFIX}{{}}""),
        (
            gone_in,
            (
                ""pip {} will enforce this behaviour change.""
                if not is_gone
                else ""Since pip {}, this is no longer supported.""
            ),
        ),
        (
            replacement,
            ""A possible replacement is {}."",
        ),
        (
            feature_flag,
            (
                ""You can use the flag --use-feature={} to test the upcoming behaviour.""
                if not is_gone
                else None
            ),
        ),
        (
            issue,
            ""Discussion can be found at https://github.com/pypa/pip/issues/{}"",
        ),
    ]

    message = "" "".join(
        format_str.format(value)
        for value, format_str in message_parts
        if format_str is not None and value is not None
    )

    
    if is_gone:
        raise PipDeprecationWarning(message)

    warnings.warn(message, category=PipDeprecationWarning, stacklevel=2)

from __future__ import annotations

from pip._internal.models.direct_url import ArchiveInfo, DirectUrl, DirInfo, VcsInfo
from pip._internal.models.link import Link
from pip._internal.utils.urls import path_to_url
from pip._internal.vcs import vcs


def direct_url_as_pep440_direct_reference(direct_url: DirectUrl, name: str) -> str:
    
    direct_url.validate()  
    requirement = name + "" @ ""
    fragments = []
    if isinstance(direct_url.info, VcsInfo):
        requirement += (
            f""{direct_url.info.vcs}+{direct_url.url}@{direct_url.info.commit_id}""
        )
    elif isinstance(direct_url.info, ArchiveInfo):
        requirement += direct_url.url
        if direct_url.info.hash:
            fragments.append(direct_url.info.hash)
    else:
        assert isinstance(direct_url.info, DirInfo)
        requirement += direct_url.url
    if direct_url.subdirectory:
        fragments.append(""subdirectory="" + direct_url.subdirectory)
    if fragments:
        requirement += ""
    return requirement


def direct_url_for_editable(source_dir: str) -> DirectUrl:
    return DirectUrl(
        url=path_to_url(source_dir),
        info=DirInfo(editable=True),
    )


def direct_url_from_link(
    link: Link, source_dir: str | None = None, link_is_in_wheel_cache: bool = False
) -> DirectUrl:
    if link.is_vcs:
        vcs_backend = vcs.get_backend_for_scheme(link.scheme)
        assert vcs_backend
        url, requested_revision, _ = vcs_backend.get_url_rev_and_auth(
            link.url_without_fragment
        )
        
        if link_is_in_wheel_cache:
            
            
            
            
            
            assert requested_revision
            commit_id = requested_revision
        else:
            
            
            
            assert source_dir
            commit_id = vcs_backend.get_revision(source_dir)
        return DirectUrl(
            url=url,
            info=VcsInfo(
                vcs=vcs_backend.name,
                commit_id=commit_id,
                requested_revision=requested_revision,
            ),
            subdirectory=link.subdirectory_fragment,
        )
    elif link.is_existing_dir():
        return DirectUrl(
            url=link.url_without_fragment,
            info=DirInfo(),
            subdirectory=link.subdirectory_fragment,
        )
    else:
        hash = None
        hash_name = link.hash_name
        if hash_name:
            hash = f""{hash_name}={link.hash}""
        return DirectUrl(
            url=link.url_without_fragment,
            info=ArchiveInfo(hash=hash),
            subdirectory=link.subdirectory_fragment,
        )

from __future__ import annotations

import os
import re
import sys

from pip._internal.locations import site_packages, user_site
from pip._internal.utils.virtualenv import (
    running_under_virtualenv,
    virtualenv_no_global,
)

__all__ = [
    ""egg_link_path_from_sys_path"",
    ""egg_link_path_from_location"",
]


def _egg_link_names(raw_name: str) -> list[str]:
    
    return [
        re.sub(""[^A-Za-z0-9.]+"", ""-"", raw_name) + "".egg-link"",
        f""{raw_name}.egg-link"",
    ]


def egg_link_path_from_sys_path(raw_name: str) -> str | None:
    
    egg_link_names = _egg_link_names(raw_name)
    for path_item in sys.path:
        for egg_link_name in egg_link_names:
            egg_link = os.path.join(path_item, egg_link_name)
            if os.path.isfile(egg_link):
                return egg_link
    return None


def egg_link_path_from_location(raw_name: str) -> str | None:
    
    sites: list[str] = []
    if running_under_virtualenv():
        sites.append(site_packages)
        if not virtualenv_no_global() and user_site:
            sites.append(user_site)
    else:
        if user_site:
            sites.append(user_site)
        sites.append(site_packages)

    egg_link_names = _egg_link_names(raw_name)
    for site in sites:
        for egg_link_name in egg_link_names:
            egglink = os.path.join(site, egg_link_name)
            if os.path.isfile(egglink):
                return egglink
    return None

from __future__ import annotations

import itertools
import os
import shutil
import sys

from pip._internal.cli.main import main
from pip._internal.utils.compat import WINDOWS

_EXECUTABLE_NAMES = [
    ""pip"",
    f""pip{sys.version_info.major}"",
    f""pip{sys.version_info.major}.{sys.version_info.minor}"",
]
if WINDOWS:
    _allowed_extensions = {"""", "".exe""}
    _EXECUTABLE_NAMES = [
        """".join(parts)
        for parts in itertools.product(_EXECUTABLE_NAMES, _allowed_extensions)
    ]


def _wrapper(args: list[str] | None = None) -> int:
    
    sys.stderr.write(
        ""WARNING: pip is being invoked by an old script wrapper. This will ""
        ""fail in a future version of pip.\n""
        ""Please see https://github.com/pypa/pip/issues/5599 for advice on ""
        ""fixing the underlying issue.\n""
        ""To avoid this problem you can invoke Python with '-m pip' instead of ""
        ""running pip directly.\n""
    )
    return main(args)


def get_best_invocation_for_this_pip() -> str:
    
    binary_directory = ""Scripts"" if WINDOWS else ""bin""
    binary_prefix = os.path.join(sys.prefix, binary_directory)

    
    
    path_parts = os.path.normcase(os.environ.get(""PATH"", """")).split(os.pathsep)
    exe_are_in_PATH = os.path.normcase(binary_prefix) in path_parts
    if exe_are_in_PATH:
        for exe_name in _EXECUTABLE_NAMES:
            found_executable = shutil.which(exe_name)
            binary_executable = os.path.join(binary_prefix, exe_name)
            if (
                found_executable
                and os.path.exists(binary_executable)
                and os.path.samefile(
                    found_executable,
                    binary_executable,
                )
            ):
                return exe_name

    
    return f""{get_best_invocation_for_this_python()} -m pip""


def get_best_invocation_for_this_python() -> str:
    
    exe = sys.executable
    exe_name = os.path.basename(exe)

    
    found_executable = shutil.which(exe_name)
    
    
    
    if found_executable and os.path.samestat(os.lstat(found_executable), os.lstat(exe)):
        return exe_name

    
    return exe

from __future__ import annotations

import fnmatch
import os
import os.path
import random
import sys
from collections.abc import Generator
from contextlib import contextmanager
from tempfile import NamedTemporaryFile
from typing import Any, BinaryIO, cast

from pip._internal.utils.compat import get_path_uid
from pip._internal.utils.misc import format_size
from pip._internal.utils.retry import retry


def check_path_owner(path: str) -> bool:
    
    
    if sys.platform == ""win32"" or not hasattr(os, ""geteuid""):
        return True

    assert os.path.isabs(path)

    previous = None
    while path != previous:
        if os.path.lexists(path):
            
            if os.geteuid() == 0:
                
                
                try:
                    path_uid = get_path_uid(path)
                except OSError:
                    return False
                return path_uid == 0
            else:
                return os.access(path, os.W_OK)
        else:
            previous, path = path, os.path.dirname(path)
    return False  


@contextmanager
def adjacent_tmp_file(path: str, **kwargs: Any) -> Generator[BinaryIO, None, None]:
    
    with NamedTemporaryFile(
        delete=False,
        dir=os.path.dirname(path),
        prefix=os.path.basename(path),
        suffix="".tmp"",
        **kwargs,
    ) as f:
        result = cast(BinaryIO, f)
        try:
            yield result
        finally:
            result.flush()
            os.fsync(result.fileno())


replace = retry(stop_after_delay=1, wait=0.25)(os.replace)




def test_writable_dir(path: str) -> bool:
    
    
    while not os.path.isdir(path):
        parent = os.path.dirname(path)
        if parent == path:
            break  
        path = parent

    if os.name == ""posix"":
        return os.access(path, os.W_OK)

    return _test_writable_dir_win(path)


def _test_writable_dir_win(path: str) -> bool:
    
    
    basename = ""accesstest_deleteme_fishfingers_custard_""
    alphabet = ""abcdefghijklmnopqrstuvwxyz0123456789""
    for _ in range(10):
        name = basename + """".join(random.choice(alphabet) for _ in range(6))
        file = os.path.join(path, name)
        try:
            fd = os.open(file, os.O_RDWR | os.O_CREAT | os.O_EXCL)
        except FileExistsError:
            pass
        except PermissionError:
            
            
            
            
            
            return False
        else:
            os.close(fd)
            os.unlink(file)
            return True

    
    raise OSError(""Unexpected condition testing for writable directory"")


def find_files(path: str, pattern: str) -> list[str]:
    
    result: list[str] = []
    for root, _, files in os.walk(path):
        matches = fnmatch.filter(files, pattern)
        result.extend(os.path.join(root, f) for f in matches)
    return result


def file_size(path: str) -> int | float:
    
    if os.path.islink(path):
        return 0
    return os.path.getsize(path)


def format_file_size(path: str) -> str:
    return format_size(file_size(path))


def directory_size(path: str) -> int | float:
    size = 0.0
    for root, _dirs, files in os.walk(path):
        for filename in files:
            file_path = os.path.join(root, filename)
            size += file_size(file_path)
    return size


def format_directory_size(path: str) -> str:
    return format_size(directory_size(path))



from pip._internal.utils.misc import splitext

WHEEL_EXTENSION = "".whl""
BZ2_EXTENSIONS: tuple[str, ...] = ("".tar.bz2"", "".tbz"")
XZ_EXTENSIONS: tuple[str, ...] = (
    "".tar.xz"",
    "".txz"",
    "".tlz"",
    "".tar.lz"",
    "".tar.lzma"",
)
ZIP_EXTENSIONS: tuple[str, ...] = ("".zip"", WHEEL_EXTENSION)
TAR_EXTENSIONS: tuple[str, ...] = ("".tar.gz"", "".tgz"", "".tar"")
ARCHIVE_EXTENSIONS = ZIP_EXTENSIONS + BZ2_EXTENSIONS + TAR_EXTENSIONS + XZ_EXTENSIONS


def is_archive_file(name: str) -> bool:
    
    ext = splitext(name)[1].lower()
    if ext in ARCHIVE_EXTENSIONS:
        return True
    return False

from __future__ import annotations

import os
import sys


def glibc_version_string() -> str | None:
    ""Returns glibc version string, or None if not using glibc.""
    return glibc_version_string_confstr() or glibc_version_string_ctypes()


def glibc_version_string_confstr() -> str | None:
    ""Primary implementation of glibc_version_string using os.confstr.""
    
    
    
    
    if sys.platform == ""win32"":
        return None
    try:
        gnu_libc_version = os.confstr(""CS_GNU_LIBC_VERSION"")
        if gnu_libc_version is None:
            return None
        
        _, version = gnu_libc_version.split()
    except (AttributeError, OSError, ValueError):
        
        return None
    return version


def glibc_version_string_ctypes() -> str | None:
    ""Fallback implementation of glibc_version_string using ctypes.""

    try:
        import ctypes
    except ImportError:
        return None

    
    
    
    
    
    
    
    
    
    
    
    
    
    try:
        process_namespace = ctypes.CDLL(None)
    except OSError:
        return None

    try:
        gnu_get_libc_version = process_namespace.gnu_get_libc_version
    except AttributeError:
        
        
        return None

    
    gnu_get_libc_version.restype = ctypes.c_char_p
    version_str: str = gnu_get_libc_version()
    
    if not isinstance(version_str, str):
        version_str = version_str.decode(""ascii"")

    return version_str



















def libc_ver() -> tuple[str, str]:
    
    glibc_version = glibc_version_string()
    if glibc_version is None:
        return ("""", """")
    else:
        return (""glibc"", glibc_version)

from __future__ import annotations

import hashlib
from collections.abc import Iterable
from typing import TYPE_CHECKING, BinaryIO, NoReturn

from pip._internal.exceptions import HashMismatch, HashMissing, InstallationError
from pip._internal.utils.misc import read_chunks

if TYPE_CHECKING:
    from hashlib import _Hash




FAVORITE_HASH = ""sha256""




STRONG_HASHES = [""sha256"", ""sha384"", ""sha512""]


class Hashes:
    

    def __init__(self, hashes: dict[str, list[str]] | None = None) -> None:
        
        allowed = {}
        if hashes is not None:
            for alg, keys in hashes.items():
                
                allowed[alg] = [k.lower() for k in sorted(keys)]
        self._allowed = allowed

    def __and__(self, other: Hashes) -> Hashes:
        if not isinstance(other, Hashes):
            return NotImplemented

        
        
        if not other:
            return self
        if not self:
            return other

        
        new = {}
        for alg, values in other._allowed.items():
            if alg not in self._allowed:
                continue
            new[alg] = [v for v in values if v in self._allowed[alg]]
        return Hashes(new)

    @property
    def digest_count(self) -> int:
        return sum(len(digests) for digests in self._allowed.values())

    def is_hash_allowed(self, hash_name: str, hex_digest: str) -> bool:
        
        return hex_digest in self._allowed.get(hash_name, [])

    def check_against_chunks(self, chunks: Iterable[bytes]) -> None:
        
        gots = {}
        for hash_name in self._allowed.keys():
            try:
                gots[hash_name] = hashlib.new(hash_name)
            except (ValueError, TypeError):
                raise InstallationError(f""Unknown hash name: {hash_name}"")

        for chunk in chunks:
            for hash in gots.values():
                hash.update(chunk)

        for hash_name, got in gots.items():
            if got.hexdigest() in self._allowed[hash_name]:
                return
        self._raise(gots)

    def _raise(self, gots: dict[str, _Hash]) -> NoReturn:
        raise HashMismatch(self._allowed, gots)

    def check_against_file(self, file: BinaryIO) -> None:
        
        return self.check_against_chunks(read_chunks(file))

    def check_against_path(self, path: str) -> None:
        with open(path, ""rb"") as file:
            return self.check_against_file(file)

    def has_one_of(self, hashes: dict[str, str]) -> bool:
        
        for hash_name, hex_digest in hashes.items():
            if self.is_hash_allowed(hash_name, hex_digest):
                return True
        return False

    def __bool__(self) -> bool:
        
        return bool(self._allowed)

    def __eq__(self, other: object) -> bool:
        if not isinstance(other, Hashes):
            return NotImplemented
        return self._allowed == other._allowed

    def __hash__(self) -> int:
        return hash(
            "","".join(
                sorted(
                    "":"".join((alg, digest))
                    for alg, digest_list in self._allowed.items()
                    for digest in digest_list
                )
            )
        )


class MissingHashes(Hashes):
    

    def __init__(self) -> None:
        
        
        
        super().__init__(hashes={FAVORITE_HASH: []})

    def _raise(self, gots: dict[str, _Hash]) -> NoReturn:
        raise HashMissing(gots[FAVORITE_HASH].hexdigest())

from __future__ import annotations

import contextlib
import errno
import logging
import logging.handlers
import os
import sys
import threading
from collections.abc import Generator
from dataclasses import dataclass
from io import TextIOWrapper
from logging import Filter
from typing import Any, ClassVar

from pip._vendor.rich.console import (
    Console,
    ConsoleOptions,
    ConsoleRenderable,
    RenderableType,
    RenderResult,
    RichCast,
)
from pip._vendor.rich.highlighter import NullHighlighter
from pip._vendor.rich.logging import RichHandler
from pip._vendor.rich.segment import Segment
from pip._vendor.rich.style import Style

from pip._internal.utils._log import VERBOSE, getLogger
from pip._internal.utils.compat import WINDOWS
from pip._internal.utils.deprecation import DEPRECATION_MSG_PREFIX
from pip._internal.utils.misc import ensure_dir

_log_state = threading.local()
_stdout_console = None
_stderr_console = None
subprocess_logger = getLogger(""pip.subprocessor"")


class BrokenStdoutLoggingError(Exception):
    


def _is_broken_pipe_error(exc_class: type[BaseException], exc: BaseException) -> bool:
    if exc_class is BrokenPipeError:
        return True

    
    
    
    if not WINDOWS:
        return False

    return isinstance(exc, OSError) and exc.errno in (errno.EINVAL, errno.EPIPE)


@contextlib.contextmanager
def indent_log(num: int = 2) -> Generator[None, None, None]:
    
    
    _log_state.indentation = get_indentation()
    _log_state.indentation += num
    try:
        yield
    finally:
        _log_state.indentation -= num


def get_indentation() -> int:
    return getattr(_log_state, ""indentation"", 0)


class IndentingFormatter(logging.Formatter):
    default_time_format = ""%Y-%m-%dT%H:%M:%S""

    def __init__(
        self,
        *args: Any,
        add_timestamp: bool = False,
        **kwargs: Any,
    ) -> None:
        
        self.add_timestamp = add_timestamp
        super().__init__(*args, **kwargs)

    def get_message_start(self, formatted: str, levelno: int) -> str:
        
        if levelno < logging.WARNING:
            return """"
        if formatted.startswith(DEPRECATION_MSG_PREFIX):
            
            
            return """"
        if levelno < logging.ERROR:
            return ""WARNING: ""

        return ""ERROR: ""

    def format(self, record: logging.LogRecord) -> str:
        
        formatted = super().format(record)
        message_start = self.get_message_start(formatted, record.levelno)
        formatted = message_start + formatted

        prefix = """"
        if self.add_timestamp:
            prefix = f""{self.formatTime(record)} ""
        prefix += "" "" * get_indentation()
        formatted = """".join([prefix + line for line in formatted.splitlines(True)])
        return formatted


@dataclass
class IndentedRenderable:
    renderable: RenderableType
    indent: int

    def __rich_console__(
        self, console: Console, options: ConsoleOptions
    ) -> RenderResult:
        segments = console.render(self.renderable, options)
        lines = Segment.split_lines(segments)
        for line in lines:
            yield Segment("" "" * self.indent)
            yield from line
            yield Segment(""\n"")


class PipConsole(Console):
    def on_broken_pipe(self) -> None:
        
        
        raise BrokenPipeError() from None


def get_console(*, stderr: bool = False) -> Console:
    if stderr:
        assert _stderr_console is not None, ""stderr rich console is missing!""
        return _stderr_console
    else:
        assert _stdout_console is not None, ""stdout rich console is missing!""
        return _stdout_console


class RichPipStreamHandler(RichHandler):
    KEYWORDS: ClassVar[list[str] | None] = []

    def __init__(self, console: Console) -> None:
        super().__init__(
            console=console,
            show_time=False,
            show_level=False,
            show_path=False,
            highlighter=NullHighlighter(),
        )

    
    def emit(self, record: logging.LogRecord) -> None:
        style: Style | None = None

        
        if getattr(record, ""rich"", False):
            assert isinstance(record.args, tuple)
            (rich_renderable,) = record.args
            assert isinstance(
                rich_renderable, (ConsoleRenderable, RichCast, str)
            ), f""{rich_renderable} is not rich-console-renderable""

            renderable: RenderableType = IndentedRenderable(
                rich_renderable, indent=get_indentation()
            )
        else:
            message = self.format(record)
            renderable = self.render_message(record, message)
            if record.levelno is not None:
                if record.levelno >= logging.ERROR:
                    style = Style(color=""red"")
                elif record.levelno >= logging.WARNING:
                    style = Style(color=""yellow"")

        try:
            self.console.print(renderable, overflow=""ignore"", crop=False, style=style)
        except Exception:
            self.handleError(record)

    def handleError(self, record: logging.LogRecord) -> None:
        

        exc_class, exc = sys.exc_info()[:2]
        
        
        
        
        if (
            exc_class
            and exc
            and self.console.file is sys.stdout
            and _is_broken_pipe_error(exc_class, exc)
        ):
            raise BrokenStdoutLoggingError()

        return super().handleError(record)


class BetterRotatingFileHandler(logging.handlers.RotatingFileHandler):
    def _open(self) -> TextIOWrapper:
        ensure_dir(os.path.dirname(self.baseFilename))
        return super()._open()


class MaxLevelFilter(Filter):
    def __init__(self, level: int) -> None:
        self.level = level

    def filter(self, record: logging.LogRecord) -> bool:
        return record.levelno < self.level


class ExcludeLoggerFilter(Filter):
    

    def filter(self, record: logging.LogRecord) -> bool:
        
        
        return not super().filter(record)


def setup_logging(verbosity: int, no_color: bool, user_log_file: str | None) -> int:
    

    
    if verbosity >= 2:
        level_number = logging.DEBUG
    elif verbosity == 1:
        level_number = VERBOSE
    elif verbosity == -1:
        level_number = logging.WARNING
    elif verbosity == -2:
        level_number = logging.ERROR
    elif verbosity <= -3:
        level_number = logging.CRITICAL
    else:
        level_number = logging.INFO

    level = logging.getLevelName(level_number)

    
    
    include_user_log = user_log_file is not None
    if include_user_log:
        additional_log_file = user_log_file
        root_level = ""DEBUG""
    else:
        additional_log_file = ""/dev/null""
        root_level = level

    
    
    vendored_log_level = ""WARNING"" if level in [""INFO"", ""ERROR""] else ""DEBUG""

    
    handler_classes = {
        ""stream"": ""pip._internal.utils.logging.RichPipStreamHandler"",
        ""file"": ""pip._internal.utils.logging.BetterRotatingFileHandler"",
    }
    handlers = [""console"", ""console_errors"", ""console_subprocess""] + (
        [""user_log""] if include_user_log else []
    )
    global _stdout_console, stderr_console
    _stdout_console = PipConsole(file=sys.stdout, no_color=no_color, soft_wrap=True)
    _stderr_console = PipConsole(file=sys.stderr, no_color=no_color, soft_wrap=True)

    logging.config.dictConfig(
        {
            ""version"": 1,
            ""disable_existing_loggers"": False,
            ""filters"": {
                ""exclude_warnings"": {
                    ""()"": ""pip._internal.utils.logging.MaxLevelFilter"",
                    ""level"": logging.WARNING,
                },
                ""restrict_to_subprocess"": {
                    ""()"": ""logging.Filter"",
                    ""name"": subprocess_logger.name,
                },
                ""exclude_subprocess"": {
                    ""()"": ""pip._internal.utils.logging.ExcludeLoggerFilter"",
                    ""name"": subprocess_logger.name,
                },
            },
            ""formatters"": {
                ""indent"": {
                    ""()"": IndentingFormatter,
                    ""format"": ""%(message)s"",
                },
                ""indent_with_timestamp"": {
                    ""()"": IndentingFormatter,
                    ""format"": ""%(message)s"",
                    ""add_timestamp"": True,
                },
            },
            ""handlers"": {
                ""console"": {
                    ""level"": level,
                    ""class"": handler_classes[""stream""],
                    ""console"": _stdout_console,
                    ""filters"": [""exclude_subprocess"", ""exclude_warnings""],
                    ""formatter"": ""indent"",
                },
                ""console_errors"": {
                    ""level"": ""WARNING"",
                    ""class"": handler_classes[""stream""],
                    ""console"": _stderr_console,
                    ""filters"": [""exclude_subprocess""],
                    ""formatter"": ""indent"",
                },
                
                
                ""console_subprocess"": {
                    ""level"": level,
                    ""class"": handler_classes[""stream""],
                    ""console"": _stderr_console,
                    ""filters"": [""restrict_to_subprocess""],
                    ""formatter"": ""indent"",
                },
                ""user_log"": {
                    ""level"": ""DEBUG"",
                    ""class"": handler_classes[""file""],
                    ""filename"": additional_log_file,
                    ""encoding"": ""utf-8"",
                    ""delay"": True,
                    ""formatter"": ""indent_with_timestamp"",
                },
            },
            ""root"": {
                ""level"": root_level,
                ""handlers"": handlers,
            },
            ""loggers"": {""pip._vendor"": {""level"": vendored_log_level}},
        }
    )

    return level_number

from __future__ import annotations

import errno
import getpass
import hashlib
import logging
import os
import posixpath
import shutil
import stat
import sys
import sysconfig
import urllib.parse
from collections.abc import Generator, Iterable, Iterator, Mapping, Sequence
from dataclasses import dataclass
from functools import partial
from io import StringIO
from itertools import filterfalse, tee, zip_longest
from pathlib import Path
from types import FunctionType, TracebackType
from typing import (
    Any,
    BinaryIO,
    Callable,
    Optional,
    TextIO,
    TypeVar,
    cast,
)

from pip._vendor.packaging.requirements import Requirement
from pip._vendor.pyproject_hooks import BuildBackendHookCaller

from pip import __version__
from pip._internal.exceptions import CommandError, ExternallyManagedEnvironment
from pip._internal.locations import get_major_minor_version
from pip._internal.utils.compat import WINDOWS
from pip._internal.utils.retry import retry
from pip._internal.utils.virtualenv import running_under_virtualenv

__all__ = [
    ""rmtree"",
    ""display_path"",
    ""backup_dir"",
    ""ask"",
    ""splitext"",
    ""format_size"",
    ""is_installable_dir"",
    ""normalize_path"",
    ""renames"",
    ""get_prog"",
    ""ensure_dir"",
    ""remove_auth_from_url"",
    ""check_externally_managed"",
    ""ConfiguredBuildBackendHookCaller"",
]

logger = logging.getLogger(__name__)

T = TypeVar(""T"")
ExcInfo = tuple[type[BaseException], BaseException, TracebackType]
VersionInfo = tuple[int, int, int]
NetlocTuple = tuple[str, tuple[Optional[str], Optional[str]]]
OnExc = Callable[[FunctionType, Path, BaseException], Any]
OnErr = Callable[[FunctionType, Path, ExcInfo], Any]

FILE_CHUNK_SIZE = 1024 * 1024


def get_pip_version() -> str:
    pip_pkg_dir = os.path.join(os.path.dirname(__file__), "".."", "".."")
    pip_pkg_dir = os.path.abspath(pip_pkg_dir)

    return f""pip {__version__} from {pip_pkg_dir} (python {get_major_minor_version()})""


def normalize_version_info(py_version_info: tuple[int, ...]) -> tuple[int, int, int]:
    
    if len(py_version_info) < 3:
        py_version_info += (3 - len(py_version_info)) * (0,)
    elif len(py_version_info) > 3:
        py_version_info = py_version_info[:3]

    return cast(""VersionInfo"", py_version_info)


def ensure_dir(path: str) -> None:
    
    try:
        os.makedirs(path)
    except OSError as e:
        
        if e.errno != errno.EEXIST and e.errno != errno.ENOTEMPTY:
            raise


def get_prog() -> str:
    try:
        prog = os.path.basename(sys.argv[0])
        if prog in (""__main__.py"", ""-c""):
            return f""{sys.executable} -m pip""
        else:
            return prog
    except (AttributeError, TypeError, IndexError):
        pass
    return ""pip""



@retry(stop_after_delay=3, wait=0.5)
def rmtree(dir: str, ignore_errors: bool = False, onexc: OnExc | None = None) -> None:
    if ignore_errors:
        onexc = _onerror_ignore
    if onexc is None:
        onexc = _onerror_reraise
    handler: OnErr = partial(rmtree_errorhandler, onexc=onexc)
    if sys.version_info >= (3, 12):
        
        shutil.rmtree(dir, onexc=handler)  
    else:
        shutil.rmtree(dir, onerror=handler)  


def _onerror_ignore(*_args: Any) -> None:
    pass


def _onerror_reraise(*_args: Any) -> None:
    raise  


def rmtree_errorhandler(
    func: FunctionType,
    path: Path,
    exc_info: ExcInfo | BaseException,
    *,
    onexc: OnExc = _onerror_reraise,
) -> None:
    
    try:
        st_mode = os.stat(path).st_mode
    except OSError:
        
        return

    if not st_mode & stat.S_IWRITE:
        
        try:
            os.chmod(path, st_mode | stat.S_IWRITE)
        except OSError:
            pass
        else:
            
            try:
                func(path)
                return
            except OSError:
                pass

    if not isinstance(exc_info, BaseException):
        _, exc_info, _ = exc_info
    onexc(func, path, exc_info)


def display_path(path: str) -> str:
    
    path = os.path.normcase(os.path.abspath(path))
    if path.startswith(os.getcwd() + os.path.sep):
        path = ""."" + path[len(os.getcwd()) :]
    return path


def backup_dir(dir: str, ext: str = "".bak"") -> str:
    
    n = 1
    extension = ext
    while os.path.exists(dir + extension):
        n += 1
        extension = ext + str(n)
    return dir + extension


def ask_path_exists(message: str, options: Iterable[str]) -> str:
    for action in os.environ.get(""PIP_EXISTS_ACTION"", """").split():
        if action in options:
            return action
    return ask(message, options)


def _check_no_input(message: str) -> None:
    
    if os.environ.get(""PIP_NO_INPUT""):
        raise Exception(
            f""No input was expected ($PIP_NO_INPUT set); question: {message}""
        )


def ask(message: str, options: Iterable[str]) -> str:
    
    while 1:
        _check_no_input(message)
        response = input(message)
        response = response.strip().lower()
        if response not in options:
            print(
                ""Your response ({!r}) was not one of the expected responses: ""
                ""{}"".format(response, "", "".join(options))
            )
        else:
            return response


def ask_input(message: str) -> str:
    
    _check_no_input(message)
    return input(message)


def ask_password(message: str) -> str:
    
    _check_no_input(message)
    return getpass.getpass(message)


def strtobool(val: str) -> int:
    
    val = val.lower()
    if val in (""y"", ""yes"", ""t"", ""true"", ""on"", ""1""):
        return 1
    elif val in (""n"", ""no"", ""f"", ""false"", ""off"", ""0""):
        return 0
    else:
        raise ValueError(f""invalid truth value {val!r}"")


def format_size(bytes: float) -> str:
    if bytes > 1000 * 1000:
        return f""{bytes / 1000.0 / 1000:.1f} MB""
    elif bytes > 10 * 1000:
        return f""{int(bytes / 1000)} kB""
    elif bytes > 1000:
        return f""{bytes / 1000.0:.1f} kB""
    else:
        return f""{int(bytes)} bytes""


def tabulate(rows: Iterable[Iterable[Any]]) -> tuple[list[str], list[int]]:
    
    rows = [tuple(map(str, row)) for row in rows]
    sizes = [max(map(len, col)) for col in zip_longest(*rows, fillvalue="""")]
    table = ["" "".join(map(str.ljust, row, sizes)).rstrip() for row in rows]
    return table, sizes


def is_installable_dir(path: str) -> bool:
    
    if not os.path.isdir(path):
        return False
    if os.path.isfile(os.path.join(path, ""pyproject.toml"")):
        return True
    if os.path.isfile(os.path.join(path, ""setup.py"")):
        return True
    return False


def read_chunks(
    file: BinaryIO, size: int = FILE_CHUNK_SIZE
) -> Generator[bytes, None, None]:
    
    while True:
        chunk = file.read(size)
        if not chunk:
            break
        yield chunk


def normalize_path(path: str, resolve_symlinks: bool = True) -> str:
    
    path = os.path.expanduser(path)
    if resolve_symlinks:
        path = os.path.realpath(path)
    else:
        path = os.path.abspath(path)
    return os.path.normcase(path)


def splitext(path: str) -> tuple[str, str]:
    
    base, ext = posixpath.splitext(path)
    if base.lower().endswith("".tar""):
        ext = base[-4:] + ext
        base = base[:-4]
    return base, ext


def renames(old: str, new: str) -> None:
    
    
    head, tail = os.path.split(new)
    if head and tail and not os.path.exists(head):
        os.makedirs(head)

    shutil.move(old, new)

    head, tail = os.path.split(old)
    if head and tail:
        try:
            os.removedirs(head)
        except OSError:
            pass


def is_local(path: str) -> bool:
    
    if not running_under_virtualenv():
        return True
    return path.startswith(normalize_path(sys.prefix))


def write_output(msg: Any, *args: Any) -> None:
    logger.info(msg, *args)


class StreamWrapper(StringIO):
    orig_stream: TextIO

    @classmethod
    def from_stream(cls, orig_stream: TextIO) -> StreamWrapper:
        ret = cls()
        ret.orig_stream = orig_stream
        return ret

    
    
    @property
    def encoding(self) -> str:  
        return self.orig_stream.encoding



def enum(*sequential: Any, **named: Any) -> type[Any]:
    enums = dict(zip(sequential, range(len(sequential))), **named)
    reverse = {value: key for key, value in enums.items()}
    enums[""reverse_mapping""] = reverse
    return type(""Enum"", (), enums)


def build_netloc(host: str, port: int | None) -> str:
    
    if port is None:
        return host
    if "":"" in host:
        
        host = f""[{host}]""
    return f""{host}:{port}""


def build_url_from_netloc(netloc: str, scheme: str = ""https"") -> str:
    
    if netloc.count("":"") >= 2 and ""@"" not in netloc and ""["" not in netloc:
        
        netloc = f""[{netloc}]""
    return f""{scheme}://{netloc}""


def parse_netloc(netloc: str) -> tuple[str | None, int | None]:
    
    url = build_url_from_netloc(netloc)
    parsed = urllib.parse.urlparse(url)
    return parsed.hostname, parsed.port


def split_auth_from_netloc(netloc: str) -> NetlocTuple:
    
    if ""@"" not in netloc:
        return netloc, (None, None)

    
    
    
    auth, netloc = netloc.rsplit(""@"", 1)
    pw: str | None = None
    if "":"" in auth:
        
        
        
        user, pw = auth.split("":"", 1)
    else:
        user, pw = auth, None

    user = urllib.parse.unquote(user)
    if pw is not None:
        pw = urllib.parse.unquote(pw)

    return netloc, (user, pw)


def redact_netloc(netloc: str) -> str:
    
    netloc, (user, password) = split_auth_from_netloc(netloc)
    if user is None:
        return netloc
    if password is None:
        user = ""****""
        password = """"
    else:
        user = urllib.parse.quote(user)
        password = "":****""
    return f""{user}{password}@{netloc}""


def _transform_url(
    url: str, transform_netloc: Callable[[str], tuple[Any, ...]]
) -> tuple[str, NetlocTuple]:
    
    purl = urllib.parse.urlsplit(url)
    netloc_tuple = transform_netloc(purl.netloc)
    
    url_pieces = (purl.scheme, netloc_tuple[0], purl.path, purl.query, purl.fragment)
    surl = urllib.parse.urlunsplit(url_pieces)
    return surl, cast(""NetlocTuple"", netloc_tuple)


def _get_netloc(netloc: str) -> NetlocTuple:
    return split_auth_from_netloc(netloc)


def _redact_netloc(netloc: str) -> tuple[str]:
    return (redact_netloc(netloc),)


def split_auth_netloc_from_url(
    url: str,
) -> tuple[str, str, tuple[str | None, str | None]]:
    
    url_without_auth, (netloc, auth) = _transform_url(url, _get_netloc)
    return url_without_auth, netloc, auth


def remove_auth_from_url(url: str) -> str:
    
    
    
    return _transform_url(url, _get_netloc)[0]


def redact_auth_from_url(url: str) -> str:
    
    return _transform_url(url, _redact_netloc)[0]


def redact_auth_from_requirement(req: Requirement) -> str:
    
    if not req.url:
        return str(req)
    return str(req).replace(req.url, redact_auth_from_url(req.url))


@dataclass(frozen=True)
class HiddenText:
    secret: str
    redacted: str

    def __repr__(self) -> str:
        return f""<HiddenText {str(self)!r}>""

    def __str__(self) -> str:
        return self.redacted

    
    def __eq__(self, other: Any) -> bool:
        if type(self) is not type(other):
            return False

        
        
        return self.secret == other.secret


def hide_value(value: str) -> HiddenText:
    return HiddenText(value, redacted=""****"")


def hide_url(url: str) -> HiddenText:
    redacted = redact_auth_from_url(url)
    return HiddenText(url, redacted=redacted)


def protect_pip_from_modification_on_windows(modifying_pip: bool) -> None:
    
    pip_names = [
        ""pip"",
        f""pip{sys.version_info.major}"",
        f""pip{sys.version_info.major}.{sys.version_info.minor}"",
    ]

    
    should_show_use_python_msg = (
        modifying_pip and WINDOWS and os.path.basename(sys.argv[0]) in pip_names
    )

    if should_show_use_python_msg:
        new_command = [sys.executable, ""-m"", ""pip""] + sys.argv[1:]
        raise CommandError(
            ""To modify pip, please run the following command:\n{}"".format(
                "" "".join(new_command)
            )
        )


def check_externally_managed() -> None:
    
    if running_under_virtualenv():
        return
    marker = os.path.join(sysconfig.get_path(""stdlib""), ""EXTERNALLY-MANAGED"")
    if not os.path.isfile(marker):
        return
    raise ExternallyManagedEnvironment.from_config(marker)


def is_console_interactive() -> bool:
    
    return sys.stdin is not None and sys.stdin.isatty()


def hash_file(path: str, blocksize: int = 1 << 20) -> tuple[Any, int]:
    

    h = hashlib.sha256()
    length = 0
    with open(path, ""rb"") as f:
        for block in read_chunks(f, size=blocksize):
            length += len(block)
            h.update(block)
    return h, length


def pairwise(iterable: Iterable[Any]) -> Iterator[tuple[Any, Any]]:
    
    iterable = iter(iterable)
    return zip_longest(iterable, iterable)


def partition(
    pred: Callable[[T], bool], iterable: Iterable[T]
) -> tuple[Iterable[T], Iterable[T]]:
    
    t1, t2 = tee(iterable)
    return filterfalse(pred, t1), filter(pred, t2)


class ConfiguredBuildBackendHookCaller(BuildBackendHookCaller):
    def __init__(
        self,
        config_holder: Any,
        source_dir: str,
        build_backend: str,
        backend_path: str | None = None,
        runner: Callable[..., None] | None = None,
        python_executable: str | None = None,
    ):
        super().__init__(
            source_dir, build_backend, backend_path, runner, python_executable
        )
        self.config_holder = config_holder

    def build_wheel(
        self,
        wheel_directory: str,
        config_settings: Mapping[str, Any] | None = None,
        metadata_directory: str | None = None,
    ) -> str:
        cs = self.config_holder.config_settings
        return super().build_wheel(
            wheel_directory, config_settings=cs, metadata_directory=metadata_directory
        )

    def build_sdist(
        self,
        sdist_directory: str,
        config_settings: Mapping[str, Any] | None = None,
    ) -> str:
        cs = self.config_holder.config_settings
        return super().build_sdist(sdist_directory, config_settings=cs)

    def build_editable(
        self,
        wheel_directory: str,
        config_settings: Mapping[str, Any] | None = None,
        metadata_directory: str | None = None,
    ) -> str:
        cs = self.config_holder.config_settings
        return super().build_editable(
            wheel_directory, config_settings=cs, metadata_directory=metadata_directory
        )

    def get_requires_for_build_wheel(
        self, config_settings: Mapping[str, Any] | None = None
    ) -> Sequence[str]:
        cs = self.config_holder.config_settings
        return super().get_requires_for_build_wheel(config_settings=cs)

    def get_requires_for_build_sdist(
        self, config_settings: Mapping[str, Any] | None = None
    ) -> Sequence[str]:
        cs = self.config_holder.config_settings
        return super().get_requires_for_build_sdist(config_settings=cs)

    def get_requires_for_build_editable(
        self, config_settings: Mapping[str, Any] | None = None
    ) -> Sequence[str]:
        cs = self.config_holder.config_settings
        return super().get_requires_for_build_editable(config_settings=cs)

    def prepare_metadata_for_build_wheel(
        self,
        metadata_directory: str,
        config_settings: Mapping[str, Any] | None = None,
        _allow_fallback: bool = True,
    ) -> str:
        cs = self.config_holder.config_settings
        return super().prepare_metadata_for_build_wheel(
            metadata_directory=metadata_directory,
            config_settings=cs,
            _allow_fallback=_allow_fallback,
        )

    def prepare_metadata_for_build_editable(
        self,
        metadata_directory: str,
        config_settings: Mapping[str, Any] | None = None,
        _allow_fallback: bool = True,
    ) -> str | None:
        cs = self.config_holder.config_settings
        return super().prepare_metadata_for_build_editable(
            metadata_directory=metadata_directory,
            config_settings=cs,
            _allow_fallback=_allow_fallback,
        )


def warn_if_run_as_root() -> None:
    
    if running_under_virtualenv():
        return
    if not hasattr(os, ""getuid""):
        return
    
    
    
    
    
    if sys.platform == ""win32"" or sys.platform == ""cygwin"":
        return

    if os.getuid() != 0:
        return

    logger.warning(
        ""Running pip as the 'root' user can result in broken permissions and ""
        ""conflicting behaviour with the system package manager, possibly ""
        ""rendering your system unusable. ""
        ""It is recommended to use a virtual environment instead: ""
        ""https://pip.pypa.io/warnings/venv. ""
        ""Use the --root-user-action option if you know what you are doing and ""
        ""want to suppress this warning.""
    )

from __future__ import annotations

import functools
import logging

from pip._vendor.packaging import specifiers, version
from pip._vendor.packaging.requirements import Requirement

logger = logging.getLogger(__name__)


@functools.lru_cache(maxsize=32)
def check_requires_python(
    requires_python: str | None, version_info: tuple[int, ...]
) -> bool:
    
    if requires_python is None:
        
        return True
    requires_python_specifier = specifiers.SpecifierSet(requires_python)

    python_version = version.parse(""."".join(map(str, version_info)))
    return python_version in requires_python_specifier


@functools.lru_cache(maxsize=10000)
def get_requirement(req_string: str) -> Requirement:
    
    
    
    
    
    
    return Requirement(req_string)

from __future__ import annotations

import functools
from time import perf_counter, sleep
from typing import TYPE_CHECKING, Callable, TypeVar

if TYPE_CHECKING:
    from typing_extensions import ParamSpec

    T = TypeVar(""T"")
    P = ParamSpec(""P"")


def retry(
    wait: float, stop_after_delay: float
) -> Callable[[Callable[P, T]], Callable[P, T]]:
    

    def wrapper(func: Callable[P, T]) -> Callable[P, T]:

        @functools.wraps(func)
        def retry_wrapped(*args: P.args, **kwargs: P.kwargs) -> T:
            
            
            start_time = perf_counter()
            while True:
                try:
                    return func(*args, **kwargs)
                except Exception:
                    if perf_counter() - start_time > stop_after_delay:
                        raise
                    sleep(wait)

        return retry_wrapped

    return wrapper

from __future__ import annotations

import sys
import textwrap
from collections.abc import Sequence




_SETUPTOOLS_SHIM = textwrap.dedent(
    
).rstrip()


def make_setuptools_shim_args(
    setup_py_path: str,
    global_options: Sequence[str] | None = None,
    no_user_config: bool = False,
    unbuffered_output: bool = False,
) -> list[str]:
    
    args = [sys.executable]
    if unbuffered_output:
        args += [""-u""]
    args += [""-c"", _SETUPTOOLS_SHIM.format(setup_py_path)]
    if global_options:
        args += global_options
    if no_user_config:
        args += [""--no-user-cfg""]
    return args


def make_setuptools_bdist_wheel_args(
    setup_py_path: str,
    global_options: Sequence[str],
    build_options: Sequence[str],
    destination_dir: str,
) -> list[str]:
    
    
    
    
    args = make_setuptools_shim_args(
        setup_py_path, global_options=global_options, unbuffered_output=True
    )
    args += [""bdist_wheel"", ""-d"", destination_dir]
    args += build_options
    return args


def make_setuptools_clean_args(
    setup_py_path: str,
    global_options: Sequence[str],
) -> list[str]:
    args = make_setuptools_shim_args(
        setup_py_path, global_options=global_options, unbuffered_output=True
    )
    args += [""clean"", ""--all""]
    return args


def make_setuptools_develop_args(
    setup_py_path: str,
    *,
    global_options: Sequence[str],
    no_user_config: bool,
    prefix: str | None,
    home: str | None,
    use_user_site: bool,
) -> list[str]:
    assert not (use_user_site and prefix)

    args = make_setuptools_shim_args(
        setup_py_path,
        global_options=global_options,
        no_user_config=no_user_config,
    )

    args += [""develop"", ""--no-deps""]

    if prefix:
        args += [""--prefix"", prefix]
    if home is not None:
        args += [""--install-dir"", home]

    if use_user_site:
        args += [""--user"", ""--prefix=""]

    return args


def make_setuptools_egg_info_args(
    setup_py_path: str,
    egg_info_dir: str | None,
    no_user_config: bool,
) -> list[str]:
    args = make_setuptools_shim_args(setup_py_path, no_user_config=no_user_config)

    args += [""egg_info""]

    if egg_info_dir:
        args += [""--egg-base"", egg_info_dir]

    return args

from __future__ import annotations

import logging
import os
import shlex
import subprocess
from collections.abc import Iterable, Mapping
from typing import Any, Callable, Literal, Union

from pip._vendor.rich.markup import escape

from pip._internal.cli.spinners import SpinnerInterface, open_spinner
from pip._internal.exceptions import InstallationSubprocessError
from pip._internal.utils.logging import VERBOSE, subprocess_logger
from pip._internal.utils.misc import HiddenText

CommandArgs = list[Union[str, HiddenText]]


def make_command(*args: str | HiddenText | CommandArgs) -> CommandArgs:
    
    command_args: CommandArgs = []
    for arg in args:
        
        
        if isinstance(arg, list):
            command_args.extend(arg)
        else:
            
            command_args.append(arg)

    return command_args


def format_command_args(args: list[str] | CommandArgs) -> str:
    
    
    
    
    
    
    return "" "".join(
        shlex.quote(str(arg)) if isinstance(arg, HiddenText) else shlex.quote(arg)
        for arg in args
    )


def reveal_command_args(args: list[str] | CommandArgs) -> list[str]:
    
    return [arg.secret if isinstance(arg, HiddenText) else arg for arg in args]


def call_subprocess(
    cmd: list[str] | CommandArgs,
    show_stdout: bool = False,
    cwd: str | None = None,
    on_returncode: Literal[""raise"", ""warn"", ""ignore""] = ""raise"",
    extra_ok_returncodes: Iterable[int] | None = None,
    extra_environ: Mapping[str, Any] | None = None,
    unset_environ: Iterable[str] | None = None,
    spinner: SpinnerInterface | None = None,
    log_failed_cmd: bool | None = True,
    stdout_only: bool | None = False,
    *,
    command_desc: str,
) -> str:
    
    if extra_ok_returncodes is None:
        extra_ok_returncodes = []
    if unset_environ is None:
        unset_environ = []
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    if show_stdout:
        
        log_subprocess: Callable[..., None] = subprocess_logger.info
        used_level = logging.INFO
    else:
        
        
        log_subprocess = subprocess_logger.verbose
        used_level = VERBOSE

    
    showing_subprocess = subprocess_logger.getEffectiveLevel() <= used_level

    
    
    use_spinner = not showing_subprocess and spinner is not None

    log_subprocess(""Running command %s"", command_desc)
    env = os.environ.copy()
    if extra_environ:
        env.update(extra_environ)
    for name in unset_environ:
        env.pop(name, None)
    try:
        proc = subprocess.Popen(
            
            reveal_command_args(cmd),
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT if not stdout_only else subprocess.PIPE,
            cwd=cwd,
            env=env,
            errors=""backslashreplace"",
        )
    except Exception as exc:
        if log_failed_cmd:
            subprocess_logger.critical(
                ""Error %s while executing command %s"",
                exc,
                command_desc,
            )
        raise
    all_output = []
    if not stdout_only:
        assert proc.stdout
        assert proc.stdin
        proc.stdin.close()
        
        while True:
            line: str = proc.stdout.readline()
            if not line:
                break
            line = line.rstrip()
            all_output.append(line + ""\n"")

            
            log_subprocess(line)
            
            if use_spinner:
                assert spinner
                spinner.spin()
        try:
            proc.wait()
        finally:
            if proc.stdout:
                proc.stdout.close()
        output = """".join(all_output)
    else:
        
        
        out, err = proc.communicate()
        
        for out_line in out.splitlines():
            log_subprocess(out_line)
        all_output.append(out)
        for err_line in err.splitlines():
            log_subprocess(err_line)
        all_output.append(err)
        output = out

    proc_had_error = proc.returncode and proc.returncode not in extra_ok_returncodes
    if use_spinner:
        assert spinner
        if proc_had_error:
            spinner.finish(""error"")
        else:
            spinner.finish(""done"")
    if proc_had_error:
        if on_returncode == ""raise"":
            error = InstallationSubprocessError(
                command_description=command_desc,
                exit_code=proc.returncode,
                output_lines=all_output if not showing_subprocess else None,
            )
            if log_failed_cmd:
                subprocess_logger.error(""%s"", error, extra={""rich"": True})
                subprocess_logger.verbose(
                    ""[bold magenta]full command[/]: [blue]%s[/]"",
                    escape(format_command_args(cmd)),
                    extra={""markup"": True},
                )
                subprocess_logger.verbose(
                    ""[bold magenta]cwd[/]: %s"",
                    escape(cwd or ""[inherit]""),
                    extra={""markup"": True},
                )

            raise error
        elif on_returncode == ""warn"":
            subprocess_logger.warning(
                'Command ""%s"" had error code %s in %s',
                command_desc,
                proc.returncode,
                cwd,
            )
        elif on_returncode == ""ignore"":
            pass
        else:
            raise ValueError(f""Invalid value: on_returncode={on_returncode!r}"")
    return output


def runner_with_spinner_message(message: str) -> Callable[..., None]:
    

    def runner(
        cmd: list[str],
        cwd: str | None = None,
        extra_environ: Mapping[str, Any] | None = None,
    ) -> None:
        with open_spinner(message) as spinner:
            call_subprocess(
                cmd,
                command_desc=message,
                cwd=cwd,
                extra_environ=extra_environ,
                spinner=spinner,
            )

    return runner

from __future__ import annotations

import errno
import itertools
import logging
import os.path
import tempfile
import traceback
from collections.abc import Generator
from contextlib import ExitStack, contextmanager
from pathlib import Path
from typing import (
    Any,
    Callable,
    TypeVar,
)

from pip._internal.utils.misc import enum, rmtree

logger = logging.getLogger(__name__)

_T = TypeVar(""_T"", bound=""TempDirectory"")




tempdir_kinds = enum(
    BUILD_ENV=""build-env"",
    EPHEM_WHEEL_CACHE=""ephem-wheel-cache"",
    REQ_BUILD=""req-build"",
)


_tempdir_manager: ExitStack | None = None


@contextmanager
def global_tempdir_manager() -> Generator[None, None, None]:
    global _tempdir_manager
    with ExitStack() as stack:
        old_tempdir_manager, _tempdir_manager = _tempdir_manager, stack
        try:
            yield
        finally:
            _tempdir_manager = old_tempdir_manager


class TempDirectoryTypeRegistry:
    

    def __init__(self) -> None:
        self._should_delete: dict[str, bool] = {}

    def set_delete(self, kind: str, value: bool) -> None:
        
        self._should_delete[kind] = value

    def get_delete(self, kind: str) -> bool:
        
        return self._should_delete.get(kind, True)


_tempdir_registry: TempDirectoryTypeRegistry | None = None


@contextmanager
def tempdir_registry() -> Generator[TempDirectoryTypeRegistry, None, None]:
    
    global _tempdir_registry
    old_tempdir_registry = _tempdir_registry
    _tempdir_registry = TempDirectoryTypeRegistry()
    try:
        yield _tempdir_registry
    finally:
        _tempdir_registry = old_tempdir_registry


class _Default:
    pass


_default = _Default()


class TempDirectory:
    

    def __init__(
        self,
        path: str | None = None,
        delete: bool | None | _Default = _default,
        kind: str = ""temp"",
        globally_managed: bool = False,
        ignore_cleanup_errors: bool = True,
    ):
        super().__init__()

        if delete is _default:
            if path is not None:
                
                
                delete = False
            else:
                
                
                delete = None

        
        
        if path is None:
            path = self._create(kind)

        self._path = path
        self._deleted = False
        self.delete = delete
        self.kind = kind
        self.ignore_cleanup_errors = ignore_cleanup_errors

        if globally_managed:
            assert _tempdir_manager is not None
            _tempdir_manager.enter_context(self)

    @property
    def path(self) -> str:
        assert not self._deleted, f""Attempted to access deleted path: {self._path}""
        return self._path

    def __repr__(self) -> str:
        return f""<{self.__class__.__name__} {self.path!r}>""

    def __enter__(self: _T) -> _T:
        return self

    def __exit__(self, exc: Any, value: Any, tb: Any) -> None:
        if self.delete is not None:
            delete = self.delete
        elif _tempdir_registry:
            delete = _tempdir_registry.get_delete(self.kind)
        else:
            delete = True

        if delete:
            self.cleanup()

    def _create(self, kind: str) -> str:
        
        
        
        
        
        path = os.path.realpath(tempfile.mkdtemp(prefix=f""pip-{kind}-""))
        logger.debug(""Created temporary directory: %s"", path)
        return path

    def cleanup(self) -> None:
        
        self._deleted = True
        if not os.path.exists(self._path):
            return

        errors: list[BaseException] = []

        def onerror(
            func: Callable[..., Any],
            path: Path,
            exc_val: BaseException,
        ) -> None:
            
            formatted_exc = ""\n"".join(
                traceback.format_exception_only(type(exc_val), exc_val)
            )
            formatted_exc = formatted_exc.rstrip()  
            if func in (os.unlink, os.remove, os.rmdir):
                logger.debug(
                    ""Failed to remove a temporary file '%s' due to %s.\n"",
                    path,
                    formatted_exc,
                )
            else:
                logger.debug(""%s failed with %s."", func.__qualname__, formatted_exc)
            errors.append(exc_val)

        if self.ignore_cleanup_errors:
            try:
                
                rmtree(self._path, ignore_errors=False)
            except OSError:
                
                rmtree(self._path, onexc=onerror)
            if errors:
                logger.warning(
                    ""Failed to remove contents in a temporary directory '%s'.\n""
                    ""You can safely remove it manually."",
                    self._path,
                )
        else:
            rmtree(self._path)


class AdjacentTempDirectory(TempDirectory):
    

    
    
    
    
    
    LEADING_CHARS = ""-~.=%0123456789""

    def __init__(self, original: str, delete: bool | None = None) -> None:
        self.original = original.rstrip(""/\\"")
        super().__init__(delete=delete)

    @classmethod
    def _generate_names(cls, name: str) -> Generator[str, None, None]:
        
        for i in range(1, len(name)):
            for candidate in itertools.combinations_with_replacement(
                cls.LEADING_CHARS, i - 1
            ):
                new_name = ""~"" + """".join(candidate) + name[i:]
                if new_name != name:
                    yield new_name

        
        for i in range(len(cls.LEADING_CHARS)):
            for candidate in itertools.combinations_with_replacement(
                cls.LEADING_CHARS, i
            ):
                new_name = ""~"" + """".join(candidate) + name
                if new_name != name:
                    yield new_name

    def _create(self, kind: str) -> str:
        root, name = os.path.split(self.original)
        for candidate in self._generate_names(name):
            path = os.path.join(root, candidate)
            try:
                os.mkdir(path)
            except OSError as ex:
                
                if ex.errno != errno.EEXIST:
                    raise
            else:
                path = os.path.realpath(path)
                break
        else:
            
            path = os.path.realpath(tempfile.mkdtemp(prefix=f""pip-{kind}-""))

        logger.debug(""Created temporary directory: %s"", path)
        return path



from __future__ import annotations

import logging
import os
import shutil
import stat
import sys
import tarfile
import zipfile
from collections.abc import Iterable
from zipfile import ZipInfo

from pip._internal.exceptions import InstallationError
from pip._internal.utils.filetypes import (
    BZ2_EXTENSIONS,
    TAR_EXTENSIONS,
    XZ_EXTENSIONS,
    ZIP_EXTENSIONS,
)
from pip._internal.utils.misc import ensure_dir

logger = logging.getLogger(__name__)


SUPPORTED_EXTENSIONS = ZIP_EXTENSIONS + TAR_EXTENSIONS

try:
    import bz2  

    SUPPORTED_EXTENSIONS += BZ2_EXTENSIONS
except ImportError:
    logger.debug(""bz2 module is not available"")

try:
    
    import lzma  

    SUPPORTED_EXTENSIONS += XZ_EXTENSIONS
except ImportError:
    logger.debug(""lzma module is not available"")


def current_umask() -> int:
    
    mask = os.umask(0)
    os.umask(mask)
    return mask


def split_leading_dir(path: str) -> list[str]:
    path = path.lstrip(""/"").lstrip(""\\"")
    if ""/"" in path and (
        (""\\"" in path and path.find(""/"") < path.find(""\\"")) or ""\\"" not in path
    ):
        return path.split(""/"", 1)
    elif ""\\"" in path:
        return path.split(""\\"", 1)
    else:
        return [path, """"]


def has_leading_dir(paths: Iterable[str]) -> bool:
    
    common_prefix = None
    for path in paths:
        prefix, rest = split_leading_dir(path)
        if not prefix:
            return False
        elif common_prefix is None:
            common_prefix = prefix
        elif prefix != common_prefix:
            return False
    return True


def is_within_directory(directory: str, target: str) -> bool:
    
    abs_directory = os.path.abspath(directory)
    abs_target = os.path.abspath(target)

    prefix = os.path.commonprefix([abs_directory, abs_target])
    return prefix == abs_directory


def _get_default_mode_plus_executable() -> int:
    return 0o777 & ~current_umask() | 0o111


def set_extracted_file_to_default_mode_plus_executable(path: str) -> None:
    
    os.chmod(path, _get_default_mode_plus_executable())


def zip_item_is_executable(info: ZipInfo) -> bool:
    mode = info.external_attr >> 16
    
    
    return bool(mode and stat.S_ISREG(mode) and mode & 0o111)


def unzip_file(filename: str, location: str, flatten: bool = True) -> None:
    
    ensure_dir(location)
    zipfp = open(filename, ""rb"")
    try:
        zip = zipfile.ZipFile(zipfp, allowZip64=True)
        leading = has_leading_dir(zip.namelist()) and flatten
        for info in zip.infolist():
            name = info.filename
            fn = name
            if leading:
                fn = split_leading_dir(name)[1]
            fn = os.path.join(location, fn)
            dir = os.path.dirname(fn)
            if not is_within_directory(location, fn):
                message = (
                    ""The zip file ({}) has a file ({}) trying to install ""
                    ""outside target directory ({})""
                )
                raise InstallationError(message.format(filename, fn, location))
            if fn.endswith((""/"", ""\\"")):
                
                ensure_dir(fn)
            else:
                ensure_dir(dir)
                
                
                fp = zip.open(name)
                try:
                    with open(fn, ""wb"") as destfp:
                        shutil.copyfileobj(fp, destfp)
                finally:
                    fp.close()
                    if zip_item_is_executable(info):
                        set_extracted_file_to_default_mode_plus_executable(fn)
    finally:
        zipfp.close()


def untar_file(filename: str, location: str) -> None:
    
    ensure_dir(location)
    if filename.lower().endswith("".gz"") or filename.lower().endswith("".tgz""):
        mode = ""r:gz""
    elif filename.lower().endswith(BZ2_EXTENSIONS):
        mode = ""r:bz2""
    elif filename.lower().endswith(XZ_EXTENSIONS):
        mode = ""r:xz""
    elif filename.lower().endswith("".tar""):
        mode = ""r""
    else:
        logger.warning(
            ""Cannot determine compression type for file %s"",
            filename,
        )
        mode = ""r:*""

    tar = tarfile.open(filename, mode, encoding=""utf-8"")  
    try:
        leading = has_leading_dir([member.name for member in tar.getmembers()])

        
        
        
        try:
            data_filter = tarfile.data_filter
        except AttributeError:
            _untar_without_filter(filename, location, tar, leading)
        else:
            default_mode_plus_executable = _get_default_mode_plus_executable()

            if leading:
                
                
                
                for member in tar.getmembers():
                    name_lead, name_rest = split_leading_dir(member.name)
                    member.name = name_rest
                    if member.islnk():
                        lnk_lead, lnk_rest = split_leading_dir(member.linkname)
                        if lnk_lead == name_lead:
                            member.linkname = lnk_rest

            def pip_filter(member: tarfile.TarInfo, path: str) -> tarfile.TarInfo:
                orig_mode = member.mode
                try:
                    try:
                        member = data_filter(member, location)
                    except tarfile.LinkOutsideDestinationError:
                        if sys.version_info[:3] in {
                            (3, 9, 17),
                            (3, 10, 12),
                            (3, 11, 4),
                        }:
                            
                            
                            
                            
                            
                            member = tarfile.tar_filter(member, location)
                        else:
                            raise
                except tarfile.TarError as exc:
                    message = ""Invalid member in the tar file {}: {}""
                    
                    
                    raise InstallationError(
                        message.format(
                            filename,
                            exc,
                        )
                    )
                if member.isfile() and orig_mode & 0o111:
                    member.mode = default_mode_plus_executable
                else:
                    
                    
                    
                    
                    member.mode = None  
                return member

            tar.extractall(location, filter=pip_filter)

    finally:
        tar.close()


def _untar_without_filter(
    filename: str,
    location: str,
    tar: tarfile.TarFile,
    leading: bool,
) -> None:
    
    for member in tar.getmembers():
        fn = member.name
        if leading:
            fn = split_leading_dir(fn)[1]
        path = os.path.join(location, fn)
        if not is_within_directory(location, path):
            message = (
                ""The tar file ({}) has a file ({}) trying to install ""
                ""outside target directory ({})""
            )
            raise InstallationError(message.format(filename, path, location))
        if member.isdir():
            ensure_dir(path)
        elif member.issym():
            try:
                tar._extract_member(member, path)
            except Exception as exc:
                
                
                logger.warning(
                    ""In the tar file %s the member %s is invalid: %s"",
                    filename,
                    member.name,
                    exc,
                )
                continue
        else:
            try:
                fp = tar.extractfile(member)
            except (KeyError, AttributeError) as exc:
                
                
                logger.warning(
                    ""In the tar file %s the member %s is invalid: %s"",
                    filename,
                    member.name,
                    exc,
                )
                continue
            ensure_dir(os.path.dirname(path))
            assert fp is not None
            with open(path, ""wb"") as destfp:
                shutil.copyfileobj(fp, destfp)
            fp.close()
            
            tar.utime(member, path)
            
            if member.mode & 0o111:
                set_extracted_file_to_default_mode_plus_executable(path)


def unpack_file(
    filename: str,
    location: str,
    content_type: str | None = None,
) -> None:
    filename = os.path.realpath(filename)
    if (
        content_type == ""application/zip""
        or filename.lower().endswith(ZIP_EXTENSIONS)
        or zipfile.is_zipfile(filename)
    ):
        unzip_file(filename, location, flatten=not filename.endswith("".whl""))
    elif (
        content_type == ""application/x-gzip""
        or tarfile.is_tarfile(filename)
        or filename.lower().endswith(TAR_EXTENSIONS + BZ2_EXTENSIONS + XZ_EXTENSIONS)
    ):
        untar_file(filename, location)
    else:
        
        
        logger.critical(
            ""Cannot unpack file %s (downloaded from %s, content-type: %s); ""
            ""cannot detect archive format"",
            filename,
            location,
            content_type,
        )
        raise InstallationError(f""Cannot determine archive format of {location}"")

import os
import string
import urllib.parse
import urllib.request

from .compat import WINDOWS


def path_to_url(path: str) -> str:
    
    path = os.path.normpath(os.path.abspath(path))
    url = urllib.parse.urljoin(""file://"", urllib.request.pathname2url(path))
    return url


def url_to_path(url: str) -> str:
    
    assert url.startswith(
        ""file:""
    ), f""You can only turn file: urls into filenames (not {url!r})""

    _, netloc, path, _, _ = urllib.parse.urlsplit(url)

    if not netloc or netloc == ""localhost"":
        
        netloc = """"
    elif WINDOWS:
        
        netloc = ""\\\\"" + netloc
    else:
        raise ValueError(
            f""non-local file URIs are not supported on this platform: {url!r}""
        )

    path = urllib.request.url2pathname(netloc + path)

    
    
    
    if (
        WINDOWS
        and not netloc  
        and len(path) >= 3
        and path[0] == ""/""  
        and path[1] in string.ascii_letters  
        and path[2:4] in ("":"", "":/"")  
    ):
        path = path[1:]

    return path

from __future__ import annotations

import logging
import os
import re
import site
import sys

logger = logging.getLogger(__name__)
_INCLUDE_SYSTEM_SITE_PACKAGES_REGEX = re.compile(
    r""include-system-site-packages\s*=\s*(?P<value>true|false)""
)


def _running_under_venv() -> bool:
    
    return sys.prefix != getattr(sys, ""base_prefix"", sys.prefix)


def _running_under_legacy_virtualenv() -> bool:
    
    
    return hasattr(sys, ""real_prefix"")


def running_under_virtualenv() -> bool:
    
    return _running_under_venv() or _running_under_legacy_virtualenv()


def _get_pyvenv_cfg_lines() -> list[str] | None:
    
    pyvenv_cfg_file = os.path.join(sys.prefix, ""pyvenv.cfg"")
    try:
        
        
        with open(pyvenv_cfg_file, encoding=""utf-8"") as f:
            return f.read().splitlines()  
    except OSError:
        return None


def _no_global_under_venv() -> bool:
    
    cfg_lines = _get_pyvenv_cfg_lines()
    if cfg_lines is None:
        
        
        logger.warning(
            ""Could not access 'pyvenv.cfg' despite a virtual environment ""
            ""being active. Assuming global site-packages is not accessible ""
            ""in this environment.""
        )
        return True

    for line in cfg_lines:
        match = _INCLUDE_SYSTEM_SITE_PACKAGES_REGEX.match(line)
        if match is not None and match.group(""value"") == ""false"":
            return True
    return False


def _no_global_under_legacy_virtualenv() -> bool:
    
    site_mod_dir = os.path.dirname(os.path.abspath(site.__file__))
    no_global_site_packages_file = os.path.join(
        site_mod_dir,
        ""no-global-site-packages.txt"",
    )
    return os.path.exists(no_global_site_packages_file)


def virtualenv_no_global() -> bool:
    
    
    
    if _running_under_venv():
        return _no_global_under_venv()

    if _running_under_legacy_virtualenv():
        return _no_global_under_legacy_virtualenv()

    return False



import logging
from email.message import Message
from email.parser import Parser
from zipfile import BadZipFile, ZipFile

from pip._vendor.packaging.utils import canonicalize_name

from pip._internal.exceptions import UnsupportedWheel

VERSION_COMPATIBLE = (1, 0)


logger = logging.getLogger(__name__)


def parse_wheel(wheel_zip: ZipFile, name: str) -> tuple[str, Message]:
    
    try:
        info_dir = wheel_dist_info_dir(wheel_zip, name)
        metadata = wheel_metadata(wheel_zip, info_dir)
        version = wheel_version(metadata)
    except UnsupportedWheel as e:
        raise UnsupportedWheel(f""{name} has an invalid wheel, {e}"")

    check_compatibility(version, name)

    return info_dir, metadata


def wheel_dist_info_dir(source: ZipFile, name: str) -> str:
    
    
    subdirs = {p.split(""/"", 1)[0] for p in source.namelist()}

    info_dirs = [s for s in subdirs if s.endswith("".dist-info"")]

    if not info_dirs:
        raise UnsupportedWheel("".dist-info directory not found"")

    if len(info_dirs) > 1:
        raise UnsupportedWheel(
            ""multiple .dist-info directories found: {}"".format("", "".join(info_dirs))
        )

    info_dir = info_dirs[0]

    info_dir_name = canonicalize_name(info_dir)
    canonical_name = canonicalize_name(name)
    if not info_dir_name.startswith(canonical_name):
        raise UnsupportedWheel(
            f"".dist-info directory {info_dir!r} does not start with {canonical_name!r}""
        )

    return info_dir


def read_wheel_metadata_file(source: ZipFile, path: str) -> bytes:
    try:
        return source.read(path)
        
        
    except (BadZipFile, KeyError, RuntimeError) as e:
        raise UnsupportedWheel(f""could not read {path!r} file: {e!r}"")


def wheel_metadata(source: ZipFile, dist_info_dir: str) -> Message:
    
    path = f""{dist_info_dir}/WHEEL""
    
    wheel_contents = read_wheel_metadata_file(source, path)

    try:
        wheel_text = wheel_contents.decode()
    except UnicodeDecodeError as e:
        raise UnsupportedWheel(f""error decoding {path!r}: {e!r}"")

    
    
    
    return Parser().parsestr(wheel_text)


def wheel_version(wheel_data: Message) -> tuple[int, ...]:
    
    version_text = wheel_data[""Wheel-Version""]
    if version_text is None:
        raise UnsupportedWheel(""WHEEL is missing Wheel-Version"")

    version = version_text.strip()

    try:
        return tuple(map(int, version.split(""."")))
    except ValueError:
        raise UnsupportedWheel(f""invalid Wheel-Version: {version!r}"")


def check_compatibility(version: tuple[int, ...], name: str) -> None:
    
    if version[0] > VERSION_COMPATIBLE[0]:
        raise UnsupportedWheel(
            ""{}'s Wheel-Version ({}) is not compatible with this version ""
            ""of pip"".format(name, ""."".join(map(str, version)))
        )
    elif version > VERSION_COMPATIBLE:
        logger.warning(
            ""Installing from a newer Wheel-Version (%s)"",
            ""."".join(map(str, version)),
        )



import functools
import itertools


def _nonblank(str):
    return str and not str.startswith(""


@functools.singledispatch
def yield_lines(iterable):
    r
    return itertools.chain.from_iterable(map(yield_lines, iterable))


@yield_lines.register(str)
def _(text):
    return filter(_nonblank, map(str.strip, text.splitlines()))


def drop_comment(line):
    
    return line.partition("" 


def join_continuation(lines):
    r
    lines = iter(lines)
    for item in lines:
        while item.endswith(""\\""):
            try:
                item = item[:-2].strip() + next(lines)
            except StopIteration:
                return
        yield item



import logging
from typing import Any, cast



VERBOSE = 15


class VerboseLogger(logging.Logger):
    

    def verbose(self, msg: str, *args: Any, **kwargs: Any) -> None:
        return self.log(VERBOSE, msg, *args, **kwargs)


def getLogger(name: str) -> VerboseLogger:
    
    return cast(VerboseLogger, logging.getLogger(name))


def init_logging() -> None:
    
    logging.setLoggerClass(VerboseLogger)
    logging.addLevelName(VERBOSE, ""VERBOSE"")


from __future__ import annotations

import logging

from pip._internal.utils.misc import HiddenText, display_path
from pip._internal.utils.subprocess import make_command
from pip._internal.utils.urls import path_to_url
from pip._internal.vcs.versioncontrol import (
    AuthInfo,
    RemoteNotFoundError,
    RevOptions,
    VersionControl,
    vcs,
)

logger = logging.getLogger(__name__)


class Bazaar(VersionControl):
    name = ""bzr""
    dirname = "".bzr""
    repo_name = ""branch""
    schemes = (
        ""bzr+http"",
        ""bzr+https"",
        ""bzr+ssh"",
        ""bzr+sftp"",
        ""bzr+ftp"",
        ""bzr+lp"",
        ""bzr+file"",
    )

    @staticmethod
    def get_base_rev_args(rev: str) -> list[str]:
        return [""-r"", rev]

    def fetch_new(
        self, dest: str, url: HiddenText, rev_options: RevOptions, verbosity: int
    ) -> None:
        rev_display = rev_options.to_display()
        logger.info(
            ""Checking out %s%s to %s"",
            url,
            rev_display,
            display_path(dest),
        )
        if verbosity <= 0:
            flags = [""--quiet""]
        elif verbosity == 1:
            flags = []
        else:
            flags = [f""-{'v'*verbosity}""]
        cmd_args = make_command(
            ""checkout"", ""--lightweight"", *flags, rev_options.to_args(), url, dest
        )
        self.run_command(cmd_args)

    def switch(
        self,
        dest: str,
        url: HiddenText,
        rev_options: RevOptions,
        verbosity: int = 0,
    ) -> None:
        self.run_command(make_command(""switch"", url), cwd=dest)

    def update(
        self,
        dest: str,
        url: HiddenText,
        rev_options: RevOptions,
        verbosity: int = 0,
    ) -> None:
        flags = []

        if verbosity <= 0:
            flags.append(""-q"")

        output = self.run_command(
            make_command(""info""), show_stdout=False, stdout_only=True, cwd=dest
        )
        if output.startswith(""Standalone ""):
            
            
            cmd_args = make_command(""bind"", *flags, url)
            self.run_command(cmd_args, cwd=dest)

        cmd_args = make_command(""update"", *flags, rev_options.to_args())
        self.run_command(cmd_args, cwd=dest)

    @classmethod
    def get_url_rev_and_auth(cls, url: str) -> tuple[str, str | None, AuthInfo]:
        
        url, rev, user_pass = super().get_url_rev_and_auth(url)
        if url.startswith(""ssh://""):
            url = ""bzr+"" + url
        return url, rev, user_pass

    @classmethod
    def get_remote_url(cls, location: str) -> str:
        urls = cls.run_command(
            [""info""], show_stdout=False, stdout_only=True, cwd=location
        )
        for line in urls.splitlines():
            line = line.strip()
            for x in (""checkout of branch: "", ""parent branch: ""):
                if line.startswith(x):
                    repo = line.split(x)[1]
                    if cls._is_local_repository(repo):
                        return path_to_url(repo)
                    return repo
        raise RemoteNotFoundError

    @classmethod
    def get_revision(cls, location: str) -> str:
        revision = cls.run_command(
            [""revno""],
            show_stdout=False,
            stdout_only=True,
            cwd=location,
        )
        return revision.splitlines()[-1]

    @classmethod
    def is_commit_id_equal(cls, dest: str, name: str | None) -> bool:
        
        return False


vcs.register(Bazaar)

from __future__ import annotations

import logging
import os.path
import pathlib
import re
import urllib.parse
import urllib.request
from dataclasses import replace
from typing import Any

from pip._internal.exceptions import BadCommand, InstallationError
from pip._internal.utils.misc import HiddenText, display_path, hide_url
from pip._internal.utils.subprocess import make_command
from pip._internal.vcs.versioncontrol import (
    AuthInfo,
    RemoteNotFoundError,
    RemoteNotValidError,
    RevOptions,
    VersionControl,
    find_path_to_project_root_from_repo_root,
    vcs,
)

urlsplit = urllib.parse.urlsplit
urlunsplit = urllib.parse.urlunsplit


logger = logging.getLogger(__name__)


GIT_VERSION_REGEX = re.compile(
    r""^git version ""  
    r""(\d+)""  
    r""\.(\d+)""  
    r""(?:\.(\d+))?""  
    r"".*$""  
)

HASH_REGEX = re.compile(""^[a-fA-F0-9]{40}$"")


SCP_REGEX = re.compile(
    r,
    re.VERBOSE,
)


def looks_like_hash(sha: str) -> bool:
    return bool(HASH_REGEX.match(sha))


class Git(VersionControl):
    name = ""git""
    dirname = "".git""
    repo_name = ""clone""
    schemes = (
        ""git+http"",
        ""git+https"",
        ""git+ssh"",
        ""git+git"",
        ""git+file"",
    )
    
    
    unset_environ = (""GIT_DIR"", ""GIT_WORK_TREE"")
    default_arg_rev = ""HEAD""

    @staticmethod
    def get_base_rev_args(rev: str) -> list[str]:
        return [rev]

    @classmethod
    def run_command(cls, *args: Any, **kwargs: Any) -> str:
        if os.environ.get(""PIP_NO_INPUT""):
            extra_environ = kwargs.get(""extra_environ"", {})
            extra_environ[""GIT_TERMINAL_PROMPT""] = ""0""
            extra_environ[""GIT_SSH_COMMAND""] = ""ssh -oBatchMode=yes""
            kwargs[""extra_environ""] = extra_environ
        return super().run_command(*args, **kwargs)

    def is_immutable_rev_checkout(self, url: str, dest: str) -> bool:
        _, rev_options = self.get_url_rev_options(hide_url(url))
        if not rev_options.rev:
            return False
        if not self.is_commit_id_equal(dest, rev_options.rev):
            
            
            return False
        
        
        
        is_tag_or_branch = bool(self.get_revision_sha(dest, rev_options.rev)[0])
        return not is_tag_or_branch

    def get_git_version(self) -> tuple[int, ...]:
        version = self.run_command(
            [""version""],
            command_desc=""git version"",
            show_stdout=False,
            stdout_only=True,
        )
        match = GIT_VERSION_REGEX.match(version)
        if not match:
            logger.warning(""Can't parse git version: %s"", version)
            return ()
        return (int(match.group(1)), int(match.group(2)))

    @classmethod
    def get_current_branch(cls, location: str) -> str | None:
        
        
        
        
        
        args = [""symbolic-ref"", ""-q"", ""HEAD""]
        output = cls.run_command(
            args,
            extra_ok_returncodes=(1,),
            show_stdout=False,
            stdout_only=True,
            cwd=location,
        )
        ref = output.strip()

        if ref.startswith(""refs/heads/""):
            return ref[len(""refs/heads/"") :]

        return None

    @classmethod
    def get_revision_sha(cls, dest: str, rev: str) -> tuple[str | None, bool]:
        
        
        output = cls.run_command(
            [""show-ref"", rev],
            cwd=dest,
            show_stdout=False,
            stdout_only=True,
            on_returncode=""ignore"",
        )
        refs = {}
        
        
        
        for line in output.strip().split(""\n""):
            line = line.rstrip(""\r"")
            if not line:
                continue
            try:
                ref_sha, ref_name = line.split("" "", maxsplit=2)
            except ValueError:
                
                
                raise ValueError(f""unexpected show-ref line: {line!r}"")

            refs[ref_name] = ref_sha

        branch_ref = f""refs/remotes/origin/{rev}""
        tag_ref = f""refs/tags/{rev}""

        sha = refs.get(branch_ref)
        if sha is not None:
            return (sha, True)

        sha = refs.get(tag_ref)

        return (sha, False)

    @classmethod
    def _should_fetch(cls, dest: str, rev: str) -> bool:
        
        if rev.startswith(""refs/""):
            
            return True

        if not looks_like_hash(rev):
            
            return False

        if cls.has_commit(dest, rev):
            
            return False

        return True

    @classmethod
    def resolve_revision(
        cls, dest: str, url: HiddenText, rev_options: RevOptions
    ) -> RevOptions:
        
        rev = rev_options.arg_rev
        
        
        assert rev is not None

        sha, is_branch = cls.get_revision_sha(dest, rev)

        if sha is not None:
            rev_options = rev_options.make_new(sha)
            rev_options = replace(rev_options, branch_name=(rev if is_branch else None))

            return rev_options

        
        
        if not looks_like_hash(rev):
            logger.info(
                ""Did not find branch or tag '%s', assuming revision or ref."",
                rev,
            )

        if not cls._should_fetch(dest, rev):
            return rev_options

        
        cls.run_command(
            make_command(""fetch"", ""-q"", url, rev_options.to_args()),
            cwd=dest,
        )
        
        sha = cls.get_revision(dest, rev=""FETCH_HEAD"")
        rev_options = rev_options.make_new(sha)

        return rev_options

    @classmethod
    def is_commit_id_equal(cls, dest: str, name: str | None) -> bool:
        
        if not name:
            
            return False

        return cls.get_revision(dest) == name

    def fetch_new(
        self, dest: str, url: HiddenText, rev_options: RevOptions, verbosity: int
    ) -> None:
        rev_display = rev_options.to_display()
        logger.info(""Cloning %s%s to %s"", url, rev_display, display_path(dest))
        if verbosity <= 0:
            flags: tuple[str, ...] = (""--quiet"",)
        elif verbosity == 1:
            flags = ()
        else:
            flags = (""--verbose"", ""--progress"")
        if self.get_git_version() >= (2, 17):
            
            
            
            self.run_command(
                make_command(
                    ""clone"",
                    ""--filter=blob:none"",
                    *flags,
                    url,
                    dest,
                )
            )
        else:
            self.run_command(make_command(""clone"", *flags, url, dest))

        if rev_options.rev:
            
            rev_options = self.resolve_revision(dest, url, rev_options)
            branch_name = getattr(rev_options, ""branch_name"", None)
            logger.debug(""Rev options %s, branch_name %s"", rev_options, branch_name)
            if branch_name is None:
                
                
                if not self.is_commit_id_equal(dest, rev_options.rev):
                    cmd_args = make_command(
                        ""checkout"",
                        ""-q"",
                        rev_options.to_args(),
                    )
                    self.run_command(cmd_args, cwd=dest)
            elif self.get_current_branch(dest) != branch_name:
                
                
                track_branch = f""origin/{branch_name}""
                cmd_args = [
                    ""checkout"",
                    ""-b"",
                    branch_name,
                    ""--track"",
                    track_branch,
                ]
                self.run_command(cmd_args, cwd=dest)
        else:
            sha = self.get_revision(dest)
            rev_options = rev_options.make_new(sha)

        logger.info(""Resolved %s to commit %s"", url, rev_options.rev)

        
        self.update_submodules(dest, verbosity=verbosity)

    def switch(
        self,
        dest: str,
        url: HiddenText,
        rev_options: RevOptions,
        verbosity: int = 0,
    ) -> None:
        self.run_command(
            make_command(""config"", ""remote.origin.url"", url),
            cwd=dest,
        )

        extra_flags = []

        if verbosity <= 0:
            extra_flags.append(""-q"")

        cmd_args = make_command(""checkout"", *extra_flags, rev_options.to_args())
        self.run_command(cmd_args, cwd=dest)

        self.update_submodules(dest, verbosity=verbosity)

    def update(
        self,
        dest: str,
        url: HiddenText,
        rev_options: RevOptions,
        verbosity: int = 0,
    ) -> None:
        extra_flags = []

        if verbosity <= 0:
            extra_flags.append(""-q"")

        
        if self.get_git_version() >= (1, 9):
            
            self.run_command([""fetch"", ""--tags"", *extra_flags], cwd=dest)
        else:
            self.run_command([""fetch"", *extra_flags], cwd=dest)
        
        rev_options = self.resolve_revision(dest, url, rev_options)
        cmd_args = make_command(
            ""reset"",
            ""--hard"",
            *extra_flags,
            rev_options.to_args(),
        )
        self.run_command(cmd_args, cwd=dest)
        
        self.update_submodules(dest, verbosity=verbosity)

    @classmethod
    def get_remote_url(cls, location: str) -> str:
        
        
        
        stdout = cls.run_command(
            [""config"", ""--get-regexp"", r""remote\..*\.url""],
            extra_ok_returncodes=(1,),
            show_stdout=False,
            stdout_only=True,
            cwd=location,
        )
        remotes = stdout.splitlines()
        try:
            found_remote = remotes[0]
        except IndexError:
            raise RemoteNotFoundError

        for remote in remotes:
            if remote.startswith(""remote.origin.url ""):
                found_remote = remote
                break
        url = found_remote.split("" "")[1]
        return cls._git_remote_to_pip_url(url.strip())

    @staticmethod
    def _git_remote_to_pip_url(url: str) -> str:
        
        if re.match(r""\w+://"", url):
            
            return url
        if os.path.exists(url):
            
            
            return pathlib.PurePath(url).as_uri()
        scp_match = SCP_REGEX.match(url)
        if scp_match:
            
            return scp_match.expand(r""ssh://\1\2/\3"")
        
        raise RemoteNotValidError(url)

    @classmethod
    def has_commit(cls, location: str, rev: str) -> bool:
        
        try:
            cls.run_command(
                [""rev-parse"", ""-q"", ""--verify"", ""sha^"" + rev],
                cwd=location,
                log_failed_cmd=False,
            )
        except InstallationError:
            return False
        else:
            return True

    @classmethod
    def get_revision(cls, location: str, rev: str | None = None) -> str:
        if rev is None:
            rev = ""HEAD""
        current_rev = cls.run_command(
            [""rev-parse"", rev],
            show_stdout=False,
            stdout_only=True,
            cwd=location,
        )
        return current_rev.strip()

    @classmethod
    def get_subdirectory(cls, location: str) -> str | None:
        
        
        git_dir = cls.run_command(
            [""rev-parse"", ""--git-dir""],
            show_stdout=False,
            stdout_only=True,
            cwd=location,
        ).strip()
        if not os.path.isabs(git_dir):
            git_dir = os.path.join(location, git_dir)
        repo_root = os.path.abspath(os.path.join(git_dir, ""..""))
        return find_path_to_project_root_from_repo_root(location, repo_root)

    @classmethod
    def get_url_rev_and_auth(cls, url: str) -> tuple[str, str | None, AuthInfo]:
        
        
        
        scheme, netloc, path, query, fragment = urlsplit(url)
        if scheme.endswith(""file""):
            initial_slashes = path[: -len(path.lstrip(""/""))]
            newpath = initial_slashes + urllib.request.url2pathname(path).replace(
                ""\\"", ""/""
            ).lstrip(""/"")
            after_plus = scheme.find(""+"") + 1
            url = scheme[:after_plus] + urlunsplit(
                (scheme[after_plus:], netloc, newpath, query, fragment),
            )

        if ""://"" not in url:
            assert ""file:"" not in url
            url = url.replace(""git+"", ""git+ssh://"")
            url, rev, user_pass = super().get_url_rev_and_auth(url)
            url = url.replace(""ssh://"", """")
        else:
            url, rev, user_pass = super().get_url_rev_and_auth(url)

        return url, rev, user_pass

    @classmethod
    def update_submodules(cls, location: str, verbosity: int = 0) -> None:
        argv = [""submodule"", ""update"", ""--init"", ""--recursive""]

        if verbosity <= 0:
            argv.append(""-q"")

        if not os.path.exists(os.path.join(location, "".gitmodules"")):
            return
        cls.run_command(
            argv,
            cwd=location,
        )

    @classmethod
    def get_repository_root(cls, location: str) -> str | None:
        loc = super().get_repository_root(location)
        if loc:
            return loc
        try:
            r = cls.run_command(
                [""rev-parse"", ""--show-toplevel""],
                cwd=location,
                show_stdout=False,
                stdout_only=True,
                on_returncode=""raise"",
                log_failed_cmd=False,
            )
        except BadCommand:
            logger.debug(
                ""could not determine if %s is under git control ""
                ""because git is not available"",
                location,
            )
            return None
        except InstallationError:
            return None
        return os.path.normpath(r.rstrip(""\r\n""))

    @staticmethod
    def should_add_vcs_url_prefix(repo_url: str) -> bool:
        
        return True


vcs.register(Git)

from __future__ import annotations

import configparser
import logging
import os

from pip._internal.exceptions import BadCommand, InstallationError
from pip._internal.utils.misc import HiddenText, display_path
from pip._internal.utils.subprocess import make_command
from pip._internal.utils.urls import path_to_url
from pip._internal.vcs.versioncontrol import (
    RevOptions,
    VersionControl,
    find_path_to_project_root_from_repo_root,
    vcs,
)

logger = logging.getLogger(__name__)


class Mercurial(VersionControl):
    name = ""hg""
    dirname = "".hg""
    repo_name = ""clone""
    schemes = (
        ""hg+file"",
        ""hg+http"",
        ""hg+https"",
        ""hg+ssh"",
        ""hg+static-http"",
    )

    @staticmethod
    def get_base_rev_args(rev: str) -> list[str]:
        return [f""--rev={rev}""]

    def fetch_new(
        self, dest: str, url: HiddenText, rev_options: RevOptions, verbosity: int
    ) -> None:
        rev_display = rev_options.to_display()
        logger.info(
            ""Cloning hg %s%s to %s"",
            url,
            rev_display,
            display_path(dest),
        )
        if verbosity <= 0:
            flags: tuple[str, ...] = (""--quiet"",)
        elif verbosity == 1:
            flags = ()
        elif verbosity == 2:
            flags = (""--verbose"",)
        else:
            flags = (""--verbose"", ""--debug"")
        self.run_command(make_command(""clone"", ""--noupdate"", *flags, url, dest))
        self.run_command(
            make_command(""update"", *flags, rev_options.to_args()),
            cwd=dest,
        )

    def switch(
        self,
        dest: str,
        url: HiddenText,
        rev_options: RevOptions,
        verbosity: int = 0,
    ) -> None:
        extra_flags = []
        repo_config = os.path.join(dest, self.dirname, ""hgrc"")
        config = configparser.RawConfigParser()

        if verbosity <= 0:
            extra_flags.append(""-q"")

        try:
            config.read(repo_config)
            config.set(""paths"", ""default"", url.secret)
            with open(repo_config, ""w"") as config_file:
                config.write(config_file)
        except (OSError, configparser.NoSectionError) as exc:
            logger.warning(""Could not switch Mercurial repository to %s: %s"", url, exc)
        else:
            cmd_args = make_command(""update"", *extra_flags, rev_options.to_args())
            self.run_command(cmd_args, cwd=dest)

    def update(
        self,
        dest: str,
        url: HiddenText,
        rev_options: RevOptions,
        verbosity: int = 0,
    ) -> None:
        extra_flags = []

        if verbosity <= 0:
            extra_flags.append(""-q"")

        self.run_command([""pull"", *extra_flags], cwd=dest)
        cmd_args = make_command(""update"", *extra_flags, rev_options.to_args())
        self.run_command(cmd_args, cwd=dest)

    @classmethod
    def get_remote_url(cls, location: str) -> str:
        url = cls.run_command(
            [""showconfig"", ""paths.default""],
            show_stdout=False,
            stdout_only=True,
            cwd=location,
        ).strip()
        if cls._is_local_repository(url):
            url = path_to_url(url)
        return url.strip()

    @classmethod
    def get_revision(cls, location: str) -> str:
        
        current_revision = cls.run_command(
            [""parents"", ""--template={rev}""],
            show_stdout=False,
            stdout_only=True,
            cwd=location,
        ).strip()
        return current_revision

    @classmethod
    def get_requirement_revision(cls, location: str) -> str:
        
        current_rev_hash = cls.run_command(
            [""parents"", ""--template={node}""],
            show_stdout=False,
            stdout_only=True,
            cwd=location,
        ).strip()
        return current_rev_hash

    @classmethod
    def is_commit_id_equal(cls, dest: str, name: str | None) -> bool:
        
        return False

    @classmethod
    def get_subdirectory(cls, location: str) -> str | None:
        
        
        repo_root = cls.run_command(
            [""root""], show_stdout=False, stdout_only=True, cwd=location
        ).strip()
        if not os.path.isabs(repo_root):
            repo_root = os.path.abspath(os.path.join(location, repo_root))
        return find_path_to_project_root_from_repo_root(location, repo_root)

    @classmethod
    def get_repository_root(cls, location: str) -> str | None:
        loc = super().get_repository_root(location)
        if loc:
            return loc
        try:
            r = cls.run_command(
                [""root""],
                cwd=location,
                show_stdout=False,
                stdout_only=True,
                on_returncode=""raise"",
                log_failed_cmd=False,
            )
        except BadCommand:
            logger.debug(
                ""could not determine if %s is under hg control ""
                ""because hg is not available"",
                location,
            )
            return None
        except InstallationError:
            return None
        return os.path.normpath(r.rstrip(""\r\n""))


vcs.register(Mercurial)

from __future__ import annotations

import logging
import os
import re

from pip._internal.utils.misc import (
    HiddenText,
    display_path,
    is_console_interactive,
    is_installable_dir,
    split_auth_from_netloc,
)
from pip._internal.utils.subprocess import CommandArgs, make_command
from pip._internal.vcs.versioncontrol import (
    AuthInfo,
    RemoteNotFoundError,
    RevOptions,
    VersionControl,
    vcs,
)

logger = logging.getLogger(__name__)

_svn_xml_url_re = re.compile('url=""([^""]+)""')
_svn_rev_re = re.compile(r'committed-rev=""(\d+)""')
_svn_info_xml_rev_re = re.compile(r'\s*revision=""(\d+)""')
_svn_info_xml_url_re = re.compile(r""<url>(.*)</url>"")


class Subversion(VersionControl):
    name = ""svn""
    dirname = "".svn""
    repo_name = ""checkout""
    schemes = (""svn+ssh"", ""svn+http"", ""svn+https"", ""svn+svn"", ""svn+file"")

    @classmethod
    def should_add_vcs_url_prefix(cls, remote_url: str) -> bool:
        return True

    @staticmethod
    def get_base_rev_args(rev: str) -> list[str]:
        return [""-r"", rev]

    @classmethod
    def get_revision(cls, location: str) -> str:
        
        
        revision = 0

        for base, dirs, _ in os.walk(location):
            if cls.dirname not in dirs:
                dirs[:] = []
                continue  
            dirs.remove(cls.dirname)
            entries_fn = os.path.join(base, cls.dirname, ""entries"")
            if not os.path.exists(entries_fn):
                
                continue

            dirurl, localrev = cls._get_svn_url_rev(base)

            if base == location:
                assert dirurl is not None
                base = dirurl + ""/""  
            elif not dirurl or not dirurl.startswith(base):
                dirs[:] = []
                continue  
            revision = max(revision, localrev)
        return str(revision)

    @classmethod
    def get_netloc_and_auth(
        cls, netloc: str, scheme: str
    ) -> tuple[str, tuple[str | None, str | None]]:
        
        if scheme == ""ssh"":
            
            
            return super().get_netloc_and_auth(netloc, scheme)

        return split_auth_from_netloc(netloc)

    @classmethod
    def get_url_rev_and_auth(cls, url: str) -> tuple[str, str | None, AuthInfo]:
        
        url, rev, user_pass = super().get_url_rev_and_auth(url)
        if url.startswith(""ssh://""):
            url = ""svn+"" + url
        return url, rev, user_pass

    @staticmethod
    def make_rev_args(username: str | None, password: HiddenText | None) -> CommandArgs:
        extra_args: CommandArgs = []
        if username:
            extra_args += [""--username"", username]
        if password:
            extra_args += [""--password"", password]

        return extra_args

    @classmethod
    def get_remote_url(cls, location: str) -> str:
        
        
        orig_location = location
        while not is_installable_dir(location):
            last_location = location
            location = os.path.dirname(location)
            if location == last_location:
                
                
                logger.warning(
                    ""Could not find Python project for directory %s (tried all ""
                    ""parent directories)"",
                    orig_location,
                )
                raise RemoteNotFoundError

        url, _rev = cls._get_svn_url_rev(location)
        if url is None:
            raise RemoteNotFoundError

        return url

    @classmethod
    def _get_svn_url_rev(cls, location: str) -> tuple[str | None, int]:
        from pip._internal.exceptions import InstallationError

        entries_path = os.path.join(location, cls.dirname, ""entries"")
        if os.path.exists(entries_path):
            with open(entries_path) as f:
                data = f.read()
        else:  
            data = """"

        url = None
        if data.startswith((""8"", ""9"", ""10"")):
            entries = list(map(str.splitlines, data.split(""\n\x0c\n"")))
            del entries[0][0]  
            url = entries[0][3]
            revs = [int(d[9]) for d in entries if len(d) > 9 and d[9]] + [0]
        elif data.startswith(""<?xml""):
            match = _svn_xml_url_re.search(data)
            if not match:
                raise ValueError(f""Badly formatted data: {data!r}"")
            url = match.group(1)  
            revs = [int(m.group(1)) for m in _svn_rev_re.finditer(data)] + [0]
        else:
            try:
                
                
                
                
                
                
                xml = cls.run_command(
                    [""info"", ""--xml"", location],
                    show_stdout=False,
                    stdout_only=True,
                )
                match = _svn_info_xml_url_re.search(xml)
                assert match is not None
                url = match.group(1)
                revs = [int(m.group(1)) for m in _svn_info_xml_rev_re.finditer(xml)]
            except InstallationError:
                url, revs = None, []

        if revs:
            rev = max(revs)
        else:
            rev = 0

        return url, rev

    @classmethod
    def is_commit_id_equal(cls, dest: str, name: str | None) -> bool:
        
        return False

    def __init__(self, use_interactive: bool | None = None) -> None:
        if use_interactive is None:
            use_interactive = is_console_interactive()
        self.use_interactive = use_interactive

        
        
        
        
        
        self._vcs_version: tuple[int, ...] | None = None

        super().__init__()

    def call_vcs_version(self) -> tuple[int, ...]:
        
        
        
        
        
        
        
        
        version_prefix = ""svn, version ""
        version = self.run_command([""--version""], show_stdout=False, stdout_only=True)
        if not version.startswith(version_prefix):
            return ()

        version = version[len(version_prefix) :].split()[0]
        version_list = version.partition(""-"")[0].split(""."")
        try:
            parsed_version = tuple(map(int, version_list))
        except ValueError:
            return ()

        return parsed_version

    def get_vcs_version(self) -> tuple[int, ...]:
        
        if self._vcs_version is not None:
            
            
            
            return self._vcs_version

        vcs_version = self.call_vcs_version()
        self._vcs_version = vcs_version
        return vcs_version

    def get_remote_call_options(self) -> CommandArgs:
        
        if not self.use_interactive:
            
            
            return [""--non-interactive""]

        svn_version = self.get_vcs_version()
        
        
        
        
        
        
        
        
        if svn_version >= (1, 8):
            return [""--force-interactive""]

        return []

    def fetch_new(
        self, dest: str, url: HiddenText, rev_options: RevOptions, verbosity: int
    ) -> None:
        rev_display = rev_options.to_display()
        logger.info(
            ""Checking out %s%s to %s"",
            url,
            rev_display,
            display_path(dest),
        )
        if verbosity <= 0:
            flags = [""--quiet""]
        else:
            flags = []
        cmd_args = make_command(
            ""checkout"",
            *flags,
            self.get_remote_call_options(),
            rev_options.to_args(),
            url,
            dest,
        )
        self.run_command(cmd_args)

    def switch(
        self,
        dest: str,
        url: HiddenText,
        rev_options: RevOptions,
        verbosity: int = 0,
    ) -> None:
        cmd_args = make_command(
            ""switch"",
            self.get_remote_call_options(),
            rev_options.to_args(),
            url,
            dest,
        )
        self.run_command(cmd_args)

    def update(
        self,
        dest: str,
        url: HiddenText,
        rev_options: RevOptions,
        verbosity: int = 0,
    ) -> None:
        cmd_args = make_command(
            ""update"",
            self.get_remote_call_options(),
            rev_options.to_args(),
            dest,
        )
        self.run_command(cmd_args)


vcs.register(Subversion)



from __future__ import annotations

import logging
import os
import shutil
import sys
import urllib.parse
from collections.abc import Iterable, Iterator, Mapping
from dataclasses import dataclass, field
from typing import (
    Any,
    Literal,
    Optional,
)

from pip._internal.cli.spinners import SpinnerInterface
from pip._internal.exceptions import BadCommand, InstallationError
from pip._internal.utils.misc import (
    HiddenText,
    ask_path_exists,
    backup_dir,
    display_path,
    hide_url,
    hide_value,
    is_installable_dir,
    rmtree,
)
from pip._internal.utils.subprocess import (
    CommandArgs,
    call_subprocess,
    format_command_args,
    make_command,
)

__all__ = [""vcs""]


logger = logging.getLogger(__name__)

AuthInfo = tuple[Optional[str], Optional[str]]


def is_url(name: str) -> bool:
    
    scheme = urllib.parse.urlsplit(name).scheme
    if not scheme:
        return False
    return scheme in [""http"", ""https"", ""file"", ""ftp""] + vcs.all_schemes


def make_vcs_requirement_url(
    repo_url: str, rev: str, project_name: str, subdir: str | None = None
) -> str:
    
    egg_project_name = project_name.replace(""-"", ""_"")
    req = f""{repo_url}@{rev}
    if subdir:
        req += f""&subdirectory={subdir}""

    return req


def find_path_to_project_root_from_repo_root(
    location: str, repo_root: str
) -> str | None:
    
    
    orig_location = location
    while not is_installable_dir(location):
        last_location = location
        location = os.path.dirname(location)
        if location == last_location:
            
            
            logger.warning(
                ""Could not find a Python project for directory %s (tried all ""
                ""parent directories)"",
                orig_location,
            )
            return None

    if os.path.samefile(repo_root, location):
        return None

    return os.path.relpath(location, repo_root)


class RemoteNotFoundError(Exception):
    pass


class RemoteNotValidError(Exception):
    def __init__(self, url: str):
        super().__init__(url)
        self.url = url


@dataclass(frozen=True)
class RevOptions:
    

    vc_class: type[VersionControl]
    rev: str | None = None
    extra_args: CommandArgs = field(default_factory=list)
    branch_name: str | None = None

    def __repr__(self) -> str:
        return f""<RevOptions {self.vc_class.name}: rev={self.rev!r}>""

    @property
    def arg_rev(self) -> str | None:
        if self.rev is None:
            return self.vc_class.default_arg_rev

        return self.rev

    def to_args(self) -> CommandArgs:
        
        args: CommandArgs = []
        rev = self.arg_rev
        if rev is not None:
            args += self.vc_class.get_base_rev_args(rev)
        args += self.extra_args

        return args

    def to_display(self) -> str:
        if not self.rev:
            return """"

        return f"" (to revision {self.rev})""

    def make_new(self, rev: str) -> RevOptions:
        
        return self.vc_class.make_rev_options(rev, extra_args=self.extra_args)


class VcsSupport:
    _registry: dict[str, VersionControl] = {}
    schemes = [""ssh"", ""git"", ""hg"", ""bzr"", ""sftp"", ""svn""]

    def __init__(self) -> None:
        
        
        urllib.parse.uses_netloc.extend(self.schemes)
        super().__init__()

    def __iter__(self) -> Iterator[str]:
        return self._registry.__iter__()

    @property
    def backends(self) -> list[VersionControl]:
        return list(self._registry.values())

    @property
    def dirnames(self) -> list[str]:
        return [backend.dirname for backend in self.backends]

    @property
    def all_schemes(self) -> list[str]:
        schemes: list[str] = []
        for backend in self.backends:
            schemes.extend(backend.schemes)
        return schemes

    def register(self, cls: type[VersionControl]) -> None:
        if not hasattr(cls, ""name""):
            logger.warning(""Cannot register VCS %s"", cls.__name__)
            return
        if cls.name not in self._registry:
            self._registry[cls.name] = cls()
            logger.debug(""Registered VCS backend: %s"", cls.name)

    def unregister(self, name: str) -> None:
        if name in self._registry:
            del self._registry[name]

    def get_backend_for_dir(self, location: str) -> VersionControl | None:
        
        vcs_backends = {}
        for vcs_backend in self._registry.values():
            repo_path = vcs_backend.get_repository_root(location)
            if not repo_path:
                continue
            logger.debug(""Determine that %s uses VCS: %s"", location, vcs_backend.name)
            vcs_backends[repo_path] = vcs_backend

        if not vcs_backends:
            return None

        
        
        
        
        inner_most_repo_path = max(vcs_backends, key=len)
        return vcs_backends[inner_most_repo_path]

    def get_backend_for_scheme(self, scheme: str) -> VersionControl | None:
        
        for vcs_backend in self._registry.values():
            if scheme in vcs_backend.schemes:
                return vcs_backend
        return None

    def get_backend(self, name: str) -> VersionControl | None:
        
        name = name.lower()
        return self._registry.get(name)


vcs = VcsSupport()


class VersionControl:
    name = """"
    dirname = """"
    repo_name = """"
    
    schemes: tuple[str, ...] = ()
    
    unset_environ: tuple[str, ...] = ()
    default_arg_rev: str | None = None

    @classmethod
    def should_add_vcs_url_prefix(cls, remote_url: str) -> bool:
        
        return not remote_url.lower().startswith(f""{cls.name}:"")

    @classmethod
    def get_subdirectory(cls, location: str) -> str | None:
        
        return None

    @classmethod
    def get_requirement_revision(cls, repo_dir: str) -> str:
        
        return cls.get_revision(repo_dir)

    @classmethod
    def get_src_requirement(cls, repo_dir: str, project_name: str) -> str:
        
        repo_url = cls.get_remote_url(repo_dir)

        if cls.should_add_vcs_url_prefix(repo_url):
            repo_url = f""{cls.name}+{repo_url}""

        revision = cls.get_requirement_revision(repo_dir)
        subdir = cls.get_subdirectory(repo_dir)
        req = make_vcs_requirement_url(repo_url, revision, project_name, subdir=subdir)

        return req

    @staticmethod
    def get_base_rev_args(rev: str) -> list[str]:
        
        raise NotImplementedError

    def is_immutable_rev_checkout(self, url: str, dest: str) -> bool:
        
        return False

    @classmethod
    def make_rev_options(
        cls, rev: str | None = None, extra_args: CommandArgs | None = None
    ) -> RevOptions:
        
        return RevOptions(cls, rev, extra_args=extra_args or [])

    @classmethod
    def _is_local_repository(cls, repo: str) -> bool:
        
        drive, tail = os.path.splitdrive(repo)
        return repo.startswith(os.path.sep) or bool(drive)

    @classmethod
    def get_netloc_and_auth(
        cls, netloc: str, scheme: str
    ) -> tuple[str, tuple[str | None, str | None]]:
        
        return netloc, (None, None)

    @classmethod
    def get_url_rev_and_auth(cls, url: str) -> tuple[str, str | None, AuthInfo]:
        
        scheme, netloc, path, query, frag = urllib.parse.urlsplit(url)
        if ""+"" not in scheme:
            raise ValueError(
                f""Sorry, {url!r} is a malformed VCS url. ""
                ""The format is <vcs>+<protocol>://<url>, ""
                ""e.g. svn+http://myrepo/svn/MyApp
            )
        
        scheme = scheme.split(""+"", 1)[1]
        netloc, user_pass = cls.get_netloc_and_auth(netloc, scheme)
        rev = None
        if ""@"" in path:
            path, rev = path.rsplit(""@"", 1)
            if not rev:
                raise InstallationError(
                    f""The URL {url!r} has an empty revision (after @) ""
                    ""which is not supported. Include a revision after @ ""
                    ""or remove @ from the URL.""
                )
        url = urllib.parse.urlunsplit((scheme, netloc, path, query, """"))
        return url, rev, user_pass

    @staticmethod
    def make_rev_args(username: str | None, password: HiddenText | None) -> CommandArgs:
        
        return []

    def get_url_rev_options(self, url: HiddenText) -> tuple[HiddenText, RevOptions]:
        
        secret_url, rev, user_pass = self.get_url_rev_and_auth(url.secret)
        username, secret_password = user_pass
        password: HiddenText | None = None
        if secret_password is not None:
            password = hide_value(secret_password)
        extra_args = self.make_rev_args(username, password)
        rev_options = self.make_rev_options(rev, extra_args=extra_args)

        return hide_url(secret_url), rev_options

    @staticmethod
    def normalize_url(url: str) -> str:
        
        return urllib.parse.unquote(url).rstrip(""/"")

    @classmethod
    def compare_urls(cls, url1: str, url2: str) -> bool:
        
        return cls.normalize_url(url1) == cls.normalize_url(url2)

    def fetch_new(
        self, dest: str, url: HiddenText, rev_options: RevOptions, verbosity: int
    ) -> None:
        
        raise NotImplementedError

    def switch(
        self,
        dest: str,
        url: HiddenText,
        rev_options: RevOptions,
        verbosity: int = 0,
    ) -> None:
        
        raise NotImplementedError

    def update(
        self,
        dest: str,
        url: HiddenText,
        rev_options: RevOptions,
        verbosity: int = 0,
    ) -> None:
        
        raise NotImplementedError

    @classmethod
    def is_commit_id_equal(cls, dest: str, name: str | None) -> bool:
        
        raise NotImplementedError

    def obtain(self, dest: str, url: HiddenText, verbosity: int) -> None:
        
        url, rev_options = self.get_url_rev_options(url)

        if not os.path.exists(dest):
            self.fetch_new(dest, url, rev_options, verbosity=verbosity)
            return

        rev_display = rev_options.to_display()
        if self.is_repository_directory(dest):
            existing_url = self.get_remote_url(dest)
            if self.compare_urls(existing_url, url.secret):
                logger.debug(
                    ""%s in %s exists, and has correct URL (%s)"",
                    self.repo_name.title(),
                    display_path(dest),
                    url,
                )
                if not self.is_commit_id_equal(dest, rev_options.rev):
                    logger.info(
                        ""Updating %s %s%s"",
                        display_path(dest),
                        self.repo_name,
                        rev_display,
                    )
                    self.update(dest, url, rev_options, verbosity=verbosity)
                else:
                    logger.info(""Skipping because already up-to-date."")
                return

            logger.warning(
                ""%s %s in %s exists with URL %s"",
                self.name,
                self.repo_name,
                display_path(dest),
                existing_url,
            )
            prompt = (""(s)witch, (i)gnore, (w)ipe, (b)ackup "", (""s"", ""i"", ""w"", ""b""))
        else:
            logger.warning(
                ""Directory %s already exists, and is not a %s %s."",
                dest,
                self.name,
                self.repo_name,
            )
            
            prompt = (""(i)gnore, (w)ipe, (b)ackup "", (""i"", ""w"", ""b""))  

        logger.warning(
            ""The plan is to install the %s repository %s"",
            self.name,
            url,
        )
        response = ask_path_exists(f""What to do?  {prompt[0]}"", prompt[1])

        if response == ""a"":
            sys.exit(-1)

        if response == ""w"":
            logger.warning(""Deleting %s"", display_path(dest))
            rmtree(dest)
            self.fetch_new(dest, url, rev_options, verbosity=verbosity)
            return

        if response == ""b"":
            dest_dir = backup_dir(dest)
            logger.warning(""Backing up %s to %s"", display_path(dest), dest_dir)
            shutil.move(dest, dest_dir)
            self.fetch_new(dest, url, rev_options, verbosity=verbosity)
            return

        
        if response == ""s"":
            logger.info(
                ""Switching %s %s to %s%s"",
                self.repo_name,
                display_path(dest),
                url,
                rev_display,
            )
            self.switch(dest, url, rev_options, verbosity=verbosity)

    def unpack(self, location: str, url: HiddenText, verbosity: int) -> None:
        
        if os.path.exists(location):
            rmtree(location)
        self.obtain(location, url=url, verbosity=verbosity)

    @classmethod
    def get_remote_url(cls, location: str) -> str:
        
        raise NotImplementedError

    @classmethod
    def get_revision(cls, location: str) -> str:
        
        raise NotImplementedError

    @classmethod
    def run_command(
        cls,
        cmd: list[str] | CommandArgs,
        show_stdout: bool = True,
        cwd: str | None = None,
        on_returncode: Literal[""raise"", ""warn"", ""ignore""] = ""raise"",
        extra_ok_returncodes: Iterable[int] | None = None,
        command_desc: str | None = None,
        extra_environ: Mapping[str, Any] | None = None,
        spinner: SpinnerInterface | None = None,
        log_failed_cmd: bool = True,
        stdout_only: bool = False,
    ) -> str:
        
        cmd = make_command(cls.name, *cmd)
        if command_desc is None:
            command_desc = format_command_args(cmd)
        try:
            return call_subprocess(
                cmd,
                show_stdout,
                cwd,
                on_returncode=on_returncode,
                extra_ok_returncodes=extra_ok_returncodes,
                command_desc=command_desc,
                extra_environ=extra_environ,
                unset_environ=cls.unset_environ,
                spinner=spinner,
                log_failed_cmd=log_failed_cmd,
                stdout_only=stdout_only,
            )
        except NotADirectoryError:
            raise BadCommand(f""Cannot find command {cls.name!r} - invalid PATH"")
        except FileNotFoundError:
            
            
            raise BadCommand(
                f""Cannot find command {cls.name!r} - do you have ""
                f""{cls.name!r} installed and in your PATH?""
            )
        except PermissionError:
            
            
            
            
            raise BadCommand(
                f""No permission to execute {cls.name!r} - install it ""
                f""locally, globally (ask admin), or check your PATH. ""
                f""See possible solutions at ""
                f""https://pip.pypa.io/en/latest/reference/pip_freeze/""
                f""
            )

    @classmethod
    def is_repository_directory(cls, path: str) -> bool:
        
        logger.debug(""Checking in %s for %s (%s)..."", path, cls.dirname, cls.name)
        return os.path.exists(os.path.join(path, cls.dirname))

    @classmethod
    def get_repository_root(cls, location: str) -> str | None:
        
        if cls.is_repository_directory(location):
            return location
        return None





import pip._internal.vcs.bazaar
import pip._internal.vcs.git
import pip._internal.vcs.mercurial
import pip._internal.vcs.subversion  
from pip._internal.vcs.versioncontrol import (  
    RemoteNotFoundError,
    RemoteNotValidError,
    is_url,
    make_vcs_requirement_url,
    vcs,
)


from __future__ import absolute_import

import glob
import os.path
import sys




DEBUNDLED = False





WHEEL_DIR = os.path.abspath(os.path.dirname(__file__))





def vendored(modulename):
    vendored_name = ""{0}.{1}"".format(__name__, modulename)

    try:
        __import__(modulename, globals(), locals(), level=0)
    except ImportError:
        
        
        
        
        
        
        
        
        pass
    else:
        sys.modules[vendored_name] = sys.modules[modulename]
        base, head = vendored_name.rsplit(""."", 1)
        setattr(sys.modules[base], head, sys.modules[modulename])







if DEBUNDLED:
    
    
    sys.path[:] = glob.glob(os.path.join(WHEEL_DIR, ""*.whl"")) + sys.path

    
    vendored(""cachecontrol"")
    vendored(""certifi"")
    vendored(""dependency-groups"")
    vendored(""distlib"")
    vendored(""distro"")
    vendored(""packaging"")
    vendored(""packaging.version"")
    vendored(""packaging.specifiers"")
    vendored(""pkg_resources"")
    vendored(""platformdirs"")
    vendored(""progress"")
    vendored(""pyproject_hooks"")
    vendored(""requests"")
    vendored(""requests.exceptions"")
    vendored(""requests.packages"")
    vendored(""requests.packages.urllib3"")
    vendored(""requests.packages.urllib3._collections"")
    vendored(""requests.packages.urllib3.connection"")
    vendored(""requests.packages.urllib3.connectionpool"")
    vendored(""requests.packages.urllib3.contrib"")
    vendored(""requests.packages.urllib3.contrib.ntlmpool"")
    vendored(""requests.packages.urllib3.contrib.pyopenssl"")
    vendored(""requests.packages.urllib3.exceptions"")
    vendored(""requests.packages.urllib3.fields"")
    vendored(""requests.packages.urllib3.filepost"")
    vendored(""requests.packages.urllib3.packages"")
    vendored(""requests.packages.urllib3.packages.ordered_dict"")
    vendored(""requests.packages.urllib3.packages.six"")
    vendored(""requests.packages.urllib3.packages.ssl_match_hostname"")
    vendored(""requests.packages.urllib3.packages.ssl_match_hostname.""
             ""_implementation"")
    vendored(""requests.packages.urllib3.poolmanager"")
    vendored(""requests.packages.urllib3.request"")
    vendored(""requests.packages.urllib3.response"")
    vendored(""requests.packages.urllib3.util"")
    vendored(""requests.packages.urllib3.util.connection"")
    vendored(""requests.packages.urllib3.util.request"")
    vendored(""requests.packages.urllib3.util.response"")
    vendored(""requests.packages.urllib3.util.retry"")
    vendored(""requests.packages.urllib3.util.ssl_"")
    vendored(""requests.packages.urllib3.util.timeout"")
    vendored(""requests.packages.urllib3.util.url"")
    vendored(""resolvelib"")
    vendored(""rich"")
    vendored(""rich.console"")
    vendored(""rich.highlighter"")
    vendored(""rich.logging"")
    vendored(""rich.markup"")
    vendored(""rich.progress"")
    vendored(""rich.segment"")
    vendored(""rich.style"")
    vendored(""rich.text"")
    vendored(""rich.traceback"")
    if sys.version_info < (3, 11):
        vendored(""tomli"")
    vendored(""truststore"")
    vendored(""urllib3"")




from __future__ import annotations

import functools
import types
import weakref
import zlib
from typing import TYPE_CHECKING, Any, Collection, Mapping

from pip._vendor.requests.adapters import HTTPAdapter

from pip._vendor.cachecontrol.cache import DictCache
from pip._vendor.cachecontrol.controller import PERMANENT_REDIRECT_STATUSES, CacheController
from pip._vendor.cachecontrol.filewrapper import CallbackFileWrapper

if TYPE_CHECKING:
    from pip._vendor.requests import PreparedRequest, Response
    from pip._vendor.urllib3 import HTTPResponse

    from pip._vendor.cachecontrol.cache import BaseCache
    from pip._vendor.cachecontrol.heuristics import BaseHeuristic
    from pip._vendor.cachecontrol.serialize import Serializer


class CacheControlAdapter(HTTPAdapter):
    invalidating_methods = {""PUT"", ""PATCH"", ""DELETE""}

    def __init__(
        self,
        cache: BaseCache | None = None,
        cache_etags: bool = True,
        controller_class: type[CacheController] | None = None,
        serializer: Serializer | None = None,
        heuristic: BaseHeuristic | None = None,
        cacheable_methods: Collection[str] | None = None,
        *args: Any,
        **kw: Any,
    ) -> None:
        super().__init__(*args, **kw)
        self.cache = DictCache() if cache is None else cache
        self.heuristic = heuristic
        self.cacheable_methods = cacheable_methods or (""GET"",)

        controller_factory = controller_class or CacheController
        self.controller = controller_factory(
            self.cache, cache_etags=cache_etags, serializer=serializer
        )

    def send(
        self,
        request: PreparedRequest,
        stream: bool = False,
        timeout: None | float | tuple[float, float] | tuple[float, None] = None,
        verify: bool | str = True,
        cert: (None | bytes | str | tuple[bytes | str, bytes | str]) = None,
        proxies: Mapping[str, str] | None = None,
        cacheable_methods: Collection[str] | None = None,
    ) -> Response:
        
        cacheable = cacheable_methods or self.cacheable_methods
        if request.method in cacheable:
            try:
                cached_response = self.controller.cached_request(request)
            except zlib.error:
                cached_response = None
            if cached_response:
                return self.build_response(request, cached_response, from_cache=True)

            
            request.headers.update(self.controller.conditional_headers(request))

        resp = super().send(request, stream, timeout, verify, cert, proxies)

        return resp

    def build_response(  
        self,
        request: PreparedRequest,
        response: HTTPResponse,
        from_cache: bool = False,
        cacheable_methods: Collection[str] | None = None,
    ) -> Response:
        
        cacheable = cacheable_methods or self.cacheable_methods
        if not from_cache and request.method in cacheable:
            
            
            if self.heuristic:
                response = self.heuristic.apply(response)

            
            if response.status == 304:
                
                
                
                
                cached_response = self.controller.update_cached_response(
                    request, response
                )

                if cached_response is not response:
                    from_cache = True

                
                
                
                
                response.read(decode_content=False)
                response.release_conn()

                response = cached_response

            
            elif int(response.status) in PERMANENT_REDIRECT_STATUSES:
                self.controller.cache_response(request, response)
            else:
                
                
                response._fp = CallbackFileWrapper(  
                    response._fp,  
                    functools.partial(
                        self.controller.cache_response, request, weakref.ref(response)
                    ),
                )
                if response.chunked:
                    super_update_chunk_length = response.__class__._update_chunk_length

                    def _update_chunk_length(
                        weak_self: weakref.ReferenceType[HTTPResponse],
                    ) -> None:
                        self = weak_self()
                        if self is None:
                            return

                        super_update_chunk_length(self)
                        if self.chunk_left == 0:
                            self._fp._close()  

                    response._update_chunk_length = functools.partial(  
                        _update_chunk_length, weakref.ref(response)
                    )

        resp: Response = super().build_response(request, response)

        
        if request.method in self.invalidating_methods and resp.ok:
            assert request.url is not None
            cache_url = self.controller.cache_url(request.url)
            self.cache.delete(cache_url)

        
        resp.from_cache = from_cache  

        return resp

    def close(self) -> None:
        self.cache.close()
        super().close()  







from __future__ import annotations

from threading import Lock
from typing import IO, TYPE_CHECKING, MutableMapping

if TYPE_CHECKING:
    from datetime import datetime


class BaseCache:
    def get(self, key: str) -> bytes | None:
        raise NotImplementedError()

    def set(
        self, key: str, value: bytes, expires: int | datetime | None = None
    ) -> None:
        raise NotImplementedError()

    def delete(self, key: str) -> None:
        raise NotImplementedError()

    def close(self) -> None:
        pass


class DictCache(BaseCache):
    def __init__(self, init_dict: MutableMapping[str, bytes] | None = None) -> None:
        self.lock = Lock()
        self.data = init_dict or {}

    def get(self, key: str) -> bytes | None:
        return self.data.get(key, None)

    def set(
        self, key: str, value: bytes, expires: int | datetime | None = None
    ) -> None:
        with self.lock:
            self.data.update({key: value})

    def delete(self, key: str) -> None:
        with self.lock:
            if key in self.data:
                self.data.pop(key)


class SeparateBodyBaseCache(BaseCache):
    

    def set_body(self, key: str, body: bytes) -> None:
        raise NotImplementedError()

    def get_body(self, key: str) -> IO[bytes] | None:
        
        raise NotImplementedError()







from __future__ import annotations

import calendar
import logging
import re
import time
import weakref
from email.utils import parsedate_tz
from typing import TYPE_CHECKING, Collection, Mapping

from pip._vendor.requests.structures import CaseInsensitiveDict

from pip._vendor.cachecontrol.cache import DictCache, SeparateBodyBaseCache
from pip._vendor.cachecontrol.serialize import Serializer

if TYPE_CHECKING:
    from typing import Literal

    from pip._vendor.requests import PreparedRequest
    from pip._vendor.urllib3 import HTTPResponse

    from pip._vendor.cachecontrol.cache import BaseCache

logger = logging.getLogger(__name__)

URI = re.compile(r""^(([^:/?

PERMANENT_REDIRECT_STATUSES = (301, 308)


def parse_uri(uri: str) -> tuple[str, str, str, str, str]:
    
    match = URI.match(uri)
    assert match is not None
    groups = match.groups()
    return (groups[1], groups[3], groups[4], groups[6], groups[8])


class CacheController:
    

    def __init__(
        self,
        cache: BaseCache | None = None,
        cache_etags: bool = True,
        serializer: Serializer | None = None,
        status_codes: Collection[int] | None = None,
    ):
        self.cache = DictCache() if cache is None else cache
        self.cache_etags = cache_etags
        self.serializer = serializer or Serializer()
        self.cacheable_status_codes = status_codes or (200, 203, 300, 301, 308)

    @classmethod
    def _urlnorm(cls, uri: str) -> str:
        
        (scheme, authority, path, query, fragment) = parse_uri(uri)
        if not scheme or not authority:
            raise Exception(""Only absolute URIs are allowed. uri = %s"" % uri)

        scheme = scheme.lower()
        authority = authority.lower()

        if not path:
            path = ""/""

        
        
        request_uri = query and ""?"".join([path, query]) or path
        defrag_uri = scheme + ""://"" + authority + request_uri

        return defrag_uri

    @classmethod
    def cache_url(cls, uri: str) -> str:
        return cls._urlnorm(uri)

    def parse_cache_control(self, headers: Mapping[str, str]) -> dict[str, int | None]:
        known_directives = {
            
            ""max-age"": (int, True),
            ""max-stale"": (int, False),
            ""min-fresh"": (int, True),
            ""no-cache"": (None, False),
            ""no-store"": (None, False),
            ""no-transform"": (None, False),
            ""only-if-cached"": (None, False),
            ""must-revalidate"": (None, False),
            ""public"": (None, False),
            ""private"": (None, False),
            ""proxy-revalidate"": (None, False),
            ""s-maxage"": (int, True),
        }

        cc_headers = headers.get(""cache-control"", headers.get(""Cache-Control"", """"))

        retval: dict[str, int | None] = {}

        for cc_directive in cc_headers.split("",""):
            if not cc_directive.strip():
                continue

            parts = cc_directive.split(""="", 1)
            directive = parts[0].strip()

            try:
                typ, required = known_directives[directive]
            except KeyError:
                logger.debug(""Ignoring unknown cache-control directive: %s"", directive)
                continue

            if not typ or not required:
                retval[directive] = None
            if typ:
                try:
                    retval[directive] = typ(parts[1].strip())
                except IndexError:
                    if required:
                        logger.debug(
                            ""Missing value for cache-control "" ""directive: %s"",
                            directive,
                        )
                except ValueError:
                    logger.debug(
                        ""Invalid value for cache-control directive "" ""%s, must be %s"",
                        directive,
                        typ.__name__,
                    )

        return retval

    def _load_from_cache(self, request: PreparedRequest) -> HTTPResponse | None:
        
        
        
        if ""Range"" in request.headers:
            return None

        cache_url = request.url
        assert cache_url is not None
        cache_data = self.cache.get(cache_url)
        if cache_data is None:
            logger.debug(""No cache entry available"")
            return None

        if isinstance(self.cache, SeparateBodyBaseCache):
            body_file = self.cache.get_body(cache_url)
        else:
            body_file = None

        result = self.serializer.loads(request, cache_data, body_file)
        if result is None:
            logger.warning(""Cache entry deserialization failed, entry ignored"")
        return result

    def cached_request(self, request: PreparedRequest) -> HTTPResponse | Literal[False]:
        
        assert request.url is not None
        cache_url = self.cache_url(request.url)
        logger.debug('Looking up ""%s"" in the cache', cache_url)
        cc = self.parse_cache_control(request.headers)

        
        if ""no-cache"" in cc:
            logger.debug('Request header has ""no-cache"", cache bypassed')
            return False

        if ""max-age"" in cc and cc[""max-age""] == 0:
            logger.debug('Request header has ""max_age"" as 0, cache bypassed')
            return False

        
        resp = self._load_from_cache(request)
        if not resp:
            return False

        
        
        
        
        
        
        
        
        
        if int(resp.status) in PERMANENT_REDIRECT_STATUSES:
            msg = (
                ""Returning cached permanent redirect response ""
                ""(ignoring date and etag information)""
            )
            logger.debug(msg)
            return resp

        headers: CaseInsensitiveDict[str] = CaseInsensitiveDict(resp.headers)
        if not headers or ""date"" not in headers:
            if ""etag"" not in headers:
                
                
                logger.debug(""Purging cached response: no date or etag"")
                self.cache.delete(cache_url)
            logger.debug(""Ignoring cached response: no date"")
            return False

        now = time.time()
        time_tuple = parsedate_tz(headers[""date""])
        assert time_tuple is not None
        date = calendar.timegm(time_tuple[:6])
        current_age = max(0, now - date)
        logger.debug(""Current age based on date: %i"", current_age)

        
        
        
        
        resp_cc = self.parse_cache_control(headers)

        
        freshness_lifetime = 0

        
        max_age = resp_cc.get(""max-age"")
        if max_age is not None:
            freshness_lifetime = max_age
            logger.debug(""Freshness lifetime from max-age: %i"", freshness_lifetime)

        
        elif ""expires"" in headers:
            expires = parsedate_tz(headers[""expires""])
            if expires is not None:
                expire_time = calendar.timegm(expires[:6]) - date
                freshness_lifetime = max(0, expire_time)
                logger.debug(""Freshness lifetime from expires: %i"", freshness_lifetime)

        
        
        max_age = cc.get(""max-age"")
        if max_age is not None:
            freshness_lifetime = max_age
            logger.debug(
                ""Freshness lifetime from request max-age: %i"", freshness_lifetime
            )

        min_fresh = cc.get(""min-fresh"")
        if min_fresh is not None:
            
            current_age += min_fresh
            logger.debug(""Adjusted current age from min-fresh: %i"", current_age)

        
        if freshness_lifetime > current_age:
            logger.debug('The response is ""fresh"", returning cached response')
            logger.debug(""%i > %i"", freshness_lifetime, current_age)
            return resp

        
        if ""etag"" not in headers:
            logger.debug('The cached response is ""stale"" with no etag, purging')
            self.cache.delete(cache_url)

        
        return False

    def conditional_headers(self, request: PreparedRequest) -> dict[str, str]:
        resp = self._load_from_cache(request)
        new_headers = {}

        if resp:
            headers: CaseInsensitiveDict[str] = CaseInsensitiveDict(resp.headers)

            if ""etag"" in headers:
                new_headers[""If-None-Match""] = headers[""ETag""]

            if ""last-modified"" in headers:
                new_headers[""If-Modified-Since""] = headers[""Last-Modified""]

        return new_headers

    def _cache_set(
        self,
        cache_url: str,
        request: PreparedRequest,
        response: HTTPResponse,
        body: bytes | None = None,
        expires_time: int | None = None,
    ) -> None:
        
        if isinstance(self.cache, SeparateBodyBaseCache):
            
            
            self.cache.set(
                cache_url,
                self.serializer.dumps(request, response, b""""),
                expires=expires_time,
            )
            
            
            if body is not None:
                self.cache.set_body(cache_url, body)
        else:
            self.cache.set(
                cache_url,
                self.serializer.dumps(request, response, body),
                expires=expires_time,
            )

    def cache_response(
        self,
        request: PreparedRequest,
        response_or_ref: HTTPResponse | weakref.ReferenceType[HTTPResponse],
        body: bytes | None = None,
        status_codes: Collection[int] | None = None,
    ) -> None:
        
        if isinstance(response_or_ref, weakref.ReferenceType):
            response = response_or_ref()
            if response is None:
                
                
                
                return
        else:
            response = response_or_ref

        
        
        cacheable_status_codes = status_codes or self.cacheable_status_codes
        if response.status not in cacheable_status_codes:
            logger.debug(
                ""Status code %s not in %s"", response.status, cacheable_status_codes
            )
            return

        response_headers: CaseInsensitiveDict[str] = CaseInsensitiveDict(
            response.headers
        )

        if ""date"" in response_headers:
            time_tuple = parsedate_tz(response_headers[""date""])
            assert time_tuple is not None
            date = calendar.timegm(time_tuple[:6])
        else:
            date = 0

        
        
        
        
        if (
            body is not None
            and ""content-length"" in response_headers
            and response_headers[""content-length""].isdigit()
            and int(response_headers[""content-length""]) != len(body)
        ):
            return

        cc_req = self.parse_cache_control(request.headers)
        cc = self.parse_cache_control(response_headers)

        assert request.url is not None
        cache_url = self.cache_url(request.url)
        logger.debug('Updating cache with response from ""%s""', cache_url)

        
        no_store = False
        if ""no-store"" in cc:
            no_store = True
            logger.debug('Response header has ""no-store""')
        if ""no-store"" in cc_req:
            no_store = True
            logger.debug('Request header has ""no-store""')
        if no_store and self.cache.get(cache_url):
            logger.debug('Purging existing cache entry to honor ""no-store""')
            self.cache.delete(cache_url)
        if no_store:
            return

        
        
        
        
        
        if ""*"" in response_headers.get(""vary"", """"):
            logger.debug('Response header has ""Vary: *""')
            return

        
        if self.cache_etags and ""etag"" in response_headers:
            expires_time = 0
            if response_headers.get(""expires""):
                expires = parsedate_tz(response_headers[""expires""])
                if expires is not None:
                    expires_time = calendar.timegm(expires[:6]) - date

            expires_time = max(expires_time, 14 * 86400)

            logger.debug(f""etag object cached for {expires_time} seconds"")
            logger.debug(""Caching due to etag"")
            self._cache_set(cache_url, request, response, body, expires_time)

        
        
        elif int(response.status) in PERMANENT_REDIRECT_STATUSES:
            logger.debug(""Caching permanent redirect"")
            self._cache_set(cache_url, request, response, b"""")

        
        
        
        elif ""date"" in response_headers:
            time_tuple = parsedate_tz(response_headers[""date""])
            assert time_tuple is not None
            date = calendar.timegm(time_tuple[:6])
            
            max_age = cc.get(""max-age"")
            if max_age is not None and max_age > 0:
                logger.debug(""Caching b/c date exists and max-age > 0"")
                expires_time = max_age
                self._cache_set(
                    cache_url,
                    request,
                    response,
                    body,
                    expires_time,
                )

            
            
            elif ""expires"" in response_headers:
                if response_headers[""expires""]:
                    expires = parsedate_tz(response_headers[""expires""])
                    if expires is not None:
                        expires_time = calendar.timegm(expires[:6]) - date
                    else:
                        expires_time = None

                    logger.debug(
                        ""Caching b/c of expires header. expires in {} seconds"".format(
                            expires_time
                        )
                    )
                    self._cache_set(
                        cache_url,
                        request,
                        response,
                        body,
                        expires_time,
                    )

    def update_cached_response(
        self, request: PreparedRequest, response: HTTPResponse
    ) -> HTTPResponse:
        
        assert request.url is not None
        cache_url = self.cache_url(request.url)
        cached_response = self._load_from_cache(request)

        if not cached_response:
            
            return response

        
        
        
        
        
        
        
        excluded_headers = [""content-length""]

        cached_response.headers.update(
            {
                k: v
                for k, v in response.headers.items()
                if k.lower() not in excluded_headers
            }
        )

        
        cached_response.status = 200

        
        self._cache_set(cache_url, request, cached_response)

        return cached_response




from __future__ import annotations

import mmap
from tempfile import NamedTemporaryFile
from typing import TYPE_CHECKING, Any, Callable

if TYPE_CHECKING:
    from http.client import HTTPResponse


class CallbackFileWrapper:
    

    def __init__(
        self, fp: HTTPResponse, callback: Callable[[bytes], None] | None
    ) -> None:
        self.__buf = NamedTemporaryFile(""rb+"", delete=True)
        self.__fp = fp
        self.__callback = callback

    def __getattr__(self, name: str) -> Any:
        
        
        
        
        
        
        
        
        fp = self.__getattribute__(""_CallbackFileWrapper__fp"")
        return getattr(fp, name)

    def __is_fp_closed(self) -> bool:
        try:
            return self.__fp.fp is None

        except AttributeError:
            pass

        try:
            closed: bool = self.__fp.closed
            return closed

        except AttributeError:
            pass

        
        
        return False

    def _close(self) -> None:
        if self.__callback:
            if self.__buf.tell() == 0:
                
                result = b""""
            else:
                
                
                
                
                self.__buf.seek(0, 0)
                result = memoryview(
                    mmap.mmap(self.__buf.fileno(), 0, access=mmap.ACCESS_READ)
                )
            self.__callback(result)

        
        
        
        
        
        self.__callback = None

        
        
        self.__buf.close()

    def read(self, amt: int | None = None) -> bytes:
        data: bytes = self.__fp.read(amt)
        if data:
            
            
            self.__buf.write(data)
        if self.__is_fp_closed():
            self._close()

        return data

    def _safe_read(self, amt: int) -> bytes:
        data: bytes = self.__fp._safe_read(amt)  
        if amt == 2 and data == b""\r\n"":
            
            
            return data

        self.__buf.write(data)
        if self.__is_fp_closed():
            self._close()

        return data




from __future__ import annotations

import calendar
import time
from datetime import datetime, timedelta, timezone
from email.utils import formatdate, parsedate, parsedate_tz
from typing import TYPE_CHECKING, Any, Mapping

if TYPE_CHECKING:
    from pip._vendor.urllib3 import HTTPResponse

TIME_FMT = ""%a, %d %b %Y %H:%M:%S GMT""


def expire_after(delta: timedelta, date: datetime | None = None) -> datetime:
    date = date or datetime.now(timezone.utc)
    return date + delta


def datetime_to_header(dt: datetime) -> str:
    return formatdate(calendar.timegm(dt.timetuple()))


class BaseHeuristic:
    def warning(self, response: HTTPResponse) -> str | None:
        
        return '110 - ""Response is Stale""'

    def update_headers(self, response: HTTPResponse) -> dict[str, str]:
        
        return {}

    def apply(self, response: HTTPResponse) -> HTTPResponse:
        updated_headers = self.update_headers(response)

        if updated_headers:
            response.headers.update(updated_headers)
            warning_header_value = self.warning(response)
            if warning_header_value is not None:
                response.headers.update({""Warning"": warning_header_value})

        return response


class OneDayCache(BaseHeuristic):
    

    def update_headers(self, response: HTTPResponse) -> dict[str, str]:
        headers = {}

        if ""expires"" not in response.headers:
            date = parsedate(response.headers[""date""])
            expires = expire_after(
                timedelta(days=1),
                date=datetime(*date[:6], tzinfo=timezone.utc),  
            )
            headers[""expires""] = datetime_to_header(expires)
            headers[""cache-control""] = ""public""
        return headers


class ExpiresAfter(BaseHeuristic):
    

    def __init__(self, **kw: Any) -> None:
        self.delta = timedelta(**kw)

    def update_headers(self, response: HTTPResponse) -> dict[str, str]:
        expires = expire_after(self.delta)
        return {""expires"": datetime_to_header(expires), ""cache-control"": ""public""}

    def warning(self, response: HTTPResponse) -> str | None:
        tmpl = ""110 - Automatically cached for %s. Response might be stale""
        return tmpl % self.delta


class LastModified(BaseHeuristic):
    

    cacheable_by_default_statuses = {
        200,
        203,
        204,
        206,
        300,
        301,
        404,
        405,
        410,
        414,
        501,
    }

    def update_headers(self, resp: HTTPResponse) -> dict[str, str]:
        headers: Mapping[str, str] = resp.headers

        if ""expires"" in headers:
            return {}

        if ""cache-control"" in headers and headers[""cache-control""] != ""public"":
            return {}

        if resp.status not in self.cacheable_by_default_statuses:
            return {}

        if ""date"" not in headers or ""last-modified"" not in headers:
            return {}

        time_tuple = parsedate_tz(headers[""date""])
        assert time_tuple is not None
        date = calendar.timegm(time_tuple[:6])
        last_modified = parsedate(headers[""last-modified""])
        if last_modified is None:
            return {}

        now = time.time()
        current_age = max(0, now - date)
        delta = date - calendar.timegm(last_modified)
        freshness_lifetime = max(0, min(delta / 10, 24 * 3600))
        if freshness_lifetime <= current_age:
            return {}

        expires = date + freshness_lifetime
        return {""expires"": time.strftime(TIME_FMT, time.gmtime(expires))}

    def warning(self, resp: HTTPResponse) -> str | None:
        return None




from __future__ import annotations

import io
from typing import IO, TYPE_CHECKING, Any, Mapping, cast

from pip._vendor import msgpack
from pip._vendor.requests.structures import CaseInsensitiveDict
from pip._vendor.urllib3 import HTTPResponse

if TYPE_CHECKING:
    from pip._vendor.requests import PreparedRequest


class Serializer:
    serde_version = ""4""

    def dumps(
        self,
        request: PreparedRequest,
        response: HTTPResponse,
        body: bytes | None = None,
    ) -> bytes:
        response_headers: CaseInsensitiveDict[str] = CaseInsensitiveDict(
            response.headers
        )

        if body is None:
            
            
            
            body = response.read(decode_content=False)
            response._fp = io.BytesIO(body)  
            response.length_remaining = len(body)

        data = {
            ""response"": {
                ""body"": body,  
                ""headers"": {str(k): str(v) for k, v in response.headers.items()},
                ""status"": response.status,
                ""version"": response.version,
                ""reason"": str(response.reason),
                ""decode_content"": response.decode_content,
            }
        }

        
        data[""vary""] = {}
        if ""vary"" in response_headers:
            varied_headers = response_headers[""vary""].split("","")
            for header in varied_headers:
                header = str(header).strip()
                header_value = request.headers.get(header, None)
                if header_value is not None:
                    header_value = str(header_value)
                data[""vary""][header] = header_value

        return b"","".join([f""cc={self.serde_version}"".encode(), self.serialize(data)])

    def serialize(self, data: dict[str, Any]) -> bytes:
        return cast(bytes, msgpack.dumps(data, use_bin_type=True))

    def loads(
        self,
        request: PreparedRequest,
        data: bytes,
        body_file: IO[bytes] | None = None,
    ) -> HTTPResponse | None:
        
        if not data:
            return None

        
        
        if not data.startswith(f""cc={self.serde_version},"".encode()):
            return None

        data = data[5:]
        return self._loads_v4(request, data, body_file)

    def prepare_response(
        self,
        request: PreparedRequest,
        cached: Mapping[str, Any],
        body_file: IO[bytes] | None = None,
    ) -> HTTPResponse | None:
        
        
        
        
        
        if ""*"" in cached.get(""vary"", {}):
            return None

        
        
        for header, value in cached.get(""vary"", {}).items():
            if request.headers.get(header, None) != value:
                return None

        body_raw = cached[""response""].pop(""body"")

        headers: CaseInsensitiveDict[str] = CaseInsensitiveDict(
            data=cached[""response""][""headers""]
        )
        if headers.get(""transfer-encoding"", """") == ""chunked"":
            headers.pop(""transfer-encoding"")

        cached[""response""][""headers""] = headers

        try:
            body: IO[bytes]
            if body_file is None:
                body = io.BytesIO(body_raw)
            else:
                body = body_file
        except TypeError:
            
            
            
            
            
            
            body = io.BytesIO(body_raw.encode(""utf8""))

        
        cached[""response""].pop(""strict"", None)

        return HTTPResponse(body=body, preload_content=False, **cached[""response""])

    def _loads_v4(
        self,
        request: PreparedRequest,
        data: bytes,
        body_file: IO[bytes] | None = None,
    ) -> HTTPResponse | None:
        try:
            cached = msgpack.loads(data, raw=False)
        except ValueError:
            return None

        return self.prepare_response(request, cached, body_file)




from __future__ import annotations

from typing import TYPE_CHECKING, Collection

from pip._vendor.cachecontrol.adapter import CacheControlAdapter
from pip._vendor.cachecontrol.cache import DictCache

if TYPE_CHECKING:
    from pip._vendor import requests

    from pip._vendor.cachecontrol.cache import BaseCache
    from pip._vendor.cachecontrol.controller import CacheController
    from pip._vendor.cachecontrol.heuristics import BaseHeuristic
    from pip._vendor.cachecontrol.serialize import Serializer


def CacheControl(
    sess: requests.Session,
    cache: BaseCache | None = None,
    cache_etags: bool = True,
    serializer: Serializer | None = None,
    heuristic: BaseHeuristic | None = None,
    controller_class: type[CacheController] | None = None,
    adapter_class: type[CacheControlAdapter] | None = None,
    cacheable_methods: Collection[str] | None = None,
) -> requests.Session:
    cache = DictCache() if cache is None else cache
    adapter_class = adapter_class or CacheControlAdapter
    adapter = adapter_class(
        cache,
        cache_etags=cache_etags,
        serializer=serializer,
        heuristic=heuristic,
        controller_class=controller_class,
        cacheable_methods=cacheable_methods,
    )
    sess.mount(""http://"", adapter)
    sess.mount(""https://"", adapter)

    return sess




from __future__ import annotations

import logging
from argparse import ArgumentParser
from typing import TYPE_CHECKING

from pip._vendor import requests

from pip._vendor.cachecontrol.adapter import CacheControlAdapter
from pip._vendor.cachecontrol.cache import DictCache
from pip._vendor.cachecontrol.controller import logger

if TYPE_CHECKING:
    from argparse import Namespace

    from pip._vendor.cachecontrol.controller import CacheController


def setup_logging() -> None:
    logger.setLevel(logging.DEBUG)
    handler = logging.StreamHandler()
    logger.addHandler(handler)


def get_session() -> requests.Session:
    adapter = CacheControlAdapter(
        DictCache(), cache_etags=True, serializer=None, heuristic=None
    )
    sess = requests.Session()
    sess.mount(""http://"", adapter)
    sess.mount(""https://"", adapter)

    sess.cache_controller = adapter.controller  
    return sess


def get_args() -> Namespace:
    parser = ArgumentParser()
    parser.add_argument(""url"", help=""The URL to try and cache"")
    return parser.parse_args()


def main() -> None:
    args = get_args()
    sess = get_session()

    
    resp = sess.get(args.url)

    
    setup_logging()

    
    cache_controller: CacheController = (
        sess.cache_controller  
    )
    cache_controller.cache_response(resp.request, resp.raw)

    
    if cache_controller.cached_request(resp.request):
        print(""Cached!"")
    else:
        print(""Not cached :("")


if __name__ == ""__main__"":
    main()







__author__ = ""Eric Larson""
__email__ = ""eric@ionrock.org""
__version__ = ""0.14.3""

from pip._vendor.cachecontrol.adapter import CacheControlAdapter
from pip._vendor.cachecontrol.controller import CacheController
from pip._vendor.cachecontrol.wrapper import CacheControl

__all__ = [
    ""__author__"",
    ""__email__"",
    ""__version__"",
    ""CacheControlAdapter"",
    ""CacheController"",
    ""CacheControl"",
]

import logging

logging.getLogger(__name__).addHandler(logging.NullHandler())




from __future__ import annotations

import hashlib
import os
import tempfile
from textwrap import dedent
from typing import IO, TYPE_CHECKING
from pathlib import Path

from pip._vendor.cachecontrol.cache import BaseCache, SeparateBodyBaseCache
from pip._vendor.cachecontrol.controller import CacheController

if TYPE_CHECKING:
    from datetime import datetime

    from filelock import BaseFileLock


class _FileCacheMixin:
    

    def __init__(
        self,
        directory: str | Path,
        forever: bool = False,
        filemode: int = 0o0600,
        dirmode: int = 0o0700,
        lock_class: type[BaseFileLock] | None = None,
    ) -> None:
        try:
            if lock_class is None:
                from filelock import FileLock

                lock_class = FileLock
        except ImportError:
            notice = dedent(
                
            )
            raise ImportError(notice)

        self.directory = directory
        self.forever = forever
        self.filemode = filemode
        self.dirmode = dirmode
        self.lock_class = lock_class

    @staticmethod
    def encode(x: str) -> str:
        return hashlib.sha224(x.encode()).hexdigest()

    def _fn(self, name: str) -> str:
        
        
        hashed = self.encode(name)
        parts = list(hashed[:5]) + [hashed]
        return os.path.join(self.directory, *parts)

    def get(self, key: str) -> bytes | None:
        name = self._fn(key)
        try:
            with open(name, ""rb"") as fh:
                return fh.read()

        except FileNotFoundError:
            return None

    def set(
        self, key: str, value: bytes, expires: int | datetime | None = None
    ) -> None:
        name = self._fn(key)
        self._write(name, value)

    def _write(self, path: str, data: bytes) -> None:
        
        
        dirname = os.path.dirname(path)
        os.makedirs(dirname, self.dirmode, exist_ok=True)

        with self.lock_class(path + "".lock""):
            
            (fd, name) = tempfile.mkstemp(dir=dirname)
            try:
                os.write(fd, data)
            finally:
                os.close(fd)
            os.chmod(name, self.filemode)
            os.replace(name, path)

    def _delete(self, key: str, suffix: str) -> None:
        name = self._fn(key) + suffix
        if not self.forever:
            try:
                os.remove(name)
            except FileNotFoundError:
                pass


class FileCache(_FileCacheMixin, BaseCache):
    

    def delete(self, key: str) -> None:
        self._delete(key, """")


class SeparateBodyFileCache(_FileCacheMixin, SeparateBodyBaseCache):
    

    def get_body(self, key: str) -> IO[bytes] | None:
        name = self._fn(key) + "".body""
        try:
            return open(name, ""rb"")
        except FileNotFoundError:
            return None

    def set_body(self, key: str, body: bytes) -> None:
        name = self._fn(key) + "".body""
        self._write(name, body)

    def delete(self, key: str) -> None:
        self._delete(key, """")
        self._delete(key, "".body"")


def url_to_file_path(url: str, filecache: FileCache) -> str:
    
    key = CacheController.cache_url(url)
    return filecache._fn(key)




from __future__ import annotations


from datetime import datetime, timezone
from typing import TYPE_CHECKING

from pip._vendor.cachecontrol.cache import BaseCache

if TYPE_CHECKING:
    from redis import Redis


class RedisCache(BaseCache):
    def __init__(self, conn: Redis[bytes]) -> None:
        self.conn = conn

    def get(self, key: str) -> bytes | None:
        return self.conn.get(key)

    def set(
        self, key: str, value: bytes, expires: int | datetime | None = None
    ) -> None:
        if not expires:
            self.conn.set(key, value)
        elif isinstance(expires, datetime):
            now_utc = datetime.now(timezone.utc)
            if expires.tzinfo is None:
                now_utc = now_utc.replace(tzinfo=None)
            delta = expires - now_utc
            self.conn.setex(key, int(delta.total_seconds()), value)
        else:
            self.conn.setex(key, expires, value)

    def delete(self, key: str) -> None:
        self.conn.delete(key)

    def clear(self) -> None:
        
        for key in self.conn.keys():
            self.conn.delete(key)

    def close(self) -> None:
        
        pass





from pip._vendor.cachecontrol.caches.file_cache import FileCache, SeparateBodyFileCache
from pip._vendor.cachecontrol.caches.redis_cache import RedisCache

__all__ = [""FileCache"", ""SeparateBodyFileCache"", ""RedisCache""]


import sys
import atexit

def exit_cacert_ctx() -> None:
    _CACERT_CTX.__exit__(None, None, None)  


if sys.version_info >= (3, 11):

    from importlib.resources import as_file, files

    _CACERT_CTX = None
    _CACERT_PATH = None

    def where() -> str:
        
        
        
        
        
        global _CACERT_CTX
        global _CACERT_PATH
        if _CACERT_PATH is None:
            
            
            
            
            
            
            
            
            
            
            _CACERT_CTX = as_file(files(""pip._vendor.certifi"").joinpath(""cacert.pem""))
            _CACERT_PATH = str(_CACERT_CTX.__enter__())
            atexit.register(exit_cacert_ctx)

        return _CACERT_PATH

    def contents() -> str:
        return files(""pip._vendor.certifi"").joinpath(""cacert.pem"").read_text(encoding=""ascii"")

else:

    from importlib.resources import path as get_path, read_text

    _CACERT_CTX = None
    _CACERT_PATH = None

    def where() -> str:
        
        
        
        
        
        global _CACERT_CTX
        global _CACERT_PATH
        if _CACERT_PATH is None:
            
            
            
            
            
            
            
            
            
            
            
            _CACERT_CTX = get_path(""pip._vendor.certifi"", ""cacert.pem"")
            _CACERT_PATH = str(_CACERT_CTX.__enter__())
            atexit.register(exit_cacert_ctx)

        return _CACERT_PATH

    def contents() -> str:
        return read_text(""pip._vendor.certifi"", ""cacert.pem"", encoding=""ascii"")

from .core import contents, where

__all__ = [""contents"", ""where""]
__version__ = ""2025.07.14""

import argparse

from pip._vendor.certifi import contents, where

parser = argparse.ArgumentParser()
parser.add_argument(""-c"", ""--contents"", action=""store_true"")
args = parser.parse_args()

if args.contents:
    print(contents())
else:
    print(where())

from __future__ import annotations

import dataclasses
import re
from collections.abc import Mapping

from pip._vendor.packaging.requirements import Requirement


def _normalize_name(name: str) -> str:
    return re.sub(r""[-_.]+"", ""-"", name).lower()


def _normalize_group_names(
    dependency_groups: Mapping[str, str | Mapping[str, str]],
) -> Mapping[str, str | Mapping[str, str]]:
    original_names: dict[str, list[str]] = {}
    normalized_groups = {}

    for group_name, value in dependency_groups.items():
        normed_group_name = _normalize_name(group_name)
        original_names.setdefault(normed_group_name, []).append(group_name)
        normalized_groups[normed_group_name] = value

    errors = []
    for normed_name, names in original_names.items():
        if len(names) > 1:
            errors.append(f""{normed_name} ({', '.join(names)})"")
    if errors:
        raise ValueError(f""Duplicate dependency group names: {', '.join(errors)}"")

    return normalized_groups


@dataclasses.dataclass
class DependencyGroupInclude:
    include_group: str


class CyclicDependencyError(ValueError):
    

    def __init__(self, requested_group: str, group: str, include_group: str) -> None:
        self.requested_group = requested_group
        self.group = group
        self.include_group = include_group

        if include_group == group:
            reason = f""{group} includes itself""
        else:
            reason = f""{include_group} -> {group}, {group} -> {include_group}""
        super().__init__(
            ""Cyclic dependency group include while resolving ""
            f""{requested_group}: {reason}""
        )


class DependencyGroupResolver:
    

    def __init__(
        self,
        dependency_groups: Mapping[str, str | Mapping[str, str]],
    ) -> None:
        if not isinstance(dependency_groups, Mapping):
            raise TypeError(""Dependency Groups table is not a mapping"")
        self.dependency_groups = _normalize_group_names(dependency_groups)
        
        self._parsed_groups: dict[
            str, tuple[Requirement | DependencyGroupInclude, ...]
        ] = {}
        
        self._include_graph_ancestors: dict[str, tuple[str, ...]] = {}
        
        self._resolve_cache: dict[str, tuple[Requirement, ...]] = {}

    def lookup(self, group: str) -> tuple[Requirement | DependencyGroupInclude, ...]:
        
        if not isinstance(group, str):
            raise TypeError(""Dependency group name is not a str"")
        group = _normalize_name(group)
        return self._parse_group(group)

    def resolve(self, group: str) -> tuple[Requirement, ...]:
        
        if not isinstance(group, str):
            raise TypeError(""Dependency group name is not a str"")
        group = _normalize_name(group)
        return self._resolve(group, group)

    def _parse_group(
        self, group: str
    ) -> tuple[Requirement | DependencyGroupInclude, ...]:
        
        if group in self._parsed_groups:
            return self._parsed_groups[group]

        if group not in self.dependency_groups:
            raise LookupError(f""Dependency group '{group}' not found"")

        raw_group = self.dependency_groups[group]
        if not isinstance(raw_group, list):
            raise TypeError(f""Dependency group '{group}' is not a list"")

        elements: list[Requirement | DependencyGroupInclude] = []
        for item in raw_group:
            if isinstance(item, str):
                
                
                
                elements.append(Requirement(item))
            elif isinstance(item, dict):
                if tuple(item.keys()) != (""include-group"",):
                    raise ValueError(f""Invalid dependency group item: {item}"")

                include_group = next(iter(item.values()))
                elements.append(DependencyGroupInclude(include_group=include_group))
            else:
                raise ValueError(f""Invalid dependency group item: {item}"")

        self._parsed_groups[group] = tuple(elements)
        return self._parsed_groups[group]

    def _resolve(self, group: str, requested_group: str) -> tuple[Requirement, ...]:
        
        if group in self._resolve_cache:
            return self._resolve_cache[group]

        parsed = self._parse_group(group)

        resolved_group = []
        for item in parsed:
            if isinstance(item, Requirement):
                resolved_group.append(item)
            elif isinstance(item, DependencyGroupInclude):
                include_group = _normalize_name(item.include_group)
                if include_group in self._include_graph_ancestors.get(group, ()):
                    raise CyclicDependencyError(
                        requested_group, group, item.include_group
                    )
                self._include_graph_ancestors[include_group] = (
                    *self._include_graph_ancestors.get(group, ()),
                    group,
                )
                resolved_group.extend(self._resolve(include_group, requested_group))
            else:  
                raise NotImplementedError(
                    f""Invalid dependency group item after parse: {item}""
                )

        self._resolve_cache[group] = tuple(resolved_group)
        return self._resolve_cache[group]


def resolve(
    dependency_groups: Mapping[str, str | Mapping[str, str]], /, *groups: str
) -> tuple[str, ...]:
    
    resolver = DependencyGroupResolver(dependency_groups)
    return tuple(str(r) for group in groups for r in resolver.resolve(group))

from __future__ import annotations

import argparse
import sys

from ._implementation import DependencyGroupResolver
from ._toml_compat import tomllib


def main(*, argv: list[str] | None = None) -> None:
    if tomllib is None:
        print(
            ""Usage error: dependency-groups CLI requires tomli or Python 3.11+"",
            file=sys.stderr,
        )
        raise SystemExit(2)

    parser = argparse.ArgumentParser(
        description=(
            ""Lint Dependency Groups for validity. ""
            ""This will eagerly load and check all of your Dependency Groups.""
        )
    )
    parser.add_argument(
        ""-f"",
        ""--pyproject-file"",
        default=""pyproject.toml"",
        help=""The pyproject.toml file. Defaults to trying in the current directory."",
    )
    args = parser.parse_args(argv if argv is not None else sys.argv[1:])

    with open(args.pyproject_file, ""rb"") as fp:
        pyproject = tomllib.load(fp)
    dependency_groups_raw = pyproject.get(""dependency-groups"", {})

    errors: list[str] = []
    try:
        resolver = DependencyGroupResolver(dependency_groups_raw)
    except (ValueError, TypeError) as e:
        errors.append(f""{type(e).__name__}: {e}"")
    else:
        for groupname in resolver.dependency_groups:
            try:
                resolver.resolve(groupname)
            except (LookupError, ValueError, TypeError) as e:
                errors.append(f""{type(e).__name__}: {e}"")

    if errors:
        print(""errors encountered while examining dependency groups:"")
        for msg in errors:
            print(f""  {msg}"")
        sys.exit(1)
    else:
        print(""ok"")
        sys.exit(0)


if __name__ == ""__main__"":
    main()

from __future__ import annotations

import argparse
import subprocess
import sys

from ._implementation import DependencyGroupResolver
from ._toml_compat import tomllib


def _invoke_pip(deps: list[str]) -> None:
    subprocess.check_call([sys.executable, ""-m"", ""pip"", ""install"", *deps])


def main(*, argv: list[str] | None = None) -> None:
    if tomllib is None:
        print(
            ""Usage error: dependency-groups CLI requires tomli or Python 3.11+"",
            file=sys.stderr,
        )
        raise SystemExit(2)

    parser = argparse.ArgumentParser(description=""Install Dependency Groups."")
    parser.add_argument(
        ""DEPENDENCY_GROUP"", nargs=""+"", help=""The dependency groups to install.""
    )
    parser.add_argument(
        ""-f"",
        ""--pyproject-file"",
        default=""pyproject.toml"",
        help=""The pyproject.toml file. Defaults to trying in the current directory."",
    )
    args = parser.parse_args(argv if argv is not None else sys.argv[1:])

    with open(args.pyproject_file, ""rb"") as fp:
        pyproject = tomllib.load(fp)
    dependency_groups_raw = pyproject.get(""dependency-groups"", {})

    errors: list[str] = []
    resolved: list[str] = []
    try:
        resolver = DependencyGroupResolver(dependency_groups_raw)
    except (ValueError, TypeError) as e:
        errors.append(f""{type(e).__name__}: {e}"")
    else:
        for groupname in args.DEPENDENCY_GROUP:
            try:
                resolved.extend(str(r) for r in resolver.resolve(groupname))
            except (LookupError, ValueError, TypeError) as e:
                errors.append(f""{type(e).__name__}: {e}"")

    if errors:
        print(""errors encountered while examining dependency groups:"")
        for msg in errors:
            print(f""  {msg}"")
        sys.exit(1)

    _invoke_pip(resolved)


if __name__ == ""__main__"":
    main()

try:
    import tomllib
except ImportError:
    try:
        from pip._vendor import tomli as tomllib  
    except ModuleNotFoundError:  
        tomllib = None  

__all__ = (""tomllib"",)

from ._implementation import (
    CyclicDependencyError,
    DependencyGroupInclude,
    DependencyGroupResolver,
    resolve,
)

__all__ = (
    ""CyclicDependencyError"",
    ""DependencyGroupInclude"",
    ""DependencyGroupResolver"",
    ""resolve"",
)

import argparse
import sys

from ._implementation import resolve
from ._toml_compat import tomllib


def main() -> None:
    if tomllib is None:
        print(
            ""Usage error: dependency-groups CLI requires tomli or Python 3.11+"",
            file=sys.stderr,
        )
        raise SystemExit(2)

    parser = argparse.ArgumentParser(
        description=(
            ""A dependency-groups CLI. Prints out a resolved group, newline-delimited.""
        )
    )
    parser.add_argument(
        ""GROUP_NAME"", nargs=""*"", help=""The dependency group(s) to resolve.""
    )
    parser.add_argument(
        ""-f"",
        ""--pyproject-file"",
        default=""pyproject.toml"",
        help=""The pyproject.toml file. Defaults to trying in the current directory."",
    )
    parser.add_argument(
        ""-o"",
        ""--output"",
        help=""An output file. Defaults to stdout."",
    )
    parser.add_argument(
        ""-l"",
        ""--list"",
        action=""store_true"",
        help=""List the available dependency groups"",
    )
    args = parser.parse_args()

    with open(args.pyproject_file, ""rb"") as fp:
        pyproject = tomllib.load(fp)

    dependency_groups_raw = pyproject.get(""dependency-groups"", {})

    if args.list:
        print(*dependency_groups_raw.keys())
        return
    if not args.GROUP_NAME:
        print(""A GROUP_NAME is required"", file=sys.stderr)
        raise SystemExit(3)

    content = ""\n"".join(resolve(dependency_groups_raw, *args.GROUP_NAME))

    if args.output is None or args.output == ""-"":
        print(content)
    else:
        with open(args.output, ""w"", encoding=""utf-8"") as fp:
            print(content, file=fp)


if __name__ == ""__main__"":
    main()







from __future__ import absolute_import

import os
import re
import shutil
import sys

try:
    import ssl
except ImportError:  
    ssl = None

if sys.version_info[0] < 3:  
    from StringIO import StringIO
    string_types = basestring,
    text_type = unicode
    from types import FileType as file_type
    import __builtin__ as builtins
    import ConfigParser as configparser
    from urlparse import urlparse, urlunparse, urljoin, urlsplit, urlunsplit
    from urllib import (urlretrieve, quote as _quote, unquote, url2pathname,
                        pathname2url, ContentTooShortError, splittype)

    def quote(s):
        if isinstance(s, unicode):
            s = s.encode('utf-8')
        return _quote(s)

    import urllib2
    from urllib2 import (Request, urlopen, URLError, HTTPError,
                         HTTPBasicAuthHandler, HTTPPasswordMgr, HTTPHandler,
                         HTTPRedirectHandler, build_opener)
    if ssl:
        from urllib2 import HTTPSHandler
    import httplib
    import xmlrpclib
    import Queue as queue
    from HTMLParser import HTMLParser
    import htmlentitydefs
    raw_input = raw_input
    from itertools import ifilter as filter
    from itertools import ifilterfalse as filterfalse

    
    
    
    
    
    
    
    

    
    
    

else:  
    from io import StringIO
    string_types = str,
    text_type = str
    from io import TextIOWrapper as file_type
    import builtins
    import configparser
    from urllib.parse import (urlparse, urlunparse, urljoin, quote, unquote,
                              urlsplit, urlunsplit, splittype)
    from urllib.request import (urlopen, urlretrieve, Request, url2pathname,
                                pathname2url, HTTPBasicAuthHandler,
                                HTTPPasswordMgr, HTTPHandler,
                                HTTPRedirectHandler, build_opener)
    if ssl:
        from urllib.request import HTTPSHandler
    from urllib.error import HTTPError, URLError, ContentTooShortError
    import http.client as httplib
    import urllib.request as urllib2
    import xmlrpc.client as xmlrpclib
    import queue
    from html.parser import HTMLParser
    import html.entities as htmlentitydefs
    raw_input = input
    from itertools import filterfalse
    filter = filter

try:
    from ssl import match_hostname, CertificateError
except ImportError:  

    class CertificateError(ValueError):
        pass

    def _dnsname_match(dn, hostname, max_wildcards=1):
        
        pats = []
        if not dn:
            return False

        parts = dn.split('.')
        leftmost, remainder = parts[0], parts[1:]

        wildcards = leftmost.count('*')
        if wildcards > max_wildcards:
            
            
            
            
            raise CertificateError(
                ""too many wildcards in certificate DNS name: "" + repr(dn))

        
        if not wildcards:
            return dn.lower() == hostname.lower()

        
        
        
        if leftmost == '*':
            
            
            pats.append('[^.]+')
        elif leftmost.startswith('xn--') or hostname.startswith('xn--'):
            
            
            
            
            pats.append(re.escape(leftmost))
        else:
            
            pats.append(re.escape(leftmost).replace(r'\*', '[^.]*'))

        
        for frag in remainder:
            pats.append(re.escape(frag))

        pat = re.compile(r'\A' + r'\.'.join(pats) + r'\Z', re.IGNORECASE)
        return pat.match(hostname)

    def match_hostname(cert, hostname):
        
        if not cert:
            raise ValueError(""empty or no certificate, match_hostname needs a ""
                             ""SSL socket or SSL context with either ""
                             ""CERT_OPTIONAL or CERT_REQUIRED"")
        dnsnames = []
        san = cert.get('subjectAltName', ())
        for key, value in san:
            if key == 'DNS':
                if _dnsname_match(value, hostname):
                    return
                dnsnames.append(value)
        if not dnsnames:
            
            
            for sub in cert.get('subject', ()):
                for key, value in sub:
                    
                    
                    if key == 'commonName':
                        if _dnsname_match(value, hostname):
                            return
                        dnsnames.append(value)
        if len(dnsnames) > 1:
            raise CertificateError(""hostname %r ""
                                   ""doesn't match either of %s"" %
                                   (hostname, ', '.join(map(repr, dnsnames))))
        elif len(dnsnames) == 1:
            raise CertificateError(""hostname %r ""
                                   ""doesn't match %r"" %
                                   (hostname, dnsnames[0]))
        else:
            raise CertificateError(""no appropriate commonName or ""
                                   ""subjectAltName fields were found"")


try:
    from types import SimpleNamespace as Container
except ImportError:  

    class Container(object):
        

        def __init__(self, **kwargs):
            self.__dict__.update(kwargs)


try:
    from shutil import which
except ImportError:  
    
    def which(cmd, mode=os.F_OK | os.X_OK, path=None):
        

        
        
        
        def _access_check(fn, mode):
            return (os.path.exists(fn) and os.access(fn, mode) and not os.path.isdir(fn))

        
        
        
        if os.path.dirname(cmd):
            if _access_check(cmd, mode):
                return cmd
            return None

        if path is None:
            path = os.environ.get(""PATH"", os.defpath)
        if not path:
            return None
        path = path.split(os.pathsep)

        if sys.platform == ""win32"":
            
            if os.curdir not in path:
                path.insert(0, os.curdir)

            
            pathext = os.environ.get(""PATHEXT"", """").split(os.pathsep)
            
            
            
            
            if any(cmd.lower().endswith(ext.lower()) for ext in pathext):
                files = [cmd]
            else:
                files = [cmd + ext for ext in pathext]
        else:
            
            
            files = [cmd]

        seen = set()
        for dir in path:
            normdir = os.path.normcase(dir)
            if normdir not in seen:
                seen.add(normdir)
                for thefile in files:
                    name = os.path.join(dir, thefile)
                    if _access_check(name, mode):
                        return name
        return None




from zipfile import ZipFile as BaseZipFile

if hasattr(BaseZipFile, '__enter__'):  
    ZipFile = BaseZipFile
else:  
    from zipfile import ZipExtFile as BaseZipExtFile

    class ZipExtFile(BaseZipExtFile):

        def __init__(self, base):
            self.__dict__.update(base.__dict__)

        def __enter__(self):
            return self

        def __exit__(self, *exc_info):
            self.close()
            

    class ZipFile(BaseZipFile):

        def __enter__(self):
            return self

        def __exit__(self, *exc_info):
            self.close()
            

        def open(self, *args, **kwargs):
            base = BaseZipFile.open(self, *args, **kwargs)
            return ZipExtFile(base)


try:
    from platform import python_implementation
except ImportError:  

    def python_implementation():
        
        if 'PyPy' in sys.version:
            return 'PyPy'
        if os.name == 'java':
            return 'Jython'
        if sys.version.startswith('IronPython'):
            return 'IronPython'
        return 'CPython'


import sysconfig

try:
    callable = callable
except NameError:  
    from collections.abc import Callable

    def callable(obj):
        return isinstance(obj, Callable)


try:
    fsencode = os.fsencode
    fsdecode = os.fsdecode
except AttributeError:  
    
    
    
    
    
    
    _fsencoding = sys.getfilesystemencoding() or 'utf-8'
    if _fsencoding == 'mbcs':
        _fserrors = 'strict'
    else:
        _fserrors = 'surrogateescape'

    def fsencode(filename):
        if isinstance(filename, bytes):
            return filename
        elif isinstance(filename, text_type):
            return filename.encode(_fsencoding, _fserrors)
        else:
            raise TypeError(""expect bytes or str, not %s"" %
                            type(filename).__name__)

    def fsdecode(filename):
        if isinstance(filename, text_type):
            return filename
        elif isinstance(filename, bytes):
            return filename.decode(_fsencoding, _fserrors)
        else:
            raise TypeError(""expect bytes or str, not %s"" %
                            type(filename).__name__)


try:
    from tokenize import detect_encoding
except ImportError:  
    from codecs import BOM_UTF8, lookup

    cookie_re = re.compile(r""coding[:=]\s*([-\w.]+)"")

    def _get_normal_name(orig_enc):
        
        
        enc = orig_enc[:12].lower().replace(""_"", ""-"")
        if enc == ""utf-8"" or enc.startswith(""utf-8-""):
            return ""utf-8""
        if enc in (""latin-1"", ""iso-8859-1"", ""iso-latin-1"") or \
           enc.startswith((""latin-1-"", ""iso-8859-1-"", ""iso-latin-1-"")):
            return ""iso-8859-1""
        return orig_enc

    def detect_encoding(readline):
        
        try:
            filename = readline.__self__.name
        except AttributeError:
            filename = None
        bom_found = False
        encoding = None
        default = 'utf-8'

        def read_or_stop():
            try:
                return readline()
            except StopIteration:
                return b''

        def find_cookie(line):
            try:
                
                
                
                line_string = line.decode('utf-8')
            except UnicodeDecodeError:
                msg = ""invalid or missing encoding declaration""
                if filename is not None:
                    msg = '{} for {!r}'.format(msg, filename)
                raise SyntaxError(msg)

            matches = cookie_re.findall(line_string)
            if not matches:
                return None
            encoding = _get_normal_name(matches[0])
            try:
                codec = lookup(encoding)
            except LookupError:
                
                if filename is None:
                    msg = ""unknown encoding: "" + encoding
                else:
                    msg = ""unknown encoding for {!r}: {}"".format(
                        filename, encoding)
                raise SyntaxError(msg)

            if bom_found:
                if codec.name != 'utf-8':
                    
                    if filename is None:
                        msg = 'encoding problem: utf-8'
                    else:
                        msg = 'encoding problem for {!r}: utf-8'.format(
                            filename)
                    raise SyntaxError(msg)
                encoding += '-sig'
            return encoding

        first = read_or_stop()
        if first.startswith(BOM_UTF8):
            bom_found = True
            first = first[3:]
            default = 'utf-8-sig'
        if not first:
            return default, []

        encoding = find_cookie(first)
        if encoding:
            return encoding, [first]

        second = read_or_stop()
        if not second:
            return default, [first]

        encoding = find_cookie(second)
        if encoding:
            return encoding, [first, second]

        return default, [first, second]



try:
    from html import escape
except ImportError:
    from cgi import escape
if sys.version_info[:2] < (3, 4):
    unescape = HTMLParser().unescape
else:
    from html import unescape

try:
    from collections import ChainMap
except ImportError:  
    from collections import MutableMapping

    try:
        from reprlib import recursive_repr as _recursive_repr
    except ImportError:

        def _recursive_repr(fillvalue='...'):
            

            def decorating_function(user_function):
                repr_running = set()

                def wrapper(self):
                    key = id(self), get_ident()
                    if key in repr_running:
                        return fillvalue
                    repr_running.add(key)
                    try:
                        result = user_function(self)
                    finally:
                        repr_running.discard(key)
                    return result

                
                wrapper.__module__ = getattr(user_function, '__module__')
                wrapper.__doc__ = getattr(user_function, '__doc__')
                wrapper.__name__ = getattr(user_function, '__name__')
                wrapper.__annotations__ = getattr(user_function,
                                                  '__annotations__', {})
                return wrapper

            return decorating_function

    class ChainMap(MutableMapping):
        

        def __init__(self, *maps):
            
            self.maps = list(maps) or [{}]  

        def __missing__(self, key):
            raise KeyError(key)

        def __getitem__(self, key):
            for mapping in self.maps:
                try:
                    return mapping[
                        key]  
                except KeyError:
                    pass
            return self.__missing__(
                key)  

        def get(self, key, default=None):
            return self[key] if key in self else default

        def __len__(self):
            return len(set().union(
                *self.maps))  

        def __iter__(self):
            return iter(set().union(*self.maps))

        def __contains__(self, key):
            return any(key in m for m in self.maps)

        def __bool__(self):
            return any(self.maps)

        @_recursive_repr()
        def __repr__(self):
            return '{0.__class__.__name__}({1})'.format(
                self, ', '.join(map(repr, self.maps)))

        @classmethod
        def fromkeys(cls, iterable, *args):
            'Create a ChainMap with a single dict created from the iterable.'
            return cls(dict.fromkeys(iterable, *args))

        def copy(self):
            'New ChainMap or subclass with a new copy of maps[0] and refs to maps[1:]'
            return self.__class__(self.maps[0].copy(), *self.maps[1:])

        __copy__ = copy

        def new_child(self):  
            'New ChainMap with a new dict followed by all previous maps.'
            return self.__class__({}, *self.maps)

        @property
        def parents(self):  
            'New ChainMap from maps[1:].'
            return self.__class__(*self.maps[1:])

        def __setitem__(self, key, value):
            self.maps[0][key] = value

        def __delitem__(self, key):
            try:
                del self.maps[0][key]
            except KeyError:
                raise KeyError(
                    'Key not found in the first mapping: {!r}'.format(key))

        def popitem(self):
            'Remove and return an item pair from maps[0]. Raise KeyError is maps[0] is empty.'
            try:
                return self.maps[0].popitem()
            except KeyError:
                raise KeyError('No keys found in the first mapping.')

        def pop(self, key, *args):
            'Remove *key* from maps[0] and return its value. Raise KeyError if *key* not in maps[0].'
            try:
                return self.maps[0].pop(key, *args)
            except KeyError:
                raise KeyError(
                    'Key not found in the first mapping: {!r}'.format(key))

        def clear(self):
            'Clear maps[0], leaving maps[1:] intact.'
            self.maps[0].clear()


try:
    from importlib.util import cache_from_source  
except ImportError:  

    def cache_from_source(path, debug_override=None):
        assert path.endswith('.py')
        if debug_override is None:
            debug_override = __debug__
        if debug_override:
            suffix = 'c'
        else:
            suffix = 'o'
        return path + suffix


try:
    from collections import OrderedDict
except ImportError:  
    
    
    
    try:
        from thread import get_ident as _get_ident
    except ImportError:
        from dummy_thread import get_ident as _get_ident

    try:
        from _abcoll import KeysView, ValuesView, ItemsView
    except ImportError:
        pass

    class OrderedDict(dict):
        'Dictionary that remembers insertion order'

        
        
        
        

        
        
        
        

        def __init__(self, *args, **kwds):
            
            if len(args) > 1:
                raise TypeError('expected at most 1 arguments, got %d' %
                                len(args))
            try:
                self.__root
            except AttributeError:
                self.__root = root = []  
                root[:] = [root, root, None]
                self.__map = {}
            self.__update(*args, **kwds)

        def __setitem__(self, key, value, dict_setitem=dict.__setitem__):
            'od.__setitem__(i, y) <==> od[i]=y'
            
            
            if key not in self:
                root = self.__root
                last = root[0]
                last[1] = root[0] = self.__map[key] = [last, root, key]
            dict_setitem(self, key, value)

        def __delitem__(self, key, dict_delitem=dict.__delitem__):
            'od.__delitem__(y) <==> del od[y]'
            
            
            dict_delitem(self, key)
            link_prev, link_next, key = self.__map.pop(key)
            link_prev[1] = link_next
            link_next[0] = link_prev

        def __iter__(self):
            'od.__iter__() <==> iter(od)'
            root = self.__root
            curr = root[1]
            while curr is not root:
                yield curr[2]
                curr = curr[1]

        def __reversed__(self):
            'od.__reversed__() <==> reversed(od)'
            root = self.__root
            curr = root[0]
            while curr is not root:
                yield curr[2]
                curr = curr[0]

        def clear(self):
            'od.clear() -> None.  Remove all items from od.'
            try:
                for node in self.__map.itervalues():
                    del node[:]
                root = self.__root
                root[:] = [root, root, None]
                self.__map.clear()
            except AttributeError:
                pass
            dict.clear(self)

        def popitem(self, last=True):
            
            if not self:
                raise KeyError('dictionary is empty')
            root = self.__root
            if last:
                link = root[0]
                link_prev = link[0]
                link_prev[1] = root
                root[0] = link_prev
            else:
                link = root[1]
                link_next = link[1]
                root[1] = link_next
                link_next[0] = root
            key = link[2]
            del self.__map[key]
            value = dict.pop(self, key)
            return key, value

        

        def keys(self):
            'od.keys() -> list of keys in od'
            return list(self)

        def values(self):
            'od.values() -> list of values in od'
            return [self[key] for key in self]

        def items(self):
            'od.items() -> list of (key, value) pairs in od'
            return [(key, self[key]) for key in self]

        def iterkeys(self):
            'od.iterkeys() -> an iterator over the keys in od'
            return iter(self)

        def itervalues(self):
            'od.itervalues -> an iterator over the values in od'
            for k in self:
                yield self[k]

        def iteritems(self):
            'od.iteritems -> an iterator over the (key, value) items in od'
            for k in self:
                yield (k, self[k])

        def update(*args, **kwds):
            
            if len(args) > 2:
                raise TypeError('update() takes at most 2 positional '
                                'arguments (%d given)' % (len(args), ))
            elif not args:
                raise TypeError('update() takes at least 1 argument (0 given)')
            self = args[0]
            
            other = ()
            if len(args) == 2:
                other = args[1]
            if isinstance(other, dict):
                for key in other:
                    self[key] = other[key]
            elif hasattr(other, 'keys'):
                for key in other.keys():
                    self[key] = other[key]
            else:
                for key, value in other:
                    self[key] = value
            for key, value in kwds.items():
                self[key] = value

        __update = update  

        __marker = object()

        def pop(self, key, default=__marker):
            
            if key in self:
                result = self[key]
                del self[key]
                return result
            if default is self.__marker:
                raise KeyError(key)
            return default

        def setdefault(self, key, default=None):
            'od.setdefault(k[,d]) -> od.get(k,d), also set od[k]=d if k not in od'
            if key in self:
                return self[key]
            self[key] = default
            return default

        def __repr__(self, _repr_running=None):
            'od.__repr__() <==> repr(od)'
            if not _repr_running:
                _repr_running = {}
            call_key = id(self), _get_ident()
            if call_key in _repr_running:
                return '...'
            _repr_running[call_key] = 1
            try:
                if not self:
                    return '%s()' % (self.__class__.__name__, )
                return '%s(%r)' % (self.__class__.__name__, self.items())
            finally:
                del _repr_running[call_key]

        def __reduce__(self):
            'Return state information for pickling'
            items = [[k, self[k]] for k in self]
            inst_dict = vars(self).copy()
            for k in vars(OrderedDict()):
                inst_dict.pop(k, None)
            if inst_dict:
                return (self.__class__, (items, ), inst_dict)
            return self.__class__, (items, )

        def copy(self):
            'od.copy() -> a shallow copy of od'
            return self.__class__(self)

        @classmethod
        def fromkeys(cls, iterable, value=None):
            
            d = cls()
            for key in iterable:
                d[key] = value
            return d

        def __eq__(self, other):
            
            if isinstance(other, OrderedDict):
                return len(self) == len(
                    other) and self.items() == other.items()
            return dict.__eq__(self, other)

        def __ne__(self, other):
            return not self == other

        

        def viewkeys(self):
            ""od.viewkeys() -> a set-like object providing a view on od's keys""
            return KeysView(self)

        def viewvalues(self):
            ""od.viewvalues() -> an object providing a view on od's values""
            return ValuesView(self)

        def viewitems(self):
            ""od.viewitems() -> a set-like object providing a view on od's items""
            return ItemsView(self)


try:
    from logging.config import BaseConfigurator, valid_ident
except ImportError:  
    IDENTIFIER = re.compile('^[a-z_][a-z0-9_]*$', re.I)

    def valid_ident(s):
        m = IDENTIFIER.match(s)
        if not m:
            raise ValueError('Not a valid Python identifier: %r' % s)
        return True

    
    
    
    
    
    
    
    

    class ConvertingDict(dict):
        

        def __getitem__(self, key):
            value = dict.__getitem__(self, key)
            result = self.configurator.convert(value)
            
            if value is not result:
                self[key] = result
                if type(result) in (ConvertingDict, ConvertingList,
                                    ConvertingTuple):
                    result.parent = self
                    result.key = key
            return result

        def get(self, key, default=None):
            value = dict.get(self, key, default)
            result = self.configurator.convert(value)
            
            if value is not result:
                self[key] = result
                if type(result) in (ConvertingDict, ConvertingList,
                                    ConvertingTuple):
                    result.parent = self
                    result.key = key
            return result

    def pop(self, key, default=None):
        value = dict.pop(self, key, default)
        result = self.configurator.convert(value)
        if value is not result:
            if type(result) in (ConvertingDict, ConvertingList,
                                ConvertingTuple):
                result.parent = self
                result.key = key
        return result

    class ConvertingList(list):
        

        def __getitem__(self, key):
            value = list.__getitem__(self, key)
            result = self.configurator.convert(value)
            
            if value is not result:
                self[key] = result
                if type(result) in (ConvertingDict, ConvertingList,
                                    ConvertingTuple):
                    result.parent = self
                    result.key = key
            return result

        def pop(self, idx=-1):
            value = list.pop(self, idx)
            result = self.configurator.convert(value)
            if value is not result:
                if type(result) in (ConvertingDict, ConvertingList,
                                    ConvertingTuple):
                    result.parent = self
            return result

    class ConvertingTuple(tuple):
        

        def __getitem__(self, key):
            value = tuple.__getitem__(self, key)
            result = self.configurator.convert(value)
            if value is not result:
                if type(result) in (ConvertingDict, ConvertingList,
                                    ConvertingTuple):
                    result.parent = self
                    result.key = key
            return result

    class BaseConfigurator(object):
        

        CONVERT_PATTERN = re.compile(r'^(?P<prefix>[a-z]+)://(?P<suffix>.*)$')

        WORD_PATTERN = re.compile(r'^\s*(\w+)\s*')
        DOT_PATTERN = re.compile(r'^\.\s*(\w+)\s*')
        INDEX_PATTERN = re.compile(r'^\[\s*(\w+)\s*\]\s*')
        DIGIT_PATTERN = re.compile(r'^\d+$')

        value_converters = {
            'ext': 'ext_convert',
            'cfg': 'cfg_convert',
        }

        
        importer = staticmethod(__import__)

        def __init__(self, config):
            self.config = ConvertingDict(config)
            self.config.configurator = self

        def resolve(self, s):
            
            name = s.split('.')
            used = name.pop(0)
            try:
                found = self.importer(used)
                for frag in name:
                    used += '.' + frag
                    try:
                        found = getattr(found, frag)
                    except AttributeError:
                        self.importer(used)
                        found = getattr(found, frag)
                return found
            except ImportError:
                e, tb = sys.exc_info()[1:]
                v = ValueError('Cannot resolve %r: %s' % (s, e))
                v.__cause__, v.__traceback__ = e, tb
                raise v

        def ext_convert(self, value):
            
            return self.resolve(value)

        def cfg_convert(self, value):
            
            rest = value
            m = self.WORD_PATTERN.match(rest)
            if m is None:
                raise ValueError(""Unable to convert %r"" % value)
            else:
                rest = rest[m.end():]
                d = self.config[m.groups()[0]]
                while rest:
                    m = self.DOT_PATTERN.match(rest)
                    if m:
                        d = d[m.groups()[0]]
                    else:
                        m = self.INDEX_PATTERN.match(rest)
                        if m:
                            idx = m.groups()[0]
                            if not self.DIGIT_PATTERN.match(idx):
                                d = d[idx]
                            else:
                                try:
                                    n = int(
                                        idx
                                    )  
                                    d = d[n]
                                except TypeError:
                                    d = d[idx]
                    if m:
                        rest = rest[m.end():]
                    else:
                        raise ValueError('Unable to convert '
                                         '%r at %r' % (value, rest))
            
            return d

        def convert(self, value):
            
            if not isinstance(value, ConvertingDict) and isinstance(
                    value, dict):
                value = ConvertingDict(value)
                value.configurator = self
            elif not isinstance(value, ConvertingList) and isinstance(
                    value, list):
                value = ConvertingList(value)
                value.configurator = self
            elif not isinstance(value, ConvertingTuple) and isinstance(value, tuple):
                value = ConvertingTuple(value)
                value.configurator = self
            elif isinstance(value, string_types):
                m = self.CONVERT_PATTERN.match(value)
                if m:
                    d = m.groupdict()
                    prefix = d['prefix']
                    converter = self.value_converters.get(prefix, None)
                    if converter:
                        suffix = d['suffix']
                        converter = getattr(self, converter)
                        value = converter(suffix)
            return value

        def configure_custom(self, config):
            
            c = config.pop('()')
            if not callable(c):
                c = self.resolve(c)
            props = config.pop('.', None)
            
            kwargs = dict([(k, config[k]) for k in config if valid_ident(k)])
            result = c(**kwargs)
            if props:
                for name, value in props.items():
                    setattr(result, name, value)
            return result

        def as_tuple(self, value):
            
            if isinstance(value, list):
                value = tuple(value)
            return value







from __future__ import unicode_literals

import bisect
import io
import logging
import os
import pkgutil
import sys
import types
import zipimport

from . import DistlibException
from .util import cached_property, get_cache_base, Cache

logger = logging.getLogger(__name__)


cache = None    


class ResourceCache(Cache):
    def __init__(self, base=None):
        if base is None:
            
            base = os.path.join(get_cache_base(), str('resource-cache'))
        super(ResourceCache, self).__init__(base)

    def is_stale(self, resource, path):
        
        
        return True

    def get(self, resource):
        
        prefix, path = resource.finder.get_cache_info(resource)
        if prefix is None:
            result = path
        else:
            result = os.path.join(self.base, self.prefix_to_dir(prefix), path)
            dirname = os.path.dirname(result)
            if not os.path.isdir(dirname):
                os.makedirs(dirname)
            if not os.path.exists(result):
                stale = True
            else:
                stale = self.is_stale(resource, path)
            if stale:
                
                with open(result, 'wb') as f:
                    f.write(resource.bytes)
        return result


class ResourceBase(object):
    def __init__(self, finder, name):
        self.finder = finder
        self.name = name


class Resource(ResourceBase):
    
    is_container = False        

    def as_stream(self):
        
        return self.finder.get_stream(self)

    @cached_property
    def file_path(self):
        global cache
        if cache is None:
            cache = ResourceCache()
        return cache.get(self)

    @cached_property
    def bytes(self):
        return self.finder.get_bytes(self)

    @cached_property
    def size(self):
        return self.finder.get_size(self)


class ResourceContainer(ResourceBase):
    is_container = True     

    @cached_property
    def resources(self):
        return self.finder.get_resources(self)


class ResourceFinder(object):
    

    if sys.platform.startswith('java'):
        skipped_extensions = ('.pyc', '.pyo', '.class')
    else:
        skipped_extensions = ('.pyc', '.pyo')

    def __init__(self, module):
        self.module = module
        self.loader = getattr(module, '__loader__', None)
        self.base = os.path.dirname(getattr(module, '__file__', ''))

    def _adjust_path(self, path):
        return os.path.realpath(path)

    def _make_path(self, resource_name):
        
        
        if isinstance(resource_name, bytes):    
            sep = b'/'
        else:
            sep = '/'
        parts = resource_name.split(sep)
        parts.insert(0, self.base)
        result = os.path.join(*parts)
        return self._adjust_path(result)

    def _find(self, path):
        return os.path.exists(path)

    def get_cache_info(self, resource):
        return None, resource.path

    def find(self, resource_name):
        path = self._make_path(resource_name)
        if not self._find(path):
            result = None
        else:
            if self._is_directory(path):
                result = ResourceContainer(self, resource_name)
            else:
                result = Resource(self, resource_name)
            result.path = path
        return result

    def get_stream(self, resource):
        return open(resource.path, 'rb')

    def get_bytes(self, resource):
        with open(resource.path, 'rb') as f:
            return f.read()

    def get_size(self, resource):
        return os.path.getsize(resource.path)

    def get_resources(self, resource):
        def allowed(f):
            return (f != '__pycache__' and not
                    f.endswith(self.skipped_extensions))
        return set([f for f in os.listdir(resource.path) if allowed(f)])

    def is_container(self, resource):
        return self._is_directory(resource.path)

    _is_directory = staticmethod(os.path.isdir)

    def iterator(self, resource_name):
        resource = self.find(resource_name)
        if resource is not None:
            todo = [resource]
            while todo:
                resource = todo.pop(0)
                yield resource
                if resource.is_container:
                    rname = resource.name
                    for name in resource.resources:
                        if not rname:
                            new_name = name
                        else:
                            new_name = '/'.join([rname, name])
                        child = self.find(new_name)
                        if child.is_container:
                            todo.append(child)
                        else:
                            yield child


class ZipResourceFinder(ResourceFinder):
    
    def __init__(self, module):
        super(ZipResourceFinder, self).__init__(module)
        archive = self.loader.archive
        self.prefix_len = 1 + len(archive)
        
        if hasattr(self.loader, '_files'):
            self._files = self.loader._files
        else:
            self._files = zipimport._zip_directory_cache[archive]
        self.index = sorted(self._files)

    def _adjust_path(self, path):
        return path

    def _find(self, path):
        path = path[self.prefix_len:]
        if path in self._files:
            result = True
        else:
            if path and path[-1] != os.sep:
                path = path + os.sep
            i = bisect.bisect(self.index, path)
            try:
                result = self.index[i].startswith(path)
            except IndexError:
                result = False
        if not result:
            logger.debug('_find failed: %r %r', path, self.loader.prefix)
        else:
            logger.debug('_find worked: %r %r', path, self.loader.prefix)
        return result

    def get_cache_info(self, resource):
        prefix = self.loader.archive
        path = resource.path[1 + len(prefix):]
        return prefix, path

    def get_bytes(self, resource):
        return self.loader.get_data(resource.path)

    def get_stream(self, resource):
        return io.BytesIO(self.get_bytes(resource))

    def get_size(self, resource):
        path = resource.path[self.prefix_len:]
        return self._files[path][3]

    def get_resources(self, resource):
        path = resource.path[self.prefix_len:]
        if path and path[-1] != os.sep:
            path += os.sep
        plen = len(path)
        result = set()
        i = bisect.bisect(self.index, path)
        while i < len(self.index):
            if not self.index[i].startswith(path):
                break
            s = self.index[i][plen:]
            result.add(s.split(os.sep, 1)[0])   
            i += 1
        return result

    def _is_directory(self, path):
        path = path[self.prefix_len:]
        if path and path[-1] != os.sep:
            path += os.sep
        i = bisect.bisect(self.index, path)
        try:
            result = self.index[i].startswith(path)
        except IndexError:
            result = False
        return result


_finder_registry = {
    type(None): ResourceFinder,
    zipimport.zipimporter: ZipResourceFinder
}

try:
    
    try:
        import _frozen_importlib_external as _fi
    except ImportError:
        import _frozen_importlib as _fi
    _finder_registry[_fi.SourceFileLoader] = ResourceFinder
    _finder_registry[_fi.FileFinder] = ResourceFinder
    
    _finder_registry[_fi.SourcelessFileLoader] = ResourceFinder
    del _fi
except (ImportError, AttributeError):
    pass


def register_finder(loader, finder_maker):
    _finder_registry[type(loader)] = finder_maker


_finder_cache = {}


def finder(package):
    
    if package in _finder_cache:
        result = _finder_cache[package]
    else:
        if package not in sys.modules:
            __import__(package)
        module = sys.modules[package]
        path = getattr(module, '__path__', None)
        if path is None:
            raise DistlibException('You cannot get a finder for a module, '
                                   'only for a package')
        loader = getattr(module, '__loader__', None)
        finder_maker = _finder_registry.get(type(loader))
        if finder_maker is None:
            raise DistlibException('Unable to locate finder for %r' % package)
        result = finder_maker(module)
        _finder_cache[package] = result
    return result


_dummy_module = types.ModuleType(str('__dummy__'))


def finder_for_path(path):
    
    result = None
    
    pkgutil.get_importer(path)
    loader = sys.path_importer_cache.get(path)
    finder = _finder_registry.get(type(loader))
    if finder:
        module = _dummy_module
        module.__file__ = os.path.join(path, '')
        module.__loader__ = loader
        result = finder(module)
    return result







from io import BytesIO
import logging
import os
import re
import struct
import sys
import time
from zipfile import ZipInfo

from .compat import sysconfig, detect_encoding, ZipFile
from .resources import finder
from .util import (FileOperator, get_export_entry, convert_path, get_executable, get_platform, in_venv)

logger = logging.getLogger(__name__)

_DEFAULT_MANIFEST = .strip()


FIRST_LINE_RE = re.compile(b'^
SCRIPT_TEMPLATE = r









if os.name == 'nt' or (os.name == 'java' and os._name == 'nt'):
    
    
    DISTLIB_PACKAGE = __name__.rsplit('.', 1)[0]

    WRAPPERS = {
        r.name: r.bytes
        for r in finder(DISTLIB_PACKAGE).iterator("""")
        if r.name.endswith("".exe"")
    }


def enquote_executable(executable):
    if ' ' in executable:
        
        
        
        
        if executable.startswith('/usr/bin/env '):
            env, _executable = executable.split(' ', 1)
            if ' ' in _executable and not _executable.startswith('""'):
                executable = '%s ""%s""' % (env, _executable)
        else:
            if not executable.startswith('""'):
                executable = '""%s""' % executable
    return executable



_enquote_executable = enquote_executable


class ScriptMaker(object):
    
    script_template = SCRIPT_TEMPLATE

    executable = None  

    def __init__(self, source_dir, target_dir, add_launchers=True, dry_run=False, fileop=None):
        self.source_dir = source_dir
        self.target_dir = target_dir
        self.add_launchers = add_launchers
        self.force = False
        self.clobber = False
        
        self.set_mode = (os.name == 'posix') or (os.name == 'java' and os._name == 'posix')
        self.variants = set(('', 'X.Y'))
        self._fileop = fileop or FileOperator(dry_run)

        self._is_nt = os.name == 'nt' or (os.name == 'java' and os._name == 'nt')
        self.version_info = sys.version_info

    def _get_alternate_executable(self, executable, options):
        if options.get('gui', False) and self._is_nt:  
            dn, fn = os.path.split(executable)
            fn = fn.replace('python', 'pythonw')
            executable = os.path.join(dn, fn)
        return executable

    if sys.platform.startswith('java'):  

        def _is_shell(self, executable):
            
            try:
                with open(executable) as fp:
                    return fp.read(2) == '
            except (OSError, IOError):
                logger.warning('Failed to open %s', executable)
                return False

        def _fix_jython_executable(self, executable):
            if self._is_shell(executable):
                
                import java

                if java.lang.System.getProperty('os.name') == 'Linux':
                    return executable
            elif executable.lower().endswith('jython.exe'):
                
                return executable
            return '/usr/bin/env %s' % executable

    def _build_shebang(self, executable, post_interp):
        
        if os.name != 'posix':
            simple_shebang = True
        elif getattr(sys, ""cross_compiling"", False):
            
            
            
            
            simple_shebang = False
        else:
            
            shebang_length = len(executable) + len(post_interp) + 3
            if sys.platform == 'darwin':
                max_shebang_length = 512
            else:
                max_shebang_length = 127
            simple_shebang = ((b' ' not in executable) and (shebang_length <= max_shebang_length))

        if simple_shebang:
            result = b'
        else:
            result = b'
            result += b""\n""
        return result

    def _get_shebang(self, encoding, post_interp=b'', options=None):
        enquote = True
        if self.executable:
            executable = self.executable
            enquote = False  
        elif not sysconfig.is_python_build():
            executable = get_executable()
        elif in_venv():  
            executable = os.path.join(sysconfig.get_path('scripts'), 'python%s' % sysconfig.get_config_var('EXE'))
        else:  
            if os.name == 'nt':
                
                
                executable = os.path.join(sysconfig.get_config_var('BINDIR'),
                                          'python%s' % (sysconfig.get_config_var('EXE')))
            else:
                executable = os.path.join(
                    sysconfig.get_config_var('BINDIR'),
                    'python%s%s' % (sysconfig.get_config_var('VERSION'), sysconfig.get_config_var('EXE')))
        if options:
            executable = self._get_alternate_executable(executable, options)

        if sys.platform.startswith('java'):  
            executable = self._fix_jython_executable(executable)

        
        
        
        
        
        
        
        

        
        
        if enquote:
            executable = enquote_executable(executable)
        
        
        executable = executable.encode('utf-8')
        
        if (sys.platform == 'cli' and '-X:Frames' not in post_interp and
                '-X:FullFrames' not in post_interp):  
            post_interp += b' -X:Frames'
        shebang = self._build_shebang(executable, post_interp)
        
        
        
        
        
        try:
            shebang.decode('utf-8')
        except UnicodeDecodeError:  
            raise ValueError('The shebang (%r) is not decodable from utf-8' % shebang)
        
        
        
        if encoding != 'utf-8':
            try:
                shebang.decode(encoding)
            except UnicodeDecodeError:  
                raise ValueError('The shebang (%r) is not decodable '
                                 'from the script encoding (%r)' % (shebang, encoding))
        return shebang

    def _get_script_text(self, entry):
        return self.script_template % dict(
            module=entry.prefix, import_name=entry.suffix.split('.')[0], func=entry.suffix)

    manifest = _DEFAULT_MANIFEST

    def get_manifest(self, exename):
        base = os.path.basename(exename)
        return self.manifest % base

    def _write_script(self, names, shebang, script_bytes, filenames, ext):
        use_launcher = self.add_launchers and self._is_nt
        if not use_launcher:
            script_bytes = shebang + script_bytes
        else:  
            if ext == 'py':
                launcher = self._get_launcher('t')
            else:
                launcher = self._get_launcher('w')
            stream = BytesIO()
            with ZipFile(stream, 'w') as zf:
                source_date_epoch = os.environ.get('SOURCE_DATE_EPOCH')
                if source_date_epoch:
                    date_time = time.gmtime(int(source_date_epoch))[:6]
                    zinfo = ZipInfo(filename='__main__.py', date_time=date_time)
                    zf.writestr(zinfo, script_bytes)
                else:
                    zf.writestr('__main__.py', script_bytes)
            zip_data = stream.getvalue()
            script_bytes = launcher + shebang + zip_data
        for name in names:
            outname = os.path.join(self.target_dir, name)
            if use_launcher:  
                n, e = os.path.splitext(outname)
                if e.startswith('.py'):
                    outname = n
                outname = '%s.exe' % outname
                try:
                    self._fileop.write_binary_file(outname, script_bytes)
                except Exception:
                    
                    logger.warning('Failed to write executable - trying to '
                                   'use .deleteme logic')
                    dfname = '%s.deleteme' % outname
                    if os.path.exists(dfname):
                        os.remove(dfname)  
                    os.rename(outname, dfname)  
                    self._fileop.write_binary_file(outname, script_bytes)
                    logger.debug('Able to replace executable using '
                                 '.deleteme logic')
                    try:
                        os.remove(dfname)
                    except Exception:
                        pass  
            else:
                if self._is_nt and not outname.endswith('.' + ext):  
                    outname = '%s.%s' % (outname, ext)
                if os.path.exists(outname) and not self.clobber:
                    logger.warning('Skipping existing file %s', outname)
                    continue
                self._fileop.write_binary_file(outname, script_bytes)
                if self.set_mode:
                    self._fileop.set_executable_mode([outname])
            filenames.append(outname)

    variant_separator = '-'

    def get_script_filenames(self, name):
        result = set()
        if '' in self.variants:
            result.add(name)
        if 'X' in self.variants:
            result.add('%s%s' % (name, self.version_info[0]))
        if 'X.Y' in self.variants:
            result.add('%s%s%s.%s' % (name, self.variant_separator, self.version_info[0], self.version_info[1]))
        return result

    def _make_script(self, entry, filenames, options=None):
        post_interp = b''
        if options:
            args = options.get('interpreter_args', [])
            if args:
                args = ' %s' % ' '.join(args)
                post_interp = args.encode('utf-8')
        shebang = self._get_shebang('utf-8', post_interp, options=options)
        script = self._get_script_text(entry).encode('utf-8')
        scriptnames = self.get_script_filenames(entry.name)
        if options and options.get('gui', False):
            ext = 'pyw'
        else:
            ext = 'py'
        self._write_script(scriptnames, shebang, script, filenames, ext)

    def _copy_script(self, script, filenames):
        adjust = False
        script = os.path.join(self.source_dir, convert_path(script))
        outname = os.path.join(self.target_dir, os.path.basename(script))
        if not self.force and not self._fileop.newer(script, outname):
            logger.debug('not copying %s (up-to-date)', script)
            return

        
        
        
        try:
            f = open(script, 'rb')
        except IOError:  
            if not self.dry_run:
                raise
            f = None
        else:
            first_line = f.readline()
            if not first_line:  
                logger.warning('%s is an empty file (skipping)', script)
                return

            match = FIRST_LINE_RE.match(first_line.replace(b'\r\n', b'\n'))
            if match:
                adjust = True
                post_interp = match.group(1) or b''

        if not adjust:
            if f:
                f.close()
            self._fileop.copy_file(script, outname)
            if self.set_mode:
                self._fileop.set_executable_mode([outname])
            filenames.append(outname)
        else:
            logger.info('copying and adjusting %s -> %s', script, self.target_dir)
            if not self._fileop.dry_run:
                encoding, lines = detect_encoding(f.readline)
                f.seek(0)
                shebang = self._get_shebang(encoding, post_interp)
                if b'pythonw' in first_line:  
                    ext = 'pyw'
                else:
                    ext = 'py'
                n = os.path.basename(outname)
                self._write_script([n], shebang, f.read(), filenames, ext)
            if f:
                f.close()

    @property
    def dry_run(self):
        return self._fileop.dry_run

    @dry_run.setter
    def dry_run(self, value):
        self._fileop.dry_run = value

    if os.name == 'nt' or (os.name == 'java' and os._name == 'nt'):  
        
        

        def _get_launcher(self, kind):
            if struct.calcsize('P') == 8:  
                bits = '64'
            else:
                bits = '32'
            platform_suffix = '-arm' if get_platform() == 'win-arm64' else ''
            name = '%s%s%s.exe' % (kind, bits, platform_suffix)
            if name not in WRAPPERS:
                msg = ('Unable to find resource %s in package %s' %
                       (name, DISTLIB_PACKAGE))
                raise ValueError(msg)
            return WRAPPERS[name]

    

    def make(self, specification, options=None):
        
        filenames = []
        entry = get_export_entry(specification)
        if entry is None:
            self._copy_script(specification, filenames)
        else:
            self._make_script(entry, filenames, options=options)
        return filenames

    def make_multiple(self, specifications, options=None):
        
        filenames = []
        for specification in specifications:
            filenames.extend(self.make(specification, options))
        return filenames





import codecs
from collections import deque
import contextlib
import csv
from glob import iglob as std_iglob
import io
import json
import logging
import os
import py_compile
import re
import socket
try:
    import ssl
except ImportError:  
    ssl = None
import subprocess
import sys
import tarfile
import tempfile
import textwrap

try:
    import threading
except ImportError:  
    import dummy_threading as threading
import time

from . import DistlibException
from .compat import (string_types, text_type, shutil, raw_input, StringIO, cache_from_source, urlopen, urljoin, httplib,
                     xmlrpclib, HTTPHandler, BaseConfigurator, valid_ident, Container, configparser, URLError, ZipFile,
                     fsdecode, unquote, urlparse)

logger = logging.getLogger(__name__)





IDENTIFIER = re.compile(r'^([\w\.-]+)\s*')
VERSION_IDENTIFIER = re.compile(r'^([\w\.*+-]+)\s*')
COMPARE_OP = re.compile(r'^(<=?|>=?|={2,3}|[~!]=)\s*')
MARKER_OP = re.compile(r'^((<=?)|(>=?)|={2,3}|[~!]=|in|not\s+in)\s*')
OR = re.compile(r'^or\b\s*')
AND = re.compile(r'^and\b\s*')
NON_SPACE = re.compile(r'(\S+)\s*')
STRING_CHUNK = re.compile(r'([\s\w\.{}()*+


def parse_marker(marker_string):
    

    def marker_var(remaining):
        
        m = IDENTIFIER.match(remaining)
        if m:
            result = m.groups()[0]
            remaining = remaining[m.end():]
        elif not remaining:
            raise SyntaxError('unexpected end of input')
        else:
            q = remaining[0]
            if q not in '\'""':
                raise SyntaxError('invalid expression: %s' % remaining)
            oq = '\'""'.replace(q, '')
            remaining = remaining[1:]
            parts = [q]
            while remaining:
                
                if remaining[0] == q:
                    break
                elif remaining[0] == oq:
                    parts.append(oq)
                    remaining = remaining[1:]
                else:
                    m = STRING_CHUNK.match(remaining)
                    if not m:
                        raise SyntaxError('error in string literal: %s' % remaining)
                    parts.append(m.groups()[0])
                    remaining = remaining[m.end():]
            else:
                s = ''.join(parts)
                raise SyntaxError('unterminated string: %s' % s)
            parts.append(q)
            result = ''.join(parts)
            remaining = remaining[1:].lstrip()  
        return result, remaining

    def marker_expr(remaining):
        if remaining and remaining[0] == '(':
            result, remaining = marker(remaining[1:].lstrip())
            if remaining[0] != ')':
                raise SyntaxError('unterminated parenthesis: %s' % remaining)
            remaining = remaining[1:].lstrip()
        else:
            lhs, remaining = marker_var(remaining)
            while remaining:
                m = MARKER_OP.match(remaining)
                if not m:
                    break
                op = m.groups()[0]
                remaining = remaining[m.end():]
                rhs, remaining = marker_var(remaining)
                lhs = {'op': op, 'lhs': lhs, 'rhs': rhs}
            result = lhs
        return result, remaining

    def marker_and(remaining):
        lhs, remaining = marker_expr(remaining)
        while remaining:
            m = AND.match(remaining)
            if not m:
                break
            remaining = remaining[m.end():]
            rhs, remaining = marker_expr(remaining)
            lhs = {'op': 'and', 'lhs': lhs, 'rhs': rhs}
        return lhs, remaining

    def marker(remaining):
        lhs, remaining = marker_and(remaining)
        while remaining:
            m = OR.match(remaining)
            if not m:
                break
            remaining = remaining[m.end():]
            rhs, remaining = marker_and(remaining)
            lhs = {'op': 'or', 'lhs': lhs, 'rhs': rhs}
        return lhs, remaining

    return marker(marker_string)


def parse_requirement(req):
    
    remaining = req.strip()
    if not remaining or remaining.startswith('
        return None
    m = IDENTIFIER.match(remaining)
    if not m:
        raise SyntaxError('name expected: %s' % remaining)
    distname = m.groups()[0]
    remaining = remaining[m.end():]
    extras = mark_expr = versions = uri = None
    if remaining and remaining[0] == '[':
        i = remaining.find(']', 1)
        if i < 0:
            raise SyntaxError('unterminated extra: %s' % remaining)
        s = remaining[1:i]
        remaining = remaining[i + 1:].lstrip()
        extras = []
        while s:
            m = IDENTIFIER.match(s)
            if not m:
                raise SyntaxError('malformed extra: %s' % s)
            extras.append(m.groups()[0])
            s = s[m.end():]
            if not s:
                break
            if s[0] != ',':
                raise SyntaxError('comma expected in extras: %s' % s)
            s = s[1:].lstrip()
        if not extras:
            extras = None
    if remaining:
        if remaining[0] == '@':
            
            remaining = remaining[1:].lstrip()
            m = NON_SPACE.match(remaining)
            if not m:
                raise SyntaxError('invalid URI: %s' % remaining)
            uri = m.groups()[0]
            t = urlparse(uri)
            
            
            
            
            if not (t.scheme and t.netloc):
                raise SyntaxError('Invalid URL: %s' % uri)
            remaining = remaining[m.end():].lstrip()
        else:

            def get_versions(ver_remaining):
                
                m = COMPARE_OP.match(ver_remaining)
                versions = None
                if m:
                    versions = []
                    while True:
                        op = m.groups()[0]
                        ver_remaining = ver_remaining[m.end():]
                        m = VERSION_IDENTIFIER.match(ver_remaining)
                        if not m:
                            raise SyntaxError('invalid version: %s' % ver_remaining)
                        v = m.groups()[0]
                        versions.append((op, v))
                        ver_remaining = ver_remaining[m.end():]
                        if not ver_remaining or ver_remaining[0] != ',':
                            break
                        ver_remaining = ver_remaining[1:].lstrip()
                        
                        
                        if not ver_remaining:
                            break
                        m = COMPARE_OP.match(ver_remaining)
                        if not m:
                            raise SyntaxError('invalid constraint: %s' % ver_remaining)
                    if not versions:
                        versions = None
                return versions, ver_remaining

            if remaining[0] != '(':
                versions, remaining = get_versions(remaining)
            else:
                i = remaining.find(')', 1)
                if i < 0:
                    raise SyntaxError('unterminated parenthesis: %s' % remaining)
                s = remaining[1:i]
                remaining = remaining[i + 1:].lstrip()
                
                
                
                if COMPARE_OP.match(s):
                    versions, _ = get_versions(s)
                else:
                    m = VERSION_IDENTIFIER.match(s)
                    if not m:
                        raise SyntaxError('invalid constraint: %s' % s)
                    v = m.groups()[0]
                    s = s[m.end():].lstrip()
                    if s:
                        raise SyntaxError('invalid constraint: %s' % s)
                    versions = [('~=', v)]

    if remaining:
        if remaining[0] != ';':
            raise SyntaxError('invalid requirement: %s' % remaining)
        remaining = remaining[1:].lstrip()

        mark_expr, remaining = parse_marker(remaining)

    if remaining and remaining[0] != '
        raise SyntaxError('unexpected trailing data: %s' % remaining)

    if not versions:
        rs = distname
    else:
        rs = '%s %s' % (distname, ', '.join(['%s %s' % con for con in versions]))
    return Container(name=distname, extras=extras, constraints=versions, marker=mark_expr, url=uri, requirement=rs)


def get_resources_dests(resources_root, rules):
    

    def get_rel_path(root, path):
        
        root = root.replace(os.path.sep, '/')
        path = path.replace(os.path.sep, '/')
        assert path.startswith(root)
        return path[len(root):].lstrip('/')

    destinations = {}
    for base, suffix, dest in rules:
        prefix = os.path.join(resources_root, base)
        for abs_base in iglob(prefix):
            abs_glob = os.path.join(abs_base, suffix)
            for abs_path in iglob(abs_glob):
                resource_file = get_rel_path(resources_root, abs_path)
                if dest is None:  
                    destinations.pop(resource_file, None)
                else:
                    rel_path = get_rel_path(abs_base, abs_path)
                    rel_dest = dest.replace(os.path.sep, '/').rstrip('/')
                    destinations[resource_file] = rel_dest + '/' + rel_path
    return destinations


def in_venv():
    if hasattr(sys, 'real_prefix'):
        
        result = True
    else:
        
        result = sys.prefix != getattr(sys, 'base_prefix', sys.prefix)
    return result


def get_executable():
    
    
    
    
    
    
    
    
    
    
    
    result = sys.executable
    if not isinstance(result, text_type):
        result = fsdecode(result)
    return result


def proceed(prompt, allowed_chars, error_prompt=None, default=None):
    p = prompt
    while True:
        s = raw_input(p)
        p = prompt
        if not s and default:
            s = default
        if s:
            c = s[0].lower()
            if c in allowed_chars:
                break
            if error_prompt:
                p = '%c: %s\n%s' % (c, error_prompt, prompt)
    return c


def extract_by_key(d, keys):
    if isinstance(keys, string_types):
        keys = keys.split()
    result = {}
    for key in keys:
        if key in d:
            result[key] = d[key]
    return result


def read_exports(stream):
    if sys.version_info[0] >= 3:
        
        stream = codecs.getreader('utf-8')(stream)
    
    data = stream.read()
    stream = StringIO(data)
    try:
        jdata = json.load(stream)
        result = jdata['extensions']['python.exports']['exports']
        for group, entries in result.items():
            for k, v in entries.items():
                s = '%s = %s' % (k, v)
                entry = get_export_entry(s)
                assert entry is not None
                entries[k] = entry
        return result
    except Exception:
        stream.seek(0, 0)

    def read_stream(cp, stream):
        if hasattr(cp, 'read_file'):
            cp.read_file(stream)
        else:
            cp.readfp(stream)

    cp = configparser.ConfigParser()
    try:
        read_stream(cp, stream)
    except configparser.MissingSectionHeaderError:
        stream.close()
        data = textwrap.dedent(data)
        stream = StringIO(data)
        read_stream(cp, stream)

    result = {}
    for key in cp.sections():
        result[key] = entries = {}
        for name, value in cp.items(key):
            s = '%s = %s' % (name, value)
            entry = get_export_entry(s)
            assert entry is not None
            
            entries[name] = entry
    return result


def write_exports(exports, stream):
    if sys.version_info[0] >= 3:
        
        stream = codecs.getwriter('utf-8')(stream)
    cp = configparser.ConfigParser()
    for k, v in exports.items():
        
        cp.add_section(k)
        for entry in v.values():
            if entry.suffix is None:
                s = entry.prefix
            else:
                s = '%s:%s' % (entry.prefix, entry.suffix)
            if entry.flags:
                s = '%s [%s]' % (s, ', '.join(entry.flags))
            cp.set(k, entry.name, s)
    cp.write(stream)


@contextlib.contextmanager
def tempdir():
    td = tempfile.mkdtemp()
    try:
        yield td
    finally:
        shutil.rmtree(td)


@contextlib.contextmanager
def chdir(d):
    cwd = os.getcwd()
    try:
        os.chdir(d)
        yield
    finally:
        os.chdir(cwd)


@contextlib.contextmanager
def socket_timeout(seconds=15):
    cto = socket.getdefaulttimeout()
    try:
        socket.setdefaulttimeout(seconds)
        yield
    finally:
        socket.setdefaulttimeout(cto)


class cached_property(object):

    def __init__(self, func):
        self.func = func
        
        

    def __get__(self, obj, cls=None):
        if obj is None:
            return self
        value = self.func(obj)
        object.__setattr__(obj, self.func.__name__, value)
        
        return value


def convert_path(pathname):
    
    if os.sep == '/':
        return pathname
    if not pathname:
        return pathname
    if pathname[0] == '/':
        raise ValueError(""path '%s' cannot be absolute"" % pathname)
    if pathname[-1] == '/':
        raise ValueError(""path '%s' cannot end with '/'"" % pathname)

    paths = pathname.split('/')
    while os.curdir in paths:
        paths.remove(os.curdir)
    if not paths:
        return os.curdir
    return os.path.join(*paths)


class FileOperator(object):

    def __init__(self, dry_run=False):
        self.dry_run = dry_run
        self.ensured = set()
        self._init_record()

    def _init_record(self):
        self.record = False
        self.files_written = set()
        self.dirs_created = set()

    def record_as_written(self, path):
        if self.record:
            self.files_written.add(path)

    def newer(self, source, target):
        
        if not os.path.exists(source):
            raise DistlibException(""file '%r' does not exist"" % os.path.abspath(source))
        if not os.path.exists(target):
            return True

        return os.stat(source).st_mtime > os.stat(target).st_mtime

    def copy_file(self, infile, outfile, check=True):
        
        self.ensure_dir(os.path.dirname(outfile))
        logger.info('Copying %s to %s', infile, outfile)
        if not self.dry_run:
            msg = None
            if check:
                if os.path.islink(outfile):
                    msg = '%s is a symlink' % outfile
                elif os.path.exists(outfile) and not os.path.isfile(outfile):
                    msg = '%s is a non-regular file' % outfile
            if msg:
                raise ValueError(msg + ' which would be overwritten')
            shutil.copyfile(infile, outfile)
        self.record_as_written(outfile)

    def copy_stream(self, instream, outfile, encoding=None):
        assert not os.path.isdir(outfile)
        self.ensure_dir(os.path.dirname(outfile))
        logger.info('Copying stream %s to %s', instream, outfile)
        if not self.dry_run:
            if encoding is None:
                outstream = open(outfile, 'wb')
            else:
                outstream = codecs.open(outfile, 'w', encoding=encoding)
            try:
                shutil.copyfileobj(instream, outstream)
            finally:
                outstream.close()
        self.record_as_written(outfile)

    def write_binary_file(self, path, data):
        self.ensure_dir(os.path.dirname(path))
        if not self.dry_run:
            if os.path.exists(path):
                os.remove(path)
            with open(path, 'wb') as f:
                f.write(data)
        self.record_as_written(path)

    def write_text_file(self, path, data, encoding):
        self.write_binary_file(path, data.encode(encoding))

    def set_mode(self, bits, mask, files):
        if os.name == 'posix' or (os.name == 'java' and os._name == 'posix'):
            
            
            for f in files:
                if self.dry_run:
                    logger.info(""changing mode of %s"", f)
                else:
                    mode = (os.stat(f).st_mode | bits) & mask
                    logger.info(""changing mode of %s to %o"", f, mode)
                    os.chmod(f, mode)

    set_executable_mode = lambda s, f: s.set_mode(0o555, 0o7777, f)

    def ensure_dir(self, path):
        path = os.path.abspath(path)
        if path not in self.ensured and not os.path.exists(path):
            self.ensured.add(path)
            d, f = os.path.split(path)
            self.ensure_dir(d)
            logger.info('Creating %s' % path)
            if not self.dry_run:
                os.mkdir(path)
            if self.record:
                self.dirs_created.add(path)

    def byte_compile(self, path, optimize=False, force=False, prefix=None, hashed_invalidation=False):
        dpath = cache_from_source(path, not optimize)
        logger.info('Byte-compiling %s to %s', path, dpath)
        if not self.dry_run:
            if force or self.newer(path, dpath):
                if not prefix:
                    diagpath = None
                else:
                    assert path.startswith(prefix)
                    diagpath = path[len(prefix):]
            compile_kwargs = {}
            if hashed_invalidation and hasattr(py_compile, 'PycInvalidationMode'):
                if not isinstance(hashed_invalidation, py_compile.PycInvalidationMode):
                    hashed_invalidation = py_compile.PycInvalidationMode.CHECKED_HASH
                compile_kwargs['invalidation_mode'] = hashed_invalidation
            py_compile.compile(path, dpath, diagpath, True, **compile_kwargs)  
        self.record_as_written(dpath)
        return dpath

    def ensure_removed(self, path):
        if os.path.exists(path):
            if os.path.isdir(path) and not os.path.islink(path):
                logger.debug('Removing directory tree at %s', path)
                if not self.dry_run:
                    shutil.rmtree(path)
                if self.record:
                    if path in self.dirs_created:
                        self.dirs_created.remove(path)
            else:
                if os.path.islink(path):
                    s = 'link'
                else:
                    s = 'file'
                logger.debug('Removing %s %s', s, path)
                if not self.dry_run:
                    os.remove(path)
                if self.record:
                    if path in self.files_written:
                        self.files_written.remove(path)

    def is_writable(self, path):
        result = False
        while not result:
            if os.path.exists(path):
                result = os.access(path, os.W_OK)
                break
            parent = os.path.dirname(path)
            if parent == path:
                break
            path = parent
        return result

    def commit(self):
        
        assert self.record
        result = self.files_written, self.dirs_created
        self._init_record()
        return result

    def rollback(self):
        if not self.dry_run:
            for f in list(self.files_written):
                if os.path.exists(f):
                    os.remove(f)
            
            
            
            dirs = sorted(self.dirs_created, reverse=True)
            for d in dirs:
                flist = os.listdir(d)
                if flist:
                    assert flist == ['__pycache__']
                    sd = os.path.join(d, flist[0])
                    os.rmdir(sd)
                os.rmdir(d)  
        self._init_record()


def resolve(module_name, dotted_path):
    if module_name in sys.modules:
        mod = sys.modules[module_name]
    else:
        mod = __import__(module_name)
    if dotted_path is None:
        result = mod
    else:
        parts = dotted_path.split('.')
        result = getattr(mod, parts.pop(0))
        for p in parts:
            result = getattr(result, p)
    return result


class ExportEntry(object):

    def __init__(self, name, prefix, suffix, flags):
        self.name = name
        self.prefix = prefix
        self.suffix = suffix
        self.flags = flags

    @cached_property
    def value(self):
        return resolve(self.prefix, self.suffix)

    def __repr__(self):  
        return '<ExportEntry %s = %s:%s %s>' % (self.name, self.prefix, self.suffix, self.flags)

    def __eq__(self, other):
        if not isinstance(other, ExportEntry):
            result = False
        else:
            result = (self.name == other.name and self.prefix == other.prefix and self.suffix == other.suffix and
                      self.flags == other.flags)
        return result

    __hash__ = object.__hash__


ENTRY_RE = re.compile(
    r, re.VERBOSE)


def get_export_entry(specification):
    m = ENTRY_RE.search(specification)
    if not m:
        result = None
        if '[' in specification or ']' in specification:
            raise DistlibException(""Invalid specification ""
                                   ""'%s'"" % specification)
    else:
        d = m.groupdict()
        name = d['name']
        path = d['callable']
        colons = path.count(':')
        if colons == 0:
            prefix, suffix = path, None
        else:
            if colons != 1:
                raise DistlibException(""Invalid specification ""
                                       ""'%s'"" % specification)
            prefix, suffix = path.split(':')
        flags = d['flags']
        if flags is None:
            if '[' in specification or ']' in specification:
                raise DistlibException(""Invalid specification ""
                                       ""'%s'"" % specification)
            flags = []
        else:
            flags = [f.strip() for f in flags.split(',')]
        result = ExportEntry(name, prefix, suffix, flags)
    return result


def get_cache_base(suffix=None):
    
    if suffix is None:
        suffix = '.distlib'
    if os.name == 'nt' and 'LOCALAPPDATA' in os.environ:
        result = os.path.expandvars('$localappdata')
    else:
        
        result = os.path.expanduser('~')
    
    
    if os.path.isdir(result):
        usable = os.access(result, os.W_OK)
        if not usable:
            logger.warning('Directory exists but is not writable: %s', result)
    else:
        try:
            os.makedirs(result)
            usable = True
        except OSError:
            logger.warning('Unable to create %s', result, exc_info=True)
            usable = False
    if not usable:
        result = tempfile.mkdtemp()
        logger.warning('Default location unusable, using %s', result)
    return os.path.join(result, suffix)


def path_to_cache_dir(path, use_abspath=True):
    
    d, p = os.path.splitdrive(os.path.abspath(path) if use_abspath else path)
    if d:
        d = d.replace(':', '---')
    p = p.replace(os.sep, '--')
    return d + p + '.cache'


def ensure_slash(s):
    if not s.endswith('/'):
        return s + '/'
    return s


def parse_credentials(netloc):
    username = password = None
    if '@' in netloc:
        prefix, netloc = netloc.rsplit('@', 1)
        if ':' not in prefix:
            username = prefix
        else:
            username, password = prefix.split(':', 1)
    if username:
        username = unquote(username)
    if password:
        password = unquote(password)
    return username, password, netloc


def get_process_umask():
    result = os.umask(0o22)
    os.umask(result)
    return result


def is_string_sequence(seq):
    result = True
    i = None
    for i, s in enumerate(seq):
        if not isinstance(s, string_types):
            result = False
            break
    assert i is not None
    return result


PROJECT_NAME_AND_VERSION = re.compile('([a-z0-9_]+([.-][a-z_][a-z0-9_]*)*)-'
                                      '([a-z0-9_.+-]+)', re.I)
PYTHON_VERSION = re.compile(r'-py(\d\.?\d?)')


def split_filename(filename, project_name=None):
    
    result = None
    pyver = None
    filename = unquote(filename).replace(' ', '-')
    m = PYTHON_VERSION.search(filename)
    if m:
        pyver = m.group(1)
        filename = filename[:m.start()]
    if project_name and len(filename) > len(project_name) + 1:
        m = re.match(re.escape(project_name) + r'\b', filename)
        if m:
            n = m.end()
            result = filename[:n], filename[n + 1:], pyver
    if result is None:
        m = PROJECT_NAME_AND_VERSION.match(filename)
        if m:
            result = m.group(1), m.group(3), pyver
    return result



NAME_VERSION_RE = re.compile(r'(?P<name>[\w .-]+)\s*'
                             r'\(\s*(?P<ver>[^\s)]+)\)$')


def parse_name_and_version(p):
    
    m = NAME_VERSION_RE.match(p)
    if not m:
        raise DistlibException('Ill-formed name/version string: \'%s\'' % p)
    d = m.groupdict()
    return d['name'].strip().lower(), d['ver']


def get_extras(requested, available):
    result = set()
    requested = set(requested or [])
    available = set(available or [])
    if '*' in requested:
        requested.remove('*')
        result |= available
    for r in requested:
        if r == '-':
            result.add(r)
        elif r.startswith('-'):
            unwanted = r[1:]
            if unwanted not in available:
                logger.warning('undeclared extra: %s' % unwanted)
            if unwanted in result:
                result.remove(unwanted)
        else:
            if r not in available:
                logger.warning('undeclared extra: %s' % r)
            result.add(r)
    return result







def _get_external_data(url):
    result = {}
    try:
        
        
        
        resp = urlopen(url)
        headers = resp.info()
        ct = headers.get('Content-Type')
        if not ct.startswith('application/json'):
            logger.debug('Unexpected response for JSON request: %s', ct)
        else:
            reader = codecs.getreader('utf-8')(resp)
            
            
            result = json.load(reader)
    except Exception as e:
        logger.exception('Failed to get external data for %s: %s', url, e)
    return result


_external_data_base_url = 'https://www.red-dove.com/pypi/projects/'


def get_project_data(name):
    url = '%s/%s/project.json' % (name[0].upper(), name)
    url = urljoin(_external_data_base_url, url)
    result = _get_external_data(url)
    return result


def get_package_data(name, version):
    url = '%s/%s/package-%s.json' % (name[0].upper(), name, version)
    url = urljoin(_external_data_base_url, url)
    return _get_external_data(url)


class Cache(object):
    

    def __init__(self, base):
        
        
        
        if not os.path.isdir(base):  
            os.makedirs(base)
        if (os.stat(base).st_mode & 0o77) != 0:
            logger.warning('Directory \'%s\' is not private', base)
        self.base = os.path.abspath(os.path.normpath(base))

    def prefix_to_dir(self, prefix, use_abspath=True):
        
        return path_to_cache_dir(prefix, use_abspath=use_abspath)

    def clear(self):
        
        not_removed = []
        for fn in os.listdir(self.base):
            fn = os.path.join(self.base, fn)
            try:
                if os.path.islink(fn) or os.path.isfile(fn):
                    os.remove(fn)
                elif os.path.isdir(fn):
                    shutil.rmtree(fn)
            except Exception:
                not_removed.append(fn)
        return not_removed


class EventMixin(object):
    

    def __init__(self):
        self._subscribers = {}

    def add(self, event, subscriber, append=True):
        
        subs = self._subscribers
        if event not in subs:
            subs[event] = deque([subscriber])
        else:
            sq = subs[event]
            if append:
                sq.append(subscriber)
            else:
                sq.appendleft(subscriber)

    def remove(self, event, subscriber):
        
        subs = self._subscribers
        if event not in subs:
            raise ValueError('No subscribers: %r' % event)
        subs[event].remove(subscriber)

    def get_subscribers(self, event):
        
        return iter(self._subscribers.get(event, ()))

    def publish(self, event, *args, **kwargs):
        
        result = []
        for subscriber in self.get_subscribers(event):
            try:
                value = subscriber(event, *args, **kwargs)
            except Exception:
                logger.exception('Exception during event publication')
                value = None
            result.append(value)
        logger.debug('publish %s: args = %s, kwargs = %s, result = %s', event, args, kwargs, result)
        return result





class Sequencer(object):

    def __init__(self):
        self._preds = {}
        self._succs = {}
        self._nodes = set()  

    def add_node(self, node):
        self._nodes.add(node)

    def remove_node(self, node, edges=False):
        if node in self._nodes:
            self._nodes.remove(node)
        if edges:
            for p in set(self._preds.get(node, ())):
                self.remove(p, node)
            for s in set(self._succs.get(node, ())):
                self.remove(node, s)
            
            for k, v in list(self._preds.items()):
                if not v:
                    del self._preds[k]
            for k, v in list(self._succs.items()):
                if not v:
                    del self._succs[k]

    def add(self, pred, succ):
        assert pred != succ
        self._preds.setdefault(succ, set()).add(pred)
        self._succs.setdefault(pred, set()).add(succ)

    def remove(self, pred, succ):
        assert pred != succ
        try:
            preds = self._preds[succ]
            succs = self._succs[pred]
        except KeyError:  
            raise ValueError('%r not a successor of anything' % succ)
        try:
            preds.remove(pred)
            succs.remove(succ)
        except KeyError:  
            raise ValueError('%r not a successor of %r' % (succ, pred))

    def is_step(self, step):
        return (step in self._preds or step in self._succs or step in self._nodes)

    def get_steps(self, final):
        if not self.is_step(final):
            raise ValueError('Unknown: %r' % final)
        result = []
        todo = []
        seen = set()
        todo.append(final)
        while todo:
            step = todo.pop(0)
            if step in seen:
                
                
                
                
                
                if step != final:
                    result.remove(step)
                    result.append(step)
            else:
                seen.add(step)
                result.append(step)
                preds = self._preds.get(step, ())
                todo.extend(preds)
        return reversed(result)

    @property
    def strong_connections(self):
        
        index_counter = [0]
        stack = []
        lowlinks = {}
        index = {}
        result = []

        graph = self._succs

        def strongconnect(node):
            
            index[node] = index_counter[0]
            lowlinks[node] = index_counter[0]
            index_counter[0] += 1
            stack.append(node)

            
            try:
                successors = graph[node]
            except Exception:
                successors = []
            for successor in successors:
                if successor not in lowlinks:
                    
                    strongconnect(successor)
                    lowlinks[node] = min(lowlinks[node], lowlinks[successor])
                elif successor in stack:
                    
                    
                    lowlinks[node] = min(lowlinks[node], index[successor])

            
            if lowlinks[node] == index[node]:
                connected_component = []

                while True:
                    successor = stack.pop()
                    connected_component.append(successor)
                    if successor == node:
                        break
                component = tuple(connected_component)
                
                result.append(component)

        for node in graph:
            if node not in lowlinks:
                strongconnect(node)

        return result

    @property
    def dot(self):
        result = ['digraph G {']
        for succ in self._preds:
            preds = self._preds[succ]
            for pred in preds:
                result.append('  %s -> %s;' % (pred, succ))
        for node in self._nodes:
            result.append('  %s;' % node)
        result.append('}')
        return '\n'.join(result)






ARCHIVE_EXTENSIONS = ('.tar.gz', '.tar.bz2', '.tar', '.zip', '.tgz', '.tbz', '.whl')


def unarchive(archive_filename, dest_dir, format=None, check=True):

    def check_path(path):
        if not isinstance(path, text_type):
            path = path.decode('utf-8')
        p = os.path.abspath(os.path.join(dest_dir, path))
        if not p.startswith(dest_dir) or p[plen] != os.sep:
            raise ValueError('path outside destination: %r' % p)

    dest_dir = os.path.abspath(dest_dir)
    plen = len(dest_dir)
    archive = None
    if format is None:
        if archive_filename.endswith(('.zip', '.whl')):
            format = 'zip'
        elif archive_filename.endswith(('.tar.gz', '.tgz')):
            format = 'tgz'
            mode = 'r:gz'
        elif archive_filename.endswith(('.tar.bz2', '.tbz')):
            format = 'tbz'
            mode = 'r:bz2'
        elif archive_filename.endswith('.tar'):
            format = 'tar'
            mode = 'r'
        else:  
            raise ValueError('Unknown format for %r' % archive_filename)
    try:
        if format == 'zip':
            archive = ZipFile(archive_filename, 'r')
            if check:
                names = archive.namelist()
                for name in names:
                    check_path(name)
        else:
            archive = tarfile.open(archive_filename, mode)
            if check:
                names = archive.getnames()
                for name in names:
                    check_path(name)
        if format != 'zip' and sys.version_info[0] < 3:
            
            
            
            
            for tarinfo in archive.getmembers():
                if not isinstance(tarinfo.name, text_type):
                    tarinfo.name = tarinfo.name.decode('utf-8')

        
        
        
        def extraction_filter(member, path):
            
            
            try:
                return tarfile.tar_filter(member, path)
            except tarfile.FilterError as exc:
                raise ValueError(str(exc))

        archive.extraction_filter = extraction_filter

        archive.extractall(dest_dir)

    finally:
        if archive:
            archive.close()


def zip_dir(directory):
    
    result = io.BytesIO()
    dlen = len(directory)
    with ZipFile(result, ""w"") as zf:
        for root, dirs, files in os.walk(directory):
            for name in files:
                full = os.path.join(root, name)
                rel = root[dlen:]
                dest = os.path.join(rel, name)
                zf.write(full, dest)
    return result






UNITS = ('', 'K', 'M', 'G', 'T', 'P')


class Progress(object):
    unknown = 'UNKNOWN'

    def __init__(self, minval=0, maxval=100):
        assert maxval is None or maxval >= minval
        self.min = self.cur = minval
        self.max = maxval
        self.started = None
        self.elapsed = 0
        self.done = False

    def update(self, curval):
        assert self.min <= curval
        assert self.max is None or curval <= self.max
        self.cur = curval
        now = time.time()
        if self.started is None:
            self.started = now
        else:
            self.elapsed = now - self.started

    def increment(self, incr):
        assert incr >= 0
        self.update(self.cur + incr)

    def start(self):
        self.update(self.min)
        return self

    def stop(self):
        if self.max is not None:
            self.update(self.max)
        self.done = True

    @property
    def maximum(self):
        return self.unknown if self.max is None else self.max

    @property
    def percentage(self):
        if self.done:
            result = '100 %'
        elif self.max is None:
            result = ' ?? %'
        else:
            v = 100.0 * (self.cur - self.min) / (self.max - self.min)
            result = '%3d %%' % v
        return result

    def format_duration(self, duration):
        if (duration <= 0) and self.max is None or self.cur == self.min:
            result = '??:??:??'
        
        
        else:
            result = time.strftime('%H:%M:%S', time.gmtime(duration))
        return result

    @property
    def ETA(self):
        if self.done:
            prefix = 'Done'
            t = self.elapsed
            
        else:
            prefix = 'ETA '
            if self.max is None:
                t = -1
            elif self.elapsed == 0 or (self.cur == self.min):
                t = 0
            else:
                
                t = float(self.max - self.min)
                t /= self.cur - self.min
                t = (t - 1) * self.elapsed
        return '%s: %s' % (prefix, self.format_duration(t))

    @property
    def speed(self):
        if self.elapsed == 0:
            result = 0.0
        else:
            result = (self.cur - self.min) / self.elapsed
        for unit in UNITS:
            if result < 1000:
                break
            result /= 1000.0
        return '%d %sB/s' % (result, unit)






RICH_GLOB = re.compile(r'\{([^}]*)\}')
_CHECK_RECURSIVE_GLOB = re.compile(r'[^/\\,{]\*\*|\*\*[^/\\,}]')
_CHECK_MISMATCH_SET = re.compile(r'^[^{]*\}|\{[^}]*$')


def iglob(path_glob):
    
    if _CHECK_RECURSIVE_GLOB.search(path_glob):
        msg = 
        raise ValueError(msg % path_glob)
    if _CHECK_MISMATCH_SET.search(path_glob):
        msg = 
        raise ValueError(msg % path_glob)
    return _iglob(path_glob)


def _iglob(path_glob):
    rich_path_glob = RICH_GLOB.split(path_glob, 1)
    if len(rich_path_glob) > 1:
        assert len(rich_path_glob) == 3, rich_path_glob
        prefix, set, suffix = rich_path_glob
        for item in set.split(','):
            for path in _iglob(''.join((prefix, item, suffix))):
                yield path
    else:
        if '**' not in path_glob:
            for item in std_iglob(path_glob):
                yield item
        else:
            prefix, radical = path_glob.split('**', 1)
            if prefix == '':
                prefix = '.'
            if radical == '':
                radical = '*'
            else:
                
                radical = radical.lstrip('/')
                radical = radical.lstrip('\\')
            for path, dir, files in os.walk(prefix):
                path = os.path.normpath(path)
                for fn in _iglob(os.path.join(path, radical)):
                    yield fn


if ssl:
    from .compat import (HTTPSHandler as BaseHTTPSHandler, match_hostname, CertificateError)

    
    
    

    class HTTPSConnection(httplib.HTTPSConnection):
        ca_certs = None  
        check_domain = True  

        
        def connect(self):
            sock = socket.create_connection((self.host, self.port), self.timeout)
            if getattr(self, '_tunnel_host', False):
                self.sock = sock
                self._tunnel()

            context = ssl.SSLContext(ssl.PROTOCOL_SSLv23)
            if hasattr(ssl, 'OP_NO_SSLv2'):
                context.options |= ssl.OP_NO_SSLv2
            if getattr(self, 'cert_file', None):
                context.load_cert_chain(self.cert_file, self.key_file)
            kwargs = {}
            if self.ca_certs:
                context.verify_mode = ssl.CERT_REQUIRED
                context.load_verify_locations(cafile=self.ca_certs)
                if getattr(ssl, 'HAS_SNI', False):
                    kwargs['server_hostname'] = self.host

            self.sock = context.wrap_socket(sock, **kwargs)
            if self.ca_certs and self.check_domain:
                try:
                    match_hostname(self.sock.getpeercert(), self.host)
                    logger.debug('Host verified: %s', self.host)
                except CertificateError:  
                    self.sock.shutdown(socket.SHUT_RDWR)
                    self.sock.close()
                    raise

    class HTTPSHandler(BaseHTTPSHandler):

        def __init__(self, ca_certs, check_domain=True):
            BaseHTTPSHandler.__init__(self)
            self.ca_certs = ca_certs
            self.check_domain = check_domain

        def _conn_maker(self, *args, **kwargs):
            
            result = HTTPSConnection(*args, **kwargs)
            if self.ca_certs:
                result.ca_certs = self.ca_certs
                result.check_domain = self.check_domain
            return result

        def https_open(self, req):
            try:
                return self.do_open(self._conn_maker, req)
            except URLError as e:
                if 'certificate verify failed' in str(e.reason):
                    raise CertificateError('Unable to verify server certificate '
                                           'for %s' % req.host)
                else:
                    raise

    
    
    
    
    
    
    
    
    
    class HTTPSOnlyHandler(HTTPSHandler, HTTPHandler):

        def http_open(self, req):
            raise URLError('Unexpected HTTP request on what should be a secure '
                           'connection: %s' % req)





class Transport(xmlrpclib.Transport):

    def __init__(self, timeout, use_datetime=0):
        self.timeout = timeout
        xmlrpclib.Transport.__init__(self, use_datetime)

    def make_connection(self, host):
        h, eh, x509 = self.get_host_info(host)
        if not self._connection or host != self._connection[0]:
            self._extra_headers = eh
            self._connection = host, httplib.HTTPConnection(h)
        return self._connection[1]


if ssl:

    class SafeTransport(xmlrpclib.SafeTransport):

        def __init__(self, timeout, use_datetime=0):
            self.timeout = timeout
            xmlrpclib.SafeTransport.__init__(self, use_datetime)

        def make_connection(self, host):
            h, eh, kwargs = self.get_host_info(host)
            if not kwargs:
                kwargs = {}
            kwargs['timeout'] = self.timeout
            if not self._connection or host != self._connection[0]:
                self._extra_headers = eh
                self._connection = host, httplib.HTTPSConnection(h, None, **kwargs)
            return self._connection[1]


class ServerProxy(xmlrpclib.ServerProxy):

    def __init__(self, uri, **kwargs):
        self.timeout = timeout = kwargs.pop('timeout', None)
        
        
        if timeout is not None:
            
            scheme = urlparse(uri)[0]
            use_datetime = kwargs.get('use_datetime', 0)
            if scheme == 'https':
                tcls = SafeTransport
            else:
                tcls = Transport
            kwargs['transport'] = t = tcls(timeout, use_datetime=use_datetime)
            self.transport = t
        xmlrpclib.ServerProxy.__init__(self, uri, **kwargs)








def _csv_open(fn, mode, **kwargs):
    if sys.version_info[0] < 3:
        mode += 'b'
    else:
        kwargs['newline'] = ''
        
        
        kwargs['encoding'] = 'utf-8'
    return open(fn, mode, **kwargs)


class CSVBase(object):
    defaults = {
        'delimiter': str(','),  
        'quotechar': str('""'),  
        'lineterminator': str('\n')  
    }

    def __enter__(self):
        return self

    def __exit__(self, *exc_info):
        self.stream.close()


class CSVReader(CSVBase):

    def __init__(self, **kwargs):
        if 'stream' in kwargs:
            stream = kwargs['stream']
            if sys.version_info[0] >= 3:
                
                stream = codecs.getreader('utf-8')(stream)
            self.stream = stream
        else:
            self.stream = _csv_open(kwargs['path'], 'r')
        self.reader = csv.reader(self.stream, **self.defaults)

    def __iter__(self):
        return self

    def next(self):
        result = next(self.reader)
        if sys.version_info[0] < 3:
            for i, item in enumerate(result):
                if not isinstance(item, text_type):
                    result[i] = item.decode('utf-8')
        return result

    __next__ = next


class CSVWriter(CSVBase):

    def __init__(self, fn, **kwargs):
        self.stream = _csv_open(fn, 'w')
        self.writer = csv.writer(self.stream, **self.defaults)

    def writerow(self, row):
        if sys.version_info[0] < 3:
            r = []
            for item in row:
                if isinstance(item, text_type):
                    item = item.encode('utf-8')
                r.append(item)
            row = r
        self.writer.writerow(row)







class Configurator(BaseConfigurator):

    value_converters = dict(BaseConfigurator.value_converters)
    value_converters['inc'] = 'inc_convert'

    def __init__(self, config, base=None):
        super(Configurator, self).__init__(config)
        self.base = base or os.getcwd()

    def configure_custom(self, config):

        def convert(o):
            if isinstance(o, (list, tuple)):
                result = type(o)([convert(i) for i in o])
            elif isinstance(o, dict):
                if '()' in o:
                    result = self.configure_custom(o)
                else:
                    result = {}
                    for k in o:
                        result[k] = convert(o[k])
            else:
                result = self.convert(o)
            return result

        c = config.pop('()')
        if not callable(c):
            c = self.resolve(c)
        props = config.pop('.', None)
        
        args = config.pop('[]', ())
        if args:
            args = tuple([convert(o) for o in args])
        items = [(k, convert(config[k])) for k in config if valid_ident(k)]
        kwargs = dict(items)
        result = c(*args, **kwargs)
        if props:
            for n, v in props.items():
                setattr(result, n, convert(v))
        return result

    def __getitem__(self, key):
        result = self.config[key]
        if isinstance(result, dict) and '()' in result:
            self.config[key] = result = self.configure_custom(result)
        return result

    def inc_convert(self, value):
        
        if not os.path.isabs(value):
            value = os.path.join(self.base, value)
        with codecs.open(value, 'r', encoding='utf-8') as f:
            result = json.load(f)
        return result


class SubprocessMixin(object):
    

    def __init__(self, verbose=False, progress=None):
        self.verbose = verbose
        self.progress = progress

    def reader(self, stream, context):
        
        progress = self.progress
        verbose = self.verbose
        while True:
            s = stream.readline()
            if not s:
                break
            if progress is not None:
                progress(s, context)
            else:
                if not verbose:
                    sys.stderr.write('.')
                else:
                    sys.stderr.write(s.decode('utf-8'))
                sys.stderr.flush()
        stream.close()

    def run_command(self, cmd, **kwargs):
        p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, **kwargs)
        t1 = threading.Thread(target=self.reader, args=(p.stdout, 'stdout'))
        t1.start()
        t2 = threading.Thread(target=self.reader, args=(p.stderr, 'stderr'))
        t2.start()
        p.wait()
        t1.join()
        t2.join()
        if self.progress is not None:
            self.progress('done.', 'main')
        elif self.verbose:
            sys.stderr.write('done.\n')
        return p


def normalize_name(name):
    
    
    return re.sub('[-_.]+', '-', name).lower()










class PyPIRCFile(object):

    DEFAULT_REPOSITORY = 'https://upload.pypi.org/legacy/'
    DEFAULT_REALM = 'pypi'

    def __init__(self, fn=None, url=None):
        if fn is None:
            fn = os.path.join(os.path.expanduser('~'), '.pypirc')
        self.filename = fn
        self.url = url

    def read(self):
        result = {}

        if os.path.exists(self.filename):
            repository = self.url or self.DEFAULT_REPOSITORY

            config = configparser.RawConfigParser()
            config.read(self.filename)
            sections = config.sections()
            if 'distutils' in sections:
                
                index_servers = config.get('distutils', 'index-servers')
                _servers = [server.strip() for server in index_servers.split('\n') if server.strip() != '']
                if _servers == []:
                    
                    if 'pypi' in sections:
                        _servers = ['pypi']
                else:
                    for server in _servers:
                        result = {'server': server}
                        result['username'] = config.get(server, 'username')

                        
                        for key, default in (('repository', self.DEFAULT_REPOSITORY), ('realm', self.DEFAULT_REALM),
                                             ('password', None)):
                            if config.has_option(server, key):
                                result[key] = config.get(server, key)
                            else:
                                result[key] = default

                        
                        
                        
                        if (server == 'pypi' and repository in (self.DEFAULT_REPOSITORY, 'pypi')):
                            result['repository'] = self.DEFAULT_REPOSITORY
                        elif (result['server'] != repository and result['repository'] != repository):
                            result = {}
            elif 'server-login' in sections:
                
                server = 'server-login'
                if config.has_option(server, 'repository'):
                    repository = config.get(server, 'repository')
                else:
                    repository = self.DEFAULT_REPOSITORY
                result = {
                    'username': config.get(server, 'username'),
                    'password': config.get(server, 'password'),
                    'repository': repository,
                    'server': server,
                    'realm': self.DEFAULT_REALM
                }
        return result

    def update(self, username, password):
        
        config = configparser.RawConfigParser()
        fn = self.filename
        config.read(fn)
        if not config.has_section('pypi'):
            config.add_section('pypi')
        config.set('pypi', 'username', username)
        config.set('pypi', 'password', password)
        with open(fn, 'w') as f:
            config.write(f)


def _load_pypirc(index):
    
    return PyPIRCFile(url=index.url).read()


def _store_pypirc(index):
    PyPIRCFile().update(index.username, index.password)








def get_host_platform():
    
    if os.name == 'nt':
        if 'amd64' in sys.version.lower():
            return 'win-amd64'
        if '(arm)' in sys.version.lower():
            return 'win-arm32'
        if '(arm64)' in sys.version.lower():
            return 'win-arm64'
        return sys.platform

    
    if ""_PYTHON_HOST_PLATFORM"" in os.environ:
        return os.environ[""_PYTHON_HOST_PLATFORM""]

    if os.name != 'posix' or not hasattr(os, 'uname'):
        
        
        return sys.platform

    

    (osname, host, release, version, machine) = os.uname()

    
    
    osname = osname.lower().replace('/', '')
    machine = machine.replace(' ', '_').replace('/', '-')

    if osname[:5] == 'linux':
        
        
        
        return ""%s-%s"" % (osname, machine)

    elif osname[:5] == 'sunos':
        if release[0] >= '5':  
            osname = 'solaris'
            release = '%d.%s' % (int(release[0]) - 3, release[2:])
            
            
            
            bitness = {2147483647: '32bit', 9223372036854775807: '64bit'}
            machine += '.%s' % bitness[sys.maxsize]
        
    elif osname[:3] == 'aix':
        from _aix_support import aix_platform
        return aix_platform()
    elif osname[:6] == 'cygwin':
        osname = 'cygwin'
        rel_re = re.compile(r'[\d.]+', re.ASCII)
        m = rel_re.match(release)
        if m:
            release = m.group()
    elif osname[:6] == 'darwin':
        import _osx_support
        try:
            from distutils import sysconfig
        except ImportError:
            import sysconfig
        osname, release, machine = _osx_support.get_platform_osx(sysconfig.get_config_vars(), osname, release, machine)

    return '%s-%s-%s' % (osname, release, machine)


_TARGET_TO_PLAT = {
    'x86': 'win32',
    'x64': 'win-amd64',
    'arm': 'win-arm32',
}


def get_platform():
    if os.name != 'nt':
        return get_host_platform()
    cross_compilation_target = os.environ.get('VSCMD_ARG_TGT_ARCH')
    if cross_compilation_target not in _TARGET_TO_PLAT:
        return get_host_platform()
    return _TARGET_TO_PLAT[cross_compilation_target]







import logging

__version__ = '0.4.0'


class DistlibException(Exception):
    pass


try:
    from logging import NullHandler
except ImportError:  

    class NullHandler(logging.Handler):

        def handle(self, record):
            pass

        def emit(self, record):
            pass

        def createLock(self):
            self.lock = None


logger = logging.getLogger(__name__)
logger.addHandler(NullHandler())


















import argparse
import json
import logging
import os
import re
import shlex
import subprocess
import sys
import warnings
from typing import (
    Any,
    Callable,
    Dict,
    Iterable,
    Optional,
    Sequence,
    TextIO,
    Tuple,
    Type,
)

try:
    from typing import TypedDict
except ImportError:
    
    TypedDict = dict

__version__ = ""1.9.0""


class VersionDict(TypedDict):
    major: str
    minor: str
    build_number: str


class InfoDict(TypedDict):
    id: str
    version: str
    version_parts: VersionDict
    like: str
    codename: str


_UNIXCONFDIR = os.environ.get(""UNIXCONFDIR"", ""/etc"")
_UNIXUSRLIBDIR = os.environ.get(""UNIXUSRLIBDIR"", ""/usr/lib"")
_OS_RELEASE_BASENAME = ""os-release""








NORMALIZED_OS_ID = {
    ""ol"": ""oracle"",  
    ""opensuse-leap"": ""opensuse"",  
}








NORMALIZED_LSB_ID = {
    ""enterpriseenterpriseas"": ""oracle"",  
    ""enterpriseenterpriseserver"": ""oracle"",  
    ""redhatenterpriseworkstation"": ""rhel"",  
    ""redhatenterpriseserver"": ""rhel"",  
    ""redhatenterprisecomputenode"": ""rhel"",  
}








NORMALIZED_DISTRO_ID = {
    ""redhat"": ""rhel"",  
}


_DISTRO_RELEASE_CONTENT_REVERSED_PATTERN = re.compile(
    r""(?:[^)]*\)(.*)\()? *(?:STL )?([\d.+\-a-z]*\d) *(?:esaeler *)?(.+)""
)


_DISTRO_RELEASE_BASENAME_PATTERN = re.compile(r""(\w+)[-_](release|version)$"")


_DISTRO_RELEASE_BASENAMES = [
    ""SuSE-release"",
    ""altlinux-release"",
    ""arch-release"",
    ""base-release"",
    ""centos-release"",
    ""fedora-release"",
    ""gentoo-release"",
    ""mageia-release"",
    ""mandrake-release"",
    ""mandriva-release"",
    ""mandrivalinux-release"",
    ""manjaro-release"",
    ""oracle-release"",
    ""redhat-release"",
    ""rocky-release"",
    ""sl-release"",
    ""slackware-version"",
]


_DISTRO_RELEASE_IGNORE_BASENAMES = (
    ""debian_version"",
    ""lsb-release"",
    ""oem-release"",
    _OS_RELEASE_BASENAME,
    ""system-release"",
    ""plesk-release"",
    ""iredmail-release"",
    ""board-release"",
    ""ec2_version"",
)


def linux_distribution(full_distribution_name: bool = True) -> Tuple[str, str, str]:
    
    warnings.warn(
        ""distro.linux_distribution() is deprecated. It should only be used as a ""
        ""compatibility shim with Python's platform.linux_distribution(). Please use ""
        ""distro.id(), distro.version() and distro.name() instead."",
        DeprecationWarning,
        stacklevel=2,
    )
    return _distro.linux_distribution(full_distribution_name)


def id() -> str:
    
    return _distro.id()


def name(pretty: bool = False) -> str:
    
    return _distro.name(pretty)


def version(pretty: bool = False, best: bool = False) -> str:
    
    return _distro.version(pretty, best)


def version_parts(best: bool = False) -> Tuple[str, str, str]:
    
    return _distro.version_parts(best)


def major_version(best: bool = False) -> str:
    
    return _distro.major_version(best)


def minor_version(best: bool = False) -> str:
    
    return _distro.minor_version(best)


def build_number(best: bool = False) -> str:
    
    return _distro.build_number(best)


def like() -> str:
    
    return _distro.like()


def codename() -> str:
    
    return _distro.codename()


def info(pretty: bool = False, best: bool = False) -> InfoDict:
    
    return _distro.info(pretty, best)


def os_release_info() -> Dict[str, str]:
    
    return _distro.os_release_info()


def lsb_release_info() -> Dict[str, str]:
    
    return _distro.lsb_release_info()


def distro_release_info() -> Dict[str, str]:
    
    return _distro.distro_release_info()


def uname_info() -> Dict[str, str]:
    
    return _distro.uname_info()


def os_release_attr(attribute: str) -> str:
    
    return _distro.os_release_attr(attribute)


def lsb_release_attr(attribute: str) -> str:
    
    return _distro.lsb_release_attr(attribute)


def distro_release_attr(attribute: str) -> str:
    
    return _distro.distro_release_attr(attribute)


def uname_attr(attribute: str) -> str:
    
    return _distro.uname_attr(attribute)


try:
    from functools import cached_property
except ImportError:
    
    class cached_property:  
        

        def __init__(self, f: Callable[[Any], Any]) -> None:
            self._fname = f.__name__
            self._f = f

        def __get__(self, obj: Any, owner: Type[Any]) -> Any:
            assert obj is not None, f""call {self._fname} on an instance""
            ret = obj.__dict__[self._fname] = self._f(obj)
            return ret


class LinuxDistribution:
    

    def __init__(
        self,
        include_lsb: Optional[bool] = None,
        os_release_file: str = """",
        distro_release_file: str = """",
        include_uname: Optional[bool] = None,
        root_dir: Optional[str] = None,
        include_oslevel: Optional[bool] = None,
    ) -> None:
        
        self.root_dir = root_dir
        self.etc_dir = os.path.join(root_dir, ""etc"") if root_dir else _UNIXCONFDIR
        self.usr_lib_dir = (
            os.path.join(root_dir, ""usr/lib"") if root_dir else _UNIXUSRLIBDIR
        )

        if os_release_file:
            self.os_release_file = os_release_file
        else:
            etc_dir_os_release_file = os.path.join(self.etc_dir, _OS_RELEASE_BASENAME)
            usr_lib_os_release_file = os.path.join(
                self.usr_lib_dir, _OS_RELEASE_BASENAME
            )

            
            
            if os.path.isfile(etc_dir_os_release_file) or not os.path.isfile(
                usr_lib_os_release_file
            ):
                self.os_release_file = etc_dir_os_release_file
            else:
                self.os_release_file = usr_lib_os_release_file

        self.distro_release_file = distro_release_file or """"  

        is_root_dir_defined = root_dir is not None
        if is_root_dir_defined and (include_lsb or include_uname or include_oslevel):
            raise ValueError(
                ""Including subprocess data sources from specific root_dir is disallowed""
                "" to prevent false information""
            )
        self.include_lsb = (
            include_lsb if include_lsb is not None else not is_root_dir_defined
        )
        self.include_uname = (
            include_uname if include_uname is not None else not is_root_dir_defined
        )
        self.include_oslevel = (
            include_oslevel if include_oslevel is not None else not is_root_dir_defined
        )

    def __repr__(self) -> str:
        
        return (
            ""LinuxDistribution(""
            ""os_release_file={self.os_release_file!r}, ""
            ""distro_release_file={self.distro_release_file!r}, ""
            ""include_lsb={self.include_lsb!r}, ""
            ""include_uname={self.include_uname!r}, ""
            ""include_oslevel={self.include_oslevel!r}, ""
            ""root_dir={self.root_dir!r}, ""
            ""_os_release_info={self._os_release_info!r}, ""
            ""_lsb_release_info={self._lsb_release_info!r}, ""
            ""_distro_release_info={self._distro_release_info!r}, ""
            ""_uname_info={self._uname_info!r}, ""
            ""_oslevel_info={self._oslevel_info!r})"".format(self=self)
        )

    def linux_distribution(
        self, full_distribution_name: bool = True
    ) -> Tuple[str, str, str]:
        
        return (
            self.name() if full_distribution_name else self.id(),
            self.version(),
            self._os_release_info.get(""release_codename"") or self.codename(),
        )

    def id(self) -> str:
        

        def normalize(distro_id: str, table: Dict[str, str]) -> str:
            distro_id = distro_id.lower().replace("" "", ""_"")
            return table.get(distro_id, distro_id)

        distro_id = self.os_release_attr(""id"")
        if distro_id:
            return normalize(distro_id, NORMALIZED_OS_ID)

        distro_id = self.lsb_release_attr(""distributor_id"")
        if distro_id:
            return normalize(distro_id, NORMALIZED_LSB_ID)

        distro_id = self.distro_release_attr(""id"")
        if distro_id:
            return normalize(distro_id, NORMALIZED_DISTRO_ID)

        distro_id = self.uname_attr(""id"")
        if distro_id:
            return normalize(distro_id, NORMALIZED_DISTRO_ID)

        return """"

    def name(self, pretty: bool = False) -> str:
        
        name = (
            self.os_release_attr(""name"")
            or self.lsb_release_attr(""distributor_id"")
            or self.distro_release_attr(""name"")
            or self.uname_attr(""name"")
        )
        if pretty:
            name = self.os_release_attr(""pretty_name"") or self.lsb_release_attr(
                ""description""
            )
            if not name:
                name = self.distro_release_attr(""name"") or self.uname_attr(""name"")
                version = self.version(pretty=True)
                if version:
                    name = f""{name} {version}""
        return name or """"

    def version(self, pretty: bool = False, best: bool = False) -> str:
        
        versions = [
            self.os_release_attr(""version_id""),
            self.lsb_release_attr(""release""),
            self.distro_release_attr(""version_id""),
            self._parse_distro_release_content(self.os_release_attr(""pretty_name"")).get(
                ""version_id"", """"
            ),
            self._parse_distro_release_content(
                self.lsb_release_attr(""description"")
            ).get(""version_id"", """"),
            self.uname_attr(""release""),
        ]
        if self.uname_attr(""id"").startswith(""aix""):
            
            versions.insert(0, self.oslevel_info())
        elif self.id() == ""debian"" or ""debian"" in self.like().split():
            
            versions.append(self._debian_version)
        version = """"
        if best:
            
            
            
            
            for v in versions:
                if v.count(""."") > version.count(""."") or version == """":
                    version = v
        else:
            for v in versions:
                if v != """":
                    version = v
                    break
        if pretty and version and self.codename():
            version = f""{version} ({self.codename()})""
        return version

    def version_parts(self, best: bool = False) -> Tuple[str, str, str]:
        
        version_str = self.version(best=best)
        if version_str:
            version_regex = re.compile(r""(\d+)\.?(\d+)?\.?(\d+)?"")
            matches = version_regex.match(version_str)
            if matches:
                major, minor, build_number = matches.groups()
                return major, minor or """", build_number or """"
        return """", """", """"

    def major_version(self, best: bool = False) -> str:
        
        return self.version_parts(best)[0]

    def minor_version(self, best: bool = False) -> str:
        
        return self.version_parts(best)[1]

    def build_number(self, best: bool = False) -> str:
        
        return self.version_parts(best)[2]

    def like(self) -> str:
        
        return self.os_release_attr(""id_like"") or """"

    def codename(self) -> str:
        
        try:
            
            
            return self._os_release_info[""codename""]
        except KeyError:
            return (
                self.lsb_release_attr(""codename"")
                or self.distro_release_attr(""codename"")
                or """"
            )

    def info(self, pretty: bool = False, best: bool = False) -> InfoDict:
        
        return InfoDict(
            id=self.id(),
            version=self.version(pretty, best),
            version_parts=VersionDict(
                major=self.major_version(best),
                minor=self.minor_version(best),
                build_number=self.build_number(best),
            ),
            like=self.like(),
            codename=self.codename(),
        )

    def os_release_info(self) -> Dict[str, str]:
        
        return self._os_release_info

    def lsb_release_info(self) -> Dict[str, str]:
        
        return self._lsb_release_info

    def distro_release_info(self) -> Dict[str, str]:
        
        return self._distro_release_info

    def uname_info(self) -> Dict[str, str]:
        
        return self._uname_info

    def oslevel_info(self) -> str:
        
        return self._oslevel_info

    def os_release_attr(self, attribute: str) -> str:
        
        return self._os_release_info.get(attribute, """")

    def lsb_release_attr(self, attribute: str) -> str:
        
        return self._lsb_release_info.get(attribute, """")

    def distro_release_attr(self, attribute: str) -> str:
        
        return self._distro_release_info.get(attribute, """")

    def uname_attr(self, attribute: str) -> str:
        
        return self._uname_info.get(attribute, """")

    @cached_property
    def _os_release_info(self) -> Dict[str, str]:
        
        if os.path.isfile(self.os_release_file):
            with open(self.os_release_file, encoding=""utf-8"") as release_file:
                return self._parse_os_release_content(release_file)
        return {}

    @staticmethod
    def _parse_os_release_content(lines: TextIO) -> Dict[str, str]:
        
        props = {}
        lexer = shlex.shlex(lines, posix=True)
        lexer.whitespace_split = True

        tokens = list(lexer)
        for token in tokens:
            
            
            
            
            
            
            
            if ""="" in token:
                k, v = token.split(""="", 1)
                props[k.lower()] = v

        if ""version"" in props:
            
            match = re.search(r""\((\D+)\)|,\s*(\D+)"", props[""version""])
            if match:
                release_codename = match.group(1) or match.group(2)
                props[""codename""] = props[""release_codename""] = release_codename

        if ""version_codename"" in props:
            
            
            
            
            props[""codename""] = props[""version_codename""]
        elif ""ubuntu_codename"" in props:
            
            props[""codename""] = props[""ubuntu_codename""]

        return props

    @cached_property
    def _lsb_release_info(self) -> Dict[str, str]:
        
        if not self.include_lsb:
            return {}
        try:
            cmd = (""lsb_release"", ""-a"")
            stdout = subprocess.check_output(cmd, stderr=subprocess.DEVNULL)
        
        except (OSError, subprocess.CalledProcessError):
            return {}
        content = self._to_str(stdout).splitlines()
        return self._parse_lsb_release_content(content)

    @staticmethod
    def _parse_lsb_release_content(lines: Iterable[str]) -> Dict[str, str]:
        
        props = {}
        for line in lines:
            kv = line.strip(""\n"").split("":"", 1)
            if len(kv) != 2:
                
                continue
            k, v = kv
            props.update({k.replace("" "", ""_"").lower(): v.strip()})
        return props

    @cached_property
    def _uname_info(self) -> Dict[str, str]:
        if not self.include_uname:
            return {}
        try:
            cmd = (""uname"", ""-rs"")
            stdout = subprocess.check_output(cmd, stderr=subprocess.DEVNULL)
        except OSError:
            return {}
        content = self._to_str(stdout).splitlines()
        return self._parse_uname_content(content)

    @cached_property
    def _oslevel_info(self) -> str:
        if not self.include_oslevel:
            return """"
        try:
            stdout = subprocess.check_output(""oslevel"", stderr=subprocess.DEVNULL)
        except (OSError, subprocess.CalledProcessError):
            return """"
        return self._to_str(stdout).strip()

    @cached_property
    def _debian_version(self) -> str:
        try:
            with open(
                os.path.join(self.etc_dir, ""debian_version""), encoding=""ascii""
            ) as fp:
                return fp.readline().rstrip()
        except FileNotFoundError:
            return """"

    @staticmethod
    def _parse_uname_content(lines: Sequence[str]) -> Dict[str, str]:
        if not lines:
            return {}
        props = {}
        match = re.search(r""^([^\s]+)\s+([\d\.]+)"", lines[0].strip())
        if match:
            name, version = match.groups()

            
            
            
            if name == ""Linux"":
                return {}
            props[""id""] = name.lower()
            props[""name""] = name
            props[""release""] = version
        return props

    @staticmethod
    def _to_str(bytestring: bytes) -> str:
        encoding = sys.getfilesystemencoding()
        return bytestring.decode(encoding)

    @cached_property
    def _distro_release_info(self) -> Dict[str, str]:
        
        if self.distro_release_file:
            
            
            distro_info = self._parse_distro_release_file(self.distro_release_file)
            basename = os.path.basename(self.distro_release_file)
            
            
            
            
            match = _DISTRO_RELEASE_BASENAME_PATTERN.match(basename)
        else:
            try:
                basenames = [
                    basename
                    for basename in os.listdir(self.etc_dir)
                    if basename not in _DISTRO_RELEASE_IGNORE_BASENAMES
                    and os.path.isfile(os.path.join(self.etc_dir, basename))
                ]
                
                
                
                basenames.sort()
            except OSError:
                
                
                
                
                basenames = _DISTRO_RELEASE_BASENAMES
            for basename in basenames:
                match = _DISTRO_RELEASE_BASENAME_PATTERN.match(basename)
                if match is None:
                    continue
                filepath = os.path.join(self.etc_dir, basename)
                distro_info = self._parse_distro_release_file(filepath)
                
                if ""name"" not in distro_info:
                    continue
                self.distro_release_file = filepath
                break
            else:  
                return {}

        if match is not None:
            distro_info[""id""] = match.group(1)

        
        if ""cloudlinux"" in distro_info.get(""name"", """").lower():
            distro_info[""id""] = ""cloudlinux""

        return distro_info

    def _parse_distro_release_file(self, filepath: str) -> Dict[str, str]:
        
        try:
            with open(filepath, encoding=""utf-8"") as fp:
                
                
                return self._parse_distro_release_content(fp.readline())
        except OSError:
            
            
            
            return {}

    @staticmethod
    def _parse_distro_release_content(line: str) -> Dict[str, str]:
        
        matches = _DISTRO_RELEASE_CONTENT_REVERSED_PATTERN.match(line.strip()[::-1])
        distro_info = {}
        if matches:
            
            distro_info[""name""] = matches.group(3)[::-1]
            if matches.group(2):
                distro_info[""version_id""] = matches.group(2)[::-1]
            if matches.group(1):
                distro_info[""codename""] = matches.group(1)[::-1]
        elif line:
            distro_info[""name""] = line.strip()
        return distro_info


_distro = LinuxDistribution()


def main() -> None:
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.DEBUG)
    logger.addHandler(logging.StreamHandler(sys.stdout))

    parser = argparse.ArgumentParser(description=""OS distro info tool"")
    parser.add_argument(
        ""--json"", ""-j"", help=""Output in machine readable format"", action=""store_true""
    )

    parser.add_argument(
        ""--root-dir"",
        ""-r"",
        type=str,
        dest=""root_dir"",
        help=""Path to the root filesystem directory (defaults to /)"",
    )

    args = parser.parse_args()

    if args.root_dir:
        dist = LinuxDistribution(
            include_lsb=False,
            include_uname=False,
            include_oslevel=False,
            root_dir=args.root_dir,
        )
    else:
        dist = _distro

    if args.json:
        logger.info(json.dumps(dist.info(), indent=4, sort_keys=True))
    else:
        logger.info(""Name: %s"", dist.name(pretty=True))
        distribution_version = dist.version(pretty=True)
        logger.info(""Version: %s"", distribution_version)
        distribution_codename = dist.codename()
        logger.info(""Codename: %s"", distribution_codename)


if __name__ == ""__main__"":
    main()

from .distro import (
    NORMALIZED_DISTRO_ID,
    NORMALIZED_LSB_ID,
    NORMALIZED_OS_ID,
    LinuxDistribution,
    __version__,
    build_number,
    codename,
    distro_release_attr,
    distro_release_info,
    id,
    info,
    like,
    linux_distribution,
    lsb_release_attr,
    lsb_release_info,
    major_version,
    minor_version,
    name,
    os_release_attr,
    os_release_info,
    uname_attr,
    uname_info,
    version,
    version_parts,
)

__all__ = [
    ""NORMALIZED_DISTRO_ID"",
    ""NORMALIZED_LSB_ID"",
    ""NORMALIZED_OS_ID"",
    ""LinuxDistribution"",
    ""build_number"",
    ""codename"",
    ""distro_release_attr"",
    ""distro_release_info"",
    ""id"",
    ""info"",
    ""like"",
    ""linux_distribution"",
    ""lsb_release_attr"",
    ""lsb_release_info"",
    ""major_version"",
    ""minor_version"",
    ""name"",
    ""os_release_attr"",
    ""os_release_info"",
    ""uname_attr"",
    ""uname_info"",
    ""version"",
    ""version_parts"",
]

__version__ = __version__

from .distro import main

if __name__ == ""__main__"":
    main()

import codecs
import re
from typing import Any, Optional, Tuple

from .core import IDNAError, alabel, decode, encode, ulabel

_unicode_dots_re = re.compile(""[\u002e\u3002\uff0e\uff61]"")


class Codec(codecs.Codec):
    def encode(self, data: str, errors: str = ""strict"") -> Tuple[bytes, int]:
        if errors != ""strict"":
            raise IDNAError('Unsupported error handling ""{}""'.format(errors))

        if not data:
            return b"""", 0

        return encode(data), len(data)

    def decode(self, data: bytes, errors: str = ""strict"") -> Tuple[str, int]:
        if errors != ""strict"":
            raise IDNAError('Unsupported error handling ""{}""'.format(errors))

        if not data:
            return """", 0

        return decode(data), len(data)


class IncrementalEncoder(codecs.BufferedIncrementalEncoder):
    def _buffer_encode(self, data: str, errors: str, final: bool) -> Tuple[bytes, int]:
        if errors != ""strict"":
            raise IDNAError('Unsupported error handling ""{}""'.format(errors))

        if not data:
            return b"""", 0

        labels = _unicode_dots_re.split(data)
        trailing_dot = b""""
        if labels:
            if not labels[-1]:
                trailing_dot = b"".""
                del labels[-1]
            elif not final:
                
                del labels[-1]
                if labels:
                    trailing_dot = b"".""

        result = []
        size = 0
        for label in labels:
            result.append(alabel(label))
            if size:
                size += 1
            size += len(label)

        
        result_bytes = b""."".join(result) + trailing_dot
        size += len(trailing_dot)
        return result_bytes, size


class IncrementalDecoder(codecs.BufferedIncrementalDecoder):
    def _buffer_decode(self, data: Any, errors: str, final: bool) -> Tuple[str, int]:
        if errors != ""strict"":
            raise IDNAError('Unsupported error handling ""{}""'.format(errors))

        if not data:
            return ("""", 0)

        if not isinstance(data, str):
            data = str(data, ""ascii"")

        labels = _unicode_dots_re.split(data)
        trailing_dot = """"
        if labels:
            if not labels[-1]:
                trailing_dot = "".""
                del labels[-1]
            elif not final:
                
                del labels[-1]
                if labels:
                    trailing_dot = "".""

        result = []
        size = 0
        for label in labels:
            result.append(ulabel(label))
            if size:
                size += 1
            size += len(label)

        result_str = ""."".join(result) + trailing_dot
        size += len(trailing_dot)
        return (result_str, size)


class StreamWriter(Codec, codecs.StreamWriter):
    pass


class StreamReader(Codec, codecs.StreamReader):
    pass


def search_function(name: str) -> Optional[codecs.CodecInfo]:
    if name != ""idna2008"":
        return None
    return codecs.CodecInfo(
        name=name,
        encode=Codec().encode,
        decode=Codec().decode,
        incrementalencoder=IncrementalEncoder,
        incrementaldecoder=IncrementalDecoder,
        streamwriter=StreamWriter,
        streamreader=StreamReader,
    )


codecs.register(search_function)

from typing import Any, Union

from .core import decode, encode


def ToASCII(label: str) -> bytes:
    return encode(label)


def ToUnicode(label: Union[bytes, bytearray]) -> str:
    return decode(label)


def nameprep(s: Any) -> None:
    raise NotImplementedError(""IDNA 2008 does not utilise nameprep protocol"")

import bisect
import re
import unicodedata
from typing import Optional, Union

from . import idnadata
from .intranges import intranges_contain

_virama_combining_class = 9
_alabel_prefix = b""xn--""
_unicode_dots_re = re.compile(""[\u002e\u3002\uff0e\uff61]"")


class IDNAError(UnicodeError):
    

    pass


class IDNABidiError(IDNAError):
    

    pass


class InvalidCodepoint(IDNAError):
    

    pass


class InvalidCodepointContext(IDNAError):
    

    pass


def _combining_class(cp: int) -> int:
    v = unicodedata.combining(chr(cp))
    if v == 0:
        if not unicodedata.name(chr(cp)):
            raise ValueError(""Unknown character in unicodedata"")
    return v


def _is_script(cp: str, script: str) -> bool:
    return intranges_contain(ord(cp), idnadata.scripts[script])


def _punycode(s: str) -> bytes:
    return s.encode(""punycode"")


def _unot(s: int) -> str:
    return ""U+{:04X}"".format(s)


def valid_label_length(label: Union[bytes, str]) -> bool:
    if len(label) > 63:
        return False
    return True


def valid_string_length(label: Union[bytes, str], trailing_dot: bool) -> bool:
    if len(label) > (254 if trailing_dot else 253):
        return False
    return True


def check_bidi(label: str, check_ltr: bool = False) -> bool:
    
    bidi_label = False
    for idx, cp in enumerate(label, 1):
        direction = unicodedata.bidirectional(cp)
        if direction == """":
            
            raise IDNABidiError(""Unknown directionality in label {} at position {}"".format(repr(label), idx))
        if direction in [""R"", ""AL"", ""AN""]:
            bidi_label = True
    if not bidi_label and not check_ltr:
        return True

    
    direction = unicodedata.bidirectional(label[0])
    if direction in [""R"", ""AL""]:
        rtl = True
    elif direction == ""L"":
        rtl = False
    else:
        raise IDNABidiError(""First codepoint in label {} must be directionality L, R or AL"".format(repr(label)))

    valid_ending = False
    number_type: Optional[str] = None
    for idx, cp in enumerate(label, 1):
        direction = unicodedata.bidirectional(cp)

        if rtl:
            
            if direction not in [
                ""R"",
                ""AL"",
                ""AN"",
                ""EN"",
                ""ES"",
                ""CS"",
                ""ET"",
                ""ON"",
                ""BN"",
                ""NSM"",
            ]:
                raise IDNABidiError(""Invalid direction for codepoint at position {} in a right-to-left label"".format(idx))
            
            if direction in [""R"", ""AL"", ""EN"", ""AN""]:
                valid_ending = True
            elif direction != ""NSM"":
                valid_ending = False
            
            if direction in [""AN"", ""EN""]:
                if not number_type:
                    number_type = direction
                else:
                    if number_type != direction:
                        raise IDNABidiError(""Can not mix numeral types in a right-to-left label"")
        else:
            
            if direction not in [""L"", ""EN"", ""ES"", ""CS"", ""ET"", ""ON"", ""BN"", ""NSM""]:
                raise IDNABidiError(""Invalid direction for codepoint at position {} in a left-to-right label"".format(idx))
            
            if direction in [""L"", ""EN""]:
                valid_ending = True
            elif direction != ""NSM"":
                valid_ending = False

    if not valid_ending:
        raise IDNABidiError(""Label ends with illegal codepoint directionality"")

    return True


def check_initial_combiner(label: str) -> bool:
    if unicodedata.category(label[0])[0] == ""M"":
        raise IDNAError(""Label begins with an illegal combining character"")
    return True


def check_hyphen_ok(label: str) -> bool:
    if label[2:4] == ""--"":
        raise IDNAError(""Label has disallowed hyphens in 3rd and 4th position"")
    if label[0] == ""-"" or label[-1] == ""-"":
        raise IDNAError(""Label must not start or end with a hyphen"")
    return True


def check_nfc(label: str) -> None:
    if unicodedata.normalize(""NFC"", label) != label:
        raise IDNAError(""Label must be in Normalization Form C"")


def valid_contextj(label: str, pos: int) -> bool:
    cp_value = ord(label[pos])

    if cp_value == 0x200C:
        if pos > 0:
            if _combining_class(ord(label[pos - 1])) == _virama_combining_class:
                return True

        ok = False
        for i in range(pos - 1, -1, -1):
            joining_type = idnadata.joining_types.get(ord(label[i]))
            if joining_type == ord(""T""):
                continue
            elif joining_type in [ord(""L""), ord(""D"")]:
                ok = True
                break
            else:
                break

        if not ok:
            return False

        ok = False
        for i in range(pos + 1, len(label)):
            joining_type = idnadata.joining_types.get(ord(label[i]))
            if joining_type == ord(""T""):
                continue
            elif joining_type in [ord(""R""), ord(""D"")]:
                ok = True
                break
            else:
                break
        return ok

    if cp_value == 0x200D:
        if pos > 0:
            if _combining_class(ord(label[pos - 1])) == _virama_combining_class:
                return True
        return False

    else:
        return False


def valid_contexto(label: str, pos: int, exception: bool = False) -> bool:
    cp_value = ord(label[pos])

    if cp_value == 0x00B7:
        if 0 < pos < len(label) - 1:
            if ord(label[pos - 1]) == 0x006C and ord(label[pos + 1]) == 0x006C:
                return True
        return False

    elif cp_value == 0x0375:
        if pos < len(label) - 1 and len(label) > 1:
            return _is_script(label[pos + 1], ""Greek"")
        return False

    elif cp_value == 0x05F3 or cp_value == 0x05F4:
        if pos > 0:
            return _is_script(label[pos - 1], ""Hebrew"")
        return False

    elif cp_value == 0x30FB:
        for cp in label:
            if cp == ""\u30fb"":
                continue
            if _is_script(cp, ""Hiragana"") or _is_script(cp, ""Katakana"") or _is_script(cp, ""Han""):
                return True
        return False

    elif 0x660 <= cp_value <= 0x669:
        for cp in label:
            if 0x6F0 <= ord(cp) <= 0x06F9:
                return False
        return True

    elif 0x6F0 <= cp_value <= 0x6F9:
        for cp in label:
            if 0x660 <= ord(cp) <= 0x0669:
                return False
        return True

    return False


def check_label(label: Union[str, bytes, bytearray]) -> None:
    if isinstance(label, (bytes, bytearray)):
        label = label.decode(""utf-8"")
    if len(label) == 0:
        raise IDNAError(""Empty Label"")

    check_nfc(label)
    check_hyphen_ok(label)
    check_initial_combiner(label)

    for pos, cp in enumerate(label):
        cp_value = ord(cp)
        if intranges_contain(cp_value, idnadata.codepoint_classes[""PVALID""]):
            continue
        elif intranges_contain(cp_value, idnadata.codepoint_classes[""CONTEXTJ""]):
            try:
                if not valid_contextj(label, pos):
                    raise InvalidCodepointContext(
                        ""Joiner {} not allowed at position {} in {}"".format(_unot(cp_value), pos + 1, repr(label))
                    )
            except ValueError:
                raise IDNAError(
                    ""Unknown codepoint adjacent to joiner {} at position {} in {}"".format(
                        _unot(cp_value), pos + 1, repr(label)
                    )
                )
        elif intranges_contain(cp_value, idnadata.codepoint_classes[""CONTEXTO""]):
            if not valid_contexto(label, pos):
                raise InvalidCodepointContext(
                    ""Codepoint {} not allowed at position {} in {}"".format(_unot(cp_value), pos + 1, repr(label))
                )
        else:
            raise InvalidCodepoint(
                ""Codepoint {} at position {} of {} not allowed"".format(_unot(cp_value), pos + 1, repr(label))
            )

    check_bidi(label)


def alabel(label: str) -> bytes:
    try:
        label_bytes = label.encode(""ascii"")
        ulabel(label_bytes)
        if not valid_label_length(label_bytes):
            raise IDNAError(""Label too long"")
        return label_bytes
    except UnicodeEncodeError:
        pass

    check_label(label)
    label_bytes = _alabel_prefix + _punycode(label)

    if not valid_label_length(label_bytes):
        raise IDNAError(""Label too long"")

    return label_bytes


def ulabel(label: Union[str, bytes, bytearray]) -> str:
    if not isinstance(label, (bytes, bytearray)):
        try:
            label_bytes = label.encode(""ascii"")
        except UnicodeEncodeError:
            check_label(label)
            return label
    else:
        label_bytes = label

    label_bytes = label_bytes.lower()
    if label_bytes.startswith(_alabel_prefix):
        label_bytes = label_bytes[len(_alabel_prefix) :]
        if not label_bytes:
            raise IDNAError(""Malformed A-label, no Punycode eligible content found"")
        if label_bytes.decode(""ascii"")[-1] == ""-"":
            raise IDNAError(""A-label must not end with a hyphen"")
    else:
        check_label(label_bytes)
        return label_bytes.decode(""ascii"")

    try:
        label = label_bytes.decode(""punycode"")
    except UnicodeError:
        raise IDNAError(""Invalid A-label"")
    check_label(label)
    return label


def uts46_remap(domain: str, std3_rules: bool = True, transitional: bool = False) -> str:
    
    from .uts46data import uts46data

    output = """"

    for pos, char in enumerate(domain):
        code_point = ord(char)
        try:
            uts46row = uts46data[code_point if code_point < 256 else bisect.bisect_left(uts46data, (code_point, ""Z"")) - 1]
            status = uts46row[1]
            replacement: Optional[str] = None
            if len(uts46row) == 3:
                replacement = uts46row[2]
            if (
                status == ""V""
                or (status == ""D"" and not transitional)
                or (status == ""3"" and not std3_rules and replacement is None)
            ):
                output += char
            elif replacement is not None and (
                status == ""M"" or (status == ""3"" and not std3_rules) or (status == ""D"" and transitional)
            ):
                output += replacement
            elif status != ""I"":
                raise IndexError()
        except IndexError:
            raise InvalidCodepoint(
                ""Codepoint {} not allowed at position {} in {}"".format(_unot(code_point), pos + 1, repr(domain))
            )

    return unicodedata.normalize(""NFC"", output)


def encode(
    s: Union[str, bytes, bytearray],
    strict: bool = False,
    uts46: bool = False,
    std3_rules: bool = False,
    transitional: bool = False,
) -> bytes:
    if not isinstance(s, str):
        try:
            s = str(s, ""ascii"")
        except UnicodeDecodeError:
            raise IDNAError(""should pass a unicode string to the function rather than a byte string."")
    if uts46:
        s = uts46_remap(s, std3_rules, transitional)
    trailing_dot = False
    result = []
    if strict:
        labels = s.split(""."")
    else:
        labels = _unicode_dots_re.split(s)
    if not labels or labels == [""""]:
        raise IDNAError(""Empty domain"")
    if labels[-1] == """":
        del labels[-1]
        trailing_dot = True
    for label in labels:
        s = alabel(label)
        if s:
            result.append(s)
        else:
            raise IDNAError(""Empty label"")
    if trailing_dot:
        result.append(b"""")
    s = b""."".join(result)
    if not valid_string_length(s, trailing_dot):
        raise IDNAError(""Domain too long"")
    return s


def decode(
    s: Union[str, bytes, bytearray],
    strict: bool = False,
    uts46: bool = False,
    std3_rules: bool = False,
) -> str:
    try:
        if not isinstance(s, str):
            s = str(s, ""ascii"")
    except UnicodeDecodeError:
        raise IDNAError(""Invalid ASCII in A-label"")
    if uts46:
        s = uts46_remap(s, std3_rules, False)
    trailing_dot = False
    result = []
    if not strict:
        labels = _unicode_dots_re.split(s)
    else:
        labels = s.split(""."")
    if not labels or labels == [""""]:
        raise IDNAError(""Empty domain"")
    if not labels[-1]:
        del labels[-1]
        trailing_dot = True
    for label in labels:
        s = ulabel(label)
        if s:
            result.append(s)
        else:
            raise IDNAError(""Empty label"")
    if trailing_dot:
        result.append("""")
    return ""."".join(result)



__version__ = ""15.1.0""
scripts = {
    ""Greek"": (
        0x37000000374,
        0x37500000378,
        0x37A0000037E,
        0x37F00000380,
        0x38400000385,
        0x38600000387,
        0x3880000038B,
        0x38C0000038D,
        0x38E000003A2,
        0x3A3000003E2,
        0x3F000000400,
        0x1D2600001D2B,
        0x1D5D00001D62,
        0x1D6600001D6B,
        0x1DBF00001DC0,
        0x1F0000001F16,
        0x1F1800001F1E,
        0x1F2000001F46,
        0x1F4800001F4E,
        0x1F5000001F58,
        0x1F5900001F5A,
        0x1F5B00001F5C,
        0x1F5D00001F5E,
        0x1F5F00001F7E,
        0x1F8000001FB5,
        0x1FB600001FC5,
        0x1FC600001FD4,
        0x1FD600001FDC,
        0x1FDD00001FF0,
        0x1FF200001FF5,
        0x1FF600001FFF,
        0x212600002127,
        0xAB650000AB66,
        0x101400001018F,
        0x101A0000101A1,
        0x1D2000001D246,
    ),
    ""Han"": (
        0x2E8000002E9A,
        0x2E9B00002EF4,
        0x2F0000002FD6,
        0x300500003006,
        0x300700003008,
        0x30210000302A,
        0x30380000303C,
        0x340000004DC0,
        0x4E000000A000,
        0xF9000000FA6E,
        0xFA700000FADA,
        0x16FE200016FE4,
        0x16FF000016FF2,
        0x200000002A6E0,
        0x2A7000002B73A,
        0x2B7400002B81E,
        0x2B8200002CEA2,
        0x2CEB00002EBE1,
        0x2EBF00002EE5E,
        0x2F8000002FA1E,
        0x300000003134B,
        0x31350000323B0,
    ),
    ""Hebrew"": (
        0x591000005C8,
        0x5D0000005EB,
        0x5EF000005F5,
        0xFB1D0000FB37,
        0xFB380000FB3D,
        0xFB3E0000FB3F,
        0xFB400000FB42,
        0xFB430000FB45,
        0xFB460000FB50,
    ),
    ""Hiragana"": (
        0x304100003097,
        0x309D000030A0,
        0x1B0010001B120,
        0x1B1320001B133,
        0x1B1500001B153,
        0x1F2000001F201,
    ),
    ""Katakana"": (
        0x30A1000030FB,
        0x30FD00003100,
        0x31F000003200,
        0x32D0000032FF,
        0x330000003358,
        0xFF660000FF70,
        0xFF710000FF9E,
        0x1AFF00001AFF4,
        0x1AFF50001AFFC,
        0x1AFFD0001AFFF,
        0x1B0000001B001,
        0x1B1200001B123,
        0x1B1550001B156,
        0x1B1640001B168,
    ),
}
joining_types = {
    0xAD: 84,
    0x300: 84,
    0x301: 84,
    0x302: 84,
    0x303: 84,
    0x304: 84,
    0x305: 84,
    0x306: 84,
    0x307: 84,
    0x308: 84,
    0x309: 84,
    0x30A: 84,
    0x30B: 84,
    0x30C: 84,
    0x30D: 84,
    0x30E: 84,
    0x30F: 84,
    0x310: 84,
    0x311: 84,
    0x312: 84,
    0x313: 84,
    0x314: 84,
    0x315: 84,
    0x316: 84,
    0x317: 84,
    0x318: 84,
    0x319: 84,
    0x31A: 84,
    0x31B: 84,
    0x31C: 84,
    0x31D: 84,
    0x31E: 84,
    0x31F: 84,
    0x320: 84,
    0x321: 84,
    0x322: 84,
    0x323: 84,
    0x324: 84,
    0x325: 84,
    0x326: 84,
    0x327: 84,
    0x328: 84,
    0x329: 84,
    0x32A: 84,
    0x32B: 84,
    0x32C: 84,
    0x32D: 84,
    0x32E: 84,
    0x32F: 84,
    0x330: 84,
    0x331: 84,
    0x332: 84,
    0x333: 84,
    0x334: 84,
    0x335: 84,
    0x336: 84,
    0x337: 84,
    0x338: 84,
    0x339: 84,
    0x33A: 84,
    0x33B: 84,
    0x33C: 84,
    0x33D: 84,
    0x33E: 84,
    0x33F: 84,
    0x340: 84,
    0x341: 84,
    0x342: 84,
    0x343: 84,
    0x344: 84,
    0x345: 84,
    0x346: 84,
    0x347: 84,
    0x348: 84,
    0x349: 84,
    0x34A: 84,
    0x34B: 84,
    0x34C: 84,
    0x34D: 84,
    0x34E: 84,
    0x34F: 84,
    0x350: 84,
    0x351: 84,
    0x352: 84,
    0x353: 84,
    0x354: 84,
    0x355: 84,
    0x356: 84,
    0x357: 84,
    0x358: 84,
    0x359: 84,
    0x35A: 84,
    0x35B: 84,
    0x35C: 84,
    0x35D: 84,
    0x35E: 84,
    0x35F: 84,
    0x360: 84,
    0x361: 84,
    0x362: 84,
    0x363: 84,
    0x364: 84,
    0x365: 84,
    0x366: 84,
    0x367: 84,
    0x368: 84,
    0x369: 84,
    0x36A: 84,
    0x36B: 84,
    0x36C: 84,
    0x36D: 84,
    0x36E: 84,
    0x36F: 84,
    0x483: 84,
    0x484: 84,
    0x485: 84,
    0x486: 84,
    0x487: 84,
    0x488: 84,
    0x489: 84,
    0x591: 84,
    0x592: 84,
    0x593: 84,
    0x594: 84,
    0x595: 84,
    0x596: 84,
    0x597: 84,
    0x598: 84,
    0x599: 84,
    0x59A: 84,
    0x59B: 84,
    0x59C: 84,
    0x59D: 84,
    0x59E: 84,
    0x59F: 84,
    0x5A0: 84,
    0x5A1: 84,
    0x5A2: 84,
    0x5A3: 84,
    0x5A4: 84,
    0x5A5: 84,
    0x5A6: 84,
    0x5A7: 84,
    0x5A8: 84,
    0x5A9: 84,
    0x5AA: 84,
    0x5AB: 84,
    0x5AC: 84,
    0x5AD: 84,
    0x5AE: 84,
    0x5AF: 84,
    0x5B0: 84,
    0x5B1: 84,
    0x5B2: 84,
    0x5B3: 84,
    0x5B4: 84,
    0x5B5: 84,
    0x5B6: 84,
    0x5B7: 84,
    0x5B8: 84,
    0x5B9: 84,
    0x5BA: 84,
    0x5BB: 84,
    0x5BC: 84,
    0x5BD: 84,
    0x5BF: 84,
    0x5C1: 84,
    0x5C2: 84,
    0x5C4: 84,
    0x5C5: 84,
    0x5C7: 84,
    0x610: 84,
    0x611: 84,
    0x612: 84,
    0x613: 84,
    0x614: 84,
    0x615: 84,
    0x616: 84,
    0x617: 84,
    0x618: 84,
    0x619: 84,
    0x61A: 84,
    0x61C: 84,
    0x620: 68,
    0x622: 82,
    0x623: 82,
    0x624: 82,
    0x625: 82,
    0x626: 68,
    0x627: 82,
    0x628: 68,
    0x629: 82,
    0x62A: 68,
    0x62B: 68,
    0x62C: 68,
    0x62D: 68,
    0x62E: 68,
    0x62F: 82,
    0x630: 82,
    0x631: 82,
    0x632: 82,
    0x633: 68,
    0x634: 68,
    0x635: 68,
    0x636: 68,
    0x637: 68,
    0x638: 68,
    0x639: 68,
    0x63A: 68,
    0x63B: 68,
    0x63C: 68,
    0x63D: 68,
    0x63E: 68,
    0x63F: 68,
    0x640: 67,
    0x641: 68,
    0x642: 68,
    0x643: 68,
    0x644: 68,
    0x645: 68,
    0x646: 68,
    0x647: 68,
    0x648: 82,
    0x649: 68,
    0x64A: 68,
    0x64B: 84,
    0x64C: 84,
    0x64D: 84,
    0x64E: 84,
    0x64F: 84,
    0x650: 84,
    0x651: 84,
    0x652: 84,
    0x653: 84,
    0x654: 84,
    0x655: 84,
    0x656: 84,
    0x657: 84,
    0x658: 84,
    0x659: 84,
    0x65A: 84,
    0x65B: 84,
    0x65C: 84,
    0x65D: 84,
    0x65E: 84,
    0x65F: 84,
    0x66E: 68,
    0x66F: 68,
    0x670: 84,
    0x671: 82,
    0x672: 82,
    0x673: 82,
    0x675: 82,
    0x676: 82,
    0x677: 82,
    0x678: 68,
    0x679: 68,
    0x67A: 68,
    0x67B: 68,
    0x67C: 68,
    0x67D: 68,
    0x67E: 68,
    0x67F: 68,
    0x680: 68,
    0x681: 68,
    0x682: 68,
    0x683: 68,
    0x684: 68,
    0x685: 68,
    0x686: 68,
    0x687: 68,
    0x688: 82,
    0x689: 82,
    0x68A: 82,
    0x68B: 82,
    0x68C: 82,
    0x68D: 82,
    0x68E: 82,
    0x68F: 82,
    0x690: 82,
    0x691: 82,
    0x692: 82,
    0x693: 82,
    0x694: 82,
    0x695: 82,
    0x696: 82,
    0x697: 82,
    0x698: 82,
    0x699: 82,
    0x69A: 68,
    0x69B: 68,
    0x69C: 68,
    0x69D: 68,
    0x69E: 68,
    0x69F: 68,
    0x6A0: 68,
    0x6A1: 68,
    0x6A2: 68,
    0x6A3: 68,
    0x6A4: 68,
    0x6A5: 68,
    0x6A6: 68,
    0x6A7: 68,
    0x6A8: 68,
    0x6A9: 68,
    0x6AA: 68,
    0x6AB: 68,
    0x6AC: 68,
    0x6AD: 68,
    0x6AE: 68,
    0x6AF: 68,
    0x6B0: 68,
    0x6B1: 68,
    0x6B2: 68,
    0x6B3: 68,
    0x6B4: 68,
    0x6B5: 68,
    0x6B6: 68,
    0x6B7: 68,
    0x6B8: 68,
    0x6B9: 68,
    0x6BA: 68,
    0x6BB: 68,
    0x6BC: 68,
    0x6BD: 68,
    0x6BE: 68,
    0x6BF: 68,
    0x6C0: 82,
    0x6C1: 68,
    0x6C2: 68,
    0x6C3: 82,
    0x6C4: 82,
    0x6C5: 82,
    0x6C6: 82,
    0x6C7: 82,
    0x6C8: 82,
    0x6C9: 82,
    0x6CA: 82,
    0x6CB: 82,
    0x6CC: 68,
    0x6CD: 82,
    0x6CE: 68,
    0x6CF: 82,
    0x6D0: 68,
    0x6D1: 68,
    0x6D2: 82,
    0x6D3: 82,
    0x6D5: 82,
    0x6D6: 84,
    0x6D7: 84,
    0x6D8: 84,
    0x6D9: 84,
    0x6DA: 84,
    0x6DB: 84,
    0x6DC: 84,
    0x6DF: 84,
    0x6E0: 84,
    0x6E1: 84,
    0x6E2: 84,
    0x6E3: 84,
    0x6E4: 84,
    0x6E7: 84,
    0x6E8: 84,
    0x6EA: 84,
    0x6EB: 84,
    0x6EC: 84,
    0x6ED: 84,
    0x6EE: 82,
    0x6EF: 82,
    0x6FA: 68,
    0x6FB: 68,
    0x6FC: 68,
    0x6FF: 68,
    0x70F: 84,
    0x710: 82,
    0x711: 84,
    0x712: 68,
    0x713: 68,
    0x714: 68,
    0x715: 82,
    0x716: 82,
    0x717: 82,
    0x718: 82,
    0x719: 82,
    0x71A: 68,
    0x71B: 68,
    0x71C: 68,
    0x71D: 68,
    0x71E: 82,
    0x71F: 68,
    0x720: 68,
    0x721: 68,
    0x722: 68,
    0x723: 68,
    0x724: 68,
    0x725: 68,
    0x726: 68,
    0x727: 68,
    0x728: 82,
    0x729: 68,
    0x72A: 82,
    0x72B: 68,
    0x72C: 82,
    0x72D: 68,
    0x72E: 68,
    0x72F: 82,
    0x730: 84,
    0x731: 84,
    0x732: 84,
    0x733: 84,
    0x734: 84,
    0x735: 84,
    0x736: 84,
    0x737: 84,
    0x738: 84,
    0x739: 84,
    0x73A: 84,
    0x73B: 84,
    0x73C: 84,
    0x73D: 84,
    0x73E: 84,
    0x73F: 84,
    0x740: 84,
    0x741: 84,
    0x742: 84,
    0x743: 84,
    0x744: 84,
    0x745: 84,
    0x746: 84,
    0x747: 84,
    0x748: 84,
    0x749: 84,
    0x74A: 84,
    0x74D: 82,
    0x74E: 68,
    0x74F: 68,
    0x750: 68,
    0x751: 68,
    0x752: 68,
    0x753: 68,
    0x754: 68,
    0x755: 68,
    0x756: 68,
    0x757: 68,
    0x758: 68,
    0x759: 82,
    0x75A: 82,
    0x75B: 82,
    0x75C: 68,
    0x75D: 68,
    0x75E: 68,
    0x75F: 68,
    0x760: 68,
    0x761: 68,
    0x762: 68,
    0x763: 68,
    0x764: 68,
    0x765: 68,
    0x766: 68,
    0x767: 68,
    0x768: 68,
    0x769: 68,
    0x76A: 68,
    0x76B: 82,
    0x76C: 82,
    0x76D: 68,
    0x76E: 68,
    0x76F: 68,
    0x770: 68,
    0x771: 82,
    0x772: 68,
    0x773: 82,
    0x774: 82,
    0x775: 68,
    0x776: 68,
    0x777: 68,
    0x778: 82,
    0x779: 82,
    0x77A: 68,
    0x77B: 68,
    0x77C: 68,
    0x77D: 68,
    0x77E: 68,
    0x77F: 68,
    0x7A6: 84,
    0x7A7: 84,
    0x7A8: 84,
    0x7A9: 84,
    0x7AA: 84,
    0x7AB: 84,
    0x7AC: 84,
    0x7AD: 84,
    0x7AE: 84,
    0x7AF: 84,
    0x7B0: 84,
    0x7CA: 68,
    0x7CB: 68,
    0x7CC: 68,
    0x7CD: 68,
    0x7CE: 68,
    0x7CF: 68,
    0x7D0: 68,
    0x7D1: 68,
    0x7D2: 68,
    0x7D3: 68,
    0x7D4: 68,
    0x7D5: 68,
    0x7D6: 68,
    0x7D7: 68,
    0x7D8: 68,
    0x7D9: 68,
    0x7DA: 68,
    0x7DB: 68,
    0x7DC: 68,
    0x7DD: 68,
    0x7DE: 68,
    0x7DF: 68,
    0x7E0: 68,
    0x7E1: 68,
    0x7E2: 68,
    0x7E3: 68,
    0x7E4: 68,
    0x7E5: 68,
    0x7E6: 68,
    0x7E7: 68,
    0x7E8: 68,
    0x7E9: 68,
    0x7EA: 68,
    0x7EB: 84,
    0x7EC: 84,
    0x7ED: 84,
    0x7EE: 84,
    0x7EF: 84,
    0x7F0: 84,
    0x7F1: 84,
    0x7F2: 84,
    0x7F3: 84,
    0x7FA: 67,
    0x7FD: 84,
    0x816: 84,
    0x817: 84,
    0x818: 84,
    0x819: 84,
    0x81B: 84,
    0x81C: 84,
    0x81D: 84,
    0x81E: 84,
    0x81F: 84,
    0x820: 84,
    0x821: 84,
    0x822: 84,
    0x823: 84,
    0x825: 84,
    0x826: 84,
    0x827: 84,
    0x829: 84,
    0x82A: 84,
    0x82B: 84,
    0x82C: 84,
    0x82D: 84,
    0x840: 82,
    0x841: 68,
    0x842: 68,
    0x843: 68,
    0x844: 68,
    0x845: 68,
    0x846: 82,
    0x847: 82,
    0x848: 68,
    0x849: 82,
    0x84A: 68,
    0x84B: 68,
    0x84C: 68,
    0x84D: 68,
    0x84E: 68,
    0x84F: 68,
    0x850: 68,
    0x851: 68,
    0x852: 68,
    0x853: 68,
    0x854: 82,
    0x855: 68,
    0x856: 82,
    0x857: 82,
    0x858: 82,
    0x859: 84,
    0x85A: 84,
    0x85B: 84,
    0x860: 68,
    0x862: 68,
    0x863: 68,
    0x864: 68,
    0x865: 68,
    0x867: 82,
    0x868: 68,
    0x869: 82,
    0x86A: 82,
    0x870: 82,
    0x871: 82,
    0x872: 82,
    0x873: 82,
    0x874: 82,
    0x875: 82,
    0x876: 82,
    0x877: 82,
    0x878: 82,
    0x879: 82,
    0x87A: 82,
    0x87B: 82,
    0x87C: 82,
    0x87D: 82,
    0x87E: 82,
    0x87F: 82,
    0x880: 82,
    0x881: 82,
    0x882: 82,
    0x883: 67,
    0x884: 67,
    0x885: 67,
    0x886: 68,
    0x889: 68,
    0x88A: 68,
    0x88B: 68,
    0x88C: 68,
    0x88D: 68,
    0x88E: 82,
    0x898: 84,
    0x899: 84,
    0x89A: 84,
    0x89B: 84,
    0x89C: 84,
    0x89D: 84,
    0x89E: 84,
    0x89F: 84,
    0x8A0: 68,
    0x8A1: 68,
    0x8A2: 68,
    0x8A3: 68,
    0x8A4: 68,
    0x8A5: 68,
    0x8A6: 68,
    0x8A7: 68,
    0x8A8: 68,
    0x8A9: 68,
    0x8AA: 82,
    0x8AB: 82,
    0x8AC: 82,
    0x8AE: 82,
    0x8AF: 68,
    0x8B0: 68,
    0x8B1: 82,
    0x8B2: 82,
    0x8B3: 68,
    0x8B4: 68,
    0x8B5: 68,
    0x8B6: 68,
    0x8B7: 68,
    0x8B8: 68,
    0x8B9: 82,
    0x8BA: 68,
    0x8BB: 68,
    0x8BC: 68,
    0x8BD: 68,
    0x8BE: 68,
    0x8BF: 68,
    0x8C0: 68,
    0x8C1: 68,
    0x8C2: 68,
    0x8C3: 68,
    0x8C4: 68,
    0x8C5: 68,
    0x8C6: 68,
    0x8C7: 68,
    0x8C8: 68,
    0x8CA: 84,
    0x8CB: 84,
    0x8CC: 84,
    0x8CD: 84,
    0x8CE: 84,
    0x8CF: 84,
    0x8D0: 84,
    0x8D1: 84,
    0x8D2: 84,
    0x8D3: 84,
    0x8D4: 84,
    0x8D5: 84,
    0x8D6: 84,
    0x8D7: 84,
    0x8D8: 84,
    0x8D9: 84,
    0x8DA: 84,
    0x8DB: 84,
    0x8DC: 84,
    0x8DD: 84,
    0x8DE: 84,
    0x8DF: 84,
    0x8E0: 84,
    0x8E1: 84,
    0x8E3: 84,
    0x8E4: 84,
    0x8E5: 84,
    0x8E6: 84,
    0x8E7: 84,
    0x8E8: 84,
    0x8E9: 84,
    0x8EA: 84,
    0x8EB: 84,
    0x8EC: 84,
    0x8ED: 84,
    0x8EE: 84,
    0x8EF: 84,
    0x8F0: 84,
    0x8F1: 84,
    0x8F2: 84,
    0x8F3: 84,
    0x8F4: 84,
    0x8F5: 84,
    0x8F6: 84,
    0x8F7: 84,
    0x8F8: 84,
    0x8F9: 84,
    0x8FA: 84,
    0x8FB: 84,
    0x8FC: 84,
    0x8FD: 84,
    0x8FE: 84,
    0x8FF: 84,
    0x900: 84,
    0x901: 84,
    0x902: 84,
    0x93A: 84,
    0x93C: 84,
    0x941: 84,
    0x942: 84,
    0x943: 84,
    0x944: 84,
    0x945: 84,
    0x946: 84,
    0x947: 84,
    0x948: 84,
    0x94D: 84,
    0x951: 84,
    0x952: 84,
    0x953: 84,
    0x954: 84,
    0x955: 84,
    0x956: 84,
    0x957: 84,
    0x962: 84,
    0x963: 84,
    0x981: 84,
    0x9BC: 84,
    0x9C1: 84,
    0x9C2: 84,
    0x9C3: 84,
    0x9C4: 84,
    0x9CD: 84,
    0x9E2: 84,
    0x9E3: 84,
    0x9FE: 84,
    0xA01: 84,
    0xA02: 84,
    0xA3C: 84,
    0xA41: 84,
    0xA42: 84,
    0xA47: 84,
    0xA48: 84,
    0xA4B: 84,
    0xA4C: 84,
    0xA4D: 84,
    0xA51: 84,
    0xA70: 84,
    0xA71: 84,
    0xA75: 84,
    0xA81: 84,
    0xA82: 84,
    0xABC: 84,
    0xAC1: 84,
    0xAC2: 84,
    0xAC3: 84,
    0xAC4: 84,
    0xAC5: 84,
    0xAC7: 84,
    0xAC8: 84,
    0xACD: 84,
    0xAE2: 84,
    0xAE3: 84,
    0xAFA: 84,
    0xAFB: 84,
    0xAFC: 84,
    0xAFD: 84,
    0xAFE: 84,
    0xAFF: 84,
    0xB01: 84,
    0xB3C: 84,
    0xB3F: 84,
    0xB41: 84,
    0xB42: 84,
    0xB43: 84,
    0xB44: 84,
    0xB4D: 84,
    0xB55: 84,
    0xB56: 84,
    0xB62: 84,
    0xB63: 84,
    0xB82: 84,
    0xBC0: 84,
    0xBCD: 84,
    0xC00: 84,
    0xC04: 84,
    0xC3C: 84,
    0xC3E: 84,
    0xC3F: 84,
    0xC40: 84,
    0xC46: 84,
    0xC47: 84,
    0xC48: 84,
    0xC4A: 84,
    0xC4B: 84,
    0xC4C: 84,
    0xC4D: 84,
    0xC55: 84,
    0xC56: 84,
    0xC62: 84,
    0xC63: 84,
    0xC81: 84,
    0xCBC: 84,
    0xCBF: 84,
    0xCC6: 84,
    0xCCC: 84,
    0xCCD: 84,
    0xCE2: 84,
    0xCE3: 84,
    0xD00: 84,
    0xD01: 84,
    0xD3B: 84,
    0xD3C: 84,
    0xD41: 84,
    0xD42: 84,
    0xD43: 84,
    0xD44: 84,
    0xD4D: 84,
    0xD62: 84,
    0xD63: 84,
    0xD81: 84,
    0xDCA: 84,
    0xDD2: 84,
    0xDD3: 84,
    0xDD4: 84,
    0xDD6: 84,
    0xE31: 84,
    0xE34: 84,
    0xE35: 84,
    0xE36: 84,
    0xE37: 84,
    0xE38: 84,
    0xE39: 84,
    0xE3A: 84,
    0xE47: 84,
    0xE48: 84,
    0xE49: 84,
    0xE4A: 84,
    0xE4B: 84,
    0xE4C: 84,
    0xE4D: 84,
    0xE4E: 84,
    0xEB1: 84,
    0xEB4: 84,
    0xEB5: 84,
    0xEB6: 84,
    0xEB7: 84,
    0xEB8: 84,
    0xEB9: 84,
    0xEBA: 84,
    0xEBB: 84,
    0xEBC: 84,
    0xEC8: 84,
    0xEC9: 84,
    0xECA: 84,
    0xECB: 84,
    0xECC: 84,
    0xECD: 84,
    0xECE: 84,
    0xF18: 84,
    0xF19: 84,
    0xF35: 84,
    0xF37: 84,
    0xF39: 84,
    0xF71: 84,
    0xF72: 84,
    0xF73: 84,
    0xF74: 84,
    0xF75: 84,
    0xF76: 84,
    0xF77: 84,
    0xF78: 84,
    0xF79: 84,
    0xF7A: 84,
    0xF7B: 84,
    0xF7C: 84,
    0xF7D: 84,
    0xF7E: 84,
    0xF80: 84,
    0xF81: 84,
    0xF82: 84,
    0xF83: 84,
    0xF84: 84,
    0xF86: 84,
    0xF87: 84,
    0xF8D: 84,
    0xF8E: 84,
    0xF8F: 84,
    0xF90: 84,
    0xF91: 84,
    0xF92: 84,
    0xF93: 84,
    0xF94: 84,
    0xF95: 84,
    0xF96: 84,
    0xF97: 84,
    0xF99: 84,
    0xF9A: 84,
    0xF9B: 84,
    0xF9C: 84,
    0xF9D: 84,
    0xF9E: 84,
    0xF9F: 84,
    0xFA0: 84,
    0xFA1: 84,
    0xFA2: 84,
    0xFA3: 84,
    0xFA4: 84,
    0xFA5: 84,
    0xFA6: 84,
    0xFA7: 84,
    0xFA8: 84,
    0xFA9: 84,
    0xFAA: 84,
    0xFAB: 84,
    0xFAC: 84,
    0xFAD: 84,
    0xFAE: 84,
    0xFAF: 84,
    0xFB0: 84,
    0xFB1: 84,
    0xFB2: 84,
    0xFB3: 84,
    0xFB4: 84,
    0xFB5: 84,
    0xFB6: 84,
    0xFB7: 84,
    0xFB8: 84,
    0xFB9: 84,
    0xFBA: 84,
    0xFBB: 84,
    0xFBC: 84,
    0xFC6: 84,
    0x102D: 84,
    0x102E: 84,
    0x102F: 84,
    0x1030: 84,
    0x1032: 84,
    0x1033: 84,
    0x1034: 84,
    0x1035: 84,
    0x1036: 84,
    0x1037: 84,
    0x1039: 84,
    0x103A: 84,
    0x103D: 84,
    0x103E: 84,
    0x1058: 84,
    0x1059: 84,
    0x105E: 84,
    0x105F: 84,
    0x1060: 84,
    0x1071: 84,
    0x1072: 84,
    0x1073: 84,
    0x1074: 84,
    0x1082: 84,
    0x1085: 84,
    0x1086: 84,
    0x108D: 84,
    0x109D: 84,
    0x135D: 84,
    0x135E: 84,
    0x135F: 84,
    0x1712: 84,
    0x1713: 84,
    0x1714: 84,
    0x1732: 84,
    0x1733: 84,
    0x1752: 84,
    0x1753: 84,
    0x1772: 84,
    0x1773: 84,
    0x17B4: 84,
    0x17B5: 84,
    0x17B7: 84,
    0x17B8: 84,
    0x17B9: 84,
    0x17BA: 84,
    0x17BB: 84,
    0x17BC: 84,
    0x17BD: 84,
    0x17C6: 84,
    0x17C9: 84,
    0x17CA: 84,
    0x17CB: 84,
    0x17CC: 84,
    0x17CD: 84,
    0x17CE: 84,
    0x17CF: 84,
    0x17D0: 84,
    0x17D1: 84,
    0x17D2: 84,
    0x17D3: 84,
    0x17DD: 84,
    0x1807: 68,
    0x180A: 67,
    0x180B: 84,
    0x180C: 84,
    0x180D: 84,
    0x180F: 84,
    0x1820: 68,
    0x1821: 68,
    0x1822: 68,
    0x1823: 68,
    0x1824: 68,
    0x1825: 68,
    0x1826: 68,
    0x1827: 68,
    0x1828: 68,
    0x1829: 68,
    0x182A: 68,
    0x182B: 68,
    0x182C: 68,
    0x182D: 68,
    0x182E: 68,
    0x182F: 68,
    0x1830: 68,
    0x1831: 68,
    0x1832: 68,
    0x1833: 68,
    0x1834: 68,
    0x1835: 68,
    0x1836: 68,
    0x1837: 68,
    0x1838: 68,
    0x1839: 68,
    0x183A: 68,
    0x183B: 68,
    0x183C: 68,
    0x183D: 68,
    0x183E: 68,
    0x183F: 68,
    0x1840: 68,
    0x1841: 68,
    0x1842: 68,
    0x1843: 68,
    0x1844: 68,
    0x1845: 68,
    0x1846: 68,
    0x1847: 68,
    0x1848: 68,
    0x1849: 68,
    0x184A: 68,
    0x184B: 68,
    0x184C: 68,
    0x184D: 68,
    0x184E: 68,
    0x184F: 68,
    0x1850: 68,
    0x1851: 68,
    0x1852: 68,
    0x1853: 68,
    0x1854: 68,
    0x1855: 68,
    0x1856: 68,
    0x1857: 68,
    0x1858: 68,
    0x1859: 68,
    0x185A: 68,
    0x185B: 68,
    0x185C: 68,
    0x185D: 68,
    0x185E: 68,
    0x185F: 68,
    0x1860: 68,
    0x1861: 68,
    0x1862: 68,
    0x1863: 68,
    0x1864: 68,
    0x1865: 68,
    0x1866: 68,
    0x1867: 68,
    0x1868: 68,
    0x1869: 68,
    0x186A: 68,
    0x186B: 68,
    0x186C: 68,
    0x186D: 68,
    0x186E: 68,
    0x186F: 68,
    0x1870: 68,
    0x1871: 68,
    0x1872: 68,
    0x1873: 68,
    0x1874: 68,
    0x1875: 68,
    0x1876: 68,
    0x1877: 68,
    0x1878: 68,
    0x1885: 84,
    0x1886: 84,
    0x1887: 68,
    0x1888: 68,
    0x1889: 68,
    0x188A: 68,
    0x188B: 68,
    0x188C: 68,
    0x188D: 68,
    0x188E: 68,
    0x188F: 68,
    0x1890: 68,
    0x1891: 68,
    0x1892: 68,
    0x1893: 68,
    0x1894: 68,
    0x1895: 68,
    0x1896: 68,
    0x1897: 68,
    0x1898: 68,
    0x1899: 68,
    0x189A: 68,
    0x189B: 68,
    0x189C: 68,
    0x189D: 68,
    0x189E: 68,
    0x189F: 68,
    0x18A0: 68,
    0x18A1: 68,
    0x18A2: 68,
    0x18A3: 68,
    0x18A4: 68,
    0x18A5: 68,
    0x18A6: 68,
    0x18A7: 68,
    0x18A8: 68,
    0x18A9: 84,
    0x18AA: 68,
    0x1920: 84,
    0x1921: 84,
    0x1922: 84,
    0x1927: 84,
    0x1928: 84,
    0x1932: 84,
    0x1939: 84,
    0x193A: 84,
    0x193B: 84,
    0x1A17: 84,
    0x1A18: 84,
    0x1A1B: 84,
    0x1A56: 84,
    0x1A58: 84,
    0x1A59: 84,
    0x1A5A: 84,
    0x1A5B: 84,
    0x1A5C: 84,
    0x1A5D: 84,
    0x1A5E: 84,
    0x1A60: 84,
    0x1A62: 84,
    0x1A65: 84,
    0x1A66: 84,
    0x1A67: 84,
    0x1A68: 84,
    0x1A69: 84,
    0x1A6A: 84,
    0x1A6B: 84,
    0x1A6C: 84,
    0x1A73: 84,
    0x1A74: 84,
    0x1A75: 84,
    0x1A76: 84,
    0x1A77: 84,
    0x1A78: 84,
    0x1A79: 84,
    0x1A7A: 84,
    0x1A7B: 84,
    0x1A7C: 84,
    0x1A7F: 84,
    0x1AB0: 84,
    0x1AB1: 84,
    0x1AB2: 84,
    0x1AB3: 84,
    0x1AB4: 84,
    0x1AB5: 84,
    0x1AB6: 84,
    0x1AB7: 84,
    0x1AB8: 84,
    0x1AB9: 84,
    0x1ABA: 84,
    0x1ABB: 84,
    0x1ABC: 84,
    0x1ABD: 84,
    0x1ABE: 84,
    0x1ABF: 84,
    0x1AC0: 84,
    0x1AC1: 84,
    0x1AC2: 84,
    0x1AC3: 84,
    0x1AC4: 84,
    0x1AC5: 84,
    0x1AC6: 84,
    0x1AC7: 84,
    0x1AC8: 84,
    0x1AC9: 84,
    0x1ACA: 84,
    0x1ACB: 84,
    0x1ACC: 84,
    0x1ACD: 84,
    0x1ACE: 84,
    0x1B00: 84,
    0x1B01: 84,
    0x1B02: 84,
    0x1B03: 84,
    0x1B34: 84,
    0x1B36: 84,
    0x1B37: 84,
    0x1B38: 84,
    0x1B39: 84,
    0x1B3A: 84,
    0x1B3C: 84,
    0x1B42: 84,
    0x1B6B: 84,
    0x1B6C: 84,
    0x1B6D: 84,
    0x1B6E: 84,
    0x1B6F: 84,
    0x1B70: 84,
    0x1B71: 84,
    0x1B72: 84,
    0x1B73: 84,
    0x1B80: 84,
    0x1B81: 84,
    0x1BA2: 84,
    0x1BA3: 84,
    0x1BA4: 84,
    0x1BA5: 84,
    0x1BA8: 84,
    0x1BA9: 84,
    0x1BAB: 84,
    0x1BAC: 84,
    0x1BAD: 84,
    0x1BE6: 84,
    0x1BE8: 84,
    0x1BE9: 84,
    0x1BED: 84,
    0x1BEF: 84,
    0x1BF0: 84,
    0x1BF1: 84,
    0x1C2C: 84,
    0x1C2D: 84,
    0x1C2E: 84,
    0x1C2F: 84,
    0x1C30: 84,
    0x1C31: 84,
    0x1C32: 84,
    0x1C33: 84,
    0x1C36: 84,
    0x1C37: 84,
    0x1CD0: 84,
    0x1CD1: 84,
    0x1CD2: 84,
    0x1CD4: 84,
    0x1CD5: 84,
    0x1CD6: 84,
    0x1CD7: 84,
    0x1CD8: 84,
    0x1CD9: 84,
    0x1CDA: 84,
    0x1CDB: 84,
    0x1CDC: 84,
    0x1CDD: 84,
    0x1CDE: 84,
    0x1CDF: 84,
    0x1CE0: 84,
    0x1CE2: 84,
    0x1CE3: 84,
    0x1CE4: 84,
    0x1CE5: 84,
    0x1CE6: 84,
    0x1CE7: 84,
    0x1CE8: 84,
    0x1CED: 84,
    0x1CF4: 84,
    0x1CF8: 84,
    0x1CF9: 84,
    0x1DC0: 84,
    0x1DC1: 84,
    0x1DC2: 84,
    0x1DC3: 84,
    0x1DC4: 84,
    0x1DC5: 84,
    0x1DC6: 84,
    0x1DC7: 84,
    0x1DC8: 84,
    0x1DC9: 84,
    0x1DCA: 84,
    0x1DCB: 84,
    0x1DCC: 84,
    0x1DCD: 84,
    0x1DCE: 84,
    0x1DCF: 84,
    0x1DD0: 84,
    0x1DD1: 84,
    0x1DD2: 84,
    0x1DD3: 84,
    0x1DD4: 84,
    0x1DD5: 84,
    0x1DD6: 84,
    0x1DD7: 84,
    0x1DD8: 84,
    0x1DD9: 84,
    0x1DDA: 84,
    0x1DDB: 84,
    0x1DDC: 84,
    0x1DDD: 84,
    0x1DDE: 84,
    0x1DDF: 84,
    0x1DE0: 84,
    0x1DE1: 84,
    0x1DE2: 84,
    0x1DE3: 84,
    0x1DE4: 84,
    0x1DE5: 84,
    0x1DE6: 84,
    0x1DE7: 84,
    0x1DE8: 84,
    0x1DE9: 84,
    0x1DEA: 84,
    0x1DEB: 84,
    0x1DEC: 84,
    0x1DED: 84,
    0x1DEE: 84,
    0x1DEF: 84,
    0x1DF0: 84,
    0x1DF1: 84,
    0x1DF2: 84,
    0x1DF3: 84,
    0x1DF4: 84,
    0x1DF5: 84,
    0x1DF6: 84,
    0x1DF7: 84,
    0x1DF8: 84,
    0x1DF9: 84,
    0x1DFA: 84,
    0x1DFB: 84,
    0x1DFC: 84,
    0x1DFD: 84,
    0x1DFE: 84,
    0x1DFF: 84,
    0x200B: 84,
    0x200D: 67,
    0x200E: 84,
    0x200F: 84,
    0x202A: 84,
    0x202B: 84,
    0x202C: 84,
    0x202D: 84,
    0x202E: 84,
    0x2060: 84,
    0x2061: 84,
    0x2062: 84,
    0x2063: 84,
    0x2064: 84,
    0x206A: 84,
    0x206B: 84,
    0x206C: 84,
    0x206D: 84,
    0x206E: 84,
    0x206F: 84,
    0x20D0: 84,
    0x20D1: 84,
    0x20D2: 84,
    0x20D3: 84,
    0x20D4: 84,
    0x20D5: 84,
    0x20D6: 84,
    0x20D7: 84,
    0x20D8: 84,
    0x20D9: 84,
    0x20DA: 84,
    0x20DB: 84,
    0x20DC: 84,
    0x20DD: 84,
    0x20DE: 84,
    0x20DF: 84,
    0x20E0: 84,
    0x20E1: 84,
    0x20E2: 84,
    0x20E3: 84,
    0x20E4: 84,
    0x20E5: 84,
    0x20E6: 84,
    0x20E7: 84,
    0x20E8: 84,
    0x20E9: 84,
    0x20EA: 84,
    0x20EB: 84,
    0x20EC: 84,
    0x20ED: 84,
    0x20EE: 84,
    0x20EF: 84,
    0x20F0: 84,
    0x2CEF: 84,
    0x2CF0: 84,
    0x2CF1: 84,
    0x2D7F: 84,
    0x2DE0: 84,
    0x2DE1: 84,
    0x2DE2: 84,
    0x2DE3: 84,
    0x2DE4: 84,
    0x2DE5: 84,
    0x2DE6: 84,
    0x2DE7: 84,
    0x2DE8: 84,
    0x2DE9: 84,
    0x2DEA: 84,
    0x2DEB: 84,
    0x2DEC: 84,
    0x2DED: 84,
    0x2DEE: 84,
    0x2DEF: 84,
    0x2DF0: 84,
    0x2DF1: 84,
    0x2DF2: 84,
    0x2DF3: 84,
    0x2DF4: 84,
    0x2DF5: 84,
    0x2DF6: 84,
    0x2DF7: 84,
    0x2DF8: 84,
    0x2DF9: 84,
    0x2DFA: 84,
    0x2DFB: 84,
    0x2DFC: 84,
    0x2DFD: 84,
    0x2DFE: 84,
    0x2DFF: 84,
    0x302A: 84,
    0x302B: 84,
    0x302C: 84,
    0x302D: 84,
    0x3099: 84,
    0x309A: 84,
    0xA66F: 84,
    0xA670: 84,
    0xA671: 84,
    0xA672: 84,
    0xA674: 84,
    0xA675: 84,
    0xA676: 84,
    0xA677: 84,
    0xA678: 84,
    0xA679: 84,
    0xA67A: 84,
    0xA67B: 84,
    0xA67C: 84,
    0xA67D: 84,
    0xA69E: 84,
    0xA69F: 84,
    0xA6F0: 84,
    0xA6F1: 84,
    0xA802: 84,
    0xA806: 84,
    0xA80B: 84,
    0xA825: 84,
    0xA826: 84,
    0xA82C: 84,
    0xA840: 68,
    0xA841: 68,
    0xA842: 68,
    0xA843: 68,
    0xA844: 68,
    0xA845: 68,
    0xA846: 68,
    0xA847: 68,
    0xA848: 68,
    0xA849: 68,
    0xA84A: 68,
    0xA84B: 68,
    0xA84C: 68,
    0xA84D: 68,
    0xA84E: 68,
    0xA84F: 68,
    0xA850: 68,
    0xA851: 68,
    0xA852: 68,
    0xA853: 68,
    0xA854: 68,
    0xA855: 68,
    0xA856: 68,
    0xA857: 68,
    0xA858: 68,
    0xA859: 68,
    0xA85A: 68,
    0xA85B: 68,
    0xA85C: 68,
    0xA85D: 68,
    0xA85E: 68,
    0xA85F: 68,
    0xA860: 68,
    0xA861: 68,
    0xA862: 68,
    0xA863: 68,
    0xA864: 68,
    0xA865: 68,
    0xA866: 68,
    0xA867: 68,
    0xA868: 68,
    0xA869: 68,
    0xA86A: 68,
    0xA86B: 68,
    0xA86C: 68,
    0xA86D: 68,
    0xA86E: 68,
    0xA86F: 68,
    0xA870: 68,
    0xA871: 68,
    0xA872: 76,
    0xA8C4: 84,
    0xA8C5: 84,
    0xA8E0: 84,
    0xA8E1: 84,
    0xA8E2: 84,
    0xA8E3: 84,
    0xA8E4: 84,
    0xA8E5: 84,
    0xA8E6: 84,
    0xA8E7: 84,
    0xA8E8: 84,
    0xA8E9: 84,
    0xA8EA: 84,
    0xA8EB: 84,
    0xA8EC: 84,
    0xA8ED: 84,
    0xA8EE: 84,
    0xA8EF: 84,
    0xA8F0: 84,
    0xA8F1: 84,
    0xA8FF: 84,
    0xA926: 84,
    0xA927: 84,
    0xA928: 84,
    0xA929: 84,
    0xA92A: 84,
    0xA92B: 84,
    0xA92C: 84,
    0xA92D: 84,
    0xA947: 84,
    0xA948: 84,
    0xA949: 84,
    0xA94A: 84,
    0xA94B: 84,
    0xA94C: 84,
    0xA94D: 84,
    0xA94E: 84,
    0xA94F: 84,
    0xA950: 84,
    0xA951: 84,
    0xA980: 84,
    0xA981: 84,
    0xA982: 84,
    0xA9B3: 84,
    0xA9B6: 84,
    0xA9B7: 84,
    0xA9B8: 84,
    0xA9B9: 84,
    0xA9BC: 84,
    0xA9BD: 84,
    0xA9E5: 84,
    0xAA29: 84,
    0xAA2A: 84,
    0xAA2B: 84,
    0xAA2C: 84,
    0xAA2D: 84,
    0xAA2E: 84,
    0xAA31: 84,
    0xAA32: 84,
    0xAA35: 84,
    0xAA36: 84,
    0xAA43: 84,
    0xAA4C: 84,
    0xAA7C: 84,
    0xAAB0: 84,
    0xAAB2: 84,
    0xAAB3: 84,
    0xAAB4: 84,
    0xAAB7: 84,
    0xAAB8: 84,
    0xAABE: 84,
    0xAABF: 84,
    0xAAC1: 84,
    0xAAEC: 84,
    0xAAED: 84,
    0xAAF6: 84,
    0xABE5: 84,
    0xABE8: 84,
    0xABED: 84,
    0xFB1E: 84,
    0xFE00: 84,
    0xFE01: 84,
    0xFE02: 84,
    0xFE03: 84,
    0xFE04: 84,
    0xFE05: 84,
    0xFE06: 84,
    0xFE07: 84,
    0xFE08: 84,
    0xFE09: 84,
    0xFE0A: 84,
    0xFE0B: 84,
    0xFE0C: 84,
    0xFE0D: 84,
    0xFE0E: 84,
    0xFE0F: 84,
    0xFE20: 84,
    0xFE21: 84,
    0xFE22: 84,
    0xFE23: 84,
    0xFE24: 84,
    0xFE25: 84,
    0xFE26: 84,
    0xFE27: 84,
    0xFE28: 84,
    0xFE29: 84,
    0xFE2A: 84,
    0xFE2B: 84,
    0xFE2C: 84,
    0xFE2D: 84,
    0xFE2E: 84,
    0xFE2F: 84,
    0xFEFF: 84,
    0xFFF9: 84,
    0xFFFA: 84,
    0xFFFB: 84,
    0x101FD: 84,
    0x102E0: 84,
    0x10376: 84,
    0x10377: 84,
    0x10378: 84,
    0x10379: 84,
    0x1037A: 84,
    0x10A01: 84,
    0x10A02: 84,
    0x10A03: 84,
    0x10A05: 84,
    0x10A06: 84,
    0x10A0C: 84,
    0x10A0D: 84,
    0x10A0E: 84,
    0x10A0F: 84,
    0x10A38: 84,
    0x10A39: 84,
    0x10A3A: 84,
    0x10A3F: 84,
    0x10AC0: 68,
    0x10AC1: 68,
    0x10AC2: 68,
    0x10AC3: 68,
    0x10AC4: 68,
    0x10AC5: 82,
    0x10AC7: 82,
    0x10AC9: 82,
    0x10ACA: 82,
    0x10ACD: 76,
    0x10ACE: 82,
    0x10ACF: 82,
    0x10AD0: 82,
    0x10AD1: 82,
    0x10AD2: 82,
    0x10AD3: 68,
    0x10AD4: 68,
    0x10AD5: 68,
    0x10AD6: 68,
    0x10AD7: 76,
    0x10AD8: 68,
    0x10AD9: 68,
    0x10ADA: 68,
    0x10ADB: 68,
    0x10ADC: 68,
    0x10ADD: 82,
    0x10ADE: 68,
    0x10ADF: 68,
    0x10AE0: 68,
    0x10AE1: 82,
    0x10AE4: 82,
    0x10AE5: 84,
    0x10AE6: 84,
    0x10AEB: 68,
    0x10AEC: 68,
    0x10AED: 68,
    0x10AEE: 68,
    0x10AEF: 82,
    0x10B80: 68,
    0x10B81: 82,
    0x10B82: 68,
    0x10B83: 82,
    0x10B84: 82,
    0x10B85: 82,
    0x10B86: 68,
    0x10B87: 68,
    0x10B88: 68,
    0x10B89: 82,
    0x10B8A: 68,
    0x10B8B: 68,
    0x10B8C: 82,
    0x10B8D: 68,
    0x10B8E: 82,
    0x10B8F: 82,
    0x10B90: 68,
    0x10B91: 82,
    0x10BA9: 82,
    0x10BAA: 82,
    0x10BAB: 82,
    0x10BAC: 82,
    0x10BAD: 68,
    0x10BAE: 68,
    0x10D00: 76,
    0x10D01: 68,
    0x10D02: 68,
    0x10D03: 68,
    0x10D04: 68,
    0x10D05: 68,
    0x10D06: 68,
    0x10D07: 68,
    0x10D08: 68,
    0x10D09: 68,
    0x10D0A: 68,
    0x10D0B: 68,
    0x10D0C: 68,
    0x10D0D: 68,
    0x10D0E: 68,
    0x10D0F: 68,
    0x10D10: 68,
    0x10D11: 68,
    0x10D12: 68,
    0x10D13: 68,
    0x10D14: 68,
    0x10D15: 68,
    0x10D16: 68,
    0x10D17: 68,
    0x10D18: 68,
    0x10D19: 68,
    0x10D1A: 68,
    0x10D1B: 68,
    0x10D1C: 68,
    0x10D1D: 68,
    0x10D1E: 68,
    0x10D1F: 68,
    0x10D20: 68,
    0x10D21: 68,
    0x10D22: 82,
    0x10D23: 68,
    0x10D24: 84,
    0x10D25: 84,
    0x10D26: 84,
    0x10D27: 84,
    0x10EAB: 84,
    0x10EAC: 84,
    0x10EFD: 84,
    0x10EFE: 84,
    0x10EFF: 84,
    0x10F30: 68,
    0x10F31: 68,
    0x10F32: 68,
    0x10F33: 82,
    0x10F34: 68,
    0x10F35: 68,
    0x10F36: 68,
    0x10F37: 68,
    0x10F38: 68,
    0x10F39: 68,
    0x10F3A: 68,
    0x10F3B: 68,
    0x10F3C: 68,
    0x10F3D: 68,
    0x10F3E: 68,
    0x10F3F: 68,
    0x10F40: 68,
    0x10F41: 68,
    0x10F42: 68,
    0x10F43: 68,
    0x10F44: 68,
    0x10F46: 84,
    0x10F47: 84,
    0x10F48: 84,
    0x10F49: 84,
    0x10F4A: 84,
    0x10F4B: 84,
    0x10F4C: 84,
    0x10F4D: 84,
    0x10F4E: 84,
    0x10F4F: 84,
    0x10F50: 84,
    0x10F51: 68,
    0x10F52: 68,
    0x10F53: 68,
    0x10F54: 82,
    0x10F70: 68,
    0x10F71: 68,
    0x10F72: 68,
    0x10F73: 68,
    0x10F74: 82,
    0x10F75: 82,
    0x10F76: 68,
    0x10F77: 68,
    0x10F78: 68,
    0x10F79: 68,
    0x10F7A: 68,
    0x10F7B: 68,
    0x10F7C: 68,
    0x10F7D: 68,
    0x10F7E: 68,
    0x10F7F: 68,
    0x10F80: 68,
    0x10F81: 68,
    0x10F82: 84,
    0x10F83: 84,
    0x10F84: 84,
    0x10F85: 84,
    0x10FB0: 68,
    0x10FB2: 68,
    0x10FB3: 68,
    0x10FB4: 82,
    0x10FB5: 82,
    0x10FB6: 82,
    0x10FB8: 68,
    0x10FB9: 82,
    0x10FBA: 82,
    0x10FBB: 68,
    0x10FBC: 68,
    0x10FBD: 82,
    0x10FBE: 68,
    0x10FBF: 68,
    0x10FC1: 68,
    0x10FC2: 82,
    0x10FC3: 82,
    0x10FC4: 68,
    0x10FC9: 82,
    0x10FCA: 68,
    0x10FCB: 76,
    0x11001: 84,
    0x11038: 84,
    0x11039: 84,
    0x1103A: 84,
    0x1103B: 84,
    0x1103C: 84,
    0x1103D: 84,
    0x1103E: 84,
    0x1103F: 84,
    0x11040: 84,
    0x11041: 84,
    0x11042: 84,
    0x11043: 84,
    0x11044: 84,
    0x11045: 84,
    0x11046: 84,
    0x11070: 84,
    0x11073: 84,
    0x11074: 84,
    0x1107F: 84,
    0x11080: 84,
    0x11081: 84,
    0x110B3: 84,
    0x110B4: 84,
    0x110B5: 84,
    0x110B6: 84,
    0x110B9: 84,
    0x110BA: 84,
    0x110C2: 84,
    0x11100: 84,
    0x11101: 84,
    0x11102: 84,
    0x11127: 84,
    0x11128: 84,
    0x11129: 84,
    0x1112A: 84,
    0x1112B: 84,
    0x1112D: 84,
    0x1112E: 84,
    0x1112F: 84,
    0x11130: 84,
    0x11131: 84,
    0x11132: 84,
    0x11133: 84,
    0x11134: 84,
    0x11173: 84,
    0x11180: 84,
    0x11181: 84,
    0x111B6: 84,
    0x111B7: 84,
    0x111B8: 84,
    0x111B9: 84,
    0x111BA: 84,
    0x111BB: 84,
    0x111BC: 84,
    0x111BD: 84,
    0x111BE: 84,
    0x111C9: 84,
    0x111CA: 84,
    0x111CB: 84,
    0x111CC: 84,
    0x111CF: 84,
    0x1122F: 84,
    0x11230: 84,
    0x11231: 84,
    0x11234: 84,
    0x11236: 84,
    0x11237: 84,
    0x1123E: 84,
    0x11241: 84,
    0x112DF: 84,
    0x112E3: 84,
    0x112E4: 84,
    0x112E5: 84,
    0x112E6: 84,
    0x112E7: 84,
    0x112E8: 84,
    0x112E9: 84,
    0x112EA: 84,
    0x11300: 84,
    0x11301: 84,
    0x1133B: 84,
    0x1133C: 84,
    0x11340: 84,
    0x11366: 84,
    0x11367: 84,
    0x11368: 84,
    0x11369: 84,
    0x1136A: 84,
    0x1136B: 84,
    0x1136C: 84,
    0x11370: 84,
    0x11371: 84,
    0x11372: 84,
    0x11373: 84,
    0x11374: 84,
    0x11438: 84,
    0x11439: 84,
    0x1143A: 84,
    0x1143B: 84,
    0x1143C: 84,
    0x1143D: 84,
    0x1143E: 84,
    0x1143F: 84,
    0x11442: 84,
    0x11443: 84,
    0x11444: 84,
    0x11446: 84,
    0x1145E: 84,
    0x114B3: 84,
    0x114B4: 84,
    0x114B5: 84,
    0x114B6: 84,
    0x114B7: 84,
    0x114B8: 84,
    0x114BA: 84,
    0x114BF: 84,
    0x114C0: 84,
    0x114C2: 84,
    0x114C3: 84,
    0x115B2: 84,
    0x115B3: 84,
    0x115B4: 84,
    0x115B5: 84,
    0x115BC: 84,
    0x115BD: 84,
    0x115BF: 84,
    0x115C0: 84,
    0x115DC: 84,
    0x115DD: 84,
    0x11633: 84,
    0x11634: 84,
    0x11635: 84,
    0x11636: 84,
    0x11637: 84,
    0x11638: 84,
    0x11639: 84,
    0x1163A: 84,
    0x1163D: 84,
    0x1163F: 84,
    0x11640: 84,
    0x116AB: 84,
    0x116AD: 84,
    0x116B0: 84,
    0x116B1: 84,
    0x116B2: 84,
    0x116B3: 84,
    0x116B4: 84,
    0x116B5: 84,
    0x116B7: 84,
    0x1171D: 84,
    0x1171E: 84,
    0x1171F: 84,
    0x11722: 84,
    0x11723: 84,
    0x11724: 84,
    0x11725: 84,
    0x11727: 84,
    0x11728: 84,
    0x11729: 84,
    0x1172A: 84,
    0x1172B: 84,
    0x1182F: 84,
    0x11830: 84,
    0x11831: 84,
    0x11832: 84,
    0x11833: 84,
    0x11834: 84,
    0x11835: 84,
    0x11836: 84,
    0x11837: 84,
    0x11839: 84,
    0x1183A: 84,
    0x1193B: 84,
    0x1193C: 84,
    0x1193E: 84,
    0x11943: 84,
    0x119D4: 84,
    0x119D5: 84,
    0x119D6: 84,
    0x119D7: 84,
    0x119DA: 84,
    0x119DB: 84,
    0x119E0: 84,
    0x11A01: 84,
    0x11A02: 84,
    0x11A03: 84,
    0x11A04: 84,
    0x11A05: 84,
    0x11A06: 84,
    0x11A07: 84,
    0x11A08: 84,
    0x11A09: 84,
    0x11A0A: 84,
    0x11A33: 84,
    0x11A34: 84,
    0x11A35: 84,
    0x11A36: 84,
    0x11A37: 84,
    0x11A38: 84,
    0x11A3B: 84,
    0x11A3C: 84,
    0x11A3D: 84,
    0x11A3E: 84,
    0x11A47: 84,
    0x11A51: 84,
    0x11A52: 84,
    0x11A53: 84,
    0x11A54: 84,
    0x11A55: 84,
    0x11A56: 84,
    0x11A59: 84,
    0x11A5A: 84,
    0x11A5B: 84,
    0x11A8A: 84,
    0x11A8B: 84,
    0x11A8C: 84,
    0x11A8D: 84,
    0x11A8E: 84,
    0x11A8F: 84,
    0x11A90: 84,
    0x11A91: 84,
    0x11A92: 84,
    0x11A93: 84,
    0x11A94: 84,
    0x11A95: 84,
    0x11A96: 84,
    0x11A98: 84,
    0x11A99: 84,
    0x11C30: 84,
    0x11C31: 84,
    0x11C32: 84,
    0x11C33: 84,
    0x11C34: 84,
    0x11C35: 84,
    0x11C36: 84,
    0x11C38: 84,
    0x11C39: 84,
    0x11C3A: 84,
    0x11C3B: 84,
    0x11C3C: 84,
    0x11C3D: 84,
    0x11C3F: 84,
    0x11C92: 84,
    0x11C93: 84,
    0x11C94: 84,
    0x11C95: 84,
    0x11C96: 84,
    0x11C97: 84,
    0x11C98: 84,
    0x11C99: 84,
    0x11C9A: 84,
    0x11C9B: 84,
    0x11C9C: 84,
    0x11C9D: 84,
    0x11C9E: 84,
    0x11C9F: 84,
    0x11CA0: 84,
    0x11CA1: 84,
    0x11CA2: 84,
    0x11CA3: 84,
    0x11CA4: 84,
    0x11CA5: 84,
    0x11CA6: 84,
    0x11CA7: 84,
    0x11CAA: 84,
    0x11CAB: 84,
    0x11CAC: 84,
    0x11CAD: 84,
    0x11CAE: 84,
    0x11CAF: 84,
    0x11CB0: 84,
    0x11CB2: 84,
    0x11CB3: 84,
    0x11CB5: 84,
    0x11CB6: 84,
    0x11D31: 84,
    0x11D32: 84,
    0x11D33: 84,
    0x11D34: 84,
    0x11D35: 84,
    0x11D36: 84,
    0x11D3A: 84,
    0x11D3C: 84,
    0x11D3D: 84,
    0x11D3F: 84,
    0x11D40: 84,
    0x11D41: 84,
    0x11D42: 84,
    0x11D43: 84,
    0x11D44: 84,
    0x11D45: 84,
    0x11D47: 84,
    0x11D90: 84,
    0x11D91: 84,
    0x11D95: 84,
    0x11D97: 84,
    0x11EF3: 84,
    0x11EF4: 84,
    0x11F00: 84,
    0x11F01: 84,
    0x11F36: 84,
    0x11F37: 84,
    0x11F38: 84,
    0x11F39: 84,
    0x11F3A: 84,
    0x11F40: 84,
    0x11F42: 84,
    0x13430: 84,
    0x13431: 84,
    0x13432: 84,
    0x13433: 84,
    0x13434: 84,
    0x13435: 84,
    0x13436: 84,
    0x13437: 84,
    0x13438: 84,
    0x13439: 84,
    0x1343A: 84,
    0x1343B: 84,
    0x1343C: 84,
    0x1343D: 84,
    0x1343E: 84,
    0x1343F: 84,
    0x13440: 84,
    0x13447: 84,
    0x13448: 84,
    0x13449: 84,
    0x1344A: 84,
    0x1344B: 84,
    0x1344C: 84,
    0x1344D: 84,
    0x1344E: 84,
    0x1344F: 84,
    0x13450: 84,
    0x13451: 84,
    0x13452: 84,
    0x13453: 84,
    0x13454: 84,
    0x13455: 84,
    0x16AF0: 84,
    0x16AF1: 84,
    0x16AF2: 84,
    0x16AF3: 84,
    0x16AF4: 84,
    0x16B30: 84,
    0x16B31: 84,
    0x16B32: 84,
    0x16B33: 84,
    0x16B34: 84,
    0x16B35: 84,
    0x16B36: 84,
    0x16F4F: 84,
    0x16F8F: 84,
    0x16F90: 84,
    0x16F91: 84,
    0x16F92: 84,
    0x16FE4: 84,
    0x1BC9D: 84,
    0x1BC9E: 84,
    0x1BCA0: 84,
    0x1BCA1: 84,
    0x1BCA2: 84,
    0x1BCA3: 84,
    0x1CF00: 84,
    0x1CF01: 84,
    0x1CF02: 84,
    0x1CF03: 84,
    0x1CF04: 84,
    0x1CF05: 84,
    0x1CF06: 84,
    0x1CF07: 84,
    0x1CF08: 84,
    0x1CF09: 84,
    0x1CF0A: 84,
    0x1CF0B: 84,
    0x1CF0C: 84,
    0x1CF0D: 84,
    0x1CF0E: 84,
    0x1CF0F: 84,
    0x1CF10: 84,
    0x1CF11: 84,
    0x1CF12: 84,
    0x1CF13: 84,
    0x1CF14: 84,
    0x1CF15: 84,
    0x1CF16: 84,
    0x1CF17: 84,
    0x1CF18: 84,
    0x1CF19: 84,
    0x1CF1A: 84,
    0x1CF1B: 84,
    0x1CF1C: 84,
    0x1CF1D: 84,
    0x1CF1E: 84,
    0x1CF1F: 84,
    0x1CF20: 84,
    0x1CF21: 84,
    0x1CF22: 84,
    0x1CF23: 84,
    0x1CF24: 84,
    0x1CF25: 84,
    0x1CF26: 84,
    0x1CF27: 84,
    0x1CF28: 84,
    0x1CF29: 84,
    0x1CF2A: 84,
    0x1CF2B: 84,
    0x1CF2C: 84,
    0x1CF2D: 84,
    0x1CF30: 84,
    0x1CF31: 84,
    0x1CF32: 84,
    0x1CF33: 84,
    0x1CF34: 84,
    0x1CF35: 84,
    0x1CF36: 84,
    0x1CF37: 84,
    0x1CF38: 84,
    0x1CF39: 84,
    0x1CF3A: 84,
    0x1CF3B: 84,
    0x1CF3C: 84,
    0x1CF3D: 84,
    0x1CF3E: 84,
    0x1CF3F: 84,
    0x1CF40: 84,
    0x1CF41: 84,
    0x1CF42: 84,
    0x1CF43: 84,
    0x1CF44: 84,
    0x1CF45: 84,
    0x1CF46: 84,
    0x1D167: 84,
    0x1D168: 84,
    0x1D169: 84,
    0x1D173: 84,
    0x1D174: 84,
    0x1D175: 84,
    0x1D176: 84,
    0x1D177: 84,
    0x1D178: 84,
    0x1D179: 84,
    0x1D17A: 84,
    0x1D17B: 84,
    0x1D17C: 84,
    0x1D17D: 84,
    0x1D17E: 84,
    0x1D17F: 84,
    0x1D180: 84,
    0x1D181: 84,
    0x1D182: 84,
    0x1D185: 84,
    0x1D186: 84,
    0x1D187: 84,
    0x1D188: 84,
    0x1D189: 84,
    0x1D18A: 84,
    0x1D18B: 84,
    0x1D1AA: 84,
    0x1D1AB: 84,
    0x1D1AC: 84,
    0x1D1AD: 84,
    0x1D242: 84,
    0x1D243: 84,
    0x1D244: 84,
    0x1DA00: 84,
    0x1DA01: 84,
    0x1DA02: 84,
    0x1DA03: 84,
    0x1DA04: 84,
    0x1DA05: 84,
    0x1DA06: 84,
    0x1DA07: 84,
    0x1DA08: 84,
    0x1DA09: 84,
    0x1DA0A: 84,
    0x1DA0B: 84,
    0x1DA0C: 84,
    0x1DA0D: 84,
    0x1DA0E: 84,
    0x1DA0F: 84,
    0x1DA10: 84,
    0x1DA11: 84,
    0x1DA12: 84,
    0x1DA13: 84,
    0x1DA14: 84,
    0x1DA15: 84,
    0x1DA16: 84,
    0x1DA17: 84,
    0x1DA18: 84,
    0x1DA19: 84,
    0x1DA1A: 84,
    0x1DA1B: 84,
    0x1DA1C: 84,
    0x1DA1D: 84,
    0x1DA1E: 84,
    0x1DA1F: 84,
    0x1DA20: 84,
    0x1DA21: 84,
    0x1DA22: 84,
    0x1DA23: 84,
    0x1DA24: 84,
    0x1DA25: 84,
    0x1DA26: 84,
    0x1DA27: 84,
    0x1DA28: 84,
    0x1DA29: 84,
    0x1DA2A: 84,
    0x1DA2B: 84,
    0x1DA2C: 84,
    0x1DA2D: 84,
    0x1DA2E: 84,
    0x1DA2F: 84,
    0x1DA30: 84,
    0x1DA31: 84,
    0x1DA32: 84,
    0x1DA33: 84,
    0x1DA34: 84,
    0x1DA35: 84,
    0x1DA36: 84,
    0x1DA3B: 84,
    0x1DA3C: 84,
    0x1DA3D: 84,
    0x1DA3E: 84,
    0x1DA3F: 84,
    0x1DA40: 84,
    0x1DA41: 84,
    0x1DA42: 84,
    0x1DA43: 84,
    0x1DA44: 84,
    0x1DA45: 84,
    0x1DA46: 84,
    0x1DA47: 84,
    0x1DA48: 84,
    0x1DA49: 84,
    0x1DA4A: 84,
    0x1DA4B: 84,
    0x1DA4C: 84,
    0x1DA4D: 84,
    0x1DA4E: 84,
    0x1DA4F: 84,
    0x1DA50: 84,
    0x1DA51: 84,
    0x1DA52: 84,
    0x1DA53: 84,
    0x1DA54: 84,
    0x1DA55: 84,
    0x1DA56: 84,
    0x1DA57: 84,
    0x1DA58: 84,
    0x1DA59: 84,
    0x1DA5A: 84,
    0x1DA5B: 84,
    0x1DA5C: 84,
    0x1DA5D: 84,
    0x1DA5E: 84,
    0x1DA5F: 84,
    0x1DA60: 84,
    0x1DA61: 84,
    0x1DA62: 84,
    0x1DA63: 84,
    0x1DA64: 84,
    0x1DA65: 84,
    0x1DA66: 84,
    0x1DA67: 84,
    0x1DA68: 84,
    0x1DA69: 84,
    0x1DA6A: 84,
    0x1DA6B: 84,
    0x1DA6C: 84,
    0x1DA75: 84,
    0x1DA84: 84,
    0x1DA9B: 84,
    0x1DA9C: 84,
    0x1DA9D: 84,
    0x1DA9E: 84,
    0x1DA9F: 84,
    0x1DAA1: 84,
    0x1DAA2: 84,
    0x1DAA3: 84,
    0x1DAA4: 84,
    0x1DAA5: 84,
    0x1DAA6: 84,
    0x1DAA7: 84,
    0x1DAA8: 84,
    0x1DAA9: 84,
    0x1DAAA: 84,
    0x1DAAB: 84,
    0x1DAAC: 84,
    0x1DAAD: 84,
    0x1DAAE: 84,
    0x1DAAF: 84,
    0x1E000: 84,
    0x1E001: 84,
    0x1E002: 84,
    0x1E003: 84,
    0x1E004: 84,
    0x1E005: 84,
    0x1E006: 84,
    0x1E008: 84,
    0x1E009: 84,
    0x1E00A: 84,
    0x1E00B: 84,
    0x1E00C: 84,
    0x1E00D: 84,
    0x1E00E: 84,
    0x1E00F: 84,
    0x1E010: 84,
    0x1E011: 84,
    0x1E012: 84,
    0x1E013: 84,
    0x1E014: 84,
    0x1E015: 84,
    0x1E016: 84,
    0x1E017: 84,
    0x1E018: 84,
    0x1E01B: 84,
    0x1E01C: 84,
    0x1E01D: 84,
    0x1E01E: 84,
    0x1E01F: 84,
    0x1E020: 84,
    0x1E021: 84,
    0x1E023: 84,
    0x1E024: 84,
    0x1E026: 84,
    0x1E027: 84,
    0x1E028: 84,
    0x1E029: 84,
    0x1E02A: 84,
    0x1E08F: 84,
    0x1E130: 84,
    0x1E131: 84,
    0x1E132: 84,
    0x1E133: 84,
    0x1E134: 84,
    0x1E135: 84,
    0x1E136: 84,
    0x1E2AE: 84,
    0x1E2EC: 84,
    0x1E2ED: 84,
    0x1E2EE: 84,
    0x1E2EF: 84,
    0x1E4EC: 84,
    0x1E4ED: 84,
    0x1E4EE: 84,
    0x1E4EF: 84,
    0x1E8D0: 84,
    0x1E8D1: 84,
    0x1E8D2: 84,
    0x1E8D3: 84,
    0x1E8D4: 84,
    0x1E8D5: 84,
    0x1E8D6: 84,
    0x1E900: 68,
    0x1E901: 68,
    0x1E902: 68,
    0x1E903: 68,
    0x1E904: 68,
    0x1E905: 68,
    0x1E906: 68,
    0x1E907: 68,
    0x1E908: 68,
    0x1E909: 68,
    0x1E90A: 68,
    0x1E90B: 68,
    0x1E90C: 68,
    0x1E90D: 68,
    0x1E90E: 68,
    0x1E90F: 68,
    0x1E910: 68,
    0x1E911: 68,
    0x1E912: 68,
    0x1E913: 68,
    0x1E914: 68,
    0x1E915: 68,
    0x1E916: 68,
    0x1E917: 68,
    0x1E918: 68,
    0x1E919: 68,
    0x1E91A: 68,
    0x1E91B: 68,
    0x1E91C: 68,
    0x1E91D: 68,
    0x1E91E: 68,
    0x1E91F: 68,
    0x1E920: 68,
    0x1E921: 68,
    0x1E922: 68,
    0x1E923: 68,
    0x1E924: 68,
    0x1E925: 68,
    0x1E926: 68,
    0x1E927: 68,
    0x1E928: 68,
    0x1E929: 68,
    0x1E92A: 68,
    0x1E92B: 68,
    0x1E92C: 68,
    0x1E92D: 68,
    0x1E92E: 68,
    0x1E92F: 68,
    0x1E930: 68,
    0x1E931: 68,
    0x1E932: 68,
    0x1E933: 68,
    0x1E934: 68,
    0x1E935: 68,
    0x1E936: 68,
    0x1E937: 68,
    0x1E938: 68,
    0x1E939: 68,
    0x1E93A: 68,
    0x1E93B: 68,
    0x1E93C: 68,
    0x1E93D: 68,
    0x1E93E: 68,
    0x1E93F: 68,
    0x1E940: 68,
    0x1E941: 68,
    0x1E942: 68,
    0x1E943: 68,
    0x1E944: 84,
    0x1E945: 84,
    0x1E946: 84,
    0x1E947: 84,
    0x1E948: 84,
    0x1E949: 84,
    0x1E94A: 84,
    0x1E94B: 84,
    0xE0001: 84,
    0xE0020: 84,
    0xE0021: 84,
    0xE0022: 84,
    0xE0023: 84,
    0xE0024: 84,
    0xE0025: 84,
    0xE0026: 84,
    0xE0027: 84,
    0xE0028: 84,
    0xE0029: 84,
    0xE002A: 84,
    0xE002B: 84,
    0xE002C: 84,
    0xE002D: 84,
    0xE002E: 84,
    0xE002F: 84,
    0xE0030: 84,
    0xE0031: 84,
    0xE0032: 84,
    0xE0033: 84,
    0xE0034: 84,
    0xE0035: 84,
    0xE0036: 84,
    0xE0037: 84,
    0xE0038: 84,
    0xE0039: 84,
    0xE003A: 84,
    0xE003B: 84,
    0xE003C: 84,
    0xE003D: 84,
    0xE003E: 84,
    0xE003F: 84,
    0xE0040: 84,
    0xE0041: 84,
    0xE0042: 84,
    0xE0043: 84,
    0xE0044: 84,
    0xE0045: 84,
    0xE0046: 84,
    0xE0047: 84,
    0xE0048: 84,
    0xE0049: 84,
    0xE004A: 84,
    0xE004B: 84,
    0xE004C: 84,
    0xE004D: 84,
    0xE004E: 84,
    0xE004F: 84,
    0xE0050: 84,
    0xE0051: 84,
    0xE0052: 84,
    0xE0053: 84,
    0xE0054: 84,
    0xE0055: 84,
    0xE0056: 84,
    0xE0057: 84,
    0xE0058: 84,
    0xE0059: 84,
    0xE005A: 84,
    0xE005B: 84,
    0xE005C: 84,
    0xE005D: 84,
    0xE005E: 84,
    0xE005F: 84,
    0xE0060: 84,
    0xE0061: 84,
    0xE0062: 84,
    0xE0063: 84,
    0xE0064: 84,
    0xE0065: 84,
    0xE0066: 84,
    0xE0067: 84,
    0xE0068: 84,
    0xE0069: 84,
    0xE006A: 84,
    0xE006B: 84,
    0xE006C: 84,
    0xE006D: 84,
    0xE006E: 84,
    0xE006F: 84,
    0xE0070: 84,
    0xE0071: 84,
    0xE0072: 84,
    0xE0073: 84,
    0xE0074: 84,
    0xE0075: 84,
    0xE0076: 84,
    0xE0077: 84,
    0xE0078: 84,
    0xE0079: 84,
    0xE007A: 84,
    0xE007B: 84,
    0xE007C: 84,
    0xE007D: 84,
    0xE007E: 84,
    0xE007F: 84,
    0xE0100: 84,
    0xE0101: 84,
    0xE0102: 84,
    0xE0103: 84,
    0xE0104: 84,
    0xE0105: 84,
    0xE0106: 84,
    0xE0107: 84,
    0xE0108: 84,
    0xE0109: 84,
    0xE010A: 84,
    0xE010B: 84,
    0xE010C: 84,
    0xE010D: 84,
    0xE010E: 84,
    0xE010F: 84,
    0xE0110: 84,
    0xE0111: 84,
    0xE0112: 84,
    0xE0113: 84,
    0xE0114: 84,
    0xE0115: 84,
    0xE0116: 84,
    0xE0117: 84,
    0xE0118: 84,
    0xE0119: 84,
    0xE011A: 84,
    0xE011B: 84,
    0xE011C: 84,
    0xE011D: 84,
    0xE011E: 84,
    0xE011F: 84,
    0xE0120: 84,
    0xE0121: 84,
    0xE0122: 84,
    0xE0123: 84,
    0xE0124: 84,
    0xE0125: 84,
    0xE0126: 84,
    0xE0127: 84,
    0xE0128: 84,
    0xE0129: 84,
    0xE012A: 84,
    0xE012B: 84,
    0xE012C: 84,
    0xE012D: 84,
    0xE012E: 84,
    0xE012F: 84,
    0xE0130: 84,
    0xE0131: 84,
    0xE0132: 84,
    0xE0133: 84,
    0xE0134: 84,
    0xE0135: 84,
    0xE0136: 84,
    0xE0137: 84,
    0xE0138: 84,
    0xE0139: 84,
    0xE013A: 84,
    0xE013B: 84,
    0xE013C: 84,
    0xE013D: 84,
    0xE013E: 84,
    0xE013F: 84,
    0xE0140: 84,
    0xE0141: 84,
    0xE0142: 84,
    0xE0143: 84,
    0xE0144: 84,
    0xE0145: 84,
    0xE0146: 84,
    0xE0147: 84,
    0xE0148: 84,
    0xE0149: 84,
    0xE014A: 84,
    0xE014B: 84,
    0xE014C: 84,
    0xE014D: 84,
    0xE014E: 84,
    0xE014F: 84,
    0xE0150: 84,
    0xE0151: 84,
    0xE0152: 84,
    0xE0153: 84,
    0xE0154: 84,
    0xE0155: 84,
    0xE0156: 84,
    0xE0157: 84,
    0xE0158: 84,
    0xE0159: 84,
    0xE015A: 84,
    0xE015B: 84,
    0xE015C: 84,
    0xE015D: 84,
    0xE015E: 84,
    0xE015F: 84,
    0xE0160: 84,
    0xE0161: 84,
    0xE0162: 84,
    0xE0163: 84,
    0xE0164: 84,
    0xE0165: 84,
    0xE0166: 84,
    0xE0167: 84,
    0xE0168: 84,
    0xE0169: 84,
    0xE016A: 84,
    0xE016B: 84,
    0xE016C: 84,
    0xE016D: 84,
    0xE016E: 84,
    0xE016F: 84,
    0xE0170: 84,
    0xE0171: 84,
    0xE0172: 84,
    0xE0173: 84,
    0xE0174: 84,
    0xE0175: 84,
    0xE0176: 84,
    0xE0177: 84,
    0xE0178: 84,
    0xE0179: 84,
    0xE017A: 84,
    0xE017B: 84,
    0xE017C: 84,
    0xE017D: 84,
    0xE017E: 84,
    0xE017F: 84,
    0xE0180: 84,
    0xE0181: 84,
    0xE0182: 84,
    0xE0183: 84,
    0xE0184: 84,
    0xE0185: 84,
    0xE0186: 84,
    0xE0187: 84,
    0xE0188: 84,
    0xE0189: 84,
    0xE018A: 84,
    0xE018B: 84,
    0xE018C: 84,
    0xE018D: 84,
    0xE018E: 84,
    0xE018F: 84,
    0xE0190: 84,
    0xE0191: 84,
    0xE0192: 84,
    0xE0193: 84,
    0xE0194: 84,
    0xE0195: 84,
    0xE0196: 84,
    0xE0197: 84,
    0xE0198: 84,
    0xE0199: 84,
    0xE019A: 84,
    0xE019B: 84,
    0xE019C: 84,
    0xE019D: 84,
    0xE019E: 84,
    0xE019F: 84,
    0xE01A0: 84,
    0xE01A1: 84,
    0xE01A2: 84,
    0xE01A3: 84,
    0xE01A4: 84,
    0xE01A5: 84,
    0xE01A6: 84,
    0xE01A7: 84,
    0xE01A8: 84,
    0xE01A9: 84,
    0xE01AA: 84,
    0xE01AB: 84,
    0xE01AC: 84,
    0xE01AD: 84,
    0xE01AE: 84,
    0xE01AF: 84,
    0xE01B0: 84,
    0xE01B1: 84,
    0xE01B2: 84,
    0xE01B3: 84,
    0xE01B4: 84,
    0xE01B5: 84,
    0xE01B6: 84,
    0xE01B7: 84,
    0xE01B8: 84,
    0xE01B9: 84,
    0xE01BA: 84,
    0xE01BB: 84,
    0xE01BC: 84,
    0xE01BD: 84,
    0xE01BE: 84,
    0xE01BF: 84,
    0xE01C0: 84,
    0xE01C1: 84,
    0xE01C2: 84,
    0xE01C3: 84,
    0xE01C4: 84,
    0xE01C5: 84,
    0xE01C6: 84,
    0xE01C7: 84,
    0xE01C8: 84,
    0xE01C9: 84,
    0xE01CA: 84,
    0xE01CB: 84,
    0xE01CC: 84,
    0xE01CD: 84,
    0xE01CE: 84,
    0xE01CF: 84,
    0xE01D0: 84,
    0xE01D1: 84,
    0xE01D2: 84,
    0xE01D3: 84,
    0xE01D4: 84,
    0xE01D5: 84,
    0xE01D6: 84,
    0xE01D7: 84,
    0xE01D8: 84,
    0xE01D9: 84,
    0xE01DA: 84,
    0xE01DB: 84,
    0xE01DC: 84,
    0xE01DD: 84,
    0xE01DE: 84,
    0xE01DF: 84,
    0xE01E0: 84,
    0xE01E1: 84,
    0xE01E2: 84,
    0xE01E3: 84,
    0xE01E4: 84,
    0xE01E5: 84,
    0xE01E6: 84,
    0xE01E7: 84,
    0xE01E8: 84,
    0xE01E9: 84,
    0xE01EA: 84,
    0xE01EB: 84,
    0xE01EC: 84,
    0xE01ED: 84,
    0xE01EE: 84,
    0xE01EF: 84,
}
codepoint_classes = {
    ""PVALID"": (
        0x2D0000002E,
        0x300000003A,
        0x610000007B,
        0xDF000000F7,
        0xF800000100,
        0x10100000102,
        0x10300000104,
        0x10500000106,
        0x10700000108,
        0x1090000010A,
        0x10B0000010C,
        0x10D0000010E,
        0x10F00000110,
        0x11100000112,
        0x11300000114,
        0x11500000116,
        0x11700000118,
        0x1190000011A,
        0x11B0000011C,
        0x11D0000011E,
        0x11F00000120,
        0x12100000122,
        0x12300000124,
        0x12500000126,
        0x12700000128,
        0x1290000012A,
        0x12B0000012C,
        0x12D0000012E,
        0x12F00000130,
        0x13100000132,
        0x13500000136,
        0x13700000139,
        0x13A0000013B,
        0x13C0000013D,
        0x13E0000013F,
        0x14200000143,
        0x14400000145,
        0x14600000147,
        0x14800000149,
        0x14B0000014C,
        0x14D0000014E,
        0x14F00000150,
        0x15100000152,
        0x15300000154,
        0x15500000156,
        0x15700000158,
        0x1590000015A,
        0x15B0000015C,
        0x15D0000015E,
        0x15F00000160,
        0x16100000162,
        0x16300000164,
        0x16500000166,
        0x16700000168,
        0x1690000016A,
        0x16B0000016C,
        0x16D0000016E,
        0x16F00000170,
        0x17100000172,
        0x17300000174,
        0x17500000176,
        0x17700000178,
        0x17A0000017B,
        0x17C0000017D,
        0x17E0000017F,
        0x18000000181,
        0x18300000184,
        0x18500000186,
        0x18800000189,
        0x18C0000018E,
        0x19200000193,
        0x19500000196,
        0x1990000019C,
        0x19E0000019F,
        0x1A1000001A2,
        0x1A3000001A4,
        0x1A5000001A6,
        0x1A8000001A9,
        0x1AA000001AC,
        0x1AD000001AE,
        0x1B0000001B1,
        0x1B4000001B5,
        0x1B6000001B7,
        0x1B9000001BC,
        0x1BD000001C4,
        0x1CE000001CF,
        0x1D0000001D1,
        0x1D2000001D3,
        0x1D4000001D5,
        0x1D6000001D7,
        0x1D8000001D9,
        0x1DA000001DB,
        0x1DC000001DE,
        0x1DF000001E0,
        0x1E1000001E2,
        0x1E3000001E4,
        0x1E5000001E6,
        0x1E7000001E8,
        0x1E9000001EA,
        0x1EB000001EC,
        0x1ED000001EE,
        0x1EF000001F1,
        0x1F5000001F6,
        0x1F9000001FA,
        0x1FB000001FC,
        0x1FD000001FE,
        0x1FF00000200,
        0x20100000202,
        0x20300000204,
        0x20500000206,
        0x20700000208,
        0x2090000020A,
        0x20B0000020C,
        0x20D0000020E,
        0x20F00000210,
        0x21100000212,
        0x21300000214,
        0x21500000216,
        0x21700000218,
        0x2190000021A,
        0x21B0000021C,
        0x21D0000021E,
        0x21F00000220,
        0x22100000222,
        0x22300000224,
        0x22500000226,
        0x22700000228,
        0x2290000022A,
        0x22B0000022C,
        0x22D0000022E,
        0x22F00000230,
        0x23100000232,
        0x2330000023A,
        0x23C0000023D,
        0x23F00000241,
        0x24200000243,
        0x24700000248,
        0x2490000024A,
        0x24B0000024C,
        0x24D0000024E,
        0x24F000002B0,
        0x2B9000002C2,
        0x2C6000002D2,
        0x2EC000002ED,
        0x2EE000002EF,
        0x30000000340,
        0x34200000343,
        0x3460000034F,
        0x35000000370,
        0x37100000372,
        0x37300000374,
        0x37700000378,
        0x37B0000037E,
        0x39000000391,
        0x3AC000003CF,
        0x3D7000003D8,
        0x3D9000003DA,
        0x3DB000003DC,
        0x3DD000003DE,
        0x3DF000003E0,
        0x3E1000003E2,
        0x3E3000003E4,
        0x3E5000003E6,
        0x3E7000003E8,
        0x3E9000003EA,
        0x3EB000003EC,
        0x3ED000003EE,
        0x3EF000003F0,
        0x3F3000003F4,
        0x3F8000003F9,
        0x3FB000003FD,
        0x43000000460,
        0x46100000462,
        0x46300000464,
        0x46500000466,
        0x46700000468,
        0x4690000046A,
        0x46B0000046C,
        0x46D0000046E,
        0x46F00000470,
        0x47100000472,
        0x47300000474,
        0x47500000476,
        0x47700000478,
        0x4790000047A,
        0x47B0000047C,
        0x47D0000047E,
        0x47F00000480,
        0x48100000482,
        0x48300000488,
        0x48B0000048C,
        0x48D0000048E,
        0x48F00000490,
        0x49100000492,
        0x49300000494,
        0x49500000496,
        0x49700000498,
        0x4990000049A,
        0x49B0000049C,
        0x49D0000049E,
        0x49F000004A0,
        0x4A1000004A2,
        0x4A3000004A4,
        0x4A5000004A6,
        0x4A7000004A8,
        0x4A9000004AA,
        0x4AB000004AC,
        0x4AD000004AE,
        0x4AF000004B0,
        0x4B1000004B2,
        0x4B3000004B4,
        0x4B5000004B6,
        0x4B7000004B8,
        0x4B9000004BA,
        0x4BB000004BC,
        0x4BD000004BE,
        0x4BF000004C0,
        0x4C2000004C3,
        0x4C4000004C5,
        0x4C6000004C7,
        0x4C8000004C9,
        0x4CA000004CB,
        0x4CC000004CD,
        0x4CE000004D0,
        0x4D1000004D2,
        0x4D3000004D4,
        0x4D5000004D6,
        0x4D7000004D8,
        0x4D9000004DA,
        0x4DB000004DC,
        0x4DD000004DE,
        0x4DF000004E0,
        0x4E1000004E2,
        0x4E3000004E4,
        0x4E5000004E6,
        0x4E7000004E8,
        0x4E9000004EA,
        0x4EB000004EC,
        0x4ED000004EE,
        0x4EF000004F0,
        0x4F1000004F2,
        0x4F3000004F4,
        0x4F5000004F6,
        0x4F7000004F8,
        0x4F9000004FA,
        0x4FB000004FC,
        0x4FD000004FE,
        0x4FF00000500,
        0x50100000502,
        0x50300000504,
        0x50500000506,
        0x50700000508,
        0x5090000050A,
        0x50B0000050C,
        0x50D0000050E,
        0x50F00000510,
        0x51100000512,
        0x51300000514,
        0x51500000516,
        0x51700000518,
        0x5190000051A,
        0x51B0000051C,
        0x51D0000051E,
        0x51F00000520,
        0x52100000522,
        0x52300000524,
        0x52500000526,
        0x52700000528,
        0x5290000052A,
        0x52B0000052C,
        0x52D0000052E,
        0x52F00000530,
        0x5590000055A,
        0x56000000587,
        0x58800000589,
        0x591000005BE,
        0x5BF000005C0,
        0x5C1000005C3,
        0x5C4000005C6,
        0x5C7000005C8,
        0x5D0000005EB,
        0x5EF000005F3,
        0x6100000061B,
        0x62000000640,
        0x64100000660,
        0x66E00000675,
        0x679000006D4,
        0x6D5000006DD,
        0x6DF000006E9,
        0x6EA000006F0,
        0x6FA00000700,
        0x7100000074B,
        0x74D000007B2,
        0x7C0000007F6,
        0x7FD000007FE,
        0x8000000082E,
        0x8400000085C,
        0x8600000086B,
        0x87000000888,
        0x8890000088F,
        0x898000008E2,
        0x8E300000958,
        0x96000000964,
        0x96600000970,
        0x97100000984,
        0x9850000098D,
        0x98F00000991,
        0x993000009A9,
        0x9AA000009B1,
        0x9B2000009B3,
        0x9B6000009BA,
        0x9BC000009C5,
        0x9C7000009C9,
        0x9CB000009CF,
        0x9D7000009D8,
        0x9E0000009E4,
        0x9E6000009F2,
        0x9FC000009FD,
        0x9FE000009FF,
        0xA0100000A04,
        0xA0500000A0B,
        0xA0F00000A11,
        0xA1300000A29,
        0xA2A00000A31,
        0xA3200000A33,
        0xA3500000A36,
        0xA3800000A3A,
        0xA3C00000A3D,
        0xA3E00000A43,
        0xA4700000A49,
        0xA4B00000A4E,
        0xA5100000A52,
        0xA5C00000A5D,
        0xA6600000A76,
        0xA8100000A84,
        0xA8500000A8E,
        0xA8F00000A92,
        0xA9300000AA9,
        0xAAA00000AB1,
        0xAB200000AB4,
        0xAB500000ABA,
        0xABC00000AC6,
        0xAC700000ACA,
        0xACB00000ACE,
        0xAD000000AD1,
        0xAE000000AE4,
        0xAE600000AF0,
        0xAF900000B00,
        0xB0100000B04,
        0xB0500000B0D,
        0xB0F00000B11,
        0xB1300000B29,
        0xB2A00000B31,
        0xB3200000B34,
        0xB3500000B3A,
        0xB3C00000B45,
        0xB4700000B49,
        0xB4B00000B4E,
        0xB5500000B58,
        0xB5F00000B64,
        0xB6600000B70,
        0xB7100000B72,
        0xB8200000B84,
        0xB8500000B8B,
        0xB8E00000B91,
        0xB9200000B96,
        0xB9900000B9B,
        0xB9C00000B9D,
        0xB9E00000BA0,
        0xBA300000BA5,
        0xBA800000BAB,
        0xBAE00000BBA,
        0xBBE00000BC3,
        0xBC600000BC9,
        0xBCA00000BCE,
        0xBD000000BD1,
        0xBD700000BD8,
        0xBE600000BF0,
        0xC0000000C0D,
        0xC0E00000C11,
        0xC1200000C29,
        0xC2A00000C3A,
        0xC3C00000C45,
        0xC4600000C49,
        0xC4A00000C4E,
        0xC5500000C57,
        0xC5800000C5B,
        0xC5D00000C5E,
        0xC6000000C64,
        0xC6600000C70,
        0xC8000000C84,
        0xC8500000C8D,
        0xC8E00000C91,
        0xC9200000CA9,
        0xCAA00000CB4,
        0xCB500000CBA,
        0xCBC00000CC5,
        0xCC600000CC9,
        0xCCA00000CCE,
        0xCD500000CD7,
        0xCDD00000CDF,
        0xCE000000CE4,
        0xCE600000CF0,
        0xCF100000CF4,
        0xD0000000D0D,
        0xD0E00000D11,
        0xD1200000D45,
        0xD4600000D49,
        0xD4A00000D4F,
        0xD5400000D58,
        0xD5F00000D64,
        0xD6600000D70,
        0xD7A00000D80,
        0xD8100000D84,
        0xD8500000D97,
        0xD9A00000DB2,
        0xDB300000DBC,
        0xDBD00000DBE,
        0xDC000000DC7,
        0xDCA00000DCB,
        0xDCF00000DD5,
        0xDD600000DD7,
        0xDD800000DE0,
        0xDE600000DF0,
        0xDF200000DF4,
        0xE0100000E33,
        0xE3400000E3B,
        0xE4000000E4F,
        0xE5000000E5A,
        0xE8100000E83,
        0xE8400000E85,
        0xE8600000E8B,
        0xE8C00000EA4,
        0xEA500000EA6,
        0xEA700000EB3,
        0xEB400000EBE,
        0xEC000000EC5,
        0xEC600000EC7,
        0xEC800000ECF,
        0xED000000EDA,
        0xEDE00000EE0,
        0xF0000000F01,
        0xF0B00000F0C,
        0xF1800000F1A,
        0xF2000000F2A,
        0xF3500000F36,
        0xF3700000F38,
        0xF3900000F3A,
        0xF3E00000F43,
        0xF4400000F48,
        0xF4900000F4D,
        0xF4E00000F52,
        0xF5300000F57,
        0xF5800000F5C,
        0xF5D00000F69,
        0xF6A00000F6D,
        0xF7100000F73,
        0xF7400000F75,
        0xF7A00000F81,
        0xF8200000F85,
        0xF8600000F93,
        0xF9400000F98,
        0xF9900000F9D,
        0xF9E00000FA2,
        0xFA300000FA7,
        0xFA800000FAC,
        0xFAD00000FB9,
        0xFBA00000FBD,
        0xFC600000FC7,
        0x10000000104A,
        0x10500000109E,
        0x10D0000010FB,
        0x10FD00001100,
        0x120000001249,
        0x124A0000124E,
        0x125000001257,
        0x125800001259,
        0x125A0000125E,
        0x126000001289,
        0x128A0000128E,
        0x1290000012B1,
        0x12B2000012B6,
        0x12B8000012BF,
        0x12C0000012C1,
        0x12C2000012C6,
        0x12C8000012D7,
        0x12D800001311,
        0x131200001316,
        0x13180000135B,
        0x135D00001360,
        0x138000001390,
        0x13A0000013F6,
        0x14010000166D,
        0x166F00001680,
        0x16810000169B,
        0x16A0000016EB,
        0x16F1000016F9,
        0x170000001716,
        0x171F00001735,
        0x174000001754,
        0x17600000176D,
        0x176E00001771,
        0x177200001774,
        0x1780000017B4,
        0x17B6000017D4,
        0x17D7000017D8,
        0x17DC000017DE,
        0x17E0000017EA,
        0x18100000181A,
        0x182000001879,
        0x1880000018AB,
        0x18B0000018F6,
        0x19000000191F,
        0x19200000192C,
        0x19300000193C,
        0x19460000196E,
        0x197000001975,
        0x1980000019AC,
        0x19B0000019CA,
        0x19D0000019DA,
        0x1A0000001A1C,
        0x1A2000001A5F,
        0x1A6000001A7D,
        0x1A7F00001A8A,
        0x1A9000001A9A,
        0x1AA700001AA8,
        0x1AB000001ABE,
        0x1ABF00001ACF,
        0x1B0000001B4D,
        0x1B5000001B5A,
        0x1B6B00001B74,
        0x1B8000001BF4,
        0x1C0000001C38,
        0x1C4000001C4A,
        0x1C4D00001C7E,
        0x1CD000001CD3,
        0x1CD400001CFB,
        0x1D0000001D2C,
        0x1D2F00001D30,
        0x1D3B00001D3C,
        0x1D4E00001D4F,
        0x1D6B00001D78,
        0x1D7900001D9B,
        0x1DC000001E00,
        0x1E0100001E02,
        0x1E0300001E04,
        0x1E0500001E06,
        0x1E0700001E08,
        0x1E0900001E0A,
        0x1E0B00001E0C,
        0x1E0D00001E0E,
        0x1E0F00001E10,
        0x1E1100001E12,
        0x1E1300001E14,
        0x1E1500001E16,
        0x1E1700001E18,
        0x1E1900001E1A,
        0x1E1B00001E1C,
        0x1E1D00001E1E,
        0x1E1F00001E20,
        0x1E2100001E22,
        0x1E2300001E24,
        0x1E2500001E26,
        0x1E2700001E28,
        0x1E2900001E2A,
        0x1E2B00001E2C,
        0x1E2D00001E2E,
        0x1E2F00001E30,
        0x1E3100001E32,
        0x1E3300001E34,
        0x1E3500001E36,
        0x1E3700001E38,
        0x1E3900001E3A,
        0x1E3B00001E3C,
        0x1E3D00001E3E,
        0x1E3F00001E40,
        0x1E4100001E42,
        0x1E4300001E44,
        0x1E4500001E46,
        0x1E4700001E48,
        0x1E4900001E4A,
        0x1E4B00001E4C,
        0x1E4D00001E4E,
        0x1E4F00001E50,
        0x1E5100001E52,
        0x1E5300001E54,
        0x1E5500001E56,
        0x1E5700001E58,
        0x1E5900001E5A,
        0x1E5B00001E5C,
        0x1E5D00001E5E,
        0x1E5F00001E60,
        0x1E6100001E62,
        0x1E6300001E64,
        0x1E6500001E66,
        0x1E6700001E68,
        0x1E6900001E6A,
        0x1E6B00001E6C,
        0x1E6D00001E6E,
        0x1E6F00001E70,
        0x1E7100001E72,
        0x1E7300001E74,
        0x1E7500001E76,
        0x1E7700001E78,
        0x1E7900001E7A,
        0x1E7B00001E7C,
        0x1E7D00001E7E,
        0x1E7F00001E80,
        0x1E8100001E82,
        0x1E8300001E84,
        0x1E8500001E86,
        0x1E8700001E88,
        0x1E8900001E8A,
        0x1E8B00001E8C,
        0x1E8D00001E8E,
        0x1E8F00001E90,
        0x1E9100001E92,
        0x1E9300001E94,
        0x1E9500001E9A,
        0x1E9C00001E9E,
        0x1E9F00001EA0,
        0x1EA100001EA2,
        0x1EA300001EA4,
        0x1EA500001EA6,
        0x1EA700001EA8,
        0x1EA900001EAA,
        0x1EAB00001EAC,
        0x1EAD00001EAE,
        0x1EAF00001EB0,
        0x1EB100001EB2,
        0x1EB300001EB4,
        0x1EB500001EB6,
        0x1EB700001EB8,
        0x1EB900001EBA,
        0x1EBB00001EBC,
        0x1EBD00001EBE,
        0x1EBF00001EC0,
        0x1EC100001EC2,
        0x1EC300001EC4,
        0x1EC500001EC6,
        0x1EC700001EC8,
        0x1EC900001ECA,
        0x1ECB00001ECC,
        0x1ECD00001ECE,
        0x1ECF00001ED0,
        0x1ED100001ED2,
        0x1ED300001ED4,
        0x1ED500001ED6,
        0x1ED700001ED8,
        0x1ED900001EDA,
        0x1EDB00001EDC,
        0x1EDD00001EDE,
        0x1EDF00001EE0,
        0x1EE100001EE2,
        0x1EE300001EE4,
        0x1EE500001EE6,
        0x1EE700001EE8,
        0x1EE900001EEA,
        0x1EEB00001EEC,
        0x1EED00001EEE,
        0x1EEF00001EF0,
        0x1EF100001EF2,
        0x1EF300001EF4,
        0x1EF500001EF6,
        0x1EF700001EF8,
        0x1EF900001EFA,
        0x1EFB00001EFC,
        0x1EFD00001EFE,
        0x1EFF00001F08,
        0x1F1000001F16,
        0x1F2000001F28,
        0x1F3000001F38,
        0x1F4000001F46,
        0x1F5000001F58,
        0x1F6000001F68,
        0x1F7000001F71,
        0x1F7200001F73,
        0x1F7400001F75,
        0x1F7600001F77,
        0x1F7800001F79,
        0x1F7A00001F7B,
        0x1F7C00001F7D,
        0x1FB000001FB2,
        0x1FB600001FB7,
        0x1FC600001FC7,
        0x1FD000001FD3,
        0x1FD600001FD8,
        0x1FE000001FE3,
        0x1FE400001FE8,
        0x1FF600001FF7,
        0x214E0000214F,
        0x218400002185,
        0x2C3000002C60,
        0x2C6100002C62,
        0x2C6500002C67,
        0x2C6800002C69,
        0x2C6A00002C6B,
        0x2C6C00002C6D,
        0x2C7100002C72,
        0x2C7300002C75,
        0x2C7600002C7C,
        0x2C8100002C82,
        0x2C8300002C84,
        0x2C8500002C86,
        0x2C8700002C88,
        0x2C8900002C8A,
        0x2C8B00002C8C,
        0x2C8D00002C8E,
        0x2C8F00002C90,
        0x2C9100002C92,
        0x2C9300002C94,
        0x2C9500002C96,
        0x2C9700002C98,
        0x2C9900002C9A,
        0x2C9B00002C9C,
        0x2C9D00002C9E,
        0x2C9F00002CA0,
        0x2CA100002CA2,
        0x2CA300002CA4,
        0x2CA500002CA6,
        0x2CA700002CA8,
        0x2CA900002CAA,
        0x2CAB00002CAC,
        0x2CAD00002CAE,
        0x2CAF00002CB0,
        0x2CB100002CB2,
        0x2CB300002CB4,
        0x2CB500002CB6,
        0x2CB700002CB8,
        0x2CB900002CBA,
        0x2CBB00002CBC,
        0x2CBD00002CBE,
        0x2CBF00002CC0,
        0x2CC100002CC2,
        0x2CC300002CC4,
        0x2CC500002CC6,
        0x2CC700002CC8,
        0x2CC900002CCA,
        0x2CCB00002CCC,
        0x2CCD00002CCE,
        0x2CCF00002CD0,
        0x2CD100002CD2,
        0x2CD300002CD4,
        0x2CD500002CD6,
        0x2CD700002CD8,
        0x2CD900002CDA,
        0x2CDB00002CDC,
        0x2CDD00002CDE,
        0x2CDF00002CE0,
        0x2CE100002CE2,
        0x2CE300002CE5,
        0x2CEC00002CED,
        0x2CEE00002CF2,
        0x2CF300002CF4,
        0x2D0000002D26,
        0x2D2700002D28,
        0x2D2D00002D2E,
        0x2D3000002D68,
        0x2D7F00002D97,
        0x2DA000002DA7,
        0x2DA800002DAF,
        0x2DB000002DB7,
        0x2DB800002DBF,
        0x2DC000002DC7,
        0x2DC800002DCF,
        0x2DD000002DD7,
        0x2DD800002DDF,
        0x2DE000002E00,
        0x2E2F00002E30,
        0x300500003008,
        0x302A0000302E,
        0x303C0000303D,
        0x304100003097,
        0x30990000309B,
        0x309D0000309F,
        0x30A1000030FB,
        0x30FC000030FF,
        0x310500003130,
        0x31A0000031C0,
        0x31F000003200,
        0x340000004DC0,
        0x4E000000A48D,
        0xA4D00000A4FE,
        0xA5000000A60D,
        0xA6100000A62C,
        0xA6410000A642,
        0xA6430000A644,
        0xA6450000A646,
        0xA6470000A648,
        0xA6490000A64A,
        0xA64B0000A64C,
        0xA64D0000A64E,
        0xA64F0000A650,
        0xA6510000A652,
        0xA6530000A654,
        0xA6550000A656,
        0xA6570000A658,
        0xA6590000A65A,
        0xA65B0000A65C,
        0xA65D0000A65E,
        0xA65F0000A660,
        0xA6610000A662,
        0xA6630000A664,
        0xA6650000A666,
        0xA6670000A668,
        0xA6690000A66A,
        0xA66B0000A66C,
        0xA66D0000A670,
        0xA6740000A67E,
        0xA67F0000A680,
        0xA6810000A682,
        0xA6830000A684,
        0xA6850000A686,
        0xA6870000A688,
        0xA6890000A68A,
        0xA68B0000A68C,
        0xA68D0000A68E,
        0xA68F0000A690,
        0xA6910000A692,
        0xA6930000A694,
        0xA6950000A696,
        0xA6970000A698,
        0xA6990000A69A,
        0xA69B0000A69C,
        0xA69E0000A6E6,
        0xA6F00000A6F2,
        0xA7170000A720,
        0xA7230000A724,
        0xA7250000A726,
        0xA7270000A728,
        0xA7290000A72A,
        0xA72B0000A72C,
        0xA72D0000A72E,
        0xA72F0000A732,
        0xA7330000A734,
        0xA7350000A736,
        0xA7370000A738,
        0xA7390000A73A,
        0xA73B0000A73C,
        0xA73D0000A73E,
        0xA73F0000A740,
        0xA7410000A742,
        0xA7430000A744,
        0xA7450000A746,
        0xA7470000A748,
        0xA7490000A74A,
        0xA74B0000A74C,
        0xA74D0000A74E,
        0xA74F0000A750,
        0xA7510000A752,
        0xA7530000A754,
        0xA7550000A756,
        0xA7570000A758,
        0xA7590000A75A,
        0xA75B0000A75C,
        0xA75D0000A75E,
        0xA75F0000A760,
        0xA7610000A762,
        0xA7630000A764,
        0xA7650000A766,
        0xA7670000A768,
        0xA7690000A76A,
        0xA76B0000A76C,
        0xA76D0000A76E,
        0xA76F0000A770,
        0xA7710000A779,
        0xA77A0000A77B,
        0xA77C0000A77D,
        0xA77F0000A780,
        0xA7810000A782,
        0xA7830000A784,
        0xA7850000A786,
        0xA7870000A789,
        0xA78C0000A78D,
        0xA78E0000A790,
        0xA7910000A792,
        0xA7930000A796,
        0xA7970000A798,
        0xA7990000A79A,
        0xA79B0000A79C,
        0xA79D0000A79E,
        0xA79F0000A7A0,
        0xA7A10000A7A2,
        0xA7A30000A7A4,
        0xA7A50000A7A6,
        0xA7A70000A7A8,
        0xA7A90000A7AA,
        0xA7AF0000A7B0,
        0xA7B50000A7B6,
        0xA7B70000A7B8,
        0xA7B90000A7BA,
        0xA7BB0000A7BC,
        0xA7BD0000A7BE,
        0xA7BF0000A7C0,
        0xA7C10000A7C2,
        0xA7C30000A7C4,
        0xA7C80000A7C9,
        0xA7CA0000A7CB,
        0xA7D10000A7D2,
        0xA7D30000A7D4,
        0xA7D50000A7D6,
        0xA7D70000A7D8,
        0xA7D90000A7DA,
        0xA7F60000A7F8,
        0xA7FA0000A828,
        0xA82C0000A82D,
        0xA8400000A874,
        0xA8800000A8C6,
        0xA8D00000A8DA,
        0xA8E00000A8F8,
        0xA8FB0000A8FC,
        0xA8FD0000A92E,
        0xA9300000A954,
        0xA9800000A9C1,
        0xA9CF0000A9DA,
        0xA9E00000A9FF,
        0xAA000000AA37,
        0xAA400000AA4E,
        0xAA500000AA5A,
        0xAA600000AA77,
        0xAA7A0000AAC3,
        0xAADB0000AADE,
        0xAAE00000AAF0,
        0xAAF20000AAF7,
        0xAB010000AB07,
        0xAB090000AB0F,
        0xAB110000AB17,
        0xAB200000AB27,
        0xAB280000AB2F,
        0xAB300000AB5B,
        0xAB600000AB69,
        0xABC00000ABEB,
        0xABEC0000ABEE,
        0xABF00000ABFA,
        0xAC000000D7A4,
        0xFA0E0000FA10,
        0xFA110000FA12,
        0xFA130000FA15,
        0xFA1F0000FA20,
        0xFA210000FA22,
        0xFA230000FA25,
        0xFA270000FA2A,
        0xFB1E0000FB1F,
        0xFE200000FE30,
        0xFE730000FE74,
        0x100000001000C,
        0x1000D00010027,
        0x100280001003B,
        0x1003C0001003E,
        0x1003F0001004E,
        0x100500001005E,
        0x10080000100FB,
        0x101FD000101FE,
        0x102800001029D,
        0x102A0000102D1,
        0x102E0000102E1,
        0x1030000010320,
        0x1032D00010341,
        0x103420001034A,
        0x103500001037B,
        0x103800001039E,
        0x103A0000103C4,
        0x103C8000103D0,
        0x104280001049E,
        0x104A0000104AA,
        0x104D8000104FC,
        0x1050000010528,
        0x1053000010564,
        0x10597000105A2,
        0x105A3000105B2,
        0x105B3000105BA,
        0x105BB000105BD,
        0x1060000010737,
        0x1074000010756,
        0x1076000010768,
        0x1078000010781,
        0x1080000010806,
        0x1080800010809,
        0x1080A00010836,
        0x1083700010839,
        0x1083C0001083D,
        0x1083F00010856,
        0x1086000010877,
        0x108800001089F,
        0x108E0000108F3,
        0x108F4000108F6,
        0x1090000010916,
        0x109200001093A,
        0x10980000109B8,
        0x109BE000109C0,
        0x10A0000010A04,
        0x10A0500010A07,
        0x10A0C00010A14,
        0x10A1500010A18,
        0x10A1900010A36,
        0x10A3800010A3B,
        0x10A3F00010A40,
        0x10A6000010A7D,
        0x10A8000010A9D,
        0x10AC000010AC8,
        0x10AC900010AE7,
        0x10B0000010B36,
        0x10B4000010B56,
        0x10B6000010B73,
        0x10B8000010B92,
        0x10C0000010C49,
        0x10CC000010CF3,
        0x10D0000010D28,
        0x10D3000010D3A,
        0x10E8000010EAA,
        0x10EAB00010EAD,
        0x10EB000010EB2,
        0x10EFD00010F1D,
        0x10F2700010F28,
        0x10F3000010F51,
        0x10F7000010F86,
        0x10FB000010FC5,
        0x10FE000010FF7,
        0x1100000011047,
        0x1106600011076,
        0x1107F000110BB,
        0x110C2000110C3,
        0x110D0000110E9,
        0x110F0000110FA,
        0x1110000011135,
        0x1113600011140,
        0x1114400011148,
        0x1115000011174,
        0x1117600011177,
        0x11180000111C5,
        0x111C9000111CD,
        0x111CE000111DB,
        0x111DC000111DD,
        0x1120000011212,
        0x1121300011238,
        0x1123E00011242,
        0x1128000011287,
        0x1128800011289,
        0x1128A0001128E,
        0x1128F0001129E,
        0x1129F000112A9,
        0x112B0000112EB,
        0x112F0000112FA,
        0x1130000011304,
        0x113050001130D,
        0x1130F00011311,
        0x1131300011329,
        0x1132A00011331,
        0x1133200011334,
        0x113350001133A,
        0x1133B00011345,
        0x1134700011349,
        0x1134B0001134E,
        0x1135000011351,
        0x1135700011358,
        0x1135D00011364,
        0x113660001136D,
        0x1137000011375,
        0x114000001144B,
        0x114500001145A,
        0x1145E00011462,
        0x11480000114C6,
        0x114C7000114C8,
        0x114D0000114DA,
        0x11580000115B6,
        0x115B8000115C1,
        0x115D8000115DE,
        0x1160000011641,
        0x1164400011645,
        0x116500001165A,
        0x11680000116B9,
        0x116C0000116CA,
        0x117000001171B,
        0x1171D0001172C,
        0x117300001173A,
        0x1174000011747,
        0x118000001183B,
        0x118C0000118EA,
        0x118FF00011907,
        0x119090001190A,
        0x1190C00011914,
        0x1191500011917,
        0x1191800011936,
        0x1193700011939,
        0x1193B00011944,
        0x119500001195A,
        0x119A0000119A8,
        0x119AA000119D8,
        0x119DA000119E2,
        0x119E3000119E5,
        0x11A0000011A3F,
        0x11A4700011A48,
        0x11A5000011A9A,
        0x11A9D00011A9E,
        0x11AB000011AF9,
        0x11C0000011C09,
        0x11C0A00011C37,
        0x11C3800011C41,
        0x11C5000011C5A,
        0x11C7200011C90,
        0x11C9200011CA8,
        0x11CA900011CB7,
        0x11D0000011D07,
        0x11D0800011D0A,
        0x11D0B00011D37,
        0x11D3A00011D3B,
        0x11D3C00011D3E,
        0x11D3F00011D48,
        0x11D5000011D5A,
        0x11D6000011D66,
        0x11D6700011D69,
        0x11D6A00011D8F,
        0x11D9000011D92,
        0x11D9300011D99,
        0x11DA000011DAA,
        0x11EE000011EF7,
        0x11F0000011F11,
        0x11F1200011F3B,
        0x11F3E00011F43,
        0x11F5000011F5A,
        0x11FB000011FB1,
        0x120000001239A,
        0x1248000012544,
        0x12F9000012FF1,
        0x1300000013430,
        0x1344000013456,
        0x1440000014647,
        0x1680000016A39,
        0x16A4000016A5F,
        0x16A6000016A6A,
        0x16A7000016ABF,
        0x16AC000016ACA,
        0x16AD000016AEE,
        0x16AF000016AF5,
        0x16B0000016B37,
        0x16B4000016B44,
        0x16B5000016B5A,
        0x16B6300016B78,
        0x16B7D00016B90,
        0x16E6000016E80,
        0x16F0000016F4B,
        0x16F4F00016F88,
        0x16F8F00016FA0,
        0x16FE000016FE2,
        0x16FE300016FE5,
        0x16FF000016FF2,
        0x17000000187F8,
        0x1880000018CD6,
        0x18D0000018D09,
        0x1AFF00001AFF4,
        0x1AFF50001AFFC,
        0x1AFFD0001AFFF,
        0x1B0000001B123,
        0x1B1320001B133,
        0x1B1500001B153,
        0x1B1550001B156,
        0x1B1640001B168,
        0x1B1700001B2FC,
        0x1BC000001BC6B,
        0x1BC700001BC7D,
        0x1BC800001BC89,
        0x1BC900001BC9A,
        0x1BC9D0001BC9F,
        0x1CF000001CF2E,
        0x1CF300001CF47,
        0x1DA000001DA37,
        0x1DA3B0001DA6D,
        0x1DA750001DA76,
        0x1DA840001DA85,
        0x1DA9B0001DAA0,
        0x1DAA10001DAB0,
        0x1DF000001DF1F,
        0x1DF250001DF2B,
        0x1E0000001E007,
        0x1E0080001E019,
        0x1E01B0001E022,
        0x1E0230001E025,
        0x1E0260001E02B,
        0x1E08F0001E090,
        0x1E1000001E12D,
        0x1E1300001E13E,
        0x1E1400001E14A,
        0x1E14E0001E14F,
        0x1E2900001E2AF,
        0x1E2C00001E2FA,
        0x1E4D00001E4FA,
        0x1E7E00001E7E7,
        0x1E7E80001E7EC,
        0x1E7ED0001E7EF,
        0x1E7F00001E7FF,
        0x1E8000001E8C5,
        0x1E8D00001E8D7,
        0x1E9220001E94C,
        0x1E9500001E95A,
        0x200000002A6E0,
        0x2A7000002B73A,
        0x2B7400002B81E,
        0x2B8200002CEA2,
        0x2CEB00002EBE1,
        0x2EBF00002EE5E,
        0x300000003134B,
        0x31350000323B0,
    ),
    ""CONTEXTJ"": (0x200C0000200E,),
    ""CONTEXTO"": (
        0xB7000000B8,
        0x37500000376,
        0x5F3000005F5,
        0x6600000066A,
        0x6F0000006FA,
        0x30FB000030FC,
    ),
}



import bisect
from typing import List, Tuple


def intranges_from_list(list_: List[int]) -> Tuple[int, ...]:
    

    sorted_list = sorted(list_)
    ranges = []
    last_write = -1
    for i in range(len(sorted_list)):
        if i + 1 < len(sorted_list):
            if sorted_list[i] == sorted_list[i + 1] - 1:
                continue
        current_range = sorted_list[last_write + 1 : i + 1]
        ranges.append(_encode_range(current_range[0], current_range[-1] + 1))
        last_write = i

    return tuple(ranges)


def _encode_range(start: int, end: int) -> int:
    return (start << 32) | end


def _decode_range(r: int) -> Tuple[int, int]:
    return (r >> 32), (r & ((1 << 32) - 1))


def intranges_contain(int_: int, ranges: Tuple[int, ...]) -> bool:
    
    tuple_ = _encode_range(int_, 0)
    pos = bisect.bisect_left(ranges, tuple_)
    
    
    if pos > 0:
        left, right = _decode_range(ranges[pos - 1])
        if left <= int_ < right:
            return True
    
    if pos < len(ranges):
        left, _ = _decode_range(ranges[pos])
        if left == int_:
            return True
    return False

__version__ = ""3.10""




from typing import List, Tuple, Union




__version__ = ""15.1.0""


def _seg_0() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x0, ""3""),
        (0x1, ""3""),
        (0x2, ""3""),
        (0x3, ""3""),
        (0x4, ""3""),
        (0x5, ""3""),
        (0x6, ""3""),
        (0x7, ""3""),
        (0x8, ""3""),
        (0x9, ""3""),
        (0xA, ""3""),
        (0xB, ""3""),
        (0xC, ""3""),
        (0xD, ""3""),
        (0xE, ""3""),
        (0xF, ""3""),
        (0x10, ""3""),
        (0x11, ""3""),
        (0x12, ""3""),
        (0x13, ""3""),
        (0x14, ""3""),
        (0x15, ""3""),
        (0x16, ""3""),
        (0x17, ""3""),
        (0x18, ""3""),
        (0x19, ""3""),
        (0x1A, ""3""),
        (0x1B, ""3""),
        (0x1C, ""3""),
        (0x1D, ""3""),
        (0x1E, ""3""),
        (0x1F, ""3""),
        (0x20, ""3""),
        (0x21, ""3""),
        (0x22, ""3""),
        (0x23, ""3""),
        (0x24, ""3""),
        (0x25, ""3""),
        (0x26, ""3""),
        (0x27, ""3""),
        (0x28, ""3""),
        (0x29, ""3""),
        (0x2A, ""3""),
        (0x2B, ""3""),
        (0x2C, ""3""),
        (0x2D, ""V""),
        (0x2E, ""V""),
        (0x2F, ""3""),
        (0x30, ""V""),
        (0x31, ""V""),
        (0x32, ""V""),
        (0x33, ""V""),
        (0x34, ""V""),
        (0x35, ""V""),
        (0x36, ""V""),
        (0x37, ""V""),
        (0x38, ""V""),
        (0x39, ""V""),
        (0x3A, ""3""),
        (0x3B, ""3""),
        (0x3C, ""3""),
        (0x3D, ""3""),
        (0x3E, ""3""),
        (0x3F, ""3""),
        (0x40, ""3""),
        (0x41, ""M"", ""a""),
        (0x42, ""M"", ""b""),
        (0x43, ""M"", ""c""),
        (0x44, ""M"", ""d""),
        (0x45, ""M"", ""e""),
        (0x46, ""M"", ""f""),
        (0x47, ""M"", ""g""),
        (0x48, ""M"", ""h""),
        (0x49, ""M"", ""i""),
        (0x4A, ""M"", ""j""),
        (0x4B, ""M"", ""k""),
        (0x4C, ""M"", ""l""),
        (0x4D, ""M"", ""m""),
        (0x4E, ""M"", ""n""),
        (0x4F, ""M"", ""o""),
        (0x50, ""M"", ""p""),
        (0x51, ""M"", ""q""),
        (0x52, ""M"", ""r""),
        (0x53, ""M"", ""s""),
        (0x54, ""M"", ""t""),
        (0x55, ""M"", ""u""),
        (0x56, ""M"", ""v""),
        (0x57, ""M"", ""w""),
        (0x58, ""M"", ""x""),
        (0x59, ""M"", ""y""),
        (0x5A, ""M"", ""z""),
        (0x5B, ""3""),
        (0x5C, ""3""),
        (0x5D, ""3""),
        (0x5E, ""3""),
        (0x5F, ""3""),
        (0x60, ""3""),
        (0x61, ""V""),
        (0x62, ""V""),
        (0x63, ""V""),
    ]


def _seg_1() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x64, ""V""),
        (0x65, ""V""),
        (0x66, ""V""),
        (0x67, ""V""),
        (0x68, ""V""),
        (0x69, ""V""),
        (0x6A, ""V""),
        (0x6B, ""V""),
        (0x6C, ""V""),
        (0x6D, ""V""),
        (0x6E, ""V""),
        (0x6F, ""V""),
        (0x70, ""V""),
        (0x71, ""V""),
        (0x72, ""V""),
        (0x73, ""V""),
        (0x74, ""V""),
        (0x75, ""V""),
        (0x76, ""V""),
        (0x77, ""V""),
        (0x78, ""V""),
        (0x79, ""V""),
        (0x7A, ""V""),
        (0x7B, ""3""),
        (0x7C, ""3""),
        (0x7D, ""3""),
        (0x7E, ""3""),
        (0x7F, ""3""),
        (0x80, ""X""),
        (0x81, ""X""),
        (0x82, ""X""),
        (0x83, ""X""),
        (0x84, ""X""),
        (0x85, ""X""),
        (0x86, ""X""),
        (0x87, ""X""),
        (0x88, ""X""),
        (0x89, ""X""),
        (0x8A, ""X""),
        (0x8B, ""X""),
        (0x8C, ""X""),
        (0x8D, ""X""),
        (0x8E, ""X""),
        (0x8F, ""X""),
        (0x90, ""X""),
        (0x91, ""X""),
        (0x92, ""X""),
        (0x93, ""X""),
        (0x94, ""X""),
        (0x95, ""X""),
        (0x96, ""X""),
        (0x97, ""X""),
        (0x98, ""X""),
        (0x99, ""X""),
        (0x9A, ""X""),
        (0x9B, ""X""),
        (0x9C, ""X""),
        (0x9D, ""X""),
        (0x9E, ""X""),
        (0x9F, ""X""),
        (0xA0, ""3"", "" ""),
        (0xA1, ""V""),
        (0xA2, ""V""),
        (0xA3, ""V""),
        (0xA4, ""V""),
        (0xA5, ""V""),
        (0xA6, ""V""),
        (0xA7, ""V""),
        (0xA8, ""3"", "" ̈""),
        (0xA9, ""V""),
        (0xAA, ""M"", ""a""),
        (0xAB, ""V""),
        (0xAC, ""V""),
        (0xAD, ""I""),
        (0xAE, ""V""),
        (0xAF, ""3"", "" ̄""),
        (0xB0, ""V""),
        (0xB1, ""V""),
        (0xB2, ""M"", ""2""),
        (0xB3, ""M"", ""3""),
        (0xB4, ""3"", "" ́""),
        (0xB5, ""M"", ""μ""),
        (0xB6, ""V""),
        (0xB7, ""V""),
        (0xB8, ""3"", "" ̧""),
        (0xB9, ""M"", ""1""),
        (0xBA, ""M"", ""o""),
        (0xBB, ""V""),
        (0xBC, ""M"", ""1⁄4""),
        (0xBD, ""M"", ""1⁄2""),
        (0xBE, ""M"", ""3⁄4""),
        (0xBF, ""V""),
        (0xC0, ""M"", ""à""),
        (0xC1, ""M"", ""á""),
        (0xC2, ""M"", ""â""),
        (0xC3, ""M"", ""ã""),
        (0xC4, ""M"", ""ä""),
        (0xC5, ""M"", ""å""),
        (0xC6, ""M"", ""æ""),
        (0xC7, ""M"", ""ç""),
    ]


def _seg_2() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0xC8, ""M"", ""è""),
        (0xC9, ""M"", ""é""),
        (0xCA, ""M"", ""ê""),
        (0xCB, ""M"", ""ë""),
        (0xCC, ""M"", ""ì""),
        (0xCD, ""M"", ""í""),
        (0xCE, ""M"", ""î""),
        (0xCF, ""M"", ""ï""),
        (0xD0, ""M"", ""ð""),
        (0xD1, ""M"", ""ñ""),
        (0xD2, ""M"", ""ò""),
        (0xD3, ""M"", ""ó""),
        (0xD4, ""M"", ""ô""),
        (0xD5, ""M"", ""õ""),
        (0xD6, ""M"", ""ö""),
        (0xD7, ""V""),
        (0xD8, ""M"", ""ø""),
        (0xD9, ""M"", ""ù""),
        (0xDA, ""M"", ""ú""),
        (0xDB, ""M"", ""û""),
        (0xDC, ""M"", ""ü""),
        (0xDD, ""M"", ""ý""),
        (0xDE, ""M"", ""þ""),
        (0xDF, ""D"", ""ss""),
        (0xE0, ""V""),
        (0xE1, ""V""),
        (0xE2, ""V""),
        (0xE3, ""V""),
        (0xE4, ""V""),
        (0xE5, ""V""),
        (0xE6, ""V""),
        (0xE7, ""V""),
        (0xE8, ""V""),
        (0xE9, ""V""),
        (0xEA, ""V""),
        (0xEB, ""V""),
        (0xEC, ""V""),
        (0xED, ""V""),
        (0xEE, ""V""),
        (0xEF, ""V""),
        (0xF0, ""V""),
        (0xF1, ""V""),
        (0xF2, ""V""),
        (0xF3, ""V""),
        (0xF4, ""V""),
        (0xF5, ""V""),
        (0xF6, ""V""),
        (0xF7, ""V""),
        (0xF8, ""V""),
        (0xF9, ""V""),
        (0xFA, ""V""),
        (0xFB, ""V""),
        (0xFC, ""V""),
        (0xFD, ""V""),
        (0xFE, ""V""),
        (0xFF, ""V""),
        (0x100, ""M"", ""ā""),
        (0x101, ""V""),
        (0x102, ""M"", ""ă""),
        (0x103, ""V""),
        (0x104, ""M"", ""ą""),
        (0x105, ""V""),
        (0x106, ""M"", ""ć""),
        (0x107, ""V""),
        (0x108, ""M"", ""ĉ""),
        (0x109, ""V""),
        (0x10A, ""M"", ""ċ""),
        (0x10B, ""V""),
        (0x10C, ""M"", ""č""),
        (0x10D, ""V""),
        (0x10E, ""M"", ""ď""),
        (0x10F, ""V""),
        (0x110, ""M"", ""đ""),
        (0x111, ""V""),
        (0x112, ""M"", ""ē""),
        (0x113, ""V""),
        (0x114, ""M"", ""ĕ""),
        (0x115, ""V""),
        (0x116, ""M"", ""ė""),
        (0x117, ""V""),
        (0x118, ""M"", ""ę""),
        (0x119, ""V""),
        (0x11A, ""M"", ""ě""),
        (0x11B, ""V""),
        (0x11C, ""M"", ""ĝ""),
        (0x11D, ""V""),
        (0x11E, ""M"", ""ğ""),
        (0x11F, ""V""),
        (0x120, ""M"", ""ġ""),
        (0x121, ""V""),
        (0x122, ""M"", ""ģ""),
        (0x123, ""V""),
        (0x124, ""M"", ""ĥ""),
        (0x125, ""V""),
        (0x126, ""M"", ""ħ""),
        (0x127, ""V""),
        (0x128, ""M"", ""ĩ""),
        (0x129, ""V""),
        (0x12A, ""M"", ""ī""),
        (0x12B, ""V""),
    ]


def _seg_3() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x12C, ""M"", ""ĭ""),
        (0x12D, ""V""),
        (0x12E, ""M"", ""į""),
        (0x12F, ""V""),
        (0x130, ""M"", ""i̇""),
        (0x131, ""V""),
        (0x132, ""M"", ""ij""),
        (0x134, ""M"", ""ĵ""),
        (0x135, ""V""),
        (0x136, ""M"", ""ķ""),
        (0x137, ""V""),
        (0x139, ""M"", ""ĺ""),
        (0x13A, ""V""),
        (0x13B, ""M"", ""ļ""),
        (0x13C, ""V""),
        (0x13D, ""M"", ""ľ""),
        (0x13E, ""V""),
        (0x13F, ""M"", ""l·""),
        (0x141, ""M"", ""ł""),
        (0x142, ""V""),
        (0x143, ""M"", ""ń""),
        (0x144, ""V""),
        (0x145, ""M"", ""ņ""),
        (0x146, ""V""),
        (0x147, ""M"", ""ň""),
        (0x148, ""V""),
        (0x149, ""M"", ""ʼn""),
        (0x14A, ""M"", ""ŋ""),
        (0x14B, ""V""),
        (0x14C, ""M"", ""ō""),
        (0x14D, ""V""),
        (0x14E, ""M"", ""ŏ""),
        (0x14F, ""V""),
        (0x150, ""M"", ""ő""),
        (0x151, ""V""),
        (0x152, ""M"", ""œ""),
        (0x153, ""V""),
        (0x154, ""M"", ""ŕ""),
        (0x155, ""V""),
        (0x156, ""M"", ""ŗ""),
        (0x157, ""V""),
        (0x158, ""M"", ""ř""),
        (0x159, ""V""),
        (0x15A, ""M"", ""ś""),
        (0x15B, ""V""),
        (0x15C, ""M"", ""ŝ""),
        (0x15D, ""V""),
        (0x15E, ""M"", ""ş""),
        (0x15F, ""V""),
        (0x160, ""M"", ""š""),
        (0x161, ""V""),
        (0x162, ""M"", ""ţ""),
        (0x163, ""V""),
        (0x164, ""M"", ""ť""),
        (0x165, ""V""),
        (0x166, ""M"", ""ŧ""),
        (0x167, ""V""),
        (0x168, ""M"", ""ũ""),
        (0x169, ""V""),
        (0x16A, ""M"", ""ū""),
        (0x16B, ""V""),
        (0x16C, ""M"", ""ŭ""),
        (0x16D, ""V""),
        (0x16E, ""M"", ""ů""),
        (0x16F, ""V""),
        (0x170, ""M"", ""ű""),
        (0x171, ""V""),
        (0x172, ""M"", ""ų""),
        (0x173, ""V""),
        (0x174, ""M"", ""ŵ""),
        (0x175, ""V""),
        (0x176, ""M"", ""ŷ""),
        (0x177, ""V""),
        (0x178, ""M"", ""ÿ""),
        (0x179, ""M"", ""ź""),
        (0x17A, ""V""),
        (0x17B, ""M"", ""ż""),
        (0x17C, ""V""),
        (0x17D, ""M"", ""ž""),
        (0x17E, ""V""),
        (0x17F, ""M"", ""s""),
        (0x180, ""V""),
        (0x181, ""M"", ""ɓ""),
        (0x182, ""M"", ""ƃ""),
        (0x183, ""V""),
        (0x184, ""M"", ""ƅ""),
        (0x185, ""V""),
        (0x186, ""M"", ""ɔ""),
        (0x187, ""M"", ""ƈ""),
        (0x188, ""V""),
        (0x189, ""M"", ""ɖ""),
        (0x18A, ""M"", ""ɗ""),
        (0x18B, ""M"", ""ƌ""),
        (0x18C, ""V""),
        (0x18E, ""M"", ""ǝ""),
        (0x18F, ""M"", ""ə""),
        (0x190, ""M"", ""ɛ""),
        (0x191, ""M"", ""ƒ""),
        (0x192, ""V""),
        (0x193, ""M"", ""ɠ""),
    ]


def _seg_4() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x194, ""M"", ""ɣ""),
        (0x195, ""V""),
        (0x196, ""M"", ""ɩ""),
        (0x197, ""M"", ""ɨ""),
        (0x198, ""M"", ""ƙ""),
        (0x199, ""V""),
        (0x19C, ""M"", ""ɯ""),
        (0x19D, ""M"", ""ɲ""),
        (0x19E, ""V""),
        (0x19F, ""M"", ""ɵ""),
        (0x1A0, ""M"", ""ơ""),
        (0x1A1, ""V""),
        (0x1A2, ""M"", ""ƣ""),
        (0x1A3, ""V""),
        (0x1A4, ""M"", ""ƥ""),
        (0x1A5, ""V""),
        (0x1A6, ""M"", ""ʀ""),
        (0x1A7, ""M"", ""ƨ""),
        (0x1A8, ""V""),
        (0x1A9, ""M"", ""ʃ""),
        (0x1AA, ""V""),
        (0x1AC, ""M"", ""ƭ""),
        (0x1AD, ""V""),
        (0x1AE, ""M"", ""ʈ""),
        (0x1AF, ""M"", ""ư""),
        (0x1B0, ""V""),
        (0x1B1, ""M"", ""ʊ""),
        (0x1B2, ""M"", ""ʋ""),
        (0x1B3, ""M"", ""ƴ""),
        (0x1B4, ""V""),
        (0x1B5, ""M"", ""ƶ""),
        (0x1B6, ""V""),
        (0x1B7, ""M"", ""ʒ""),
        (0x1B8, ""M"", ""ƹ""),
        (0x1B9, ""V""),
        (0x1BC, ""M"", ""ƽ""),
        (0x1BD, ""V""),
        (0x1C4, ""M"", ""dž""),
        (0x1C7, ""M"", ""lj""),
        (0x1CA, ""M"", ""nj""),
        (0x1CD, ""M"", ""ǎ""),
        (0x1CE, ""V""),
        (0x1CF, ""M"", ""ǐ""),
        (0x1D0, ""V""),
        (0x1D1, ""M"", ""ǒ""),
        (0x1D2, ""V""),
        (0x1D3, ""M"", ""ǔ""),
        (0x1D4, ""V""),
        (0x1D5, ""M"", ""ǖ""),
        (0x1D6, ""V""),
        (0x1D7, ""M"", ""ǘ""),
        (0x1D8, ""V""),
        (0x1D9, ""M"", ""ǚ""),
        (0x1DA, ""V""),
        (0x1DB, ""M"", ""ǜ""),
        (0x1DC, ""V""),
        (0x1DE, ""M"", ""ǟ""),
        (0x1DF, ""V""),
        (0x1E0, ""M"", ""ǡ""),
        (0x1E1, ""V""),
        (0x1E2, ""M"", ""ǣ""),
        (0x1E3, ""V""),
        (0x1E4, ""M"", ""ǥ""),
        (0x1E5, ""V""),
        (0x1E6, ""M"", ""ǧ""),
        (0x1E7, ""V""),
        (0x1E8, ""M"", ""ǩ""),
        (0x1E9, ""V""),
        (0x1EA, ""M"", ""ǫ""),
        (0x1EB, ""V""),
        (0x1EC, ""M"", ""ǭ""),
        (0x1ED, ""V""),
        (0x1EE, ""M"", ""ǯ""),
        (0x1EF, ""V""),
        (0x1F1, ""M"", ""dz""),
        (0x1F4, ""M"", ""ǵ""),
        (0x1F5, ""V""),
        (0x1F6, ""M"", ""ƕ""),
        (0x1F7, ""M"", ""ƿ""),
        (0x1F8, ""M"", ""ǹ""),
        (0x1F9, ""V""),
        (0x1FA, ""M"", ""ǻ""),
        (0x1FB, ""V""),
        (0x1FC, ""M"", ""ǽ""),
        (0x1FD, ""V""),
        (0x1FE, ""M"", ""ǿ""),
        (0x1FF, ""V""),
        (0x200, ""M"", ""ȁ""),
        (0x201, ""V""),
        (0x202, ""M"", ""ȃ""),
        (0x203, ""V""),
        (0x204, ""M"", ""ȅ""),
        (0x205, ""V""),
        (0x206, ""M"", ""ȇ""),
        (0x207, ""V""),
        (0x208, ""M"", ""ȉ""),
        (0x209, ""V""),
        (0x20A, ""M"", ""ȋ""),
        (0x20B, ""V""),
        (0x20C, ""M"", ""ȍ""),
    ]


def _seg_5() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x20D, ""V""),
        (0x20E, ""M"", ""ȏ""),
        (0x20F, ""V""),
        (0x210, ""M"", ""ȑ""),
        (0x211, ""V""),
        (0x212, ""M"", ""ȓ""),
        (0x213, ""V""),
        (0x214, ""M"", ""ȕ""),
        (0x215, ""V""),
        (0x216, ""M"", ""ȗ""),
        (0x217, ""V""),
        (0x218, ""M"", ""ș""),
        (0x219, ""V""),
        (0x21A, ""M"", ""ț""),
        (0x21B, ""V""),
        (0x21C, ""M"", ""ȝ""),
        (0x21D, ""V""),
        (0x21E, ""M"", ""ȟ""),
        (0x21F, ""V""),
        (0x220, ""M"", ""ƞ""),
        (0x221, ""V""),
        (0x222, ""M"", ""ȣ""),
        (0x223, ""V""),
        (0x224, ""M"", ""ȥ""),
        (0x225, ""V""),
        (0x226, ""M"", ""ȧ""),
        (0x227, ""V""),
        (0x228, ""M"", ""ȩ""),
        (0x229, ""V""),
        (0x22A, ""M"", ""ȫ""),
        (0x22B, ""V""),
        (0x22C, ""M"", ""ȭ""),
        (0x22D, ""V""),
        (0x22E, ""M"", ""ȯ""),
        (0x22F, ""V""),
        (0x230, ""M"", ""ȱ""),
        (0x231, ""V""),
        (0x232, ""M"", ""ȳ""),
        (0x233, ""V""),
        (0x23A, ""M"", ""ⱥ""),
        (0x23B, ""M"", ""ȼ""),
        (0x23C, ""V""),
        (0x23D, ""M"", ""ƚ""),
        (0x23E, ""M"", ""ⱦ""),
        (0x23F, ""V""),
        (0x241, ""M"", ""ɂ""),
        (0x242, ""V""),
        (0x243, ""M"", ""ƀ""),
        (0x244, ""M"", ""ʉ""),
        (0x245, ""M"", ""ʌ""),
        (0x246, ""M"", ""ɇ""),
        (0x247, ""V""),
        (0x248, ""M"", ""ɉ""),
        (0x249, ""V""),
        (0x24A, ""M"", ""ɋ""),
        (0x24B, ""V""),
        (0x24C, ""M"", ""ɍ""),
        (0x24D, ""V""),
        (0x24E, ""M"", ""ɏ""),
        (0x24F, ""V""),
        (0x2B0, ""M"", ""h""),
        (0x2B1, ""M"", ""ɦ""),
        (0x2B2, ""M"", ""j""),
        (0x2B3, ""M"", ""r""),
        (0x2B4, ""M"", ""ɹ""),
        (0x2B5, ""M"", ""ɻ""),
        (0x2B6, ""M"", ""ʁ""),
        (0x2B7, ""M"", ""w""),
        (0x2B8, ""M"", ""y""),
        (0x2B9, ""V""),
        (0x2D8, ""3"", "" ̆""),
        (0x2D9, ""3"", "" ̇""),
        (0x2DA, ""3"", "" ̊""),
        (0x2DB, ""3"", "" ̨""),
        (0x2DC, ""3"", "" ̃""),
        (0x2DD, ""3"", "" ̋""),
        (0x2DE, ""V""),
        (0x2E0, ""M"", ""ɣ""),
        (0x2E1, ""M"", ""l""),
        (0x2E2, ""M"", ""s""),
        (0x2E3, ""M"", ""x""),
        (0x2E4, ""M"", ""ʕ""),
        (0x2E5, ""V""),
        (0x340, ""M"", ""̀""),
        (0x341, ""M"", ""́""),
        (0x342, ""V""),
        (0x343, ""M"", ""̓""),
        (0x344, ""M"", ""̈́""),
        (0x345, ""M"", ""ι""),
        (0x346, ""V""),
        (0x34F, ""I""),
        (0x350, ""V""),
        (0x370, ""M"", ""ͱ""),
        (0x371, ""V""),
        (0x372, ""M"", ""ͳ""),
        (0x373, ""V""),
        (0x374, ""M"", ""ʹ""),
        (0x375, ""V""),
        (0x376, ""M"", ""ͷ""),
        (0x377, ""V""),
    ]


def _seg_6() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x378, ""X""),
        (0x37A, ""3"", "" ι""),
        (0x37B, ""V""),
        (0x37E, ""3"", "";""),
        (0x37F, ""M"", ""ϳ""),
        (0x380, ""X""),
        (0x384, ""3"", "" ́""),
        (0x385, ""3"", "" ̈́""),
        (0x386, ""M"", ""ά""),
        (0x387, ""M"", ""·""),
        (0x388, ""M"", ""έ""),
        (0x389, ""M"", ""ή""),
        (0x38A, ""M"", ""ί""),
        (0x38B, ""X""),
        (0x38C, ""M"", ""ό""),
        (0x38D, ""X""),
        (0x38E, ""M"", ""ύ""),
        (0x38F, ""M"", ""ώ""),
        (0x390, ""V""),
        (0x391, ""M"", ""α""),
        (0x392, ""M"", ""β""),
        (0x393, ""M"", ""γ""),
        (0x394, ""M"", ""δ""),
        (0x395, ""M"", ""ε""),
        (0x396, ""M"", ""ζ""),
        (0x397, ""M"", ""η""),
        (0x398, ""M"", ""θ""),
        (0x399, ""M"", ""ι""),
        (0x39A, ""M"", ""κ""),
        (0x39B, ""M"", ""λ""),
        (0x39C, ""M"", ""μ""),
        (0x39D, ""M"", ""ν""),
        (0x39E, ""M"", ""ξ""),
        (0x39F, ""M"", ""ο""),
        (0x3A0, ""M"", ""π""),
        (0x3A1, ""M"", ""ρ""),
        (0x3A2, ""X""),
        (0x3A3, ""M"", ""σ""),
        (0x3A4, ""M"", ""τ""),
        (0x3A5, ""M"", ""υ""),
        (0x3A6, ""M"", ""φ""),
        (0x3A7, ""M"", ""χ""),
        (0x3A8, ""M"", ""ψ""),
        (0x3A9, ""M"", ""ω""),
        (0x3AA, ""M"", ""ϊ""),
        (0x3AB, ""M"", ""ϋ""),
        (0x3AC, ""V""),
        (0x3C2, ""D"", ""σ""),
        (0x3C3, ""V""),
        (0x3CF, ""M"", ""ϗ""),
        (0x3D0, ""M"", ""β""),
        (0x3D1, ""M"", ""θ""),
        (0x3D2, ""M"", ""υ""),
        (0x3D3, ""M"", ""ύ""),
        (0x3D4, ""M"", ""ϋ""),
        (0x3D5, ""M"", ""φ""),
        (0x3D6, ""M"", ""π""),
        (0x3D7, ""V""),
        (0x3D8, ""M"", ""ϙ""),
        (0x3D9, ""V""),
        (0x3DA, ""M"", ""ϛ""),
        (0x3DB, ""V""),
        (0x3DC, ""M"", ""ϝ""),
        (0x3DD, ""V""),
        (0x3DE, ""M"", ""ϟ""),
        (0x3DF, ""V""),
        (0x3E0, ""M"", ""ϡ""),
        (0x3E1, ""V""),
        (0x3E2, ""M"", ""ϣ""),
        (0x3E3, ""V""),
        (0x3E4, ""M"", ""ϥ""),
        (0x3E5, ""V""),
        (0x3E6, ""M"", ""ϧ""),
        (0x3E7, ""V""),
        (0x3E8, ""M"", ""ϩ""),
        (0x3E9, ""V""),
        (0x3EA, ""M"", ""ϫ""),
        (0x3EB, ""V""),
        (0x3EC, ""M"", ""ϭ""),
        (0x3ED, ""V""),
        (0x3EE, ""M"", ""ϯ""),
        (0x3EF, ""V""),
        (0x3F0, ""M"", ""κ""),
        (0x3F1, ""M"", ""ρ""),
        (0x3F2, ""M"", ""σ""),
        (0x3F3, ""V""),
        (0x3F4, ""M"", ""θ""),
        (0x3F5, ""M"", ""ε""),
        (0x3F6, ""V""),
        (0x3F7, ""M"", ""ϸ""),
        (0x3F8, ""V""),
        (0x3F9, ""M"", ""σ""),
        (0x3FA, ""M"", ""ϻ""),
        (0x3FB, ""V""),
        (0x3FD, ""M"", ""ͻ""),
        (0x3FE, ""M"", ""ͼ""),
        (0x3FF, ""M"", ""ͽ""),
        (0x400, ""M"", ""ѐ""),
        (0x401, ""M"", ""ё""),
        (0x402, ""M"", ""ђ""),
    ]


def _seg_7() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x403, ""M"", ""ѓ""),
        (0x404, ""M"", ""є""),
        (0x405, ""M"", ""ѕ""),
        (0x406, ""M"", ""і""),
        (0x407, ""M"", ""ї""),
        (0x408, ""M"", ""ј""),
        (0x409, ""M"", ""љ""),
        (0x40A, ""M"", ""њ""),
        (0x40B, ""M"", ""ћ""),
        (0x40C, ""M"", ""ќ""),
        (0x40D, ""M"", ""ѝ""),
        (0x40E, ""M"", ""ў""),
        (0x40F, ""M"", ""џ""),
        (0x410, ""M"", ""а""),
        (0x411, ""M"", ""б""),
        (0x412, ""M"", ""в""),
        (0x413, ""M"", ""г""),
        (0x414, ""M"", ""д""),
        (0x415, ""M"", ""е""),
        (0x416, ""M"", ""ж""),
        (0x417, ""M"", ""з""),
        (0x418, ""M"", ""и""),
        (0x419, ""M"", ""й""),
        (0x41A, ""M"", ""к""),
        (0x41B, ""M"", ""л""),
        (0x41C, ""M"", ""м""),
        (0x41D, ""M"", ""н""),
        (0x41E, ""M"", ""о""),
        (0x41F, ""M"", ""п""),
        (0x420, ""M"", ""р""),
        (0x421, ""M"", ""с""),
        (0x422, ""M"", ""т""),
        (0x423, ""M"", ""у""),
        (0x424, ""M"", ""ф""),
        (0x425, ""M"", ""х""),
        (0x426, ""M"", ""ц""),
        (0x427, ""M"", ""ч""),
        (0x428, ""M"", ""ш""),
        (0x429, ""M"", ""щ""),
        (0x42A, ""M"", ""ъ""),
        (0x42B, ""M"", ""ы""),
        (0x42C, ""M"", ""ь""),
        (0x42D, ""M"", ""э""),
        (0x42E, ""M"", ""ю""),
        (0x42F, ""M"", ""я""),
        (0x430, ""V""),
        (0x460, ""M"", ""ѡ""),
        (0x461, ""V""),
        (0x462, ""M"", ""ѣ""),
        (0x463, ""V""),
        (0x464, ""M"", ""ѥ""),
        (0x465, ""V""),
        (0x466, ""M"", ""ѧ""),
        (0x467, ""V""),
        (0x468, ""M"", ""ѩ""),
        (0x469, ""V""),
        (0x46A, ""M"", ""ѫ""),
        (0x46B, ""V""),
        (0x46C, ""M"", ""ѭ""),
        (0x46D, ""V""),
        (0x46E, ""M"", ""ѯ""),
        (0x46F, ""V""),
        (0x470, ""M"", ""ѱ""),
        (0x471, ""V""),
        (0x472, ""M"", ""ѳ""),
        (0x473, ""V""),
        (0x474, ""M"", ""ѵ""),
        (0x475, ""V""),
        (0x476, ""M"", ""ѷ""),
        (0x477, ""V""),
        (0x478, ""M"", ""ѹ""),
        (0x479, ""V""),
        (0x47A, ""M"", ""ѻ""),
        (0x47B, ""V""),
        (0x47C, ""M"", ""ѽ""),
        (0x47D, ""V""),
        (0x47E, ""M"", ""ѿ""),
        (0x47F, ""V""),
        (0x480, ""M"", ""ҁ""),
        (0x481, ""V""),
        (0x48A, ""M"", ""ҋ""),
        (0x48B, ""V""),
        (0x48C, ""M"", ""ҍ""),
        (0x48D, ""V""),
        (0x48E, ""M"", ""ҏ""),
        (0x48F, ""V""),
        (0x490, ""M"", ""ґ""),
        (0x491, ""V""),
        (0x492, ""M"", ""ғ""),
        (0x493, ""V""),
        (0x494, ""M"", ""ҕ""),
        (0x495, ""V""),
        (0x496, ""M"", ""җ""),
        (0x497, ""V""),
        (0x498, ""M"", ""ҙ""),
        (0x499, ""V""),
        (0x49A, ""M"", ""қ""),
        (0x49B, ""V""),
        (0x49C, ""M"", ""ҝ""),
        (0x49D, ""V""),
    ]


def _seg_8() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x49E, ""M"", ""ҟ""),
        (0x49F, ""V""),
        (0x4A0, ""M"", ""ҡ""),
        (0x4A1, ""V""),
        (0x4A2, ""M"", ""ң""),
        (0x4A3, ""V""),
        (0x4A4, ""M"", ""ҥ""),
        (0x4A5, ""V""),
        (0x4A6, ""M"", ""ҧ""),
        (0x4A7, ""V""),
        (0x4A8, ""M"", ""ҩ""),
        (0x4A9, ""V""),
        (0x4AA, ""M"", ""ҫ""),
        (0x4AB, ""V""),
        (0x4AC, ""M"", ""ҭ""),
        (0x4AD, ""V""),
        (0x4AE, ""M"", ""ү""),
        (0x4AF, ""V""),
        (0x4B0, ""M"", ""ұ""),
        (0x4B1, ""V""),
        (0x4B2, ""M"", ""ҳ""),
        (0x4B3, ""V""),
        (0x4B4, ""M"", ""ҵ""),
        (0x4B5, ""V""),
        (0x4B6, ""M"", ""ҷ""),
        (0x4B7, ""V""),
        (0x4B8, ""M"", ""ҹ""),
        (0x4B9, ""V""),
        (0x4BA, ""M"", ""һ""),
        (0x4BB, ""V""),
        (0x4BC, ""M"", ""ҽ""),
        (0x4BD, ""V""),
        (0x4BE, ""M"", ""ҿ""),
        (0x4BF, ""V""),
        (0x4C0, ""X""),
        (0x4C1, ""M"", ""ӂ""),
        (0x4C2, ""V""),
        (0x4C3, ""M"", ""ӄ""),
        (0x4C4, ""V""),
        (0x4C5, ""M"", ""ӆ""),
        (0x4C6, ""V""),
        (0x4C7, ""M"", ""ӈ""),
        (0x4C8, ""V""),
        (0x4C9, ""M"", ""ӊ""),
        (0x4CA, ""V""),
        (0x4CB, ""M"", ""ӌ""),
        (0x4CC, ""V""),
        (0x4CD, ""M"", ""ӎ""),
        (0x4CE, ""V""),
        (0x4D0, ""M"", ""ӑ""),
        (0x4D1, ""V""),
        (0x4D2, ""M"", ""ӓ""),
        (0x4D3, ""V""),
        (0x4D4, ""M"", ""ӕ""),
        (0x4D5, ""V""),
        (0x4D6, ""M"", ""ӗ""),
        (0x4D7, ""V""),
        (0x4D8, ""M"", ""ә""),
        (0x4D9, ""V""),
        (0x4DA, ""M"", ""ӛ""),
        (0x4DB, ""V""),
        (0x4DC, ""M"", ""ӝ""),
        (0x4DD, ""V""),
        (0x4DE, ""M"", ""ӟ""),
        (0x4DF, ""V""),
        (0x4E0, ""M"", ""ӡ""),
        (0x4E1, ""V""),
        (0x4E2, ""M"", ""ӣ""),
        (0x4E3, ""V""),
        (0x4E4, ""M"", ""ӥ""),
        (0x4E5, ""V""),
        (0x4E6, ""M"", ""ӧ""),
        (0x4E7, ""V""),
        (0x4E8, ""M"", ""ө""),
        (0x4E9, ""V""),
        (0x4EA, ""M"", ""ӫ""),
        (0x4EB, ""V""),
        (0x4EC, ""M"", ""ӭ""),
        (0x4ED, ""V""),
        (0x4EE, ""M"", ""ӯ""),
        (0x4EF, ""V""),
        (0x4F0, ""M"", ""ӱ""),
        (0x4F1, ""V""),
        (0x4F2, ""M"", ""ӳ""),
        (0x4F3, ""V""),
        (0x4F4, ""M"", ""ӵ""),
        (0x4F5, ""V""),
        (0x4F6, ""M"", ""ӷ""),
        (0x4F7, ""V""),
        (0x4F8, ""M"", ""ӹ""),
        (0x4F9, ""V""),
        (0x4FA, ""M"", ""ӻ""),
        (0x4FB, ""V""),
        (0x4FC, ""M"", ""ӽ""),
        (0x4FD, ""V""),
        (0x4FE, ""M"", ""ӿ""),
        (0x4FF, ""V""),
        (0x500, ""M"", ""ԁ""),
        (0x501, ""V""),
        (0x502, ""M"", ""ԃ""),
    ]


def _seg_9() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x503, ""V""),
        (0x504, ""M"", ""ԅ""),
        (0x505, ""V""),
        (0x506, ""M"", ""ԇ""),
        (0x507, ""V""),
        (0x508, ""M"", ""ԉ""),
        (0x509, ""V""),
        (0x50A, ""M"", ""ԋ""),
        (0x50B, ""V""),
        (0x50C, ""M"", ""ԍ""),
        (0x50D, ""V""),
        (0x50E, ""M"", ""ԏ""),
        (0x50F, ""V""),
        (0x510, ""M"", ""ԑ""),
        (0x511, ""V""),
        (0x512, ""M"", ""ԓ""),
        (0x513, ""V""),
        (0x514, ""M"", ""ԕ""),
        (0x515, ""V""),
        (0x516, ""M"", ""ԗ""),
        (0x517, ""V""),
        (0x518, ""M"", ""ԙ""),
        (0x519, ""V""),
        (0x51A, ""M"", ""ԛ""),
        (0x51B, ""V""),
        (0x51C, ""M"", ""ԝ""),
        (0x51D, ""V""),
        (0x51E, ""M"", ""ԟ""),
        (0x51F, ""V""),
        (0x520, ""M"", ""ԡ""),
        (0x521, ""V""),
        (0x522, ""M"", ""ԣ""),
        (0x523, ""V""),
        (0x524, ""M"", ""ԥ""),
        (0x525, ""V""),
        (0x526, ""M"", ""ԧ""),
        (0x527, ""V""),
        (0x528, ""M"", ""ԩ""),
        (0x529, ""V""),
        (0x52A, ""M"", ""ԫ""),
        (0x52B, ""V""),
        (0x52C, ""M"", ""ԭ""),
        (0x52D, ""V""),
        (0x52E, ""M"", ""ԯ""),
        (0x52F, ""V""),
        (0x530, ""X""),
        (0x531, ""M"", ""ա""),
        (0x532, ""M"", ""բ""),
        (0x533, ""M"", ""գ""),
        (0x534, ""M"", ""դ""),
        (0x535, ""M"", ""ե""),
        (0x536, ""M"", ""զ""),
        (0x537, ""M"", ""է""),
        (0x538, ""M"", ""ը""),
        (0x539, ""M"", ""թ""),
        (0x53A, ""M"", ""ժ""),
        (0x53B, ""M"", ""ի""),
        (0x53C, ""M"", ""լ""),
        (0x53D, ""M"", ""խ""),
        (0x53E, ""M"", ""ծ""),
        (0x53F, ""M"", ""կ""),
        (0x540, ""M"", ""հ""),
        (0x541, ""M"", ""ձ""),
        (0x542, ""M"", ""ղ""),
        (0x543, ""M"", ""ճ""),
        (0x544, ""M"", ""մ""),
        (0x545, ""M"", ""յ""),
        (0x546, ""M"", ""ն""),
        (0x547, ""M"", ""շ""),
        (0x548, ""M"", ""ո""),
        (0x549, ""M"", ""չ""),
        (0x54A, ""M"", ""պ""),
        (0x54B, ""M"", ""ջ""),
        (0x54C, ""M"", ""ռ""),
        (0x54D, ""M"", ""ս""),
        (0x54E, ""M"", ""վ""),
        (0x54F, ""M"", ""տ""),
        (0x550, ""M"", ""ր""),
        (0x551, ""M"", ""ց""),
        (0x552, ""M"", ""ւ""),
        (0x553, ""M"", ""փ""),
        (0x554, ""M"", ""ք""),
        (0x555, ""M"", ""օ""),
        (0x556, ""M"", ""ֆ""),
        (0x557, ""X""),
        (0x559, ""V""),
        (0x587, ""M"", ""եւ""),
        (0x588, ""V""),
        (0x58B, ""X""),
        (0x58D, ""V""),
        (0x590, ""X""),
        (0x591, ""V""),
        (0x5C8, ""X""),
        (0x5D0, ""V""),
        (0x5EB, ""X""),
        (0x5EF, ""V""),
        (0x5F5, ""X""),
        (0x606, ""V""),
        (0x61C, ""X""),
        (0x61D, ""V""),
    ]


def _seg_10() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x675, ""M"", ""اٴ""),
        (0x676, ""M"", ""وٴ""),
        (0x677, ""M"", ""ۇٴ""),
        (0x678, ""M"", ""يٴ""),
        (0x679, ""V""),
        (0x6DD, ""X""),
        (0x6DE, ""V""),
        (0x70E, ""X""),
        (0x710, ""V""),
        (0x74B, ""X""),
        (0x74D, ""V""),
        (0x7B2, ""X""),
        (0x7C0, ""V""),
        (0x7FB, ""X""),
        (0x7FD, ""V""),
        (0x82E, ""X""),
        (0x830, ""V""),
        (0x83F, ""X""),
        (0x840, ""V""),
        (0x85C, ""X""),
        (0x85E, ""V""),
        (0x85F, ""X""),
        (0x860, ""V""),
        (0x86B, ""X""),
        (0x870, ""V""),
        (0x88F, ""X""),
        (0x898, ""V""),
        (0x8E2, ""X""),
        (0x8E3, ""V""),
        (0x958, ""M"", ""क़""),
        (0x959, ""M"", ""ख़""),
        (0x95A, ""M"", ""ग़""),
        (0x95B, ""M"", ""ज़""),
        (0x95C, ""M"", ""ड़""),
        (0x95D, ""M"", ""ढ़""),
        (0x95E, ""M"", ""फ़""),
        (0x95F, ""M"", ""य़""),
        (0x960, ""V""),
        (0x984, ""X""),
        (0x985, ""V""),
        (0x98D, ""X""),
        (0x98F, ""V""),
        (0x991, ""X""),
        (0x993, ""V""),
        (0x9A9, ""X""),
        (0x9AA, ""V""),
        (0x9B1, ""X""),
        (0x9B2, ""V""),
        (0x9B3, ""X""),
        (0x9B6, ""V""),
        (0x9BA, ""X""),
        (0x9BC, ""V""),
        (0x9C5, ""X""),
        (0x9C7, ""V""),
        (0x9C9, ""X""),
        (0x9CB, ""V""),
        (0x9CF, ""X""),
        (0x9D7, ""V""),
        (0x9D8, ""X""),
        (0x9DC, ""M"", ""ড়""),
        (0x9DD, ""M"", ""ঢ়""),
        (0x9DE, ""X""),
        (0x9DF, ""M"", ""য়""),
        (0x9E0, ""V""),
        (0x9E4, ""X""),
        (0x9E6, ""V""),
        (0x9FF, ""X""),
        (0xA01, ""V""),
        (0xA04, ""X""),
        (0xA05, ""V""),
        (0xA0B, ""X""),
        (0xA0F, ""V""),
        (0xA11, ""X""),
        (0xA13, ""V""),
        (0xA29, ""X""),
        (0xA2A, ""V""),
        (0xA31, ""X""),
        (0xA32, ""V""),
        (0xA33, ""M"", ""ਲ਼""),
        (0xA34, ""X""),
        (0xA35, ""V""),
        (0xA36, ""M"", ""ਸ਼""),
        (0xA37, ""X""),
        (0xA38, ""V""),
        (0xA3A, ""X""),
        (0xA3C, ""V""),
        (0xA3D, ""X""),
        (0xA3E, ""V""),
        (0xA43, ""X""),
        (0xA47, ""V""),
        (0xA49, ""X""),
        (0xA4B, ""V""),
        (0xA4E, ""X""),
        (0xA51, ""V""),
        (0xA52, ""X""),
        (0xA59, ""M"", ""ਖ਼""),
        (0xA5A, ""M"", ""ਗ਼""),
        (0xA5B, ""M"", ""ਜ਼""),
        (0xA5C, ""V""),
        (0xA5D, ""X""),
    ]


def _seg_11() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0xA5E, ""M"", ""ਫ਼""),
        (0xA5F, ""X""),
        (0xA66, ""V""),
        (0xA77, ""X""),
        (0xA81, ""V""),
        (0xA84, ""X""),
        (0xA85, ""V""),
        (0xA8E, ""X""),
        (0xA8F, ""V""),
        (0xA92, ""X""),
        (0xA93, ""V""),
        (0xAA9, ""X""),
        (0xAAA, ""V""),
        (0xAB1, ""X""),
        (0xAB2, ""V""),
        (0xAB4, ""X""),
        (0xAB5, ""V""),
        (0xABA, ""X""),
        (0xABC, ""V""),
        (0xAC6, ""X""),
        (0xAC7, ""V""),
        (0xACA, ""X""),
        (0xACB, ""V""),
        (0xACE, ""X""),
        (0xAD0, ""V""),
        (0xAD1, ""X""),
        (0xAE0, ""V""),
        (0xAE4, ""X""),
        (0xAE6, ""V""),
        (0xAF2, ""X""),
        (0xAF9, ""V""),
        (0xB00, ""X""),
        (0xB01, ""V""),
        (0xB04, ""X""),
        (0xB05, ""V""),
        (0xB0D, ""X""),
        (0xB0F, ""V""),
        (0xB11, ""X""),
        (0xB13, ""V""),
        (0xB29, ""X""),
        (0xB2A, ""V""),
        (0xB31, ""X""),
        (0xB32, ""V""),
        (0xB34, ""X""),
        (0xB35, ""V""),
        (0xB3A, ""X""),
        (0xB3C, ""V""),
        (0xB45, ""X""),
        (0xB47, ""V""),
        (0xB49, ""X""),
        (0xB4B, ""V""),
        (0xB4E, ""X""),
        (0xB55, ""V""),
        (0xB58, ""X""),
        (0xB5C, ""M"", ""ଡ଼""),
        (0xB5D, ""M"", ""ଢ଼""),
        (0xB5E, ""X""),
        (0xB5F, ""V""),
        (0xB64, ""X""),
        (0xB66, ""V""),
        (0xB78, ""X""),
        (0xB82, ""V""),
        (0xB84, ""X""),
        (0xB85, ""V""),
        (0xB8B, ""X""),
        (0xB8E, ""V""),
        (0xB91, ""X""),
        (0xB92, ""V""),
        (0xB96, ""X""),
        (0xB99, ""V""),
        (0xB9B, ""X""),
        (0xB9C, ""V""),
        (0xB9D, ""X""),
        (0xB9E, ""V""),
        (0xBA0, ""X""),
        (0xBA3, ""V""),
        (0xBA5, ""X""),
        (0xBA8, ""V""),
        (0xBAB, ""X""),
        (0xBAE, ""V""),
        (0xBBA, ""X""),
        (0xBBE, ""V""),
        (0xBC3, ""X""),
        (0xBC6, ""V""),
        (0xBC9, ""X""),
        (0xBCA, ""V""),
        (0xBCE, ""X""),
        (0xBD0, ""V""),
        (0xBD1, ""X""),
        (0xBD7, ""V""),
        (0xBD8, ""X""),
        (0xBE6, ""V""),
        (0xBFB, ""X""),
        (0xC00, ""V""),
        (0xC0D, ""X""),
        (0xC0E, ""V""),
        (0xC11, ""X""),
        (0xC12, ""V""),
        (0xC29, ""X""),
        (0xC2A, ""V""),
    ]


def _seg_12() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0xC3A, ""X""),
        (0xC3C, ""V""),
        (0xC45, ""X""),
        (0xC46, ""V""),
        (0xC49, ""X""),
        (0xC4A, ""V""),
        (0xC4E, ""X""),
        (0xC55, ""V""),
        (0xC57, ""X""),
        (0xC58, ""V""),
        (0xC5B, ""X""),
        (0xC5D, ""V""),
        (0xC5E, ""X""),
        (0xC60, ""V""),
        (0xC64, ""X""),
        (0xC66, ""V""),
        (0xC70, ""X""),
        (0xC77, ""V""),
        (0xC8D, ""X""),
        (0xC8E, ""V""),
        (0xC91, ""X""),
        (0xC92, ""V""),
        (0xCA9, ""X""),
        (0xCAA, ""V""),
        (0xCB4, ""X""),
        (0xCB5, ""V""),
        (0xCBA, ""X""),
        (0xCBC, ""V""),
        (0xCC5, ""X""),
        (0xCC6, ""V""),
        (0xCC9, ""X""),
        (0xCCA, ""V""),
        (0xCCE, ""X""),
        (0xCD5, ""V""),
        (0xCD7, ""X""),
        (0xCDD, ""V""),
        (0xCDF, ""X""),
        (0xCE0, ""V""),
        (0xCE4, ""X""),
        (0xCE6, ""V""),
        (0xCF0, ""X""),
        (0xCF1, ""V""),
        (0xCF4, ""X""),
        (0xD00, ""V""),
        (0xD0D, ""X""),
        (0xD0E, ""V""),
        (0xD11, ""X""),
        (0xD12, ""V""),
        (0xD45, ""X""),
        (0xD46, ""V""),
        (0xD49, ""X""),
        (0xD4A, ""V""),
        (0xD50, ""X""),
        (0xD54, ""V""),
        (0xD64, ""X""),
        (0xD66, ""V""),
        (0xD80, ""X""),
        (0xD81, ""V""),
        (0xD84, ""X""),
        (0xD85, ""V""),
        (0xD97, ""X""),
        (0xD9A, ""V""),
        (0xDB2, ""X""),
        (0xDB3, ""V""),
        (0xDBC, ""X""),
        (0xDBD, ""V""),
        (0xDBE, ""X""),
        (0xDC0, ""V""),
        (0xDC7, ""X""),
        (0xDCA, ""V""),
        (0xDCB, ""X""),
        (0xDCF, ""V""),
        (0xDD5, ""X""),
        (0xDD6, ""V""),
        (0xDD7, ""X""),
        (0xDD8, ""V""),
        (0xDE0, ""X""),
        (0xDE6, ""V""),
        (0xDF0, ""X""),
        (0xDF2, ""V""),
        (0xDF5, ""X""),
        (0xE01, ""V""),
        (0xE33, ""M"", ""ํา""),
        (0xE34, ""V""),
        (0xE3B, ""X""),
        (0xE3F, ""V""),
        (0xE5C, ""X""),
        (0xE81, ""V""),
        (0xE83, ""X""),
        (0xE84, ""V""),
        (0xE85, ""X""),
        (0xE86, ""V""),
        (0xE8B, ""X""),
        (0xE8C, ""V""),
        (0xEA4, ""X""),
        (0xEA5, ""V""),
        (0xEA6, ""X""),
        (0xEA7, ""V""),
        (0xEB3, ""M"", ""ໍາ""),
        (0xEB4, ""V""),
    ]


def _seg_13() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0xEBE, ""X""),
        (0xEC0, ""V""),
        (0xEC5, ""X""),
        (0xEC6, ""V""),
        (0xEC7, ""X""),
        (0xEC8, ""V""),
        (0xECF, ""X""),
        (0xED0, ""V""),
        (0xEDA, ""X""),
        (0xEDC, ""M"", ""ຫນ""),
        (0xEDD, ""M"", ""ຫມ""),
        (0xEDE, ""V""),
        (0xEE0, ""X""),
        (0xF00, ""V""),
        (0xF0C, ""M"", ""་""),
        (0xF0D, ""V""),
        (0xF43, ""M"", ""གྷ""),
        (0xF44, ""V""),
        (0xF48, ""X""),
        (0xF49, ""V""),
        (0xF4D, ""M"", ""ཌྷ""),
        (0xF4E, ""V""),
        (0xF52, ""M"", ""དྷ""),
        (0xF53, ""V""),
        (0xF57, ""M"", ""བྷ""),
        (0xF58, ""V""),
        (0xF5C, ""M"", ""ཛྷ""),
        (0xF5D, ""V""),
        (0xF69, ""M"", ""ཀྵ""),
        (0xF6A, ""V""),
        (0xF6D, ""X""),
        (0xF71, ""V""),
        (0xF73, ""M"", ""ཱི""),
        (0xF74, ""V""),
        (0xF75, ""M"", ""ཱུ""),
        (0xF76, ""M"", ""ྲྀ""),
        (0xF77, ""M"", ""ྲཱྀ""),
        (0xF78, ""M"", ""ླྀ""),
        (0xF79, ""M"", ""ླཱྀ""),
        (0xF7A, ""V""),
        (0xF81, ""M"", ""ཱྀ""),
        (0xF82, ""V""),
        (0xF93, ""M"", ""ྒྷ""),
        (0xF94, ""V""),
        (0xF98, ""X""),
        (0xF99, ""V""),
        (0xF9D, ""M"", ""ྜྷ""),
        (0xF9E, ""V""),
        (0xFA2, ""M"", ""ྡྷ""),
        (0xFA3, ""V""),
        (0xFA7, ""M"", ""ྦྷ""),
        (0xFA8, ""V""),
        (0xFAC, ""M"", ""ྫྷ""),
        (0xFAD, ""V""),
        (0xFB9, ""M"", ""ྐྵ""),
        (0xFBA, ""V""),
        (0xFBD, ""X""),
        (0xFBE, ""V""),
        (0xFCD, ""X""),
        (0xFCE, ""V""),
        (0xFDB, ""X""),
        (0x1000, ""V""),
        (0x10A0, ""X""),
        (0x10C7, ""M"", ""ⴧ""),
        (0x10C8, ""X""),
        (0x10CD, ""M"", ""ⴭ""),
        (0x10CE, ""X""),
        (0x10D0, ""V""),
        (0x10FC, ""M"", ""ნ""),
        (0x10FD, ""V""),
        (0x115F, ""X""),
        (0x1161, ""V""),
        (0x1249, ""X""),
        (0x124A, ""V""),
        (0x124E, ""X""),
        (0x1250, ""V""),
        (0x1257, ""X""),
        (0x1258, ""V""),
        (0x1259, ""X""),
        (0x125A, ""V""),
        (0x125E, ""X""),
        (0x1260, ""V""),
        (0x1289, ""X""),
        (0x128A, ""V""),
        (0x128E, ""X""),
        (0x1290, ""V""),
        (0x12B1, ""X""),
        (0x12B2, ""V""),
        (0x12B6, ""X""),
        (0x12B8, ""V""),
        (0x12BF, ""X""),
        (0x12C0, ""V""),
        (0x12C1, ""X""),
        (0x12C2, ""V""),
        (0x12C6, ""X""),
        (0x12C8, ""V""),
        (0x12D7, ""X""),
        (0x12D8, ""V""),
        (0x1311, ""X""),
        (0x1312, ""V""),
    ]


def _seg_14() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x1316, ""X""),
        (0x1318, ""V""),
        (0x135B, ""X""),
        (0x135D, ""V""),
        (0x137D, ""X""),
        (0x1380, ""V""),
        (0x139A, ""X""),
        (0x13A0, ""V""),
        (0x13F6, ""X""),
        (0x13F8, ""M"", ""Ᏸ""),
        (0x13F9, ""M"", ""Ᏹ""),
        (0x13FA, ""M"", ""Ᏺ""),
        (0x13FB, ""M"", ""Ᏻ""),
        (0x13FC, ""M"", ""Ᏼ""),
        (0x13FD, ""M"", ""Ᏽ""),
        (0x13FE, ""X""),
        (0x1400, ""V""),
        (0x1680, ""X""),
        (0x1681, ""V""),
        (0x169D, ""X""),
        (0x16A0, ""V""),
        (0x16F9, ""X""),
        (0x1700, ""V""),
        (0x1716, ""X""),
        (0x171F, ""V""),
        (0x1737, ""X""),
        (0x1740, ""V""),
        (0x1754, ""X""),
        (0x1760, ""V""),
        (0x176D, ""X""),
        (0x176E, ""V""),
        (0x1771, ""X""),
        (0x1772, ""V""),
        (0x1774, ""X""),
        (0x1780, ""V""),
        (0x17B4, ""X""),
        (0x17B6, ""V""),
        (0x17DE, ""X""),
        (0x17E0, ""V""),
        (0x17EA, ""X""),
        (0x17F0, ""V""),
        (0x17FA, ""X""),
        (0x1800, ""V""),
        (0x1806, ""X""),
        (0x1807, ""V""),
        (0x180B, ""I""),
        (0x180E, ""X""),
        (0x180F, ""I""),
        (0x1810, ""V""),
        (0x181A, ""X""),
        (0x1820, ""V""),
        (0x1879, ""X""),
        (0x1880, ""V""),
        (0x18AB, ""X""),
        (0x18B0, ""V""),
        (0x18F6, ""X""),
        (0x1900, ""V""),
        (0x191F, ""X""),
        (0x1920, ""V""),
        (0x192C, ""X""),
        (0x1930, ""V""),
        (0x193C, ""X""),
        (0x1940, ""V""),
        (0x1941, ""X""),
        (0x1944, ""V""),
        (0x196E, ""X""),
        (0x1970, ""V""),
        (0x1975, ""X""),
        (0x1980, ""V""),
        (0x19AC, ""X""),
        (0x19B0, ""V""),
        (0x19CA, ""X""),
        (0x19D0, ""V""),
        (0x19DB, ""X""),
        (0x19DE, ""V""),
        (0x1A1C, ""X""),
        (0x1A1E, ""V""),
        (0x1A5F, ""X""),
        (0x1A60, ""V""),
        (0x1A7D, ""X""),
        (0x1A7F, ""V""),
        (0x1A8A, ""X""),
        (0x1A90, ""V""),
        (0x1A9A, ""X""),
        (0x1AA0, ""V""),
        (0x1AAE, ""X""),
        (0x1AB0, ""V""),
        (0x1ACF, ""X""),
        (0x1B00, ""V""),
        (0x1B4D, ""X""),
        (0x1B50, ""V""),
        (0x1B7F, ""X""),
        (0x1B80, ""V""),
        (0x1BF4, ""X""),
        (0x1BFC, ""V""),
        (0x1C38, ""X""),
        (0x1C3B, ""V""),
        (0x1C4A, ""X""),
        (0x1C4D, ""V""),
        (0x1C80, ""M"", ""в""),
    ]


def _seg_15() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x1C81, ""M"", ""д""),
        (0x1C82, ""M"", ""о""),
        (0x1C83, ""M"", ""с""),
        (0x1C84, ""M"", ""т""),
        (0x1C86, ""M"", ""ъ""),
        (0x1C87, ""M"", ""ѣ""),
        (0x1C88, ""M"", ""ꙋ""),
        (0x1C89, ""X""),
        (0x1C90, ""M"", ""ა""),
        (0x1C91, ""M"", ""ბ""),
        (0x1C92, ""M"", ""გ""),
        (0x1C93, ""M"", ""დ""),
        (0x1C94, ""M"", ""ე""),
        (0x1C95, ""M"", ""ვ""),
        (0x1C96, ""M"", ""ზ""),
        (0x1C97, ""M"", ""თ""),
        (0x1C98, ""M"", ""ი""),
        (0x1C99, ""M"", ""კ""),
        (0x1C9A, ""M"", ""ლ""),
        (0x1C9B, ""M"", ""მ""),
        (0x1C9C, ""M"", ""ნ""),
        (0x1C9D, ""M"", ""ო""),
        (0x1C9E, ""M"", ""პ""),
        (0x1C9F, ""M"", ""ჟ""),
        (0x1CA0, ""M"", ""რ""),
        (0x1CA1, ""M"", ""ს""),
        (0x1CA2, ""M"", ""ტ""),
        (0x1CA3, ""M"", ""უ""),
        (0x1CA4, ""M"", ""ფ""),
        (0x1CA5, ""M"", ""ქ""),
        (0x1CA6, ""M"", ""ღ""),
        (0x1CA7, ""M"", ""ყ""),
        (0x1CA8, ""M"", ""შ""),
        (0x1CA9, ""M"", ""ჩ""),
        (0x1CAA, ""M"", ""ც""),
        (0x1CAB, ""M"", ""ძ""),
        (0x1CAC, ""M"", ""წ""),
        (0x1CAD, ""M"", ""ჭ""),
        (0x1CAE, ""M"", ""ხ""),
        (0x1CAF, ""M"", ""ჯ""),
        (0x1CB0, ""M"", ""ჰ""),
        (0x1CB1, ""M"", ""ჱ""),
        (0x1CB2, ""M"", ""ჲ""),
        (0x1CB3, ""M"", ""ჳ""),
        (0x1CB4, ""M"", ""ჴ""),
        (0x1CB5, ""M"", ""ჵ""),
        (0x1CB6, ""M"", ""ჶ""),
        (0x1CB7, ""M"", ""ჷ""),
        (0x1CB8, ""M"", ""ჸ""),
        (0x1CB9, ""M"", ""ჹ""),
        (0x1CBA, ""M"", ""ჺ""),
        (0x1CBB, ""X""),
        (0x1CBD, ""M"", ""ჽ""),
        (0x1CBE, ""M"", ""ჾ""),
        (0x1CBF, ""M"", ""ჿ""),
        (0x1CC0, ""V""),
        (0x1CC8, ""X""),
        (0x1CD0, ""V""),
        (0x1CFB, ""X""),
        (0x1D00, ""V""),
        (0x1D2C, ""M"", ""a""),
        (0x1D2D, ""M"", ""æ""),
        (0x1D2E, ""M"", ""b""),
        (0x1D2F, ""V""),
        (0x1D30, ""M"", ""d""),
        (0x1D31, ""M"", ""e""),
        (0x1D32, ""M"", ""ǝ""),
        (0x1D33, ""M"", ""g""),
        (0x1D34, ""M"", ""h""),
        (0x1D35, ""M"", ""i""),
        (0x1D36, ""M"", ""j""),
        (0x1D37, ""M"", ""k""),
        (0x1D38, ""M"", ""l""),
        (0x1D39, ""M"", ""m""),
        (0x1D3A, ""M"", ""n""),
        (0x1D3B, ""V""),
        (0x1D3C, ""M"", ""o""),
        (0x1D3D, ""M"", ""ȣ""),
        (0x1D3E, ""M"", ""p""),
        (0x1D3F, ""M"", ""r""),
        (0x1D40, ""M"", ""t""),
        (0x1D41, ""M"", ""u""),
        (0x1D42, ""M"", ""w""),
        (0x1D43, ""M"", ""a""),
        (0x1D44, ""M"", ""ɐ""),
        (0x1D45, ""M"", ""ɑ""),
        (0x1D46, ""M"", ""ᴂ""),
        (0x1D47, ""M"", ""b""),
        (0x1D48, ""M"", ""d""),
        (0x1D49, ""M"", ""e""),
        (0x1D4A, ""M"", ""ə""),
        (0x1D4B, ""M"", ""ɛ""),
        (0x1D4C, ""M"", ""ɜ""),
        (0x1D4D, ""M"", ""g""),
        (0x1D4E, ""V""),
        (0x1D4F, ""M"", ""k""),
        (0x1D50, ""M"", ""m""),
        (0x1D51, ""M"", ""ŋ""),
        (0x1D52, ""M"", ""o""),
        (0x1D53, ""M"", ""ɔ""),
    ]


def _seg_16() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x1D54, ""M"", ""ᴖ""),
        (0x1D55, ""M"", ""ᴗ""),
        (0x1D56, ""M"", ""p""),
        (0x1D57, ""M"", ""t""),
        (0x1D58, ""M"", ""u""),
        (0x1D59, ""M"", ""ᴝ""),
        (0x1D5A, ""M"", ""ɯ""),
        (0x1D5B, ""M"", ""v""),
        (0x1D5C, ""M"", ""ᴥ""),
        (0x1D5D, ""M"", ""β""),
        (0x1D5E, ""M"", ""γ""),
        (0x1D5F, ""M"", ""δ""),
        (0x1D60, ""M"", ""φ""),
        (0x1D61, ""M"", ""χ""),
        (0x1D62, ""M"", ""i""),
        (0x1D63, ""M"", ""r""),
        (0x1D64, ""M"", ""u""),
        (0x1D65, ""M"", ""v""),
        (0x1D66, ""M"", ""β""),
        (0x1D67, ""M"", ""γ""),
        (0x1D68, ""M"", ""ρ""),
        (0x1D69, ""M"", ""φ""),
        (0x1D6A, ""M"", ""χ""),
        (0x1D6B, ""V""),
        (0x1D78, ""M"", ""н""),
        (0x1D79, ""V""),
        (0x1D9B, ""M"", ""ɒ""),
        (0x1D9C, ""M"", ""c""),
        (0x1D9D, ""M"", ""ɕ""),
        (0x1D9E, ""M"", ""ð""),
        (0x1D9F, ""M"", ""ɜ""),
        (0x1DA0, ""M"", ""f""),
        (0x1DA1, ""M"", ""ɟ""),
        (0x1DA2, ""M"", ""ɡ""),
        (0x1DA3, ""M"", ""ɥ""),
        (0x1DA4, ""M"", ""ɨ""),
        (0x1DA5, ""M"", ""ɩ""),
        (0x1DA6, ""M"", ""ɪ""),
        (0x1DA7, ""M"", ""ᵻ""),
        (0x1DA8, ""M"", ""ʝ""),
        (0x1DA9, ""M"", ""ɭ""),
        (0x1DAA, ""M"", ""ᶅ""),
        (0x1DAB, ""M"", ""ʟ""),
        (0x1DAC, ""M"", ""ɱ""),
        (0x1DAD, ""M"", ""ɰ""),
        (0x1DAE, ""M"", ""ɲ""),
        (0x1DAF, ""M"", ""ɳ""),
        (0x1DB0, ""M"", ""ɴ""),
        (0x1DB1, ""M"", ""ɵ""),
        (0x1DB2, ""M"", ""ɸ""),
        (0x1DB3, ""M"", ""ʂ""),
        (0x1DB4, ""M"", ""ʃ""),
        (0x1DB5, ""M"", ""ƫ""),
        (0x1DB6, ""M"", ""ʉ""),
        (0x1DB7, ""M"", ""ʊ""),
        (0x1DB8, ""M"", ""ᴜ""),
        (0x1DB9, ""M"", ""ʋ""),
        (0x1DBA, ""M"", ""ʌ""),
        (0x1DBB, ""M"", ""z""),
        (0x1DBC, ""M"", ""ʐ""),
        (0x1DBD, ""M"", ""ʑ""),
        (0x1DBE, ""M"", ""ʒ""),
        (0x1DBF, ""M"", ""θ""),
        (0x1DC0, ""V""),
        (0x1E00, ""M"", ""ḁ""),
        (0x1E01, ""V""),
        (0x1E02, ""M"", ""ḃ""),
        (0x1E03, ""V""),
        (0x1E04, ""M"", ""ḅ""),
        (0x1E05, ""V""),
        (0x1E06, ""M"", ""ḇ""),
        (0x1E07, ""V""),
        (0x1E08, ""M"", ""ḉ""),
        (0x1E09, ""V""),
        (0x1E0A, ""M"", ""ḋ""),
        (0x1E0B, ""V""),
        (0x1E0C, ""M"", ""ḍ""),
        (0x1E0D, ""V""),
        (0x1E0E, ""M"", ""ḏ""),
        (0x1E0F, ""V""),
        (0x1E10, ""M"", ""ḑ""),
        (0x1E11, ""V""),
        (0x1E12, ""M"", ""ḓ""),
        (0x1E13, ""V""),
        (0x1E14, ""M"", ""ḕ""),
        (0x1E15, ""V""),
        (0x1E16, ""M"", ""ḗ""),
        (0x1E17, ""V""),
        (0x1E18, ""M"", ""ḙ""),
        (0x1E19, ""V""),
        (0x1E1A, ""M"", ""ḛ""),
        (0x1E1B, ""V""),
        (0x1E1C, ""M"", ""ḝ""),
        (0x1E1D, ""V""),
        (0x1E1E, ""M"", ""ḟ""),
        (0x1E1F, ""V""),
        (0x1E20, ""M"", ""ḡ""),
        (0x1E21, ""V""),
        (0x1E22, ""M"", ""ḣ""),
        (0x1E23, ""V""),
    ]


def _seg_17() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x1E24, ""M"", ""ḥ""),
        (0x1E25, ""V""),
        (0x1E26, ""M"", ""ḧ""),
        (0x1E27, ""V""),
        (0x1E28, ""M"", ""ḩ""),
        (0x1E29, ""V""),
        (0x1E2A, ""M"", ""ḫ""),
        (0x1E2B, ""V""),
        (0x1E2C, ""M"", ""ḭ""),
        (0x1E2D, ""V""),
        (0x1E2E, ""M"", ""ḯ""),
        (0x1E2F, ""V""),
        (0x1E30, ""M"", ""ḱ""),
        (0x1E31, ""V""),
        (0x1E32, ""M"", ""ḳ""),
        (0x1E33, ""V""),
        (0x1E34, ""M"", ""ḵ""),
        (0x1E35, ""V""),
        (0x1E36, ""M"", ""ḷ""),
        (0x1E37, ""V""),
        (0x1E38, ""M"", ""ḹ""),
        (0x1E39, ""V""),
        (0x1E3A, ""M"", ""ḻ""),
        (0x1E3B, ""V""),
        (0x1E3C, ""M"", ""ḽ""),
        (0x1E3D, ""V""),
        (0x1E3E, ""M"", ""ḿ""),
        (0x1E3F, ""V""),
        (0x1E40, ""M"", ""ṁ""),
        (0x1E41, ""V""),
        (0x1E42, ""M"", ""ṃ""),
        (0x1E43, ""V""),
        (0x1E44, ""M"", ""ṅ""),
        (0x1E45, ""V""),
        (0x1E46, ""M"", ""ṇ""),
        (0x1E47, ""V""),
        (0x1E48, ""M"", ""ṉ""),
        (0x1E49, ""V""),
        (0x1E4A, ""M"", ""ṋ""),
        (0x1E4B, ""V""),
        (0x1E4C, ""M"", ""ṍ""),
        (0x1E4D, ""V""),
        (0x1E4E, ""M"", ""ṏ""),
        (0x1E4F, ""V""),
        (0x1E50, ""M"", ""ṑ""),
        (0x1E51, ""V""),
        (0x1E52, ""M"", ""ṓ""),
        (0x1E53, ""V""),
        (0x1E54, ""M"", ""ṕ""),
        (0x1E55, ""V""),
        (0x1E56, ""M"", ""ṗ""),
        (0x1E57, ""V""),
        (0x1E58, ""M"", ""ṙ""),
        (0x1E59, ""V""),
        (0x1E5A, ""M"", ""ṛ""),
        (0x1E5B, ""V""),
        (0x1E5C, ""M"", ""ṝ""),
        (0x1E5D, ""V""),
        (0x1E5E, ""M"", ""ṟ""),
        (0x1E5F, ""V""),
        (0x1E60, ""M"", ""ṡ""),
        (0x1E61, ""V""),
        (0x1E62, ""M"", ""ṣ""),
        (0x1E63, ""V""),
        (0x1E64, ""M"", ""ṥ""),
        (0x1E65, ""V""),
        (0x1E66, ""M"", ""ṧ""),
        (0x1E67, ""V""),
        (0x1E68, ""M"", ""ṩ""),
        (0x1E69, ""V""),
        (0x1E6A, ""M"", ""ṫ""),
        (0x1E6B, ""V""),
        (0x1E6C, ""M"", ""ṭ""),
        (0x1E6D, ""V""),
        (0x1E6E, ""M"", ""ṯ""),
        (0x1E6F, ""V""),
        (0x1E70, ""M"", ""ṱ""),
        (0x1E71, ""V""),
        (0x1E72, ""M"", ""ṳ""),
        (0x1E73, ""V""),
        (0x1E74, ""M"", ""ṵ""),
        (0x1E75, ""V""),
        (0x1E76, ""M"", ""ṷ""),
        (0x1E77, ""V""),
        (0x1E78, ""M"", ""ṹ""),
        (0x1E79, ""V""),
        (0x1E7A, ""M"", ""ṻ""),
        (0x1E7B, ""V""),
        (0x1E7C, ""M"", ""ṽ""),
        (0x1E7D, ""V""),
        (0x1E7E, ""M"", ""ṿ""),
        (0x1E7F, ""V""),
        (0x1E80, ""M"", ""ẁ""),
        (0x1E81, ""V""),
        (0x1E82, ""M"", ""ẃ""),
        (0x1E83, ""V""),
        (0x1E84, ""M"", ""ẅ""),
        (0x1E85, ""V""),
        (0x1E86, ""M"", ""ẇ""),
        (0x1E87, ""V""),
    ]


def _seg_18() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x1E88, ""M"", ""ẉ""),
        (0x1E89, ""V""),
        (0x1E8A, ""M"", ""ẋ""),
        (0x1E8B, ""V""),
        (0x1E8C, ""M"", ""ẍ""),
        (0x1E8D, ""V""),
        (0x1E8E, ""M"", ""ẏ""),
        (0x1E8F, ""V""),
        (0x1E90, ""M"", ""ẑ""),
        (0x1E91, ""V""),
        (0x1E92, ""M"", ""ẓ""),
        (0x1E93, ""V""),
        (0x1E94, ""M"", ""ẕ""),
        (0x1E95, ""V""),
        (0x1E9A, ""M"", ""aʾ""),
        (0x1E9B, ""M"", ""ṡ""),
        (0x1E9C, ""V""),
        (0x1E9E, ""M"", ""ß""),
        (0x1E9F, ""V""),
        (0x1EA0, ""M"", ""ạ""),
        (0x1EA1, ""V""),
        (0x1EA2, ""M"", ""ả""),
        (0x1EA3, ""V""),
        (0x1EA4, ""M"", ""ấ""),
        (0x1EA5, ""V""),
        (0x1EA6, ""M"", ""ầ""),
        (0x1EA7, ""V""),
        (0x1EA8, ""M"", ""ẩ""),
        (0x1EA9, ""V""),
        (0x1EAA, ""M"", ""ẫ""),
        (0x1EAB, ""V""),
        (0x1EAC, ""M"", ""ậ""),
        (0x1EAD, ""V""),
        (0x1EAE, ""M"", ""ắ""),
        (0x1EAF, ""V""),
        (0x1EB0, ""M"", ""ằ""),
        (0x1EB1, ""V""),
        (0x1EB2, ""M"", ""ẳ""),
        (0x1EB3, ""V""),
        (0x1EB4, ""M"", ""ẵ""),
        (0x1EB5, ""V""),
        (0x1EB6, ""M"", ""ặ""),
        (0x1EB7, ""V""),
        (0x1EB8, ""M"", ""ẹ""),
        (0x1EB9, ""V""),
        (0x1EBA, ""M"", ""ẻ""),
        (0x1EBB, ""V""),
        (0x1EBC, ""M"", ""ẽ""),
        (0x1EBD, ""V""),
        (0x1EBE, ""M"", ""ế""),
        (0x1EBF, ""V""),
        (0x1EC0, ""M"", ""ề""),
        (0x1EC1, ""V""),
        (0x1EC2, ""M"", ""ể""),
        (0x1EC3, ""V""),
        (0x1EC4, ""M"", ""ễ""),
        (0x1EC5, ""V""),
        (0x1EC6, ""M"", ""ệ""),
        (0x1EC7, ""V""),
        (0x1EC8, ""M"", ""ỉ""),
        (0x1EC9, ""V""),
        (0x1ECA, ""M"", ""ị""),
        (0x1ECB, ""V""),
        (0x1ECC, ""M"", ""ọ""),
        (0x1ECD, ""V""),
        (0x1ECE, ""M"", ""ỏ""),
        (0x1ECF, ""V""),
        (0x1ED0, ""M"", ""ố""),
        (0x1ED1, ""V""),
        (0x1ED2, ""M"", ""ồ""),
        (0x1ED3, ""V""),
        (0x1ED4, ""M"", ""ổ""),
        (0x1ED5, ""V""),
        (0x1ED6, ""M"", ""ỗ""),
        (0x1ED7, ""V""),
        (0x1ED8, ""M"", ""ộ""),
        (0x1ED9, ""V""),
        (0x1EDA, ""M"", ""ớ""),
        (0x1EDB, ""V""),
        (0x1EDC, ""M"", ""ờ""),
        (0x1EDD, ""V""),
        (0x1EDE, ""M"", ""ở""),
        (0x1EDF, ""V""),
        (0x1EE0, ""M"", ""ỡ""),
        (0x1EE1, ""V""),
        (0x1EE2, ""M"", ""ợ""),
        (0x1EE3, ""V""),
        (0x1EE4, ""M"", ""ụ""),
        (0x1EE5, ""V""),
        (0x1EE6, ""M"", ""ủ""),
        (0x1EE7, ""V""),
        (0x1EE8, ""M"", ""ứ""),
        (0x1EE9, ""V""),
        (0x1EEA, ""M"", ""ừ""),
        (0x1EEB, ""V""),
        (0x1EEC, ""M"", ""ử""),
        (0x1EED, ""V""),
        (0x1EEE, ""M"", ""ữ""),
        (0x1EEF, ""V""),
        (0x1EF0, ""M"", ""ự""),
    ]


def _seg_19() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x1EF1, ""V""),
        (0x1EF2, ""M"", ""ỳ""),
        (0x1EF3, ""V""),
        (0x1EF4, ""M"", ""ỵ""),
        (0x1EF5, ""V""),
        (0x1EF6, ""M"", ""ỷ""),
        (0x1EF7, ""V""),
        (0x1EF8, ""M"", ""ỹ""),
        (0x1EF9, ""V""),
        (0x1EFA, ""M"", ""ỻ""),
        (0x1EFB, ""V""),
        (0x1EFC, ""M"", ""ỽ""),
        (0x1EFD, ""V""),
        (0x1EFE, ""M"", ""ỿ""),
        (0x1EFF, ""V""),
        (0x1F08, ""M"", ""ἀ""),
        (0x1F09, ""M"", ""ἁ""),
        (0x1F0A, ""M"", ""ἂ""),
        (0x1F0B, ""M"", ""ἃ""),
        (0x1F0C, ""M"", ""ἄ""),
        (0x1F0D, ""M"", ""ἅ""),
        (0x1F0E, ""M"", ""ἆ""),
        (0x1F0F, ""M"", ""ἇ""),
        (0x1F10, ""V""),
        (0x1F16, ""X""),
        (0x1F18, ""M"", ""ἐ""),
        (0x1F19, ""M"", ""ἑ""),
        (0x1F1A, ""M"", ""ἒ""),
        (0x1F1B, ""M"", ""ἓ""),
        (0x1F1C, ""M"", ""ἔ""),
        (0x1F1D, ""M"", ""ἕ""),
        (0x1F1E, ""X""),
        (0x1F20, ""V""),
        (0x1F28, ""M"", ""ἠ""),
        (0x1F29, ""M"", ""ἡ""),
        (0x1F2A, ""M"", ""ἢ""),
        (0x1F2B, ""M"", ""ἣ""),
        (0x1F2C, ""M"", ""ἤ""),
        (0x1F2D, ""M"", ""ἥ""),
        (0x1F2E, ""M"", ""ἦ""),
        (0x1F2F, ""M"", ""ἧ""),
        (0x1F30, ""V""),
        (0x1F38, ""M"", ""ἰ""),
        (0x1F39, ""M"", ""ἱ""),
        (0x1F3A, ""M"", ""ἲ""),
        (0x1F3B, ""M"", ""ἳ""),
        (0x1F3C, ""M"", ""ἴ""),
        (0x1F3D, ""M"", ""ἵ""),
        (0x1F3E, ""M"", ""ἶ""),
        (0x1F3F, ""M"", ""ἷ""),
        (0x1F40, ""V""),
        (0x1F46, ""X""),
        (0x1F48, ""M"", ""ὀ""),
        (0x1F49, ""M"", ""ὁ""),
        (0x1F4A, ""M"", ""ὂ""),
        (0x1F4B, ""M"", ""ὃ""),
        (0x1F4C, ""M"", ""ὄ""),
        (0x1F4D, ""M"", ""ὅ""),
        (0x1F4E, ""X""),
        (0x1F50, ""V""),
        (0x1F58, ""X""),
        (0x1F59, ""M"", ""ὑ""),
        (0x1F5A, ""X""),
        (0x1F5B, ""M"", ""ὓ""),
        (0x1F5C, ""X""),
        (0x1F5D, ""M"", ""ὕ""),
        (0x1F5E, ""X""),
        (0x1F5F, ""M"", ""ὗ""),
        (0x1F60, ""V""),
        (0x1F68, ""M"", ""ὠ""),
        (0x1F69, ""M"", ""ὡ""),
        (0x1F6A, ""M"", ""ὢ""),
        (0x1F6B, ""M"", ""ὣ""),
        (0x1F6C, ""M"", ""ὤ""),
        (0x1F6D, ""M"", ""ὥ""),
        (0x1F6E, ""M"", ""ὦ""),
        (0x1F6F, ""M"", ""ὧ""),
        (0x1F70, ""V""),
        (0x1F71, ""M"", ""ά""),
        (0x1F72, ""V""),
        (0x1F73, ""M"", ""έ""),
        (0x1F74, ""V""),
        (0x1F75, ""M"", ""ή""),
        (0x1F76, ""V""),
        (0x1F77, ""M"", ""ί""),
        (0x1F78, ""V""),
        (0x1F79, ""M"", ""ό""),
        (0x1F7A, ""V""),
        (0x1F7B, ""M"", ""ύ""),
        (0x1F7C, ""V""),
        (0x1F7D, ""M"", ""ώ""),
        (0x1F7E, ""X""),
        (0x1F80, ""M"", ""ἀι""),
        (0x1F81, ""M"", ""ἁι""),
        (0x1F82, ""M"", ""ἂι""),
        (0x1F83, ""M"", ""ἃι""),
        (0x1F84, ""M"", ""ἄι""),
        (0x1F85, ""M"", ""ἅι""),
        (0x1F86, ""M"", ""ἆι""),
        (0x1F87, ""M"", ""ἇι""),
    ]


def _seg_20() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x1F88, ""M"", ""ἀι""),
        (0x1F89, ""M"", ""ἁι""),
        (0x1F8A, ""M"", ""ἂι""),
        (0x1F8B, ""M"", ""ἃι""),
        (0x1F8C, ""M"", ""ἄι""),
        (0x1F8D, ""M"", ""ἅι""),
        (0x1F8E, ""M"", ""ἆι""),
        (0x1F8F, ""M"", ""ἇι""),
        (0x1F90, ""M"", ""ἠι""),
        (0x1F91, ""M"", ""ἡι""),
        (0x1F92, ""M"", ""ἢι""),
        (0x1F93, ""M"", ""ἣι""),
        (0x1F94, ""M"", ""ἤι""),
        (0x1F95, ""M"", ""ἥι""),
        (0x1F96, ""M"", ""ἦι""),
        (0x1F97, ""M"", ""ἧι""),
        (0x1F98, ""M"", ""ἠι""),
        (0x1F99, ""M"", ""ἡι""),
        (0x1F9A, ""M"", ""ἢι""),
        (0x1F9B, ""M"", ""ἣι""),
        (0x1F9C, ""M"", ""ἤι""),
        (0x1F9D, ""M"", ""ἥι""),
        (0x1F9E, ""M"", ""ἦι""),
        (0x1F9F, ""M"", ""ἧι""),
        (0x1FA0, ""M"", ""ὠι""),
        (0x1FA1, ""M"", ""ὡι""),
        (0x1FA2, ""M"", ""ὢι""),
        (0x1FA3, ""M"", ""ὣι""),
        (0x1FA4, ""M"", ""ὤι""),
        (0x1FA5, ""M"", ""ὥι""),
        (0x1FA6, ""M"", ""ὦι""),
        (0x1FA7, ""M"", ""ὧι""),
        (0x1FA8, ""M"", ""ὠι""),
        (0x1FA9, ""M"", ""ὡι""),
        (0x1FAA, ""M"", ""ὢι""),
        (0x1FAB, ""M"", ""ὣι""),
        (0x1FAC, ""M"", ""ὤι""),
        (0x1FAD, ""M"", ""ὥι""),
        (0x1FAE, ""M"", ""ὦι""),
        (0x1FAF, ""M"", ""ὧι""),
        (0x1FB0, ""V""),
        (0x1FB2, ""M"", ""ὰι""),
        (0x1FB3, ""M"", ""αι""),
        (0x1FB4, ""M"", ""άι""),
        (0x1FB5, ""X""),
        (0x1FB6, ""V""),
        (0x1FB7, ""M"", ""ᾶι""),
        (0x1FB8, ""M"", ""ᾰ""),
        (0x1FB9, ""M"", ""ᾱ""),
        (0x1FBA, ""M"", ""ὰ""),
        (0x1FBB, ""M"", ""ά""),
        (0x1FBC, ""M"", ""αι""),
        (0x1FBD, ""3"", "" ̓""),
        (0x1FBE, ""M"", ""ι""),
        (0x1FBF, ""3"", "" ̓""),
        (0x1FC0, ""3"", "" ͂""),
        (0x1FC1, ""3"", "" ̈͂""),
        (0x1FC2, ""M"", ""ὴι""),
        (0x1FC3, ""M"", ""ηι""),
        (0x1FC4, ""M"", ""ήι""),
        (0x1FC5, ""X""),
        (0x1FC6, ""V""),
        (0x1FC7, ""M"", ""ῆι""),
        (0x1FC8, ""M"", ""ὲ""),
        (0x1FC9, ""M"", ""έ""),
        (0x1FCA, ""M"", ""ὴ""),
        (0x1FCB, ""M"", ""ή""),
        (0x1FCC, ""M"", ""ηι""),
        (0x1FCD, ""3"", "" ̓̀""),
        (0x1FCE, ""3"", "" ̓́""),
        (0x1FCF, ""3"", "" ̓͂""),
        (0x1FD0, ""V""),
        (0x1FD3, ""M"", ""ΐ""),
        (0x1FD4, ""X""),
        (0x1FD6, ""V""),
        (0x1FD8, ""M"", ""ῐ""),
        (0x1FD9, ""M"", ""ῑ""),
        (0x1FDA, ""M"", ""ὶ""),
        (0x1FDB, ""M"", ""ί""),
        (0x1FDC, ""X""),
        (0x1FDD, ""3"", "" ̔̀""),
        (0x1FDE, ""3"", "" ̔́""),
        (0x1FDF, ""3"", "" ̔͂""),
        (0x1FE0, ""V""),
        (0x1FE3, ""M"", ""ΰ""),
        (0x1FE4, ""V""),
        (0x1FE8, ""M"", ""ῠ""),
        (0x1FE9, ""M"", ""ῡ""),
        (0x1FEA, ""M"", ""ὺ""),
        (0x1FEB, ""M"", ""ύ""),
        (0x1FEC, ""M"", ""ῥ""),
        (0x1FED, ""3"", "" ̈̀""),
        (0x1FEE, ""3"", "" ̈́""),
        (0x1FEF, ""3"", ""`""),
        (0x1FF0, ""X""),
        (0x1FF2, ""M"", ""ὼι""),
        (0x1FF3, ""M"", ""ωι""),
        (0x1FF4, ""M"", ""ώι""),
        (0x1FF5, ""X""),
        (0x1FF6, ""V""),
    ]


def _seg_21() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x1FF7, ""M"", ""ῶι""),
        (0x1FF8, ""M"", ""ὸ""),
        (0x1FF9, ""M"", ""ό""),
        (0x1FFA, ""M"", ""ὼ""),
        (0x1FFB, ""M"", ""ώ""),
        (0x1FFC, ""M"", ""ωι""),
        (0x1FFD, ""3"", "" ́""),
        (0x1FFE, ""3"", "" ̔""),
        (0x1FFF, ""X""),
        (0x2000, ""3"", "" ""),
        (0x200B, ""I""),
        (0x200C, ""D"", """"),
        (0x200E, ""X""),
        (0x2010, ""V""),
        (0x2011, ""M"", ""‐""),
        (0x2012, ""V""),
        (0x2017, ""3"", "" ̳""),
        (0x2018, ""V""),
        (0x2024, ""X""),
        (0x2027, ""V""),
        (0x2028, ""X""),
        (0x202F, ""3"", "" ""),
        (0x2030, ""V""),
        (0x2033, ""M"", ""′′""),
        (0x2034, ""M"", ""′′′""),
        (0x2035, ""V""),
        (0x2036, ""M"", ""‵‵""),
        (0x2037, ""M"", ""‵‵‵""),
        (0x2038, ""V""),
        (0x203C, ""3"", ""!!""),
        (0x203D, ""V""),
        (0x203E, ""3"", "" ̅""),
        (0x203F, ""V""),
        (0x2047, ""3"", ""??""),
        (0x2048, ""3"", ""?!""),
        (0x2049, ""3"", ""!?""),
        (0x204A, ""V""),
        (0x2057, ""M"", ""′′′′""),
        (0x2058, ""V""),
        (0x205F, ""3"", "" ""),
        (0x2060, ""I""),
        (0x2061, ""X""),
        (0x2064, ""I""),
        (0x2065, ""X""),
        (0x2070, ""M"", ""0""),
        (0x2071, ""M"", ""i""),
        (0x2072, ""X""),
        (0x2074, ""M"", ""4""),
        (0x2075, ""M"", ""5""),
        (0x2076, ""M"", ""6""),
        (0x2077, ""M"", ""7""),
        (0x2078, ""M"", ""8""),
        (0x2079, ""M"", ""9""),
        (0x207A, ""3"", ""+""),
        (0x207B, ""M"", ""−""),
        (0x207C, ""3"", ""=""),
        (0x207D, ""3"", ""(""),
        (0x207E, ""3"", "")""),
        (0x207F, ""M"", ""n""),
        (0x2080, ""M"", ""0""),
        (0x2081, ""M"", ""1""),
        (0x2082, ""M"", ""2""),
        (0x2083, ""M"", ""3""),
        (0x2084, ""M"", ""4""),
        (0x2085, ""M"", ""5""),
        (0x2086, ""M"", ""6""),
        (0x2087, ""M"", ""7""),
        (0x2088, ""M"", ""8""),
        (0x2089, ""M"", ""9""),
        (0x208A, ""3"", ""+""),
        (0x208B, ""M"", ""−""),
        (0x208C, ""3"", ""=""),
        (0x208D, ""3"", ""(""),
        (0x208E, ""3"", "")""),
        (0x208F, ""X""),
        (0x2090, ""M"", ""a""),
        (0x2091, ""M"", ""e""),
        (0x2092, ""M"", ""o""),
        (0x2093, ""M"", ""x""),
        (0x2094, ""M"", ""ə""),
        (0x2095, ""M"", ""h""),
        (0x2096, ""M"", ""k""),
        (0x2097, ""M"", ""l""),
        (0x2098, ""M"", ""m""),
        (0x2099, ""M"", ""n""),
        (0x209A, ""M"", ""p""),
        (0x209B, ""M"", ""s""),
        (0x209C, ""M"", ""t""),
        (0x209D, ""X""),
        (0x20A0, ""V""),
        (0x20A8, ""M"", ""rs""),
        (0x20A9, ""V""),
        (0x20C1, ""X""),
        (0x20D0, ""V""),
        (0x20F1, ""X""),
        (0x2100, ""3"", ""a/c""),
        (0x2101, ""3"", ""a/s""),
        (0x2102, ""M"", ""c""),
        (0x2103, ""M"", ""°c""),
        (0x2104, ""V""),
    ]


def _seg_22() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x2105, ""3"", ""c/o""),
        (0x2106, ""3"", ""c/u""),
        (0x2107, ""M"", ""ɛ""),
        (0x2108, ""V""),
        (0x2109, ""M"", ""°f""),
        (0x210A, ""M"", ""g""),
        (0x210B, ""M"", ""h""),
        (0x210F, ""M"", ""ħ""),
        (0x2110, ""M"", ""i""),
        (0x2112, ""M"", ""l""),
        (0x2114, ""V""),
        (0x2115, ""M"", ""n""),
        (0x2116, ""M"", ""no""),
        (0x2117, ""V""),
        (0x2119, ""M"", ""p""),
        (0x211A, ""M"", ""q""),
        (0x211B, ""M"", ""r""),
        (0x211E, ""V""),
        (0x2120, ""M"", ""sm""),
        (0x2121, ""M"", ""tel""),
        (0x2122, ""M"", ""tm""),
        (0x2123, ""V""),
        (0x2124, ""M"", ""z""),
        (0x2125, ""V""),
        (0x2126, ""M"", ""ω""),
        (0x2127, ""V""),
        (0x2128, ""M"", ""z""),
        (0x2129, ""V""),
        (0x212A, ""M"", ""k""),
        (0x212B, ""M"", ""å""),
        (0x212C, ""M"", ""b""),
        (0x212D, ""M"", ""c""),
        (0x212E, ""V""),
        (0x212F, ""M"", ""e""),
        (0x2131, ""M"", ""f""),
        (0x2132, ""X""),
        (0x2133, ""M"", ""m""),
        (0x2134, ""M"", ""o""),
        (0x2135, ""M"", ""א""),
        (0x2136, ""M"", ""ב""),
        (0x2137, ""M"", ""ג""),
        (0x2138, ""M"", ""ד""),
        (0x2139, ""M"", ""i""),
        (0x213A, ""V""),
        (0x213B, ""M"", ""fax""),
        (0x213C, ""M"", ""π""),
        (0x213D, ""M"", ""γ""),
        (0x213F, ""M"", ""π""),
        (0x2140, ""M"", ""∑""),
        (0x2141, ""V""),
        (0x2145, ""M"", ""d""),
        (0x2147, ""M"", ""e""),
        (0x2148, ""M"", ""i""),
        (0x2149, ""M"", ""j""),
        (0x214A, ""V""),
        (0x2150, ""M"", ""1⁄7""),
        (0x2151, ""M"", ""1⁄9""),
        (0x2152, ""M"", ""1⁄10""),
        (0x2153, ""M"", ""1⁄3""),
        (0x2154, ""M"", ""2⁄3""),
        (0x2155, ""M"", ""1⁄5""),
        (0x2156, ""M"", ""2⁄5""),
        (0x2157, ""M"", ""3⁄5""),
        (0x2158, ""M"", ""4⁄5""),
        (0x2159, ""M"", ""1⁄6""),
        (0x215A, ""M"", ""5⁄6""),
        (0x215B, ""M"", ""1⁄8""),
        (0x215C, ""M"", ""3⁄8""),
        (0x215D, ""M"", ""5⁄8""),
        (0x215E, ""M"", ""7⁄8""),
        (0x215F, ""M"", ""1⁄""),
        (0x2160, ""M"", ""i""),
        (0x2161, ""M"", ""ii""),
        (0x2162, ""M"", ""iii""),
        (0x2163, ""M"", ""iv""),
        (0x2164, ""M"", ""v""),
        (0x2165, ""M"", ""vi""),
        (0x2166, ""M"", ""vii""),
        (0x2167, ""M"", ""viii""),
        (0x2168, ""M"", ""ix""),
        (0x2169, ""M"", ""x""),
        (0x216A, ""M"", ""xi""),
        (0x216B, ""M"", ""xii""),
        (0x216C, ""M"", ""l""),
        (0x216D, ""M"", ""c""),
        (0x216E, ""M"", ""d""),
        (0x216F, ""M"", ""m""),
        (0x2170, ""M"", ""i""),
        (0x2171, ""M"", ""ii""),
        (0x2172, ""M"", ""iii""),
        (0x2173, ""M"", ""iv""),
        (0x2174, ""M"", ""v""),
        (0x2175, ""M"", ""vi""),
        (0x2176, ""M"", ""vii""),
        (0x2177, ""M"", ""viii""),
        (0x2178, ""M"", ""ix""),
        (0x2179, ""M"", ""x""),
        (0x217A, ""M"", ""xi""),
        (0x217B, ""M"", ""xii""),
        (0x217C, ""M"", ""l""),
    ]


def _seg_23() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x217D, ""M"", ""c""),
        (0x217E, ""M"", ""d""),
        (0x217F, ""M"", ""m""),
        (0x2180, ""V""),
        (0x2183, ""X""),
        (0x2184, ""V""),
        (0x2189, ""M"", ""0⁄3""),
        (0x218A, ""V""),
        (0x218C, ""X""),
        (0x2190, ""V""),
        (0x222C, ""M"", ""∫∫""),
        (0x222D, ""M"", ""∫∫∫""),
        (0x222E, ""V""),
        (0x222F, ""M"", ""∮∮""),
        (0x2230, ""M"", ""∮∮∮""),
        (0x2231, ""V""),
        (0x2329, ""M"", ""〈""),
        (0x232A, ""M"", ""〉""),
        (0x232B, ""V""),
        (0x2427, ""X""),
        (0x2440, ""V""),
        (0x244B, ""X""),
        (0x2460, ""M"", ""1""),
        (0x2461, ""M"", ""2""),
        (0x2462, ""M"", ""3""),
        (0x2463, ""M"", ""4""),
        (0x2464, ""M"", ""5""),
        (0x2465, ""M"", ""6""),
        (0x2466, ""M"", ""7""),
        (0x2467, ""M"", ""8""),
        (0x2468, ""M"", ""9""),
        (0x2469, ""M"", ""10""),
        (0x246A, ""M"", ""11""),
        (0x246B, ""M"", ""12""),
        (0x246C, ""M"", ""13""),
        (0x246D, ""M"", ""14""),
        (0x246E, ""M"", ""15""),
        (0x246F, ""M"", ""16""),
        (0x2470, ""M"", ""17""),
        (0x2471, ""M"", ""18""),
        (0x2472, ""M"", ""19""),
        (0x2473, ""M"", ""20""),
        (0x2474, ""3"", ""(1)""),
        (0x2475, ""3"", ""(2)""),
        (0x2476, ""3"", ""(3)""),
        (0x2477, ""3"", ""(4)""),
        (0x2478, ""3"", ""(5)""),
        (0x2479, ""3"", ""(6)""),
        (0x247A, ""3"", ""(7)""),
        (0x247B, ""3"", ""(8)""),
        (0x247C, ""3"", ""(9)""),
        (0x247D, ""3"", ""(10)""),
        (0x247E, ""3"", ""(11)""),
        (0x247F, ""3"", ""(12)""),
        (0x2480, ""3"", ""(13)""),
        (0x2481, ""3"", ""(14)""),
        (0x2482, ""3"", ""(15)""),
        (0x2483, ""3"", ""(16)""),
        (0x2484, ""3"", ""(17)""),
        (0x2485, ""3"", ""(18)""),
        (0x2486, ""3"", ""(19)""),
        (0x2487, ""3"", ""(20)""),
        (0x2488, ""X""),
        (0x249C, ""3"", ""(a)""),
        (0x249D, ""3"", ""(b)""),
        (0x249E, ""3"", ""(c)""),
        (0x249F, ""3"", ""(d)""),
        (0x24A0, ""3"", ""(e)""),
        (0x24A1, ""3"", ""(f)""),
        (0x24A2, ""3"", ""(g)""),
        (0x24A3, ""3"", ""(h)""),
        (0x24A4, ""3"", ""(i)""),
        (0x24A5, ""3"", ""(j)""),
        (0x24A6, ""3"", ""(k)""),
        (0x24A7, ""3"", ""(l)""),
        (0x24A8, ""3"", ""(m)""),
        (0x24A9, ""3"", ""(n)""),
        (0x24AA, ""3"", ""(o)""),
        (0x24AB, ""3"", ""(p)""),
        (0x24AC, ""3"", ""(q)""),
        (0x24AD, ""3"", ""(r)""),
        (0x24AE, ""3"", ""(s)""),
        (0x24AF, ""3"", ""(t)""),
        (0x24B0, ""3"", ""(u)""),
        (0x24B1, ""3"", ""(v)""),
        (0x24B2, ""3"", ""(w)""),
        (0x24B3, ""3"", ""(x)""),
        (0x24B4, ""3"", ""(y)""),
        (0x24B5, ""3"", ""(z)""),
        (0x24B6, ""M"", ""a""),
        (0x24B7, ""M"", ""b""),
        (0x24B8, ""M"", ""c""),
        (0x24B9, ""M"", ""d""),
        (0x24BA, ""M"", ""e""),
        (0x24BB, ""M"", ""f""),
        (0x24BC, ""M"", ""g""),
        (0x24BD, ""M"", ""h""),
        (0x24BE, ""M"", ""i""),
        (0x24BF, ""M"", ""j""),
        (0x24C0, ""M"", ""k""),
    ]


def _seg_24() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x24C1, ""M"", ""l""),
        (0x24C2, ""M"", ""m""),
        (0x24C3, ""M"", ""n""),
        (0x24C4, ""M"", ""o""),
        (0x24C5, ""M"", ""p""),
        (0x24C6, ""M"", ""q""),
        (0x24C7, ""M"", ""r""),
        (0x24C8, ""M"", ""s""),
        (0x24C9, ""M"", ""t""),
        (0x24CA, ""M"", ""u""),
        (0x24CB, ""M"", ""v""),
        (0x24CC, ""M"", ""w""),
        (0x24CD, ""M"", ""x""),
        (0x24CE, ""M"", ""y""),
        (0x24CF, ""M"", ""z""),
        (0x24D0, ""M"", ""a""),
        (0x24D1, ""M"", ""b""),
        (0x24D2, ""M"", ""c""),
        (0x24D3, ""M"", ""d""),
        (0x24D4, ""M"", ""e""),
        (0x24D5, ""M"", ""f""),
        (0x24D6, ""M"", ""g""),
        (0x24D7, ""M"", ""h""),
        (0x24D8, ""M"", ""i""),
        (0x24D9, ""M"", ""j""),
        (0x24DA, ""M"", ""k""),
        (0x24DB, ""M"", ""l""),
        (0x24DC, ""M"", ""m""),
        (0x24DD, ""M"", ""n""),
        (0x24DE, ""M"", ""o""),
        (0x24DF, ""M"", ""p""),
        (0x24E0, ""M"", ""q""),
        (0x24E1, ""M"", ""r""),
        (0x24E2, ""M"", ""s""),
        (0x24E3, ""M"", ""t""),
        (0x24E4, ""M"", ""u""),
        (0x24E5, ""M"", ""v""),
        (0x24E6, ""M"", ""w""),
        (0x24E7, ""M"", ""x""),
        (0x24E8, ""M"", ""y""),
        (0x24E9, ""M"", ""z""),
        (0x24EA, ""M"", ""0""),
        (0x24EB, ""V""),
        (0x2A0C, ""M"", ""∫∫∫∫""),
        (0x2A0D, ""V""),
        (0x2A74, ""3"", ""::=""),
        (0x2A75, ""3"", ""==""),
        (0x2A76, ""3"", ""===""),
        (0x2A77, ""V""),
        (0x2ADC, ""M"", ""⫝̸""),
        (0x2ADD, ""V""),
        (0x2B74, ""X""),
        (0x2B76, ""V""),
        (0x2B96, ""X""),
        (0x2B97, ""V""),
        (0x2C00, ""M"", ""ⰰ""),
        (0x2C01, ""M"", ""ⰱ""),
        (0x2C02, ""M"", ""ⰲ""),
        (0x2C03, ""M"", ""ⰳ""),
        (0x2C04, ""M"", ""ⰴ""),
        (0x2C05, ""M"", ""ⰵ""),
        (0x2C06, ""M"", ""ⰶ""),
        (0x2C07, ""M"", ""ⰷ""),
        (0x2C08, ""M"", ""ⰸ""),
        (0x2C09, ""M"", ""ⰹ""),
        (0x2C0A, ""M"", ""ⰺ""),
        (0x2C0B, ""M"", ""ⰻ""),
        (0x2C0C, ""M"", ""ⰼ""),
        (0x2C0D, ""M"", ""ⰽ""),
        (0x2C0E, ""M"", ""ⰾ""),
        (0x2C0F, ""M"", ""ⰿ""),
        (0x2C10, ""M"", ""ⱀ""),
        (0x2C11, ""M"", ""ⱁ""),
        (0x2C12, ""M"", ""ⱂ""),
        (0x2C13, ""M"", ""ⱃ""),
        (0x2C14, ""M"", ""ⱄ""),
        (0x2C15, ""M"", ""ⱅ""),
        (0x2C16, ""M"", ""ⱆ""),
        (0x2C17, ""M"", ""ⱇ""),
        (0x2C18, ""M"", ""ⱈ""),
        (0x2C19, ""M"", ""ⱉ""),
        (0x2C1A, ""M"", ""ⱊ""),
        (0x2C1B, ""M"", ""ⱋ""),
        (0x2C1C, ""M"", ""ⱌ""),
        (0x2C1D, ""M"", ""ⱍ""),
        (0x2C1E, ""M"", ""ⱎ""),
        (0x2C1F, ""M"", ""ⱏ""),
        (0x2C20, ""M"", ""ⱐ""),
        (0x2C21, ""M"", ""ⱑ""),
        (0x2C22, ""M"", ""ⱒ""),
        (0x2C23, ""M"", ""ⱓ""),
        (0x2C24, ""M"", ""ⱔ""),
        (0x2C25, ""M"", ""ⱕ""),
        (0x2C26, ""M"", ""ⱖ""),
        (0x2C27, ""M"", ""ⱗ""),
        (0x2C28, ""M"", ""ⱘ""),
        (0x2C29, ""M"", ""ⱙ""),
        (0x2C2A, ""M"", ""ⱚ""),
        (0x2C2B, ""M"", ""ⱛ""),
        (0x2C2C, ""M"", ""ⱜ""),
    ]


def _seg_25() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x2C2D, ""M"", ""ⱝ""),
        (0x2C2E, ""M"", ""ⱞ""),
        (0x2C2F, ""M"", ""ⱟ""),
        (0x2C30, ""V""),
        (0x2C60, ""M"", ""ⱡ""),
        (0x2C61, ""V""),
        (0x2C62, ""M"", ""ɫ""),
        (0x2C63, ""M"", ""ᵽ""),
        (0x2C64, ""M"", ""ɽ""),
        (0x2C65, ""V""),
        (0x2C67, ""M"", ""ⱨ""),
        (0x2C68, ""V""),
        (0x2C69, ""M"", ""ⱪ""),
        (0x2C6A, ""V""),
        (0x2C6B, ""M"", ""ⱬ""),
        (0x2C6C, ""V""),
        (0x2C6D, ""M"", ""ɑ""),
        (0x2C6E, ""M"", ""ɱ""),
        (0x2C6F, ""M"", ""ɐ""),
        (0x2C70, ""M"", ""ɒ""),
        (0x2C71, ""V""),
        (0x2C72, ""M"", ""ⱳ""),
        (0x2C73, ""V""),
        (0x2C75, ""M"", ""ⱶ""),
        (0x2C76, ""V""),
        (0x2C7C, ""M"", ""j""),
        (0x2C7D, ""M"", ""v""),
        (0x2C7E, ""M"", ""ȿ""),
        (0x2C7F, ""M"", ""ɀ""),
        (0x2C80, ""M"", ""ⲁ""),
        (0x2C81, ""V""),
        (0x2C82, ""M"", ""ⲃ""),
        (0x2C83, ""V""),
        (0x2C84, ""M"", ""ⲅ""),
        (0x2C85, ""V""),
        (0x2C86, ""M"", ""ⲇ""),
        (0x2C87, ""V""),
        (0x2C88, ""M"", ""ⲉ""),
        (0x2C89, ""V""),
        (0x2C8A, ""M"", ""ⲋ""),
        (0x2C8B, ""V""),
        (0x2C8C, ""M"", ""ⲍ""),
        (0x2C8D, ""V""),
        (0x2C8E, ""M"", ""ⲏ""),
        (0x2C8F, ""V""),
        (0x2C90, ""M"", ""ⲑ""),
        (0x2C91, ""V""),
        (0x2C92, ""M"", ""ⲓ""),
        (0x2C93, ""V""),
        (0x2C94, ""M"", ""ⲕ""),
        (0x2C95, ""V""),
        (0x2C96, ""M"", ""ⲗ""),
        (0x2C97, ""V""),
        (0x2C98, ""M"", ""ⲙ""),
        (0x2C99, ""V""),
        (0x2C9A, ""M"", ""ⲛ""),
        (0x2C9B, ""V""),
        (0x2C9C, ""M"", ""ⲝ""),
        (0x2C9D, ""V""),
        (0x2C9E, ""M"", ""ⲟ""),
        (0x2C9F, ""V""),
        (0x2CA0, ""M"", ""ⲡ""),
        (0x2CA1, ""V""),
        (0x2CA2, ""M"", ""ⲣ""),
        (0x2CA3, ""V""),
        (0x2CA4, ""M"", ""ⲥ""),
        (0x2CA5, ""V""),
        (0x2CA6, ""M"", ""ⲧ""),
        (0x2CA7, ""V""),
        (0x2CA8, ""M"", ""ⲩ""),
        (0x2CA9, ""V""),
        (0x2CAA, ""M"", ""ⲫ""),
        (0x2CAB, ""V""),
        (0x2CAC, ""M"", ""ⲭ""),
        (0x2CAD, ""V""),
        (0x2CAE, ""M"", ""ⲯ""),
        (0x2CAF, ""V""),
        (0x2CB0, ""M"", ""ⲱ""),
        (0x2CB1, ""V""),
        (0x2CB2, ""M"", ""ⲳ""),
        (0x2CB3, ""V""),
        (0x2CB4, ""M"", ""ⲵ""),
        (0x2CB5, ""V""),
        (0x2CB6, ""M"", ""ⲷ""),
        (0x2CB7, ""V""),
        (0x2CB8, ""M"", ""ⲹ""),
        (0x2CB9, ""V""),
        (0x2CBA, ""M"", ""ⲻ""),
        (0x2CBB, ""V""),
        (0x2CBC, ""M"", ""ⲽ""),
        (0x2CBD, ""V""),
        (0x2CBE, ""M"", ""ⲿ""),
        (0x2CBF, ""V""),
        (0x2CC0, ""M"", ""ⳁ""),
        (0x2CC1, ""V""),
        (0x2CC2, ""M"", ""ⳃ""),
        (0x2CC3, ""V""),
        (0x2CC4, ""M"", ""ⳅ""),
        (0x2CC5, ""V""),
        (0x2CC6, ""M"", ""ⳇ""),
    ]


def _seg_26() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x2CC7, ""V""),
        (0x2CC8, ""M"", ""ⳉ""),
        (0x2CC9, ""V""),
        (0x2CCA, ""M"", ""ⳋ""),
        (0x2CCB, ""V""),
        (0x2CCC, ""M"", ""ⳍ""),
        (0x2CCD, ""V""),
        (0x2CCE, ""M"", ""ⳏ""),
        (0x2CCF, ""V""),
        (0x2CD0, ""M"", ""ⳑ""),
        (0x2CD1, ""V""),
        (0x2CD2, ""M"", ""ⳓ""),
        (0x2CD3, ""V""),
        (0x2CD4, ""M"", ""ⳕ""),
        (0x2CD5, ""V""),
        (0x2CD6, ""M"", ""ⳗ""),
        (0x2CD7, ""V""),
        (0x2CD8, ""M"", ""ⳙ""),
        (0x2CD9, ""V""),
        (0x2CDA, ""M"", ""ⳛ""),
        (0x2CDB, ""V""),
        (0x2CDC, ""M"", ""ⳝ""),
        (0x2CDD, ""V""),
        (0x2CDE, ""M"", ""ⳟ""),
        (0x2CDF, ""V""),
        (0x2CE0, ""M"", ""ⳡ""),
        (0x2CE1, ""V""),
        (0x2CE2, ""M"", ""ⳣ""),
        (0x2CE3, ""V""),
        (0x2CEB, ""M"", ""ⳬ""),
        (0x2CEC, ""V""),
        (0x2CED, ""M"", ""ⳮ""),
        (0x2CEE, ""V""),
        (0x2CF2, ""M"", ""ⳳ""),
        (0x2CF3, ""V""),
        (0x2CF4, ""X""),
        (0x2CF9, ""V""),
        (0x2D26, ""X""),
        (0x2D27, ""V""),
        (0x2D28, ""X""),
        (0x2D2D, ""V""),
        (0x2D2E, ""X""),
        (0x2D30, ""V""),
        (0x2D68, ""X""),
        (0x2D6F, ""M"", ""ⵡ""),
        (0x2D70, ""V""),
        (0x2D71, ""X""),
        (0x2D7F, ""V""),
        (0x2D97, ""X""),
        (0x2DA0, ""V""),
        (0x2DA7, ""X""),
        (0x2DA8, ""V""),
        (0x2DAF, ""X""),
        (0x2DB0, ""V""),
        (0x2DB7, ""X""),
        (0x2DB8, ""V""),
        (0x2DBF, ""X""),
        (0x2DC0, ""V""),
        (0x2DC7, ""X""),
        (0x2DC8, ""V""),
        (0x2DCF, ""X""),
        (0x2DD0, ""V""),
        (0x2DD7, ""X""),
        (0x2DD8, ""V""),
        (0x2DDF, ""X""),
        (0x2DE0, ""V""),
        (0x2E5E, ""X""),
        (0x2E80, ""V""),
        (0x2E9A, ""X""),
        (0x2E9B, ""V""),
        (0x2E9F, ""M"", ""母""),
        (0x2EA0, ""V""),
        (0x2EF3, ""M"", ""龟""),
        (0x2EF4, ""X""),
        (0x2F00, ""M"", ""一""),
        (0x2F01, ""M"", ""丨""),
        (0x2F02, ""M"", ""丶""),
        (0x2F03, ""M"", ""丿""),
        (0x2F04, ""M"", ""乙""),
        (0x2F05, ""M"", ""亅""),
        (0x2F06, ""M"", ""二""),
        (0x2F07, ""M"", ""亠""),
        (0x2F08, ""M"", ""人""),
        (0x2F09, ""M"", ""儿""),
        (0x2F0A, ""M"", ""入""),
        (0x2F0B, ""M"", ""八""),
        (0x2F0C, ""M"", ""冂""),
        (0x2F0D, ""M"", ""冖""),
        (0x2F0E, ""M"", ""冫""),
        (0x2F0F, ""M"", ""几""),
        (0x2F10, ""M"", ""凵""),
        (0x2F11, ""M"", ""刀""),
        (0x2F12, ""M"", ""力""),
        (0x2F13, ""M"", ""勹""),
        (0x2F14, ""M"", ""匕""),
        (0x2F15, ""M"", ""匚""),
        (0x2F16, ""M"", ""匸""),
        (0x2F17, ""M"", ""十""),
        (0x2F18, ""M"", ""卜""),
        (0x2F19, ""M"", ""卩""),
    ]


def _seg_27() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x2F1A, ""M"", ""厂""),
        (0x2F1B, ""M"", ""厶""),
        (0x2F1C, ""M"", ""又""),
        (0x2F1D, ""M"", ""口""),
        (0x2F1E, ""M"", ""囗""),
        (0x2F1F, ""M"", ""土""),
        (0x2F20, ""M"", ""士""),
        (0x2F21, ""M"", ""夂""),
        (0x2F22, ""M"", ""夊""),
        (0x2F23, ""M"", ""夕""),
        (0x2F24, ""M"", ""大""),
        (0x2F25, ""M"", ""女""),
        (0x2F26, ""M"", ""子""),
        (0x2F27, ""M"", ""宀""),
        (0x2F28, ""M"", ""寸""),
        (0x2F29, ""M"", ""小""),
        (0x2F2A, ""M"", ""尢""),
        (0x2F2B, ""M"", ""尸""),
        (0x2F2C, ""M"", ""屮""),
        (0x2F2D, ""M"", ""山""),
        (0x2F2E, ""M"", ""巛""),
        (0x2F2F, ""M"", ""工""),
        (0x2F30, ""M"", ""己""),
        (0x2F31, ""M"", ""巾""),
        (0x2F32, ""M"", ""干""),
        (0x2F33, ""M"", ""幺""),
        (0x2F34, ""M"", ""广""),
        (0x2F35, ""M"", ""廴""),
        (0x2F36, ""M"", ""廾""),
        (0x2F37, ""M"", ""弋""),
        (0x2F38, ""M"", ""弓""),
        (0x2F39, ""M"", ""彐""),
        (0x2F3A, ""M"", ""彡""),
        (0x2F3B, ""M"", ""彳""),
        (0x2F3C, ""M"", ""心""),
        (0x2F3D, ""M"", ""戈""),
        (0x2F3E, ""M"", ""戶""),
        (0x2F3F, ""M"", ""手""),
        (0x2F40, ""M"", ""支""),
        (0x2F41, ""M"", ""攴""),
        (0x2F42, ""M"", ""文""),
        (0x2F43, ""M"", ""斗""),
        (0x2F44, ""M"", ""斤""),
        (0x2F45, ""M"", ""方""),
        (0x2F46, ""M"", ""无""),
        (0x2F47, ""M"", ""日""),
        (0x2F48, ""M"", ""曰""),
        (0x2F49, ""M"", ""月""),
        (0x2F4A, ""M"", ""木""),
        (0x2F4B, ""M"", ""欠""),
        (0x2F4C, ""M"", ""止""),
        (0x2F4D, ""M"", ""歹""),
        (0x2F4E, ""M"", ""殳""),
        (0x2F4F, ""M"", ""毋""),
        (0x2F50, ""M"", ""比""),
        (0x2F51, ""M"", ""毛""),
        (0x2F52, ""M"", ""氏""),
        (0x2F53, ""M"", ""气""),
        (0x2F54, ""M"", ""水""),
        (0x2F55, ""M"", ""火""),
        (0x2F56, ""M"", ""爪""),
        (0x2F57, ""M"", ""父""),
        (0x2F58, ""M"", ""爻""),
        (0x2F59, ""M"", ""爿""),
        (0x2F5A, ""M"", ""片""),
        (0x2F5B, ""M"", ""牙""),
        (0x2F5C, ""M"", ""牛""),
        (0x2F5D, ""M"", ""犬""),
        (0x2F5E, ""M"", ""玄""),
        (0x2F5F, ""M"", ""玉""),
        (0x2F60, ""M"", ""瓜""),
        (0x2F61, ""M"", ""瓦""),
        (0x2F62, ""M"", ""甘""),
        (0x2F63, ""M"", ""生""),
        (0x2F64, ""M"", ""用""),
        (0x2F65, ""M"", ""田""),
        (0x2F66, ""M"", ""疋""),
        (0x2F67, ""M"", ""疒""),
        (0x2F68, ""M"", ""癶""),
        (0x2F69, ""M"", ""白""),
        (0x2F6A, ""M"", ""皮""),
        (0x2F6B, ""M"", ""皿""),
        (0x2F6C, ""M"", ""目""),
        (0x2F6D, ""M"", ""矛""),
        (0x2F6E, ""M"", ""矢""),
        (0x2F6F, ""M"", ""石""),
        (0x2F70, ""M"", ""示""),
        (0x2F71, ""M"", ""禸""),
        (0x2F72, ""M"", ""禾""),
        (0x2F73, ""M"", ""穴""),
        (0x2F74, ""M"", ""立""),
        (0x2F75, ""M"", ""竹""),
        (0x2F76, ""M"", ""米""),
        (0x2F77, ""M"", ""糸""),
        (0x2F78, ""M"", ""缶""),
        (0x2F79, ""M"", ""网""),
        (0x2F7A, ""M"", ""羊""),
        (0x2F7B, ""M"", ""羽""),
        (0x2F7C, ""M"", ""老""),
        (0x2F7D, ""M"", ""而""),
    ]


def _seg_28() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x2F7E, ""M"", ""耒""),
        (0x2F7F, ""M"", ""耳""),
        (0x2F80, ""M"", ""聿""),
        (0x2F81, ""M"", ""肉""),
        (0x2F82, ""M"", ""臣""),
        (0x2F83, ""M"", ""自""),
        (0x2F84, ""M"", ""至""),
        (0x2F85, ""M"", ""臼""),
        (0x2F86, ""M"", ""舌""),
        (0x2F87, ""M"", ""舛""),
        (0x2F88, ""M"", ""舟""),
        (0x2F89, ""M"", ""艮""),
        (0x2F8A, ""M"", ""色""),
        (0x2F8B, ""M"", ""艸""),
        (0x2F8C, ""M"", ""虍""),
        (0x2F8D, ""M"", ""虫""),
        (0x2F8E, ""M"", ""血""),
        (0x2F8F, ""M"", ""行""),
        (0x2F90, ""M"", ""衣""),
        (0x2F91, ""M"", ""襾""),
        (0x2F92, ""M"", ""見""),
        (0x2F93, ""M"", ""角""),
        (0x2F94, ""M"", ""言""),
        (0x2F95, ""M"", ""谷""),
        (0x2F96, ""M"", ""豆""),
        (0x2F97, ""M"", ""豕""),
        (0x2F98, ""M"", ""豸""),
        (0x2F99, ""M"", ""貝""),
        (0x2F9A, ""M"", ""赤""),
        (0x2F9B, ""M"", ""走""),
        (0x2F9C, ""M"", ""足""),
        (0x2F9D, ""M"", ""身""),
        (0x2F9E, ""M"", ""車""),
        (0x2F9F, ""M"", ""辛""),
        (0x2FA0, ""M"", ""辰""),
        (0x2FA1, ""M"", ""辵""),
        (0x2FA2, ""M"", ""邑""),
        (0x2FA3, ""M"", ""酉""),
        (0x2FA4, ""M"", ""釆""),
        (0x2FA5, ""M"", ""里""),
        (0x2FA6, ""M"", ""金""),
        (0x2FA7, ""M"", ""長""),
        (0x2FA8, ""M"", ""門""),
        (0x2FA9, ""M"", ""阜""),
        (0x2FAA, ""M"", ""隶""),
        (0x2FAB, ""M"", ""隹""),
        (0x2FAC, ""M"", ""雨""),
        (0x2FAD, ""M"", ""靑""),
        (0x2FAE, ""M"", ""非""),
        (0x2FAF, ""M"", ""面""),
        (0x2FB0, ""M"", ""革""),
        (0x2FB1, ""M"", ""韋""),
        (0x2FB2, ""M"", ""韭""),
        (0x2FB3, ""M"", ""音""),
        (0x2FB4, ""M"", ""頁""),
        (0x2FB5, ""M"", ""風""),
        (0x2FB6, ""M"", ""飛""),
        (0x2FB7, ""M"", ""食""),
        (0x2FB8, ""M"", ""首""),
        (0x2FB9, ""M"", ""香""),
        (0x2FBA, ""M"", ""馬""),
        (0x2FBB, ""M"", ""骨""),
        (0x2FBC, ""M"", ""高""),
        (0x2FBD, ""M"", ""髟""),
        (0x2FBE, ""M"", ""鬥""),
        (0x2FBF, ""M"", ""鬯""),
        (0x2FC0, ""M"", ""鬲""),
        (0x2FC1, ""M"", ""鬼""),
        (0x2FC2, ""M"", ""魚""),
        (0x2FC3, ""M"", ""鳥""),
        (0x2FC4, ""M"", ""鹵""),
        (0x2FC5, ""M"", ""鹿""),
        (0x2FC6, ""M"", ""麥""),
        (0x2FC7, ""M"", ""麻""),
        (0x2FC8, ""M"", ""黃""),
        (0x2FC9, ""M"", ""黍""),
        (0x2FCA, ""M"", ""黑""),
        (0x2FCB, ""M"", ""黹""),
        (0x2FCC, ""M"", ""黽""),
        (0x2FCD, ""M"", ""鼎""),
        (0x2FCE, ""M"", ""鼓""),
        (0x2FCF, ""M"", ""鼠""),
        (0x2FD0, ""M"", ""鼻""),
        (0x2FD1, ""M"", ""齊""),
        (0x2FD2, ""M"", ""齒""),
        (0x2FD3, ""M"", ""龍""),
        (0x2FD4, ""M"", ""龜""),
        (0x2FD5, ""M"", ""龠""),
        (0x2FD6, ""X""),
        (0x3000, ""3"", "" ""),
        (0x3001, ""V""),
        (0x3002, ""M"", "".""),
        (0x3003, ""V""),
        (0x3036, ""M"", ""〒""),
        (0x3037, ""V""),
        (0x3038, ""M"", ""十""),
        (0x3039, ""M"", ""卄""),
        (0x303A, ""M"", ""卅""),
        (0x303B, ""V""),
        (0x3040, ""X""),
    ]


def _seg_29() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x3041, ""V""),
        (0x3097, ""X""),
        (0x3099, ""V""),
        (0x309B, ""3"", "" ゙""),
        (0x309C, ""3"", "" ゚""),
        (0x309D, ""V""),
        (0x309F, ""M"", ""より""),
        (0x30A0, ""V""),
        (0x30FF, ""M"", ""コト""),
        (0x3100, ""X""),
        (0x3105, ""V""),
        (0x3130, ""X""),
        (0x3131, ""M"", ""ᄀ""),
        (0x3132, ""M"", ""ᄁ""),
        (0x3133, ""M"", ""ᆪ""),
        (0x3134, ""M"", ""ᄂ""),
        (0x3135, ""M"", ""ᆬ""),
        (0x3136, ""M"", ""ᆭ""),
        (0x3137, ""M"", ""ᄃ""),
        (0x3138, ""M"", ""ᄄ""),
        (0x3139, ""M"", ""ᄅ""),
        (0x313A, ""M"", ""ᆰ""),
        (0x313B, ""M"", ""ᆱ""),
        (0x313C, ""M"", ""ᆲ""),
        (0x313D, ""M"", ""ᆳ""),
        (0x313E, ""M"", ""ᆴ""),
        (0x313F, ""M"", ""ᆵ""),
        (0x3140, ""M"", ""ᄚ""),
        (0x3141, ""M"", ""ᄆ""),
        (0x3142, ""M"", ""ᄇ""),
        (0x3143, ""M"", ""ᄈ""),
        (0x3144, ""M"", ""ᄡ""),
        (0x3145, ""M"", ""ᄉ""),
        (0x3146, ""M"", ""ᄊ""),
        (0x3147, ""M"", ""ᄋ""),
        (0x3148, ""M"", ""ᄌ""),
        (0x3149, ""M"", ""ᄍ""),
        (0x314A, ""M"", ""ᄎ""),
        (0x314B, ""M"", ""ᄏ""),
        (0x314C, ""M"", ""ᄐ""),
        (0x314D, ""M"", ""ᄑ""),
        (0x314E, ""M"", ""ᄒ""),
        (0x314F, ""M"", ""ᅡ""),
        (0x3150, ""M"", ""ᅢ""),
        (0x3151, ""M"", ""ᅣ""),
        (0x3152, ""M"", ""ᅤ""),
        (0x3153, ""M"", ""ᅥ""),
        (0x3154, ""M"", ""ᅦ""),
        (0x3155, ""M"", ""ᅧ""),
        (0x3156, ""M"", ""ᅨ""),
        (0x3157, ""M"", ""ᅩ""),
        (0x3158, ""M"", ""ᅪ""),
        (0x3159, ""M"", ""ᅫ""),
        (0x315A, ""M"", ""ᅬ""),
        (0x315B, ""M"", ""ᅭ""),
        (0x315C, ""M"", ""ᅮ""),
        (0x315D, ""M"", ""ᅯ""),
        (0x315E, ""M"", ""ᅰ""),
        (0x315F, ""M"", ""ᅱ""),
        (0x3160, ""M"", ""ᅲ""),
        (0x3161, ""M"", ""ᅳ""),
        (0x3162, ""M"", ""ᅴ""),
        (0x3163, ""M"", ""ᅵ""),
        (0x3164, ""X""),
        (0x3165, ""M"", ""ᄔ""),
        (0x3166, ""M"", ""ᄕ""),
        (0x3167, ""M"", ""ᇇ""),
        (0x3168, ""M"", ""ᇈ""),
        (0x3169, ""M"", ""ᇌ""),
        (0x316A, ""M"", ""ᇎ""),
        (0x316B, ""M"", ""ᇓ""),
        (0x316C, ""M"", ""ᇗ""),
        (0x316D, ""M"", ""ᇙ""),
        (0x316E, ""M"", ""ᄜ""),
        (0x316F, ""M"", ""ᇝ""),
        (0x3170, ""M"", ""ᇟ""),
        (0x3171, ""M"", ""ᄝ""),
        (0x3172, ""M"", ""ᄞ""),
        (0x3173, ""M"", ""ᄠ""),
        (0x3174, ""M"", ""ᄢ""),
        (0x3175, ""M"", ""ᄣ""),
        (0x3176, ""M"", ""ᄧ""),
        (0x3177, ""M"", ""ᄩ""),
        (0x3178, ""M"", ""ᄫ""),
        (0x3179, ""M"", ""ᄬ""),
        (0x317A, ""M"", ""ᄭ""),
        (0x317B, ""M"", ""ᄮ""),
        (0x317C, ""M"", ""ᄯ""),
        (0x317D, ""M"", ""ᄲ""),
        (0x317E, ""M"", ""ᄶ""),
        (0x317F, ""M"", ""ᅀ""),
        (0x3180, ""M"", ""ᅇ""),
        (0x3181, ""M"", ""ᅌ""),
        (0x3182, ""M"", ""ᇱ""),
        (0x3183, ""M"", ""ᇲ""),
        (0x3184, ""M"", ""ᅗ""),
        (0x3185, ""M"", ""ᅘ""),
        (0x3186, ""M"", ""ᅙ""),
        (0x3187, ""M"", ""ᆄ""),
        (0x3188, ""M"", ""ᆅ""),
    ]


def _seg_30() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x3189, ""M"", ""ᆈ""),
        (0x318A, ""M"", ""ᆑ""),
        (0x318B, ""M"", ""ᆒ""),
        (0x318C, ""M"", ""ᆔ""),
        (0x318D, ""M"", ""ᆞ""),
        (0x318E, ""M"", ""ᆡ""),
        (0x318F, ""X""),
        (0x3190, ""V""),
        (0x3192, ""M"", ""一""),
        (0x3193, ""M"", ""二""),
        (0x3194, ""M"", ""三""),
        (0x3195, ""M"", ""四""),
        (0x3196, ""M"", ""上""),
        (0x3197, ""M"", ""中""),
        (0x3198, ""M"", ""下""),
        (0x3199, ""M"", ""甲""),
        (0x319A, ""M"", ""乙""),
        (0x319B, ""M"", ""丙""),
        (0x319C, ""M"", ""丁""),
        (0x319D, ""M"", ""天""),
        (0x319E, ""M"", ""地""),
        (0x319F, ""M"", ""人""),
        (0x31A0, ""V""),
        (0x31E4, ""X""),
        (0x31F0, ""V""),
        (0x3200, ""3"", ""(ᄀ)""),
        (0x3201, ""3"", ""(ᄂ)""),
        (0x3202, ""3"", ""(ᄃ)""),
        (0x3203, ""3"", ""(ᄅ)""),
        (0x3204, ""3"", ""(ᄆ)""),
        (0x3205, ""3"", ""(ᄇ)""),
        (0x3206, ""3"", ""(ᄉ)""),
        (0x3207, ""3"", ""(ᄋ)""),
        (0x3208, ""3"", ""(ᄌ)""),
        (0x3209, ""3"", ""(ᄎ)""),
        (0x320A, ""3"", ""(ᄏ)""),
        (0x320B, ""3"", ""(ᄐ)""),
        (0x320C, ""3"", ""(ᄑ)""),
        (0x320D, ""3"", ""(ᄒ)""),
        (0x320E, ""3"", ""(가)""),
        (0x320F, ""3"", ""(나)""),
        (0x3210, ""3"", ""(다)""),
        (0x3211, ""3"", ""(라)""),
        (0x3212, ""3"", ""(마)""),
        (0x3213, ""3"", ""(바)""),
        (0x3214, ""3"", ""(사)""),
        (0x3215, ""3"", ""(아)""),
        (0x3216, ""3"", ""(자)""),
        (0x3217, ""3"", ""(차)""),
        (0x3218, ""3"", ""(카)""),
        (0x3219, ""3"", ""(타)""),
        (0x321A, ""3"", ""(파)""),
        (0x321B, ""3"", ""(하)""),
        (0x321C, ""3"", ""(주)""),
        (0x321D, ""3"", ""(오전)""),
        (0x321E, ""3"", ""(오후)""),
        (0x321F, ""X""),
        (0x3220, ""3"", ""(一)""),
        (0x3221, ""3"", ""(二)""),
        (0x3222, ""3"", ""(三)""),
        (0x3223, ""3"", ""(四)""),
        (0x3224, ""3"", ""(五)""),
        (0x3225, ""3"", ""(六)""),
        (0x3226, ""3"", ""(七)""),
        (0x3227, ""3"", ""(八)""),
        (0x3228, ""3"", ""(九)""),
        (0x3229, ""3"", ""(十)""),
        (0x322A, ""3"", ""(月)""),
        (0x322B, ""3"", ""(火)""),
        (0x322C, ""3"", ""(水)""),
        (0x322D, ""3"", ""(木)""),
        (0x322E, ""3"", ""(金)""),
        (0x322F, ""3"", ""(土)""),
        (0x3230, ""3"", ""(日)""),
        (0x3231, ""3"", ""(株)""),
        (0x3232, ""3"", ""(有)""),
        (0x3233, ""3"", ""(社)""),
        (0x3234, ""3"", ""(名)""),
        (0x3235, ""3"", ""(特)""),
        (0x3236, ""3"", ""(財)""),
        (0x3237, ""3"", ""(祝)""),
        (0x3238, ""3"", ""(労)""),
        (0x3239, ""3"", ""(代)""),
        (0x323A, ""3"", ""(呼)""),
        (0x323B, ""3"", ""(学)""),
        (0x323C, ""3"", ""(監)""),
        (0x323D, ""3"", ""(企)""),
        (0x323E, ""3"", ""(資)""),
        (0x323F, ""3"", ""(協)""),
        (0x3240, ""3"", ""(祭)""),
        (0x3241, ""3"", ""(休)""),
        (0x3242, ""3"", ""(自)""),
        (0x3243, ""3"", ""(至)""),
        (0x3244, ""M"", ""問""),
        (0x3245, ""M"", ""幼""),
        (0x3246, ""M"", ""文""),
        (0x3247, ""M"", ""箏""),
        (0x3248, ""V""),
        (0x3250, ""M"", ""pte""),
        (0x3251, ""M"", ""21""),
    ]


def _seg_31() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x3252, ""M"", ""22""),
        (0x3253, ""M"", ""23""),
        (0x3254, ""M"", ""24""),
        (0x3255, ""M"", ""25""),
        (0x3256, ""M"", ""26""),
        (0x3257, ""M"", ""27""),
        (0x3258, ""M"", ""28""),
        (0x3259, ""M"", ""29""),
        (0x325A, ""M"", ""30""),
        (0x325B, ""M"", ""31""),
        (0x325C, ""M"", ""32""),
        (0x325D, ""M"", ""33""),
        (0x325E, ""M"", ""34""),
        (0x325F, ""M"", ""35""),
        (0x3260, ""M"", ""ᄀ""),
        (0x3261, ""M"", ""ᄂ""),
        (0x3262, ""M"", ""ᄃ""),
        (0x3263, ""M"", ""ᄅ""),
        (0x3264, ""M"", ""ᄆ""),
        (0x3265, ""M"", ""ᄇ""),
        (0x3266, ""M"", ""ᄉ""),
        (0x3267, ""M"", ""ᄋ""),
        (0x3268, ""M"", ""ᄌ""),
        (0x3269, ""M"", ""ᄎ""),
        (0x326A, ""M"", ""ᄏ""),
        (0x326B, ""M"", ""ᄐ""),
        (0x326C, ""M"", ""ᄑ""),
        (0x326D, ""M"", ""ᄒ""),
        (0x326E, ""M"", ""가""),
        (0x326F, ""M"", ""나""),
        (0x3270, ""M"", ""다""),
        (0x3271, ""M"", ""라""),
        (0x3272, ""M"", ""마""),
        (0x3273, ""M"", ""바""),
        (0x3274, ""M"", ""사""),
        (0x3275, ""M"", ""아""),
        (0x3276, ""M"", ""자""),
        (0x3277, ""M"", ""차""),
        (0x3278, ""M"", ""카""),
        (0x3279, ""M"", ""타""),
        (0x327A, ""M"", ""파""),
        (0x327B, ""M"", ""하""),
        (0x327C, ""M"", ""참고""),
        (0x327D, ""M"", ""주의""),
        (0x327E, ""M"", ""우""),
        (0x327F, ""V""),
        (0x3280, ""M"", ""一""),
        (0x3281, ""M"", ""二""),
        (0x3282, ""M"", ""三""),
        (0x3283, ""M"", ""四""),
        (0x3284, ""M"", ""五""),
        (0x3285, ""M"", ""六""),
        (0x3286, ""M"", ""七""),
        (0x3287, ""M"", ""八""),
        (0x3288, ""M"", ""九""),
        (0x3289, ""M"", ""十""),
        (0x328A, ""M"", ""月""),
        (0x328B, ""M"", ""火""),
        (0x328C, ""M"", ""水""),
        (0x328D, ""M"", ""木""),
        (0x328E, ""M"", ""金""),
        (0x328F, ""M"", ""土""),
        (0x3290, ""M"", ""日""),
        (0x3291, ""M"", ""株""),
        (0x3292, ""M"", ""有""),
        (0x3293, ""M"", ""社""),
        (0x3294, ""M"", ""名""),
        (0x3295, ""M"", ""特""),
        (0x3296, ""M"", ""財""),
        (0x3297, ""M"", ""祝""),
        (0x3298, ""M"", ""労""),
        (0x3299, ""M"", ""秘""),
        (0x329A, ""M"", ""男""),
        (0x329B, ""M"", ""女""),
        (0x329C, ""M"", ""適""),
        (0x329D, ""M"", ""優""),
        (0x329E, ""M"", ""印""),
        (0x329F, ""M"", ""注""),
        (0x32A0, ""M"", ""項""),
        (0x32A1, ""M"", ""休""),
        (0x32A2, ""M"", ""写""),
        (0x32A3, ""M"", ""正""),
        (0x32A4, ""M"", ""上""),
        (0x32A5, ""M"", ""中""),
        (0x32A6, ""M"", ""下""),
        (0x32A7, ""M"", ""左""),
        (0x32A8, ""M"", ""右""),
        (0x32A9, ""M"", ""医""),
        (0x32AA, ""M"", ""宗""),
        (0x32AB, ""M"", ""学""),
        (0x32AC, ""M"", ""監""),
        (0x32AD, ""M"", ""企""),
        (0x32AE, ""M"", ""資""),
        (0x32AF, ""M"", ""協""),
        (0x32B0, ""M"", ""夜""),
        (0x32B1, ""M"", ""36""),
        (0x32B2, ""M"", ""37""),
        (0x32B3, ""M"", ""38""),
        (0x32B4, ""M"", ""39""),
        (0x32B5, ""M"", ""40""),
    ]


def _seg_32() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x32B6, ""M"", ""41""),
        (0x32B7, ""M"", ""42""),
        (0x32B8, ""M"", ""43""),
        (0x32B9, ""M"", ""44""),
        (0x32BA, ""M"", ""45""),
        (0x32BB, ""M"", ""46""),
        (0x32BC, ""M"", ""47""),
        (0x32BD, ""M"", ""48""),
        (0x32BE, ""M"", ""49""),
        (0x32BF, ""M"", ""50""),
        (0x32C0, ""M"", ""1月""),
        (0x32C1, ""M"", ""2月""),
        (0x32C2, ""M"", ""3月""),
        (0x32C3, ""M"", ""4月""),
        (0x32C4, ""M"", ""5月""),
        (0x32C5, ""M"", ""6月""),
        (0x32C6, ""M"", ""7月""),
        (0x32C7, ""M"", ""8月""),
        (0x32C8, ""M"", ""9月""),
        (0x32C9, ""M"", ""10月""),
        (0x32CA, ""M"", ""11月""),
        (0x32CB, ""M"", ""12月""),
        (0x32CC, ""M"", ""hg""),
        (0x32CD, ""M"", ""erg""),
        (0x32CE, ""M"", ""ev""),
        (0x32CF, ""M"", ""ltd""),
        (0x32D0, ""M"", ""ア""),
        (0x32D1, ""M"", ""イ""),
        (0x32D2, ""M"", ""ウ""),
        (0x32D3, ""M"", ""エ""),
        (0x32D4, ""M"", ""オ""),
        (0x32D5, ""M"", ""カ""),
        (0x32D6, ""M"", ""キ""),
        (0x32D7, ""M"", ""ク""),
        (0x32D8, ""M"", ""ケ""),
        (0x32D9, ""M"", ""コ""),
        (0x32DA, ""M"", ""サ""),
        (0x32DB, ""M"", ""シ""),
        (0x32DC, ""M"", ""ス""),
        (0x32DD, ""M"", ""セ""),
        (0x32DE, ""M"", ""ソ""),
        (0x32DF, ""M"", ""タ""),
        (0x32E0, ""M"", ""チ""),
        (0x32E1, ""M"", ""ツ""),
        (0x32E2, ""M"", ""テ""),
        (0x32E3, ""M"", ""ト""),
        (0x32E4, ""M"", ""ナ""),
        (0x32E5, ""M"", ""ニ""),
        (0x32E6, ""M"", ""ヌ""),
        (0x32E7, ""M"", ""ネ""),
        (0x32E8, ""M"", ""ノ""),
        (0x32E9, ""M"", ""ハ""),
        (0x32EA, ""M"", ""ヒ""),
        (0x32EB, ""M"", ""フ""),
        (0x32EC, ""M"", ""ヘ""),
        (0x32ED, ""M"", ""ホ""),
        (0x32EE, ""M"", ""マ""),
        (0x32EF, ""M"", ""ミ""),
        (0x32F0, ""M"", ""ム""),
        (0x32F1, ""M"", ""メ""),
        (0x32F2, ""M"", ""モ""),
        (0x32F3, ""M"", ""ヤ""),
        (0x32F4, ""M"", ""ユ""),
        (0x32F5, ""M"", ""ヨ""),
        (0x32F6, ""M"", ""ラ""),
        (0x32F7, ""M"", ""リ""),
        (0x32F8, ""M"", ""ル""),
        (0x32F9, ""M"", ""レ""),
        (0x32FA, ""M"", ""ロ""),
        (0x32FB, ""M"", ""ワ""),
        (0x32FC, ""M"", ""ヰ""),
        (0x32FD, ""M"", ""ヱ""),
        (0x32FE, ""M"", ""ヲ""),
        (0x32FF, ""M"", ""令和""),
        (0x3300, ""M"", ""アパート""),
        (0x3301, ""M"", ""アルファ""),
        (0x3302, ""M"", ""アンペア""),
        (0x3303, ""M"", ""アール""),
        (0x3304, ""M"", ""イニング""),
        (0x3305, ""M"", ""インチ""),
        (0x3306, ""M"", ""ウォン""),
        (0x3307, ""M"", ""エスクード""),
        (0x3308, ""M"", ""エーカー""),
        (0x3309, ""M"", ""オンス""),
        (0x330A, ""M"", ""オーム""),
        (0x330B, ""M"", ""カイリ""),
        (0x330C, ""M"", ""カラット""),
        (0x330D, ""M"", ""カロリー""),
        (0x330E, ""M"", ""ガロン""),
        (0x330F, ""M"", ""ガンマ""),
        (0x3310, ""M"", ""ギガ""),
        (0x3311, ""M"", ""ギニー""),
        (0x3312, ""M"", ""キュリー""),
        (0x3313, ""M"", ""ギルダー""),
        (0x3314, ""M"", ""キロ""),
        (0x3315, ""M"", ""キログラム""),
        (0x3316, ""M"", ""キロメートル""),
        (0x3317, ""M"", ""キロワット""),
        (0x3318, ""M"", ""グラム""),
        (0x3319, ""M"", ""グラムトン""),
    ]


def _seg_33() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x331A, ""M"", ""クルゼイロ""),
        (0x331B, ""M"", ""クローネ""),
        (0x331C, ""M"", ""ケース""),
        (0x331D, ""M"", ""コルナ""),
        (0x331E, ""M"", ""コーポ""),
        (0x331F, ""M"", ""サイクル""),
        (0x3320, ""M"", ""サンチーム""),
        (0x3321, ""M"", ""シリング""),
        (0x3322, ""M"", ""センチ""),
        (0x3323, ""M"", ""セント""),
        (0x3324, ""M"", ""ダース""),
        (0x3325, ""M"", ""デシ""),
        (0x3326, ""M"", ""ドル""),
        (0x3327, ""M"", ""トン""),
        (0x3328, ""M"", ""ナノ""),
        (0x3329, ""M"", ""ノット""),
        (0x332A, ""M"", ""ハイツ""),
        (0x332B, ""M"", ""パーセント""),
        (0x332C, ""M"", ""パーツ""),
        (0x332D, ""M"", ""バーレル""),
        (0x332E, ""M"", ""ピアストル""),
        (0x332F, ""M"", ""ピクル""),
        (0x3330, ""M"", ""ピコ""),
        (0x3331, ""M"", ""ビル""),
        (0x3332, ""M"", ""ファラッド""),
        (0x3333, ""M"", ""フィート""),
        (0x3334, ""M"", ""ブッシェル""),
        (0x3335, ""M"", ""フラン""),
        (0x3336, ""M"", ""ヘクタール""),
        (0x3337, ""M"", ""ペソ""),
        (0x3338, ""M"", ""ペニヒ""),
        (0x3339, ""M"", ""ヘルツ""),
        (0x333A, ""M"", ""ペンス""),
        (0x333B, ""M"", ""ページ""),
        (0x333C, ""M"", ""ベータ""),
        (0x333D, ""M"", ""ポイント""),
        (0x333E, ""M"", ""ボルト""),
        (0x333F, ""M"", ""ホン""),
        (0x3340, ""M"", ""ポンド""),
        (0x3341, ""M"", ""ホール""),
        (0x3342, ""M"", ""ホーン""),
        (0x3343, ""M"", ""マイクロ""),
        (0x3344, ""M"", ""マイル""),
        (0x3345, ""M"", ""マッハ""),
        (0x3346, ""M"", ""マルク""),
        (0x3347, ""M"", ""マンション""),
        (0x3348, ""M"", ""ミクロン""),
        (0x3349, ""M"", ""ミリ""),
        (0x334A, ""M"", ""ミリバール""),
        (0x334B, ""M"", ""メガ""),
        (0x334C, ""M"", ""メガトン""),
        (0x334D, ""M"", ""メートル""),
        (0x334E, ""M"", ""ヤード""),
        (0x334F, ""M"", ""ヤール""),
        (0x3350, ""M"", ""ユアン""),
        (0x3351, ""M"", ""リットル""),
        (0x3352, ""M"", ""リラ""),
        (0x3353, ""M"", ""ルピー""),
        (0x3354, ""M"", ""ルーブル""),
        (0x3355, ""M"", ""レム""),
        (0x3356, ""M"", ""レントゲン""),
        (0x3357, ""M"", ""ワット""),
        (0x3358, ""M"", ""0点""),
        (0x3359, ""M"", ""1点""),
        (0x335A, ""M"", ""2点""),
        (0x335B, ""M"", ""3点""),
        (0x335C, ""M"", ""4点""),
        (0x335D, ""M"", ""5点""),
        (0x335E, ""M"", ""6点""),
        (0x335F, ""M"", ""7点""),
        (0x3360, ""M"", ""8点""),
        (0x3361, ""M"", ""9点""),
        (0x3362, ""M"", ""10点""),
        (0x3363, ""M"", ""11点""),
        (0x3364, ""M"", ""12点""),
        (0x3365, ""M"", ""13点""),
        (0x3366, ""M"", ""14点""),
        (0x3367, ""M"", ""15点""),
        (0x3368, ""M"", ""16点""),
        (0x3369, ""M"", ""17点""),
        (0x336A, ""M"", ""18点""),
        (0x336B, ""M"", ""19点""),
        (0x336C, ""M"", ""20点""),
        (0x336D, ""M"", ""21点""),
        (0x336E, ""M"", ""22点""),
        (0x336F, ""M"", ""23点""),
        (0x3370, ""M"", ""24点""),
        (0x3371, ""M"", ""hpa""),
        (0x3372, ""M"", ""da""),
        (0x3373, ""M"", ""au""),
        (0x3374, ""M"", ""bar""),
        (0x3375, ""M"", ""ov""),
        (0x3376, ""M"", ""pc""),
        (0x3377, ""M"", ""dm""),
        (0x3378, ""M"", ""dm2""),
        (0x3379, ""M"", ""dm3""),
        (0x337A, ""M"", ""iu""),
        (0x337B, ""M"", ""平成""),
        (0x337C, ""M"", ""昭和""),
        (0x337D, ""M"", ""大正""),
    ]


def _seg_34() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x337E, ""M"", ""明治""),
        (0x337F, ""M"", ""株式会社""),
        (0x3380, ""M"", ""pa""),
        (0x3381, ""M"", ""na""),
        (0x3382, ""M"", ""μa""),
        (0x3383, ""M"", ""ma""),
        (0x3384, ""M"", ""ka""),
        (0x3385, ""M"", ""kb""),
        (0x3386, ""M"", ""mb""),
        (0x3387, ""M"", ""gb""),
        (0x3388, ""M"", ""cal""),
        (0x3389, ""M"", ""kcal""),
        (0x338A, ""M"", ""pf""),
        (0x338B, ""M"", ""nf""),
        (0x338C, ""M"", ""μf""),
        (0x338D, ""M"", ""μg""),
        (0x338E, ""M"", ""mg""),
        (0x338F, ""M"", ""kg""),
        (0x3390, ""M"", ""hz""),
        (0x3391, ""M"", ""khz""),
        (0x3392, ""M"", ""mhz""),
        (0x3393, ""M"", ""ghz""),
        (0x3394, ""M"", ""thz""),
        (0x3395, ""M"", ""μl""),
        (0x3396, ""M"", ""ml""),
        (0x3397, ""M"", ""dl""),
        (0x3398, ""M"", ""kl""),
        (0x3399, ""M"", ""fm""),
        (0x339A, ""M"", ""nm""),
        (0x339B, ""M"", ""μm""),
        (0x339C, ""M"", ""mm""),
        (0x339D, ""M"", ""cm""),
        (0x339E, ""M"", ""km""),
        (0x339F, ""M"", ""mm2""),
        (0x33A0, ""M"", ""cm2""),
        (0x33A1, ""M"", ""m2""),
        (0x33A2, ""M"", ""km2""),
        (0x33A3, ""M"", ""mm3""),
        (0x33A4, ""M"", ""cm3""),
        (0x33A5, ""M"", ""m3""),
        (0x33A6, ""M"", ""km3""),
        (0x33A7, ""M"", ""m∕s""),
        (0x33A8, ""M"", ""m∕s2""),
        (0x33A9, ""M"", ""pa""),
        (0x33AA, ""M"", ""kpa""),
        (0x33AB, ""M"", ""mpa""),
        (0x33AC, ""M"", ""gpa""),
        (0x33AD, ""M"", ""rad""),
        (0x33AE, ""M"", ""rad∕s""),
        (0x33AF, ""M"", ""rad∕s2""),
        (0x33B0, ""M"", ""ps""),
        (0x33B1, ""M"", ""ns""),
        (0x33B2, ""M"", ""μs""),
        (0x33B3, ""M"", ""ms""),
        (0x33B4, ""M"", ""pv""),
        (0x33B5, ""M"", ""nv""),
        (0x33B6, ""M"", ""μv""),
        (0x33B7, ""M"", ""mv""),
        (0x33B8, ""M"", ""kv""),
        (0x33B9, ""M"", ""mv""),
        (0x33BA, ""M"", ""pw""),
        (0x33BB, ""M"", ""nw""),
        (0x33BC, ""M"", ""μw""),
        (0x33BD, ""M"", ""mw""),
        (0x33BE, ""M"", ""kw""),
        (0x33BF, ""M"", ""mw""),
        (0x33C0, ""M"", ""kω""),
        (0x33C1, ""M"", ""mω""),
        (0x33C2, ""X""),
        (0x33C3, ""M"", ""bq""),
        (0x33C4, ""M"", ""cc""),
        (0x33C5, ""M"", ""cd""),
        (0x33C6, ""M"", ""c∕kg""),
        (0x33C7, ""X""),
        (0x33C8, ""M"", ""db""),
        (0x33C9, ""M"", ""gy""),
        (0x33CA, ""M"", ""ha""),
        (0x33CB, ""M"", ""hp""),
        (0x33CC, ""M"", ""in""),
        (0x33CD, ""M"", ""kk""),
        (0x33CE, ""M"", ""km""),
        (0x33CF, ""M"", ""kt""),
        (0x33D0, ""M"", ""lm""),
        (0x33D1, ""M"", ""ln""),
        (0x33D2, ""M"", ""log""),
        (0x33D3, ""M"", ""lx""),
        (0x33D4, ""M"", ""mb""),
        (0x33D5, ""M"", ""mil""),
        (0x33D6, ""M"", ""mol""),
        (0x33D7, ""M"", ""ph""),
        (0x33D8, ""X""),
        (0x33D9, ""M"", ""ppm""),
        (0x33DA, ""M"", ""pr""),
        (0x33DB, ""M"", ""sr""),
        (0x33DC, ""M"", ""sv""),
        (0x33DD, ""M"", ""wb""),
        (0x33DE, ""M"", ""v∕m""),
        (0x33DF, ""M"", ""a∕m""),
        (0x33E0, ""M"", ""1日""),
        (0x33E1, ""M"", ""2日""),
    ]


def _seg_35() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x33E2, ""M"", ""3日""),
        (0x33E3, ""M"", ""4日""),
        (0x33E4, ""M"", ""5日""),
        (0x33E5, ""M"", ""6日""),
        (0x33E6, ""M"", ""7日""),
        (0x33E7, ""M"", ""8日""),
        (0x33E8, ""M"", ""9日""),
        (0x33E9, ""M"", ""10日""),
        (0x33EA, ""M"", ""11日""),
        (0x33EB, ""M"", ""12日""),
        (0x33EC, ""M"", ""13日""),
        (0x33ED, ""M"", ""14日""),
        (0x33EE, ""M"", ""15日""),
        (0x33EF, ""M"", ""16日""),
        (0x33F0, ""M"", ""17日""),
        (0x33F1, ""M"", ""18日""),
        (0x33F2, ""M"", ""19日""),
        (0x33F3, ""M"", ""20日""),
        (0x33F4, ""M"", ""21日""),
        (0x33F5, ""M"", ""22日""),
        (0x33F6, ""M"", ""23日""),
        (0x33F7, ""M"", ""24日""),
        (0x33F8, ""M"", ""25日""),
        (0x33F9, ""M"", ""26日""),
        (0x33FA, ""M"", ""27日""),
        (0x33FB, ""M"", ""28日""),
        (0x33FC, ""M"", ""29日""),
        (0x33FD, ""M"", ""30日""),
        (0x33FE, ""M"", ""31日""),
        (0x33FF, ""M"", ""gal""),
        (0x3400, ""V""),
        (0xA48D, ""X""),
        (0xA490, ""V""),
        (0xA4C7, ""X""),
        (0xA4D0, ""V""),
        (0xA62C, ""X""),
        (0xA640, ""M"", ""ꙁ""),
        (0xA641, ""V""),
        (0xA642, ""M"", ""ꙃ""),
        (0xA643, ""V""),
        (0xA644, ""M"", ""ꙅ""),
        (0xA645, ""V""),
        (0xA646, ""M"", ""ꙇ""),
        (0xA647, ""V""),
        (0xA648, ""M"", ""ꙉ""),
        (0xA649, ""V""),
        (0xA64A, ""M"", ""ꙋ""),
        (0xA64B, ""V""),
        (0xA64C, ""M"", ""ꙍ""),
        (0xA64D, ""V""),
        (0xA64E, ""M"", ""ꙏ""),
        (0xA64F, ""V""),
        (0xA650, ""M"", ""ꙑ""),
        (0xA651, ""V""),
        (0xA652, ""M"", ""ꙓ""),
        (0xA653, ""V""),
        (0xA654, ""M"", ""ꙕ""),
        (0xA655, ""V""),
        (0xA656, ""M"", ""ꙗ""),
        (0xA657, ""V""),
        (0xA658, ""M"", ""ꙙ""),
        (0xA659, ""V""),
        (0xA65A, ""M"", ""ꙛ""),
        (0xA65B, ""V""),
        (0xA65C, ""M"", ""ꙝ""),
        (0xA65D, ""V""),
        (0xA65E, ""M"", ""ꙟ""),
        (0xA65F, ""V""),
        (0xA660, ""M"", ""ꙡ""),
        (0xA661, ""V""),
        (0xA662, ""M"", ""ꙣ""),
        (0xA663, ""V""),
        (0xA664, ""M"", ""ꙥ""),
        (0xA665, ""V""),
        (0xA666, ""M"", ""ꙧ""),
        (0xA667, ""V""),
        (0xA668, ""M"", ""ꙩ""),
        (0xA669, ""V""),
        (0xA66A, ""M"", ""ꙫ""),
        (0xA66B, ""V""),
        (0xA66C, ""M"", ""ꙭ""),
        (0xA66D, ""V""),
        (0xA680, ""M"", ""ꚁ""),
        (0xA681, ""V""),
        (0xA682, ""M"", ""ꚃ""),
        (0xA683, ""V""),
        (0xA684, ""M"", ""ꚅ""),
        (0xA685, ""V""),
        (0xA686, ""M"", ""ꚇ""),
        (0xA687, ""V""),
        (0xA688, ""M"", ""ꚉ""),
        (0xA689, ""V""),
        (0xA68A, ""M"", ""ꚋ""),
        (0xA68B, ""V""),
        (0xA68C, ""M"", ""ꚍ""),
        (0xA68D, ""V""),
        (0xA68E, ""M"", ""ꚏ""),
        (0xA68F, ""V""),
        (0xA690, ""M"", ""ꚑ""),
        (0xA691, ""V""),
    ]


def _seg_36() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0xA692, ""M"", ""ꚓ""),
        (0xA693, ""V""),
        (0xA694, ""M"", ""ꚕ""),
        (0xA695, ""V""),
        (0xA696, ""M"", ""ꚗ""),
        (0xA697, ""V""),
        (0xA698, ""M"", ""ꚙ""),
        (0xA699, ""V""),
        (0xA69A, ""M"", ""ꚛ""),
        (0xA69B, ""V""),
        (0xA69C, ""M"", ""ъ""),
        (0xA69D, ""M"", ""ь""),
        (0xA69E, ""V""),
        (0xA6F8, ""X""),
        (0xA700, ""V""),
        (0xA722, ""M"", ""ꜣ""),
        (0xA723, ""V""),
        (0xA724, ""M"", ""ꜥ""),
        (0xA725, ""V""),
        (0xA726, ""M"", ""ꜧ""),
        (0xA727, ""V""),
        (0xA728, ""M"", ""ꜩ""),
        (0xA729, ""V""),
        (0xA72A, ""M"", ""ꜫ""),
        (0xA72B, ""V""),
        (0xA72C, ""M"", ""ꜭ""),
        (0xA72D, ""V""),
        (0xA72E, ""M"", ""ꜯ""),
        (0xA72F, ""V""),
        (0xA732, ""M"", ""ꜳ""),
        (0xA733, ""V""),
        (0xA734, ""M"", ""ꜵ""),
        (0xA735, ""V""),
        (0xA736, ""M"", ""ꜷ""),
        (0xA737, ""V""),
        (0xA738, ""M"", ""ꜹ""),
        (0xA739, ""V""),
        (0xA73A, ""M"", ""ꜻ""),
        (0xA73B, ""V""),
        (0xA73C, ""M"", ""ꜽ""),
        (0xA73D, ""V""),
        (0xA73E, ""M"", ""ꜿ""),
        (0xA73F, ""V""),
        (0xA740, ""M"", ""ꝁ""),
        (0xA741, ""V""),
        (0xA742, ""M"", ""ꝃ""),
        (0xA743, ""V""),
        (0xA744, ""M"", ""ꝅ""),
        (0xA745, ""V""),
        (0xA746, ""M"", ""ꝇ""),
        (0xA747, ""V""),
        (0xA748, ""M"", ""ꝉ""),
        (0xA749, ""V""),
        (0xA74A, ""M"", ""ꝋ""),
        (0xA74B, ""V""),
        (0xA74C, ""M"", ""ꝍ""),
        (0xA74D, ""V""),
        (0xA74E, ""M"", ""ꝏ""),
        (0xA74F, ""V""),
        (0xA750, ""M"", ""ꝑ""),
        (0xA751, ""V""),
        (0xA752, ""M"", ""ꝓ""),
        (0xA753, ""V""),
        (0xA754, ""M"", ""ꝕ""),
        (0xA755, ""V""),
        (0xA756, ""M"", ""ꝗ""),
        (0xA757, ""V""),
        (0xA758, ""M"", ""ꝙ""),
        (0xA759, ""V""),
        (0xA75A, ""M"", ""ꝛ""),
        (0xA75B, ""V""),
        (0xA75C, ""M"", ""ꝝ""),
        (0xA75D, ""V""),
        (0xA75E, ""M"", ""ꝟ""),
        (0xA75F, ""V""),
        (0xA760, ""M"", ""ꝡ""),
        (0xA761, ""V""),
        (0xA762, ""M"", ""ꝣ""),
        (0xA763, ""V""),
        (0xA764, ""M"", ""ꝥ""),
        (0xA765, ""V""),
        (0xA766, ""M"", ""ꝧ""),
        (0xA767, ""V""),
        (0xA768, ""M"", ""ꝩ""),
        (0xA769, ""V""),
        (0xA76A, ""M"", ""ꝫ""),
        (0xA76B, ""V""),
        (0xA76C, ""M"", ""ꝭ""),
        (0xA76D, ""V""),
        (0xA76E, ""M"", ""ꝯ""),
        (0xA76F, ""V""),
        (0xA770, ""M"", ""ꝯ""),
        (0xA771, ""V""),
        (0xA779, ""M"", ""ꝺ""),
        (0xA77A, ""V""),
        (0xA77B, ""M"", ""ꝼ""),
        (0xA77C, ""V""),
        (0xA77D, ""M"", ""ᵹ""),
        (0xA77E, ""M"", ""ꝿ""),
        (0xA77F, ""V""),
    ]


def _seg_37() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0xA780, ""M"", ""ꞁ""),
        (0xA781, ""V""),
        (0xA782, ""M"", ""ꞃ""),
        (0xA783, ""V""),
        (0xA784, ""M"", ""ꞅ""),
        (0xA785, ""V""),
        (0xA786, ""M"", ""ꞇ""),
        (0xA787, ""V""),
        (0xA78B, ""M"", ""ꞌ""),
        (0xA78C, ""V""),
        (0xA78D, ""M"", ""ɥ""),
        (0xA78E, ""V""),
        (0xA790, ""M"", ""ꞑ""),
        (0xA791, ""V""),
        (0xA792, ""M"", ""ꞓ""),
        (0xA793, ""V""),
        (0xA796, ""M"", ""ꞗ""),
        (0xA797, ""V""),
        (0xA798, ""M"", ""ꞙ""),
        (0xA799, ""V""),
        (0xA79A, ""M"", ""ꞛ""),
        (0xA79B, ""V""),
        (0xA79C, ""M"", ""ꞝ""),
        (0xA79D, ""V""),
        (0xA79E, ""M"", ""ꞟ""),
        (0xA79F, ""V""),
        (0xA7A0, ""M"", ""ꞡ""),
        (0xA7A1, ""V""),
        (0xA7A2, ""M"", ""ꞣ""),
        (0xA7A3, ""V""),
        (0xA7A4, ""M"", ""ꞥ""),
        (0xA7A5, ""V""),
        (0xA7A6, ""M"", ""ꞧ""),
        (0xA7A7, ""V""),
        (0xA7A8, ""M"", ""ꞩ""),
        (0xA7A9, ""V""),
        (0xA7AA, ""M"", ""ɦ""),
        (0xA7AB, ""M"", ""ɜ""),
        (0xA7AC, ""M"", ""ɡ""),
        (0xA7AD, ""M"", ""ɬ""),
        (0xA7AE, ""M"", ""ɪ""),
        (0xA7AF, ""V""),
        (0xA7B0, ""M"", ""ʞ""),
        (0xA7B1, ""M"", ""ʇ""),
        (0xA7B2, ""M"", ""ʝ""),
        (0xA7B3, ""M"", ""ꭓ""),
        (0xA7B4, ""M"", ""ꞵ""),
        (0xA7B5, ""V""),
        (0xA7B6, ""M"", ""ꞷ""),
        (0xA7B7, ""V""),
        (0xA7B8, ""M"", ""ꞹ""),
        (0xA7B9, ""V""),
        (0xA7BA, ""M"", ""ꞻ""),
        (0xA7BB, ""V""),
        (0xA7BC, ""M"", ""ꞽ""),
        (0xA7BD, ""V""),
        (0xA7BE, ""M"", ""ꞿ""),
        (0xA7BF, ""V""),
        (0xA7C0, ""M"", ""ꟁ""),
        (0xA7C1, ""V""),
        (0xA7C2, ""M"", ""ꟃ""),
        (0xA7C3, ""V""),
        (0xA7C4, ""M"", ""ꞔ""),
        (0xA7C5, ""M"", ""ʂ""),
        (0xA7C6, ""M"", ""ᶎ""),
        (0xA7C7, ""M"", ""ꟈ""),
        (0xA7C8, ""V""),
        (0xA7C9, ""M"", ""ꟊ""),
        (0xA7CA, ""V""),
        (0xA7CB, ""X""),
        (0xA7D0, ""M"", ""ꟑ""),
        (0xA7D1, ""V""),
        (0xA7D2, ""X""),
        (0xA7D3, ""V""),
        (0xA7D4, ""X""),
        (0xA7D5, ""V""),
        (0xA7D6, ""M"", ""ꟗ""),
        (0xA7D7, ""V""),
        (0xA7D8, ""M"", ""ꟙ""),
        (0xA7D9, ""V""),
        (0xA7DA, ""X""),
        (0xA7F2, ""M"", ""c""),
        (0xA7F3, ""M"", ""f""),
        (0xA7F4, ""M"", ""q""),
        (0xA7F5, ""M"", ""ꟶ""),
        (0xA7F6, ""V""),
        (0xA7F8, ""M"", ""ħ""),
        (0xA7F9, ""M"", ""œ""),
        (0xA7FA, ""V""),
        (0xA82D, ""X""),
        (0xA830, ""V""),
        (0xA83A, ""X""),
        (0xA840, ""V""),
        (0xA878, ""X""),
        (0xA880, ""V""),
        (0xA8C6, ""X""),
        (0xA8CE, ""V""),
        (0xA8DA, ""X""),
        (0xA8E0, ""V""),
        (0xA954, ""X""),
    ]


def _seg_38() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0xA95F, ""V""),
        (0xA97D, ""X""),
        (0xA980, ""V""),
        (0xA9CE, ""X""),
        (0xA9CF, ""V""),
        (0xA9DA, ""X""),
        (0xA9DE, ""V""),
        (0xA9FF, ""X""),
        (0xAA00, ""V""),
        (0xAA37, ""X""),
        (0xAA40, ""V""),
        (0xAA4E, ""X""),
        (0xAA50, ""V""),
        (0xAA5A, ""X""),
        (0xAA5C, ""V""),
        (0xAAC3, ""X""),
        (0xAADB, ""V""),
        (0xAAF7, ""X""),
        (0xAB01, ""V""),
        (0xAB07, ""X""),
        (0xAB09, ""V""),
        (0xAB0F, ""X""),
        (0xAB11, ""V""),
        (0xAB17, ""X""),
        (0xAB20, ""V""),
        (0xAB27, ""X""),
        (0xAB28, ""V""),
        (0xAB2F, ""X""),
        (0xAB30, ""V""),
        (0xAB5C, ""M"", ""ꜧ""),
        (0xAB5D, ""M"", ""ꬷ""),
        (0xAB5E, ""M"", ""ɫ""),
        (0xAB5F, ""M"", ""ꭒ""),
        (0xAB60, ""V""),
        (0xAB69, ""M"", ""ʍ""),
        (0xAB6A, ""V""),
        (0xAB6C, ""X""),
        (0xAB70, ""M"", ""Ꭰ""),
        (0xAB71, ""M"", ""Ꭱ""),
        (0xAB72, ""M"", ""Ꭲ""),
        (0xAB73, ""M"", ""Ꭳ""),
        (0xAB74, ""M"", ""Ꭴ""),
        (0xAB75, ""M"", ""Ꭵ""),
        (0xAB76, ""M"", ""Ꭶ""),
        (0xAB77, ""M"", ""Ꭷ""),
        (0xAB78, ""M"", ""Ꭸ""),
        (0xAB79, ""M"", ""Ꭹ""),
        (0xAB7A, ""M"", ""Ꭺ""),
        (0xAB7B, ""M"", ""Ꭻ""),
        (0xAB7C, ""M"", ""Ꭼ""),
        (0xAB7D, ""M"", ""Ꭽ""),
        (0xAB7E, ""M"", ""Ꭾ""),
        (0xAB7F, ""M"", ""Ꭿ""),
        (0xAB80, ""M"", ""Ꮀ""),
        (0xAB81, ""M"", ""Ꮁ""),
        (0xAB82, ""M"", ""Ꮂ""),
        (0xAB83, ""M"", ""Ꮃ""),
        (0xAB84, ""M"", ""Ꮄ""),
        (0xAB85, ""M"", ""Ꮅ""),
        (0xAB86, ""M"", ""Ꮆ""),
        (0xAB87, ""M"", ""Ꮇ""),
        (0xAB88, ""M"", ""Ꮈ""),
        (0xAB89, ""M"", ""Ꮉ""),
        (0xAB8A, ""M"", ""Ꮊ""),
        (0xAB8B, ""M"", ""Ꮋ""),
        (0xAB8C, ""M"", ""Ꮌ""),
        (0xAB8D, ""M"", ""Ꮍ""),
        (0xAB8E, ""M"", ""Ꮎ""),
        (0xAB8F, ""M"", ""Ꮏ""),
        (0xAB90, ""M"", ""Ꮐ""),
        (0xAB91, ""M"", ""Ꮑ""),
        (0xAB92, ""M"", ""Ꮒ""),
        (0xAB93, ""M"", ""Ꮓ""),
        (0xAB94, ""M"", ""Ꮔ""),
        (0xAB95, ""M"", ""Ꮕ""),
        (0xAB96, ""M"", ""Ꮖ""),
        (0xAB97, ""M"", ""Ꮗ""),
        (0xAB98, ""M"", ""Ꮘ""),
        (0xAB99, ""M"", ""Ꮙ""),
        (0xAB9A, ""M"", ""Ꮚ""),
        (0xAB9B, ""M"", ""Ꮛ""),
        (0xAB9C, ""M"", ""Ꮜ""),
        (0xAB9D, ""M"", ""Ꮝ""),
        (0xAB9E, ""M"", ""Ꮞ""),
        (0xAB9F, ""M"", ""Ꮟ""),
        (0xABA0, ""M"", ""Ꮠ""),
        (0xABA1, ""M"", ""Ꮡ""),
        (0xABA2, ""M"", ""Ꮢ""),
        (0xABA3, ""M"", ""Ꮣ""),
        (0xABA4, ""M"", ""Ꮤ""),
        (0xABA5, ""M"", ""Ꮥ""),
        (0xABA6, ""M"", ""Ꮦ""),
        (0xABA7, ""M"", ""Ꮧ""),
        (0xABA8, ""M"", ""Ꮨ""),
        (0xABA9, ""M"", ""Ꮩ""),
        (0xABAA, ""M"", ""Ꮪ""),
        (0xABAB, ""M"", ""Ꮫ""),
        (0xABAC, ""M"", ""Ꮬ""),
        (0xABAD, ""M"", ""Ꮭ""),
        (0xABAE, ""M"", ""Ꮮ""),
    ]


def _seg_39() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0xABAF, ""M"", ""Ꮯ""),
        (0xABB0, ""M"", ""Ꮰ""),
        (0xABB1, ""M"", ""Ꮱ""),
        (0xABB2, ""M"", ""Ꮲ""),
        (0xABB3, ""M"", ""Ꮳ""),
        (0xABB4, ""M"", ""Ꮴ""),
        (0xABB5, ""M"", ""Ꮵ""),
        (0xABB6, ""M"", ""Ꮶ""),
        (0xABB7, ""M"", ""Ꮷ""),
        (0xABB8, ""M"", ""Ꮸ""),
        (0xABB9, ""M"", ""Ꮹ""),
        (0xABBA, ""M"", ""Ꮺ""),
        (0xABBB, ""M"", ""Ꮻ""),
        (0xABBC, ""M"", ""Ꮼ""),
        (0xABBD, ""M"", ""Ꮽ""),
        (0xABBE, ""M"", ""Ꮾ""),
        (0xABBF, ""M"", ""Ꮿ""),
        (0xABC0, ""V""),
        (0xABEE, ""X""),
        (0xABF0, ""V""),
        (0xABFA, ""X""),
        (0xAC00, ""V""),
        (0xD7A4, ""X""),
        (0xD7B0, ""V""),
        (0xD7C7, ""X""),
        (0xD7CB, ""V""),
        (0xD7FC, ""X""),
        (0xF900, ""M"", ""豈""),
        (0xF901, ""M"", ""更""),
        (0xF902, ""M"", ""車""),
        (0xF903, ""M"", ""賈""),
        (0xF904, ""M"", ""滑""),
        (0xF905, ""M"", ""串""),
        (0xF906, ""M"", ""句""),
        (0xF907, ""M"", ""龜""),
        (0xF909, ""M"", ""契""),
        (0xF90A, ""M"", ""金""),
        (0xF90B, ""M"", ""喇""),
        (0xF90C, ""M"", ""奈""),
        (0xF90D, ""M"", ""懶""),
        (0xF90E, ""M"", ""癩""),
        (0xF90F, ""M"", ""羅""),
        (0xF910, ""M"", ""蘿""),
        (0xF911, ""M"", ""螺""),
        (0xF912, ""M"", ""裸""),
        (0xF913, ""M"", ""邏""),
        (0xF914, ""M"", ""樂""),
        (0xF915, ""M"", ""洛""),
        (0xF916, ""M"", ""烙""),
        (0xF917, ""M"", ""珞""),
        (0xF918, ""M"", ""落""),
        (0xF919, ""M"", ""酪""),
        (0xF91A, ""M"", ""駱""),
        (0xF91B, ""M"", ""亂""),
        (0xF91C, ""M"", ""卵""),
        (0xF91D, ""M"", ""欄""),
        (0xF91E, ""M"", ""爛""),
        (0xF91F, ""M"", ""蘭""),
        (0xF920, ""M"", ""鸞""),
        (0xF921, ""M"", ""嵐""),
        (0xF922, ""M"", ""濫""),
        (0xF923, ""M"", ""藍""),
        (0xF924, ""M"", ""襤""),
        (0xF925, ""M"", ""拉""),
        (0xF926, ""M"", ""臘""),
        (0xF927, ""M"", ""蠟""),
        (0xF928, ""M"", ""廊""),
        (0xF929, ""M"", ""朗""),
        (0xF92A, ""M"", ""浪""),
        (0xF92B, ""M"", ""狼""),
        (0xF92C, ""M"", ""郎""),
        (0xF92D, ""M"", ""來""),
        (0xF92E, ""M"", ""冷""),
        (0xF92F, ""M"", ""勞""),
        (0xF930, ""M"", ""擄""),
        (0xF931, ""M"", ""櫓""),
        (0xF932, ""M"", ""爐""),
        (0xF933, ""M"", ""盧""),
        (0xF934, ""M"", ""老""),
        (0xF935, ""M"", ""蘆""),
        (0xF936, ""M"", ""虜""),
        (0xF937, ""M"", ""路""),
        (0xF938, ""M"", ""露""),
        (0xF939, ""M"", ""魯""),
        (0xF93A, ""M"", ""鷺""),
        (0xF93B, ""M"", ""碌""),
        (0xF93C, ""M"", ""祿""),
        (0xF93D, ""M"", ""綠""),
        (0xF93E, ""M"", ""菉""),
        (0xF93F, ""M"", ""錄""),
        (0xF940, ""M"", ""鹿""),
        (0xF941, ""M"", ""論""),
        (0xF942, ""M"", ""壟""),
        (0xF943, ""M"", ""弄""),
        (0xF944, ""M"", ""籠""),
        (0xF945, ""M"", ""聾""),
        (0xF946, ""M"", ""牢""),
        (0xF947, ""M"", ""磊""),
        (0xF948, ""M"", ""賂""),
        (0xF949, ""M"", ""雷""),
    ]


def _seg_40() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0xF94A, ""M"", ""壘""),
        (0xF94B, ""M"", ""屢""),
        (0xF94C, ""M"", ""樓""),
        (0xF94D, ""M"", ""淚""),
        (0xF94E, ""M"", ""漏""),
        (0xF94F, ""M"", ""累""),
        (0xF950, ""M"", ""縷""),
        (0xF951, ""M"", ""陋""),
        (0xF952, ""M"", ""勒""),
        (0xF953, ""M"", ""肋""),
        (0xF954, ""M"", ""凜""),
        (0xF955, ""M"", ""凌""),
        (0xF956, ""M"", ""稜""),
        (0xF957, ""M"", ""綾""),
        (0xF958, ""M"", ""菱""),
        (0xF959, ""M"", ""陵""),
        (0xF95A, ""M"", ""讀""),
        (0xF95B, ""M"", ""拏""),
        (0xF95C, ""M"", ""樂""),
        (0xF95D, ""M"", ""諾""),
        (0xF95E, ""M"", ""丹""),
        (0xF95F, ""M"", ""寧""),
        (0xF960, ""M"", ""怒""),
        (0xF961, ""M"", ""率""),
        (0xF962, ""M"", ""異""),
        (0xF963, ""M"", ""北""),
        (0xF964, ""M"", ""磻""),
        (0xF965, ""M"", ""便""),
        (0xF966, ""M"", ""復""),
        (0xF967, ""M"", ""不""),
        (0xF968, ""M"", ""泌""),
        (0xF969, ""M"", ""數""),
        (0xF96A, ""M"", ""索""),
        (0xF96B, ""M"", ""參""),
        (0xF96C, ""M"", ""塞""),
        (0xF96D, ""M"", ""省""),
        (0xF96E, ""M"", ""葉""),
        (0xF96F, ""M"", ""說""),
        (0xF970, ""M"", ""殺""),
        (0xF971, ""M"", ""辰""),
        (0xF972, ""M"", ""沈""),
        (0xF973, ""M"", ""拾""),
        (0xF974, ""M"", ""若""),
        (0xF975, ""M"", ""掠""),
        (0xF976, ""M"", ""略""),
        (0xF977, ""M"", ""亮""),
        (0xF978, ""M"", ""兩""),
        (0xF979, ""M"", ""凉""),
        (0xF97A, ""M"", ""梁""),
        (0xF97B, ""M"", ""糧""),
        (0xF97C, ""M"", ""良""),
        (0xF97D, ""M"", ""諒""),
        (0xF97E, ""M"", ""量""),
        (0xF97F, ""M"", ""勵""),
        (0xF980, ""M"", ""呂""),
        (0xF981, ""M"", ""女""),
        (0xF982, ""M"", ""廬""),
        (0xF983, ""M"", ""旅""),
        (0xF984, ""M"", ""濾""),
        (0xF985, ""M"", ""礪""),
        (0xF986, ""M"", ""閭""),
        (0xF987, ""M"", ""驪""),
        (0xF988, ""M"", ""麗""),
        (0xF989, ""M"", ""黎""),
        (0xF98A, ""M"", ""力""),
        (0xF98B, ""M"", ""曆""),
        (0xF98C, ""M"", ""歷""),
        (0xF98D, ""M"", ""轢""),
        (0xF98E, ""M"", ""年""),
        (0xF98F, ""M"", ""憐""),
        (0xF990, ""M"", ""戀""),
        (0xF991, ""M"", ""撚""),
        (0xF992, ""M"", ""漣""),
        (0xF993, ""M"", ""煉""),
        (0xF994, ""M"", ""璉""),
        (0xF995, ""M"", ""秊""),
        (0xF996, ""M"", ""練""),
        (0xF997, ""M"", ""聯""),
        (0xF998, ""M"", ""輦""),
        (0xF999, ""M"", ""蓮""),
        (0xF99A, ""M"", ""連""),
        (0xF99B, ""M"", ""鍊""),
        (0xF99C, ""M"", ""列""),
        (0xF99D, ""M"", ""劣""),
        (0xF99E, ""M"", ""咽""),
        (0xF99F, ""M"", ""烈""),
        (0xF9A0, ""M"", ""裂""),
        (0xF9A1, ""M"", ""說""),
        (0xF9A2, ""M"", ""廉""),
        (0xF9A3, ""M"", ""念""),
        (0xF9A4, ""M"", ""捻""),
        (0xF9A5, ""M"", ""殮""),
        (0xF9A6, ""M"", ""簾""),
        (0xF9A7, ""M"", ""獵""),
        (0xF9A8, ""M"", ""令""),
        (0xF9A9, ""M"", ""囹""),
        (0xF9AA, ""M"", ""寧""),
        (0xF9AB, ""M"", ""嶺""),
        (0xF9AC, ""M"", ""怜""),
        (0xF9AD, ""M"", ""玲""),
    ]


def _seg_41() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0xF9AE, ""M"", ""瑩""),
        (0xF9AF, ""M"", ""羚""),
        (0xF9B0, ""M"", ""聆""),
        (0xF9B1, ""M"", ""鈴""),
        (0xF9B2, ""M"", ""零""),
        (0xF9B3, ""M"", ""靈""),
        (0xF9B4, ""M"", ""領""),
        (0xF9B5, ""M"", ""例""),
        (0xF9B6, ""M"", ""禮""),
        (0xF9B7, ""M"", ""醴""),
        (0xF9B8, ""M"", ""隸""),
        (0xF9B9, ""M"", ""惡""),
        (0xF9BA, ""M"", ""了""),
        (0xF9BB, ""M"", ""僚""),
        (0xF9BC, ""M"", ""寮""),
        (0xF9BD, ""M"", ""尿""),
        (0xF9BE, ""M"", ""料""),
        (0xF9BF, ""M"", ""樂""),
        (0xF9C0, ""M"", ""燎""),
        (0xF9C1, ""M"", ""療""),
        (0xF9C2, ""M"", ""蓼""),
        (0xF9C3, ""M"", ""遼""),
        (0xF9C4, ""M"", ""龍""),
        (0xF9C5, ""M"", ""暈""),
        (0xF9C6, ""M"", ""阮""),
        (0xF9C7, ""M"", ""劉""),
        (0xF9C8, ""M"", ""杻""),
        (0xF9C9, ""M"", ""柳""),
        (0xF9CA, ""M"", ""流""),
        (0xF9CB, ""M"", ""溜""),
        (0xF9CC, ""M"", ""琉""),
        (0xF9CD, ""M"", ""留""),
        (0xF9CE, ""M"", ""硫""),
        (0xF9CF, ""M"", ""紐""),
        (0xF9D0, ""M"", ""類""),
        (0xF9D1, ""M"", ""六""),
        (0xF9D2, ""M"", ""戮""),
        (0xF9D3, ""M"", ""陸""),
        (0xF9D4, ""M"", ""倫""),
        (0xF9D5, ""M"", ""崙""),
        (0xF9D6, ""M"", ""淪""),
        (0xF9D7, ""M"", ""輪""),
        (0xF9D8, ""M"", ""律""),
        (0xF9D9, ""M"", ""慄""),
        (0xF9DA, ""M"", ""栗""),
        (0xF9DB, ""M"", ""率""),
        (0xF9DC, ""M"", ""隆""),
        (0xF9DD, ""M"", ""利""),
        (0xF9DE, ""M"", ""吏""),
        (0xF9DF, ""M"", ""履""),
        (0xF9E0, ""M"", ""易""),
        (0xF9E1, ""M"", ""李""),
        (0xF9E2, ""M"", ""梨""),
        (0xF9E3, ""M"", ""泥""),
        (0xF9E4, ""M"", ""理""),
        (0xF9E5, ""M"", ""痢""),
        (0xF9E6, ""M"", ""罹""),
        (0xF9E7, ""M"", ""裏""),
        (0xF9E8, ""M"", ""裡""),
        (0xF9E9, ""M"", ""里""),
        (0xF9EA, ""M"", ""離""),
        (0xF9EB, ""M"", ""匿""),
        (0xF9EC, ""M"", ""溺""),
        (0xF9ED, ""M"", ""吝""),
        (0xF9EE, ""M"", ""燐""),
        (0xF9EF, ""M"", ""璘""),
        (0xF9F0, ""M"", ""藺""),
        (0xF9F1, ""M"", ""隣""),
        (0xF9F2, ""M"", ""鱗""),
        (0xF9F3, ""M"", ""麟""),
        (0xF9F4, ""M"", ""林""),
        (0xF9F5, ""M"", ""淋""),
        (0xF9F6, ""M"", ""臨""),
        (0xF9F7, ""M"", ""立""),
        (0xF9F8, ""M"", ""笠""),
        (0xF9F9, ""M"", ""粒""),
        (0xF9FA, ""M"", ""狀""),
        (0xF9FB, ""M"", ""炙""),
        (0xF9FC, ""M"", ""識""),
        (0xF9FD, ""M"", ""什""),
        (0xF9FE, ""M"", ""茶""),
        (0xF9FF, ""M"", ""刺""),
        (0xFA00, ""M"", ""切""),
        (0xFA01, ""M"", ""度""),
        (0xFA02, ""M"", ""拓""),
        (0xFA03, ""M"", ""糖""),
        (0xFA04, ""M"", ""宅""),
        (0xFA05, ""M"", ""洞""),
        (0xFA06, ""M"", ""暴""),
        (0xFA07, ""M"", ""輻""),
        (0xFA08, ""M"", ""行""),
        (0xFA09, ""M"", ""降""),
        (0xFA0A, ""M"", ""見""),
        (0xFA0B, ""M"", ""廓""),
        (0xFA0C, ""M"", ""兀""),
        (0xFA0D, ""M"", ""嗀""),
        (0xFA0E, ""V""),
        (0xFA10, ""M"", ""塚""),
        (0xFA11, ""V""),
        (0xFA12, ""M"", ""晴""),
    ]


def _seg_42() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0xFA13, ""V""),
        (0xFA15, ""M"", ""凞""),
        (0xFA16, ""M"", ""猪""),
        (0xFA17, ""M"", ""益""),
        (0xFA18, ""M"", ""礼""),
        (0xFA19, ""M"", ""神""),
        (0xFA1A, ""M"", ""祥""),
        (0xFA1B, ""M"", ""福""),
        (0xFA1C, ""M"", ""靖""),
        (0xFA1D, ""M"", ""精""),
        (0xFA1E, ""M"", ""羽""),
        (0xFA1F, ""V""),
        (0xFA20, ""M"", ""蘒""),
        (0xFA21, ""V""),
        (0xFA22, ""M"", ""諸""),
        (0xFA23, ""V""),
        (0xFA25, ""M"", ""逸""),
        (0xFA26, ""M"", ""都""),
        (0xFA27, ""V""),
        (0xFA2A, ""M"", ""飯""),
        (0xFA2B, ""M"", ""飼""),
        (0xFA2C, ""M"", ""館""),
        (0xFA2D, ""M"", ""鶴""),
        (0xFA2E, ""M"", ""郞""),
        (0xFA2F, ""M"", ""隷""),
        (0xFA30, ""M"", ""侮""),
        (0xFA31, ""M"", ""僧""),
        (0xFA32, ""M"", ""免""),
        (0xFA33, ""M"", ""勉""),
        (0xFA34, ""M"", ""勤""),
        (0xFA35, ""M"", ""卑""),
        (0xFA36, ""M"", ""喝""),
        (0xFA37, ""M"", ""嘆""),
        (0xFA38, ""M"", ""器""),
        (0xFA39, ""M"", ""塀""),
        (0xFA3A, ""M"", ""墨""),
        (0xFA3B, ""M"", ""層""),
        (0xFA3C, ""M"", ""屮""),
        (0xFA3D, ""M"", ""悔""),
        (0xFA3E, ""M"", ""慨""),
        (0xFA3F, ""M"", ""憎""),
        (0xFA40, ""M"", ""懲""),
        (0xFA41, ""M"", ""敏""),
        (0xFA42, ""M"", ""既""),
        (0xFA43, ""M"", ""暑""),
        (0xFA44, ""M"", ""梅""),
        (0xFA45, ""M"", ""海""),
        (0xFA46, ""M"", ""渚""),
        (0xFA47, ""M"", ""漢""),
        (0xFA48, ""M"", ""煮""),
        (0xFA49, ""M"", ""爫""),
        (0xFA4A, ""M"", ""琢""),
        (0xFA4B, ""M"", ""碑""),
        (0xFA4C, ""M"", ""社""),
        (0xFA4D, ""M"", ""祉""),
        (0xFA4E, ""M"", ""祈""),
        (0xFA4F, ""M"", ""祐""),
        (0xFA50, ""M"", ""祖""),
        (0xFA51, ""M"", ""祝""),
        (0xFA52, ""M"", ""禍""),
        (0xFA53, ""M"", ""禎""),
        (0xFA54, ""M"", ""穀""),
        (0xFA55, ""M"", ""突""),
        (0xFA56, ""M"", ""節""),
        (0xFA57, ""M"", ""練""),
        (0xFA58, ""M"", ""縉""),
        (0xFA59, ""M"", ""繁""),
        (0xFA5A, ""M"", ""署""),
        (0xFA5B, ""M"", ""者""),
        (0xFA5C, ""M"", ""臭""),
        (0xFA5D, ""M"", ""艹""),
        (0xFA5F, ""M"", ""著""),
        (0xFA60, ""M"", ""褐""),
        (0xFA61, ""M"", ""視""),
        (0xFA62, ""M"", ""謁""),
        (0xFA63, ""M"", ""謹""),
        (0xFA64, ""M"", ""賓""),
        (0xFA65, ""M"", ""贈""),
        (0xFA66, ""M"", ""辶""),
        (0xFA67, ""M"", ""逸""),
        (0xFA68, ""M"", ""難""),
        (0xFA69, ""M"", ""響""),
        (0xFA6A, ""M"", ""頻""),
        (0xFA6B, ""M"", ""恵""),
        (0xFA6C, ""M"", ""𤋮""),
        (0xFA6D, ""M"", ""舘""),
        (0xFA6E, ""X""),
        (0xFA70, ""M"", ""並""),
        (0xFA71, ""M"", ""况""),
        (0xFA72, ""M"", ""全""),
        (0xFA73, ""M"", ""侀""),
        (0xFA74, ""M"", ""充""),
        (0xFA75, ""M"", ""冀""),
        (0xFA76, ""M"", ""勇""),
        (0xFA77, ""M"", ""勺""),
        (0xFA78, ""M"", ""喝""),
        (0xFA79, ""M"", ""啕""),
        (0xFA7A, ""M"", ""喙""),
        (0xFA7B, ""M"", ""嗢""),
        (0xFA7C, ""M"", ""塚""),
    ]


def _seg_43() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0xFA7D, ""M"", ""墳""),
        (0xFA7E, ""M"", ""奄""),
        (0xFA7F, ""M"", ""奔""),
        (0xFA80, ""M"", ""婢""),
        (0xFA81, ""M"", ""嬨""),
        (0xFA82, ""M"", ""廒""),
        (0xFA83, ""M"", ""廙""),
        (0xFA84, ""M"", ""彩""),
        (0xFA85, ""M"", ""徭""),
        (0xFA86, ""M"", ""惘""),
        (0xFA87, ""M"", ""慎""),
        (0xFA88, ""M"", ""愈""),
        (0xFA89, ""M"", ""憎""),
        (0xFA8A, ""M"", ""慠""),
        (0xFA8B, ""M"", ""懲""),
        (0xFA8C, ""M"", ""戴""),
        (0xFA8D, ""M"", ""揄""),
        (0xFA8E, ""M"", ""搜""),
        (0xFA8F, ""M"", ""摒""),
        (0xFA90, ""M"", ""敖""),
        (0xFA91, ""M"", ""晴""),
        (0xFA92, ""M"", ""朗""),
        (0xFA93, ""M"", ""望""),
        (0xFA94, ""M"", ""杖""),
        (0xFA95, ""M"", ""歹""),
        (0xFA96, ""M"", ""殺""),
        (0xFA97, ""M"", ""流""),
        (0xFA98, ""M"", ""滛""),
        (0xFA99, ""M"", ""滋""),
        (0xFA9A, ""M"", ""漢""),
        (0xFA9B, ""M"", ""瀞""),
        (0xFA9C, ""M"", ""煮""),
        (0xFA9D, ""M"", ""瞧""),
        (0xFA9E, ""M"", ""爵""),
        (0xFA9F, ""M"", ""犯""),
        (0xFAA0, ""M"", ""猪""),
        (0xFAA1, ""M"", ""瑱""),
        (0xFAA2, ""M"", ""甆""),
        (0xFAA3, ""M"", ""画""),
        (0xFAA4, ""M"", ""瘝""),
        (0xFAA5, ""M"", ""瘟""),
        (0xFAA6, ""M"", ""益""),
        (0xFAA7, ""M"", ""盛""),
        (0xFAA8, ""M"", ""直""),
        (0xFAA9, ""M"", ""睊""),
        (0xFAAA, ""M"", ""着""),
        (0xFAAB, ""M"", ""磌""),
        (0xFAAC, ""M"", ""窱""),
        (0xFAAD, ""M"", ""節""),
        (0xFAAE, ""M"", ""类""),
        (0xFAAF, ""M"", ""絛""),
        (0xFAB0, ""M"", ""練""),
        (0xFAB1, ""M"", ""缾""),
        (0xFAB2, ""M"", ""者""),
        (0xFAB3, ""M"", ""荒""),
        (0xFAB4, ""M"", ""華""),
        (0xFAB5, ""M"", ""蝹""),
        (0xFAB6, ""M"", ""襁""),
        (0xFAB7, ""M"", ""覆""),
        (0xFAB8, ""M"", ""視""),
        (0xFAB9, ""M"", ""調""),
        (0xFABA, ""M"", ""諸""),
        (0xFABB, ""M"", ""請""),
        (0xFABC, ""M"", ""謁""),
        (0xFABD, ""M"", ""諾""),
        (0xFABE, ""M"", ""諭""),
        (0xFABF, ""M"", ""謹""),
        (0xFAC0, ""M"", ""變""),
        (0xFAC1, ""M"", ""贈""),
        (0xFAC2, ""M"", ""輸""),
        (0xFAC3, ""M"", ""遲""),
        (0xFAC4, ""M"", ""醙""),
        (0xFAC5, ""M"", ""鉶""),
        (0xFAC6, ""M"", ""陼""),
        (0xFAC7, ""M"", ""難""),
        (0xFAC8, ""M"", ""靖""),
        (0xFAC9, ""M"", ""韛""),
        (0xFACA, ""M"", ""響""),
        (0xFACB, ""M"", ""頋""),
        (0xFACC, ""M"", ""頻""),
        (0xFACD, ""M"", ""鬒""),
        (0xFACE, ""M"", ""龜""),
        (0xFACF, ""M"", ""𢡊""),
        (0xFAD0, ""M"", ""𢡄""),
        (0xFAD1, ""M"", ""𣏕""),
        (0xFAD2, ""M"", ""㮝""),
        (0xFAD3, ""M"", ""䀘""),
        (0xFAD4, ""M"", ""䀹""),
        (0xFAD5, ""M"", ""𥉉""),
        (0xFAD6, ""M"", ""𥳐""),
        (0xFAD7, ""M"", ""𧻓""),
        (0xFAD8, ""M"", ""齃""),
        (0xFAD9, ""M"", ""龎""),
        (0xFADA, ""X""),
        (0xFB00, ""M"", ""ff""),
        (0xFB01, ""M"", ""fi""),
        (0xFB02, ""M"", ""fl""),
        (0xFB03, ""M"", ""ffi""),
        (0xFB04, ""M"", ""ffl""),
        (0xFB05, ""M"", ""st""),
    ]


def _seg_44() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0xFB07, ""X""),
        (0xFB13, ""M"", ""մն""),
        (0xFB14, ""M"", ""մե""),
        (0xFB15, ""M"", ""մի""),
        (0xFB16, ""M"", ""վն""),
        (0xFB17, ""M"", ""մխ""),
        (0xFB18, ""X""),
        (0xFB1D, ""M"", ""יִ""),
        (0xFB1E, ""V""),
        (0xFB1F, ""M"", ""ײַ""),
        (0xFB20, ""M"", ""ע""),
        (0xFB21, ""M"", ""א""),
        (0xFB22, ""M"", ""ד""),
        (0xFB23, ""M"", ""ה""),
        (0xFB24, ""M"", ""כ""),
        (0xFB25, ""M"", ""ל""),
        (0xFB26, ""M"", ""ם""),
        (0xFB27, ""M"", ""ר""),
        (0xFB28, ""M"", ""ת""),
        (0xFB29, ""3"", ""+""),
        (0xFB2A, ""M"", ""שׁ""),
        (0xFB2B, ""M"", ""שׂ""),
        (0xFB2C, ""M"", ""שּׁ""),
        (0xFB2D, ""M"", ""שּׂ""),
        (0xFB2E, ""M"", ""אַ""),
        (0xFB2F, ""M"", ""אָ""),
        (0xFB30, ""M"", ""אּ""),
        (0xFB31, ""M"", ""בּ""),
        (0xFB32, ""M"", ""גּ""),
        (0xFB33, ""M"", ""דּ""),
        (0xFB34, ""M"", ""הּ""),
        (0xFB35, ""M"", ""וּ""),
        (0xFB36, ""M"", ""זּ""),
        (0xFB37, ""X""),
        (0xFB38, ""M"", ""טּ""),
        (0xFB39, ""M"", ""יּ""),
        (0xFB3A, ""M"", ""ךּ""),
        (0xFB3B, ""M"", ""כּ""),
        (0xFB3C, ""M"", ""לּ""),
        (0xFB3D, ""X""),
        (0xFB3E, ""M"", ""מּ""),
        (0xFB3F, ""X""),
        (0xFB40, ""M"", ""נּ""),
        (0xFB41, ""M"", ""סּ""),
        (0xFB42, ""X""),
        (0xFB43, ""M"", ""ףּ""),
        (0xFB44, ""M"", ""פּ""),
        (0xFB45, ""X""),
        (0xFB46, ""M"", ""צּ""),
        (0xFB47, ""M"", ""קּ""),
        (0xFB48, ""M"", ""רּ""),
        (0xFB49, ""M"", ""שּ""),
        (0xFB4A, ""M"", ""תּ""),
        (0xFB4B, ""M"", ""וֹ""),
        (0xFB4C, ""M"", ""בֿ""),
        (0xFB4D, ""M"", ""כֿ""),
        (0xFB4E, ""M"", ""פֿ""),
        (0xFB4F, ""M"", ""אל""),
        (0xFB50, ""M"", ""ٱ""),
        (0xFB52, ""M"", ""ٻ""),
        (0xFB56, ""M"", ""پ""),
        (0xFB5A, ""M"", ""ڀ""),
        (0xFB5E, ""M"", ""ٺ""),
        (0xFB62, ""M"", ""ٿ""),
        (0xFB66, ""M"", ""ٹ""),
        (0xFB6A, ""M"", ""ڤ""),
        (0xFB6E, ""M"", ""ڦ""),
        (0xFB72, ""M"", ""ڄ""),
        (0xFB76, ""M"", ""ڃ""),
        (0xFB7A, ""M"", ""چ""),
        (0xFB7E, ""M"", ""ڇ""),
        (0xFB82, ""M"", ""ڍ""),
        (0xFB84, ""M"", ""ڌ""),
        (0xFB86, ""M"", ""ڎ""),
        (0xFB88, ""M"", ""ڈ""),
        (0xFB8A, ""M"", ""ژ""),
        (0xFB8C, ""M"", ""ڑ""),
        (0xFB8E, ""M"", ""ک""),
        (0xFB92, ""M"", ""گ""),
        (0xFB96, ""M"", ""ڳ""),
        (0xFB9A, ""M"", ""ڱ""),
        (0xFB9E, ""M"", ""ں""),
        (0xFBA0, ""M"", ""ڻ""),
        (0xFBA4, ""M"", ""ۀ""),
        (0xFBA6, ""M"", ""ہ""),
        (0xFBAA, ""M"", ""ھ""),
        (0xFBAE, ""M"", ""ے""),
        (0xFBB0, ""M"", ""ۓ""),
        (0xFBB2, ""V""),
        (0xFBC3, ""X""),
        (0xFBD3, ""M"", ""ڭ""),
        (0xFBD7, ""M"", ""ۇ""),
        (0xFBD9, ""M"", ""ۆ""),
        (0xFBDB, ""M"", ""ۈ""),
        (0xFBDD, ""M"", ""ۇٴ""),
        (0xFBDE, ""M"", ""ۋ""),
        (0xFBE0, ""M"", ""ۅ""),
        (0xFBE2, ""M"", ""ۉ""),
        (0xFBE4, ""M"", ""ې""),
        (0xFBE8, ""M"", ""ى""),
    ]


def _seg_45() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0xFBEA, ""M"", ""ئا""),
        (0xFBEC, ""M"", ""ئە""),
        (0xFBEE, ""M"", ""ئو""),
        (0xFBF0, ""M"", ""ئۇ""),
        (0xFBF2, ""M"", ""ئۆ""),
        (0xFBF4, ""M"", ""ئۈ""),
        (0xFBF6, ""M"", ""ئې""),
        (0xFBF9, ""M"", ""ئى""),
        (0xFBFC, ""M"", ""ی""),
        (0xFC00, ""M"", ""ئج""),
        (0xFC01, ""M"", ""ئح""),
        (0xFC02, ""M"", ""ئم""),
        (0xFC03, ""M"", ""ئى""),
        (0xFC04, ""M"", ""ئي""),
        (0xFC05, ""M"", ""بج""),
        (0xFC06, ""M"", ""بح""),
        (0xFC07, ""M"", ""بخ""),
        (0xFC08, ""M"", ""بم""),
        (0xFC09, ""M"", ""بى""),
        (0xFC0A, ""M"", ""بي""),
        (0xFC0B, ""M"", ""تج""),
        (0xFC0C, ""M"", ""تح""),
        (0xFC0D, ""M"", ""تخ""),
        (0xFC0E, ""M"", ""تم""),
        (0xFC0F, ""M"", ""تى""),
        (0xFC10, ""M"", ""تي""),
        (0xFC11, ""M"", ""ثج""),
        (0xFC12, ""M"", ""ثم""),
        (0xFC13, ""M"", ""ثى""),
        (0xFC14, ""M"", ""ثي""),
        (0xFC15, ""M"", ""جح""),
        (0xFC16, ""M"", ""جم""),
        (0xFC17, ""M"", ""حج""),
        (0xFC18, ""M"", ""حم""),
        (0xFC19, ""M"", ""خج""),
        (0xFC1A, ""M"", ""خح""),
        (0xFC1B, ""M"", ""خم""),
        (0xFC1C, ""M"", ""سج""),
        (0xFC1D, ""M"", ""سح""),
        (0xFC1E, ""M"", ""سخ""),
        (0xFC1F, ""M"", ""سم""),
        (0xFC20, ""M"", ""صح""),
        (0xFC21, ""M"", ""صم""),
        (0xFC22, ""M"", ""ضج""),
        (0xFC23, ""M"", ""ضح""),
        (0xFC24, ""M"", ""ضخ""),
        (0xFC25, ""M"", ""ضم""),
        (0xFC26, ""M"", ""طح""),
        (0xFC27, ""M"", ""طم""),
        (0xFC28, ""M"", ""ظم""),
        (0xFC29, ""M"", ""عج""),
        (0xFC2A, ""M"", ""عم""),
        (0xFC2B, ""M"", ""غج""),
        (0xFC2C, ""M"", ""غم""),
        (0xFC2D, ""M"", ""فج""),
        (0xFC2E, ""M"", ""فح""),
        (0xFC2F, ""M"", ""فخ""),
        (0xFC30, ""M"", ""فم""),
        (0xFC31, ""M"", ""فى""),
        (0xFC32, ""M"", ""في""),
        (0xFC33, ""M"", ""قح""),
        (0xFC34, ""M"", ""قم""),
        (0xFC35, ""M"", ""قى""),
        (0xFC36, ""M"", ""قي""),
        (0xFC37, ""M"", ""كا""),
        (0xFC38, ""M"", ""كج""),
        (0xFC39, ""M"", ""كح""),
        (0xFC3A, ""M"", ""كخ""),
        (0xFC3B, ""M"", ""كل""),
        (0xFC3C, ""M"", ""كم""),
        (0xFC3D, ""M"", ""كى""),
        (0xFC3E, ""M"", ""كي""),
        (0xFC3F, ""M"", ""لج""),
        (0xFC40, ""M"", ""لح""),
        (0xFC41, ""M"", ""لخ""),
        (0xFC42, ""M"", ""لم""),
        (0xFC43, ""M"", ""لى""),
        (0xFC44, ""M"", ""لي""),
        (0xFC45, ""M"", ""مج""),
        (0xFC46, ""M"", ""مح""),
        (0xFC47, ""M"", ""مخ""),
        (0xFC48, ""M"", ""مم""),
        (0xFC49, ""M"", ""مى""),
        (0xFC4A, ""M"", ""مي""),
        (0xFC4B, ""M"", ""نج""),
        (0xFC4C, ""M"", ""نح""),
        (0xFC4D, ""M"", ""نخ""),
        (0xFC4E, ""M"", ""نم""),
        (0xFC4F, ""M"", ""نى""),
        (0xFC50, ""M"", ""ني""),
        (0xFC51, ""M"", ""هج""),
        (0xFC52, ""M"", ""هم""),
        (0xFC53, ""M"", ""هى""),
        (0xFC54, ""M"", ""هي""),
        (0xFC55, ""M"", ""يج""),
        (0xFC56, ""M"", ""يح""),
        (0xFC57, ""M"", ""يخ""),
        (0xFC58, ""M"", ""يم""),
        (0xFC59, ""M"", ""يى""),
        (0xFC5A, ""M"", ""يي""),
    ]


def _seg_46() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0xFC5B, ""M"", ""ذٰ""),
        (0xFC5C, ""M"", ""رٰ""),
        (0xFC5D, ""M"", ""ىٰ""),
        (0xFC5E, ""3"", "" ٌّ""),
        (0xFC5F, ""3"", "" ٍّ""),
        (0xFC60, ""3"", "" َّ""),
        (0xFC61, ""3"", "" ُّ""),
        (0xFC62, ""3"", "" ِّ""),
        (0xFC63, ""3"", "" ّٰ""),
        (0xFC64, ""M"", ""ئر""),
        (0xFC65, ""M"", ""ئز""),
        (0xFC66, ""M"", ""ئم""),
        (0xFC67, ""M"", ""ئن""),
        (0xFC68, ""M"", ""ئى""),
        (0xFC69, ""M"", ""ئي""),
        (0xFC6A, ""M"", ""بر""),
        (0xFC6B, ""M"", ""بز""),
        (0xFC6C, ""M"", ""بم""),
        (0xFC6D, ""M"", ""بن""),
        (0xFC6E, ""M"", ""بى""),
        (0xFC6F, ""M"", ""بي""),
        (0xFC70, ""M"", ""تر""),
        (0xFC71, ""M"", ""تز""),
        (0xFC72, ""M"", ""تم""),
        (0xFC73, ""M"", ""تن""),
        (0xFC74, ""M"", ""تى""),
        (0xFC75, ""M"", ""تي""),
        (0xFC76, ""M"", ""ثر""),
        (0xFC77, ""M"", ""ثز""),
        (0xFC78, ""M"", ""ثم""),
        (0xFC79, ""M"", ""ثن""),
        (0xFC7A, ""M"", ""ثى""),
        (0xFC7B, ""M"", ""ثي""),
        (0xFC7C, ""M"", ""فى""),
        (0xFC7D, ""M"", ""في""),
        (0xFC7E, ""M"", ""قى""),
        (0xFC7F, ""M"", ""قي""),
        (0xFC80, ""M"", ""كا""),
        (0xFC81, ""M"", ""كل""),
        (0xFC82, ""M"", ""كم""),
        (0xFC83, ""M"", ""كى""),
        (0xFC84, ""M"", ""كي""),
        (0xFC85, ""M"", ""لم""),
        (0xFC86, ""M"", ""لى""),
        (0xFC87, ""M"", ""لي""),
        (0xFC88, ""M"", ""ما""),
        (0xFC89, ""M"", ""مم""),
        (0xFC8A, ""M"", ""نر""),
        (0xFC8B, ""M"", ""نز""),
        (0xFC8C, ""M"", ""نم""),
        (0xFC8D, ""M"", ""نن""),
        (0xFC8E, ""M"", ""نى""),
        (0xFC8F, ""M"", ""ني""),
        (0xFC90, ""M"", ""ىٰ""),
        (0xFC91, ""M"", ""ير""),
        (0xFC92, ""M"", ""يز""),
        (0xFC93, ""M"", ""يم""),
        (0xFC94, ""M"", ""ين""),
        (0xFC95, ""M"", ""يى""),
        (0xFC96, ""M"", ""يي""),
        (0xFC97, ""M"", ""ئج""),
        (0xFC98, ""M"", ""ئح""),
        (0xFC99, ""M"", ""ئخ""),
        (0xFC9A, ""M"", ""ئم""),
        (0xFC9B, ""M"", ""ئه""),
        (0xFC9C, ""M"", ""بج""),
        (0xFC9D, ""M"", ""بح""),
        (0xFC9E, ""M"", ""بخ""),
        (0xFC9F, ""M"", ""بم""),
        (0xFCA0, ""M"", ""به""),
        (0xFCA1, ""M"", ""تج""),
        (0xFCA2, ""M"", ""تح""),
        (0xFCA3, ""M"", ""تخ""),
        (0xFCA4, ""M"", ""تم""),
        (0xFCA5, ""M"", ""ته""),
        (0xFCA6, ""M"", ""ثم""),
        (0xFCA7, ""M"", ""جح""),
        (0xFCA8, ""M"", ""جم""),
        (0xFCA9, ""M"", ""حج""),
        (0xFCAA, ""M"", ""حم""),
        (0xFCAB, ""M"", ""خج""),
        (0xFCAC, ""M"", ""خم""),
        (0xFCAD, ""M"", ""سج""),
        (0xFCAE, ""M"", ""سح""),
        (0xFCAF, ""M"", ""سخ""),
        (0xFCB0, ""M"", ""سم""),
        (0xFCB1, ""M"", ""صح""),
        (0xFCB2, ""M"", ""صخ""),
        (0xFCB3, ""M"", ""صم""),
        (0xFCB4, ""M"", ""ضج""),
        (0xFCB5, ""M"", ""ضح""),
        (0xFCB6, ""M"", ""ضخ""),
        (0xFCB7, ""M"", ""ضم""),
        (0xFCB8, ""M"", ""طح""),
        (0xFCB9, ""M"", ""ظم""),
        (0xFCBA, ""M"", ""عج""),
        (0xFCBB, ""M"", ""عم""),
        (0xFCBC, ""M"", ""غج""),
        (0xFCBD, ""M"", ""غم""),
        (0xFCBE, ""M"", ""فج""),
    ]


def _seg_47() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0xFCBF, ""M"", ""فح""),
        (0xFCC0, ""M"", ""فخ""),
        (0xFCC1, ""M"", ""فم""),
        (0xFCC2, ""M"", ""قح""),
        (0xFCC3, ""M"", ""قم""),
        (0xFCC4, ""M"", ""كج""),
        (0xFCC5, ""M"", ""كح""),
        (0xFCC6, ""M"", ""كخ""),
        (0xFCC7, ""M"", ""كل""),
        (0xFCC8, ""M"", ""كم""),
        (0xFCC9, ""M"", ""لج""),
        (0xFCCA, ""M"", ""لح""),
        (0xFCCB, ""M"", ""لخ""),
        (0xFCCC, ""M"", ""لم""),
        (0xFCCD, ""M"", ""له""),
        (0xFCCE, ""M"", ""مج""),
        (0xFCCF, ""M"", ""مح""),
        (0xFCD0, ""M"", ""مخ""),
        (0xFCD1, ""M"", ""مم""),
        (0xFCD2, ""M"", ""نج""),
        (0xFCD3, ""M"", ""نح""),
        (0xFCD4, ""M"", ""نخ""),
        (0xFCD5, ""M"", ""نم""),
        (0xFCD6, ""M"", ""نه""),
        (0xFCD7, ""M"", ""هج""),
        (0xFCD8, ""M"", ""هم""),
        (0xFCD9, ""M"", ""هٰ""),
        (0xFCDA, ""M"", ""يج""),
        (0xFCDB, ""M"", ""يح""),
        (0xFCDC, ""M"", ""يخ""),
        (0xFCDD, ""M"", ""يم""),
        (0xFCDE, ""M"", ""يه""),
        (0xFCDF, ""M"", ""ئم""),
        (0xFCE0, ""M"", ""ئه""),
        (0xFCE1, ""M"", ""بم""),
        (0xFCE2, ""M"", ""به""),
        (0xFCE3, ""M"", ""تم""),
        (0xFCE4, ""M"", ""ته""),
        (0xFCE5, ""M"", ""ثم""),
        (0xFCE6, ""M"", ""ثه""),
        (0xFCE7, ""M"", ""سم""),
        (0xFCE8, ""M"", ""سه""),
        (0xFCE9, ""M"", ""شم""),
        (0xFCEA, ""M"", ""شه""),
        (0xFCEB, ""M"", ""كل""),
        (0xFCEC, ""M"", ""كم""),
        (0xFCED, ""M"", ""لم""),
        (0xFCEE, ""M"", ""نم""),
        (0xFCEF, ""M"", ""نه""),
        (0xFCF0, ""M"", ""يم""),
        (0xFCF1, ""M"", ""يه""),
        (0xFCF2, ""M"", ""ـَّ""),
        (0xFCF3, ""M"", ""ـُّ""),
        (0xFCF4, ""M"", ""ـِّ""),
        (0xFCF5, ""M"", ""طى""),
        (0xFCF6, ""M"", ""طي""),
        (0xFCF7, ""M"", ""عى""),
        (0xFCF8, ""M"", ""عي""),
        (0xFCF9, ""M"", ""غى""),
        (0xFCFA, ""M"", ""غي""),
        (0xFCFB, ""M"", ""سى""),
        (0xFCFC, ""M"", ""سي""),
        (0xFCFD, ""M"", ""شى""),
        (0xFCFE, ""M"", ""شي""),
        (0xFCFF, ""M"", ""حى""),
        (0xFD00, ""M"", ""حي""),
        (0xFD01, ""M"", ""جى""),
        (0xFD02, ""M"", ""جي""),
        (0xFD03, ""M"", ""خى""),
        (0xFD04, ""M"", ""خي""),
        (0xFD05, ""M"", ""صى""),
        (0xFD06, ""M"", ""صي""),
        (0xFD07, ""M"", ""ضى""),
        (0xFD08, ""M"", ""ضي""),
        (0xFD09, ""M"", ""شج""),
        (0xFD0A, ""M"", ""شح""),
        (0xFD0B, ""M"", ""شخ""),
        (0xFD0C, ""M"", ""شم""),
        (0xFD0D, ""M"", ""شر""),
        (0xFD0E, ""M"", ""سر""),
        (0xFD0F, ""M"", ""صر""),
        (0xFD10, ""M"", ""ضر""),
        (0xFD11, ""M"", ""طى""),
        (0xFD12, ""M"", ""طي""),
        (0xFD13, ""M"", ""عى""),
        (0xFD14, ""M"", ""عي""),
        (0xFD15, ""M"", ""غى""),
        (0xFD16, ""M"", ""غي""),
        (0xFD17, ""M"", ""سى""),
        (0xFD18, ""M"", ""سي""),
        (0xFD19, ""M"", ""شى""),
        (0xFD1A, ""M"", ""شي""),
        (0xFD1B, ""M"", ""حى""),
        (0xFD1C, ""M"", ""حي""),
        (0xFD1D, ""M"", ""جى""),
        (0xFD1E, ""M"", ""جي""),
        (0xFD1F, ""M"", ""خى""),
        (0xFD20, ""M"", ""خي""),
        (0xFD21, ""M"", ""صى""),
        (0xFD22, ""M"", ""صي""),
    ]


def _seg_48() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0xFD23, ""M"", ""ضى""),
        (0xFD24, ""M"", ""ضي""),
        (0xFD25, ""M"", ""شج""),
        (0xFD26, ""M"", ""شح""),
        (0xFD27, ""M"", ""شخ""),
        (0xFD28, ""M"", ""شم""),
        (0xFD29, ""M"", ""شر""),
        (0xFD2A, ""M"", ""سر""),
        (0xFD2B, ""M"", ""صر""),
        (0xFD2C, ""M"", ""ضر""),
        (0xFD2D, ""M"", ""شج""),
        (0xFD2E, ""M"", ""شح""),
        (0xFD2F, ""M"", ""شخ""),
        (0xFD30, ""M"", ""شم""),
        (0xFD31, ""M"", ""سه""),
        (0xFD32, ""M"", ""شه""),
        (0xFD33, ""M"", ""طم""),
        (0xFD34, ""M"", ""سج""),
        (0xFD35, ""M"", ""سح""),
        (0xFD36, ""M"", ""سخ""),
        (0xFD37, ""M"", ""شج""),
        (0xFD38, ""M"", ""شح""),
        (0xFD39, ""M"", ""شخ""),
        (0xFD3A, ""M"", ""طم""),
        (0xFD3B, ""M"", ""ظم""),
        (0xFD3C, ""M"", ""اً""),
        (0xFD3E, ""V""),
        (0xFD50, ""M"", ""تجم""),
        (0xFD51, ""M"", ""تحج""),
        (0xFD53, ""M"", ""تحم""),
        (0xFD54, ""M"", ""تخم""),
        (0xFD55, ""M"", ""تمج""),
        (0xFD56, ""M"", ""تمح""),
        (0xFD57, ""M"", ""تمخ""),
        (0xFD58, ""M"", ""جمح""),
        (0xFD5A, ""M"", ""حمي""),
        (0xFD5B, ""M"", ""حمى""),
        (0xFD5C, ""M"", ""سحج""),
        (0xFD5D, ""M"", ""سجح""),
        (0xFD5E, ""M"", ""سجى""),
        (0xFD5F, ""M"", ""سمح""),
        (0xFD61, ""M"", ""سمج""),
        (0xFD62, ""M"", ""سمم""),
        (0xFD64, ""M"", ""صحح""),
        (0xFD66, ""M"", ""صمم""),
        (0xFD67, ""M"", ""شحم""),
        (0xFD69, ""M"", ""شجي""),
        (0xFD6A, ""M"", ""شمخ""),
        (0xFD6C, ""M"", ""شمم""),
        (0xFD6E, ""M"", ""ضحى""),
        (0xFD6F, ""M"", ""ضخم""),
        (0xFD71, ""M"", ""طمح""),
        (0xFD73, ""M"", ""طمم""),
        (0xFD74, ""M"", ""طمي""),
        (0xFD75, ""M"", ""عجم""),
        (0xFD76, ""M"", ""عمم""),
        (0xFD78, ""M"", ""عمى""),
        (0xFD79, ""M"", ""غمم""),
        (0xFD7A, ""M"", ""غمي""),
        (0xFD7B, ""M"", ""غمى""),
        (0xFD7C, ""M"", ""فخم""),
        (0xFD7E, ""M"", ""قمح""),
        (0xFD7F, ""M"", ""قمم""),
        (0xFD80, ""M"", ""لحم""),
        (0xFD81, ""M"", ""لحي""),
        (0xFD82, ""M"", ""لحى""),
        (0xFD83, ""M"", ""لجج""),
        (0xFD85, ""M"", ""لخم""),
        (0xFD87, ""M"", ""لمح""),
        (0xFD89, ""M"", ""محج""),
        (0xFD8A, ""M"", ""محم""),
        (0xFD8B, ""M"", ""محي""),
        (0xFD8C, ""M"", ""مجح""),
        (0xFD8D, ""M"", ""مجم""),
        (0xFD8E, ""M"", ""مخج""),
        (0xFD8F, ""M"", ""مخم""),
        (0xFD90, ""X""),
        (0xFD92, ""M"", ""مجخ""),
        (0xFD93, ""M"", ""همج""),
        (0xFD94, ""M"", ""همم""),
        (0xFD95, ""M"", ""نحم""),
        (0xFD96, ""M"", ""نحى""),
        (0xFD97, ""M"", ""نجم""),
        (0xFD99, ""M"", ""نجى""),
        (0xFD9A, ""M"", ""نمي""),
        (0xFD9B, ""M"", ""نمى""),
        (0xFD9C, ""M"", ""يمم""),
        (0xFD9E, ""M"", ""بخي""),
        (0xFD9F, ""M"", ""تجي""),
        (0xFDA0, ""M"", ""تجى""),
        (0xFDA1, ""M"", ""تخي""),
        (0xFDA2, ""M"", ""تخى""),
        (0xFDA3, ""M"", ""تمي""),
        (0xFDA4, ""M"", ""تمى""),
        (0xFDA5, ""M"", ""جمي""),
        (0xFDA6, ""M"", ""جحى""),
        (0xFDA7, ""M"", ""جمى""),
        (0xFDA8, ""M"", ""سخى""),
        (0xFDA9, ""M"", ""صحي""),
        (0xFDAA, ""M"", ""شحي""),
    ]


def _seg_49() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0xFDAB, ""M"", ""ضحي""),
        (0xFDAC, ""M"", ""لجي""),
        (0xFDAD, ""M"", ""لمي""),
        (0xFDAE, ""M"", ""يحي""),
        (0xFDAF, ""M"", ""يجي""),
        (0xFDB0, ""M"", ""يمي""),
        (0xFDB1, ""M"", ""ممي""),
        (0xFDB2, ""M"", ""قمي""),
        (0xFDB3, ""M"", ""نحي""),
        (0xFDB4, ""M"", ""قمح""),
        (0xFDB5, ""M"", ""لحم""),
        (0xFDB6, ""M"", ""عمي""),
        (0xFDB7, ""M"", ""كمي""),
        (0xFDB8, ""M"", ""نجح""),
        (0xFDB9, ""M"", ""مخي""),
        (0xFDBA, ""M"", ""لجم""),
        (0xFDBB, ""M"", ""كمم""),
        (0xFDBC, ""M"", ""لجم""),
        (0xFDBD, ""M"", ""نجح""),
        (0xFDBE, ""M"", ""جحي""),
        (0xFDBF, ""M"", ""حجي""),
        (0xFDC0, ""M"", ""مجي""),
        (0xFDC1, ""M"", ""فمي""),
        (0xFDC2, ""M"", ""بحي""),
        (0xFDC3, ""M"", ""كمم""),
        (0xFDC4, ""M"", ""عجم""),
        (0xFDC5, ""M"", ""صمم""),
        (0xFDC6, ""M"", ""سخي""),
        (0xFDC7, ""M"", ""نجي""),
        (0xFDC8, ""X""),
        (0xFDCF, ""V""),
        (0xFDD0, ""X""),
        (0xFDF0, ""M"", ""صلے""),
        (0xFDF1, ""M"", ""قلے""),
        (0xFDF2, ""M"", ""الله""),
        (0xFDF3, ""M"", ""اكبر""),
        (0xFDF4, ""M"", ""محمد""),
        (0xFDF5, ""M"", ""صلعم""),
        (0xFDF6, ""M"", ""رسول""),
        (0xFDF7, ""M"", ""عليه""),
        (0xFDF8, ""M"", ""وسلم""),
        (0xFDF9, ""M"", ""صلى""),
        (0xFDFA, ""3"", ""صلى الله عليه وسلم""),
        (0xFDFB, ""3"", ""جل جلاله""),
        (0xFDFC, ""M"", ""ریال""),
        (0xFDFD, ""V""),
        (0xFE00, ""I""),
        (0xFE10, ""3"", "",""),
        (0xFE11, ""M"", ""、""),
        (0xFE12, ""X""),
        (0xFE13, ""3"", "":""),
        (0xFE14, ""3"", "";""),
        (0xFE15, ""3"", ""!""),
        (0xFE16, ""3"", ""?""),
        (0xFE17, ""M"", ""〖""),
        (0xFE18, ""M"", ""〗""),
        (0xFE19, ""X""),
        (0xFE20, ""V""),
        (0xFE30, ""X""),
        (0xFE31, ""M"", ""—""),
        (0xFE32, ""M"", ""–""),
        (0xFE33, ""3"", ""_""),
        (0xFE35, ""3"", ""(""),
        (0xFE36, ""3"", "")""),
        (0xFE37, ""3"", ""{""),
        (0xFE38, ""3"", ""}""),
        (0xFE39, ""M"", ""〔""),
        (0xFE3A, ""M"", ""〕""),
        (0xFE3B, ""M"", ""【""),
        (0xFE3C, ""M"", ""】""),
        (0xFE3D, ""M"", ""《""),
        (0xFE3E, ""M"", ""》""),
        (0xFE3F, ""M"", ""〈""),
        (0xFE40, ""M"", ""〉""),
        (0xFE41, ""M"", ""「""),
        (0xFE42, ""M"", ""」""),
        (0xFE43, ""M"", ""『""),
        (0xFE44, ""M"", ""』""),
        (0xFE45, ""V""),
        (0xFE47, ""3"", ""[""),
        (0xFE48, ""3"", ""]""),
        (0xFE49, ""3"", "" ̅""),
        (0xFE4D, ""3"", ""_""),
        (0xFE50, ""3"", "",""),
        (0xFE51, ""M"", ""、""),
        (0xFE52, ""X""),
        (0xFE54, ""3"", "";""),
        (0xFE55, ""3"", "":""),
        (0xFE56, ""3"", ""?""),
        (0xFE57, ""3"", ""!""),
        (0xFE58, ""M"", ""—""),
        (0xFE59, ""3"", ""(""),
        (0xFE5A, ""3"", "")""),
        (0xFE5B, ""3"", ""{""),
        (0xFE5C, ""3"", ""}""),
        (0xFE5D, ""M"", ""〔""),
        (0xFE5E, ""M"", ""〕""),
        (0xFE5F, ""3"", ""
        (0xFE60, ""3"", ""&""),
        (0xFE61, ""3"", ""*""),
    ]


def _seg_50() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0xFE62, ""3"", ""+""),
        (0xFE63, ""M"", ""-""),
        (0xFE64, ""3"", ""<""),
        (0xFE65, ""3"", "">""),
        (0xFE66, ""3"", ""=""),
        (0xFE67, ""X""),
        (0xFE68, ""3"", ""\\""),
        (0xFE69, ""3"", ""$""),
        (0xFE6A, ""3"", ""%""),
        (0xFE6B, ""3"", ""@""),
        (0xFE6C, ""X""),
        (0xFE70, ""3"", "" ً""),
        (0xFE71, ""M"", ""ـً""),
        (0xFE72, ""3"", "" ٌ""),
        (0xFE73, ""V""),
        (0xFE74, ""3"", "" ٍ""),
        (0xFE75, ""X""),
        (0xFE76, ""3"", "" َ""),
        (0xFE77, ""M"", ""ـَ""),
        (0xFE78, ""3"", "" ُ""),
        (0xFE79, ""M"", ""ـُ""),
        (0xFE7A, ""3"", "" ِ""),
        (0xFE7B, ""M"", ""ـِ""),
        (0xFE7C, ""3"", "" ّ""),
        (0xFE7D, ""M"", ""ـّ""),
        (0xFE7E, ""3"", "" ْ""),
        (0xFE7F, ""M"", ""ـْ""),
        (0xFE80, ""M"", ""ء""),
        (0xFE81, ""M"", ""آ""),
        (0xFE83, ""M"", ""أ""),
        (0xFE85, ""M"", ""ؤ""),
        (0xFE87, ""M"", ""إ""),
        (0xFE89, ""M"", ""ئ""),
        (0xFE8D, ""M"", ""ا""),
        (0xFE8F, ""M"", ""ب""),
        (0xFE93, ""M"", ""ة""),
        (0xFE95, ""M"", ""ت""),
        (0xFE99, ""M"", ""ث""),
        (0xFE9D, ""M"", ""ج""),
        (0xFEA1, ""M"", ""ح""),
        (0xFEA5, ""M"", ""خ""),
        (0xFEA9, ""M"", ""د""),
        (0xFEAB, ""M"", ""ذ""),
        (0xFEAD, ""M"", ""ر""),
        (0xFEAF, ""M"", ""ز""),
        (0xFEB1, ""M"", ""س""),
        (0xFEB5, ""M"", ""ش""),
        (0xFEB9, ""M"", ""ص""),
        (0xFEBD, ""M"", ""ض""),
        (0xFEC1, ""M"", ""ط""),
        (0xFEC5, ""M"", ""ظ""),
        (0xFEC9, ""M"", ""ع""),
        (0xFECD, ""M"", ""غ""),
        (0xFED1, ""M"", ""ف""),
        (0xFED5, ""M"", ""ق""),
        (0xFED9, ""M"", ""ك""),
        (0xFEDD, ""M"", ""ل""),
        (0xFEE1, ""M"", ""م""),
        (0xFEE5, ""M"", ""ن""),
        (0xFEE9, ""M"", ""ه""),
        (0xFEED, ""M"", ""و""),
        (0xFEEF, ""M"", ""ى""),
        (0xFEF1, ""M"", ""ي""),
        (0xFEF5, ""M"", ""لآ""),
        (0xFEF7, ""M"", ""لأ""),
        (0xFEF9, ""M"", ""لإ""),
        (0xFEFB, ""M"", ""لا""),
        (0xFEFD, ""X""),
        (0xFEFF, ""I""),
        (0xFF00, ""X""),
        (0xFF01, ""3"", ""!""),
        (0xFF02, ""3"", '""'),
        (0xFF03, ""3"", ""
        (0xFF04, ""3"", ""$""),
        (0xFF05, ""3"", ""%""),
        (0xFF06, ""3"", ""&""),
        (0xFF07, ""3"", ""'""),
        (0xFF08, ""3"", ""(""),
        (0xFF09, ""3"", "")""),
        (0xFF0A, ""3"", ""*""),
        (0xFF0B, ""3"", ""+""),
        (0xFF0C, ""3"", "",""),
        (0xFF0D, ""M"", ""-""),
        (0xFF0E, ""M"", "".""),
        (0xFF0F, ""3"", ""/""),
        (0xFF10, ""M"", ""0""),
        (0xFF11, ""M"", ""1""),
        (0xFF12, ""M"", ""2""),
        (0xFF13, ""M"", ""3""),
        (0xFF14, ""M"", ""4""),
        (0xFF15, ""M"", ""5""),
        (0xFF16, ""M"", ""6""),
        (0xFF17, ""M"", ""7""),
        (0xFF18, ""M"", ""8""),
        (0xFF19, ""M"", ""9""),
        (0xFF1A, ""3"", "":""),
        (0xFF1B, ""3"", "";""),
        (0xFF1C, ""3"", ""<""),
        (0xFF1D, ""3"", ""=""),
        (0xFF1E, ""3"", "">""),
    ]


def _seg_51() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0xFF1F, ""3"", ""?""),
        (0xFF20, ""3"", ""@""),
        (0xFF21, ""M"", ""a""),
        (0xFF22, ""M"", ""b""),
        (0xFF23, ""M"", ""c""),
        (0xFF24, ""M"", ""d""),
        (0xFF25, ""M"", ""e""),
        (0xFF26, ""M"", ""f""),
        (0xFF27, ""M"", ""g""),
        (0xFF28, ""M"", ""h""),
        (0xFF29, ""M"", ""i""),
        (0xFF2A, ""M"", ""j""),
        (0xFF2B, ""M"", ""k""),
        (0xFF2C, ""M"", ""l""),
        (0xFF2D, ""M"", ""m""),
        (0xFF2E, ""M"", ""n""),
        (0xFF2F, ""M"", ""o""),
        (0xFF30, ""M"", ""p""),
        (0xFF31, ""M"", ""q""),
        (0xFF32, ""M"", ""r""),
        (0xFF33, ""M"", ""s""),
        (0xFF34, ""M"", ""t""),
        (0xFF35, ""M"", ""u""),
        (0xFF36, ""M"", ""v""),
        (0xFF37, ""M"", ""w""),
        (0xFF38, ""M"", ""x""),
        (0xFF39, ""M"", ""y""),
        (0xFF3A, ""M"", ""z""),
        (0xFF3B, ""3"", ""[""),
        (0xFF3C, ""3"", ""\\""),
        (0xFF3D, ""3"", ""]""),
        (0xFF3E, ""3"", ""^""),
        (0xFF3F, ""3"", ""_""),
        (0xFF40, ""3"", ""`""),
        (0xFF41, ""M"", ""a""),
        (0xFF42, ""M"", ""b""),
        (0xFF43, ""M"", ""c""),
        (0xFF44, ""M"", ""d""),
        (0xFF45, ""M"", ""e""),
        (0xFF46, ""M"", ""f""),
        (0xFF47, ""M"", ""g""),
        (0xFF48, ""M"", ""h""),
        (0xFF49, ""M"", ""i""),
        (0xFF4A, ""M"", ""j""),
        (0xFF4B, ""M"", ""k""),
        (0xFF4C, ""M"", ""l""),
        (0xFF4D, ""M"", ""m""),
        (0xFF4E, ""M"", ""n""),
        (0xFF4F, ""M"", ""o""),
        (0xFF50, ""M"", ""p""),
        (0xFF51, ""M"", ""q""),
        (0xFF52, ""M"", ""r""),
        (0xFF53, ""M"", ""s""),
        (0xFF54, ""M"", ""t""),
        (0xFF55, ""M"", ""u""),
        (0xFF56, ""M"", ""v""),
        (0xFF57, ""M"", ""w""),
        (0xFF58, ""M"", ""x""),
        (0xFF59, ""M"", ""y""),
        (0xFF5A, ""M"", ""z""),
        (0xFF5B, ""3"", ""{""),
        (0xFF5C, ""3"", ""|""),
        (0xFF5D, ""3"", ""}""),
        (0xFF5E, ""3"", ""~""),
        (0xFF5F, ""M"", ""⦅""),
        (0xFF60, ""M"", ""⦆""),
        (0xFF61, ""M"", "".""),
        (0xFF62, ""M"", ""「""),
        (0xFF63, ""M"", ""」""),
        (0xFF64, ""M"", ""、""),
        (0xFF65, ""M"", ""・""),
        (0xFF66, ""M"", ""ヲ""),
        (0xFF67, ""M"", ""ァ""),
        (0xFF68, ""M"", ""ィ""),
        (0xFF69, ""M"", ""ゥ""),
        (0xFF6A, ""M"", ""ェ""),
        (0xFF6B, ""M"", ""ォ""),
        (0xFF6C, ""M"", ""ャ""),
        (0xFF6D, ""M"", ""ュ""),
        (0xFF6E, ""M"", ""ョ""),
        (0xFF6F, ""M"", ""ッ""),
        (0xFF70, ""M"", ""ー""),
        (0xFF71, ""M"", ""ア""),
        (0xFF72, ""M"", ""イ""),
        (0xFF73, ""M"", ""ウ""),
        (0xFF74, ""M"", ""エ""),
        (0xFF75, ""M"", ""オ""),
        (0xFF76, ""M"", ""カ""),
        (0xFF77, ""M"", ""キ""),
        (0xFF78, ""M"", ""ク""),
        (0xFF79, ""M"", ""ケ""),
        (0xFF7A, ""M"", ""コ""),
        (0xFF7B, ""M"", ""サ""),
        (0xFF7C, ""M"", ""シ""),
        (0xFF7D, ""M"", ""ス""),
        (0xFF7E, ""M"", ""セ""),
        (0xFF7F, ""M"", ""ソ""),
        (0xFF80, ""M"", ""タ""),
        (0xFF81, ""M"", ""チ""),
        (0xFF82, ""M"", ""ツ""),
    ]


def _seg_52() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0xFF83, ""M"", ""テ""),
        (0xFF84, ""M"", ""ト""),
        (0xFF85, ""M"", ""ナ""),
        (0xFF86, ""M"", ""ニ""),
        (0xFF87, ""M"", ""ヌ""),
        (0xFF88, ""M"", ""ネ""),
        (0xFF89, ""M"", ""ノ""),
        (0xFF8A, ""M"", ""ハ""),
        (0xFF8B, ""M"", ""ヒ""),
        (0xFF8C, ""M"", ""フ""),
        (0xFF8D, ""M"", ""ヘ""),
        (0xFF8E, ""M"", ""ホ""),
        (0xFF8F, ""M"", ""マ""),
        (0xFF90, ""M"", ""ミ""),
        (0xFF91, ""M"", ""ム""),
        (0xFF92, ""M"", ""メ""),
        (0xFF93, ""M"", ""モ""),
        (0xFF94, ""M"", ""ヤ""),
        (0xFF95, ""M"", ""ユ""),
        (0xFF96, ""M"", ""ヨ""),
        (0xFF97, ""M"", ""ラ""),
        (0xFF98, ""M"", ""リ""),
        (0xFF99, ""M"", ""ル""),
        (0xFF9A, ""M"", ""レ""),
        (0xFF9B, ""M"", ""ロ""),
        (0xFF9C, ""M"", ""ワ""),
        (0xFF9D, ""M"", ""ン""),
        (0xFF9E, ""M"", ""゙""),
        (0xFF9F, ""M"", ""゚""),
        (0xFFA0, ""X""),
        (0xFFA1, ""M"", ""ᄀ""),
        (0xFFA2, ""M"", ""ᄁ""),
        (0xFFA3, ""M"", ""ᆪ""),
        (0xFFA4, ""M"", ""ᄂ""),
        (0xFFA5, ""M"", ""ᆬ""),
        (0xFFA6, ""M"", ""ᆭ""),
        (0xFFA7, ""M"", ""ᄃ""),
        (0xFFA8, ""M"", ""ᄄ""),
        (0xFFA9, ""M"", ""ᄅ""),
        (0xFFAA, ""M"", ""ᆰ""),
        (0xFFAB, ""M"", ""ᆱ""),
        (0xFFAC, ""M"", ""ᆲ""),
        (0xFFAD, ""M"", ""ᆳ""),
        (0xFFAE, ""M"", ""ᆴ""),
        (0xFFAF, ""M"", ""ᆵ""),
        (0xFFB0, ""M"", ""ᄚ""),
        (0xFFB1, ""M"", ""ᄆ""),
        (0xFFB2, ""M"", ""ᄇ""),
        (0xFFB3, ""M"", ""ᄈ""),
        (0xFFB4, ""M"", ""ᄡ""),
        (0xFFB5, ""M"", ""ᄉ""),
        (0xFFB6, ""M"", ""ᄊ""),
        (0xFFB7, ""M"", ""ᄋ""),
        (0xFFB8, ""M"", ""ᄌ""),
        (0xFFB9, ""M"", ""ᄍ""),
        (0xFFBA, ""M"", ""ᄎ""),
        (0xFFBB, ""M"", ""ᄏ""),
        (0xFFBC, ""M"", ""ᄐ""),
        (0xFFBD, ""M"", ""ᄑ""),
        (0xFFBE, ""M"", ""ᄒ""),
        (0xFFBF, ""X""),
        (0xFFC2, ""M"", ""ᅡ""),
        (0xFFC3, ""M"", ""ᅢ""),
        (0xFFC4, ""M"", ""ᅣ""),
        (0xFFC5, ""M"", ""ᅤ""),
        (0xFFC6, ""M"", ""ᅥ""),
        (0xFFC7, ""M"", ""ᅦ""),
        (0xFFC8, ""X""),
        (0xFFCA, ""M"", ""ᅧ""),
        (0xFFCB, ""M"", ""ᅨ""),
        (0xFFCC, ""M"", ""ᅩ""),
        (0xFFCD, ""M"", ""ᅪ""),
        (0xFFCE, ""M"", ""ᅫ""),
        (0xFFCF, ""M"", ""ᅬ""),
        (0xFFD0, ""X""),
        (0xFFD2, ""M"", ""ᅭ""),
        (0xFFD3, ""M"", ""ᅮ""),
        (0xFFD4, ""M"", ""ᅯ""),
        (0xFFD5, ""M"", ""ᅰ""),
        (0xFFD6, ""M"", ""ᅱ""),
        (0xFFD7, ""M"", ""ᅲ""),
        (0xFFD8, ""X""),
        (0xFFDA, ""M"", ""ᅳ""),
        (0xFFDB, ""M"", ""ᅴ""),
        (0xFFDC, ""M"", ""ᅵ""),
        (0xFFDD, ""X""),
        (0xFFE0, ""M"", ""¢""),
        (0xFFE1, ""M"", ""£""),
        (0xFFE2, ""M"", ""¬""),
        (0xFFE3, ""3"", "" ̄""),
        (0xFFE4, ""M"", ""¦""),
        (0xFFE5, ""M"", ""¥""),
        (0xFFE6, ""M"", ""₩""),
        (0xFFE7, ""X""),
        (0xFFE8, ""M"", ""│""),
        (0xFFE9, ""M"", ""←""),
        (0xFFEA, ""M"", ""↑""),
        (0xFFEB, ""M"", ""→""),
        (0xFFEC, ""M"", ""↓""),
        (0xFFED, ""M"", ""■""),
    ]


def _seg_53() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0xFFEE, ""M"", ""○""),
        (0xFFEF, ""X""),
        (0x10000, ""V""),
        (0x1000C, ""X""),
        (0x1000D, ""V""),
        (0x10027, ""X""),
        (0x10028, ""V""),
        (0x1003B, ""X""),
        (0x1003C, ""V""),
        (0x1003E, ""X""),
        (0x1003F, ""V""),
        (0x1004E, ""X""),
        (0x10050, ""V""),
        (0x1005E, ""X""),
        (0x10080, ""V""),
        (0x100FB, ""X""),
        (0x10100, ""V""),
        (0x10103, ""X""),
        (0x10107, ""V""),
        (0x10134, ""X""),
        (0x10137, ""V""),
        (0x1018F, ""X""),
        (0x10190, ""V""),
        (0x1019D, ""X""),
        (0x101A0, ""V""),
        (0x101A1, ""X""),
        (0x101D0, ""V""),
        (0x101FE, ""X""),
        (0x10280, ""V""),
        (0x1029D, ""X""),
        (0x102A0, ""V""),
        (0x102D1, ""X""),
        (0x102E0, ""V""),
        (0x102FC, ""X""),
        (0x10300, ""V""),
        (0x10324, ""X""),
        (0x1032D, ""V""),
        (0x1034B, ""X""),
        (0x10350, ""V""),
        (0x1037B, ""X""),
        (0x10380, ""V""),
        (0x1039E, ""X""),
        (0x1039F, ""V""),
        (0x103C4, ""X""),
        (0x103C8, ""V""),
        (0x103D6, ""X""),
        (0x10400, ""M"", ""𐐨""),
        (0x10401, ""M"", ""𐐩""),
        (0x10402, ""M"", ""𐐪""),
        (0x10403, ""M"", ""𐐫""),
        (0x10404, ""M"", ""𐐬""),
        (0x10405, ""M"", ""𐐭""),
        (0x10406, ""M"", ""𐐮""),
        (0x10407, ""M"", ""𐐯""),
        (0x10408, ""M"", ""𐐰""),
        (0x10409, ""M"", ""𐐱""),
        (0x1040A, ""M"", ""𐐲""),
        (0x1040B, ""M"", ""𐐳""),
        (0x1040C, ""M"", ""𐐴""),
        (0x1040D, ""M"", ""𐐵""),
        (0x1040E, ""M"", ""𐐶""),
        (0x1040F, ""M"", ""𐐷""),
        (0x10410, ""M"", ""𐐸""),
        (0x10411, ""M"", ""𐐹""),
        (0x10412, ""M"", ""𐐺""),
        (0x10413, ""M"", ""𐐻""),
        (0x10414, ""M"", ""𐐼""),
        (0x10415, ""M"", ""𐐽""),
        (0x10416, ""M"", ""𐐾""),
        (0x10417, ""M"", ""𐐿""),
        (0x10418, ""M"", ""𐑀""),
        (0x10419, ""M"", ""𐑁""),
        (0x1041A, ""M"", ""𐑂""),
        (0x1041B, ""M"", ""𐑃""),
        (0x1041C, ""M"", ""𐑄""),
        (0x1041D, ""M"", ""𐑅""),
        (0x1041E, ""M"", ""𐑆""),
        (0x1041F, ""M"", ""𐑇""),
        (0x10420, ""M"", ""𐑈""),
        (0x10421, ""M"", ""𐑉""),
        (0x10422, ""M"", ""𐑊""),
        (0x10423, ""M"", ""𐑋""),
        (0x10424, ""M"", ""𐑌""),
        (0x10425, ""M"", ""𐑍""),
        (0x10426, ""M"", ""𐑎""),
        (0x10427, ""M"", ""𐑏""),
        (0x10428, ""V""),
        (0x1049E, ""X""),
        (0x104A0, ""V""),
        (0x104AA, ""X""),
        (0x104B0, ""M"", ""𐓘""),
        (0x104B1, ""M"", ""𐓙""),
        (0x104B2, ""M"", ""𐓚""),
        (0x104B3, ""M"", ""𐓛""),
        (0x104B4, ""M"", ""𐓜""),
        (0x104B5, ""M"", ""𐓝""),
        (0x104B6, ""M"", ""𐓞""),
        (0x104B7, ""M"", ""𐓟""),
        (0x104B8, ""M"", ""𐓠""),
        (0x104B9, ""M"", ""𐓡""),
    ]


def _seg_54() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x104BA, ""M"", ""𐓢""),
        (0x104BB, ""M"", ""𐓣""),
        (0x104BC, ""M"", ""𐓤""),
        (0x104BD, ""M"", ""𐓥""),
        (0x104BE, ""M"", ""𐓦""),
        (0x104BF, ""M"", ""𐓧""),
        (0x104C0, ""M"", ""𐓨""),
        (0x104C1, ""M"", ""𐓩""),
        (0x104C2, ""M"", ""𐓪""),
        (0x104C3, ""M"", ""𐓫""),
        (0x104C4, ""M"", ""𐓬""),
        (0x104C5, ""M"", ""𐓭""),
        (0x104C6, ""M"", ""𐓮""),
        (0x104C7, ""M"", ""𐓯""),
        (0x104C8, ""M"", ""𐓰""),
        (0x104C9, ""M"", ""𐓱""),
        (0x104CA, ""M"", ""𐓲""),
        (0x104CB, ""M"", ""𐓳""),
        (0x104CC, ""M"", ""𐓴""),
        (0x104CD, ""M"", ""𐓵""),
        (0x104CE, ""M"", ""𐓶""),
        (0x104CF, ""M"", ""𐓷""),
        (0x104D0, ""M"", ""𐓸""),
        (0x104D1, ""M"", ""𐓹""),
        (0x104D2, ""M"", ""𐓺""),
        (0x104D3, ""M"", ""𐓻""),
        (0x104D4, ""X""),
        (0x104D8, ""V""),
        (0x104FC, ""X""),
        (0x10500, ""V""),
        (0x10528, ""X""),
        (0x10530, ""V""),
        (0x10564, ""X""),
        (0x1056F, ""V""),
        (0x10570, ""M"", ""𐖗""),
        (0x10571, ""M"", ""𐖘""),
        (0x10572, ""M"", ""𐖙""),
        (0x10573, ""M"", ""𐖚""),
        (0x10574, ""M"", ""𐖛""),
        (0x10575, ""M"", ""𐖜""),
        (0x10576, ""M"", ""𐖝""),
        (0x10577, ""M"", ""𐖞""),
        (0x10578, ""M"", ""𐖟""),
        (0x10579, ""M"", ""𐖠""),
        (0x1057A, ""M"", ""𐖡""),
        (0x1057B, ""X""),
        (0x1057C, ""M"", ""𐖣""),
        (0x1057D, ""M"", ""𐖤""),
        (0x1057E, ""M"", ""𐖥""),
        (0x1057F, ""M"", ""𐖦""),
        (0x10580, ""M"", ""𐖧""),
        (0x10581, ""M"", ""𐖨""),
        (0x10582, ""M"", ""𐖩""),
        (0x10583, ""M"", ""𐖪""),
        (0x10584, ""M"", ""𐖫""),
        (0x10585, ""M"", ""𐖬""),
        (0x10586, ""M"", ""𐖭""),
        (0x10587, ""M"", ""𐖮""),
        (0x10588, ""M"", ""𐖯""),
        (0x10589, ""M"", ""𐖰""),
        (0x1058A, ""M"", ""𐖱""),
        (0x1058B, ""X""),
        (0x1058C, ""M"", ""𐖳""),
        (0x1058D, ""M"", ""𐖴""),
        (0x1058E, ""M"", ""𐖵""),
        (0x1058F, ""M"", ""𐖶""),
        (0x10590, ""M"", ""𐖷""),
        (0x10591, ""M"", ""𐖸""),
        (0x10592, ""M"", ""𐖹""),
        (0x10593, ""X""),
        (0x10594, ""M"", ""𐖻""),
        (0x10595, ""M"", ""𐖼""),
        (0x10596, ""X""),
        (0x10597, ""V""),
        (0x105A2, ""X""),
        (0x105A3, ""V""),
        (0x105B2, ""X""),
        (0x105B3, ""V""),
        (0x105BA, ""X""),
        (0x105BB, ""V""),
        (0x105BD, ""X""),
        (0x10600, ""V""),
        (0x10737, ""X""),
        (0x10740, ""V""),
        (0x10756, ""X""),
        (0x10760, ""V""),
        (0x10768, ""X""),
        (0x10780, ""V""),
        (0x10781, ""M"", ""ː""),
        (0x10782, ""M"", ""ˑ""),
        (0x10783, ""M"", ""æ""),
        (0x10784, ""M"", ""ʙ""),
        (0x10785, ""M"", ""ɓ""),
        (0x10786, ""X""),
        (0x10787, ""M"", ""ʣ""),
        (0x10788, ""M"", ""ꭦ""),
        (0x10789, ""M"", ""ʥ""),
        (0x1078A, ""M"", ""ʤ""),
        (0x1078B, ""M"", ""ɖ""),
        (0x1078C, ""M"", ""ɗ""),
    ]


def _seg_55() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x1078D, ""M"", ""ᶑ""),
        (0x1078E, ""M"", ""ɘ""),
        (0x1078F, ""M"", ""ɞ""),
        (0x10790, ""M"", ""ʩ""),
        (0x10791, ""M"", ""ɤ""),
        (0x10792, ""M"", ""ɢ""),
        (0x10793, ""M"", ""ɠ""),
        (0x10794, ""M"", ""ʛ""),
        (0x10795, ""M"", ""ħ""),
        (0x10796, ""M"", ""ʜ""),
        (0x10797, ""M"", ""ɧ""),
        (0x10798, ""M"", ""ʄ""),
        (0x10799, ""M"", ""ʪ""),
        (0x1079A, ""M"", ""ʫ""),
        (0x1079B, ""M"", ""ɬ""),
        (0x1079C, ""M"", ""𝼄""),
        (0x1079D, ""M"", ""ꞎ""),
        (0x1079E, ""M"", ""ɮ""),
        (0x1079F, ""M"", ""𝼅""),
        (0x107A0, ""M"", ""ʎ""),
        (0x107A1, ""M"", ""𝼆""),
        (0x107A2, ""M"", ""ø""),
        (0x107A3, ""M"", ""ɶ""),
        (0x107A4, ""M"", ""ɷ""),
        (0x107A5, ""M"", ""q""),
        (0x107A6, ""M"", ""ɺ""),
        (0x107A7, ""M"", ""𝼈""),
        (0x107A8, ""M"", ""ɽ""),
        (0x107A9, ""M"", ""ɾ""),
        (0x107AA, ""M"", ""ʀ""),
        (0x107AB, ""M"", ""ʨ""),
        (0x107AC, ""M"", ""ʦ""),
        (0x107AD, ""M"", ""ꭧ""),
        (0x107AE, ""M"", ""ʧ""),
        (0x107AF, ""M"", ""ʈ""),
        (0x107B0, ""M"", ""ⱱ""),
        (0x107B1, ""X""),
        (0x107B2, ""M"", ""ʏ""),
        (0x107B3, ""M"", ""ʡ""),
        (0x107B4, ""M"", ""ʢ""),
        (0x107B5, ""M"", ""ʘ""),
        (0x107B6, ""M"", ""ǀ""),
        (0x107B7, ""M"", ""ǁ""),
        (0x107B8, ""M"", ""ǂ""),
        (0x107B9, ""M"", ""𝼊""),
        (0x107BA, ""M"", ""𝼞""),
        (0x107BB, ""X""),
        (0x10800, ""V""),
        (0x10806, ""X""),
        (0x10808, ""V""),
        (0x10809, ""X""),
        (0x1080A, ""V""),
        (0x10836, ""X""),
        (0x10837, ""V""),
        (0x10839, ""X""),
        (0x1083C, ""V""),
        (0x1083D, ""X""),
        (0x1083F, ""V""),
        (0x10856, ""X""),
        (0x10857, ""V""),
        (0x1089F, ""X""),
        (0x108A7, ""V""),
        (0x108B0, ""X""),
        (0x108E0, ""V""),
        (0x108F3, ""X""),
        (0x108F4, ""V""),
        (0x108F6, ""X""),
        (0x108FB, ""V""),
        (0x1091C, ""X""),
        (0x1091F, ""V""),
        (0x1093A, ""X""),
        (0x1093F, ""V""),
        (0x10940, ""X""),
        (0x10980, ""V""),
        (0x109B8, ""X""),
        (0x109BC, ""V""),
        (0x109D0, ""X""),
        (0x109D2, ""V""),
        (0x10A04, ""X""),
        (0x10A05, ""V""),
        (0x10A07, ""X""),
        (0x10A0C, ""V""),
        (0x10A14, ""X""),
        (0x10A15, ""V""),
        (0x10A18, ""X""),
        (0x10A19, ""V""),
        (0x10A36, ""X""),
        (0x10A38, ""V""),
        (0x10A3B, ""X""),
        (0x10A3F, ""V""),
        (0x10A49, ""X""),
        (0x10A50, ""V""),
        (0x10A59, ""X""),
        (0x10A60, ""V""),
        (0x10AA0, ""X""),
        (0x10AC0, ""V""),
        (0x10AE7, ""X""),
        (0x10AEB, ""V""),
        (0x10AF7, ""X""),
        (0x10B00, ""V""),
    ]


def _seg_56() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x10B36, ""X""),
        (0x10B39, ""V""),
        (0x10B56, ""X""),
        (0x10B58, ""V""),
        (0x10B73, ""X""),
        (0x10B78, ""V""),
        (0x10B92, ""X""),
        (0x10B99, ""V""),
        (0x10B9D, ""X""),
        (0x10BA9, ""V""),
        (0x10BB0, ""X""),
        (0x10C00, ""V""),
        (0x10C49, ""X""),
        (0x10C80, ""M"", ""𐳀""),
        (0x10C81, ""M"", ""𐳁""),
        (0x10C82, ""M"", ""𐳂""),
        (0x10C83, ""M"", ""𐳃""),
        (0x10C84, ""M"", ""𐳄""),
        (0x10C85, ""M"", ""𐳅""),
        (0x10C86, ""M"", ""𐳆""),
        (0x10C87, ""M"", ""𐳇""),
        (0x10C88, ""M"", ""𐳈""),
        (0x10C89, ""M"", ""𐳉""),
        (0x10C8A, ""M"", ""𐳊""),
        (0x10C8B, ""M"", ""𐳋""),
        (0x10C8C, ""M"", ""𐳌""),
        (0x10C8D, ""M"", ""𐳍""),
        (0x10C8E, ""M"", ""𐳎""),
        (0x10C8F, ""M"", ""𐳏""),
        (0x10C90, ""M"", ""𐳐""),
        (0x10C91, ""M"", ""𐳑""),
        (0x10C92, ""M"", ""𐳒""),
        (0x10C93, ""M"", ""𐳓""),
        (0x10C94, ""M"", ""𐳔""),
        (0x10C95, ""M"", ""𐳕""),
        (0x10C96, ""M"", ""𐳖""),
        (0x10C97, ""M"", ""𐳗""),
        (0x10C98, ""M"", ""𐳘""),
        (0x10C99, ""M"", ""𐳙""),
        (0x10C9A, ""M"", ""𐳚""),
        (0x10C9B, ""M"", ""𐳛""),
        (0x10C9C, ""M"", ""𐳜""),
        (0x10C9D, ""M"", ""𐳝""),
        (0x10C9E, ""M"", ""𐳞""),
        (0x10C9F, ""M"", ""𐳟""),
        (0x10CA0, ""M"", ""𐳠""),
        (0x10CA1, ""M"", ""𐳡""),
        (0x10CA2, ""M"", ""𐳢""),
        (0x10CA3, ""M"", ""𐳣""),
        (0x10CA4, ""M"", ""𐳤""),
        (0x10CA5, ""M"", ""𐳥""),
        (0x10CA6, ""M"", ""𐳦""),
        (0x10CA7, ""M"", ""𐳧""),
        (0x10CA8, ""M"", ""𐳨""),
        (0x10CA9, ""M"", ""𐳩""),
        (0x10CAA, ""M"", ""𐳪""),
        (0x10CAB, ""M"", ""𐳫""),
        (0x10CAC, ""M"", ""𐳬""),
        (0x10CAD, ""M"", ""𐳭""),
        (0x10CAE, ""M"", ""𐳮""),
        (0x10CAF, ""M"", ""𐳯""),
        (0x10CB0, ""M"", ""𐳰""),
        (0x10CB1, ""M"", ""𐳱""),
        (0x10CB2, ""M"", ""𐳲""),
        (0x10CB3, ""X""),
        (0x10CC0, ""V""),
        (0x10CF3, ""X""),
        (0x10CFA, ""V""),
        (0x10D28, ""X""),
        (0x10D30, ""V""),
        (0x10D3A, ""X""),
        (0x10E60, ""V""),
        (0x10E7F, ""X""),
        (0x10E80, ""V""),
        (0x10EAA, ""X""),
        (0x10EAB, ""V""),
        (0x10EAE, ""X""),
        (0x10EB0, ""V""),
        (0x10EB2, ""X""),
        (0x10EFD, ""V""),
        (0x10F28, ""X""),
        (0x10F30, ""V""),
        (0x10F5A, ""X""),
        (0x10F70, ""V""),
        (0x10F8A, ""X""),
        (0x10FB0, ""V""),
        (0x10FCC, ""X""),
        (0x10FE0, ""V""),
        (0x10FF7, ""X""),
        (0x11000, ""V""),
        (0x1104E, ""X""),
        (0x11052, ""V""),
        (0x11076, ""X""),
        (0x1107F, ""V""),
        (0x110BD, ""X""),
        (0x110BE, ""V""),
        (0x110C3, ""X""),
        (0x110D0, ""V""),
        (0x110E9, ""X""),
        (0x110F0, ""V""),
    ]


def _seg_57() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x110FA, ""X""),
        (0x11100, ""V""),
        (0x11135, ""X""),
        (0x11136, ""V""),
        (0x11148, ""X""),
        (0x11150, ""V""),
        (0x11177, ""X""),
        (0x11180, ""V""),
        (0x111E0, ""X""),
        (0x111E1, ""V""),
        (0x111F5, ""X""),
        (0x11200, ""V""),
        (0x11212, ""X""),
        (0x11213, ""V""),
        (0x11242, ""X""),
        (0x11280, ""V""),
        (0x11287, ""X""),
        (0x11288, ""V""),
        (0x11289, ""X""),
        (0x1128A, ""V""),
        (0x1128E, ""X""),
        (0x1128F, ""V""),
        (0x1129E, ""X""),
        (0x1129F, ""V""),
        (0x112AA, ""X""),
        (0x112B0, ""V""),
        (0x112EB, ""X""),
        (0x112F0, ""V""),
        (0x112FA, ""X""),
        (0x11300, ""V""),
        (0x11304, ""X""),
        (0x11305, ""V""),
        (0x1130D, ""X""),
        (0x1130F, ""V""),
        (0x11311, ""X""),
        (0x11313, ""V""),
        (0x11329, ""X""),
        (0x1132A, ""V""),
        (0x11331, ""X""),
        (0x11332, ""V""),
        (0x11334, ""X""),
        (0x11335, ""V""),
        (0x1133A, ""X""),
        (0x1133B, ""V""),
        (0x11345, ""X""),
        (0x11347, ""V""),
        (0x11349, ""X""),
        (0x1134B, ""V""),
        (0x1134E, ""X""),
        (0x11350, ""V""),
        (0x11351, ""X""),
        (0x11357, ""V""),
        (0x11358, ""X""),
        (0x1135D, ""V""),
        (0x11364, ""X""),
        (0x11366, ""V""),
        (0x1136D, ""X""),
        (0x11370, ""V""),
        (0x11375, ""X""),
        (0x11400, ""V""),
        (0x1145C, ""X""),
        (0x1145D, ""V""),
        (0x11462, ""X""),
        (0x11480, ""V""),
        (0x114C8, ""X""),
        (0x114D0, ""V""),
        (0x114DA, ""X""),
        (0x11580, ""V""),
        (0x115B6, ""X""),
        (0x115B8, ""V""),
        (0x115DE, ""X""),
        (0x11600, ""V""),
        (0x11645, ""X""),
        (0x11650, ""V""),
        (0x1165A, ""X""),
        (0x11660, ""V""),
        (0x1166D, ""X""),
        (0x11680, ""V""),
        (0x116BA, ""X""),
        (0x116C0, ""V""),
        (0x116CA, ""X""),
        (0x11700, ""V""),
        (0x1171B, ""X""),
        (0x1171D, ""V""),
        (0x1172C, ""X""),
        (0x11730, ""V""),
        (0x11747, ""X""),
        (0x11800, ""V""),
        (0x1183C, ""X""),
        (0x118A0, ""M"", ""𑣀""),
        (0x118A1, ""M"", ""𑣁""),
        (0x118A2, ""M"", ""𑣂""),
        (0x118A3, ""M"", ""𑣃""),
        (0x118A4, ""M"", ""𑣄""),
        (0x118A5, ""M"", ""𑣅""),
        (0x118A6, ""M"", ""𑣆""),
        (0x118A7, ""M"", ""𑣇""),
        (0x118A8, ""M"", ""𑣈""),
        (0x118A9, ""M"", ""𑣉""),
        (0x118AA, ""M"", ""𑣊""),
    ]


def _seg_58() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x118AB, ""M"", ""𑣋""),
        (0x118AC, ""M"", ""𑣌""),
        (0x118AD, ""M"", ""𑣍""),
        (0x118AE, ""M"", ""𑣎""),
        (0x118AF, ""M"", ""𑣏""),
        (0x118B0, ""M"", ""𑣐""),
        (0x118B1, ""M"", ""𑣑""),
        (0x118B2, ""M"", ""𑣒""),
        (0x118B3, ""M"", ""𑣓""),
        (0x118B4, ""M"", ""𑣔""),
        (0x118B5, ""M"", ""𑣕""),
        (0x118B6, ""M"", ""𑣖""),
        (0x118B7, ""M"", ""𑣗""),
        (0x118B8, ""M"", ""𑣘""),
        (0x118B9, ""M"", ""𑣙""),
        (0x118BA, ""M"", ""𑣚""),
        (0x118BB, ""M"", ""𑣛""),
        (0x118BC, ""M"", ""𑣜""),
        (0x118BD, ""M"", ""𑣝""),
        (0x118BE, ""M"", ""𑣞""),
        (0x118BF, ""M"", ""𑣟""),
        (0x118C0, ""V""),
        (0x118F3, ""X""),
        (0x118FF, ""V""),
        (0x11907, ""X""),
        (0x11909, ""V""),
        (0x1190A, ""X""),
        (0x1190C, ""V""),
        (0x11914, ""X""),
        (0x11915, ""V""),
        (0x11917, ""X""),
        (0x11918, ""V""),
        (0x11936, ""X""),
        (0x11937, ""V""),
        (0x11939, ""X""),
        (0x1193B, ""V""),
        (0x11947, ""X""),
        (0x11950, ""V""),
        (0x1195A, ""X""),
        (0x119A0, ""V""),
        (0x119A8, ""X""),
        (0x119AA, ""V""),
        (0x119D8, ""X""),
        (0x119DA, ""V""),
        (0x119E5, ""X""),
        (0x11A00, ""V""),
        (0x11A48, ""X""),
        (0x11A50, ""V""),
        (0x11AA3, ""X""),
        (0x11AB0, ""V""),
        (0x11AF9, ""X""),
        (0x11B00, ""V""),
        (0x11B0A, ""X""),
        (0x11C00, ""V""),
        (0x11C09, ""X""),
        (0x11C0A, ""V""),
        (0x11C37, ""X""),
        (0x11C38, ""V""),
        (0x11C46, ""X""),
        (0x11C50, ""V""),
        (0x11C6D, ""X""),
        (0x11C70, ""V""),
        (0x11C90, ""X""),
        (0x11C92, ""V""),
        (0x11CA8, ""X""),
        (0x11CA9, ""V""),
        (0x11CB7, ""X""),
        (0x11D00, ""V""),
        (0x11D07, ""X""),
        (0x11D08, ""V""),
        (0x11D0A, ""X""),
        (0x11D0B, ""V""),
        (0x11D37, ""X""),
        (0x11D3A, ""V""),
        (0x11D3B, ""X""),
        (0x11D3C, ""V""),
        (0x11D3E, ""X""),
        (0x11D3F, ""V""),
        (0x11D48, ""X""),
        (0x11D50, ""V""),
        (0x11D5A, ""X""),
        (0x11D60, ""V""),
        (0x11D66, ""X""),
        (0x11D67, ""V""),
        (0x11D69, ""X""),
        (0x11D6A, ""V""),
        (0x11D8F, ""X""),
        (0x11D90, ""V""),
        (0x11D92, ""X""),
        (0x11D93, ""V""),
        (0x11D99, ""X""),
        (0x11DA0, ""V""),
        (0x11DAA, ""X""),
        (0x11EE0, ""V""),
        (0x11EF9, ""X""),
        (0x11F00, ""V""),
        (0x11F11, ""X""),
        (0x11F12, ""V""),
        (0x11F3B, ""X""),
        (0x11F3E, ""V""),
    ]


def _seg_59() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x11F5A, ""X""),
        (0x11FB0, ""V""),
        (0x11FB1, ""X""),
        (0x11FC0, ""V""),
        (0x11FF2, ""X""),
        (0x11FFF, ""V""),
        (0x1239A, ""X""),
        (0x12400, ""V""),
        (0x1246F, ""X""),
        (0x12470, ""V""),
        (0x12475, ""X""),
        (0x12480, ""V""),
        (0x12544, ""X""),
        (0x12F90, ""V""),
        (0x12FF3, ""X""),
        (0x13000, ""V""),
        (0x13430, ""X""),
        (0x13440, ""V""),
        (0x13456, ""X""),
        (0x14400, ""V""),
        (0x14647, ""X""),
        (0x16800, ""V""),
        (0x16A39, ""X""),
        (0x16A40, ""V""),
        (0x16A5F, ""X""),
        (0x16A60, ""V""),
        (0x16A6A, ""X""),
        (0x16A6E, ""V""),
        (0x16ABF, ""X""),
        (0x16AC0, ""V""),
        (0x16ACA, ""X""),
        (0x16AD0, ""V""),
        (0x16AEE, ""X""),
        (0x16AF0, ""V""),
        (0x16AF6, ""X""),
        (0x16B00, ""V""),
        (0x16B46, ""X""),
        (0x16B50, ""V""),
        (0x16B5A, ""X""),
        (0x16B5B, ""V""),
        (0x16B62, ""X""),
        (0x16B63, ""V""),
        (0x16B78, ""X""),
        (0x16B7D, ""V""),
        (0x16B90, ""X""),
        (0x16E40, ""M"", ""𖹠""),
        (0x16E41, ""M"", ""𖹡""),
        (0x16E42, ""M"", ""𖹢""),
        (0x16E43, ""M"", ""𖹣""),
        (0x16E44, ""M"", ""𖹤""),
        (0x16E45, ""M"", ""𖹥""),
        (0x16E46, ""M"", ""𖹦""),
        (0x16E47, ""M"", ""𖹧""),
        (0x16E48, ""M"", ""𖹨""),
        (0x16E49, ""M"", ""𖹩""),
        (0x16E4A, ""M"", ""𖹪""),
        (0x16E4B, ""M"", ""𖹫""),
        (0x16E4C, ""M"", ""𖹬""),
        (0x16E4D, ""M"", ""𖹭""),
        (0x16E4E, ""M"", ""𖹮""),
        (0x16E4F, ""M"", ""𖹯""),
        (0x16E50, ""M"", ""𖹰""),
        (0x16E51, ""M"", ""𖹱""),
        (0x16E52, ""M"", ""𖹲""),
        (0x16E53, ""M"", ""𖹳""),
        (0x16E54, ""M"", ""𖹴""),
        (0x16E55, ""M"", ""𖹵""),
        (0x16E56, ""M"", ""𖹶""),
        (0x16E57, ""M"", ""𖹷""),
        (0x16E58, ""M"", ""𖹸""),
        (0x16E59, ""M"", ""𖹹""),
        (0x16E5A, ""M"", ""𖹺""),
        (0x16E5B, ""M"", ""𖹻""),
        (0x16E5C, ""M"", ""𖹼""),
        (0x16E5D, ""M"", ""𖹽""),
        (0x16E5E, ""M"", ""𖹾""),
        (0x16E5F, ""M"", ""𖹿""),
        (0x16E60, ""V""),
        (0x16E9B, ""X""),
        (0x16F00, ""V""),
        (0x16F4B, ""X""),
        (0x16F4F, ""V""),
        (0x16F88, ""X""),
        (0x16F8F, ""V""),
        (0x16FA0, ""X""),
        (0x16FE0, ""V""),
        (0x16FE5, ""X""),
        (0x16FF0, ""V""),
        (0x16FF2, ""X""),
        (0x17000, ""V""),
        (0x187F8, ""X""),
        (0x18800, ""V""),
        (0x18CD6, ""X""),
        (0x18D00, ""V""),
        (0x18D09, ""X""),
        (0x1AFF0, ""V""),
        (0x1AFF4, ""X""),
        (0x1AFF5, ""V""),
        (0x1AFFC, ""X""),
        (0x1AFFD, ""V""),
    ]


def _seg_60() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x1AFFF, ""X""),
        (0x1B000, ""V""),
        (0x1B123, ""X""),
        (0x1B132, ""V""),
        (0x1B133, ""X""),
        (0x1B150, ""V""),
        (0x1B153, ""X""),
        (0x1B155, ""V""),
        (0x1B156, ""X""),
        (0x1B164, ""V""),
        (0x1B168, ""X""),
        (0x1B170, ""V""),
        (0x1B2FC, ""X""),
        (0x1BC00, ""V""),
        (0x1BC6B, ""X""),
        (0x1BC70, ""V""),
        (0x1BC7D, ""X""),
        (0x1BC80, ""V""),
        (0x1BC89, ""X""),
        (0x1BC90, ""V""),
        (0x1BC9A, ""X""),
        (0x1BC9C, ""V""),
        (0x1BCA0, ""I""),
        (0x1BCA4, ""X""),
        (0x1CF00, ""V""),
        (0x1CF2E, ""X""),
        (0x1CF30, ""V""),
        (0x1CF47, ""X""),
        (0x1CF50, ""V""),
        (0x1CFC4, ""X""),
        (0x1D000, ""V""),
        (0x1D0F6, ""X""),
        (0x1D100, ""V""),
        (0x1D127, ""X""),
        (0x1D129, ""V""),
        (0x1D15E, ""M"", ""𝅗𝅥""),
        (0x1D15F, ""M"", ""𝅘𝅥""),
        (0x1D160, ""M"", ""𝅘𝅥𝅮""),
        (0x1D161, ""M"", ""𝅘𝅥𝅯""),
        (0x1D162, ""M"", ""𝅘𝅥𝅰""),
        (0x1D163, ""M"", ""𝅘𝅥𝅱""),
        (0x1D164, ""M"", ""𝅘𝅥𝅲""),
        (0x1D165, ""V""),
        (0x1D173, ""X""),
        (0x1D17B, ""V""),
        (0x1D1BB, ""M"", ""𝆹𝅥""),
        (0x1D1BC, ""M"", ""𝆺𝅥""),
        (0x1D1BD, ""M"", ""𝆹𝅥𝅮""),
        (0x1D1BE, ""M"", ""𝆺𝅥𝅮""),
        (0x1D1BF, ""M"", ""𝆹𝅥𝅯""),
        (0x1D1C0, ""M"", ""𝆺𝅥𝅯""),
        (0x1D1C1, ""V""),
        (0x1D1EB, ""X""),
        (0x1D200, ""V""),
        (0x1D246, ""X""),
        (0x1D2C0, ""V""),
        (0x1D2D4, ""X""),
        (0x1D2E0, ""V""),
        (0x1D2F4, ""X""),
        (0x1D300, ""V""),
        (0x1D357, ""X""),
        (0x1D360, ""V""),
        (0x1D379, ""X""),
        (0x1D400, ""M"", ""a""),
        (0x1D401, ""M"", ""b""),
        (0x1D402, ""M"", ""c""),
        (0x1D403, ""M"", ""d""),
        (0x1D404, ""M"", ""e""),
        (0x1D405, ""M"", ""f""),
        (0x1D406, ""M"", ""g""),
        (0x1D407, ""M"", ""h""),
        (0x1D408, ""M"", ""i""),
        (0x1D409, ""M"", ""j""),
        (0x1D40A, ""M"", ""k""),
        (0x1D40B, ""M"", ""l""),
        (0x1D40C, ""M"", ""m""),
        (0x1D40D, ""M"", ""n""),
        (0x1D40E, ""M"", ""o""),
        (0x1D40F, ""M"", ""p""),
        (0x1D410, ""M"", ""q""),
        (0x1D411, ""M"", ""r""),
        (0x1D412, ""M"", ""s""),
        (0x1D413, ""M"", ""t""),
        (0x1D414, ""M"", ""u""),
        (0x1D415, ""M"", ""v""),
        (0x1D416, ""M"", ""w""),
        (0x1D417, ""M"", ""x""),
        (0x1D418, ""M"", ""y""),
        (0x1D419, ""M"", ""z""),
        (0x1D41A, ""M"", ""a""),
        (0x1D41B, ""M"", ""b""),
        (0x1D41C, ""M"", ""c""),
        (0x1D41D, ""M"", ""d""),
        (0x1D41E, ""M"", ""e""),
        (0x1D41F, ""M"", ""f""),
        (0x1D420, ""M"", ""g""),
        (0x1D421, ""M"", ""h""),
        (0x1D422, ""M"", ""i""),
        (0x1D423, ""M"", ""j""),
        (0x1D424, ""M"", ""k""),
    ]


def _seg_61() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x1D425, ""M"", ""l""),
        (0x1D426, ""M"", ""m""),
        (0x1D427, ""M"", ""n""),
        (0x1D428, ""M"", ""o""),
        (0x1D429, ""M"", ""p""),
        (0x1D42A, ""M"", ""q""),
        (0x1D42B, ""M"", ""r""),
        (0x1D42C, ""M"", ""s""),
        (0x1D42D, ""M"", ""t""),
        (0x1D42E, ""M"", ""u""),
        (0x1D42F, ""M"", ""v""),
        (0x1D430, ""M"", ""w""),
        (0x1D431, ""M"", ""x""),
        (0x1D432, ""M"", ""y""),
        (0x1D433, ""M"", ""z""),
        (0x1D434, ""M"", ""a""),
        (0x1D435, ""M"", ""b""),
        (0x1D436, ""M"", ""c""),
        (0x1D437, ""M"", ""d""),
        (0x1D438, ""M"", ""e""),
        (0x1D439, ""M"", ""f""),
        (0x1D43A, ""M"", ""g""),
        (0x1D43B, ""M"", ""h""),
        (0x1D43C, ""M"", ""i""),
        (0x1D43D, ""M"", ""j""),
        (0x1D43E, ""M"", ""k""),
        (0x1D43F, ""M"", ""l""),
        (0x1D440, ""M"", ""m""),
        (0x1D441, ""M"", ""n""),
        (0x1D442, ""M"", ""o""),
        (0x1D443, ""M"", ""p""),
        (0x1D444, ""M"", ""q""),
        (0x1D445, ""M"", ""r""),
        (0x1D446, ""M"", ""s""),
        (0x1D447, ""M"", ""t""),
        (0x1D448, ""M"", ""u""),
        (0x1D449, ""M"", ""v""),
        (0x1D44A, ""M"", ""w""),
        (0x1D44B, ""M"", ""x""),
        (0x1D44C, ""M"", ""y""),
        (0x1D44D, ""M"", ""z""),
        (0x1D44E, ""M"", ""a""),
        (0x1D44F, ""M"", ""b""),
        (0x1D450, ""M"", ""c""),
        (0x1D451, ""M"", ""d""),
        (0x1D452, ""M"", ""e""),
        (0x1D453, ""M"", ""f""),
        (0x1D454, ""M"", ""g""),
        (0x1D455, ""X""),
        (0x1D456, ""M"", ""i""),
        (0x1D457, ""M"", ""j""),
        (0x1D458, ""M"", ""k""),
        (0x1D459, ""M"", ""l""),
        (0x1D45A, ""M"", ""m""),
        (0x1D45B, ""M"", ""n""),
        (0x1D45C, ""M"", ""o""),
        (0x1D45D, ""M"", ""p""),
        (0x1D45E, ""M"", ""q""),
        (0x1D45F, ""M"", ""r""),
        (0x1D460, ""M"", ""s""),
        (0x1D461, ""M"", ""t""),
        (0x1D462, ""M"", ""u""),
        (0x1D463, ""M"", ""v""),
        (0x1D464, ""M"", ""w""),
        (0x1D465, ""M"", ""x""),
        (0x1D466, ""M"", ""y""),
        (0x1D467, ""M"", ""z""),
        (0x1D468, ""M"", ""a""),
        (0x1D469, ""M"", ""b""),
        (0x1D46A, ""M"", ""c""),
        (0x1D46B, ""M"", ""d""),
        (0x1D46C, ""M"", ""e""),
        (0x1D46D, ""M"", ""f""),
        (0x1D46E, ""M"", ""g""),
        (0x1D46F, ""M"", ""h""),
        (0x1D470, ""M"", ""i""),
        (0x1D471, ""M"", ""j""),
        (0x1D472, ""M"", ""k""),
        (0x1D473, ""M"", ""l""),
        (0x1D474, ""M"", ""m""),
        (0x1D475, ""M"", ""n""),
        (0x1D476, ""M"", ""o""),
        (0x1D477, ""M"", ""p""),
        (0x1D478, ""M"", ""q""),
        (0x1D479, ""M"", ""r""),
        (0x1D47A, ""M"", ""s""),
        (0x1D47B, ""M"", ""t""),
        (0x1D47C, ""M"", ""u""),
        (0x1D47D, ""M"", ""v""),
        (0x1D47E, ""M"", ""w""),
        (0x1D47F, ""M"", ""x""),
        (0x1D480, ""M"", ""y""),
        (0x1D481, ""M"", ""z""),
        (0x1D482, ""M"", ""a""),
        (0x1D483, ""M"", ""b""),
        (0x1D484, ""M"", ""c""),
        (0x1D485, ""M"", ""d""),
        (0x1D486, ""M"", ""e""),
        (0x1D487, ""M"", ""f""),
        (0x1D488, ""M"", ""g""),
    ]


def _seg_62() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x1D489, ""M"", ""h""),
        (0x1D48A, ""M"", ""i""),
        (0x1D48B, ""M"", ""j""),
        (0x1D48C, ""M"", ""k""),
        (0x1D48D, ""M"", ""l""),
        (0x1D48E, ""M"", ""m""),
        (0x1D48F, ""M"", ""n""),
        (0x1D490, ""M"", ""o""),
        (0x1D491, ""M"", ""p""),
        (0x1D492, ""M"", ""q""),
        (0x1D493, ""M"", ""r""),
        (0x1D494, ""M"", ""s""),
        (0x1D495, ""M"", ""t""),
        (0x1D496, ""M"", ""u""),
        (0x1D497, ""M"", ""v""),
        (0x1D498, ""M"", ""w""),
        (0x1D499, ""M"", ""x""),
        (0x1D49A, ""M"", ""y""),
        (0x1D49B, ""M"", ""z""),
        (0x1D49C, ""M"", ""a""),
        (0x1D49D, ""X""),
        (0x1D49E, ""M"", ""c""),
        (0x1D49F, ""M"", ""d""),
        (0x1D4A0, ""X""),
        (0x1D4A2, ""M"", ""g""),
        (0x1D4A3, ""X""),
        (0x1D4A5, ""M"", ""j""),
        (0x1D4A6, ""M"", ""k""),
        (0x1D4A7, ""X""),
        (0x1D4A9, ""M"", ""n""),
        (0x1D4AA, ""M"", ""o""),
        (0x1D4AB, ""M"", ""p""),
        (0x1D4AC, ""M"", ""q""),
        (0x1D4AD, ""X""),
        (0x1D4AE, ""M"", ""s""),
        (0x1D4AF, ""M"", ""t""),
        (0x1D4B0, ""M"", ""u""),
        (0x1D4B1, ""M"", ""v""),
        (0x1D4B2, ""M"", ""w""),
        (0x1D4B3, ""M"", ""x""),
        (0x1D4B4, ""M"", ""y""),
        (0x1D4B5, ""M"", ""z""),
        (0x1D4B6, ""M"", ""a""),
        (0x1D4B7, ""M"", ""b""),
        (0x1D4B8, ""M"", ""c""),
        (0x1D4B9, ""M"", ""d""),
        (0x1D4BA, ""X""),
        (0x1D4BB, ""M"", ""f""),
        (0x1D4BC, ""X""),
        (0x1D4BD, ""M"", ""h""),
        (0x1D4BE, ""M"", ""i""),
        (0x1D4BF, ""M"", ""j""),
        (0x1D4C0, ""M"", ""k""),
        (0x1D4C1, ""M"", ""l""),
        (0x1D4C2, ""M"", ""m""),
        (0x1D4C3, ""M"", ""n""),
        (0x1D4C4, ""X""),
        (0x1D4C5, ""M"", ""p""),
        (0x1D4C6, ""M"", ""q""),
        (0x1D4C7, ""M"", ""r""),
        (0x1D4C8, ""M"", ""s""),
        (0x1D4C9, ""M"", ""t""),
        (0x1D4CA, ""M"", ""u""),
        (0x1D4CB, ""M"", ""v""),
        (0x1D4CC, ""M"", ""w""),
        (0x1D4CD, ""M"", ""x""),
        (0x1D4CE, ""M"", ""y""),
        (0x1D4CF, ""M"", ""z""),
        (0x1D4D0, ""M"", ""a""),
        (0x1D4D1, ""M"", ""b""),
        (0x1D4D2, ""M"", ""c""),
        (0x1D4D3, ""M"", ""d""),
        (0x1D4D4, ""M"", ""e""),
        (0x1D4D5, ""M"", ""f""),
        (0x1D4D6, ""M"", ""g""),
        (0x1D4D7, ""M"", ""h""),
        (0x1D4D8, ""M"", ""i""),
        (0x1D4D9, ""M"", ""j""),
        (0x1D4DA, ""M"", ""k""),
        (0x1D4DB, ""M"", ""l""),
        (0x1D4DC, ""M"", ""m""),
        (0x1D4DD, ""M"", ""n""),
        (0x1D4DE, ""M"", ""o""),
        (0x1D4DF, ""M"", ""p""),
        (0x1D4E0, ""M"", ""q""),
        (0x1D4E1, ""M"", ""r""),
        (0x1D4E2, ""M"", ""s""),
        (0x1D4E3, ""M"", ""t""),
        (0x1D4E4, ""M"", ""u""),
        (0x1D4E5, ""M"", ""v""),
        (0x1D4E6, ""M"", ""w""),
        (0x1D4E7, ""M"", ""x""),
        (0x1D4E8, ""M"", ""y""),
        (0x1D4E9, ""M"", ""z""),
        (0x1D4EA, ""M"", ""a""),
        (0x1D4EB, ""M"", ""b""),
        (0x1D4EC, ""M"", ""c""),
        (0x1D4ED, ""M"", ""d""),
        (0x1D4EE, ""M"", ""e""),
        (0x1D4EF, ""M"", ""f""),
    ]


def _seg_63() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x1D4F0, ""M"", ""g""),
        (0x1D4F1, ""M"", ""h""),
        (0x1D4F2, ""M"", ""i""),
        (0x1D4F3, ""M"", ""j""),
        (0x1D4F4, ""M"", ""k""),
        (0x1D4F5, ""M"", ""l""),
        (0x1D4F6, ""M"", ""m""),
        (0x1D4F7, ""M"", ""n""),
        (0x1D4F8, ""M"", ""o""),
        (0x1D4F9, ""M"", ""p""),
        (0x1D4FA, ""M"", ""q""),
        (0x1D4FB, ""M"", ""r""),
        (0x1D4FC, ""M"", ""s""),
        (0x1D4FD, ""M"", ""t""),
        (0x1D4FE, ""M"", ""u""),
        (0x1D4FF, ""M"", ""v""),
        (0x1D500, ""M"", ""w""),
        (0x1D501, ""M"", ""x""),
        (0x1D502, ""M"", ""y""),
        (0x1D503, ""M"", ""z""),
        (0x1D504, ""M"", ""a""),
        (0x1D505, ""M"", ""b""),
        (0x1D506, ""X""),
        (0x1D507, ""M"", ""d""),
        (0x1D508, ""M"", ""e""),
        (0x1D509, ""M"", ""f""),
        (0x1D50A, ""M"", ""g""),
        (0x1D50B, ""X""),
        (0x1D50D, ""M"", ""j""),
        (0x1D50E, ""M"", ""k""),
        (0x1D50F, ""M"", ""l""),
        (0x1D510, ""M"", ""m""),
        (0x1D511, ""M"", ""n""),
        (0x1D512, ""M"", ""o""),
        (0x1D513, ""M"", ""p""),
        (0x1D514, ""M"", ""q""),
        (0x1D515, ""X""),
        (0x1D516, ""M"", ""s""),
        (0x1D517, ""M"", ""t""),
        (0x1D518, ""M"", ""u""),
        (0x1D519, ""M"", ""v""),
        (0x1D51A, ""M"", ""w""),
        (0x1D51B, ""M"", ""x""),
        (0x1D51C, ""M"", ""y""),
        (0x1D51D, ""X""),
        (0x1D51E, ""M"", ""a""),
        (0x1D51F, ""M"", ""b""),
        (0x1D520, ""M"", ""c""),
        (0x1D521, ""M"", ""d""),
        (0x1D522, ""M"", ""e""),
        (0x1D523, ""M"", ""f""),
        (0x1D524, ""M"", ""g""),
        (0x1D525, ""M"", ""h""),
        (0x1D526, ""M"", ""i""),
        (0x1D527, ""M"", ""j""),
        (0x1D528, ""M"", ""k""),
        (0x1D529, ""M"", ""l""),
        (0x1D52A, ""M"", ""m""),
        (0x1D52B, ""M"", ""n""),
        (0x1D52C, ""M"", ""o""),
        (0x1D52D, ""M"", ""p""),
        (0x1D52E, ""M"", ""q""),
        (0x1D52F, ""M"", ""r""),
        (0x1D530, ""M"", ""s""),
        (0x1D531, ""M"", ""t""),
        (0x1D532, ""M"", ""u""),
        (0x1D533, ""M"", ""v""),
        (0x1D534, ""M"", ""w""),
        (0x1D535, ""M"", ""x""),
        (0x1D536, ""M"", ""y""),
        (0x1D537, ""M"", ""z""),
        (0x1D538, ""M"", ""a""),
        (0x1D539, ""M"", ""b""),
        (0x1D53A, ""X""),
        (0x1D53B, ""M"", ""d""),
        (0x1D53C, ""M"", ""e""),
        (0x1D53D, ""M"", ""f""),
        (0x1D53E, ""M"", ""g""),
        (0x1D53F, ""X""),
        (0x1D540, ""M"", ""i""),
        (0x1D541, ""M"", ""j""),
        (0x1D542, ""M"", ""k""),
        (0x1D543, ""M"", ""l""),
        (0x1D544, ""M"", ""m""),
        (0x1D545, ""X""),
        (0x1D546, ""M"", ""o""),
        (0x1D547, ""X""),
        (0x1D54A, ""M"", ""s""),
        (0x1D54B, ""M"", ""t""),
        (0x1D54C, ""M"", ""u""),
        (0x1D54D, ""M"", ""v""),
        (0x1D54E, ""M"", ""w""),
        (0x1D54F, ""M"", ""x""),
        (0x1D550, ""M"", ""y""),
        (0x1D551, ""X""),
        (0x1D552, ""M"", ""a""),
        (0x1D553, ""M"", ""b""),
        (0x1D554, ""M"", ""c""),
        (0x1D555, ""M"", ""d""),
        (0x1D556, ""M"", ""e""),
    ]


def _seg_64() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x1D557, ""M"", ""f""),
        (0x1D558, ""M"", ""g""),
        (0x1D559, ""M"", ""h""),
        (0x1D55A, ""M"", ""i""),
        (0x1D55B, ""M"", ""j""),
        (0x1D55C, ""M"", ""k""),
        (0x1D55D, ""M"", ""l""),
        (0x1D55E, ""M"", ""m""),
        (0x1D55F, ""M"", ""n""),
        (0x1D560, ""M"", ""o""),
        (0x1D561, ""M"", ""p""),
        (0x1D562, ""M"", ""q""),
        (0x1D563, ""M"", ""r""),
        (0x1D564, ""M"", ""s""),
        (0x1D565, ""M"", ""t""),
        (0x1D566, ""M"", ""u""),
        (0x1D567, ""M"", ""v""),
        (0x1D568, ""M"", ""w""),
        (0x1D569, ""M"", ""x""),
        (0x1D56A, ""M"", ""y""),
        (0x1D56B, ""M"", ""z""),
        (0x1D56C, ""M"", ""a""),
        (0x1D56D, ""M"", ""b""),
        (0x1D56E, ""M"", ""c""),
        (0x1D56F, ""M"", ""d""),
        (0x1D570, ""M"", ""e""),
        (0x1D571, ""M"", ""f""),
        (0x1D572, ""M"", ""g""),
        (0x1D573, ""M"", ""h""),
        (0x1D574, ""M"", ""i""),
        (0x1D575, ""M"", ""j""),
        (0x1D576, ""M"", ""k""),
        (0x1D577, ""M"", ""l""),
        (0x1D578, ""M"", ""m""),
        (0x1D579, ""M"", ""n""),
        (0x1D57A, ""M"", ""o""),
        (0x1D57B, ""M"", ""p""),
        (0x1D57C, ""M"", ""q""),
        (0x1D57D, ""M"", ""r""),
        (0x1D57E, ""M"", ""s""),
        (0x1D57F, ""M"", ""t""),
        (0x1D580, ""M"", ""u""),
        (0x1D581, ""M"", ""v""),
        (0x1D582, ""M"", ""w""),
        (0x1D583, ""M"", ""x""),
        (0x1D584, ""M"", ""y""),
        (0x1D585, ""M"", ""z""),
        (0x1D586, ""M"", ""a""),
        (0x1D587, ""M"", ""b""),
        (0x1D588, ""M"", ""c""),
        (0x1D589, ""M"", ""d""),
        (0x1D58A, ""M"", ""e""),
        (0x1D58B, ""M"", ""f""),
        (0x1D58C, ""M"", ""g""),
        (0x1D58D, ""M"", ""h""),
        (0x1D58E, ""M"", ""i""),
        (0x1D58F, ""M"", ""j""),
        (0x1D590, ""M"", ""k""),
        (0x1D591, ""M"", ""l""),
        (0x1D592, ""M"", ""m""),
        (0x1D593, ""M"", ""n""),
        (0x1D594, ""M"", ""o""),
        (0x1D595, ""M"", ""p""),
        (0x1D596, ""M"", ""q""),
        (0x1D597, ""M"", ""r""),
        (0x1D598, ""M"", ""s""),
        (0x1D599, ""M"", ""t""),
        (0x1D59A, ""M"", ""u""),
        (0x1D59B, ""M"", ""v""),
        (0x1D59C, ""M"", ""w""),
        (0x1D59D, ""M"", ""x""),
        (0x1D59E, ""M"", ""y""),
        (0x1D59F, ""M"", ""z""),
        (0x1D5A0, ""M"", ""a""),
        (0x1D5A1, ""M"", ""b""),
        (0x1D5A2, ""M"", ""c""),
        (0x1D5A3, ""M"", ""d""),
        (0x1D5A4, ""M"", ""e""),
        (0x1D5A5, ""M"", ""f""),
        (0x1D5A6, ""M"", ""g""),
        (0x1D5A7, ""M"", ""h""),
        (0x1D5A8, ""M"", ""i""),
        (0x1D5A9, ""M"", ""j""),
        (0x1D5AA, ""M"", ""k""),
        (0x1D5AB, ""M"", ""l""),
        (0x1D5AC, ""M"", ""m""),
        (0x1D5AD, ""M"", ""n""),
        (0x1D5AE, ""M"", ""o""),
        (0x1D5AF, ""M"", ""p""),
        (0x1D5B0, ""M"", ""q""),
        (0x1D5B1, ""M"", ""r""),
        (0x1D5B2, ""M"", ""s""),
        (0x1D5B3, ""M"", ""t""),
        (0x1D5B4, ""M"", ""u""),
        (0x1D5B5, ""M"", ""v""),
        (0x1D5B6, ""M"", ""w""),
        (0x1D5B7, ""M"", ""x""),
        (0x1D5B8, ""M"", ""y""),
        (0x1D5B9, ""M"", ""z""),
        (0x1D5BA, ""M"", ""a""),
    ]


def _seg_65() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x1D5BB, ""M"", ""b""),
        (0x1D5BC, ""M"", ""c""),
        (0x1D5BD, ""M"", ""d""),
        (0x1D5BE, ""M"", ""e""),
        (0x1D5BF, ""M"", ""f""),
        (0x1D5C0, ""M"", ""g""),
        (0x1D5C1, ""M"", ""h""),
        (0x1D5C2, ""M"", ""i""),
        (0x1D5C3, ""M"", ""j""),
        (0x1D5C4, ""M"", ""k""),
        (0x1D5C5, ""M"", ""l""),
        (0x1D5C6, ""M"", ""m""),
        (0x1D5C7, ""M"", ""n""),
        (0x1D5C8, ""M"", ""o""),
        (0x1D5C9, ""M"", ""p""),
        (0x1D5CA, ""M"", ""q""),
        (0x1D5CB, ""M"", ""r""),
        (0x1D5CC, ""M"", ""s""),
        (0x1D5CD, ""M"", ""t""),
        (0x1D5CE, ""M"", ""u""),
        (0x1D5CF, ""M"", ""v""),
        (0x1D5D0, ""M"", ""w""),
        (0x1D5D1, ""M"", ""x""),
        (0x1D5D2, ""M"", ""y""),
        (0x1D5D3, ""M"", ""z""),
        (0x1D5D4, ""M"", ""a""),
        (0x1D5D5, ""M"", ""b""),
        (0x1D5D6, ""M"", ""c""),
        (0x1D5D7, ""M"", ""d""),
        (0x1D5D8, ""M"", ""e""),
        (0x1D5D9, ""M"", ""f""),
        (0x1D5DA, ""M"", ""g""),
        (0x1D5DB, ""M"", ""h""),
        (0x1D5DC, ""M"", ""i""),
        (0x1D5DD, ""M"", ""j""),
        (0x1D5DE, ""M"", ""k""),
        (0x1D5DF, ""M"", ""l""),
        (0x1D5E0, ""M"", ""m""),
        (0x1D5E1, ""M"", ""n""),
        (0x1D5E2, ""M"", ""o""),
        (0x1D5E3, ""M"", ""p""),
        (0x1D5E4, ""M"", ""q""),
        (0x1D5E5, ""M"", ""r""),
        (0x1D5E6, ""M"", ""s""),
        (0x1D5E7, ""M"", ""t""),
        (0x1D5E8, ""M"", ""u""),
        (0x1D5E9, ""M"", ""v""),
        (0x1D5EA, ""M"", ""w""),
        (0x1D5EB, ""M"", ""x""),
        (0x1D5EC, ""M"", ""y""),
        (0x1D5ED, ""M"", ""z""),
        (0x1D5EE, ""M"", ""a""),
        (0x1D5EF, ""M"", ""b""),
        (0x1D5F0, ""M"", ""c""),
        (0x1D5F1, ""M"", ""d""),
        (0x1D5F2, ""M"", ""e""),
        (0x1D5F3, ""M"", ""f""),
        (0x1D5F4, ""M"", ""g""),
        (0x1D5F5, ""M"", ""h""),
        (0x1D5F6, ""M"", ""i""),
        (0x1D5F7, ""M"", ""j""),
        (0x1D5F8, ""M"", ""k""),
        (0x1D5F9, ""M"", ""l""),
        (0x1D5FA, ""M"", ""m""),
        (0x1D5FB, ""M"", ""n""),
        (0x1D5FC, ""M"", ""o""),
        (0x1D5FD, ""M"", ""p""),
        (0x1D5FE, ""M"", ""q""),
        (0x1D5FF, ""M"", ""r""),
        (0x1D600, ""M"", ""s""),
        (0x1D601, ""M"", ""t""),
        (0x1D602, ""M"", ""u""),
        (0x1D603, ""M"", ""v""),
        (0x1D604, ""M"", ""w""),
        (0x1D605, ""M"", ""x""),
        (0x1D606, ""M"", ""y""),
        (0x1D607, ""M"", ""z""),
        (0x1D608, ""M"", ""a""),
        (0x1D609, ""M"", ""b""),
        (0x1D60A, ""M"", ""c""),
        (0x1D60B, ""M"", ""d""),
        (0x1D60C, ""M"", ""e""),
        (0x1D60D, ""M"", ""f""),
        (0x1D60E, ""M"", ""g""),
        (0x1D60F, ""M"", ""h""),
        (0x1D610, ""M"", ""i""),
        (0x1D611, ""M"", ""j""),
        (0x1D612, ""M"", ""k""),
        (0x1D613, ""M"", ""l""),
        (0x1D614, ""M"", ""m""),
        (0x1D615, ""M"", ""n""),
        (0x1D616, ""M"", ""o""),
        (0x1D617, ""M"", ""p""),
        (0x1D618, ""M"", ""q""),
        (0x1D619, ""M"", ""r""),
        (0x1D61A, ""M"", ""s""),
        (0x1D61B, ""M"", ""t""),
        (0x1D61C, ""M"", ""u""),
        (0x1D61D, ""M"", ""v""),
        (0x1D61E, ""M"", ""w""),
    ]


def _seg_66() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x1D61F, ""M"", ""x""),
        (0x1D620, ""M"", ""y""),
        (0x1D621, ""M"", ""z""),
        (0x1D622, ""M"", ""a""),
        (0x1D623, ""M"", ""b""),
        (0x1D624, ""M"", ""c""),
        (0x1D625, ""M"", ""d""),
        (0x1D626, ""M"", ""e""),
        (0x1D627, ""M"", ""f""),
        (0x1D628, ""M"", ""g""),
        (0x1D629, ""M"", ""h""),
        (0x1D62A, ""M"", ""i""),
        (0x1D62B, ""M"", ""j""),
        (0x1D62C, ""M"", ""k""),
        (0x1D62D, ""M"", ""l""),
        (0x1D62E, ""M"", ""m""),
        (0x1D62F, ""M"", ""n""),
        (0x1D630, ""M"", ""o""),
        (0x1D631, ""M"", ""p""),
        (0x1D632, ""M"", ""q""),
        (0x1D633, ""M"", ""r""),
        (0x1D634, ""M"", ""s""),
        (0x1D635, ""M"", ""t""),
        (0x1D636, ""M"", ""u""),
        (0x1D637, ""M"", ""v""),
        (0x1D638, ""M"", ""w""),
        (0x1D639, ""M"", ""x""),
        (0x1D63A, ""M"", ""y""),
        (0x1D63B, ""M"", ""z""),
        (0x1D63C, ""M"", ""a""),
        (0x1D63D, ""M"", ""b""),
        (0x1D63E, ""M"", ""c""),
        (0x1D63F, ""M"", ""d""),
        (0x1D640, ""M"", ""e""),
        (0x1D641, ""M"", ""f""),
        (0x1D642, ""M"", ""g""),
        (0x1D643, ""M"", ""h""),
        (0x1D644, ""M"", ""i""),
        (0x1D645, ""M"", ""j""),
        (0x1D646, ""M"", ""k""),
        (0x1D647, ""M"", ""l""),
        (0x1D648, ""M"", ""m""),
        (0x1D649, ""M"", ""n""),
        (0x1D64A, ""M"", ""o""),
        (0x1D64B, ""M"", ""p""),
        (0x1D64C, ""M"", ""q""),
        (0x1D64D, ""M"", ""r""),
        (0x1D64E, ""M"", ""s""),
        (0x1D64F, ""M"", ""t""),
        (0x1D650, ""M"", ""u""),
        (0x1D651, ""M"", ""v""),
        (0x1D652, ""M"", ""w""),
        (0x1D653, ""M"", ""x""),
        (0x1D654, ""M"", ""y""),
        (0x1D655, ""M"", ""z""),
        (0x1D656, ""M"", ""a""),
        (0x1D657, ""M"", ""b""),
        (0x1D658, ""M"", ""c""),
        (0x1D659, ""M"", ""d""),
        (0x1D65A, ""M"", ""e""),
        (0x1D65B, ""M"", ""f""),
        (0x1D65C, ""M"", ""g""),
        (0x1D65D, ""M"", ""h""),
        (0x1D65E, ""M"", ""i""),
        (0x1D65F, ""M"", ""j""),
        (0x1D660, ""M"", ""k""),
        (0x1D661, ""M"", ""l""),
        (0x1D662, ""M"", ""m""),
        (0x1D663, ""M"", ""n""),
        (0x1D664, ""M"", ""o""),
        (0x1D665, ""M"", ""p""),
        (0x1D666, ""M"", ""q""),
        (0x1D667, ""M"", ""r""),
        (0x1D668, ""M"", ""s""),
        (0x1D669, ""M"", ""t""),
        (0x1D66A, ""M"", ""u""),
        (0x1D66B, ""M"", ""v""),
        (0x1D66C, ""M"", ""w""),
        (0x1D66D, ""M"", ""x""),
        (0x1D66E, ""M"", ""y""),
        (0x1D66F, ""M"", ""z""),
        (0x1D670, ""M"", ""a""),
        (0x1D671, ""M"", ""b""),
        (0x1D672, ""M"", ""c""),
        (0x1D673, ""M"", ""d""),
        (0x1D674, ""M"", ""e""),
        (0x1D675, ""M"", ""f""),
        (0x1D676, ""M"", ""g""),
        (0x1D677, ""M"", ""h""),
        (0x1D678, ""M"", ""i""),
        (0x1D679, ""M"", ""j""),
        (0x1D67A, ""M"", ""k""),
        (0x1D67B, ""M"", ""l""),
        (0x1D67C, ""M"", ""m""),
        (0x1D67D, ""M"", ""n""),
        (0x1D67E, ""M"", ""o""),
        (0x1D67F, ""M"", ""p""),
        (0x1D680, ""M"", ""q""),
        (0x1D681, ""M"", ""r""),
        (0x1D682, ""M"", ""s""),
    ]


def _seg_67() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x1D683, ""M"", ""t""),
        (0x1D684, ""M"", ""u""),
        (0x1D685, ""M"", ""v""),
        (0x1D686, ""M"", ""w""),
        (0x1D687, ""M"", ""x""),
        (0x1D688, ""M"", ""y""),
        (0x1D689, ""M"", ""z""),
        (0x1D68A, ""M"", ""a""),
        (0x1D68B, ""M"", ""b""),
        (0x1D68C, ""M"", ""c""),
        (0x1D68D, ""M"", ""d""),
        (0x1D68E, ""M"", ""e""),
        (0x1D68F, ""M"", ""f""),
        (0x1D690, ""M"", ""g""),
        (0x1D691, ""M"", ""h""),
        (0x1D692, ""M"", ""i""),
        (0x1D693, ""M"", ""j""),
        (0x1D694, ""M"", ""k""),
        (0x1D695, ""M"", ""l""),
        (0x1D696, ""M"", ""m""),
        (0x1D697, ""M"", ""n""),
        (0x1D698, ""M"", ""o""),
        (0x1D699, ""M"", ""p""),
        (0x1D69A, ""M"", ""q""),
        (0x1D69B, ""M"", ""r""),
        (0x1D69C, ""M"", ""s""),
        (0x1D69D, ""M"", ""t""),
        (0x1D69E, ""M"", ""u""),
        (0x1D69F, ""M"", ""v""),
        (0x1D6A0, ""M"", ""w""),
        (0x1D6A1, ""M"", ""x""),
        (0x1D6A2, ""M"", ""y""),
        (0x1D6A3, ""M"", ""z""),
        (0x1D6A4, ""M"", ""ı""),
        (0x1D6A5, ""M"", ""ȷ""),
        (0x1D6A6, ""X""),
        (0x1D6A8, ""M"", ""α""),
        (0x1D6A9, ""M"", ""β""),
        (0x1D6AA, ""M"", ""γ""),
        (0x1D6AB, ""M"", ""δ""),
        (0x1D6AC, ""M"", ""ε""),
        (0x1D6AD, ""M"", ""ζ""),
        (0x1D6AE, ""M"", ""η""),
        (0x1D6AF, ""M"", ""θ""),
        (0x1D6B0, ""M"", ""ι""),
        (0x1D6B1, ""M"", ""κ""),
        (0x1D6B2, ""M"", ""λ""),
        (0x1D6B3, ""M"", ""μ""),
        (0x1D6B4, ""M"", ""ν""),
        (0x1D6B5, ""M"", ""ξ""),
        (0x1D6B6, ""M"", ""ο""),
        (0x1D6B7, ""M"", ""π""),
        (0x1D6B8, ""M"", ""ρ""),
        (0x1D6B9, ""M"", ""θ""),
        (0x1D6BA, ""M"", ""σ""),
        (0x1D6BB, ""M"", ""τ""),
        (0x1D6BC, ""M"", ""υ""),
        (0x1D6BD, ""M"", ""φ""),
        (0x1D6BE, ""M"", ""χ""),
        (0x1D6BF, ""M"", ""ψ""),
        (0x1D6C0, ""M"", ""ω""),
        (0x1D6C1, ""M"", ""∇""),
        (0x1D6C2, ""M"", ""α""),
        (0x1D6C3, ""M"", ""β""),
        (0x1D6C4, ""M"", ""γ""),
        (0x1D6C5, ""M"", ""δ""),
        (0x1D6C6, ""M"", ""ε""),
        (0x1D6C7, ""M"", ""ζ""),
        (0x1D6C8, ""M"", ""η""),
        (0x1D6C9, ""M"", ""θ""),
        (0x1D6CA, ""M"", ""ι""),
        (0x1D6CB, ""M"", ""κ""),
        (0x1D6CC, ""M"", ""λ""),
        (0x1D6CD, ""M"", ""μ""),
        (0x1D6CE, ""M"", ""ν""),
        (0x1D6CF, ""M"", ""ξ""),
        (0x1D6D0, ""M"", ""ο""),
        (0x1D6D1, ""M"", ""π""),
        (0x1D6D2, ""M"", ""ρ""),
        (0x1D6D3, ""M"", ""σ""),
        (0x1D6D5, ""M"", ""τ""),
        (0x1D6D6, ""M"", ""υ""),
        (0x1D6D7, ""M"", ""φ""),
        (0x1D6D8, ""M"", ""χ""),
        (0x1D6D9, ""M"", ""ψ""),
        (0x1D6DA, ""M"", ""ω""),
        (0x1D6DB, ""M"", ""∂""),
        (0x1D6DC, ""M"", ""ε""),
        (0x1D6DD, ""M"", ""θ""),
        (0x1D6DE, ""M"", ""κ""),
        (0x1D6DF, ""M"", ""φ""),
        (0x1D6E0, ""M"", ""ρ""),
        (0x1D6E1, ""M"", ""π""),
        (0x1D6E2, ""M"", ""α""),
        (0x1D6E3, ""M"", ""β""),
        (0x1D6E4, ""M"", ""γ""),
        (0x1D6E5, ""M"", ""δ""),
        (0x1D6E6, ""M"", ""ε""),
        (0x1D6E7, ""M"", ""ζ""),
        (0x1D6E8, ""M"", ""η""),
    ]


def _seg_68() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x1D6E9, ""M"", ""θ""),
        (0x1D6EA, ""M"", ""ι""),
        (0x1D6EB, ""M"", ""κ""),
        (0x1D6EC, ""M"", ""λ""),
        (0x1D6ED, ""M"", ""μ""),
        (0x1D6EE, ""M"", ""ν""),
        (0x1D6EF, ""M"", ""ξ""),
        (0x1D6F0, ""M"", ""ο""),
        (0x1D6F1, ""M"", ""π""),
        (0x1D6F2, ""M"", ""ρ""),
        (0x1D6F3, ""M"", ""θ""),
        (0x1D6F4, ""M"", ""σ""),
        (0x1D6F5, ""M"", ""τ""),
        (0x1D6F6, ""M"", ""υ""),
        (0x1D6F7, ""M"", ""φ""),
        (0x1D6F8, ""M"", ""χ""),
        (0x1D6F9, ""M"", ""ψ""),
        (0x1D6FA, ""M"", ""ω""),
        (0x1D6FB, ""M"", ""∇""),
        (0x1D6FC, ""M"", ""α""),
        (0x1D6FD, ""M"", ""β""),
        (0x1D6FE, ""M"", ""γ""),
        (0x1D6FF, ""M"", ""δ""),
        (0x1D700, ""M"", ""ε""),
        (0x1D701, ""M"", ""ζ""),
        (0x1D702, ""M"", ""η""),
        (0x1D703, ""M"", ""θ""),
        (0x1D704, ""M"", ""ι""),
        (0x1D705, ""M"", ""κ""),
        (0x1D706, ""M"", ""λ""),
        (0x1D707, ""M"", ""μ""),
        (0x1D708, ""M"", ""ν""),
        (0x1D709, ""M"", ""ξ""),
        (0x1D70A, ""M"", ""ο""),
        (0x1D70B, ""M"", ""π""),
        (0x1D70C, ""M"", ""ρ""),
        (0x1D70D, ""M"", ""σ""),
        (0x1D70F, ""M"", ""τ""),
        (0x1D710, ""M"", ""υ""),
        (0x1D711, ""M"", ""φ""),
        (0x1D712, ""M"", ""χ""),
        (0x1D713, ""M"", ""ψ""),
        (0x1D714, ""M"", ""ω""),
        (0x1D715, ""M"", ""∂""),
        (0x1D716, ""M"", ""ε""),
        (0x1D717, ""M"", ""θ""),
        (0x1D718, ""M"", ""κ""),
        (0x1D719, ""M"", ""φ""),
        (0x1D71A, ""M"", ""ρ""),
        (0x1D71B, ""M"", ""π""),
        (0x1D71C, ""M"", ""α""),
        (0x1D71D, ""M"", ""β""),
        (0x1D71E, ""M"", ""γ""),
        (0x1D71F, ""M"", ""δ""),
        (0x1D720, ""M"", ""ε""),
        (0x1D721, ""M"", ""ζ""),
        (0x1D722, ""M"", ""η""),
        (0x1D723, ""M"", ""θ""),
        (0x1D724, ""M"", ""ι""),
        (0x1D725, ""M"", ""κ""),
        (0x1D726, ""M"", ""λ""),
        (0x1D727, ""M"", ""μ""),
        (0x1D728, ""M"", ""ν""),
        (0x1D729, ""M"", ""ξ""),
        (0x1D72A, ""M"", ""ο""),
        (0x1D72B, ""M"", ""π""),
        (0x1D72C, ""M"", ""ρ""),
        (0x1D72D, ""M"", ""θ""),
        (0x1D72E, ""M"", ""σ""),
        (0x1D72F, ""M"", ""τ""),
        (0x1D730, ""M"", ""υ""),
        (0x1D731, ""M"", ""φ""),
        (0x1D732, ""M"", ""χ""),
        (0x1D733, ""M"", ""ψ""),
        (0x1D734, ""M"", ""ω""),
        (0x1D735, ""M"", ""∇""),
        (0x1D736, ""M"", ""α""),
        (0x1D737, ""M"", ""β""),
        (0x1D738, ""M"", ""γ""),
        (0x1D739, ""M"", ""δ""),
        (0x1D73A, ""M"", ""ε""),
        (0x1D73B, ""M"", ""ζ""),
        (0x1D73C, ""M"", ""η""),
        (0x1D73D, ""M"", ""θ""),
        (0x1D73E, ""M"", ""ι""),
        (0x1D73F, ""M"", ""κ""),
        (0x1D740, ""M"", ""λ""),
        (0x1D741, ""M"", ""μ""),
        (0x1D742, ""M"", ""ν""),
        (0x1D743, ""M"", ""ξ""),
        (0x1D744, ""M"", ""ο""),
        (0x1D745, ""M"", ""π""),
        (0x1D746, ""M"", ""ρ""),
        (0x1D747, ""M"", ""σ""),
        (0x1D749, ""M"", ""τ""),
        (0x1D74A, ""M"", ""υ""),
        (0x1D74B, ""M"", ""φ""),
        (0x1D74C, ""M"", ""χ""),
        (0x1D74D, ""M"", ""ψ""),
        (0x1D74E, ""M"", ""ω""),
    ]


def _seg_69() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x1D74F, ""M"", ""∂""),
        (0x1D750, ""M"", ""ε""),
        (0x1D751, ""M"", ""θ""),
        (0x1D752, ""M"", ""κ""),
        (0x1D753, ""M"", ""φ""),
        (0x1D754, ""M"", ""ρ""),
        (0x1D755, ""M"", ""π""),
        (0x1D756, ""M"", ""α""),
        (0x1D757, ""M"", ""β""),
        (0x1D758, ""M"", ""γ""),
        (0x1D759, ""M"", ""δ""),
        (0x1D75A, ""M"", ""ε""),
        (0x1D75B, ""M"", ""ζ""),
        (0x1D75C, ""M"", ""η""),
        (0x1D75D, ""M"", ""θ""),
        (0x1D75E, ""M"", ""ι""),
        (0x1D75F, ""M"", ""κ""),
        (0x1D760, ""M"", ""λ""),
        (0x1D761, ""M"", ""μ""),
        (0x1D762, ""M"", ""ν""),
        (0x1D763, ""M"", ""ξ""),
        (0x1D764, ""M"", ""ο""),
        (0x1D765, ""M"", ""π""),
        (0x1D766, ""M"", ""ρ""),
        (0x1D767, ""M"", ""θ""),
        (0x1D768, ""M"", ""σ""),
        (0x1D769, ""M"", ""τ""),
        (0x1D76A, ""M"", ""υ""),
        (0x1D76B, ""M"", ""φ""),
        (0x1D76C, ""M"", ""χ""),
        (0x1D76D, ""M"", ""ψ""),
        (0x1D76E, ""M"", ""ω""),
        (0x1D76F, ""M"", ""∇""),
        (0x1D770, ""M"", ""α""),
        (0x1D771, ""M"", ""β""),
        (0x1D772, ""M"", ""γ""),
        (0x1D773, ""M"", ""δ""),
        (0x1D774, ""M"", ""ε""),
        (0x1D775, ""M"", ""ζ""),
        (0x1D776, ""M"", ""η""),
        (0x1D777, ""M"", ""θ""),
        (0x1D778, ""M"", ""ι""),
        (0x1D779, ""M"", ""κ""),
        (0x1D77A, ""M"", ""λ""),
        (0x1D77B, ""M"", ""μ""),
        (0x1D77C, ""M"", ""ν""),
        (0x1D77D, ""M"", ""ξ""),
        (0x1D77E, ""M"", ""ο""),
        (0x1D77F, ""M"", ""π""),
        (0x1D780, ""M"", ""ρ""),
        (0x1D781, ""M"", ""σ""),
        (0x1D783, ""M"", ""τ""),
        (0x1D784, ""M"", ""υ""),
        (0x1D785, ""M"", ""φ""),
        (0x1D786, ""M"", ""χ""),
        (0x1D787, ""M"", ""ψ""),
        (0x1D788, ""M"", ""ω""),
        (0x1D789, ""M"", ""∂""),
        (0x1D78A, ""M"", ""ε""),
        (0x1D78B, ""M"", ""θ""),
        (0x1D78C, ""M"", ""κ""),
        (0x1D78D, ""M"", ""φ""),
        (0x1D78E, ""M"", ""ρ""),
        (0x1D78F, ""M"", ""π""),
        (0x1D790, ""M"", ""α""),
        (0x1D791, ""M"", ""β""),
        (0x1D792, ""M"", ""γ""),
        (0x1D793, ""M"", ""δ""),
        (0x1D794, ""M"", ""ε""),
        (0x1D795, ""M"", ""ζ""),
        (0x1D796, ""M"", ""η""),
        (0x1D797, ""M"", ""θ""),
        (0x1D798, ""M"", ""ι""),
        (0x1D799, ""M"", ""κ""),
        (0x1D79A, ""M"", ""λ""),
        (0x1D79B, ""M"", ""μ""),
        (0x1D79C, ""M"", ""ν""),
        (0x1D79D, ""M"", ""ξ""),
        (0x1D79E, ""M"", ""ο""),
        (0x1D79F, ""M"", ""π""),
        (0x1D7A0, ""M"", ""ρ""),
        (0x1D7A1, ""M"", ""θ""),
        (0x1D7A2, ""M"", ""σ""),
        (0x1D7A3, ""M"", ""τ""),
        (0x1D7A4, ""M"", ""υ""),
        (0x1D7A5, ""M"", ""φ""),
        (0x1D7A6, ""M"", ""χ""),
        (0x1D7A7, ""M"", ""ψ""),
        (0x1D7A8, ""M"", ""ω""),
        (0x1D7A9, ""M"", ""∇""),
        (0x1D7AA, ""M"", ""α""),
        (0x1D7AB, ""M"", ""β""),
        (0x1D7AC, ""M"", ""γ""),
        (0x1D7AD, ""M"", ""δ""),
        (0x1D7AE, ""M"", ""ε""),
        (0x1D7AF, ""M"", ""ζ""),
        (0x1D7B0, ""M"", ""η""),
        (0x1D7B1, ""M"", ""θ""),
        (0x1D7B2, ""M"", ""ι""),
        (0x1D7B3, ""M"", ""κ""),
    ]


def _seg_70() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x1D7B4, ""M"", ""λ""),
        (0x1D7B5, ""M"", ""μ""),
        (0x1D7B6, ""M"", ""ν""),
        (0x1D7B7, ""M"", ""ξ""),
        (0x1D7B8, ""M"", ""ο""),
        (0x1D7B9, ""M"", ""π""),
        (0x1D7BA, ""M"", ""ρ""),
        (0x1D7BB, ""M"", ""σ""),
        (0x1D7BD, ""M"", ""τ""),
        (0x1D7BE, ""M"", ""υ""),
        (0x1D7BF, ""M"", ""φ""),
        (0x1D7C0, ""M"", ""χ""),
        (0x1D7C1, ""M"", ""ψ""),
        (0x1D7C2, ""M"", ""ω""),
        (0x1D7C3, ""M"", ""∂""),
        (0x1D7C4, ""M"", ""ε""),
        (0x1D7C5, ""M"", ""θ""),
        (0x1D7C6, ""M"", ""κ""),
        (0x1D7C7, ""M"", ""φ""),
        (0x1D7C8, ""M"", ""ρ""),
        (0x1D7C9, ""M"", ""π""),
        (0x1D7CA, ""M"", ""ϝ""),
        (0x1D7CC, ""X""),
        (0x1D7CE, ""M"", ""0""),
        (0x1D7CF, ""M"", ""1""),
        (0x1D7D0, ""M"", ""2""),
        (0x1D7D1, ""M"", ""3""),
        (0x1D7D2, ""M"", ""4""),
        (0x1D7D3, ""M"", ""5""),
        (0x1D7D4, ""M"", ""6""),
        (0x1D7D5, ""M"", ""7""),
        (0x1D7D6, ""M"", ""8""),
        (0x1D7D7, ""M"", ""9""),
        (0x1D7D8, ""M"", ""0""),
        (0x1D7D9, ""M"", ""1""),
        (0x1D7DA, ""M"", ""2""),
        (0x1D7DB, ""M"", ""3""),
        (0x1D7DC, ""M"", ""4""),
        (0x1D7DD, ""M"", ""5""),
        (0x1D7DE, ""M"", ""6""),
        (0x1D7DF, ""M"", ""7""),
        (0x1D7E0, ""M"", ""8""),
        (0x1D7E1, ""M"", ""9""),
        (0x1D7E2, ""M"", ""0""),
        (0x1D7E3, ""M"", ""1""),
        (0x1D7E4, ""M"", ""2""),
        (0x1D7E5, ""M"", ""3""),
        (0x1D7E6, ""M"", ""4""),
        (0x1D7E7, ""M"", ""5""),
        (0x1D7E8, ""M"", ""6""),
        (0x1D7E9, ""M"", ""7""),
        (0x1D7EA, ""M"", ""8""),
        (0x1D7EB, ""M"", ""9""),
        (0x1D7EC, ""M"", ""0""),
        (0x1D7ED, ""M"", ""1""),
        (0x1D7EE, ""M"", ""2""),
        (0x1D7EF, ""M"", ""3""),
        (0x1D7F0, ""M"", ""4""),
        (0x1D7F1, ""M"", ""5""),
        (0x1D7F2, ""M"", ""6""),
        (0x1D7F3, ""M"", ""7""),
        (0x1D7F4, ""M"", ""8""),
        (0x1D7F5, ""M"", ""9""),
        (0x1D7F6, ""M"", ""0""),
        (0x1D7F7, ""M"", ""1""),
        (0x1D7F8, ""M"", ""2""),
        (0x1D7F9, ""M"", ""3""),
        (0x1D7FA, ""M"", ""4""),
        (0x1D7FB, ""M"", ""5""),
        (0x1D7FC, ""M"", ""6""),
        (0x1D7FD, ""M"", ""7""),
        (0x1D7FE, ""M"", ""8""),
        (0x1D7FF, ""M"", ""9""),
        (0x1D800, ""V""),
        (0x1DA8C, ""X""),
        (0x1DA9B, ""V""),
        (0x1DAA0, ""X""),
        (0x1DAA1, ""V""),
        (0x1DAB0, ""X""),
        (0x1DF00, ""V""),
        (0x1DF1F, ""X""),
        (0x1DF25, ""V""),
        (0x1DF2B, ""X""),
        (0x1E000, ""V""),
        (0x1E007, ""X""),
        (0x1E008, ""V""),
        (0x1E019, ""X""),
        (0x1E01B, ""V""),
        (0x1E022, ""X""),
        (0x1E023, ""V""),
        (0x1E025, ""X""),
        (0x1E026, ""V""),
        (0x1E02B, ""X""),
        (0x1E030, ""M"", ""а""),
        (0x1E031, ""M"", ""б""),
        (0x1E032, ""M"", ""в""),
        (0x1E033, ""M"", ""г""),
        (0x1E034, ""M"", ""д""),
        (0x1E035, ""M"", ""е""),
        (0x1E036, ""M"", ""ж""),
    ]


def _seg_71() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x1E037, ""M"", ""з""),
        (0x1E038, ""M"", ""и""),
        (0x1E039, ""M"", ""к""),
        (0x1E03A, ""M"", ""л""),
        (0x1E03B, ""M"", ""м""),
        (0x1E03C, ""M"", ""о""),
        (0x1E03D, ""M"", ""п""),
        (0x1E03E, ""M"", ""р""),
        (0x1E03F, ""M"", ""с""),
        (0x1E040, ""M"", ""т""),
        (0x1E041, ""M"", ""у""),
        (0x1E042, ""M"", ""ф""),
        (0x1E043, ""M"", ""х""),
        (0x1E044, ""M"", ""ц""),
        (0x1E045, ""M"", ""ч""),
        (0x1E046, ""M"", ""ш""),
        (0x1E047, ""M"", ""ы""),
        (0x1E048, ""M"", ""э""),
        (0x1E049, ""M"", ""ю""),
        (0x1E04A, ""M"", ""ꚉ""),
        (0x1E04B, ""M"", ""ә""),
        (0x1E04C, ""M"", ""і""),
        (0x1E04D, ""M"", ""ј""),
        (0x1E04E, ""M"", ""ө""),
        (0x1E04F, ""M"", ""ү""),
        (0x1E050, ""M"", ""ӏ""),
        (0x1E051, ""M"", ""а""),
        (0x1E052, ""M"", ""б""),
        (0x1E053, ""M"", ""в""),
        (0x1E054, ""M"", ""г""),
        (0x1E055, ""M"", ""д""),
        (0x1E056, ""M"", ""е""),
        (0x1E057, ""M"", ""ж""),
        (0x1E058, ""M"", ""з""),
        (0x1E059, ""M"", ""и""),
        (0x1E05A, ""M"", ""к""),
        (0x1E05B, ""M"", ""л""),
        (0x1E05C, ""M"", ""о""),
        (0x1E05D, ""M"", ""п""),
        (0x1E05E, ""M"", ""с""),
        (0x1E05F, ""M"", ""у""),
        (0x1E060, ""M"", ""ф""),
        (0x1E061, ""M"", ""х""),
        (0x1E062, ""M"", ""ц""),
        (0x1E063, ""M"", ""ч""),
        (0x1E064, ""M"", ""ш""),
        (0x1E065, ""M"", ""ъ""),
        (0x1E066, ""M"", ""ы""),
        (0x1E067, ""M"", ""ґ""),
        (0x1E068, ""M"", ""і""),
        (0x1E069, ""M"", ""ѕ""),
        (0x1E06A, ""M"", ""џ""),
        (0x1E06B, ""M"", ""ҫ""),
        (0x1E06C, ""M"", ""ꙑ""),
        (0x1E06D, ""M"", ""ұ""),
        (0x1E06E, ""X""),
        (0x1E08F, ""V""),
        (0x1E090, ""X""),
        (0x1E100, ""V""),
        (0x1E12D, ""X""),
        (0x1E130, ""V""),
        (0x1E13E, ""X""),
        (0x1E140, ""V""),
        (0x1E14A, ""X""),
        (0x1E14E, ""V""),
        (0x1E150, ""X""),
        (0x1E290, ""V""),
        (0x1E2AF, ""X""),
        (0x1E2C0, ""V""),
        (0x1E2FA, ""X""),
        (0x1E2FF, ""V""),
        (0x1E300, ""X""),
        (0x1E4D0, ""V""),
        (0x1E4FA, ""X""),
        (0x1E7E0, ""V""),
        (0x1E7E7, ""X""),
        (0x1E7E8, ""V""),
        (0x1E7EC, ""X""),
        (0x1E7ED, ""V""),
        (0x1E7EF, ""X""),
        (0x1E7F0, ""V""),
        (0x1E7FF, ""X""),
        (0x1E800, ""V""),
        (0x1E8C5, ""X""),
        (0x1E8C7, ""V""),
        (0x1E8D7, ""X""),
        (0x1E900, ""M"", ""𞤢""),
        (0x1E901, ""M"", ""𞤣""),
        (0x1E902, ""M"", ""𞤤""),
        (0x1E903, ""M"", ""𞤥""),
        (0x1E904, ""M"", ""𞤦""),
        (0x1E905, ""M"", ""𞤧""),
        (0x1E906, ""M"", ""𞤨""),
        (0x1E907, ""M"", ""𞤩""),
        (0x1E908, ""M"", ""𞤪""),
        (0x1E909, ""M"", ""𞤫""),
        (0x1E90A, ""M"", ""𞤬""),
        (0x1E90B, ""M"", ""𞤭""),
        (0x1E90C, ""M"", ""𞤮""),
        (0x1E90D, ""M"", ""𞤯""),
    ]


def _seg_72() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x1E90E, ""M"", ""𞤰""),
        (0x1E90F, ""M"", ""𞤱""),
        (0x1E910, ""M"", ""𞤲""),
        (0x1E911, ""M"", ""𞤳""),
        (0x1E912, ""M"", ""𞤴""),
        (0x1E913, ""M"", ""𞤵""),
        (0x1E914, ""M"", ""𞤶""),
        (0x1E915, ""M"", ""𞤷""),
        (0x1E916, ""M"", ""𞤸""),
        (0x1E917, ""M"", ""𞤹""),
        (0x1E918, ""M"", ""𞤺""),
        (0x1E919, ""M"", ""𞤻""),
        (0x1E91A, ""M"", ""𞤼""),
        (0x1E91B, ""M"", ""𞤽""),
        (0x1E91C, ""M"", ""𞤾""),
        (0x1E91D, ""M"", ""𞤿""),
        (0x1E91E, ""M"", ""𞥀""),
        (0x1E91F, ""M"", ""𞥁""),
        (0x1E920, ""M"", ""𞥂""),
        (0x1E921, ""M"", ""𞥃""),
        (0x1E922, ""V""),
        (0x1E94C, ""X""),
        (0x1E950, ""V""),
        (0x1E95A, ""X""),
        (0x1E95E, ""V""),
        (0x1E960, ""X""),
        (0x1EC71, ""V""),
        (0x1ECB5, ""X""),
        (0x1ED01, ""V""),
        (0x1ED3E, ""X""),
        (0x1EE00, ""M"", ""ا""),
        (0x1EE01, ""M"", ""ب""),
        (0x1EE02, ""M"", ""ج""),
        (0x1EE03, ""M"", ""د""),
        (0x1EE04, ""X""),
        (0x1EE05, ""M"", ""و""),
        (0x1EE06, ""M"", ""ز""),
        (0x1EE07, ""M"", ""ح""),
        (0x1EE08, ""M"", ""ط""),
        (0x1EE09, ""M"", ""ي""),
        (0x1EE0A, ""M"", ""ك""),
        (0x1EE0B, ""M"", ""ل""),
        (0x1EE0C, ""M"", ""م""),
        (0x1EE0D, ""M"", ""ن""),
        (0x1EE0E, ""M"", ""س""),
        (0x1EE0F, ""M"", ""ع""),
        (0x1EE10, ""M"", ""ف""),
        (0x1EE11, ""M"", ""ص""),
        (0x1EE12, ""M"", ""ق""),
        (0x1EE13, ""M"", ""ر""),
        (0x1EE14, ""M"", ""ش""),
        (0x1EE15, ""M"", ""ت""),
        (0x1EE16, ""M"", ""ث""),
        (0x1EE17, ""M"", ""خ""),
        (0x1EE18, ""M"", ""ذ""),
        (0x1EE19, ""M"", ""ض""),
        (0x1EE1A, ""M"", ""ظ""),
        (0x1EE1B, ""M"", ""غ""),
        (0x1EE1C, ""M"", ""ٮ""),
        (0x1EE1D, ""M"", ""ں""),
        (0x1EE1E, ""M"", ""ڡ""),
        (0x1EE1F, ""M"", ""ٯ""),
        (0x1EE20, ""X""),
        (0x1EE21, ""M"", ""ب""),
        (0x1EE22, ""M"", ""ج""),
        (0x1EE23, ""X""),
        (0x1EE24, ""M"", ""ه""),
        (0x1EE25, ""X""),
        (0x1EE27, ""M"", ""ح""),
        (0x1EE28, ""X""),
        (0x1EE29, ""M"", ""ي""),
        (0x1EE2A, ""M"", ""ك""),
        (0x1EE2B, ""M"", ""ل""),
        (0x1EE2C, ""M"", ""م""),
        (0x1EE2D, ""M"", ""ن""),
        (0x1EE2E, ""M"", ""س""),
        (0x1EE2F, ""M"", ""ع""),
        (0x1EE30, ""M"", ""ف""),
        (0x1EE31, ""M"", ""ص""),
        (0x1EE32, ""M"", ""ق""),
        (0x1EE33, ""X""),
        (0x1EE34, ""M"", ""ش""),
        (0x1EE35, ""M"", ""ت""),
        (0x1EE36, ""M"", ""ث""),
        (0x1EE37, ""M"", ""خ""),
        (0x1EE38, ""X""),
        (0x1EE39, ""M"", ""ض""),
        (0x1EE3A, ""X""),
        (0x1EE3B, ""M"", ""غ""),
        (0x1EE3C, ""X""),
        (0x1EE42, ""M"", ""ج""),
        (0x1EE43, ""X""),
        (0x1EE47, ""M"", ""ح""),
        (0x1EE48, ""X""),
        (0x1EE49, ""M"", ""ي""),
        (0x1EE4A, ""X""),
        (0x1EE4B, ""M"", ""ل""),
        (0x1EE4C, ""X""),
        (0x1EE4D, ""M"", ""ن""),
        (0x1EE4E, ""M"", ""س""),
    ]


def _seg_73() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x1EE4F, ""M"", ""ع""),
        (0x1EE50, ""X""),
        (0x1EE51, ""M"", ""ص""),
        (0x1EE52, ""M"", ""ق""),
        (0x1EE53, ""X""),
        (0x1EE54, ""M"", ""ش""),
        (0x1EE55, ""X""),
        (0x1EE57, ""M"", ""خ""),
        (0x1EE58, ""X""),
        (0x1EE59, ""M"", ""ض""),
        (0x1EE5A, ""X""),
        (0x1EE5B, ""M"", ""غ""),
        (0x1EE5C, ""X""),
        (0x1EE5D, ""M"", ""ں""),
        (0x1EE5E, ""X""),
        (0x1EE5F, ""M"", ""ٯ""),
        (0x1EE60, ""X""),
        (0x1EE61, ""M"", ""ب""),
        (0x1EE62, ""M"", ""ج""),
        (0x1EE63, ""X""),
        (0x1EE64, ""M"", ""ه""),
        (0x1EE65, ""X""),
        (0x1EE67, ""M"", ""ح""),
        (0x1EE68, ""M"", ""ط""),
        (0x1EE69, ""M"", ""ي""),
        (0x1EE6A, ""M"", ""ك""),
        (0x1EE6B, ""X""),
        (0x1EE6C, ""M"", ""م""),
        (0x1EE6D, ""M"", ""ن""),
        (0x1EE6E, ""M"", ""س""),
        (0x1EE6F, ""M"", ""ع""),
        (0x1EE70, ""M"", ""ف""),
        (0x1EE71, ""M"", ""ص""),
        (0x1EE72, ""M"", ""ق""),
        (0x1EE73, ""X""),
        (0x1EE74, ""M"", ""ش""),
        (0x1EE75, ""M"", ""ت""),
        (0x1EE76, ""M"", ""ث""),
        (0x1EE77, ""M"", ""خ""),
        (0x1EE78, ""X""),
        (0x1EE79, ""M"", ""ض""),
        (0x1EE7A, ""M"", ""ظ""),
        (0x1EE7B, ""M"", ""غ""),
        (0x1EE7C, ""M"", ""ٮ""),
        (0x1EE7D, ""X""),
        (0x1EE7E, ""M"", ""ڡ""),
        (0x1EE7F, ""X""),
        (0x1EE80, ""M"", ""ا""),
        (0x1EE81, ""M"", ""ب""),
        (0x1EE82, ""M"", ""ج""),
        (0x1EE83, ""M"", ""د""),
        (0x1EE84, ""M"", ""ه""),
        (0x1EE85, ""M"", ""و""),
        (0x1EE86, ""M"", ""ز""),
        (0x1EE87, ""M"", ""ح""),
        (0x1EE88, ""M"", ""ط""),
        (0x1EE89, ""M"", ""ي""),
        (0x1EE8A, ""X""),
        (0x1EE8B, ""M"", ""ل""),
        (0x1EE8C, ""M"", ""م""),
        (0x1EE8D, ""M"", ""ن""),
        (0x1EE8E, ""M"", ""س""),
        (0x1EE8F, ""M"", ""ع""),
        (0x1EE90, ""M"", ""ف""),
        (0x1EE91, ""M"", ""ص""),
        (0x1EE92, ""M"", ""ق""),
        (0x1EE93, ""M"", ""ر""),
        (0x1EE94, ""M"", ""ش""),
        (0x1EE95, ""M"", ""ت""),
        (0x1EE96, ""M"", ""ث""),
        (0x1EE97, ""M"", ""خ""),
        (0x1EE98, ""M"", ""ذ""),
        (0x1EE99, ""M"", ""ض""),
        (0x1EE9A, ""M"", ""ظ""),
        (0x1EE9B, ""M"", ""غ""),
        (0x1EE9C, ""X""),
        (0x1EEA1, ""M"", ""ب""),
        (0x1EEA2, ""M"", ""ج""),
        (0x1EEA3, ""M"", ""د""),
        (0x1EEA4, ""X""),
        (0x1EEA5, ""M"", ""و""),
        (0x1EEA6, ""M"", ""ز""),
        (0x1EEA7, ""M"", ""ح""),
        (0x1EEA8, ""M"", ""ط""),
        (0x1EEA9, ""M"", ""ي""),
        (0x1EEAA, ""X""),
        (0x1EEAB, ""M"", ""ل""),
        (0x1EEAC, ""M"", ""م""),
        (0x1EEAD, ""M"", ""ن""),
        (0x1EEAE, ""M"", ""س""),
        (0x1EEAF, ""M"", ""ع""),
        (0x1EEB0, ""M"", ""ف""),
        (0x1EEB1, ""M"", ""ص""),
        (0x1EEB2, ""M"", ""ق""),
        (0x1EEB3, ""M"", ""ر""),
        (0x1EEB4, ""M"", ""ش""),
        (0x1EEB5, ""M"", ""ت""),
        (0x1EEB6, ""M"", ""ث""),
        (0x1EEB7, ""M"", ""خ""),
        (0x1EEB8, ""M"", ""ذ""),
    ]


def _seg_74() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x1EEB9, ""M"", ""ض""),
        (0x1EEBA, ""M"", ""ظ""),
        (0x1EEBB, ""M"", ""غ""),
        (0x1EEBC, ""X""),
        (0x1EEF0, ""V""),
        (0x1EEF2, ""X""),
        (0x1F000, ""V""),
        (0x1F02C, ""X""),
        (0x1F030, ""V""),
        (0x1F094, ""X""),
        (0x1F0A0, ""V""),
        (0x1F0AF, ""X""),
        (0x1F0B1, ""V""),
        (0x1F0C0, ""X""),
        (0x1F0C1, ""V""),
        (0x1F0D0, ""X""),
        (0x1F0D1, ""V""),
        (0x1F0F6, ""X""),
        (0x1F101, ""3"", ""0,""),
        (0x1F102, ""3"", ""1,""),
        (0x1F103, ""3"", ""2,""),
        (0x1F104, ""3"", ""3,""),
        (0x1F105, ""3"", ""4,""),
        (0x1F106, ""3"", ""5,""),
        (0x1F107, ""3"", ""6,""),
        (0x1F108, ""3"", ""7,""),
        (0x1F109, ""3"", ""8,""),
        (0x1F10A, ""3"", ""9,""),
        (0x1F10B, ""V""),
        (0x1F110, ""3"", ""(a)""),
        (0x1F111, ""3"", ""(b)""),
        (0x1F112, ""3"", ""(c)""),
        (0x1F113, ""3"", ""(d)""),
        (0x1F114, ""3"", ""(e)""),
        (0x1F115, ""3"", ""(f)""),
        (0x1F116, ""3"", ""(g)""),
        (0x1F117, ""3"", ""(h)""),
        (0x1F118, ""3"", ""(i)""),
        (0x1F119, ""3"", ""(j)""),
        (0x1F11A, ""3"", ""(k)""),
        (0x1F11B, ""3"", ""(l)""),
        (0x1F11C, ""3"", ""(m)""),
        (0x1F11D, ""3"", ""(n)""),
        (0x1F11E, ""3"", ""(o)""),
        (0x1F11F, ""3"", ""(p)""),
        (0x1F120, ""3"", ""(q)""),
        (0x1F121, ""3"", ""(r)""),
        (0x1F122, ""3"", ""(s)""),
        (0x1F123, ""3"", ""(t)""),
        (0x1F124, ""3"", ""(u)""),
        (0x1F125, ""3"", ""(v)""),
        (0x1F126, ""3"", ""(w)""),
        (0x1F127, ""3"", ""(x)""),
        (0x1F128, ""3"", ""(y)""),
        (0x1F129, ""3"", ""(z)""),
        (0x1F12A, ""M"", ""〔s〕""),
        (0x1F12B, ""M"", ""c""),
        (0x1F12C, ""M"", ""r""),
        (0x1F12D, ""M"", ""cd""),
        (0x1F12E, ""M"", ""wz""),
        (0x1F12F, ""V""),
        (0x1F130, ""M"", ""a""),
        (0x1F131, ""M"", ""b""),
        (0x1F132, ""M"", ""c""),
        (0x1F133, ""M"", ""d""),
        (0x1F134, ""M"", ""e""),
        (0x1F135, ""M"", ""f""),
        (0x1F136, ""M"", ""g""),
        (0x1F137, ""M"", ""h""),
        (0x1F138, ""M"", ""i""),
        (0x1F139, ""M"", ""j""),
        (0x1F13A, ""M"", ""k""),
        (0x1F13B, ""M"", ""l""),
        (0x1F13C, ""M"", ""m""),
        (0x1F13D, ""M"", ""n""),
        (0x1F13E, ""M"", ""o""),
        (0x1F13F, ""M"", ""p""),
        (0x1F140, ""M"", ""q""),
        (0x1F141, ""M"", ""r""),
        (0x1F142, ""M"", ""s""),
        (0x1F143, ""M"", ""t""),
        (0x1F144, ""M"", ""u""),
        (0x1F145, ""M"", ""v""),
        (0x1F146, ""M"", ""w""),
        (0x1F147, ""M"", ""x""),
        (0x1F148, ""M"", ""y""),
        (0x1F149, ""M"", ""z""),
        (0x1F14A, ""M"", ""hv""),
        (0x1F14B, ""M"", ""mv""),
        (0x1F14C, ""M"", ""sd""),
        (0x1F14D, ""M"", ""ss""),
        (0x1F14E, ""M"", ""ppv""),
        (0x1F14F, ""M"", ""wc""),
        (0x1F150, ""V""),
        (0x1F16A, ""M"", ""mc""),
        (0x1F16B, ""M"", ""md""),
        (0x1F16C, ""M"", ""mr""),
        (0x1F16D, ""V""),
        (0x1F190, ""M"", ""dj""),
        (0x1F191, ""V""),
    ]


def _seg_75() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x1F1AE, ""X""),
        (0x1F1E6, ""V""),
        (0x1F200, ""M"", ""ほか""),
        (0x1F201, ""M"", ""ココ""),
        (0x1F202, ""M"", ""サ""),
        (0x1F203, ""X""),
        (0x1F210, ""M"", ""手""),
        (0x1F211, ""M"", ""字""),
        (0x1F212, ""M"", ""双""),
        (0x1F213, ""M"", ""デ""),
        (0x1F214, ""M"", ""二""),
        (0x1F215, ""M"", ""多""),
        (0x1F216, ""M"", ""解""),
        (0x1F217, ""M"", ""天""),
        (0x1F218, ""M"", ""交""),
        (0x1F219, ""M"", ""映""),
        (0x1F21A, ""M"", ""無""),
        (0x1F21B, ""M"", ""料""),
        (0x1F21C, ""M"", ""前""),
        (0x1F21D, ""M"", ""後""),
        (0x1F21E, ""M"", ""再""),
        (0x1F21F, ""M"", ""新""),
        (0x1F220, ""M"", ""初""),
        (0x1F221, ""M"", ""終""),
        (0x1F222, ""M"", ""生""),
        (0x1F223, ""M"", ""販""),
        (0x1F224, ""M"", ""声""),
        (0x1F225, ""M"", ""吹""),
        (0x1F226, ""M"", ""演""),
        (0x1F227, ""M"", ""投""),
        (0x1F228, ""M"", ""捕""),
        (0x1F229, ""M"", ""一""),
        (0x1F22A, ""M"", ""三""),
        (0x1F22B, ""M"", ""遊""),
        (0x1F22C, ""M"", ""左""),
        (0x1F22D, ""M"", ""中""),
        (0x1F22E, ""M"", ""右""),
        (0x1F22F, ""M"", ""指""),
        (0x1F230, ""M"", ""走""),
        (0x1F231, ""M"", ""打""),
        (0x1F232, ""M"", ""禁""),
        (0x1F233, ""M"", ""空""),
        (0x1F234, ""M"", ""合""),
        (0x1F235, ""M"", ""満""),
        (0x1F236, ""M"", ""有""),
        (0x1F237, ""M"", ""月""),
        (0x1F238, ""M"", ""申""),
        (0x1F239, ""M"", ""割""),
        (0x1F23A, ""M"", ""営""),
        (0x1F23B, ""M"", ""配""),
        (0x1F23C, ""X""),
        (0x1F240, ""M"", ""〔本〕""),
        (0x1F241, ""M"", ""〔三〕""),
        (0x1F242, ""M"", ""〔二〕""),
        (0x1F243, ""M"", ""〔安〕""),
        (0x1F244, ""M"", ""〔点〕""),
        (0x1F245, ""M"", ""〔打〕""),
        (0x1F246, ""M"", ""〔盗〕""),
        (0x1F247, ""M"", ""〔勝〕""),
        (0x1F248, ""M"", ""〔敗〕""),
        (0x1F249, ""X""),
        (0x1F250, ""M"", ""得""),
        (0x1F251, ""M"", ""可""),
        (0x1F252, ""X""),
        (0x1F260, ""V""),
        (0x1F266, ""X""),
        (0x1F300, ""V""),
        (0x1F6D8, ""X""),
        (0x1F6DC, ""V""),
        (0x1F6ED, ""X""),
        (0x1F6F0, ""V""),
        (0x1F6FD, ""X""),
        (0x1F700, ""V""),
        (0x1F777, ""X""),
        (0x1F77B, ""V""),
        (0x1F7DA, ""X""),
        (0x1F7E0, ""V""),
        (0x1F7EC, ""X""),
        (0x1F7F0, ""V""),
        (0x1F7F1, ""X""),
        (0x1F800, ""V""),
        (0x1F80C, ""X""),
        (0x1F810, ""V""),
        (0x1F848, ""X""),
        (0x1F850, ""V""),
        (0x1F85A, ""X""),
        (0x1F860, ""V""),
        (0x1F888, ""X""),
        (0x1F890, ""V""),
        (0x1F8AE, ""X""),
        (0x1F8B0, ""V""),
        (0x1F8B2, ""X""),
        (0x1F900, ""V""),
        (0x1FA54, ""X""),
        (0x1FA60, ""V""),
        (0x1FA6E, ""X""),
        (0x1FA70, ""V""),
        (0x1FA7D, ""X""),
        (0x1FA80, ""V""),
        (0x1FA89, ""X""),
    ]


def _seg_76() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x1FA90, ""V""),
        (0x1FABE, ""X""),
        (0x1FABF, ""V""),
        (0x1FAC6, ""X""),
        (0x1FACE, ""V""),
        (0x1FADC, ""X""),
        (0x1FAE0, ""V""),
        (0x1FAE9, ""X""),
        (0x1FAF0, ""V""),
        (0x1FAF9, ""X""),
        (0x1FB00, ""V""),
        (0x1FB93, ""X""),
        (0x1FB94, ""V""),
        (0x1FBCB, ""X""),
        (0x1FBF0, ""M"", ""0""),
        (0x1FBF1, ""M"", ""1""),
        (0x1FBF2, ""M"", ""2""),
        (0x1FBF3, ""M"", ""3""),
        (0x1FBF4, ""M"", ""4""),
        (0x1FBF5, ""M"", ""5""),
        (0x1FBF6, ""M"", ""6""),
        (0x1FBF7, ""M"", ""7""),
        (0x1FBF8, ""M"", ""8""),
        (0x1FBF9, ""M"", ""9""),
        (0x1FBFA, ""X""),
        (0x20000, ""V""),
        (0x2A6E0, ""X""),
        (0x2A700, ""V""),
        (0x2B73A, ""X""),
        (0x2B740, ""V""),
        (0x2B81E, ""X""),
        (0x2B820, ""V""),
        (0x2CEA2, ""X""),
        (0x2CEB0, ""V""),
        (0x2EBE1, ""X""),
        (0x2EBF0, ""V""),
        (0x2EE5E, ""X""),
        (0x2F800, ""M"", ""丽""),
        (0x2F801, ""M"", ""丸""),
        (0x2F802, ""M"", ""乁""),
        (0x2F803, ""M"", ""𠄢""),
        (0x2F804, ""M"", ""你""),
        (0x2F805, ""M"", ""侮""),
        (0x2F806, ""M"", ""侻""),
        (0x2F807, ""M"", ""倂""),
        (0x2F808, ""M"", ""偺""),
        (0x2F809, ""M"", ""備""),
        (0x2F80A, ""M"", ""僧""),
        (0x2F80B, ""M"", ""像""),
        (0x2F80C, ""M"", ""㒞""),
        (0x2F80D, ""M"", ""𠘺""),
        (0x2F80E, ""M"", ""免""),
        (0x2F80F, ""M"", ""兔""),
        (0x2F810, ""M"", ""兤""),
        (0x2F811, ""M"", ""具""),
        (0x2F812, ""M"", ""𠔜""),
        (0x2F813, ""M"", ""㒹""),
        (0x2F814, ""M"", ""內""),
        (0x2F815, ""M"", ""再""),
        (0x2F816, ""M"", ""𠕋""),
        (0x2F817, ""M"", ""冗""),
        (0x2F818, ""M"", ""冤""),
        (0x2F819, ""M"", ""仌""),
        (0x2F81A, ""M"", ""冬""),
        (0x2F81B, ""M"", ""况""),
        (0x2F81C, ""M"", ""𩇟""),
        (0x2F81D, ""M"", ""凵""),
        (0x2F81E, ""M"", ""刃""),
        (0x2F81F, ""M"", ""㓟""),
        (0x2F820, ""M"", ""刻""),
        (0x2F821, ""M"", ""剆""),
        (0x2F822, ""M"", ""割""),
        (0x2F823, ""M"", ""剷""),
        (0x2F824, ""M"", ""㔕""),
        (0x2F825, ""M"", ""勇""),
        (0x2F826, ""M"", ""勉""),
        (0x2F827, ""M"", ""勤""),
        (0x2F828, ""M"", ""勺""),
        (0x2F829, ""M"", ""包""),
        (0x2F82A, ""M"", ""匆""),
        (0x2F82B, ""M"", ""北""),
        (0x2F82C, ""M"", ""卉""),
        (0x2F82D, ""M"", ""卑""),
        (0x2F82E, ""M"", ""博""),
        (0x2F82F, ""M"", ""即""),
        (0x2F830, ""M"", ""卽""),
        (0x2F831, ""M"", ""卿""),
        (0x2F834, ""M"", ""𠨬""),
        (0x2F835, ""M"", ""灰""),
        (0x2F836, ""M"", ""及""),
        (0x2F837, ""M"", ""叟""),
        (0x2F838, ""M"", ""𠭣""),
        (0x2F839, ""M"", ""叫""),
        (0x2F83A, ""M"", ""叱""),
        (0x2F83B, ""M"", ""吆""),
        (0x2F83C, ""M"", ""咞""),
        (0x2F83D, ""M"", ""吸""),
        (0x2F83E, ""M"", ""呈""),
        (0x2F83F, ""M"", ""周""),
        (0x2F840, ""M"", ""咢""),
    ]


def _seg_77() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x2F841, ""M"", ""哶""),
        (0x2F842, ""M"", ""唐""),
        (0x2F843, ""M"", ""啓""),
        (0x2F844, ""M"", ""啣""),
        (0x2F845, ""M"", ""善""),
        (0x2F847, ""M"", ""喙""),
        (0x2F848, ""M"", ""喫""),
        (0x2F849, ""M"", ""喳""),
        (0x2F84A, ""M"", ""嗂""),
        (0x2F84B, ""M"", ""圖""),
        (0x2F84C, ""M"", ""嘆""),
        (0x2F84D, ""M"", ""圗""),
        (0x2F84E, ""M"", ""噑""),
        (0x2F84F, ""M"", ""噴""),
        (0x2F850, ""M"", ""切""),
        (0x2F851, ""M"", ""壮""),
        (0x2F852, ""M"", ""城""),
        (0x2F853, ""M"", ""埴""),
        (0x2F854, ""M"", ""堍""),
        (0x2F855, ""M"", ""型""),
        (0x2F856, ""M"", ""堲""),
        (0x2F857, ""M"", ""報""),
        (0x2F858, ""M"", ""墬""),
        (0x2F859, ""M"", ""𡓤""),
        (0x2F85A, ""M"", ""売""),
        (0x2F85B, ""M"", ""壷""),
        (0x2F85C, ""M"", ""夆""),
        (0x2F85D, ""M"", ""多""),
        (0x2F85E, ""M"", ""夢""),
        (0x2F85F, ""M"", ""奢""),
        (0x2F860, ""M"", ""𡚨""),
        (0x2F861, ""M"", ""𡛪""),
        (0x2F862, ""M"", ""姬""),
        (0x2F863, ""M"", ""娛""),
        (0x2F864, ""M"", ""娧""),
        (0x2F865, ""M"", ""姘""),
        (0x2F866, ""M"", ""婦""),
        (0x2F867, ""M"", ""㛮""),
        (0x2F868, ""X""),
        (0x2F869, ""M"", ""嬈""),
        (0x2F86A, ""M"", ""嬾""),
        (0x2F86C, ""M"", ""𡧈""),
        (0x2F86D, ""M"", ""寃""),
        (0x2F86E, ""M"", ""寘""),
        (0x2F86F, ""M"", ""寧""),
        (0x2F870, ""M"", ""寳""),
        (0x2F871, ""M"", ""𡬘""),
        (0x2F872, ""M"", ""寿""),
        (0x2F873, ""M"", ""将""),
        (0x2F874, ""X""),
        (0x2F875, ""M"", ""尢""),
        (0x2F876, ""M"", ""㞁""),
        (0x2F877, ""M"", ""屠""),
        (0x2F878, ""M"", ""屮""),
        (0x2F879, ""M"", ""峀""),
        (0x2F87A, ""M"", ""岍""),
        (0x2F87B, ""M"", ""𡷤""),
        (0x2F87C, ""M"", ""嵃""),
        (0x2F87D, ""M"", ""𡷦""),
        (0x2F87E, ""M"", ""嵮""),
        (0x2F87F, ""M"", ""嵫""),
        (0x2F880, ""M"", ""嵼""),
        (0x2F881, ""M"", ""巡""),
        (0x2F882, ""M"", ""巢""),
        (0x2F883, ""M"", ""㠯""),
        (0x2F884, ""M"", ""巽""),
        (0x2F885, ""M"", ""帨""),
        (0x2F886, ""M"", ""帽""),
        (0x2F887, ""M"", ""幩""),
        (0x2F888, ""M"", ""㡢""),
        (0x2F889, ""M"", ""𢆃""),
        (0x2F88A, ""M"", ""㡼""),
        (0x2F88B, ""M"", ""庰""),
        (0x2F88C, ""M"", ""庳""),
        (0x2F88D, ""M"", ""庶""),
        (0x2F88E, ""M"", ""廊""),
        (0x2F88F, ""M"", ""𪎒""),
        (0x2F890, ""M"", ""廾""),
        (0x2F891, ""M"", ""𢌱""),
        (0x2F893, ""M"", ""舁""),
        (0x2F894, ""M"", ""弢""),
        (0x2F896, ""M"", ""㣇""),
        (0x2F897, ""M"", ""𣊸""),
        (0x2F898, ""M"", ""𦇚""),
        (0x2F899, ""M"", ""形""),
        (0x2F89A, ""M"", ""彫""),
        (0x2F89B, ""M"", ""㣣""),
        (0x2F89C, ""M"", ""徚""),
        (0x2F89D, ""M"", ""忍""),
        (0x2F89E, ""M"", ""志""),
        (0x2F89F, ""M"", ""忹""),
        (0x2F8A0, ""M"", ""悁""),
        (0x2F8A1, ""M"", ""㤺""),
        (0x2F8A2, ""M"", ""㤜""),
        (0x2F8A3, ""M"", ""悔""),
        (0x2F8A4, ""M"", ""𢛔""),
        (0x2F8A5, ""M"", ""惇""),
        (0x2F8A6, ""M"", ""慈""),
        (0x2F8A7, ""M"", ""慌""),
        (0x2F8A8, ""M"", ""慎""),
    ]


def _seg_78() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x2F8A9, ""M"", ""慌""),
        (0x2F8AA, ""M"", ""慺""),
        (0x2F8AB, ""M"", ""憎""),
        (0x2F8AC, ""M"", ""憲""),
        (0x2F8AD, ""M"", ""憤""),
        (0x2F8AE, ""M"", ""憯""),
        (0x2F8AF, ""M"", ""懞""),
        (0x2F8B0, ""M"", ""懲""),
        (0x2F8B1, ""M"", ""懶""),
        (0x2F8B2, ""M"", ""成""),
        (0x2F8B3, ""M"", ""戛""),
        (0x2F8B4, ""M"", ""扝""),
        (0x2F8B5, ""M"", ""抱""),
        (0x2F8B6, ""M"", ""拔""),
        (0x2F8B7, ""M"", ""捐""),
        (0x2F8B8, ""M"", ""𢬌""),
        (0x2F8B9, ""M"", ""挽""),
        (0x2F8BA, ""M"", ""拼""),
        (0x2F8BB, ""M"", ""捨""),
        (0x2F8BC, ""M"", ""掃""),
        (0x2F8BD, ""M"", ""揤""),
        (0x2F8BE, ""M"", ""𢯱""),
        (0x2F8BF, ""M"", ""搢""),
        (0x2F8C0, ""M"", ""揅""),
        (0x2F8C1, ""M"", ""掩""),
        (0x2F8C2, ""M"", ""㨮""),
        (0x2F8C3, ""M"", ""摩""),
        (0x2F8C4, ""M"", ""摾""),
        (0x2F8C5, ""M"", ""撝""),
        (0x2F8C6, ""M"", ""摷""),
        (0x2F8C7, ""M"", ""㩬""),
        (0x2F8C8, ""M"", ""敏""),
        (0x2F8C9, ""M"", ""敬""),
        (0x2F8CA, ""M"", ""𣀊""),
        (0x2F8CB, ""M"", ""旣""),
        (0x2F8CC, ""M"", ""書""),
        (0x2F8CD, ""M"", ""晉""),
        (0x2F8CE, ""M"", ""㬙""),
        (0x2F8CF, ""M"", ""暑""),
        (0x2F8D0, ""M"", ""㬈""),
        (0x2F8D1, ""M"", ""㫤""),
        (0x2F8D2, ""M"", ""冒""),
        (0x2F8D3, ""M"", ""冕""),
        (0x2F8D4, ""M"", ""最""),
        (0x2F8D5, ""M"", ""暜""),
        (0x2F8D6, ""M"", ""肭""),
        (0x2F8D7, ""M"", ""䏙""),
        (0x2F8D8, ""M"", ""朗""),
        (0x2F8D9, ""M"", ""望""),
        (0x2F8DA, ""M"", ""朡""),
        (0x2F8DB, ""M"", ""杞""),
        (0x2F8DC, ""M"", ""杓""),
        (0x2F8DD, ""M"", ""𣏃""),
        (0x2F8DE, ""M"", ""㭉""),
        (0x2F8DF, ""M"", ""柺""),
        (0x2F8E0, ""M"", ""枅""),
        (0x2F8E1, ""M"", ""桒""),
        (0x2F8E2, ""M"", ""梅""),
        (0x2F8E3, ""M"", ""𣑭""),
        (0x2F8E4, ""M"", ""梎""),
        (0x2F8E5, ""M"", ""栟""),
        (0x2F8E6, ""M"", ""椔""),
        (0x2F8E7, ""M"", ""㮝""),
        (0x2F8E8, ""M"", ""楂""),
        (0x2F8E9, ""M"", ""榣""),
        (0x2F8EA, ""M"", ""槪""),
        (0x2F8EB, ""M"", ""檨""),
        (0x2F8EC, ""M"", ""𣚣""),
        (0x2F8ED, ""M"", ""櫛""),
        (0x2F8EE, ""M"", ""㰘""),
        (0x2F8EF, ""M"", ""次""),
        (0x2F8F0, ""M"", ""𣢧""),
        (0x2F8F1, ""M"", ""歔""),
        (0x2F8F2, ""M"", ""㱎""),
        (0x2F8F3, ""M"", ""歲""),
        (0x2F8F4, ""M"", ""殟""),
        (0x2F8F5, ""M"", ""殺""),
        (0x2F8F6, ""M"", ""殻""),
        (0x2F8F7, ""M"", ""𣪍""),
        (0x2F8F8, ""M"", ""𡴋""),
        (0x2F8F9, ""M"", ""𣫺""),
        (0x2F8FA, ""M"", ""汎""),
        (0x2F8FB, ""M"", ""𣲼""),
        (0x2F8FC, ""M"", ""沿""),
        (0x2F8FD, ""M"", ""泍""),
        (0x2F8FE, ""M"", ""汧""),
        (0x2F8FF, ""M"", ""洖""),
        (0x2F900, ""M"", ""派""),
        (0x2F901, ""M"", ""海""),
        (0x2F902, ""M"", ""流""),
        (0x2F903, ""M"", ""浩""),
        (0x2F904, ""M"", ""浸""),
        (0x2F905, ""M"", ""涅""),
        (0x2F906, ""M"", ""𣴞""),
        (0x2F907, ""M"", ""洴""),
        (0x2F908, ""M"", ""港""),
        (0x2F909, ""M"", ""湮""),
        (0x2F90A, ""M"", ""㴳""),
        (0x2F90B, ""M"", ""滋""),
        (0x2F90C, ""M"", ""滇""),
    ]


def _seg_79() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x2F90D, ""M"", ""𣻑""),
        (0x2F90E, ""M"", ""淹""),
        (0x2F90F, ""M"", ""潮""),
        (0x2F910, ""M"", ""𣽞""),
        (0x2F911, ""M"", ""𣾎""),
        (0x2F912, ""M"", ""濆""),
        (0x2F913, ""M"", ""瀹""),
        (0x2F914, ""M"", ""瀞""),
        (0x2F915, ""M"", ""瀛""),
        (0x2F916, ""M"", ""㶖""),
        (0x2F917, ""M"", ""灊""),
        (0x2F918, ""M"", ""災""),
        (0x2F919, ""M"", ""灷""),
        (0x2F91A, ""M"", ""炭""),
        (0x2F91B, ""M"", ""𠔥""),
        (0x2F91C, ""M"", ""煅""),
        (0x2F91D, ""M"", ""𤉣""),
        (0x2F91E, ""M"", ""熜""),
        (0x2F91F, ""X""),
        (0x2F920, ""M"", ""爨""),
        (0x2F921, ""M"", ""爵""),
        (0x2F922, ""M"", ""牐""),
        (0x2F923, ""M"", ""𤘈""),
        (0x2F924, ""M"", ""犀""),
        (0x2F925, ""M"", ""犕""),
        (0x2F926, ""M"", ""𤜵""),
        (0x2F927, ""M"", ""𤠔""),
        (0x2F928, ""M"", ""獺""),
        (0x2F929, ""M"", ""王""),
        (0x2F92A, ""M"", ""㺬""),
        (0x2F92B, ""M"", ""玥""),
        (0x2F92C, ""M"", ""㺸""),
        (0x2F92E, ""M"", ""瑇""),
        (0x2F92F, ""M"", ""瑜""),
        (0x2F930, ""M"", ""瑱""),
        (0x2F931, ""M"", ""璅""),
        (0x2F932, ""M"", ""瓊""),
        (0x2F933, ""M"", ""㼛""),
        (0x2F934, ""M"", ""甤""),
        (0x2F935, ""M"", ""𤰶""),
        (0x2F936, ""M"", ""甾""),
        (0x2F937, ""M"", ""𤲒""),
        (0x2F938, ""M"", ""異""),
        (0x2F939, ""M"", ""𢆟""),
        (0x2F93A, ""M"", ""瘐""),
        (0x2F93B, ""M"", ""𤾡""),
        (0x2F93C, ""M"", ""𤾸""),
        (0x2F93D, ""M"", ""𥁄""),
        (0x2F93E, ""M"", ""㿼""),
        (0x2F93F, ""M"", ""䀈""),
        (0x2F940, ""M"", ""直""),
        (0x2F941, ""M"", ""𥃳""),
        (0x2F942, ""M"", ""𥃲""),
        (0x2F943, ""M"", ""𥄙""),
        (0x2F944, ""M"", ""𥄳""),
        (0x2F945, ""M"", ""眞""),
        (0x2F946, ""M"", ""真""),
        (0x2F948, ""M"", ""睊""),
        (0x2F949, ""M"", ""䀹""),
        (0x2F94A, ""M"", ""瞋""),
        (0x2F94B, ""M"", ""䁆""),
        (0x2F94C, ""M"", ""䂖""),
        (0x2F94D, ""M"", ""𥐝""),
        (0x2F94E, ""M"", ""硎""),
        (0x2F94F, ""M"", ""碌""),
        (0x2F950, ""M"", ""磌""),
        (0x2F951, ""M"", ""䃣""),
        (0x2F952, ""M"", ""𥘦""),
        (0x2F953, ""M"", ""祖""),
        (0x2F954, ""M"", ""𥚚""),
        (0x2F955, ""M"", ""𥛅""),
        (0x2F956, ""M"", ""福""),
        (0x2F957, ""M"", ""秫""),
        (0x2F958, ""M"", ""䄯""),
        (0x2F959, ""M"", ""穀""),
        (0x2F95A, ""M"", ""穊""),
        (0x2F95B, ""M"", ""穏""),
        (0x2F95C, ""M"", ""𥥼""),
        (0x2F95D, ""M"", ""𥪧""),
        (0x2F95F, ""X""),
        (0x2F960, ""M"", ""䈂""),
        (0x2F961, ""M"", ""𥮫""),
        (0x2F962, ""M"", ""篆""),
        (0x2F963, ""M"", ""築""),
        (0x2F964, ""M"", ""䈧""),
        (0x2F965, ""M"", ""𥲀""),
        (0x2F966, ""M"", ""糒""),
        (0x2F967, ""M"", ""䊠""),
        (0x2F968, ""M"", ""糨""),
        (0x2F969, ""M"", ""糣""),
        (0x2F96A, ""M"", ""紀""),
        (0x2F96B, ""M"", ""𥾆""),
        (0x2F96C, ""M"", ""絣""),
        (0x2F96D, ""M"", ""䌁""),
        (0x2F96E, ""M"", ""緇""),
        (0x2F96F, ""M"", ""縂""),
        (0x2F970, ""M"", ""繅""),
        (0x2F971, ""M"", ""䌴""),
        (0x2F972, ""M"", ""𦈨""),
        (0x2F973, ""M"", ""𦉇""),
    ]


def _seg_80() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x2F974, ""M"", ""䍙""),
        (0x2F975, ""M"", ""𦋙""),
        (0x2F976, ""M"", ""罺""),
        (0x2F977, ""M"", ""𦌾""),
        (0x2F978, ""M"", ""羕""),
        (0x2F979, ""M"", ""翺""),
        (0x2F97A, ""M"", ""者""),
        (0x2F97B, ""M"", ""𦓚""),
        (0x2F97C, ""M"", ""𦔣""),
        (0x2F97D, ""M"", ""聠""),
        (0x2F97E, ""M"", ""𦖨""),
        (0x2F97F, ""M"", ""聰""),
        (0x2F980, ""M"", ""𣍟""),
        (0x2F981, ""M"", ""䏕""),
        (0x2F982, ""M"", ""育""),
        (0x2F983, ""M"", ""脃""),
        (0x2F984, ""M"", ""䐋""),
        (0x2F985, ""M"", ""脾""),
        (0x2F986, ""M"", ""媵""),
        (0x2F987, ""M"", ""𦞧""),
        (0x2F988, ""M"", ""𦞵""),
        (0x2F989, ""M"", ""𣎓""),
        (0x2F98A, ""M"", ""𣎜""),
        (0x2F98B, ""M"", ""舁""),
        (0x2F98C, ""M"", ""舄""),
        (0x2F98D, ""M"", ""辞""),
        (0x2F98E, ""M"", ""䑫""),
        (0x2F98F, ""M"", ""芑""),
        (0x2F990, ""M"", ""芋""),
        (0x2F991, ""M"", ""芝""),
        (0x2F992, ""M"", ""劳""),
        (0x2F993, ""M"", ""花""),
        (0x2F994, ""M"", ""芳""),
        (0x2F995, ""M"", ""芽""),
        (0x2F996, ""M"", ""苦""),
        (0x2F997, ""M"", ""𦬼""),
        (0x2F998, ""M"", ""若""),
        (0x2F999, ""M"", ""茝""),
        (0x2F99A, ""M"", ""荣""),
        (0x2F99B, ""M"", ""莭""),
        (0x2F99C, ""M"", ""茣""),
        (0x2F99D, ""M"", ""莽""),
        (0x2F99E, ""M"", ""菧""),
        (0x2F99F, ""M"", ""著""),
        (0x2F9A0, ""M"", ""荓""),
        (0x2F9A1, ""M"", ""菊""),
        (0x2F9A2, ""M"", ""菌""),
        (0x2F9A3, ""M"", ""菜""),
        (0x2F9A4, ""M"", ""𦰶""),
        (0x2F9A5, ""M"", ""𦵫""),
        (0x2F9A6, ""M"", ""𦳕""),
        (0x2F9A7, ""M"", ""䔫""),
        (0x2F9A8, ""M"", ""蓱""),
        (0x2F9A9, ""M"", ""蓳""),
        (0x2F9AA, ""M"", ""蔖""),
        (0x2F9AB, ""M"", ""𧏊""),
        (0x2F9AC, ""M"", ""蕤""),
        (0x2F9AD, ""M"", ""𦼬""),
        (0x2F9AE, ""M"", ""䕝""),
        (0x2F9AF, ""M"", ""䕡""),
        (0x2F9B0, ""M"", ""𦾱""),
        (0x2F9B1, ""M"", ""𧃒""),
        (0x2F9B2, ""M"", ""䕫""),
        (0x2F9B3, ""M"", ""虐""),
        (0x2F9B4, ""M"", ""虜""),
        (0x2F9B5, ""M"", ""虧""),
        (0x2F9B6, ""M"", ""虩""),
        (0x2F9B7, ""M"", ""蚩""),
        (0x2F9B8, ""M"", ""蚈""),
        (0x2F9B9, ""M"", ""蜎""),
        (0x2F9BA, ""M"", ""蛢""),
        (0x2F9BB, ""M"", ""蝹""),
        (0x2F9BC, ""M"", ""蜨""),
        (0x2F9BD, ""M"", ""蝫""),
        (0x2F9BE, ""M"", ""螆""),
        (0x2F9BF, ""X""),
        (0x2F9C0, ""M"", ""蟡""),
        (0x2F9C1, ""M"", ""蠁""),
        (0x2F9C2, ""M"", ""䗹""),
        (0x2F9C3, ""M"", ""衠""),
        (0x2F9C4, ""M"", ""衣""),
        (0x2F9C5, ""M"", ""𧙧""),
        (0x2F9C6, ""M"", ""裗""),
        (0x2F9C7, ""M"", ""裞""),
        (0x2F9C8, ""M"", ""䘵""),
        (0x2F9C9, ""M"", ""裺""),
        (0x2F9CA, ""M"", ""㒻""),
        (0x2F9CB, ""M"", ""𧢮""),
        (0x2F9CC, ""M"", ""𧥦""),
        (0x2F9CD, ""M"", ""䚾""),
        (0x2F9CE, ""M"", ""䛇""),
        (0x2F9CF, ""M"", ""誠""),
        (0x2F9D0, ""M"", ""諭""),
        (0x2F9D1, ""M"", ""變""),
        (0x2F9D2, ""M"", ""豕""),
        (0x2F9D3, ""M"", ""𧲨""),
        (0x2F9D4, ""M"", ""貫""),
        (0x2F9D5, ""M"", ""賁""),
        (0x2F9D6, ""M"", ""贛""),
        (0x2F9D7, ""M"", ""起""),
    ]


def _seg_81() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
    return [
        (0x2F9D8, ""M"", ""𧼯""),
        (0x2F9D9, ""M"", ""𠠄""),
        (0x2F9DA, ""M"", ""跋""),
        (0x2F9DB, ""M"", ""趼""),
        (0x2F9DC, ""M"", ""跰""),
        (0x2F9DD, ""M"", ""𠣞""),
        (0x2F9DE, ""M"", ""軔""),
        (0x2F9DF, ""M"", ""輸""),
        (0x2F9E0, ""M"", ""𨗒""),
        (0x2F9E1, ""M"", ""𨗭""),
        (0x2F9E2, ""M"", ""邔""),
        (0x2F9E3, ""M"", ""郱""),
        (0x2F9E4, ""M"", ""鄑""),
        (0x2F9E5, ""M"", ""𨜮""),
        (0x2F9E6, ""M"", ""鄛""),
        (0x2F9E7, ""M"", ""鈸""),
        (0x2F9E8, ""M"", ""鋗""),
        (0x2F9E9, ""M"", ""鋘""),
        (0x2F9EA, ""M"", ""鉼""),
        (0x2F9EB, ""M"", ""鏹""),
        (0x2F9EC, ""M"", ""鐕""),
        (0x2F9ED, ""M"", ""𨯺""),
        (0x2F9EE, ""M"", ""開""),
        (0x2F9EF, ""M"", ""䦕""),
        (0x2F9F0, ""M"", ""閷""),
        (0x2F9F1, ""M"", ""𨵷""),
        (0x2F9F2, ""M"", ""䧦""),
        (0x2F9F3, ""M"", ""雃""),
        (0x2F9F4, ""M"", ""嶲""),
        (0x2F9F5, ""M"", ""霣""),
        (0x2F9F6, ""M"", ""𩅅""),
        (0x2F9F7, ""M"", ""𩈚""),
        (0x2F9F8, ""M"", ""䩮""),
        (0x2F9F9, ""M"", ""䩶""),
        (0x2F9FA, ""M"", ""韠""),
        (0x2F9FB, ""M"", ""𩐊""),
        (0x2F9FC, ""M"", ""䪲""),
        (0x2F9FD, ""M"", ""𩒖""),
        (0x2F9FE, ""M"", ""頋""),
        (0x2FA00, ""M"", ""頩""),
        (0x2FA01, ""M"", ""𩖶""),
        (0x2FA02, ""M"", ""飢""),
        (0x2FA03, ""M"", ""䬳""),
        (0x2FA04, ""M"", ""餩""),
        (0x2FA05, ""M"", ""馧""),
        (0x2FA06, ""M"", ""駂""),
        (0x2FA07, ""M"", ""駾""),
        (0x2FA08, ""M"", ""䯎""),
        (0x2FA09, ""M"", ""𩬰""),
        (0x2FA0A, ""M"", ""鬒""),
        (0x2FA0B, ""M"", ""鱀""),
        (0x2FA0C, ""M"", ""鳽""),
        (0x2FA0D, ""M"", ""䳎""),
        (0x2FA0E, ""M"", ""䳭""),
        (0x2FA0F, ""M"", ""鵧""),
        (0x2FA10, ""M"", ""𪃎""),
        (0x2FA11, ""M"", ""䳸""),
        (0x2FA12, ""M"", ""𪄅""),
        (0x2FA13, ""M"", ""𪈎""),
        (0x2FA14, ""M"", ""𪊑""),
        (0x2FA15, ""M"", ""麻""),
        (0x2FA16, ""M"", ""䵖""),
        (0x2FA17, ""M"", ""黹""),
        (0x2FA18, ""M"", ""黾""),
        (0x2FA19, ""M"", ""鼅""),
        (0x2FA1A, ""M"", ""鼏""),
        (0x2FA1B, ""M"", ""鼖""),
        (0x2FA1C, ""M"", ""鼻""),
        (0x2FA1D, ""M"", ""𪘀""),
        (0x2FA1E, ""X""),
        (0x30000, ""V""),
        (0x3134B, ""X""),
        (0x31350, ""V""),
        (0x323B0, ""X""),
        (0xE0100, ""I""),
        (0xE01F0, ""X""),
    ]


uts46data = tuple(
    _seg_0()
    + _seg_1()
    + _seg_2()
    + _seg_3()
    + _seg_4()
    + _seg_5()
    + _seg_6()
    + _seg_7()
    + _seg_8()
    + _seg_9()
    + _seg_10()
    + _seg_11()
    + _seg_12()
    + _seg_13()
    + _seg_14()
    + _seg_15()
    + _seg_16()
    + _seg_17()
    + _seg_18()
    + _seg_19()
    + _seg_20()
    + _seg_21()
    + _seg_22()
    + _seg_23()
    + _seg_24()
    + _seg_25()
    + _seg_26()
    + _seg_27()
    + _seg_28()
    + _seg_29()
    + _seg_30()
    + _seg_31()
    + _seg_32()
    + _seg_33()
    + _seg_34()
    + _seg_35()
    + _seg_36()
    + _seg_37()
    + _seg_38()
    + _seg_39()
    + _seg_40()
    + _seg_41()
    + _seg_42()
    + _seg_43()
    + _seg_44()
    + _seg_45()
    + _seg_46()
    + _seg_47()
    + _seg_48()
    + _seg_49()
    + _seg_50()
    + _seg_51()
    + _seg_52()
    + _seg_53()
    + _seg_54()
    + _seg_55()
    + _seg_56()
    + _seg_57()
    + _seg_58()
    + _seg_59()
    + _seg_60()
    + _seg_61()
    + _seg_62()
    + _seg_63()
    + _seg_64()
    + _seg_65()
    + _seg_66()
    + _seg_67()
    + _seg_68()
    + _seg_69()
    + _seg_70()
    + _seg_71()
    + _seg_72()
    + _seg_73()
    + _seg_74()
    + _seg_75()
    + _seg_76()
    + _seg_77()
    + _seg_78()
    + _seg_79()
    + _seg_80()
    + _seg_81()
)  

from .core import (
    IDNABidiError,
    IDNAError,
    InvalidCodepoint,
    InvalidCodepointContext,
    alabel,
    check_bidi,
    check_hyphen_ok,
    check_initial_combiner,
    check_label,
    check_nfc,
    decode,
    encode,
    ulabel,
    uts46_remap,
    valid_contextj,
    valid_contexto,
    valid_label_length,
    valid_string_length,
)
from .intranges import intranges_contain
from .package_data import __version__

__all__ = [
    ""__version__"",
    ""IDNABidiError"",
    ""IDNAError"",
    ""InvalidCodepoint"",
    ""InvalidCodepointContext"",
    ""alabel"",
    ""check_bidi"",
    ""check_hyphen_ok"",
    ""check_initial_combiner"",
    ""check_label"",
    ""check_nfc"",
    ""decode"",
    ""encode"",
    ""intranges_contain"",
    ""ulabel"",
    ""uts46_remap"",
    ""valid_contextj"",
    ""valid_contexto"",
    ""valid_label_length"",
    ""valid_string_length"",
]

class UnpackException(Exception):
    


class BufferFull(UnpackException):
    pass


class OutOfData(UnpackException):
    pass


class FormatError(ValueError, UnpackException):
    


class StackError(ValueError, UnpackException):
    



UnpackValueError = ValueError


class ExtraData(UnpackValueError):
    

    def __init__(self, unpacked, extra):
        self.unpacked = unpacked
        self.extra = extra

    def __str__(self):
        return ""unpack(b) received extra data.""



PackException = Exception
PackValueError = ValueError
PackOverflowError = OverflowError

import datetime
import struct
from collections import namedtuple


class ExtType(namedtuple(""ExtType"", ""code data"")):
    

    def __new__(cls, code, data):
        if not isinstance(code, int):
            raise TypeError(""code must be int"")
        if not isinstance(data, bytes):
            raise TypeError(""data must be bytes"")
        if not 0 <= code <= 127:
            raise ValueError(""code must be 0~127"")
        return super().__new__(cls, code, data)


class Timestamp:
    

    __slots__ = [""seconds"", ""nanoseconds""]

    def __init__(self, seconds, nanoseconds=0):
        
        if not isinstance(seconds, int):
            raise TypeError(""seconds must be an integer"")
        if not isinstance(nanoseconds, int):
            raise TypeError(""nanoseconds must be an integer"")
        if not (0 <= nanoseconds < 10**9):
            raise ValueError(""nanoseconds must be a non-negative integer less than 999999999."")
        self.seconds = seconds
        self.nanoseconds = nanoseconds

    def __repr__(self):
        
        return f""Timestamp(seconds={self.seconds}, nanoseconds={self.nanoseconds})""

    def __eq__(self, other):
        
        if type(other) is self.__class__:
            return self.seconds == other.seconds and self.nanoseconds == other.nanoseconds
        return False

    def __ne__(self, other):
        
        return not self.__eq__(other)

    def __hash__(self):
        return hash((self.seconds, self.nanoseconds))

    @staticmethod
    def from_bytes(b):
        
        if len(b) == 4:
            seconds = struct.unpack(""!L"", b)[0]
            nanoseconds = 0
        elif len(b) == 8:
            data64 = struct.unpack(""!Q"", b)[0]
            seconds = data64 & 0x00000003FFFFFFFF
            nanoseconds = data64 >> 34
        elif len(b) == 12:
            nanoseconds, seconds = struct.unpack(""!Iq"", b)
        else:
            raise ValueError(
                ""Timestamp type can only be created from 32, 64, or 96-bit byte objects""
            )
        return Timestamp(seconds, nanoseconds)

    def to_bytes(self):
        
        if (self.seconds >> 34) == 0:  
            data64 = self.nanoseconds << 34 | self.seconds
            if data64 & 0xFFFFFFFF00000000 == 0:
                
                data = struct.pack(""!L"", data64)
            else:
                
                data = struct.pack(""!Q"", data64)
        else:
            
            data = struct.pack(""!Iq"", self.nanoseconds, self.seconds)
        return data

    @staticmethod
    def from_unix(unix_sec):
        
        seconds = int(unix_sec // 1)
        nanoseconds = int((unix_sec % 1) * 10**9)
        return Timestamp(seconds, nanoseconds)

    def to_unix(self):
        
        return self.seconds + self.nanoseconds / 1e9

    @staticmethod
    def from_unix_nano(unix_ns):
        
        return Timestamp(*divmod(unix_ns, 10**9))

    def to_unix_nano(self):
        
        return self.seconds * 10**9 + self.nanoseconds

    def to_datetime(self):
        
        utc = datetime.timezone.utc
        return datetime.datetime.fromtimestamp(0, utc) + datetime.timedelta(
            seconds=self.seconds, microseconds=self.nanoseconds // 1000
        )

    @staticmethod
    def from_datetime(dt):
        
        return Timestamp(seconds=int(dt.timestamp()), nanoseconds=dt.microsecond * 1000)



import struct
import sys
from datetime import datetime as _DateTime

if hasattr(sys, ""pypy_version_info""):
    from __pypy__ import newlist_hint
    from __pypy__.builders import BytesBuilder

    _USING_STRINGBUILDER = True

    class BytesIO:
        def __init__(self, s=b""""):
            if s:
                self.builder = BytesBuilder(len(s))
                self.builder.append(s)
            else:
                self.builder = BytesBuilder()

        def write(self, s):
            if isinstance(s, memoryview):
                s = s.tobytes()
            elif isinstance(s, bytearray):
                s = bytes(s)
            self.builder.append(s)

        def getvalue(self):
            return self.builder.build()

else:
    from io import BytesIO

    _USING_STRINGBUILDER = False

    def newlist_hint(size):
        return []


from .exceptions import BufferFull, ExtraData, FormatError, OutOfData, StackError
from .ext import ExtType, Timestamp

EX_SKIP = 0
EX_CONSTRUCT = 1
EX_READ_ARRAY_HEADER = 2
EX_READ_MAP_HEADER = 3

TYPE_IMMEDIATE = 0
TYPE_ARRAY = 1
TYPE_MAP = 2
TYPE_RAW = 3
TYPE_BIN = 4
TYPE_EXT = 5

DEFAULT_RECURSE_LIMIT = 511


def _check_type_strict(obj, t, type=type, tuple=tuple):
    if type(t) is tuple:
        return type(obj) in t
    else:
        return type(obj) is t


def _get_data_from_buffer(obj):
    view = memoryview(obj)
    if view.itemsize != 1:
        raise ValueError(""cannot unpack from multi-byte object"")
    return view


def unpackb(packed, **kwargs):
    
    unpacker = Unpacker(None, max_buffer_size=len(packed), **kwargs)
    unpacker.feed(packed)
    try:
        ret = unpacker._unpack()
    except OutOfData:
        raise ValueError(""Unpack failed: incomplete input"")
    except RecursionError:
        raise StackError
    if unpacker._got_extradata():
        raise ExtraData(ret, unpacker._get_extradata())
    return ret


_NO_FORMAT_USED = """"
_MSGPACK_HEADERS = {
    0xC4: (1, _NO_FORMAT_USED, TYPE_BIN),
    0xC5: (2, "">H"", TYPE_BIN),
    0xC6: (4, "">I"", TYPE_BIN),
    0xC7: (2, ""Bb"", TYPE_EXT),
    0xC8: (3, "">Hb"", TYPE_EXT),
    0xC9: (5, "">Ib"", TYPE_EXT),
    0xCA: (4, "">f""),
    0xCB: (8, "">d""),
    0xCC: (1, _NO_FORMAT_USED),
    0xCD: (2, "">H""),
    0xCE: (4, "">I""),
    0xCF: (8, "">Q""),
    0xD0: (1, ""b""),
    0xD1: (2, "">h""),
    0xD2: (4, "">i""),
    0xD3: (8, "">q""),
    0xD4: (1, ""b1s"", TYPE_EXT),
    0xD5: (2, ""b2s"", TYPE_EXT),
    0xD6: (4, ""b4s"", TYPE_EXT),
    0xD7: (8, ""b8s"", TYPE_EXT),
    0xD8: (16, ""b16s"", TYPE_EXT),
    0xD9: (1, _NO_FORMAT_USED, TYPE_RAW),
    0xDA: (2, "">H"", TYPE_RAW),
    0xDB: (4, "">I"", TYPE_RAW),
    0xDC: (2, "">H"", TYPE_ARRAY),
    0xDD: (4, "">I"", TYPE_ARRAY),
    0xDE: (2, "">H"", TYPE_MAP),
    0xDF: (4, "">I"", TYPE_MAP),
}


class Unpacker:
    

    def __init__(
        self,
        file_like=None,
        *,
        read_size=0,
        use_list=True,
        raw=False,
        timestamp=0,
        strict_map_key=True,
        object_hook=None,
        object_pairs_hook=None,
        list_hook=None,
        unicode_errors=None,
        max_buffer_size=100 * 1024 * 1024,
        ext_hook=ExtType,
        max_str_len=-1,
        max_bin_len=-1,
        max_array_len=-1,
        max_map_len=-1,
        max_ext_len=-1,
    ):
        if unicode_errors is None:
            unicode_errors = ""strict""

        if file_like is None:
            self._feeding = True
        else:
            if not callable(file_like.read):
                raise TypeError(""`file_like.read` must be callable"")
            self.file_like = file_like
            self._feeding = False

        
        self._buffer = bytearray()
        
        self._buff_i = 0

        
        
        
        
        
        
        
        self._buf_checkpoint = 0

        if not max_buffer_size:
            max_buffer_size = 2**31 - 1
        if max_str_len == -1:
            max_str_len = max_buffer_size
        if max_bin_len == -1:
            max_bin_len = max_buffer_size
        if max_array_len == -1:
            max_array_len = max_buffer_size
        if max_map_len == -1:
            max_map_len = max_buffer_size // 2
        if max_ext_len == -1:
            max_ext_len = max_buffer_size

        self._max_buffer_size = max_buffer_size
        if read_size > self._max_buffer_size:
            raise ValueError(""read_size must be smaller than max_buffer_size"")
        self._read_size = read_size or min(self._max_buffer_size, 16 * 1024)
        self._raw = bool(raw)
        self._strict_map_key = bool(strict_map_key)
        self._unicode_errors = unicode_errors
        self._use_list = use_list
        if not (0 <= timestamp <= 3):
            raise ValueError(""timestamp must be 0..3"")
        self._timestamp = timestamp
        self._list_hook = list_hook
        self._object_hook = object_hook
        self._object_pairs_hook = object_pairs_hook
        self._ext_hook = ext_hook
        self._max_str_len = max_str_len
        self._max_bin_len = max_bin_len
        self._max_array_len = max_array_len
        self._max_map_len = max_map_len
        self._max_ext_len = max_ext_len
        self._stream_offset = 0

        if list_hook is not None and not callable(list_hook):
            raise TypeError(""`list_hook` is not callable"")
        if object_hook is not None and not callable(object_hook):
            raise TypeError(""`object_hook` is not callable"")
        if object_pairs_hook is not None and not callable(object_pairs_hook):
            raise TypeError(""`object_pairs_hook` is not callable"")
        if object_hook is not None and object_pairs_hook is not None:
            raise TypeError(""object_pairs_hook and object_hook are mutually exclusive"")
        if not callable(ext_hook):
            raise TypeError(""`ext_hook` is not callable"")

    def feed(self, next_bytes):
        assert self._feeding
        view = _get_data_from_buffer(next_bytes)
        if len(self._buffer) - self._buff_i + len(view) > self._max_buffer_size:
            raise BufferFull

        
        if self._buf_checkpoint > 0:
            del self._buffer[: self._buf_checkpoint]
            self._buff_i -= self._buf_checkpoint
            self._buf_checkpoint = 0

        
        self._buffer.extend(view)
        view.release()

    def _consume(self):
        
        self._stream_offset += self._buff_i - self._buf_checkpoint
        self._buf_checkpoint = self._buff_i

    def _got_extradata(self):
        return self._buff_i < len(self._buffer)

    def _get_extradata(self):
        return self._buffer[self._buff_i :]

    def read_bytes(self, n):
        ret = self._read(n, raise_outofdata=False)
        self._consume()
        return ret

    def _read(self, n, raise_outofdata=True):
        
        self._reserve(n, raise_outofdata=raise_outofdata)
        i = self._buff_i
        ret = self._buffer[i : i + n]
        self._buff_i = i + len(ret)
        return ret

    def _reserve(self, n, raise_outofdata=True):
        remain_bytes = len(self._buffer) - self._buff_i - n

        
        if remain_bytes >= 0:
            return

        if self._feeding:
            self._buff_i = self._buf_checkpoint
            raise OutOfData

        
        if self._buf_checkpoint > 0:
            del self._buffer[: self._buf_checkpoint]
            self._buff_i -= self._buf_checkpoint
            self._buf_checkpoint = 0

        
        remain_bytes = -remain_bytes
        if remain_bytes + len(self._buffer) > self._max_buffer_size:
            raise BufferFull
        while remain_bytes > 0:
            to_read_bytes = max(self._read_size, remain_bytes)
            read_data = self.file_like.read(to_read_bytes)
            if not read_data:
                break
            assert isinstance(read_data, bytes)
            self._buffer += read_data
            remain_bytes -= len(read_data)

        if len(self._buffer) < n + self._buff_i and raise_outofdata:
            self._buff_i = 0  
            raise OutOfData

    def _read_header(self):
        typ = TYPE_IMMEDIATE
        n = 0
        obj = None
        self._reserve(1)
        b = self._buffer[self._buff_i]
        self._buff_i += 1
        if b & 0b10000000 == 0:
            obj = b
        elif b & 0b11100000 == 0b11100000:
            obj = -1 - (b ^ 0xFF)
        elif b & 0b11100000 == 0b10100000:
            n = b & 0b00011111
            typ = TYPE_RAW
            if n > self._max_str_len:
                raise ValueError(f""{n} exceeds max_str_len({self._max_str_len})"")
            obj = self._read(n)
        elif b & 0b11110000 == 0b10010000:
            n = b & 0b00001111
            typ = TYPE_ARRAY
            if n > self._max_array_len:
                raise ValueError(f""{n} exceeds max_array_len({self._max_array_len})"")
        elif b & 0b11110000 == 0b10000000:
            n = b & 0b00001111
            typ = TYPE_MAP
            if n > self._max_map_len:
                raise ValueError(f""{n} exceeds max_map_len({self._max_map_len})"")
        elif b == 0xC0:
            obj = None
        elif b == 0xC2:
            obj = False
        elif b == 0xC3:
            obj = True
        elif 0xC4 <= b <= 0xC6:
            size, fmt, typ = _MSGPACK_HEADERS[b]
            self._reserve(size)
            if len(fmt) > 0:
                n = struct.unpack_from(fmt, self._buffer, self._buff_i)[0]
            else:
                n = self._buffer[self._buff_i]
            self._buff_i += size
            if n > self._max_bin_len:
                raise ValueError(f""{n} exceeds max_bin_len({self._max_bin_len})"")
            obj = self._read(n)
        elif 0xC7 <= b <= 0xC9:
            size, fmt, typ = _MSGPACK_HEADERS[b]
            self._reserve(size)
            L, n = struct.unpack_from(fmt, self._buffer, self._buff_i)
            self._buff_i += size
            if L > self._max_ext_len:
                raise ValueError(f""{L} exceeds max_ext_len({self._max_ext_len})"")
            obj = self._read(L)
        elif 0xCA <= b <= 0xD3:
            size, fmt = _MSGPACK_HEADERS[b]
            self._reserve(size)
            if len(fmt) > 0:
                obj = struct.unpack_from(fmt, self._buffer, self._buff_i)[0]
            else:
                obj = self._buffer[self._buff_i]
            self._buff_i += size
        elif 0xD4 <= b <= 0xD8:
            size, fmt, typ = _MSGPACK_HEADERS[b]
            if self._max_ext_len < size:
                raise ValueError(f""{size} exceeds max_ext_len({self._max_ext_len})"")
            self._reserve(size + 1)
            n, obj = struct.unpack_from(fmt, self._buffer, self._buff_i)
            self._buff_i += size + 1
        elif 0xD9 <= b <= 0xDB:
            size, fmt, typ = _MSGPACK_HEADERS[b]
            self._reserve(size)
            if len(fmt) > 0:
                (n,) = struct.unpack_from(fmt, self._buffer, self._buff_i)
            else:
                n = self._buffer[self._buff_i]
            self._buff_i += size
            if n > self._max_str_len:
                raise ValueError(f""{n} exceeds max_str_len({self._max_str_len})"")
            obj = self._read(n)
        elif 0xDC <= b <= 0xDD:
            size, fmt, typ = _MSGPACK_HEADERS[b]
            self._reserve(size)
            (n,) = struct.unpack_from(fmt, self._buffer, self._buff_i)
            self._buff_i += size
            if n > self._max_array_len:
                raise ValueError(f""{n} exceeds max_array_len({self._max_array_len})"")
        elif 0xDE <= b <= 0xDF:
            size, fmt, typ = _MSGPACK_HEADERS[b]
            self._reserve(size)
            (n,) = struct.unpack_from(fmt, self._buffer, self._buff_i)
            self._buff_i += size
            if n > self._max_map_len:
                raise ValueError(f""{n} exceeds max_map_len({self._max_map_len})"")
        else:
            raise FormatError(""Unknown header: 0x%x"" % b)
        return typ, n, obj

    def _unpack(self, execute=EX_CONSTRUCT):
        typ, n, obj = self._read_header()

        if execute == EX_READ_ARRAY_HEADER:
            if typ != TYPE_ARRAY:
                raise ValueError(""Expected array"")
            return n
        if execute == EX_READ_MAP_HEADER:
            if typ != TYPE_MAP:
                raise ValueError(""Expected map"")
            return n
        
        if typ == TYPE_ARRAY:
            if execute == EX_SKIP:
                for i in range(n):
                    
                    self._unpack(EX_SKIP)
                return
            ret = newlist_hint(n)
            for i in range(n):
                ret.append(self._unpack(EX_CONSTRUCT))
            if self._list_hook is not None:
                ret = self._list_hook(ret)
            
            return ret if self._use_list else tuple(ret)
        if typ == TYPE_MAP:
            if execute == EX_SKIP:
                for i in range(n):
                    
                    self._unpack(EX_SKIP)
                    self._unpack(EX_SKIP)
                return
            if self._object_pairs_hook is not None:
                ret = self._object_pairs_hook(
                    (self._unpack(EX_CONSTRUCT), self._unpack(EX_CONSTRUCT)) for _ in range(n)
                )
            else:
                ret = {}
                for _ in range(n):
                    key = self._unpack(EX_CONSTRUCT)
                    if self._strict_map_key and type(key) not in (str, bytes):
                        raise ValueError(""%s is not allowed for map key"" % str(type(key)))
                    if isinstance(key, str):
                        key = sys.intern(key)
                    ret[key] = self._unpack(EX_CONSTRUCT)
                if self._object_hook is not None:
                    ret = self._object_hook(ret)
            return ret
        if execute == EX_SKIP:
            return
        if typ == TYPE_RAW:
            if self._raw:
                obj = bytes(obj)
            else:
                obj = obj.decode(""utf_8"", self._unicode_errors)
            return obj
        if typ == TYPE_BIN:
            return bytes(obj)
        if typ == TYPE_EXT:
            if n == -1:  
                ts = Timestamp.from_bytes(bytes(obj))
                if self._timestamp == 1:
                    return ts.to_unix()
                elif self._timestamp == 2:
                    return ts.to_unix_nano()
                elif self._timestamp == 3:
                    return ts.to_datetime()
                else:
                    return ts
            else:
                return self._ext_hook(n, bytes(obj))
        assert typ == TYPE_IMMEDIATE
        return obj

    def __iter__(self):
        return self

    def __next__(self):
        try:
            ret = self._unpack(EX_CONSTRUCT)
            self._consume()
            return ret
        except OutOfData:
            self._consume()
            raise StopIteration
        except RecursionError:
            raise StackError

    next = __next__

    def skip(self):
        self._unpack(EX_SKIP)
        self._consume()

    def unpack(self):
        try:
            ret = self._unpack(EX_CONSTRUCT)
        except RecursionError:
            raise StackError
        self._consume()
        return ret

    def read_array_header(self):
        ret = self._unpack(EX_READ_ARRAY_HEADER)
        self._consume()
        return ret

    def read_map_header(self):
        ret = self._unpack(EX_READ_MAP_HEADER)
        self._consume()
        return ret

    def tell(self):
        return self._stream_offset


class Packer:
    

    def __init__(
        self,
        *,
        default=None,
        use_single_float=False,
        autoreset=True,
        use_bin_type=True,
        strict_types=False,
        datetime=False,
        unicode_errors=None,
        buf_size=None,
    ):
        self._strict_types = strict_types
        self._use_float = use_single_float
        self._autoreset = autoreset
        self._use_bin_type = use_bin_type
        self._buffer = BytesIO()
        self._datetime = bool(datetime)
        self._unicode_errors = unicode_errors or ""strict""
        if default is not None and not callable(default):
            raise TypeError(""default must be callable"")
        self._default = default

    def _pack(
        self,
        obj,
        nest_limit=DEFAULT_RECURSE_LIMIT,
        check=isinstance,
        check_type_strict=_check_type_strict,
    ):
        default_used = False
        if self._strict_types:
            check = check_type_strict
            list_types = list
        else:
            list_types = (list, tuple)
        while True:
            if nest_limit < 0:
                raise ValueError(""recursion limit exceeded"")
            if obj is None:
                return self._buffer.write(b""\xc0"")
            if check(obj, bool):
                if obj:
                    return self._buffer.write(b""\xc3"")
                return self._buffer.write(b""\xc2"")
            if check(obj, int):
                if 0 <= obj < 0x80:
                    return self._buffer.write(struct.pack(""B"", obj))
                if -0x20 <= obj < 0:
                    return self._buffer.write(struct.pack(""b"", obj))
                if 0x80 <= obj <= 0xFF:
                    return self._buffer.write(struct.pack(""BB"", 0xCC, obj))
                if -0x80 <= obj < 0:
                    return self._buffer.write(struct.pack("">Bb"", 0xD0, obj))
                if 0xFF < obj <= 0xFFFF:
                    return self._buffer.write(struct.pack("">BH"", 0xCD, obj))
                if -0x8000 <= obj < -0x80:
                    return self._buffer.write(struct.pack("">Bh"", 0xD1, obj))
                if 0xFFFF < obj <= 0xFFFFFFFF:
                    return self._buffer.write(struct.pack("">BI"", 0xCE, obj))
                if -0x80000000 <= obj < -0x8000:
                    return self._buffer.write(struct.pack("">Bi"", 0xD2, obj))
                if 0xFFFFFFFF < obj <= 0xFFFFFFFFFFFFFFFF:
                    return self._buffer.write(struct.pack("">BQ"", 0xCF, obj))
                if -0x8000000000000000 <= obj < -0x80000000:
                    return self._buffer.write(struct.pack("">Bq"", 0xD3, obj))
                if not default_used and self._default is not None:
                    obj = self._default(obj)
                    default_used = True
                    continue
                raise OverflowError(""Integer value out of range"")
            if check(obj, (bytes, bytearray)):
                n = len(obj)
                if n >= 2**32:
                    raise ValueError(""%s is too large"" % type(obj).__name__)
                self._pack_bin_header(n)
                return self._buffer.write(obj)
            if check(obj, str):
                obj = obj.encode(""utf-8"", self._unicode_errors)
                n = len(obj)
                if n >= 2**32:
                    raise ValueError(""String is too large"")
                self._pack_raw_header(n)
                return self._buffer.write(obj)
            if check(obj, memoryview):
                n = obj.nbytes
                if n >= 2**32:
                    raise ValueError(""Memoryview is too large"")
                self._pack_bin_header(n)
                return self._buffer.write(obj)
            if check(obj, float):
                if self._use_float:
                    return self._buffer.write(struct.pack("">Bf"", 0xCA, obj))
                return self._buffer.write(struct.pack("">Bd"", 0xCB, obj))
            if check(obj, (ExtType, Timestamp)):
                if check(obj, Timestamp):
                    code = -1
                    data = obj.to_bytes()
                else:
                    code = obj.code
                    data = obj.data
                assert isinstance(code, int)
                assert isinstance(data, bytes)
                L = len(data)
                if L == 1:
                    self._buffer.write(b""\xd4"")
                elif L == 2:
                    self._buffer.write(b""\xd5"")
                elif L == 4:
                    self._buffer.write(b""\xd6"")
                elif L == 8:
                    self._buffer.write(b""\xd7"")
                elif L == 16:
                    self._buffer.write(b""\xd8"")
                elif L <= 0xFF:
                    self._buffer.write(struct.pack("">BB"", 0xC7, L))
                elif L <= 0xFFFF:
                    self._buffer.write(struct.pack("">BH"", 0xC8, L))
                else:
                    self._buffer.write(struct.pack("">BI"", 0xC9, L))
                self._buffer.write(struct.pack(""b"", code))
                self._buffer.write(data)
                return
            if check(obj, list_types):
                n = len(obj)
                self._pack_array_header(n)
                for i in range(n):
                    self._pack(obj[i], nest_limit - 1)
                return
            if check(obj, dict):
                return self._pack_map_pairs(len(obj), obj.items(), nest_limit - 1)

            if self._datetime and check(obj, _DateTime) and obj.tzinfo is not None:
                obj = Timestamp.from_datetime(obj)
                default_used = 1
                continue

            if not default_used and self._default is not None:
                obj = self._default(obj)
                default_used = 1
                continue

            if self._datetime and check(obj, _DateTime):
                raise ValueError(f""Cannot serialize {obj!r} where tzinfo=None"")

            raise TypeError(f""Cannot serialize {obj!r}"")

    def pack(self, obj):
        try:
            self._pack(obj)
        except:
            self._buffer = BytesIO()  
            raise
        if self._autoreset:
            ret = self._buffer.getvalue()
            self._buffer = BytesIO()
            return ret

    def pack_map_pairs(self, pairs):
        self._pack_map_pairs(len(pairs), pairs)
        if self._autoreset:
            ret = self._buffer.getvalue()
            self._buffer = BytesIO()
            return ret

    def pack_array_header(self, n):
        if n >= 2**32:
            raise ValueError
        self._pack_array_header(n)
        if self._autoreset:
            ret = self._buffer.getvalue()
            self._buffer = BytesIO()
            return ret

    def pack_map_header(self, n):
        if n >= 2**32:
            raise ValueError
        self._pack_map_header(n)
        if self._autoreset:
            ret = self._buffer.getvalue()
            self._buffer = BytesIO()
            return ret

    def pack_ext_type(self, typecode, data):
        if not isinstance(typecode, int):
            raise TypeError(""typecode must have int type."")
        if not 0 <= typecode <= 127:
            raise ValueError(""typecode should be 0-127"")
        if not isinstance(data, bytes):
            raise TypeError(""data must have bytes type"")
        L = len(data)
        if L > 0xFFFFFFFF:
            raise ValueError(""Too large data"")
        if L == 1:
            self._buffer.write(b""\xd4"")
        elif L == 2:
            self._buffer.write(b""\xd5"")
        elif L == 4:
            self._buffer.write(b""\xd6"")
        elif L == 8:
            self._buffer.write(b""\xd7"")
        elif L == 16:
            self._buffer.write(b""\xd8"")
        elif L <= 0xFF:
            self._buffer.write(b""\xc7"" + struct.pack(""B"", L))
        elif L <= 0xFFFF:
            self._buffer.write(b""\xc8"" + struct.pack("">H"", L))
        else:
            self._buffer.write(b""\xc9"" + struct.pack("">I"", L))
        self._buffer.write(struct.pack(""B"", typecode))
        self._buffer.write(data)

    def _pack_array_header(self, n):
        if n <= 0x0F:
            return self._buffer.write(struct.pack(""B"", 0x90 + n))
        if n <= 0xFFFF:
            return self._buffer.write(struct.pack("">BH"", 0xDC, n))
        if n <= 0xFFFFFFFF:
            return self._buffer.write(struct.pack("">BI"", 0xDD, n))
        raise ValueError(""Array is too large"")

    def _pack_map_header(self, n):
        if n <= 0x0F:
            return self._buffer.write(struct.pack(""B"", 0x80 + n))
        if n <= 0xFFFF:
            return self._buffer.write(struct.pack("">BH"", 0xDE, n))
        if n <= 0xFFFFFFFF:
            return self._buffer.write(struct.pack("">BI"", 0xDF, n))
        raise ValueError(""Dict is too large"")

    def _pack_map_pairs(self, n, pairs, nest_limit=DEFAULT_RECURSE_LIMIT):
        self._pack_map_header(n)
        for k, v in pairs:
            self._pack(k, nest_limit - 1)
            self._pack(v, nest_limit - 1)

    def _pack_raw_header(self, n):
        if n <= 0x1F:
            self._buffer.write(struct.pack(""B"", 0xA0 + n))
        elif self._use_bin_type and n <= 0xFF:
            self._buffer.write(struct.pack("">BB"", 0xD9, n))
        elif n <= 0xFFFF:
            self._buffer.write(struct.pack("">BH"", 0xDA, n))
        elif n <= 0xFFFFFFFF:
            self._buffer.write(struct.pack("">BI"", 0xDB, n))
        else:
            raise ValueError(""Raw is too large"")

    def _pack_bin_header(self, n):
        if not self._use_bin_type:
            return self._pack_raw_header(n)
        elif n <= 0xFF:
            return self._buffer.write(struct.pack("">BB"", 0xC4, n))
        elif n <= 0xFFFF:
            return self._buffer.write(struct.pack("">BH"", 0xC5, n))
        elif n <= 0xFFFFFFFF:
            return self._buffer.write(struct.pack("">BI"", 0xC6, n))
        else:
            raise ValueError(""Bin is too large"")

    def bytes(self):
        
        return self._buffer.getvalue()

    def reset(self):
        
        self._buffer = BytesIO()

    def getbuffer(self):
        
        if _USING_STRINGBUILDER:
            return memoryview(self.bytes())
        else:
            return self._buffer.getbuffer()


import os

from .exceptions import *  
from .ext import ExtType, Timestamp

version = (1, 1, 1)
__version__ = ""1.1.1""


if os.environ.get(""MSGPACK_PUREPYTHON""):
    from .fallback import Packer, Unpacker, unpackb
else:
    try:
        from ._cmsgpack import Packer, Unpacker, unpackb
    except ImportError:
        from .fallback import Packer, Unpacker, unpackb


def pack(o, stream, **kwargs):
    
    packer = Packer(**kwargs)
    stream.write(packer.pack(o))


def packb(o, **kwargs):
    
    return Packer(**kwargs).pack(o)


def unpack(stream, **kwargs):
    
    data = stream.read()
    return unpackb(data, **kwargs)



load = unpack
loads = unpackb

dump = pack
dumps = packb





from __future__ import annotations

import operator
import os
import platform
import sys
from typing import AbstractSet, Any, Callable, Literal, TypedDict, Union, cast

from ._parser import MarkerAtom, MarkerList, Op, Value, Variable
from ._parser import parse_marker as _parse_marker
from ._tokenizer import ParserSyntaxError
from .specifiers import InvalidSpecifier, Specifier
from .utils import canonicalize_name

__all__ = [
    ""EvaluateContext"",
    ""InvalidMarker"",
    ""Marker"",
    ""UndefinedComparison"",
    ""UndefinedEnvironmentName"",
    ""default_environment"",
]

Operator = Callable[[str, Union[str, AbstractSet[str]]], bool]
EvaluateContext = Literal[""metadata"", ""lock_file"", ""requirement""]
MARKERS_ALLOWING_SET = {""extras"", ""dependency_groups""}


class InvalidMarker(ValueError):
    


class UndefinedComparison(ValueError):
    


class UndefinedEnvironmentName(ValueError):
    


class Environment(TypedDict):
    implementation_name: str
    

    implementation_version: str
    

    os_name: str
    

    platform_machine: str
    

    platform_release: str
    

    platform_system: str
    

    platform_version: str
    

    python_full_version: str
    

    platform_python_implementation: str
    

    python_version: str
    

    sys_platform: str
    


def _normalize_extra_values(results: Any) -> Any:
    
    if isinstance(results[0], tuple):
        lhs, op, rhs = results[0]
        if isinstance(lhs, Variable) and lhs.value == ""extra"":
            normalized_extra = canonicalize_name(rhs.value)
            rhs = Value(normalized_extra)
        elif isinstance(rhs, Variable) and rhs.value == ""extra"":
            normalized_extra = canonicalize_name(lhs.value)
            lhs = Value(normalized_extra)
        results[0] = lhs, op, rhs
    return results


def _format_marker(
    marker: list[str] | MarkerAtom | str, first: bool | None = True
) -> str:
    assert isinstance(marker, (list, tuple, str))

    
    
    
    
    if (
        isinstance(marker, list)
        and len(marker) == 1
        and isinstance(marker[0], (list, tuple))
    ):
        return _format_marker(marker[0])

    if isinstance(marker, list):
        inner = (_format_marker(m, first=False) for m in marker)
        if first:
            return "" "".join(inner)
        else:
            return ""("" + "" "".join(inner) + "")""
    elif isinstance(marker, tuple):
        return "" "".join([m.serialize() for m in marker])
    else:
        return marker


_operators: dict[str, Operator] = {
    ""in"": lambda lhs, rhs: lhs in rhs,
    ""not in"": lambda lhs, rhs: lhs not in rhs,
    ""<"": operator.lt,
    ""<="": operator.le,
    ""=="": operator.eq,
    ""!="": operator.ne,
    "">="": operator.ge,
    "">"": operator.gt,
}


def _eval_op(lhs: str, op: Op, rhs: str | AbstractSet[str]) -> bool:
    if isinstance(rhs, str):
        try:
            spec = Specifier("""".join([op.serialize(), rhs]))
        except InvalidSpecifier:
            pass
        else:
            return spec.contains(lhs, prereleases=True)

    oper: Operator | None = _operators.get(op.serialize())
    if oper is None:
        raise UndefinedComparison(f""Undefined {op!r} on {lhs!r} and {rhs!r}."")

    return oper(lhs, rhs)


def _normalize(
    lhs: str, rhs: str | AbstractSet[str], key: str
) -> tuple[str, str | AbstractSet[str]]:
    
    
    
    
    if key == ""extra"":
        assert isinstance(rhs, str), ""extra value must be a string""
        return (canonicalize_name(lhs), canonicalize_name(rhs))
    if key in MARKERS_ALLOWING_SET:
        if isinstance(rhs, str):  
            return (canonicalize_name(lhs), canonicalize_name(rhs))
        else:
            return (canonicalize_name(lhs), {canonicalize_name(v) for v in rhs})

    
    return lhs, rhs


def _evaluate_markers(
    markers: MarkerList, environment: dict[str, str | AbstractSet[str]]
) -> bool:
    groups: list[list[bool]] = [[]]

    for marker in markers:
        assert isinstance(marker, (list, tuple, str))

        if isinstance(marker, list):
            groups[-1].append(_evaluate_markers(marker, environment))
        elif isinstance(marker, tuple):
            lhs, op, rhs = marker

            if isinstance(lhs, Variable):
                environment_key = lhs.value
                lhs_value = environment[environment_key]
                rhs_value = rhs.value
            else:
                lhs_value = lhs.value
                environment_key = rhs.value
                rhs_value = environment[environment_key]
            assert isinstance(lhs_value, str), ""lhs must be a string""
            lhs_value, rhs_value = _normalize(lhs_value, rhs_value, key=environment_key)
            groups[-1].append(_eval_op(lhs_value, op, rhs_value))
        else:
            assert marker in [""and"", ""or""]
            if marker == ""or"":
                groups.append([])

    return any(all(item) for item in groups)


def format_full_version(info: sys._version_info) -> str:
    version = f""{info.major}.{info.minor}.{info.micro}""
    kind = info.releaselevel
    if kind != ""final"":
        version += kind[0] + str(info.serial)
    return version


def default_environment() -> Environment:
    iver = format_full_version(sys.implementation.version)
    implementation_name = sys.implementation.name
    return {
        ""implementation_name"": implementation_name,
        ""implementation_version"": iver,
        ""os_name"": os.name,
        ""platform_machine"": platform.machine(),
        ""platform_release"": platform.release(),
        ""platform_system"": platform.system(),
        ""platform_version"": platform.version(),
        ""python_full_version"": platform.python_version(),
        ""platform_python_implementation"": platform.python_implementation(),
        ""python_version"": ""."".join(platform.python_version_tuple()[:2]),
        ""sys_platform"": sys.platform,
    }


class Marker:
    def __init__(self, marker: str) -> None:
        
        
        
        try:
            self._markers = _normalize_extra_values(_parse_marker(marker))
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
        except ParserSyntaxError as e:
            raise InvalidMarker(str(e)) from e

    def __str__(self) -> str:
        return _format_marker(self._markers)

    def __repr__(self) -> str:
        return f""<Marker('{self}')>""

    def __hash__(self) -> int:
        return hash((self.__class__.__name__, str(self)))

    def __eq__(self, other: Any) -> bool:
        if not isinstance(other, Marker):
            return NotImplemented

        return str(self) == str(other)

    def evaluate(
        self,
        environment: dict[str, str] | None = None,
        context: EvaluateContext = ""metadata"",
    ) -> bool:
        
        current_environment = cast(
            ""dict[str, str | AbstractSet[str]]"", default_environment()
        )
        if context == ""lock_file"":
            current_environment.update(
                extras=frozenset(), dependency_groups=frozenset()
            )
        elif context == ""metadata"":
            current_environment[""extra""] = """"
        if environment is not None:
            current_environment.update(environment)
            
            
            if ""extra"" in current_environment and current_environment[""extra""] is None:
                current_environment[""extra""] = """"

        return _evaluate_markers(
            self._markers, _repair_python_full_version(current_environment)
        )


def _repair_python_full_version(
    env: dict[str, str | AbstractSet[str]],
) -> dict[str, str | AbstractSet[str]]:
    
    python_full_version = cast(str, env[""python_full_version""])
    if python_full_version.endswith(""+""):
        env[""python_full_version""] = f""{python_full_version}local""
    return env

from __future__ import annotations

import email.feedparser
import email.header
import email.message
import email.parser
import email.policy
import pathlib
import sys
import typing
from typing import (
    Any,
    Callable,
    Generic,
    Literal,
    TypedDict,
    cast,
)

from . import licenses, requirements, specifiers, utils
from . import version as version_module
from .licenses import NormalizedLicenseExpression

T = typing.TypeVar(""T"")


if sys.version_info >= (3, 11):  
    ExceptionGroup = ExceptionGroup
else:  

    class ExceptionGroup(Exception):
        

        message: str
        exceptions: list[Exception]

        def __init__(self, message: str, exceptions: list[Exception]) -> None:
            self.message = message
            self.exceptions = exceptions

        def __repr__(self) -> str:
            return f""{self.__class__.__name__}({self.message!r}, {self.exceptions!r})""


class InvalidMetadata(ValueError):
    

    field: str
    

    def __init__(self, field: str, message: str) -> None:
        self.field = field
        super().__init__(message)






class RawMetadata(TypedDict, total=False):
    

    
    metadata_version: str
    name: str
    version: str
    platforms: list[str]
    summary: str
    description: str
    keywords: list[str]
    home_page: str
    author: str
    author_email: str
    license: str

    
    supported_platforms: list[str]
    download_url: str
    classifiers: list[str]
    requires: list[str]
    provides: list[str]
    obsoletes: list[str]

    
    maintainer: str
    maintainer_email: str
    requires_dist: list[str]
    provides_dist: list[str]
    obsoletes_dist: list[str]
    requires_python: str
    requires_external: list[str]
    project_urls: dict[str, str]

    
    
    
    
    
    
    
    

    
    description_content_type: str
    provides_extra: list[str]

    
    dynamic: list[str]

    
    
    

    
    license_expression: str
    license_files: list[str]


_STRING_FIELDS = {
    ""author"",
    ""author_email"",
    ""description"",
    ""description_content_type"",
    ""download_url"",
    ""home_page"",
    ""license"",
    ""license_expression"",
    ""maintainer"",
    ""maintainer_email"",
    ""metadata_version"",
    ""name"",
    ""requires_python"",
    ""summary"",
    ""version"",
}

_LIST_FIELDS = {
    ""classifiers"",
    ""dynamic"",
    ""license_files"",
    ""obsoletes"",
    ""obsoletes_dist"",
    ""platforms"",
    ""provides"",
    ""provides_dist"",
    ""provides_extra"",
    ""requires"",
    ""requires_dist"",
    ""requires_external"",
    ""supported_platforms"",
}

_DICT_FIELDS = {
    ""project_urls"",
}


def _parse_keywords(data: str) -> list[str]:
    
    return [k.strip() for k in data.split("","")]


def _parse_project_urls(data: list[str]) -> dict[str, str]:
    
    urls = {}
    for pair in data:
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        parts = [p.strip() for p in pair.split("","", 1)]
        parts.extend([""""] * (max(0, 2 - len(parts))))  

        
        
        
        
        
        label, url = parts
        if label in urls:
            
            
            
            raise KeyError(""duplicate labels in project urls"")
        urls[label] = url

    return urls


def _get_payload(msg: email.message.Message, source: bytes | str) -> str:
    
    
    
    if isinstance(source, str):
        payload = msg.get_payload()
        assert isinstance(payload, str)
        return payload
    
    
    else:
        bpayload = msg.get_payload(decode=True)
        assert isinstance(bpayload, bytes)
        try:
            return bpayload.decode(""utf8"", ""strict"")
        except UnicodeDecodeError as exc:
            raise ValueError(""payload in an invalid encoding"") from exc














_EMAIL_TO_RAW_MAPPING = {
    ""author"": ""author"",
    ""author-email"": ""author_email"",
    ""classifier"": ""classifiers"",
    ""description"": ""description"",
    ""description-content-type"": ""description_content_type"",
    ""download-url"": ""download_url"",
    ""dynamic"": ""dynamic"",
    ""home-page"": ""home_page"",
    ""keywords"": ""keywords"",
    ""license"": ""license"",
    ""license-expression"": ""license_expression"",
    ""license-file"": ""license_files"",
    ""maintainer"": ""maintainer"",
    ""maintainer-email"": ""maintainer_email"",
    ""metadata-version"": ""metadata_version"",
    ""name"": ""name"",
    ""obsoletes"": ""obsoletes"",
    ""obsoletes-dist"": ""obsoletes_dist"",
    ""platform"": ""platforms"",
    ""project-url"": ""project_urls"",
    ""provides"": ""provides"",
    ""provides-dist"": ""provides_dist"",
    ""provides-extra"": ""provides_extra"",
    ""requires"": ""requires"",
    ""requires-dist"": ""requires_dist"",
    ""requires-external"": ""requires_external"",
    ""requires-python"": ""requires_python"",
    ""summary"": ""summary"",
    ""supported-platform"": ""supported_platforms"",
    ""version"": ""version"",
}
_RAW_TO_EMAIL_MAPPING = {raw: email for email, raw in _EMAIL_TO_RAW_MAPPING.items()}


def parse_email(data: bytes | str) -> tuple[RawMetadata, dict[str, list[str]]]:
    
    raw: dict[str, str | list[str] | dict[str, str]] = {}
    unparsed: dict[str, list[str]] = {}

    if isinstance(data, str):
        parsed = email.parser.Parser(policy=email.policy.compat32).parsestr(data)
    else:
        parsed = email.parser.BytesParser(policy=email.policy.compat32).parsebytes(data)

    
    
    
    for name in frozenset(parsed.keys()):
        
        
        name = name.lower()

        
        
        
        headers = parsed.get_all(name) or []

        
        
        
        
        
        
        
        value = []
        
        
        valid_encoding = True
        for h in headers:
            
            
            assert isinstance(h, (email.header.Header, str))

            
            
            
            
            
            
            
            
            if isinstance(h, email.header.Header):
                
                
                
                chunks: list[tuple[bytes, str | None]] = []
                for bin, encoding in email.header.decode_header(h):
                    try:
                        bin.decode(""utf8"", ""strict"")
                    except UnicodeDecodeError:
                        
                        encoding = ""latin1""
                        valid_encoding = False
                    else:
                        encoding = ""utf8""
                    chunks.append((bin, encoding))

                
                
                
                value.append(str(email.header.make_header(chunks)))
            
            else:
                value.append(h)

        
        
        
        if not valid_encoding:
            unparsed[name] = value
            continue

        raw_name = _EMAIL_TO_RAW_MAPPING.get(name)
        if raw_name is None:
            
            
            
            
            
            
            
            unparsed[name] = value
            continue

        
        
        
        
        
        
        
        
        if raw_name in _STRING_FIELDS and len(value) == 1:
            raw[raw_name] = value[0]
        
        
        
        elif raw_name in _LIST_FIELDS:
            raw[raw_name] = value
        
        
        
        
        
        elif raw_name == ""keywords"" and len(value) == 1:
            raw[raw_name] = _parse_keywords(value[0])
        
        
        
        
        
        
        
        
        
        elif raw_name == ""project_urls"":
            try:
                raw[raw_name] = _parse_project_urls(value)
            except KeyError:
                unparsed[name] = value
        
        
        else:
            unparsed[name] = value

    
    
    
    
    try:
        payload = _get_payload(parsed, data)
    except ValueError:
        unparsed.setdefault(""description"", []).append(
            parsed.get_payload(decode=isinstance(data, bytes))  
        )
    else:
        if payload:
            
            
            if ""description"" in raw:
                description_header = cast(str, raw.pop(""description""))
                unparsed.setdefault(""description"", []).extend(
                    [description_header, payload]
                )
            elif ""description"" in unparsed:
                unparsed[""description""].append(payload)
            else:
                raw[""description""] = payload

    
    
    
    
    return cast(RawMetadata, raw), unparsed


_NOT_FOUND = object()



_VALID_METADATA_VERSIONS = [""1.0"", ""1.1"", ""1.2"", ""2.1"", ""2.2"", ""2.3"", ""2.4""]
_MetadataVersion = Literal[""1.0"", ""1.1"", ""1.2"", ""2.1"", ""2.2"", ""2.3"", ""2.4""]

_REQUIRED_ATTRS = frozenset([""metadata_version"", ""name"", ""version""])


class _Validator(Generic[T]):
    

    name: str
    raw_name: str
    added: _MetadataVersion

    def __init__(
        self,
        *,
        added: _MetadataVersion = ""1.0"",
    ) -> None:
        self.added = added

    def __set_name__(self, _owner: Metadata, name: str) -> None:
        self.name = name
        self.raw_name = _RAW_TO_EMAIL_MAPPING[name]

    def __get__(self, instance: Metadata, _owner: type[Metadata]) -> T:
        
        
        
        cache = instance.__dict__
        value = instance._raw.get(self.name)

        
        
        
        
        if self.name in _REQUIRED_ATTRS or value is not None:
            try:
                converter: Callable[[Any], T] = getattr(self, f""_process_{self.name}"")
            except AttributeError:
                pass
            else:
                value = converter(value)

        cache[self.name] = value
        try:
            del instance._raw[self.name]  
        except KeyError:
            pass

        return cast(T, value)

    def _invalid_metadata(
        self, msg: str, cause: Exception | None = None
    ) -> InvalidMetadata:
        exc = InvalidMetadata(
            self.raw_name, msg.format_map({""field"": repr(self.raw_name)})
        )
        exc.__cause__ = cause
        return exc

    def _process_metadata_version(self, value: str) -> _MetadataVersion:
        
        if value not in _VALID_METADATA_VERSIONS:
            raise self._invalid_metadata(f""{value!r} is not a valid metadata version"")
        return cast(_MetadataVersion, value)

    def _process_name(self, value: str) -> str:
        if not value:
            raise self._invalid_metadata(""{field} is a required field"")
        
        try:
            utils.canonicalize_name(value, validate=True)
        except utils.InvalidName as exc:
            raise self._invalid_metadata(
                f""{value!r} is invalid for {{field}}"", cause=exc
            ) from exc
        else:
            return value

    def _process_version(self, value: str) -> version_module.Version:
        if not value:
            raise self._invalid_metadata(""{field} is a required field"")
        try:
            return version_module.parse(value)
        except version_module.InvalidVersion as exc:
            raise self._invalid_metadata(
                f""{value!r} is invalid for {{field}}"", cause=exc
            ) from exc

    def _process_summary(self, value: str) -> str:
        
        if ""\n"" in value:
            raise self._invalid_metadata(""{field} must be a single line"")
        return value

    def _process_description_content_type(self, value: str) -> str:
        content_types = {""text/plain"", ""text/x-rst"", ""text/markdown""}
        message = email.message.EmailMessage()
        message[""content-type""] = value

        content_type, parameters = (
            
            message.get_content_type().lower(),
            message[""content-type""].params,
        )
        
        
        if content_type not in content_types or content_type not in value.lower():
            raise self._invalid_metadata(
                f""{{field}} must be one of {list(content_types)}, not {value!r}""
            )

        charset = parameters.get(""charset"", ""UTF-8"")
        if charset != ""UTF-8"":
            raise self._invalid_metadata(
                f""{{field}} can only specify the UTF-8 charset, not {list(charset)}""
            )

        markdown_variants = {""GFM"", ""CommonMark""}
        variant = parameters.get(""variant"", ""GFM"")  
        if content_type == ""text/markdown"" and variant not in markdown_variants:
            raise self._invalid_metadata(
                f""valid Markdown variants for {{field}} are {list(markdown_variants)}, ""
                f""not {variant!r}"",
            )
        return value

    def _process_dynamic(self, value: list[str]) -> list[str]:
        for dynamic_field in map(str.lower, value):
            if dynamic_field in {""name"", ""version"", ""metadata-version""}:
                raise self._invalid_metadata(
                    f""{dynamic_field!r} is not allowed as a dynamic field""
                )
            elif dynamic_field not in _EMAIL_TO_RAW_MAPPING:
                raise self._invalid_metadata(
                    f""{dynamic_field!r} is not a valid dynamic field""
                )
        return list(map(str.lower, value))

    def _process_provides_extra(
        self,
        value: list[str],
    ) -> list[utils.NormalizedName]:
        normalized_names = []
        try:
            for name in value:
                normalized_names.append(utils.canonicalize_name(name, validate=True))
        except utils.InvalidName as exc:
            raise self._invalid_metadata(
                f""{name!r} is invalid for {{field}}"", cause=exc
            ) from exc
        else:
            return normalized_names

    def _process_requires_python(self, value: str) -> specifiers.SpecifierSet:
        try:
            return specifiers.SpecifierSet(value)
        except specifiers.InvalidSpecifier as exc:
            raise self._invalid_metadata(
                f""{value!r} is invalid for {{field}}"", cause=exc
            ) from exc

    def _process_requires_dist(
        self,
        value: list[str],
    ) -> list[requirements.Requirement]:
        reqs = []
        try:
            for req in value:
                reqs.append(requirements.Requirement(req))
        except requirements.InvalidRequirement as exc:
            raise self._invalid_metadata(
                f""{req!r} is invalid for {{field}}"", cause=exc
            ) from exc
        else:
            return reqs

    def _process_license_expression(
        self, value: str
    ) -> NormalizedLicenseExpression | None:
        try:
            return licenses.canonicalize_license_expression(value)
        except ValueError as exc:
            raise self._invalid_metadata(
                f""{value!r} is invalid for {{field}}"", cause=exc
            ) from exc

    def _process_license_files(self, value: list[str]) -> list[str]:
        paths = []
        for path in value:
            if "".."" in path:
                raise self._invalid_metadata(
                    f""{path!r} is invalid for {{field}}, ""
                    ""parent directory indicators are not allowed""
                )
            if ""*"" in path:
                raise self._invalid_metadata(
                    f""{path!r} is invalid for {{field}}, paths must be resolved""
                )
            if (
                pathlib.PurePosixPath(path).is_absolute()
                or pathlib.PureWindowsPath(path).is_absolute()
            ):
                raise self._invalid_metadata(
                    f""{path!r} is invalid for {{field}}, paths must be relative""
                )
            if pathlib.PureWindowsPath(path).as_posix() != path:
                raise self._invalid_metadata(
                    f""{path!r} is invalid for {{field}}, paths must use '/' delimiter""
                )
            paths.append(path)
        return paths


class Metadata:
    

    _raw: RawMetadata

    @classmethod
    def from_raw(cls, data: RawMetadata, *, validate: bool = True) -> Metadata:
        
        ins = cls()
        ins._raw = data.copy()  

        if validate:
            exceptions: list[Exception] = []
            try:
                metadata_version = ins.metadata_version
                metadata_age = _VALID_METADATA_VERSIONS.index(metadata_version)
            except InvalidMetadata as metadata_version_exc:
                exceptions.append(metadata_version_exc)
                metadata_version = None

            
            
            fields_to_check = frozenset(ins._raw) | _REQUIRED_ATTRS
            
            fields_to_check -= {""metadata_version""}

            for key in fields_to_check:
                try:
                    if metadata_version:
                        
                        
                        try:
                            field_metadata_version = cls.__dict__[key].added
                        except KeyError:
                            exc = InvalidMetadata(key, f""unrecognized field: {key!r}"")
                            exceptions.append(exc)
                            continue
                        field_age = _VALID_METADATA_VERSIONS.index(
                            field_metadata_version
                        )
                        if field_age > metadata_age:
                            field = _RAW_TO_EMAIL_MAPPING[key]
                            exc = InvalidMetadata(
                                field,
                                f""{field} introduced in metadata version ""
                                f""{field_metadata_version}, not {metadata_version}"",
                            )
                            exceptions.append(exc)
                            continue
                    getattr(ins, key)
                except InvalidMetadata as exc:
                    exceptions.append(exc)

            if exceptions:
                raise ExceptionGroup(""invalid metadata"", exceptions)

        return ins

    @classmethod
    def from_email(cls, data: bytes | str, *, validate: bool = True) -> Metadata:
        
        raw, unparsed = parse_email(data)

        if validate:
            exceptions: list[Exception] = []
            for unparsed_key in unparsed:
                if unparsed_key in _EMAIL_TO_RAW_MAPPING:
                    message = f""{unparsed_key!r} has invalid data""
                else:
                    message = f""unrecognized field: {unparsed_key!r}""
                exceptions.append(InvalidMetadata(unparsed_key, message))

            if exceptions:
                raise ExceptionGroup(""unparsed"", exceptions)

        try:
            return cls.from_raw(raw, validate=validate)
        except ExceptionGroup as exc_group:
            raise ExceptionGroup(
                ""invalid or unparsed metadata"", exc_group.exceptions
            ) from None

    metadata_version: _Validator[_MetadataVersion] = _Validator()
    
    
    
    name: _Validator[str] = _Validator()
    
    version: _Validator[version_module.Version] = _Validator()
    
    dynamic: _Validator[list[str] | None] = _Validator(
        added=""2.2"",
    )
    
    platforms: _Validator[list[str] | None] = _Validator()
    
    supported_platforms: _Validator[list[str] | None] = _Validator(added=""1.1"")
    
    summary: _Validator[str | None] = _Validator()
    
    description: _Validator[str | None] = _Validator()  
    
    description_content_type: _Validator[str | None] = _Validator(added=""2.1"")
    
    keywords: _Validator[list[str] | None] = _Validator()
    
    home_page: _Validator[str | None] = _Validator()
    
    download_url: _Validator[str | None] = _Validator(added=""1.1"")
    
    author: _Validator[str | None] = _Validator()
    
    author_email: _Validator[str | None] = _Validator()
    
    maintainer: _Validator[str | None] = _Validator(added=""1.2"")
    
    maintainer_email: _Validator[str | None] = _Validator(added=""1.2"")
    
    license: _Validator[str | None] = _Validator()
    
    license_expression: _Validator[NormalizedLicenseExpression | None] = _Validator(
        added=""2.4""
    )
    
    license_files: _Validator[list[str] | None] = _Validator(added=""2.4"")
    
    classifiers: _Validator[list[str] | None] = _Validator(added=""1.1"")
    
    requires_dist: _Validator[list[requirements.Requirement] | None] = _Validator(
        added=""1.2""
    )
    
    requires_python: _Validator[specifiers.SpecifierSet | None] = _Validator(
        added=""1.2""
    )
    
    
    
    requires_external: _Validator[list[str] | None] = _Validator(added=""1.2"")
    
    project_urls: _Validator[dict[str, str] | None] = _Validator(added=""1.2"")
    
    
    
    provides_extra: _Validator[list[utils.NormalizedName] | None] = _Validator(
        added=""2.1"",
    )
    
    provides_dist: _Validator[list[str] | None] = _Validator(added=""1.2"")
    
    obsoletes_dist: _Validator[list[str] | None] = _Validator(added=""1.2"")
    
    requires: _Validator[list[str] | None] = _Validator(added=""1.1"")
    
    provides: _Validator[list[str] | None] = _Validator(added=""1.1"")
    
    obsoletes: _Validator[list[str] | None] = _Validator(added=""1.1"")
    




from __future__ import annotations

from typing import Any, Iterator

from ._parser import parse_requirement as _parse_requirement
from ._tokenizer import ParserSyntaxError
from .markers import Marker, _normalize_extra_values
from .specifiers import SpecifierSet
from .utils import canonicalize_name


class InvalidRequirement(ValueError):
    


class Requirement:
    

    
    
    
    

    def __init__(self, requirement_string: str) -> None:
        try:
            parsed = _parse_requirement(requirement_string)
        except ParserSyntaxError as e:
            raise InvalidRequirement(str(e)) from e

        self.name: str = parsed.name
        self.url: str | None = parsed.url or None
        self.extras: set[str] = set(parsed.extras or [])
        self.specifier: SpecifierSet = SpecifierSet(parsed.specifier)
        self.marker: Marker | None = None
        if parsed.marker is not None:
            self.marker = Marker.__new__(Marker)
            self.marker._markers = _normalize_extra_values(parsed.marker)

    def _iter_parts(self, name: str) -> Iterator[str]:
        yield name

        if self.extras:
            formatted_extras = "","".join(sorted(self.extras))
            yield f""[{formatted_extras}]""

        if self.specifier:
            yield str(self.specifier)

        if self.url:
            yield f""@ {self.url}""
            if self.marker:
                yield "" ""

        if self.marker:
            yield f""; {self.marker}""

    def __str__(self) -> str:
        return """".join(self._iter_parts(self.name))

    def __repr__(self) -> str:
        return f""<Requirement('{self}')>""

    def __hash__(self) -> int:
        return hash(
            (
                self.__class__.__name__,
                *self._iter_parts(canonicalize_name(self.name)),
            )
        )

    def __eq__(self, other: Any) -> bool:
        if not isinstance(other, Requirement):
            return NotImplemented

        return (
            canonicalize_name(self.name) == canonicalize_name(other.name)
            and self.extras == other.extras
            and self.specifier == other.specifier
            and self.url == other.url
            and self.marker == other.marker
        )






from __future__ import annotations

import abc
import itertools
import re
from typing import Callable, Iterable, Iterator, TypeVar, Union

from .utils import canonicalize_version
from .version import Version

UnparsedVersion = Union[Version, str]
UnparsedVersionVar = TypeVar(""UnparsedVersionVar"", bound=UnparsedVersion)
CallableOperator = Callable[[Version, str], bool]


def _coerce_version(version: UnparsedVersion) -> Version:
    if not isinstance(version, Version):
        version = Version(version)
    return version


class InvalidSpecifier(ValueError):
    


class BaseSpecifier(metaclass=abc.ABCMeta):
    @abc.abstractmethod
    def __str__(self) -> str:
        

    @abc.abstractmethod
    def __hash__(self) -> int:
        

    @abc.abstractmethod
    def __eq__(self, other: object) -> bool:
        

    @property
    @abc.abstractmethod
    def prereleases(self) -> bool | None:
        

    @prereleases.setter
    def prereleases(self, value: bool) -> None:
        

    @abc.abstractmethod
    def contains(self, item: str, prereleases: bool | None = None) -> bool:
        

    @abc.abstractmethod
    def filter(
        self, iterable: Iterable[UnparsedVersionVar], prereleases: bool | None = None
    ) -> Iterator[UnparsedVersionVar]:
        


class Specifier(BaseSpecifier):
    

    _operator_regex_str = r
    _version_regex_str = r

    _regex = re.compile(
        r""^\s*"" + _operator_regex_str + _version_regex_str + r""\s*$"",
        re.VERBOSE | re.IGNORECASE,
    )

    _operators = {
        ""~="": ""compatible"",
        ""=="": ""equal"",
        ""!="": ""not_equal"",
        ""<="": ""less_than_equal"",
        "">="": ""greater_than_equal"",
        ""<"": ""less_than"",
        "">"": ""greater_than"",
        ""==="": ""arbitrary"",
    }

    def __init__(self, spec: str = """", prereleases: bool | None = None) -> None:
        
        match = self._regex.search(spec)
        if not match:
            raise InvalidSpecifier(f""Invalid specifier: {spec!r}"")

        self._spec: tuple[str, str] = (
            match.group(""operator"").strip(),
            match.group(""version"").strip(),
        )

        
        self._prereleases = prereleases

    
    @property  
    def prereleases(self) -> bool:
        
        
        if self._prereleases is not None:
            return self._prereleases

        
        
        
        operator, version = self._spec
        if operator in [""=="", "">="", ""<="", ""~="", ""==="", "">"", ""<""]:
            
            
            if operator == ""=="" and version.endswith("".*""):
                version = version[:-2]

            
            
            if Version(version).is_prerelease:
                return True

        return False

    @prereleases.setter
    def prereleases(self, value: bool) -> None:
        self._prereleases = value

    @property
    def operator(self) -> str:
        
        return self._spec[0]

    @property
    def version(self) -> str:
        
        return self._spec[1]

    def __repr__(self) -> str:
        
        pre = (
            f"", prereleases={self.prereleases!r}""
            if self._prereleases is not None
            else """"
        )

        return f""<{self.__class__.__name__}({str(self)!r}{pre})>""

    def __str__(self) -> str:
        
        return ""{}{}"".format(*self._spec)

    @property
    def _canonical_spec(self) -> tuple[str, str]:
        canonical_version = canonicalize_version(
            self._spec[1],
            strip_trailing_zero=(self._spec[0] != ""~=""),
        )
        return self._spec[0], canonical_version

    def __hash__(self) -> int:
        return hash(self._canonical_spec)

    def __eq__(self, other: object) -> bool:
        
        if isinstance(other, str):
            try:
                other = self.__class__(str(other))
            except InvalidSpecifier:
                return NotImplemented
        elif not isinstance(other, self.__class__):
            return NotImplemented

        return self._canonical_spec == other._canonical_spec

    def _get_operator(self, op: str) -> CallableOperator:
        operator_callable: CallableOperator = getattr(
            self, f""_compare_{self._operators[op]}""
        )
        return operator_callable

    def _compare_compatible(self, prospective: Version, spec: str) -> bool:
        
        
        
        
        

        
        
        prefix = _version_join(
            list(itertools.takewhile(_is_not_suffix, _version_split(spec)))[:-1]
        )

        
        prefix += "".*""

        return self._get_operator("">="")(prospective, spec) and self._get_operator(""=="")(
            prospective, prefix
        )

    def _compare_equal(self, prospective: Version, spec: str) -> bool:
        
        if spec.endswith("".*""):
            
            normalized_prospective = canonicalize_version(
                prospective.public, strip_trailing_zero=False
            )
            
            normalized_spec = canonicalize_version(spec[:-2], strip_trailing_zero=False)
            
            
            split_spec = _version_split(normalized_spec)

            
            
            
            split_prospective = _version_split(normalized_prospective)

            
            
            padded_prospective, _ = _pad_version(split_prospective, split_spec)

            
            
            
            shortened_prospective = padded_prospective[: len(split_spec)]

            return shortened_prospective == split_spec
        else:
            
            spec_version = Version(spec)

            
            
            
            if not spec_version.local:
                prospective = Version(prospective.public)

            return prospective == spec_version

    def _compare_not_equal(self, prospective: Version, spec: str) -> bool:
        return not self._compare_equal(prospective, spec)

    def _compare_less_than_equal(self, prospective: Version, spec: str) -> bool:
        
        
        
        return Version(prospective.public) <= Version(spec)

    def _compare_greater_than_equal(self, prospective: Version, spec: str) -> bool:
        
        
        
        return Version(prospective.public) >= Version(spec)

    def _compare_less_than(self, prospective: Version, spec_str: str) -> bool:
        
        
        spec = Version(spec_str)

        
        
        
        if not prospective < spec:
            return False

        
        
        
        
        if not spec.is_prerelease and prospective.is_prerelease:
            if Version(prospective.base_version) == Version(spec.base_version):
                return False

        
        
        
        return True

    def _compare_greater_than(self, prospective: Version, spec_str: str) -> bool:
        
        
        spec = Version(spec_str)

        
        
        
        if not prospective > spec:
            return False

        
        
        
        
        if not spec.is_postrelease and prospective.is_postrelease:
            if Version(prospective.base_version) == Version(spec.base_version):
                return False

        
        
        if prospective.local is not None:
            if Version(prospective.base_version) == Version(spec.base_version):
                return False

        
        
        
        return True

    def _compare_arbitrary(self, prospective: Version, spec: str) -> bool:
        return str(prospective).lower() == str(spec).lower()

    def __contains__(self, item: str | Version) -> bool:
        
        return self.contains(item)

    def contains(self, item: UnparsedVersion, prereleases: bool | None = None) -> bool:
        

        
        if prereleases is None:
            prereleases = self.prereleases

        
        
        normalized_item = _coerce_version(item)

        
        
        
        if normalized_item.is_prerelease and not prereleases:
            return False

        
        
        operator_callable: CallableOperator = self._get_operator(self.operator)
        return operator_callable(normalized_item, self.version)

    def filter(
        self, iterable: Iterable[UnparsedVersionVar], prereleases: bool | None = None
    ) -> Iterator[UnparsedVersionVar]:
        

        yielded = False
        found_prereleases = []

        kw = {""prereleases"": prereleases if prereleases is not None else True}

        
        
        for version in iterable:
            parsed_version = _coerce_version(version)

            if self.contains(parsed_version, **kw):
                
                
                
                if parsed_version.is_prerelease and not (
                    prereleases or self.prereleases
                ):
                    found_prereleases.append(version)
                
                
                else:
                    yielded = True
                    yield version

        
        
        
        if not yielded and found_prereleases:
            for version in found_prereleases:
                yield version


_prefix_regex = re.compile(r""^([0-9]+)((?:a|b|c|rc)[0-9]+)$"")


def _version_split(version: str) -> list[str]:
    
    result: list[str] = []

    epoch, _, rest = version.rpartition(""!"")
    result.append(epoch or ""0"")

    for item in rest.split("".""):
        match = _prefix_regex.search(item)
        if match:
            result.extend(match.groups())
        else:
            result.append(item)
    return result


def _version_join(components: list[str]) -> str:
    
    epoch, *rest = components
    return f""{epoch}!{'.'.join(rest)}""


def _is_not_suffix(segment: str) -> bool:
    return not any(
        segment.startswith(prefix) for prefix in (""dev"", ""a"", ""b"", ""rc"", ""post"")
    )


def _pad_version(left: list[str], right: list[str]) -> tuple[list[str], list[str]]:
    left_split, right_split = [], []

    
    left_split.append(list(itertools.takewhile(lambda x: x.isdigit(), left)))
    right_split.append(list(itertools.takewhile(lambda x: x.isdigit(), right)))

    
    left_split.append(left[len(left_split[0]) :])
    right_split.append(right[len(right_split[0]) :])

    
    left_split.insert(1, [""0""] * max(0, len(right_split[0]) - len(left_split[0])))
    right_split.insert(1, [""0""] * max(0, len(left_split[0]) - len(right_split[0])))

    return (
        list(itertools.chain.from_iterable(left_split)),
        list(itertools.chain.from_iterable(right_split)),
    )


class SpecifierSet(BaseSpecifier):
    

    def __init__(
        self,
        specifiers: str | Iterable[Specifier] = """",
        prereleases: bool | None = None,
    ) -> None:
        

        if isinstance(specifiers, str):
            
            
            split_specifiers = [s.strip() for s in specifiers.split("","") if s.strip()]

            
            
            self._specs = frozenset(map(Specifier, split_specifiers))
        else:
            
            self._specs = frozenset(specifiers)

        
        
        self._prereleases = prereleases

    @property
    def prereleases(self) -> bool | None:
        
        
        if self._prereleases is not None:
            return self._prereleases

        
        
        
        if not self._specs:
            return None

        
        
        return any(s.prereleases for s in self._specs)

    @prereleases.setter
    def prereleases(self, value: bool) -> None:
        self._prereleases = value

    def __repr__(self) -> str:
        
        pre = (
            f"", prereleases={self.prereleases!r}""
            if self._prereleases is not None
            else """"
        )

        return f""<SpecifierSet({str(self)!r}{pre})>""

    def __str__(self) -> str:
        
        return "","".join(sorted(str(s) for s in self._specs))

    def __hash__(self) -> int:
        return hash(self._specs)

    def __and__(self, other: SpecifierSet | str) -> SpecifierSet:
        
        if isinstance(other, str):
            other = SpecifierSet(other)
        elif not isinstance(other, SpecifierSet):
            return NotImplemented

        specifier = SpecifierSet()
        specifier._specs = frozenset(self._specs | other._specs)

        if self._prereleases is None and other._prereleases is not None:
            specifier._prereleases = other._prereleases
        elif self._prereleases is not None and other._prereleases is None:
            specifier._prereleases = self._prereleases
        elif self._prereleases == other._prereleases:
            specifier._prereleases = self._prereleases
        else:
            raise ValueError(
                ""Cannot combine SpecifierSets with True and False prerelease overrides.""
            )

        return specifier

    def __eq__(self, other: object) -> bool:
        
        if isinstance(other, (str, Specifier)):
            other = SpecifierSet(str(other))
        elif not isinstance(other, SpecifierSet):
            return NotImplemented

        return self._specs == other._specs

    def __len__(self) -> int:
        
        return len(self._specs)

    def __iter__(self) -> Iterator[Specifier]:
        
        return iter(self._specs)

    def __contains__(self, item: UnparsedVersion) -> bool:
        
        return self.contains(item)

    def contains(
        self,
        item: UnparsedVersion,
        prereleases: bool | None = None,
        installed: bool | None = None,
    ) -> bool:
        
        
        if not isinstance(item, Version):
            item = Version(item)

        
        
        
        if prereleases is None:
            prereleases = self.prereleases

        
        
        
        
        
        
        if not prereleases and item.is_prerelease:
            return False

        if installed and item.is_prerelease:
            item = Version(item.base_version)

        
        
        
        
        return all(s.contains(item, prereleases=prereleases) for s in self._specs)

    def filter(
        self, iterable: Iterable[UnparsedVersionVar], prereleases: bool | None = None
    ) -> Iterator[UnparsedVersionVar]:
        
        
        
        
        if prereleases is None:
            prereleases = self.prereleases

        
        
        
        if self._specs:
            for spec in self._specs:
                iterable = spec.filter(iterable, prereleases=bool(prereleases))
            return iter(iterable)
        
        
        
        else:
            filtered: list[UnparsedVersionVar] = []
            found_prereleases: list[UnparsedVersionVar] = []

            for item in iterable:
                parsed_version = _coerce_version(item)

                
                
                if parsed_version.is_prerelease and not prereleases:
                    if not filtered:
                        found_prereleases.append(item)
                else:
                    filtered.append(item)

            
            
            if not filtered and found_prereleases and prereleases is None:
                return iter(found_prereleases)

            return iter(filtered)





from __future__ import annotations

import logging
import platform
import re
import struct
import subprocess
import sys
import sysconfig
from importlib.machinery import EXTENSION_SUFFIXES
from typing import (
    Iterable,
    Iterator,
    Sequence,
    Tuple,
    cast,
)

from . import _manylinux, _musllinux

logger = logging.getLogger(__name__)

PythonVersion = Sequence[int]
AppleVersion = Tuple[int, int]

INTERPRETER_SHORT_NAMES: dict[str, str] = {
    ""python"": ""py"",  
    ""cpython"": ""cp"",
    ""pypy"": ""pp"",
    ""ironpython"": ""ip"",
    ""jython"": ""jy"",
}


_32_BIT_INTERPRETER = struct.calcsize(""P"") == 4


class Tag:
    

    __slots__ = [""_abi"", ""_hash"", ""_interpreter"", ""_platform""]

    def __init__(self, interpreter: str, abi: str, platform: str) -> None:
        self._interpreter = interpreter.lower()
        self._abi = abi.lower()
        self._platform = platform.lower()
        
        
        
        
        
        self._hash = hash((self._interpreter, self._abi, self._platform))

    @property
    def interpreter(self) -> str:
        return self._interpreter

    @property
    def abi(self) -> str:
        return self._abi

    @property
    def platform(self) -> str:
        return self._platform

    def __eq__(self, other: object) -> bool:
        if not isinstance(other, Tag):
            return NotImplemented

        return (
            (self._hash == other._hash)  
            and (self._platform == other._platform)
            and (self._abi == other._abi)
            and (self._interpreter == other._interpreter)
        )

    def __hash__(self) -> int:
        return self._hash

    def __str__(self) -> str:
        return f""{self._interpreter}-{self._abi}-{self._platform}""

    def __repr__(self) -> str:
        return f""<{self} @ {id(self)}>""


def parse_tag(tag: str) -> frozenset[Tag]:
    
    tags = set()
    interpreters, abis, platforms = tag.split(""-"")
    for interpreter in interpreters.split("".""):
        for abi in abis.split("".""):
            for platform_ in platforms.split("".""):
                tags.add(Tag(interpreter, abi, platform_))
    return frozenset(tags)


def _get_config_var(name: str, warn: bool = False) -> int | str | None:
    value: int | str | None = sysconfig.get_config_var(name)
    if value is None and warn:
        logger.debug(
            ""Config variable '%s' is unset, Python ABI tag may be incorrect"", name
        )
    return value


def _normalize_string(string: str) -> str:
    return string.replace(""."", ""_"").replace(""-"", ""_"").replace("" "", ""_"")


def _is_threaded_cpython(abis: list[str]) -> bool:
    
    if len(abis) == 0:
        return False
    
    m = re.match(r""cp\d+(.*)"", abis[0])
    if not m:
        return False
    abiflags = m.group(1)
    return ""t"" in abiflags


def _abi3_applies(python_version: PythonVersion, threading: bool) -> bool:
    
    return len(python_version) > 1 and tuple(python_version) >= (3, 2) and not threading


def _cpython_abis(py_version: PythonVersion, warn: bool = False) -> list[str]:
    py_version = tuple(py_version)  
    abis = []
    version = _version_nodot(py_version[:2])
    threading = debug = pymalloc = ucs4 = """"
    with_debug = _get_config_var(""Py_DEBUG"", warn)
    has_refcount = hasattr(sys, ""gettotalrefcount"")
    
    
    
    has_ext = ""_d.pyd"" in EXTENSION_SUFFIXES
    if with_debug or (with_debug is None and (has_refcount or has_ext)):
        debug = ""d""
    if py_version >= (3, 13) and _get_config_var(""Py_GIL_DISABLED"", warn):
        threading = ""t""
    if py_version < (3, 8):
        with_pymalloc = _get_config_var(""WITH_PYMALLOC"", warn)
        if with_pymalloc or with_pymalloc is None:
            pymalloc = ""m""
        if py_version < (3, 3):
            unicode_size = _get_config_var(""Py_UNICODE_SIZE"", warn)
            if unicode_size == 4 or (
                unicode_size is None and sys.maxunicode == 0x10FFFF
            ):
                ucs4 = ""u""
    elif debug:
        
        
        abis.append(f""cp{version}{threading}"")
    abis.insert(0, f""cp{version}{threading}{debug}{pymalloc}{ucs4}"")
    return abis


def cpython_tags(
    python_version: PythonVersion | None = None,
    abis: Iterable[str] | None = None,
    platforms: Iterable[str] | None = None,
    *,
    warn: bool = False,
) -> Iterator[Tag]:
    
    if not python_version:
        python_version = sys.version_info[:2]

    interpreter = f""cp{_version_nodot(python_version[:2])}""

    if abis is None:
        if len(python_version) > 1:
            abis = _cpython_abis(python_version, warn)
        else:
            abis = []
    abis = list(abis)
    
    for explicit_abi in (""abi3"", ""none""):
        try:
            abis.remove(explicit_abi)
        except ValueError:
            pass

    platforms = list(platforms or platform_tags())
    for abi in abis:
        for platform_ in platforms:
            yield Tag(interpreter, abi, platform_)

    threading = _is_threaded_cpython(abis)
    use_abi3 = _abi3_applies(python_version, threading)
    if use_abi3:
        yield from (Tag(interpreter, ""abi3"", platform_) for platform_ in platforms)
    yield from (Tag(interpreter, ""none"", platform_) for platform_ in platforms)

    if use_abi3:
        for minor_version in range(python_version[1] - 1, 1, -1):
            for platform_ in platforms:
                version = _version_nodot((python_version[0], minor_version))
                interpreter = f""cp{version}""
                yield Tag(interpreter, ""abi3"", platform_)


def _generic_abi() -> list[str]:
    
    
    
    
    
    
    
    
    
    
    

    ext_suffix = _get_config_var(""EXT_SUFFIX"", warn=True)
    if not isinstance(ext_suffix, str) or ext_suffix[0] != ""."":
        raise SystemError(""invalid sysconfig.get_config_var('EXT_SUFFIX')"")
    parts = ext_suffix.split(""."")
    if len(parts) < 3:
        
        return _cpython_abis(sys.version_info[:2])
    soabi = parts[1]
    if soabi.startswith(""cpython""):
        
        abi = ""cp"" + soabi.split(""-"")[1]
    elif soabi.startswith(""cp""):
        
        abi = soabi.split(""-"")[0]
    elif soabi.startswith(""pypy""):
        abi = ""-"".join(soabi.split(""-"")[:2])
    elif soabi.startswith(""graalpy""):
        abi = ""-"".join(soabi.split(""-"")[:3])
    elif soabi:
        
        abi = soabi
    else:
        return []
    return [_normalize_string(abi)]


def generic_tags(
    interpreter: str | None = None,
    abis: Iterable[str] | None = None,
    platforms: Iterable[str] | None = None,
    *,
    warn: bool = False,
) -> Iterator[Tag]:
    
    if not interpreter:
        interp_name = interpreter_name()
        interp_version = interpreter_version(warn=warn)
        interpreter = """".join([interp_name, interp_version])
    if abis is None:
        abis = _generic_abi()
    else:
        abis = list(abis)
    platforms = list(platforms or platform_tags())
    if ""none"" not in abis:
        abis.append(""none"")
    for abi in abis:
        for platform_ in platforms:
            yield Tag(interpreter, abi, platform_)


def _py_interpreter_range(py_version: PythonVersion) -> Iterator[str]:
    
    if len(py_version) > 1:
        yield f""py{_version_nodot(py_version[:2])}""
    yield f""py{py_version[0]}""
    if len(py_version) > 1:
        for minor in range(py_version[1] - 1, -1, -1):
            yield f""py{_version_nodot((py_version[0], minor))}""


def compatible_tags(
    python_version: PythonVersion | None = None,
    interpreter: str | None = None,
    platforms: Iterable[str] | None = None,
) -> Iterator[Tag]:
    
    if not python_version:
        python_version = sys.version_info[:2]
    platforms = list(platforms or platform_tags())
    for version in _py_interpreter_range(python_version):
        for platform_ in platforms:
            yield Tag(version, ""none"", platform_)
    if interpreter:
        yield Tag(interpreter, ""none"", ""any"")
    for version in _py_interpreter_range(python_version):
        yield Tag(version, ""none"", ""any"")


def _mac_arch(arch: str, is_32bit: bool = _32_BIT_INTERPRETER) -> str:
    if not is_32bit:
        return arch

    if arch.startswith(""ppc""):
        return ""ppc""

    return ""i386""


def _mac_binary_formats(version: AppleVersion, cpu_arch: str) -> list[str]:
    formats = [cpu_arch]
    if cpu_arch == ""x86_64"":
        if version < (10, 4):
            return []
        formats.extend([""intel"", ""fat64"", ""fat32""])

    elif cpu_arch == ""i386"":
        if version < (10, 4):
            return []
        formats.extend([""intel"", ""fat32"", ""fat""])

    elif cpu_arch == ""ppc64"":
        
        if version > (10, 5) or version < (10, 4):
            return []
        formats.append(""fat64"")

    elif cpu_arch == ""ppc"":
        if version > (10, 6):
            return []
        formats.extend([""fat32"", ""fat""])

    if cpu_arch in {""arm64"", ""x86_64""}:
        formats.append(""universal2"")

    if cpu_arch in {""x86_64"", ""i386"", ""ppc64"", ""ppc"", ""intel""}:
        formats.append(""universal"")

    return formats


def mac_platforms(
    version: AppleVersion | None = None, arch: str | None = None
) -> Iterator[str]:
    
    version_str, _, cpu_arch = platform.mac_ver()
    if version is None:
        version = cast(""AppleVersion"", tuple(map(int, version_str.split(""."")[:2])))
        if version == (10, 16):
            
            
            version_str = subprocess.run(
                [
                    sys.executable,
                    ""-sS"",
                    ""-c"",
                    ""import platform; print(platform.mac_ver()[0])"",
                ],
                check=True,
                env={""SYSTEM_VERSION_COMPAT"": ""0""},
                stdout=subprocess.PIPE,
                text=True,
            ).stdout
            version = cast(""AppleVersion"", tuple(map(int, version_str.split(""."")[:2])))
    else:
        version = version
    if arch is None:
        arch = _mac_arch(cpu_arch)
    else:
        arch = arch

    if (10, 0) <= version and version < (11, 0):
        
        
        major_version = 10
        for minor_version in range(version[1], -1, -1):
            compat_version = major_version, minor_version
            binary_formats = _mac_binary_formats(compat_version, arch)
            for binary_format in binary_formats:
                yield f""macosx_{major_version}_{minor_version}_{binary_format}""

    if version >= (11, 0):
        
        
        minor_version = 0
        for major_version in range(version[0], 10, -1):
            compat_version = major_version, minor_version
            binary_formats = _mac_binary_formats(compat_version, arch)
            for binary_format in binary_formats:
                yield f""macosx_{major_version}_{minor_version}_{binary_format}""

    if version >= (11, 0):
        
        
        
        
        
        
        
        major_version = 10
        if arch == ""x86_64"":
            for minor_version in range(16, 3, -1):
                compat_version = major_version, minor_version
                binary_formats = _mac_binary_formats(compat_version, arch)
                for binary_format in binary_formats:
                    yield f""macosx_{major_version}_{minor_version}_{binary_format}""
        else:
            for minor_version in range(16, 3, -1):
                compat_version = major_version, minor_version
                binary_format = ""universal2""
                yield f""macosx_{major_version}_{minor_version}_{binary_format}""


def ios_platforms(
    version: AppleVersion | None = None, multiarch: str | None = None
) -> Iterator[str]:
    
    if version is None:
        
        
        
        _, release, _, _ = platform.ios_ver()  
        version = cast(""AppleVersion"", tuple(map(int, release.split(""."")[:2])))

    if multiarch is None:
        multiarch = sys.implementation._multiarch
    multiarch = multiarch.replace(""-"", ""_"")

    ios_platform_template = ""ios_{major}_{minor}_{multiarch}""

    
    
    
    
    
    
    

    
    if version[0] < 12:
        return

    
    yield ios_platform_template.format(
        major=version[0], minor=version[1], multiarch=multiarch
    )

    
    
    for minor in range(version[1] - 1, -1, -1):
        yield ios_platform_template.format(
            major=version[0], minor=minor, multiarch=multiarch
        )

    for major in range(version[0] - 1, 11, -1):
        for minor in range(9, -1, -1):
            yield ios_platform_template.format(
                major=major, minor=minor, multiarch=multiarch
            )


def android_platforms(
    api_level: int | None = None, abi: str | None = None
) -> Iterator[str]:
    
    if platform.system() != ""Android"" and (api_level is None or abi is None):
        raise TypeError(
            ""on non-Android platforms, the api_level and abi arguments are required""
        )

    if api_level is None:
        
        
        api_level = platform.android_ver().api_level  

    if abi is None:
        abi = sysconfig.get_platform().split(""-"")[-1]
    abi = _normalize_string(abi)

    
    
    
    min_api_level = 16
    for ver in range(api_level, min_api_level - 1, -1):
        yield f""android_{ver}_{abi}""


def _linux_platforms(is_32bit: bool = _32_BIT_INTERPRETER) -> Iterator[str]:
    linux = _normalize_string(sysconfig.get_platform())
    if not linux.startswith(""linux_""):
        
        yield linux
        return
    if is_32bit:
        if linux == ""linux_x86_64"":
            linux = ""linux_i686""
        elif linux == ""linux_aarch64"":
            linux = ""linux_armv8l""
    _, arch = linux.split(""_"", 1)
    archs = {""armv8l"": [""armv8l"", ""armv7l""]}.get(arch, [arch])
    yield from _manylinux.platform_tags(archs)
    yield from _musllinux.platform_tags(archs)
    for arch in archs:
        yield f""linux_{arch}""


def _generic_platforms() -> Iterator[str]:
    yield _normalize_string(sysconfig.get_platform())


def platform_tags() -> Iterator[str]:
    
    if platform.system() == ""Darwin"":
        return mac_platforms()
    elif platform.system() == ""iOS"":
        return ios_platforms()
    elif platform.system() == ""Android"":
        return android_platforms()
    elif platform.system() == ""Linux"":
        return _linux_platforms()
    else:
        return _generic_platforms()


def interpreter_name() -> str:
    
    name = sys.implementation.name
    return INTERPRETER_SHORT_NAMES.get(name) or name


def interpreter_version(*, warn: bool = False) -> str:
    
    version = _get_config_var(""py_version_nodot"", warn=warn)
    if version:
        version = str(version)
    else:
        version = _version_nodot(sys.version_info[:2])
    return version


def _version_nodot(version: PythonVersion) -> str:
    return """".join(map(str, version))


def sys_tags(*, warn: bool = False) -> Iterator[Tag]:
    

    interp_name = interpreter_name()
    if interp_name == ""cp"":
        yield from cpython_tags(warn=warn)
    else:
        yield from generic_tags()

    if interp_name == ""pp"":
        interp = ""pp3""
    elif interp_name == ""cp"":
        interp = ""cp"" + interpreter_version(warn=warn)
    else:
        interp = None
    yield from compatible_tags(interpreter=interp)





from __future__ import annotations

import functools
import re
from typing import NewType, Tuple, Union, cast

from .tags import Tag, parse_tag
from .version import InvalidVersion, Version, _TrimmedRelease

BuildTag = Union[Tuple[()], Tuple[int, str]]
NormalizedName = NewType(""NormalizedName"", str)


class InvalidName(ValueError):
    


class InvalidWheelFilename(ValueError):
    


class InvalidSdistFilename(ValueError):
    



_validate_regex = re.compile(
    r""^([A-Z0-9]|[A-Z0-9][A-Z0-9._-]*[A-Z0-9])$"", re.IGNORECASE
)
_canonicalize_regex = re.compile(r""[-_.]+"")
_normalized_regex = re.compile(r""^([a-z0-9]|[a-z0-9]([a-z0-9-](?!--))*[a-z0-9])$"")

_build_tag_regex = re.compile(r""(\d+)(.*)"")


def canonicalize_name(name: str, *, validate: bool = False) -> NormalizedName:
    if validate and not _validate_regex.match(name):
        raise InvalidName(f""name is invalid: {name!r}"")
    
    value = _canonicalize_regex.sub(""-"", name).lower()
    return cast(NormalizedName, value)


def is_normalized_name(name: str) -> bool:
    return _normalized_regex.match(name) is not None


@functools.singledispatch
def canonicalize_version(
    version: Version | str, *, strip_trailing_zero: bool = True
) -> str:
    
    return str(_TrimmedRelease(str(version)) if strip_trailing_zero else version)


@canonicalize_version.register
def _(version: str, *, strip_trailing_zero: bool = True) -> str:
    try:
        parsed = Version(version)
    except InvalidVersion:
        
        return version
    return canonicalize_version(parsed, strip_trailing_zero=strip_trailing_zero)


def parse_wheel_filename(
    filename: str,
) -> tuple[NormalizedName, Version, BuildTag, frozenset[Tag]]:
    if not filename.endswith("".whl""):
        raise InvalidWheelFilename(
            f""Invalid wheel filename (extension must be '.whl'): {filename!r}""
        )

    filename = filename[:-4]
    dashes = filename.count(""-"")
    if dashes not in (4, 5):
        raise InvalidWheelFilename(
            f""Invalid wheel filename (wrong number of parts): {filename!r}""
        )

    parts = filename.split(""-"", dashes - 2)
    name_part = parts[0]
    
    if ""__"" in name_part or re.match(r""^[\w\d._]*$"", name_part, re.UNICODE) is None:
        raise InvalidWheelFilename(f""Invalid project name: {filename!r}"")
    name = canonicalize_name(name_part)

    try:
        version = Version(parts[1])
    except InvalidVersion as e:
        raise InvalidWheelFilename(
            f""Invalid wheel filename (invalid version): {filename!r}""
        ) from e

    if dashes == 5:
        build_part = parts[2]
        build_match = _build_tag_regex.match(build_part)
        if build_match is None:
            raise InvalidWheelFilename(
                f""Invalid build number: {build_part} in {filename!r}""
            )
        build = cast(BuildTag, (int(build_match.group(1)), build_match.group(2)))
    else:
        build = ()
    tags = parse_tag(parts[-1])
    return (name, version, build, tags)


def parse_sdist_filename(filename: str) -> tuple[NormalizedName, Version]:
    if filename.endswith("".tar.gz""):
        file_stem = filename[: -len("".tar.gz"")]
    elif filename.endswith("".zip""):
        file_stem = filename[: -len("".zip"")]
    else:
        raise InvalidSdistFilename(
            f""Invalid sdist filename (extension must be '.tar.gz' or '.zip'):""
            f"" {filename!r}""
        )

    
    
    name_part, sep, version_part = file_stem.rpartition(""-"")
    if not sep:
        raise InvalidSdistFilename(f""Invalid sdist filename: {filename!r}"")

    name = canonicalize_name(name_part)

    try:
        version = Version(version_part)
    except InvalidVersion as e:
        raise InvalidSdistFilename(
            f""Invalid sdist filename (invalid version): {filename!r}""
        ) from e

    return (name, version)






from __future__ import annotations

import itertools
import re
from typing import Any, Callable, NamedTuple, SupportsInt, Tuple, Union

from ._structures import Infinity, InfinityType, NegativeInfinity, NegativeInfinityType

__all__ = [""VERSION_PATTERN"", ""InvalidVersion"", ""Version"", ""parse""]

LocalType = Tuple[Union[int, str], ...]

CmpPrePostDevType = Union[InfinityType, NegativeInfinityType, Tuple[str, int]]
CmpLocalType = Union[
    NegativeInfinityType,
    Tuple[Union[Tuple[int, str], Tuple[NegativeInfinityType, Union[int, str]]], ...],
]
CmpKey = Tuple[
    int,
    Tuple[int, ...],
    CmpPrePostDevType,
    CmpPrePostDevType,
    CmpPrePostDevType,
    CmpLocalType,
]
VersionComparisonMethod = Callable[[CmpKey, CmpKey], bool]


class _Version(NamedTuple):
    epoch: int
    release: tuple[int, ...]
    dev: tuple[str, int] | None
    pre: tuple[str, int] | None
    post: tuple[str, int] | None
    local: LocalType | None


def parse(version: str) -> Version:
    
    return Version(version)


class InvalidVersion(ValueError):
    


class _BaseVersion:
    _key: tuple[Any, ...]

    def __hash__(self) -> int:
        return hash(self._key)

    
    
    
    def __lt__(self, other: _BaseVersion) -> bool:
        if not isinstance(other, _BaseVersion):
            return NotImplemented

        return self._key < other._key

    def __le__(self, other: _BaseVersion) -> bool:
        if not isinstance(other, _BaseVersion):
            return NotImplemented

        return self._key <= other._key

    def __eq__(self, other: object) -> bool:
        if not isinstance(other, _BaseVersion):
            return NotImplemented

        return self._key == other._key

    def __ge__(self, other: _BaseVersion) -> bool:
        if not isinstance(other, _BaseVersion):
            return NotImplemented

        return self._key >= other._key

    def __gt__(self, other: _BaseVersion) -> bool:
        if not isinstance(other, _BaseVersion):
            return NotImplemented

        return self._key > other._key

    def __ne__(self, other: object) -> bool:
        if not isinstance(other, _BaseVersion):
            return NotImplemented

        return self._key != other._key




_VERSION_PATTERN = r

VERSION_PATTERN = _VERSION_PATTERN



class Version(_BaseVersion):
    

    _regex = re.compile(r""^\s*"" + VERSION_PATTERN + r""\s*$"", re.VERBOSE | re.IGNORECASE)
    _key: CmpKey

    def __init__(self, version: str) -> None:
        

        
        match = self._regex.search(version)
        if not match:
            raise InvalidVersion(f""Invalid version: {version!r}"")

        
        self._version = _Version(
            epoch=int(match.group(""epoch"")) if match.group(""epoch"") else 0,
            release=tuple(int(i) for i in match.group(""release"").split(""."")),
            pre=_parse_letter_version(match.group(""pre_l""), match.group(""pre_n"")),
            post=_parse_letter_version(
                match.group(""post_l""), match.group(""post_n1"") or match.group(""post_n2"")
            ),
            dev=_parse_letter_version(match.group(""dev_l""), match.group(""dev_n"")),
            local=_parse_local_version(match.group(""local"")),
        )

        
        self._key = _cmpkey(
            self._version.epoch,
            self._version.release,
            self._version.pre,
            self._version.post,
            self._version.dev,
            self._version.local,
        )

    def __repr__(self) -> str:
        
        return f""<Version('{self}')>""

    def __str__(self) -> str:
        
        parts = []

        
        if self.epoch != 0:
            parts.append(f""{self.epoch}!"")

        
        parts.append(""."".join(str(x) for x in self.release))

        
        if self.pre is not None:
            parts.append("""".join(str(x) for x in self.pre))

        
        if self.post is not None:
            parts.append(f"".post{self.post}"")

        
        if self.dev is not None:
            parts.append(f"".dev{self.dev}"")

        
        if self.local is not None:
            parts.append(f""+{self.local}"")

        return """".join(parts)

    @property
    def epoch(self) -> int:
        
        return self._version.epoch

    @property
    def release(self) -> tuple[int, ...]:
        
        return self._version.release

    @property
    def pre(self) -> tuple[str, int] | None:
        
        return self._version.pre

    @property
    def post(self) -> int | None:
        
        return self._version.post[1] if self._version.post else None

    @property
    def dev(self) -> int | None:
        
        return self._version.dev[1] if self._version.dev else None

    @property
    def local(self) -> str | None:
        
        if self._version.local:
            return ""."".join(str(x) for x in self._version.local)
        else:
            return None

    @property
    def public(self) -> str:
        
        return str(self).split(""+"", 1)[0]

    @property
    def base_version(self) -> str:
        
        parts = []

        
        if self.epoch != 0:
            parts.append(f""{self.epoch}!"")

        
        parts.append(""."".join(str(x) for x in self.release))

        return """".join(parts)

    @property
    def is_prerelease(self) -> bool:
        
        return self.dev is not None or self.pre is not None

    @property
    def is_postrelease(self) -> bool:
        
        return self.post is not None

    @property
    def is_devrelease(self) -> bool:
        
        return self.dev is not None

    @property
    def major(self) -> int:
        
        return self.release[0] if len(self.release) >= 1 else 0

    @property
    def minor(self) -> int:
        
        return self.release[1] if len(self.release) >= 2 else 0

    @property
    def micro(self) -> int:
        
        return self.release[2] if len(self.release) >= 3 else 0


class _TrimmedRelease(Version):
    @property
    def release(self) -> tuple[int, ...]:
        
        rel = super().release
        nonzeros = (index for index, val in enumerate(rel) if val)
        last_nonzero = max(nonzeros, default=0)
        return rel[: last_nonzero + 1]


def _parse_letter_version(
    letter: str | None, number: str | bytes | SupportsInt | None
) -> tuple[str, int] | None:
    if letter:
        
        
        if number is None:
            number = 0

        
        letter = letter.lower()

        
        
        
        if letter == ""alpha"":
            letter = ""a""
        elif letter == ""beta"":
            letter = ""b""
        elif letter in [""c"", ""pre"", ""preview""]:
            letter = ""rc""
        elif letter in [""rev"", ""r""]:
            letter = ""post""

        return letter, int(number)

    assert not letter
    if number:
        
        
        letter = ""post""

        return letter, int(number)

    return None


_local_version_separators = re.compile(r""[\._-]"")


def _parse_local_version(local: str | None) -> LocalType | None:
    
    if local is not None:
        return tuple(
            part.lower() if not part.isdigit() else int(part)
            for part in _local_version_separators.split(local)
        )
    return None


def _cmpkey(
    epoch: int,
    release: tuple[int, ...],
    pre: tuple[str, int] | None,
    post: tuple[str, int] | None,
    dev: tuple[str, int] | None,
    local: LocalType | None,
) -> CmpKey:
    
    
    
    
    
    _release = tuple(
        reversed(list(itertools.dropwhile(lambda x: x == 0, reversed(release))))
    )

    
    
    
    
    if pre is None and post is None and dev is not None:
        _pre: CmpPrePostDevType = NegativeInfinity
    
    
    elif pre is None:
        _pre = Infinity
    else:
        _pre = pre

    
    if post is None:
        _post: CmpPrePostDevType = NegativeInfinity

    else:
        _post = post

    
    if dev is None:
        _dev: CmpPrePostDevType = Infinity

    else:
        _dev = dev

    if local is None:
        
        _local: CmpLocalType = NegativeInfinity
    else:
        
        
        
        
        
        
        
        _local = tuple(
            (i, """") if isinstance(i, int) else (NegativeInfinity, i) for i in local
        )

    return epoch, _release, _pre, _post, _dev, _local



from __future__ import annotations

import enum
import os
import struct
from typing import IO


class ELFInvalid(ValueError):
    pass


class EIClass(enum.IntEnum):
    C32 = 1
    C64 = 2


class EIData(enum.IntEnum):
    Lsb = 1
    Msb = 2


class EMachine(enum.IntEnum):
    I386 = 3
    S390 = 22
    Arm = 40
    X8664 = 62
    AArc64 = 183


class ELFFile:
    

    def __init__(self, f: IO[bytes]) -> None:
        self._f = f

        try:
            ident = self._read(""16B"")
        except struct.error as e:
            raise ELFInvalid(""unable to parse identification"") from e
        magic = bytes(ident[:4])
        if magic != b""\x7fELF"":
            raise ELFInvalid(f""invalid magic: {magic!r}"")

        self.capacity = ident[4]  
        self.encoding = ident[5]  

        try:
            
            
            
            e_fmt, self._p_fmt, self._p_idx = {
                (1, 1): (""<HHIIIIIHHH"", ""<IIIIIIII"", (0, 1, 4)),  
                (1, 2): ("">HHIIIIIHHH"", "">IIIIIIII"", (0, 1, 4)),  
                (2, 1): (""<HHIQQQIHHH"", ""<IIQQQQQQ"", (0, 2, 5)),  
                (2, 2): ("">HHIQQQIHHH"", "">IIQQQQQQ"", (0, 2, 5)),  
            }[(self.capacity, self.encoding)]
        except KeyError as e:
            raise ELFInvalid(
                f""unrecognized capacity ({self.capacity}) or encoding ({self.encoding})""
            ) from e

        try:
            (
                _,
                self.machine,  
                _,
                _,
                self._e_phoff,  
                _,
                self.flags,  
                _,
                self._e_phentsize,  
                self._e_phnum,  
            ) = self._read(e_fmt)
        except struct.error as e:
            raise ELFInvalid(""unable to parse machine and section information"") from e

    def _read(self, fmt: str) -> tuple[int, ...]:
        return struct.unpack(fmt, self._f.read(struct.calcsize(fmt)))

    @property
    def interpreter(self) -> str | None:
        
        for index in range(self._e_phnum):
            self._f.seek(self._e_phoff + self._e_phentsize * index)
            try:
                data = self._read(self._p_fmt)
            except struct.error:
                continue
            if data[self._p_idx[0]] != 3:  
                continue
            self._f.seek(data[self._p_idx[1]])
            return os.fsdecode(self._f.read(data[self._p_idx[2]])).strip(""\0"")
        return None

from __future__ import annotations

import collections
import contextlib
import functools
import os
import re
import sys
import warnings
from typing import Generator, Iterator, NamedTuple, Sequence

from ._elffile import EIClass, EIData, ELFFile, EMachine

EF_ARM_ABIMASK = 0xFF000000
EF_ARM_ABI_VER5 = 0x05000000
EF_ARM_ABI_FLOAT_HARD = 0x00000400




@contextlib.contextmanager
def _parse_elf(path: str) -> Generator[ELFFile | None, None, None]:
    try:
        with open(path, ""rb"") as f:
            yield ELFFile(f)
    except (OSError, TypeError, ValueError):
        yield None


def _is_linux_armhf(executable: str) -> bool:
    
    
    
    with _parse_elf(executable) as f:
        return (
            f is not None
            and f.capacity == EIClass.C32
            and f.encoding == EIData.Lsb
            and f.machine == EMachine.Arm
            and f.flags & EF_ARM_ABIMASK == EF_ARM_ABI_VER5
            and f.flags & EF_ARM_ABI_FLOAT_HARD == EF_ARM_ABI_FLOAT_HARD
        )


def _is_linux_i686(executable: str) -> bool:
    with _parse_elf(executable) as f:
        return (
            f is not None
            and f.capacity == EIClass.C32
            and f.encoding == EIData.Lsb
            and f.machine == EMachine.I386
        )


def _have_compatible_abi(executable: str, archs: Sequence[str]) -> bool:
    if ""armv7l"" in archs:
        return _is_linux_armhf(executable)
    if ""i686"" in archs:
        return _is_linux_i686(executable)
    allowed_archs = {
        ""x86_64"",
        ""aarch64"",
        ""ppc64"",
        ""ppc64le"",
        ""s390x"",
        ""loongarch64"",
        ""riscv64"",
    }
    return any(arch in allowed_archs for arch in archs)







_LAST_GLIBC_MINOR: dict[int, int] = collections.defaultdict(lambda: 50)


class _GLibCVersion(NamedTuple):
    major: int
    minor: int


def _glibc_version_string_confstr() -> str | None:
    
    
    
    
    
    try:
        
        version_string: str | None = os.confstr(""CS_GNU_LIBC_VERSION"")
        assert version_string is not None
        _, version = version_string.rsplit()
    except (AssertionError, AttributeError, OSError, ValueError):
        
        return None
    return version


def _glibc_version_string_ctypes() -> str | None:
    
    try:
        import ctypes
    except ImportError:
        return None

    
    
    
    
    
    
    
    
    
    
    
    
    
    try:
        process_namespace = ctypes.CDLL(None)
    except OSError:
        return None

    try:
        gnu_get_libc_version = process_namespace.gnu_get_libc_version
    except AttributeError:
        
        
        return None

    
    gnu_get_libc_version.restype = ctypes.c_char_p
    version_str: str = gnu_get_libc_version()
    
    if not isinstance(version_str, str):
        version_str = version_str.decode(""ascii"")

    return version_str


def _glibc_version_string() -> str | None:
    
    return _glibc_version_string_confstr() or _glibc_version_string_ctypes()


def _parse_glibc_version(version_str: str) -> tuple[int, int]:
    
    m = re.match(r""(?P<major>[0-9]+)\.(?P<minor>[0-9]+)"", version_str)
    if not m:
        warnings.warn(
            f""Expected glibc version with 2 components major.minor, got: {version_str}"",
            RuntimeWarning,
            stacklevel=2,
        )
        return -1, -1
    return int(m.group(""major"")), int(m.group(""minor""))


@functools.lru_cache
def _get_glibc_version() -> tuple[int, int]:
    version_str = _glibc_version_string()
    if version_str is None:
        return (-1, -1)
    return _parse_glibc_version(version_str)



def _is_compatible(arch: str, version: _GLibCVersion) -> bool:
    sys_glibc = _get_glibc_version()
    if sys_glibc < version:
        return False
    
    try:
        import _manylinux
    except ImportError:
        return True
    if hasattr(_manylinux, ""manylinux_compatible""):
        result = _manylinux.manylinux_compatible(version[0], version[1], arch)
        if result is not None:
            return bool(result)
        return True
    if version == _GLibCVersion(2, 5):
        if hasattr(_manylinux, ""manylinux1_compatible""):
            return bool(_manylinux.manylinux1_compatible)
    if version == _GLibCVersion(2, 12):
        if hasattr(_manylinux, ""manylinux2010_compatible""):
            return bool(_manylinux.manylinux2010_compatible)
    if version == _GLibCVersion(2, 17):
        if hasattr(_manylinux, ""manylinux2014_compatible""):
            return bool(_manylinux.manylinux2014_compatible)
    return True


_LEGACY_MANYLINUX_MAP = {
    
    (2, 17): ""manylinux2014"",
    
    (2, 12): ""manylinux2010"",
    
    (2, 5): ""manylinux1"",
}


def platform_tags(archs: Sequence[str]) -> Iterator[str]:
    
    if not _have_compatible_abi(sys.executable, archs):
        return
    
    too_old_glibc2 = _GLibCVersion(2, 16)
    if set(archs) & {""x86_64"", ""i686""}:
        
        too_old_glibc2 = _GLibCVersion(2, 4)
    current_glibc = _GLibCVersion(*_get_glibc_version())
    glibc_max_list = [current_glibc]
    
    
    
    
    
    
    for glibc_major in range(current_glibc.major - 1, 1, -1):
        glibc_minor = _LAST_GLIBC_MINOR[glibc_major]
        glibc_max_list.append(_GLibCVersion(glibc_major, glibc_minor))
    for arch in archs:
        for glibc_max in glibc_max_list:
            if glibc_max.major == too_old_glibc2.major:
                min_minor = too_old_glibc2.minor
            else:
                
                min_minor = -1
            for glibc_minor in range(glibc_max.minor, min_minor, -1):
                glibc_version = _GLibCVersion(glibc_max.major, glibc_minor)
                tag = ""manylinux_{}_{}"".format(*glibc_version)
                if _is_compatible(arch, glibc_version):
                    yield f""{tag}_{arch}""
                
                if glibc_version in _LEGACY_MANYLINUX_MAP:
                    legacy_tag = _LEGACY_MANYLINUX_MAP[glibc_version]
                    if _is_compatible(arch, glibc_version):
                        yield f""{legacy_tag}_{arch}""



from __future__ import annotations

import functools
import re
import subprocess
import sys
from typing import Iterator, NamedTuple, Sequence

from ._elffile import ELFFile


class _MuslVersion(NamedTuple):
    major: int
    minor: int


def _parse_musl_version(output: str) -> _MuslVersion | None:
    lines = [n for n in (n.strip() for n in output.splitlines()) if n]
    if len(lines) < 2 or lines[0][:4] != ""musl"":
        return None
    m = re.match(r""Version (\d+)\.(\d+)"", lines[1])
    if not m:
        return None
    return _MuslVersion(major=int(m.group(1)), minor=int(m.group(2)))


@functools.lru_cache
def _get_musl_version(executable: str) -> _MuslVersion | None:
    
    try:
        with open(executable, ""rb"") as f:
            ld = ELFFile(f).interpreter
    except (OSError, TypeError, ValueError):
        return None
    if ld is None or ""musl"" not in ld:
        return None
    proc = subprocess.run([ld], stderr=subprocess.PIPE, text=True)
    return _parse_musl_version(proc.stderr)


def platform_tags(archs: Sequence[str]) -> Iterator[str]:
    
    sys_musl = _get_musl_version(sys.executable)
    if sys_musl is None:  
        return
    for arch in archs:
        for minor in range(sys_musl.minor, -1, -1):
            yield f""musllinux_{sys_musl.major}_{minor}_{arch}""


if __name__ == ""__main__"":  
    import sysconfig

    plat = sysconfig.get_platform()
    assert plat.startswith(""linux-""), ""not linux""

    print(""plat:"", plat)
    print(""musl:"", _get_musl_version(sys.executable))
    print(""tags:"", end="" "")
    for t in platform_tags(re.sub(r""[.-]"", ""_"", plat.split(""-"", 1)[-1])):
        print(t, end=""\n      "")



from __future__ import annotations

import ast
from typing import NamedTuple, Sequence, Tuple, Union

from ._tokenizer import DEFAULT_RULES, Tokenizer


class Node:
    def __init__(self, value: str) -> None:
        self.value = value

    def __str__(self) -> str:
        return self.value

    def __repr__(self) -> str:
        return f""<{self.__class__.__name__}('{self}')>""

    def serialize(self) -> str:
        raise NotImplementedError


class Variable(Node):
    def serialize(self) -> str:
        return str(self)


class Value(Node):
    def serialize(self) -> str:
        return f'""{self}""'


class Op(Node):
    def serialize(self) -> str:
        return str(self)


MarkerVar = Union[Variable, Value]
MarkerItem = Tuple[MarkerVar, Op, MarkerVar]
MarkerAtom = Union[MarkerItem, Sequence[""MarkerAtom""]]
MarkerList = Sequence[Union[""MarkerList"", MarkerAtom, str]]


class ParsedRequirement(NamedTuple):
    name: str
    url: str
    extras: list[str]
    specifier: str
    marker: MarkerList | None





def parse_requirement(source: str) -> ParsedRequirement:
    return _parse_requirement(Tokenizer(source, rules=DEFAULT_RULES))


def _parse_requirement(tokenizer: Tokenizer) -> ParsedRequirement:
    
    tokenizer.consume(""WS"")

    name_token = tokenizer.expect(
        ""IDENTIFIER"", expected=""package name at the start of dependency specifier""
    )
    name = name_token.text
    tokenizer.consume(""WS"")

    extras = _parse_extras(tokenizer)
    tokenizer.consume(""WS"")

    url, specifier, marker = _parse_requirement_details(tokenizer)
    tokenizer.expect(""END"", expected=""end of dependency specifier"")

    return ParsedRequirement(name, url, extras, specifier, marker)


def _parse_requirement_details(
    tokenizer: Tokenizer,
) -> tuple[str, str, MarkerList | None]:
    

    specifier = """"
    url = """"
    marker = None

    if tokenizer.check(""AT""):
        tokenizer.read()
        tokenizer.consume(""WS"")

        url_start = tokenizer.position
        url = tokenizer.expect(""URL"", expected=""URL after @"").text
        if tokenizer.check(""END"", peek=True):
            return (url, specifier, marker)

        tokenizer.expect(""WS"", expected=""whitespace after URL"")

        
        if tokenizer.check(""END"", peek=True):
            return (url, specifier, marker)

        marker = _parse_requirement_marker(
            tokenizer, span_start=url_start, after=""URL and whitespace""
        )
    else:
        specifier_start = tokenizer.position
        specifier = _parse_specifier(tokenizer)
        tokenizer.consume(""WS"")

        if tokenizer.check(""END"", peek=True):
            return (url, specifier, marker)

        marker = _parse_requirement_marker(
            tokenizer,
            span_start=specifier_start,
            after=(
                ""version specifier""
                if specifier
                else ""name and no valid version specifier""
            ),
        )

    return (url, specifier, marker)


def _parse_requirement_marker(
    tokenizer: Tokenizer, *, span_start: int, after: str
) -> MarkerList:
    

    if not tokenizer.check(""SEMICOLON""):
        tokenizer.raise_syntax_error(
            f""Expected end or semicolon (after {after})"",
            span_start=span_start,
        )
    tokenizer.read()

    marker = _parse_marker(tokenizer)
    tokenizer.consume(""WS"")

    return marker


def _parse_extras(tokenizer: Tokenizer) -> list[str]:
    
    if not tokenizer.check(""LEFT_BRACKET"", peek=True):
        return []

    with tokenizer.enclosing_tokens(
        ""LEFT_BRACKET"",
        ""RIGHT_BRACKET"",
        around=""extras"",
    ):
        tokenizer.consume(""WS"")
        extras = _parse_extras_list(tokenizer)
        tokenizer.consume(""WS"")

    return extras


def _parse_extras_list(tokenizer: Tokenizer) -> list[str]:
    
    extras: list[str] = []

    if not tokenizer.check(""IDENTIFIER""):
        return extras

    extras.append(tokenizer.read().text)

    while True:
        tokenizer.consume(""WS"")
        if tokenizer.check(""IDENTIFIER"", peek=True):
            tokenizer.raise_syntax_error(""Expected comma between extra names"")
        elif not tokenizer.check(""COMMA""):
            break

        tokenizer.read()
        tokenizer.consume(""WS"")

        extra_token = tokenizer.expect(""IDENTIFIER"", expected=""extra name after comma"")
        extras.append(extra_token.text)

    return extras


def _parse_specifier(tokenizer: Tokenizer) -> str:
    
    with tokenizer.enclosing_tokens(
        ""LEFT_PARENTHESIS"",
        ""RIGHT_PARENTHESIS"",
        around=""version specifier"",
    ):
        tokenizer.consume(""WS"")
        parsed_specifiers = _parse_version_many(tokenizer)
        tokenizer.consume(""WS"")

    return parsed_specifiers


def _parse_version_many(tokenizer: Tokenizer) -> str:
    
    parsed_specifiers = """"
    while tokenizer.check(""SPECIFIER""):
        span_start = tokenizer.position
        parsed_specifiers += tokenizer.read().text
        if tokenizer.check(""VERSION_PREFIX_TRAIL"", peek=True):
            tokenizer.raise_syntax_error(
                "".* suffix can only be used with `==` or `!=` operators"",
                span_start=span_start,
                span_end=tokenizer.position + 1,
            )
        if tokenizer.check(""VERSION_LOCAL_LABEL_TRAIL"", peek=True):
            tokenizer.raise_syntax_error(
                ""Local version label can only be used with `==` or `!=` operators"",
                span_start=span_start,
                span_end=tokenizer.position,
            )
        tokenizer.consume(""WS"")
        if not tokenizer.check(""COMMA""):
            break
        parsed_specifiers += tokenizer.read().text
        tokenizer.consume(""WS"")

    return parsed_specifiers





def parse_marker(source: str) -> MarkerList:
    return _parse_full_marker(Tokenizer(source, rules=DEFAULT_RULES))


def _parse_full_marker(tokenizer: Tokenizer) -> MarkerList:
    retval = _parse_marker(tokenizer)
    tokenizer.expect(""END"", expected=""end of marker expression"")
    return retval


def _parse_marker(tokenizer: Tokenizer) -> MarkerList:
    
    expression = [_parse_marker_atom(tokenizer)]
    while tokenizer.check(""BOOLOP""):
        token = tokenizer.read()
        expr_right = _parse_marker_atom(tokenizer)
        expression.extend((token.text, expr_right))
    return expression


def _parse_marker_atom(tokenizer: Tokenizer) -> MarkerAtom:
    

    tokenizer.consume(""WS"")
    if tokenizer.check(""LEFT_PARENTHESIS"", peek=True):
        with tokenizer.enclosing_tokens(
            ""LEFT_PARENTHESIS"",
            ""RIGHT_PARENTHESIS"",
            around=""marker expression"",
        ):
            tokenizer.consume(""WS"")
            marker: MarkerAtom = _parse_marker(tokenizer)
            tokenizer.consume(""WS"")
    else:
        marker = _parse_marker_item(tokenizer)
    tokenizer.consume(""WS"")
    return marker


def _parse_marker_item(tokenizer: Tokenizer) -> MarkerItem:
    
    tokenizer.consume(""WS"")
    marker_var_left = _parse_marker_var(tokenizer)
    tokenizer.consume(""WS"")
    marker_op = _parse_marker_op(tokenizer)
    tokenizer.consume(""WS"")
    marker_var_right = _parse_marker_var(tokenizer)
    tokenizer.consume(""WS"")
    return (marker_var_left, marker_op, marker_var_right)


def _parse_marker_var(tokenizer: Tokenizer) -> MarkerVar:
    
    if tokenizer.check(""VARIABLE""):
        return process_env_var(tokenizer.read().text.replace(""."", ""_""))
    elif tokenizer.check(""QUOTED_STRING""):
        return process_python_str(tokenizer.read().text)
    else:
        tokenizer.raise_syntax_error(
            message=""Expected a marker variable or quoted string""
        )


def process_env_var(env_var: str) -> Variable:
    if env_var in (""platform_python_implementation"", ""python_implementation""):
        return Variable(""platform_python_implementation"")
    else:
        return Variable(env_var)


def process_python_str(python_str: str) -> Value:
    value = ast.literal_eval(python_str)
    return Value(str(value))


def _parse_marker_op(tokenizer: Tokenizer) -> Op:
    
    if tokenizer.check(""IN""):
        tokenizer.read()
        return Op(""in"")
    elif tokenizer.check(""NOT""):
        tokenizer.read()
        tokenizer.expect(""WS"", expected=""whitespace after 'not'"")
        tokenizer.expect(""IN"", expected=""'in' after 'not'"")
        return Op(""not in"")
    elif tokenizer.check(""OP""):
        return Op(tokenizer.read().text)
    else:
        return tokenizer.raise_syntax_error(
            ""Expected marker operator, one of <=, <, !=, ==, >=, >, ~=, ===, in, not in""
        )






class InfinityType:
    def __repr__(self) -> str:
        return ""Infinity""

    def __hash__(self) -> int:
        return hash(repr(self))

    def __lt__(self, other: object) -> bool:
        return False

    def __le__(self, other: object) -> bool:
        return False

    def __eq__(self, other: object) -> bool:
        return isinstance(other, self.__class__)

    def __gt__(self, other: object) -> bool:
        return True

    def __ge__(self, other: object) -> bool:
        return True

    def __neg__(self: object) -> ""NegativeInfinityType"":
        return NegativeInfinity


Infinity = InfinityType()


class NegativeInfinityType:
    def __repr__(self) -> str:
        return ""-Infinity""

    def __hash__(self) -> int:
        return hash(repr(self))

    def __lt__(self, other: object) -> bool:
        return True

    def __le__(self, other: object) -> bool:
        return True

    def __eq__(self, other: object) -> bool:
        return isinstance(other, self.__class__)

    def __gt__(self, other: object) -> bool:
        return False

    def __ge__(self, other: object) -> bool:
        return False

    def __neg__(self: object) -> InfinityType:
        return Infinity


NegativeInfinity = NegativeInfinityType()

from __future__ import annotations

import contextlib
import re
from dataclasses import dataclass
from typing import Iterator, NoReturn

from .specifiers import Specifier


@dataclass
class Token:
    name: str
    text: str
    position: int


class ParserSyntaxError(Exception):
    

    def __init__(
        self,
        message: str,
        *,
        source: str,
        span: tuple[int, int],
    ) -> None:
        self.span = span
        self.message = message
        self.source = source

        super().__init__()

    def __str__(self) -> str:
        marker = "" "" * self.span[0] + ""~"" * (self.span[1] - self.span[0]) + ""^""
        return ""\n    "".join([self.message, self.source, marker])


DEFAULT_RULES: dict[str, str | re.Pattern[str]] = {
    ""LEFT_PARENTHESIS"": r""\("",
    ""RIGHT_PARENTHESIS"": r""\)"",
    ""LEFT_BRACKET"": r""\["",
    ""RIGHT_BRACKET"": r""\]"",
    ""SEMICOLON"": r"";"",
    ""COMMA"": r"","",
    ""QUOTED_STRING"": re.compile(
        r,
        re.VERBOSE,
    ),
    ""OP"": r""(===|==|~=|!=|<=|>=|<|>)"",
    ""BOOLOP"": r""\b(or|and)\b"",
    ""IN"": r""\bin\b"",
    ""NOT"": r""\bnot\b"",
    ""VARIABLE"": re.compile(
        r,
        re.VERBOSE,
    ),
    ""SPECIFIER"": re.compile(
        Specifier._operator_regex_str + Specifier._version_regex_str,
        re.VERBOSE | re.IGNORECASE,
    ),
    ""AT"": r""\@"",
    ""URL"": r""[^ \t]+"",
    ""IDENTIFIER"": r""\b[a-zA-Z0-9][a-zA-Z0-9._-]*\b"",
    ""VERSION_PREFIX_TRAIL"": r""\.\*"",
    ""VERSION_LOCAL_LABEL_TRAIL"": r""\+[a-z0-9]+(?:[-_\.][a-z0-9]+)*"",
    ""WS"": r""[ \t]+"",
    ""END"": r""$"",
}


class Tokenizer:
    

    def __init__(
        self,
        source: str,
        *,
        rules: dict[str, str | re.Pattern[str]],
    ) -> None:
        self.source = source
        self.rules: dict[str, re.Pattern[str]] = {
            name: re.compile(pattern) for name, pattern in rules.items()
        }
        self.next_token: Token | None = None
        self.position = 0

    def consume(self, name: str) -> None:
        
        if self.check(name):
            self.read()

    def check(self, name: str, *, peek: bool = False) -> bool:
        
        assert self.next_token is None, (
            f""Cannot check for {name!r}, already have {self.next_token!r}""
        )
        assert name in self.rules, f""Unknown token name: {name!r}""

        expression = self.rules[name]

        match = expression.match(self.source, self.position)
        if match is None:
            return False
        if not peek:
            self.next_token = Token(name, match[0], self.position)
        return True

    def expect(self, name: str, *, expected: str) -> Token:
        
        if not self.check(name):
            raise self.raise_syntax_error(f""Expected {expected}"")
        return self.read()

    def read(self) -> Token:
        
        token = self.next_token
        assert token is not None

        self.position += len(token.text)
        self.next_token = None

        return token

    def raise_syntax_error(
        self,
        message: str,
        *,
        span_start: int | None = None,
        span_end: int | None = None,
    ) -> NoReturn:
        
        span = (
            self.position if span_start is None else span_start,
            self.position if span_end is None else span_end,
        )
        raise ParserSyntaxError(
            message,
            source=self.source,
            span=span,
        )

    @contextlib.contextmanager
    def enclosing_tokens(
        self, open_token: str, close_token: str, *, around: str
    ) -> Iterator[None]:
        if self.check(open_token):
            open_position = self.position
            self.read()
        else:
            open_position = None

        yield

        if open_position is None:
            return

        if not self.check(close_token):
            self.raise_syntax_error(
                f""Expected matching {close_token} for {open_token}, after {around}"",
                span_start=open_position,
            )

        self.read()





__title__ = ""packaging""
__summary__ = ""Core utilities for Python packages""
__uri__ = ""https://github.com/pypa/packaging""

__version__ = ""25.0""

__author__ = ""Donald Stufft and individual contributors""
__email__ = ""donald@stufft.io""

__license__ = ""BSD-2-Clause or Apache-2.0""
__copyright__ = f""2014 {__author__}""


from __future__ import annotations

from typing import TypedDict

class SPDXLicense(TypedDict):
    id: str
    deprecated: bool

class SPDXException(TypedDict):
    id: str
    deprecated: bool


VERSION = '3.25.0'

LICENSES: dict[str, SPDXLicense] = {
    '0bsd': {'id': '0BSD', 'deprecated': False},
    '3d-slicer-1.0': {'id': '3D-Slicer-1.0', 'deprecated': False},
    'aal': {'id': 'AAL', 'deprecated': False},
    'abstyles': {'id': 'Abstyles', 'deprecated': False},
    'adacore-doc': {'id': 'AdaCore-doc', 'deprecated': False},
    'adobe-2006': {'id': 'Adobe-2006', 'deprecated': False},
    'adobe-display-postscript': {'id': 'Adobe-Display-PostScript', 'deprecated': False},
    'adobe-glyph': {'id': 'Adobe-Glyph', 'deprecated': False},
    'adobe-utopia': {'id': 'Adobe-Utopia', 'deprecated': False},
    'adsl': {'id': 'ADSL', 'deprecated': False},
    'afl-1.1': {'id': 'AFL-1.1', 'deprecated': False},
    'afl-1.2': {'id': 'AFL-1.2', 'deprecated': False},
    'afl-2.0': {'id': 'AFL-2.0', 'deprecated': False},
    'afl-2.1': {'id': 'AFL-2.1', 'deprecated': False},
    'afl-3.0': {'id': 'AFL-3.0', 'deprecated': False},
    'afmparse': {'id': 'Afmparse', 'deprecated': False},
    'agpl-1.0': {'id': 'AGPL-1.0', 'deprecated': True},
    'agpl-1.0-only': {'id': 'AGPL-1.0-only', 'deprecated': False},
    'agpl-1.0-or-later': {'id': 'AGPL-1.0-or-later', 'deprecated': False},
    'agpl-3.0': {'id': 'AGPL-3.0', 'deprecated': True},
    'agpl-3.0-only': {'id': 'AGPL-3.0-only', 'deprecated': False},
    'agpl-3.0-or-later': {'id': 'AGPL-3.0-or-later', 'deprecated': False},
    'aladdin': {'id': 'Aladdin', 'deprecated': False},
    'amd-newlib': {'id': 'AMD-newlib', 'deprecated': False},
    'amdplpa': {'id': 'AMDPLPA', 'deprecated': False},
    'aml': {'id': 'AML', 'deprecated': False},
    'aml-glslang': {'id': 'AML-glslang', 'deprecated': False},
    'ampas': {'id': 'AMPAS', 'deprecated': False},
    'antlr-pd': {'id': 'ANTLR-PD', 'deprecated': False},
    'antlr-pd-fallback': {'id': 'ANTLR-PD-fallback', 'deprecated': False},
    'any-osi': {'id': 'any-OSI', 'deprecated': False},
    'apache-1.0': {'id': 'Apache-1.0', 'deprecated': False},
    'apache-1.1': {'id': 'Apache-1.1', 'deprecated': False},
    'apache-2.0': {'id': 'Apache-2.0', 'deprecated': False},
    'apafml': {'id': 'APAFML', 'deprecated': False},
    'apl-1.0': {'id': 'APL-1.0', 'deprecated': False},
    'app-s2p': {'id': 'App-s2p', 'deprecated': False},
    'apsl-1.0': {'id': 'APSL-1.0', 'deprecated': False},
    'apsl-1.1': {'id': 'APSL-1.1', 'deprecated': False},
    'apsl-1.2': {'id': 'APSL-1.2', 'deprecated': False},
    'apsl-2.0': {'id': 'APSL-2.0', 'deprecated': False},
    'arphic-1999': {'id': 'Arphic-1999', 'deprecated': False},
    'artistic-1.0': {'id': 'Artistic-1.0', 'deprecated': False},
    'artistic-1.0-cl8': {'id': 'Artistic-1.0-cl8', 'deprecated': False},
    'artistic-1.0-perl': {'id': 'Artistic-1.0-Perl', 'deprecated': False},
    'artistic-2.0': {'id': 'Artistic-2.0', 'deprecated': False},
    'aswf-digital-assets-1.0': {'id': 'ASWF-Digital-Assets-1.0', 'deprecated': False},
    'aswf-digital-assets-1.1': {'id': 'ASWF-Digital-Assets-1.1', 'deprecated': False},
    'baekmuk': {'id': 'Baekmuk', 'deprecated': False},
    'bahyph': {'id': 'Bahyph', 'deprecated': False},
    'barr': {'id': 'Barr', 'deprecated': False},
    'bcrypt-solar-designer': {'id': 'bcrypt-Solar-Designer', 'deprecated': False},
    'beerware': {'id': 'Beerware', 'deprecated': False},
    'bitstream-charter': {'id': 'Bitstream-Charter', 'deprecated': False},
    'bitstream-vera': {'id': 'Bitstream-Vera', 'deprecated': False},
    'bittorrent-1.0': {'id': 'BitTorrent-1.0', 'deprecated': False},
    'bittorrent-1.1': {'id': 'BitTorrent-1.1', 'deprecated': False},
    'blessing': {'id': 'blessing', 'deprecated': False},
    'blueoak-1.0.0': {'id': 'BlueOak-1.0.0', 'deprecated': False},
    'boehm-gc': {'id': 'Boehm-GC', 'deprecated': False},
    'borceux': {'id': 'Borceux', 'deprecated': False},
    'brian-gladman-2-clause': {'id': 'Brian-Gladman-2-Clause', 'deprecated': False},
    'brian-gladman-3-clause': {'id': 'Brian-Gladman-3-Clause', 'deprecated': False},
    'bsd-1-clause': {'id': 'BSD-1-Clause', 'deprecated': False},
    'bsd-2-clause': {'id': 'BSD-2-Clause', 'deprecated': False},
    'bsd-2-clause-darwin': {'id': 'BSD-2-Clause-Darwin', 'deprecated': False},
    'bsd-2-clause-first-lines': {'id': 'BSD-2-Clause-first-lines', 'deprecated': False},
    'bsd-2-clause-freebsd': {'id': 'BSD-2-Clause-FreeBSD', 'deprecated': True},
    'bsd-2-clause-netbsd': {'id': 'BSD-2-Clause-NetBSD', 'deprecated': True},
    'bsd-2-clause-patent': {'id': 'BSD-2-Clause-Patent', 'deprecated': False},
    'bsd-2-clause-views': {'id': 'BSD-2-Clause-Views', 'deprecated': False},
    'bsd-3-clause': {'id': 'BSD-3-Clause', 'deprecated': False},
    'bsd-3-clause-acpica': {'id': 'BSD-3-Clause-acpica', 'deprecated': False},
    'bsd-3-clause-attribution': {'id': 'BSD-3-Clause-Attribution', 'deprecated': False},
    'bsd-3-clause-clear': {'id': 'BSD-3-Clause-Clear', 'deprecated': False},
    'bsd-3-clause-flex': {'id': 'BSD-3-Clause-flex', 'deprecated': False},
    'bsd-3-clause-hp': {'id': 'BSD-3-Clause-HP', 'deprecated': False},
    'bsd-3-clause-lbnl': {'id': 'BSD-3-Clause-LBNL', 'deprecated': False},
    'bsd-3-clause-modification': {'id': 'BSD-3-Clause-Modification', 'deprecated': False},
    'bsd-3-clause-no-military-license': {'id': 'BSD-3-Clause-No-Military-License', 'deprecated': False},
    'bsd-3-clause-no-nuclear-license': {'id': 'BSD-3-Clause-No-Nuclear-License', 'deprecated': False},
    'bsd-3-clause-no-nuclear-license-2014': {'id': 'BSD-3-Clause-No-Nuclear-License-2014', 'deprecated': False},
    'bsd-3-clause-no-nuclear-warranty': {'id': 'BSD-3-Clause-No-Nuclear-Warranty', 'deprecated': False},
    'bsd-3-clause-open-mpi': {'id': 'BSD-3-Clause-Open-MPI', 'deprecated': False},
    'bsd-3-clause-sun': {'id': 'BSD-3-Clause-Sun', 'deprecated': False},
    'bsd-4-clause': {'id': 'BSD-4-Clause', 'deprecated': False},
    'bsd-4-clause-shortened': {'id': 'BSD-4-Clause-Shortened', 'deprecated': False},
    'bsd-4-clause-uc': {'id': 'BSD-4-Clause-UC', 'deprecated': False},
    'bsd-4.3reno': {'id': 'BSD-4.3RENO', 'deprecated': False},
    'bsd-4.3tahoe': {'id': 'BSD-4.3TAHOE', 'deprecated': False},
    'bsd-advertising-acknowledgement': {'id': 'BSD-Advertising-Acknowledgement', 'deprecated': False},
    'bsd-attribution-hpnd-disclaimer': {'id': 'BSD-Attribution-HPND-disclaimer', 'deprecated': False},
    'bsd-inferno-nettverk': {'id': 'BSD-Inferno-Nettverk', 'deprecated': False},
    'bsd-protection': {'id': 'BSD-Protection', 'deprecated': False},
    'bsd-source-beginning-file': {'id': 'BSD-Source-beginning-file', 'deprecated': False},
    'bsd-source-code': {'id': 'BSD-Source-Code', 'deprecated': False},
    'bsd-systemics': {'id': 'BSD-Systemics', 'deprecated': False},
    'bsd-systemics-w3works': {'id': 'BSD-Systemics-W3Works', 'deprecated': False},
    'bsl-1.0': {'id': 'BSL-1.0', 'deprecated': False},
    'busl-1.1': {'id': 'BUSL-1.1', 'deprecated': False},
    'bzip2-1.0.5': {'id': 'bzip2-1.0.5', 'deprecated': True},
    'bzip2-1.0.6': {'id': 'bzip2-1.0.6', 'deprecated': False},
    'c-uda-1.0': {'id': 'C-UDA-1.0', 'deprecated': False},
    'cal-1.0': {'id': 'CAL-1.0', 'deprecated': False},
    'cal-1.0-combined-work-exception': {'id': 'CAL-1.0-Combined-Work-Exception', 'deprecated': False},
    'caldera': {'id': 'Caldera', 'deprecated': False},
    'caldera-no-preamble': {'id': 'Caldera-no-preamble', 'deprecated': False},
    'catharon': {'id': 'Catharon', 'deprecated': False},
    'catosl-1.1': {'id': 'CATOSL-1.1', 'deprecated': False},
    'cc-by-1.0': {'id': 'CC-BY-1.0', 'deprecated': False},
    'cc-by-2.0': {'id': 'CC-BY-2.0', 'deprecated': False},
    'cc-by-2.5': {'id': 'CC-BY-2.5', 'deprecated': False},
    'cc-by-2.5-au': {'id': 'CC-BY-2.5-AU', 'deprecated': False},
    'cc-by-3.0': {'id': 'CC-BY-3.0', 'deprecated': False},
    'cc-by-3.0-at': {'id': 'CC-BY-3.0-AT', 'deprecated': False},
    'cc-by-3.0-au': {'id': 'CC-BY-3.0-AU', 'deprecated': False},
    'cc-by-3.0-de': {'id': 'CC-BY-3.0-DE', 'deprecated': False},
    'cc-by-3.0-igo': {'id': 'CC-BY-3.0-IGO', 'deprecated': False},
    'cc-by-3.0-nl': {'id': 'CC-BY-3.0-NL', 'deprecated': False},
    'cc-by-3.0-us': {'id': 'CC-BY-3.0-US', 'deprecated': False},
    'cc-by-4.0': {'id': 'CC-BY-4.0', 'deprecated': False},
    'cc-by-nc-1.0': {'id': 'CC-BY-NC-1.0', 'deprecated': False},
    'cc-by-nc-2.0': {'id': 'CC-BY-NC-2.0', 'deprecated': False},
    'cc-by-nc-2.5': {'id': 'CC-BY-NC-2.5', 'deprecated': False},
    'cc-by-nc-3.0': {'id': 'CC-BY-NC-3.0', 'deprecated': False},
    'cc-by-nc-3.0-de': {'id': 'CC-BY-NC-3.0-DE', 'deprecated': False},
    'cc-by-nc-4.0': {'id': 'CC-BY-NC-4.0', 'deprecated': False},
    'cc-by-nc-nd-1.0': {'id': 'CC-BY-NC-ND-1.0', 'deprecated': False},
    'cc-by-nc-nd-2.0': {'id': 'CC-BY-NC-ND-2.0', 'deprecated': False},
    'cc-by-nc-nd-2.5': {'id': 'CC-BY-NC-ND-2.5', 'deprecated': False},
    'cc-by-nc-nd-3.0': {'id': 'CC-BY-NC-ND-3.0', 'deprecated': False},
    'cc-by-nc-nd-3.0-de': {'id': 'CC-BY-NC-ND-3.0-DE', 'deprecated': False},
    'cc-by-nc-nd-3.0-igo': {'id': 'CC-BY-NC-ND-3.0-IGO', 'deprecated': False},
    'cc-by-nc-nd-4.0': {'id': 'CC-BY-NC-ND-4.0', 'deprecated': False},
    'cc-by-nc-sa-1.0': {'id': 'CC-BY-NC-SA-1.0', 'deprecated': False},
    'cc-by-nc-sa-2.0': {'id': 'CC-BY-NC-SA-2.0', 'deprecated': False},
    'cc-by-nc-sa-2.0-de': {'id': 'CC-BY-NC-SA-2.0-DE', 'deprecated': False},
    'cc-by-nc-sa-2.0-fr': {'id': 'CC-BY-NC-SA-2.0-FR', 'deprecated': False},
    'cc-by-nc-sa-2.0-uk': {'id': 'CC-BY-NC-SA-2.0-UK', 'deprecated': False},
    'cc-by-nc-sa-2.5': {'id': 'CC-BY-NC-SA-2.5', 'deprecated': False},
    'cc-by-nc-sa-3.0': {'id': 'CC-BY-NC-SA-3.0', 'deprecated': False},
    'cc-by-nc-sa-3.0-de': {'id': 'CC-BY-NC-SA-3.0-DE', 'deprecated': False},
    'cc-by-nc-sa-3.0-igo': {'id': 'CC-BY-NC-SA-3.0-IGO', 'deprecated': False},
    'cc-by-nc-sa-4.0': {'id': 'CC-BY-NC-SA-4.0', 'deprecated': False},
    'cc-by-nd-1.0': {'id': 'CC-BY-ND-1.0', 'deprecated': False},
    'cc-by-nd-2.0': {'id': 'CC-BY-ND-2.0', 'deprecated': False},
    'cc-by-nd-2.5': {'id': 'CC-BY-ND-2.5', 'deprecated': False},
    'cc-by-nd-3.0': {'id': 'CC-BY-ND-3.0', 'deprecated': False},
    'cc-by-nd-3.0-de': {'id': 'CC-BY-ND-3.0-DE', 'deprecated': False},
    'cc-by-nd-4.0': {'id': 'CC-BY-ND-4.0', 'deprecated': False},
    'cc-by-sa-1.0': {'id': 'CC-BY-SA-1.0', 'deprecated': False},
    'cc-by-sa-2.0': {'id': 'CC-BY-SA-2.0', 'deprecated': False},
    'cc-by-sa-2.0-uk': {'id': 'CC-BY-SA-2.0-UK', 'deprecated': False},
    'cc-by-sa-2.1-jp': {'id': 'CC-BY-SA-2.1-JP', 'deprecated': False},
    'cc-by-sa-2.5': {'id': 'CC-BY-SA-2.5', 'deprecated': False},
    'cc-by-sa-3.0': {'id': 'CC-BY-SA-3.0', 'deprecated': False},
    'cc-by-sa-3.0-at': {'id': 'CC-BY-SA-3.0-AT', 'deprecated': False},
    'cc-by-sa-3.0-de': {'id': 'CC-BY-SA-3.0-DE', 'deprecated': False},
    'cc-by-sa-3.0-igo': {'id': 'CC-BY-SA-3.0-IGO', 'deprecated': False},
    'cc-by-sa-4.0': {'id': 'CC-BY-SA-4.0', 'deprecated': False},
    'cc-pddc': {'id': 'CC-PDDC', 'deprecated': False},
    'cc0-1.0': {'id': 'CC0-1.0', 'deprecated': False},
    'cddl-1.0': {'id': 'CDDL-1.0', 'deprecated': False},
    'cddl-1.1': {'id': 'CDDL-1.1', 'deprecated': False},
    'cdl-1.0': {'id': 'CDL-1.0', 'deprecated': False},
    'cdla-permissive-1.0': {'id': 'CDLA-Permissive-1.0', 'deprecated': False},
    'cdla-permissive-2.0': {'id': 'CDLA-Permissive-2.0', 'deprecated': False},
    'cdla-sharing-1.0': {'id': 'CDLA-Sharing-1.0', 'deprecated': False},
    'cecill-1.0': {'id': 'CECILL-1.0', 'deprecated': False},
    'cecill-1.1': {'id': 'CECILL-1.1', 'deprecated': False},
    'cecill-2.0': {'id': 'CECILL-2.0', 'deprecated': False},
    'cecill-2.1': {'id': 'CECILL-2.1', 'deprecated': False},
    'cecill-b': {'id': 'CECILL-B', 'deprecated': False},
    'cecill-c': {'id': 'CECILL-C', 'deprecated': False},
    'cern-ohl-1.1': {'id': 'CERN-OHL-1.1', 'deprecated': False},
    'cern-ohl-1.2': {'id': 'CERN-OHL-1.2', 'deprecated': False},
    'cern-ohl-p-2.0': {'id': 'CERN-OHL-P-2.0', 'deprecated': False},
    'cern-ohl-s-2.0': {'id': 'CERN-OHL-S-2.0', 'deprecated': False},
    'cern-ohl-w-2.0': {'id': 'CERN-OHL-W-2.0', 'deprecated': False},
    'cfitsio': {'id': 'CFITSIO', 'deprecated': False},
    'check-cvs': {'id': 'check-cvs', 'deprecated': False},
    'checkmk': {'id': 'checkmk', 'deprecated': False},
    'clartistic': {'id': 'ClArtistic', 'deprecated': False},
    'clips': {'id': 'Clips', 'deprecated': False},
    'cmu-mach': {'id': 'CMU-Mach', 'deprecated': False},
    'cmu-mach-nodoc': {'id': 'CMU-Mach-nodoc', 'deprecated': False},
    'cnri-jython': {'id': 'CNRI-Jython', 'deprecated': False},
    'cnri-python': {'id': 'CNRI-Python', 'deprecated': False},
    'cnri-python-gpl-compatible': {'id': 'CNRI-Python-GPL-Compatible', 'deprecated': False},
    'coil-1.0': {'id': 'COIL-1.0', 'deprecated': False},
    'community-spec-1.0': {'id': 'Community-Spec-1.0', 'deprecated': False},
    'condor-1.1': {'id': 'Condor-1.1', 'deprecated': False},
    'copyleft-next-0.3.0': {'id': 'copyleft-next-0.3.0', 'deprecated': False},
    'copyleft-next-0.3.1': {'id': 'copyleft-next-0.3.1', 'deprecated': False},
    'cornell-lossless-jpeg': {'id': 'Cornell-Lossless-JPEG', 'deprecated': False},
    'cpal-1.0': {'id': 'CPAL-1.0', 'deprecated': False},
    'cpl-1.0': {'id': 'CPL-1.0', 'deprecated': False},
    'cpol-1.02': {'id': 'CPOL-1.02', 'deprecated': False},
    'cronyx': {'id': 'Cronyx', 'deprecated': False},
    'crossword': {'id': 'Crossword', 'deprecated': False},
    'crystalstacker': {'id': 'CrystalStacker', 'deprecated': False},
    'cua-opl-1.0': {'id': 'CUA-OPL-1.0', 'deprecated': False},
    'cube': {'id': 'Cube', 'deprecated': False},
    'curl': {'id': 'curl', 'deprecated': False},
    'cve-tou': {'id': 'cve-tou', 'deprecated': False},
    'd-fsl-1.0': {'id': 'D-FSL-1.0', 'deprecated': False},
    'dec-3-clause': {'id': 'DEC-3-Clause', 'deprecated': False},
    'diffmark': {'id': 'diffmark', 'deprecated': False},
    'dl-de-by-2.0': {'id': 'DL-DE-BY-2.0', 'deprecated': False},
    'dl-de-zero-2.0': {'id': 'DL-DE-ZERO-2.0', 'deprecated': False},
    'doc': {'id': 'DOC', 'deprecated': False},
    'docbook-schema': {'id': 'DocBook-Schema', 'deprecated': False},
    'docbook-xml': {'id': 'DocBook-XML', 'deprecated': False},
    'dotseqn': {'id': 'Dotseqn', 'deprecated': False},
    'drl-1.0': {'id': 'DRL-1.0', 'deprecated': False},
    'drl-1.1': {'id': 'DRL-1.1', 'deprecated': False},
    'dsdp': {'id': 'DSDP', 'deprecated': False},
    'dtoa': {'id': 'dtoa', 'deprecated': False},
    'dvipdfm': {'id': 'dvipdfm', 'deprecated': False},
    'ecl-1.0': {'id': 'ECL-1.0', 'deprecated': False},
    'ecl-2.0': {'id': 'ECL-2.0', 'deprecated': False},
    'ecos-2.0': {'id': 'eCos-2.0', 'deprecated': True},
    'efl-1.0': {'id': 'EFL-1.0', 'deprecated': False},
    'efl-2.0': {'id': 'EFL-2.0', 'deprecated': False},
    'egenix': {'id': 'eGenix', 'deprecated': False},
    'elastic-2.0': {'id': 'Elastic-2.0', 'deprecated': False},
    'entessa': {'id': 'Entessa', 'deprecated': False},
    'epics': {'id': 'EPICS', 'deprecated': False},
    'epl-1.0': {'id': 'EPL-1.0', 'deprecated': False},
    'epl-2.0': {'id': 'EPL-2.0', 'deprecated': False},
    'erlpl-1.1': {'id': 'ErlPL-1.1', 'deprecated': False},
    'etalab-2.0': {'id': 'etalab-2.0', 'deprecated': False},
    'eudatagrid': {'id': 'EUDatagrid', 'deprecated': False},
    'eupl-1.0': {'id': 'EUPL-1.0', 'deprecated': False},
    'eupl-1.1': {'id': 'EUPL-1.1', 'deprecated': False},
    'eupl-1.2': {'id': 'EUPL-1.2', 'deprecated': False},
    'eurosym': {'id': 'Eurosym', 'deprecated': False},
    'fair': {'id': 'Fair', 'deprecated': False},
    'fbm': {'id': 'FBM', 'deprecated': False},
    'fdk-aac': {'id': 'FDK-AAC', 'deprecated': False},
    'ferguson-twofish': {'id': 'Ferguson-Twofish', 'deprecated': False},
    'frameworx-1.0': {'id': 'Frameworx-1.0', 'deprecated': False},
    'freebsd-doc': {'id': 'FreeBSD-DOC', 'deprecated': False},
    'freeimage': {'id': 'FreeImage', 'deprecated': False},
    'fsfap': {'id': 'FSFAP', 'deprecated': False},
    'fsfap-no-warranty-disclaimer': {'id': 'FSFAP-no-warranty-disclaimer', 'deprecated': False},
    'fsful': {'id': 'FSFUL', 'deprecated': False},
    'fsfullr': {'id': 'FSFULLR', 'deprecated': False},
    'fsfullrwd': {'id': 'FSFULLRWD', 'deprecated': False},
    'ftl': {'id': 'FTL', 'deprecated': False},
    'furuseth': {'id': 'Furuseth', 'deprecated': False},
    'fwlw': {'id': 'fwlw', 'deprecated': False},
    'gcr-docs': {'id': 'GCR-docs', 'deprecated': False},
    'gd': {'id': 'GD', 'deprecated': False},
    'gfdl-1.1': {'id': 'GFDL-1.1', 'deprecated': True},
    'gfdl-1.1-invariants-only': {'id': 'GFDL-1.1-invariants-only', 'deprecated': False},
    'gfdl-1.1-invariants-or-later': {'id': 'GFDL-1.1-invariants-or-later', 'deprecated': False},
    'gfdl-1.1-no-invariants-only': {'id': 'GFDL-1.1-no-invariants-only', 'deprecated': False},
    'gfdl-1.1-no-invariants-or-later': {'id': 'GFDL-1.1-no-invariants-or-later', 'deprecated': False},
    'gfdl-1.1-only': {'id': 'GFDL-1.1-only', 'deprecated': False},
    'gfdl-1.1-or-later': {'id': 'GFDL-1.1-or-later', 'deprecated': False},
    'gfdl-1.2': {'id': 'GFDL-1.2', 'deprecated': True},
    'gfdl-1.2-invariants-only': {'id': 'GFDL-1.2-invariants-only', 'deprecated': False},
    'gfdl-1.2-invariants-or-later': {'id': 'GFDL-1.2-invariants-or-later', 'deprecated': False},
    'gfdl-1.2-no-invariants-only': {'id': 'GFDL-1.2-no-invariants-only', 'deprecated': False},
    'gfdl-1.2-no-invariants-or-later': {'id': 'GFDL-1.2-no-invariants-or-later', 'deprecated': False},
    'gfdl-1.2-only': {'id': 'GFDL-1.2-only', 'deprecated': False},
    'gfdl-1.2-or-later': {'id': 'GFDL-1.2-or-later', 'deprecated': False},
    'gfdl-1.3': {'id': 'GFDL-1.3', 'deprecated': True},
    'gfdl-1.3-invariants-only': {'id': 'GFDL-1.3-invariants-only', 'deprecated': False},
    'gfdl-1.3-invariants-or-later': {'id': 'GFDL-1.3-invariants-or-later', 'deprecated': False},
    'gfdl-1.3-no-invariants-only': {'id': 'GFDL-1.3-no-invariants-only', 'deprecated': False},
    'gfdl-1.3-no-invariants-or-later': {'id': 'GFDL-1.3-no-invariants-or-later', 'deprecated': False},
    'gfdl-1.3-only': {'id': 'GFDL-1.3-only', 'deprecated': False},
    'gfdl-1.3-or-later': {'id': 'GFDL-1.3-or-later', 'deprecated': False},
    'giftware': {'id': 'Giftware', 'deprecated': False},
    'gl2ps': {'id': 'GL2PS', 'deprecated': False},
    'glide': {'id': 'Glide', 'deprecated': False},
    'glulxe': {'id': 'Glulxe', 'deprecated': False},
    'glwtpl': {'id': 'GLWTPL', 'deprecated': False},
    'gnuplot': {'id': 'gnuplot', 'deprecated': False},
    'gpl-1.0': {'id': 'GPL-1.0', 'deprecated': True},
    'gpl-1.0+': {'id': 'GPL-1.0+', 'deprecated': True},
    'gpl-1.0-only': {'id': 'GPL-1.0-only', 'deprecated': False},
    'gpl-1.0-or-later': {'id': 'GPL-1.0-or-later', 'deprecated': False},
    'gpl-2.0': {'id': 'GPL-2.0', 'deprecated': True},
    'gpl-2.0+': {'id': 'GPL-2.0+', 'deprecated': True},
    'gpl-2.0-only': {'id': 'GPL-2.0-only', 'deprecated': False},
    'gpl-2.0-or-later': {'id': 'GPL-2.0-or-later', 'deprecated': False},
    'gpl-2.0-with-autoconf-exception': {'id': 'GPL-2.0-with-autoconf-exception', 'deprecated': True},
    'gpl-2.0-with-bison-exception': {'id': 'GPL-2.0-with-bison-exception', 'deprecated': True},
    'gpl-2.0-with-classpath-exception': {'id': 'GPL-2.0-with-classpath-exception', 'deprecated': True},
    'gpl-2.0-with-font-exception': {'id': 'GPL-2.0-with-font-exception', 'deprecated': True},
    'gpl-2.0-with-gcc-exception': {'id': 'GPL-2.0-with-GCC-exception', 'deprecated': True},
    'gpl-3.0': {'id': 'GPL-3.0', 'deprecated': True},
    'gpl-3.0+': {'id': 'GPL-3.0+', 'deprecated': True},
    'gpl-3.0-only': {'id': 'GPL-3.0-only', 'deprecated': False},
    'gpl-3.0-or-later': {'id': 'GPL-3.0-or-later', 'deprecated': False},
    'gpl-3.0-with-autoconf-exception': {'id': 'GPL-3.0-with-autoconf-exception', 'deprecated': True},
    'gpl-3.0-with-gcc-exception': {'id': 'GPL-3.0-with-GCC-exception', 'deprecated': True},
    'graphics-gems': {'id': 'Graphics-Gems', 'deprecated': False},
    'gsoap-1.3b': {'id': 'gSOAP-1.3b', 'deprecated': False},
    'gtkbook': {'id': 'gtkbook', 'deprecated': False},
    'gutmann': {'id': 'Gutmann', 'deprecated': False},
    'haskellreport': {'id': 'HaskellReport', 'deprecated': False},
    'hdparm': {'id': 'hdparm', 'deprecated': False},
    'hidapi': {'id': 'HIDAPI', 'deprecated': False},
    'hippocratic-2.1': {'id': 'Hippocratic-2.1', 'deprecated': False},
    'hp-1986': {'id': 'HP-1986', 'deprecated': False},
    'hp-1989': {'id': 'HP-1989', 'deprecated': False},
    'hpnd': {'id': 'HPND', 'deprecated': False},
    'hpnd-dec': {'id': 'HPND-DEC', 'deprecated': False},
    'hpnd-doc': {'id': 'HPND-doc', 'deprecated': False},
    'hpnd-doc-sell': {'id': 'HPND-doc-sell', 'deprecated': False},
    'hpnd-export-us': {'id': 'HPND-export-US', 'deprecated': False},
    'hpnd-export-us-acknowledgement': {'id': 'HPND-export-US-acknowledgement', 'deprecated': False},
    'hpnd-export-us-modify': {'id': 'HPND-export-US-modify', 'deprecated': False},
    'hpnd-export2-us': {'id': 'HPND-export2-US', 'deprecated': False},
    'hpnd-fenneberg-livingston': {'id': 'HPND-Fenneberg-Livingston', 'deprecated': False},
    'hpnd-inria-imag': {'id': 'HPND-INRIA-IMAG', 'deprecated': False},
    'hpnd-intel': {'id': 'HPND-Intel', 'deprecated': False},
    'hpnd-kevlin-henney': {'id': 'HPND-Kevlin-Henney', 'deprecated': False},
    'hpnd-markus-kuhn': {'id': 'HPND-Markus-Kuhn', 'deprecated': False},
    'hpnd-merchantability-variant': {'id': 'HPND-merchantability-variant', 'deprecated': False},
    'hpnd-mit-disclaimer': {'id': 'HPND-MIT-disclaimer', 'deprecated': False},
    'hpnd-netrek': {'id': 'HPND-Netrek', 'deprecated': False},
    'hpnd-pbmplus': {'id': 'HPND-Pbmplus', 'deprecated': False},
    'hpnd-sell-mit-disclaimer-xserver': {'id': 'HPND-sell-MIT-disclaimer-xserver', 'deprecated': False},
    'hpnd-sell-regexpr': {'id': 'HPND-sell-regexpr', 'deprecated': False},
    'hpnd-sell-variant': {'id': 'HPND-sell-variant', 'deprecated': False},
    'hpnd-sell-variant-mit-disclaimer': {'id': 'HPND-sell-variant-MIT-disclaimer', 'deprecated': False},
    'hpnd-sell-variant-mit-disclaimer-rev': {'id': 'HPND-sell-variant-MIT-disclaimer-rev', 'deprecated': False},
    'hpnd-uc': {'id': 'HPND-UC', 'deprecated': False},
    'hpnd-uc-export-us': {'id': 'HPND-UC-export-US', 'deprecated': False},
    'htmltidy': {'id': 'HTMLTIDY', 'deprecated': False},
    'ibm-pibs': {'id': 'IBM-pibs', 'deprecated': False},
    'icu': {'id': 'ICU', 'deprecated': False},
    'iec-code-components-eula': {'id': 'IEC-Code-Components-EULA', 'deprecated': False},
    'ijg': {'id': 'IJG', 'deprecated': False},
    'ijg-short': {'id': 'IJG-short', 'deprecated': False},
    'imagemagick': {'id': 'ImageMagick', 'deprecated': False},
    'imatix': {'id': 'iMatix', 'deprecated': False},
    'imlib2': {'id': 'Imlib2', 'deprecated': False},
    'info-zip': {'id': 'Info-ZIP', 'deprecated': False},
    'inner-net-2.0': {'id': 'Inner-Net-2.0', 'deprecated': False},
    'intel': {'id': 'Intel', 'deprecated': False},
    'intel-acpi': {'id': 'Intel-ACPI', 'deprecated': False},
    'interbase-1.0': {'id': 'Interbase-1.0', 'deprecated': False},
    'ipa': {'id': 'IPA', 'deprecated': False},
    'ipl-1.0': {'id': 'IPL-1.0', 'deprecated': False},
    'isc': {'id': 'ISC', 'deprecated': False},
    'isc-veillard': {'id': 'ISC-Veillard', 'deprecated': False},
    'jam': {'id': 'Jam', 'deprecated': False},
    'jasper-2.0': {'id': 'JasPer-2.0', 'deprecated': False},
    'jpl-image': {'id': 'JPL-image', 'deprecated': False},
    'jpnic': {'id': 'JPNIC', 'deprecated': False},
    'json': {'id': 'JSON', 'deprecated': False},
    'kastrup': {'id': 'Kastrup', 'deprecated': False},
    'kazlib': {'id': 'Kazlib', 'deprecated': False},
    'knuth-ctan': {'id': 'Knuth-CTAN', 'deprecated': False},
    'lal-1.2': {'id': 'LAL-1.2', 'deprecated': False},
    'lal-1.3': {'id': 'LAL-1.3', 'deprecated': False},
    'latex2e': {'id': 'Latex2e', 'deprecated': False},
    'latex2e-translated-notice': {'id': 'Latex2e-translated-notice', 'deprecated': False},
    'leptonica': {'id': 'Leptonica', 'deprecated': False},
    'lgpl-2.0': {'id': 'LGPL-2.0', 'deprecated': True},
    'lgpl-2.0+': {'id': 'LGPL-2.0+', 'deprecated': True},
    'lgpl-2.0-only': {'id': 'LGPL-2.0-only', 'deprecated': False},
    'lgpl-2.0-or-later': {'id': 'LGPL-2.0-or-later', 'deprecated': False},
    'lgpl-2.1': {'id': 'LGPL-2.1', 'deprecated': True},
    'lgpl-2.1+': {'id': 'LGPL-2.1+', 'deprecated': True},
    'lgpl-2.1-only': {'id': 'LGPL-2.1-only', 'deprecated': False},
    'lgpl-2.1-or-later': {'id': 'LGPL-2.1-or-later', 'deprecated': False},
    'lgpl-3.0': {'id': 'LGPL-3.0', 'deprecated': True},
    'lgpl-3.0+': {'id': 'LGPL-3.0+', 'deprecated': True},
    'lgpl-3.0-only': {'id': 'LGPL-3.0-only', 'deprecated': False},
    'lgpl-3.0-or-later': {'id': 'LGPL-3.0-or-later', 'deprecated': False},
    'lgpllr': {'id': 'LGPLLR', 'deprecated': False},
    'libpng': {'id': 'Libpng', 'deprecated': False},
    'libpng-2.0': {'id': 'libpng-2.0', 'deprecated': False},
    'libselinux-1.0': {'id': 'libselinux-1.0', 'deprecated': False},
    'libtiff': {'id': 'libtiff', 'deprecated': False},
    'libutil-david-nugent': {'id': 'libutil-David-Nugent', 'deprecated': False},
    'liliq-p-1.1': {'id': 'LiLiQ-P-1.1', 'deprecated': False},
    'liliq-r-1.1': {'id': 'LiLiQ-R-1.1', 'deprecated': False},
    'liliq-rplus-1.1': {'id': 'LiLiQ-Rplus-1.1', 'deprecated': False},
    'linux-man-pages-1-para': {'id': 'Linux-man-pages-1-para', 'deprecated': False},
    'linux-man-pages-copyleft': {'id': 'Linux-man-pages-copyleft', 'deprecated': False},
    'linux-man-pages-copyleft-2-para': {'id': 'Linux-man-pages-copyleft-2-para', 'deprecated': False},
    'linux-man-pages-copyleft-var': {'id': 'Linux-man-pages-copyleft-var', 'deprecated': False},
    'linux-openib': {'id': 'Linux-OpenIB', 'deprecated': False},
    'loop': {'id': 'LOOP', 'deprecated': False},
    'lpd-document': {'id': 'LPD-document', 'deprecated': False},
    'lpl-1.0': {'id': 'LPL-1.0', 'deprecated': False},
    'lpl-1.02': {'id': 'LPL-1.02', 'deprecated': False},
    'lppl-1.0': {'id': 'LPPL-1.0', 'deprecated': False},
    'lppl-1.1': {'id': 'LPPL-1.1', 'deprecated': False},
    'lppl-1.2': {'id': 'LPPL-1.2', 'deprecated': False},
    'lppl-1.3a': {'id': 'LPPL-1.3a', 'deprecated': False},
    'lppl-1.3c': {'id': 'LPPL-1.3c', 'deprecated': False},
    'lsof': {'id': 'lsof', 'deprecated': False},
    'lucida-bitmap-fonts': {'id': 'Lucida-Bitmap-Fonts', 'deprecated': False},
    'lzma-sdk-9.11-to-9.20': {'id': 'LZMA-SDK-9.11-to-9.20', 'deprecated': False},
    'lzma-sdk-9.22': {'id': 'LZMA-SDK-9.22', 'deprecated': False},
    'mackerras-3-clause': {'id': 'Mackerras-3-Clause', 'deprecated': False},
    'mackerras-3-clause-acknowledgment': {'id': 'Mackerras-3-Clause-acknowledgment', 'deprecated': False},
    'magaz': {'id': 'magaz', 'deprecated': False},
    'mailprio': {'id': 'mailprio', 'deprecated': False},
    'makeindex': {'id': 'MakeIndex', 'deprecated': False},
    'martin-birgmeier': {'id': 'Martin-Birgmeier', 'deprecated': False},
    'mcphee-slideshow': {'id': 'McPhee-slideshow', 'deprecated': False},
    'metamail': {'id': 'metamail', 'deprecated': False},
    'minpack': {'id': 'Minpack', 'deprecated': False},
    'miros': {'id': 'MirOS', 'deprecated': False},
    'mit': {'id': 'MIT', 'deprecated': False},
    'mit-0': {'id': 'MIT-0', 'deprecated': False},
    'mit-advertising': {'id': 'MIT-advertising', 'deprecated': False},
    'mit-cmu': {'id': 'MIT-CMU', 'deprecated': False},
    'mit-enna': {'id': 'MIT-enna', 'deprecated': False},
    'mit-feh': {'id': 'MIT-feh', 'deprecated': False},
    'mit-festival': {'id': 'MIT-Festival', 'deprecated': False},
    'mit-khronos-old': {'id': 'MIT-Khronos-old', 'deprecated': False},
    'mit-modern-variant': {'id': 'MIT-Modern-Variant', 'deprecated': False},
    'mit-open-group': {'id': 'MIT-open-group', 'deprecated': False},
    'mit-testregex': {'id': 'MIT-testregex', 'deprecated': False},
    'mit-wu': {'id': 'MIT-Wu', 'deprecated': False},
    'mitnfa': {'id': 'MITNFA', 'deprecated': False},
    'mmixware': {'id': 'MMIXware', 'deprecated': False},
    'motosoto': {'id': 'Motosoto', 'deprecated': False},
    'mpeg-ssg': {'id': 'MPEG-SSG', 'deprecated': False},
    'mpi-permissive': {'id': 'mpi-permissive', 'deprecated': False},
    'mpich2': {'id': 'mpich2', 'deprecated': False},
    'mpl-1.0': {'id': 'MPL-1.0', 'deprecated': False},
    'mpl-1.1': {'id': 'MPL-1.1', 'deprecated': False},
    'mpl-2.0': {'id': 'MPL-2.0', 'deprecated': False},
    'mpl-2.0-no-copyleft-exception': {'id': 'MPL-2.0-no-copyleft-exception', 'deprecated': False},
    'mplus': {'id': 'mplus', 'deprecated': False},
    'ms-lpl': {'id': 'MS-LPL', 'deprecated': False},
    'ms-pl': {'id': 'MS-PL', 'deprecated': False},
    'ms-rl': {'id': 'MS-RL', 'deprecated': False},
    'mtll': {'id': 'MTLL', 'deprecated': False},
    'mulanpsl-1.0': {'id': 'MulanPSL-1.0', 'deprecated': False},
    'mulanpsl-2.0': {'id': 'MulanPSL-2.0', 'deprecated': False},
    'multics': {'id': 'Multics', 'deprecated': False},
    'mup': {'id': 'Mup', 'deprecated': False},
    'naist-2003': {'id': 'NAIST-2003', 'deprecated': False},
    'nasa-1.3': {'id': 'NASA-1.3', 'deprecated': False},
    'naumen': {'id': 'Naumen', 'deprecated': False},
    'nbpl-1.0': {'id': 'NBPL-1.0', 'deprecated': False},
    'ncbi-pd': {'id': 'NCBI-PD', 'deprecated': False},
    'ncgl-uk-2.0': {'id': 'NCGL-UK-2.0', 'deprecated': False},
    'ncl': {'id': 'NCL', 'deprecated': False},
    'ncsa': {'id': 'NCSA', 'deprecated': False},
    'net-snmp': {'id': 'Net-SNMP', 'deprecated': True},
    'netcdf': {'id': 'NetCDF', 'deprecated': False},
    'newsletr': {'id': 'Newsletr', 'deprecated': False},
    'ngpl': {'id': 'NGPL', 'deprecated': False},
    'nicta-1.0': {'id': 'NICTA-1.0', 'deprecated': False},
    'nist-pd': {'id': 'NIST-PD', 'deprecated': False},
    'nist-pd-fallback': {'id': 'NIST-PD-fallback', 'deprecated': False},
    'nist-software': {'id': 'NIST-Software', 'deprecated': False},
    'nlod-1.0': {'id': 'NLOD-1.0', 'deprecated': False},
    'nlod-2.0': {'id': 'NLOD-2.0', 'deprecated': False},
    'nlpl': {'id': 'NLPL', 'deprecated': False},
    'nokia': {'id': 'Nokia', 'deprecated': False},
    'nosl': {'id': 'NOSL', 'deprecated': False},
    'noweb': {'id': 'Noweb', 'deprecated': False},
    'npl-1.0': {'id': 'NPL-1.0', 'deprecated': False},
    'npl-1.1': {'id': 'NPL-1.1', 'deprecated': False},
    'nposl-3.0': {'id': 'NPOSL-3.0', 'deprecated': False},
    'nrl': {'id': 'NRL', 'deprecated': False},
    'ntp': {'id': 'NTP', 'deprecated': False},
    'ntp-0': {'id': 'NTP-0', 'deprecated': False},
    'nunit': {'id': 'Nunit', 'deprecated': True},
    'o-uda-1.0': {'id': 'O-UDA-1.0', 'deprecated': False},
    'oar': {'id': 'OAR', 'deprecated': False},
    'occt-pl': {'id': 'OCCT-PL', 'deprecated': False},
    'oclc-2.0': {'id': 'OCLC-2.0', 'deprecated': False},
    'odbl-1.0': {'id': 'ODbL-1.0', 'deprecated': False},
    'odc-by-1.0': {'id': 'ODC-By-1.0', 'deprecated': False},
    'offis': {'id': 'OFFIS', 'deprecated': False},
    'ofl-1.0': {'id': 'OFL-1.0', 'deprecated': False},
    'ofl-1.0-no-rfn': {'id': 'OFL-1.0-no-RFN', 'deprecated': False},
    'ofl-1.0-rfn': {'id': 'OFL-1.0-RFN', 'deprecated': False},
    'ofl-1.1': {'id': 'OFL-1.1', 'deprecated': False},
    'ofl-1.1-no-rfn': {'id': 'OFL-1.1-no-RFN', 'deprecated': False},
    'ofl-1.1-rfn': {'id': 'OFL-1.1-RFN', 'deprecated': False},
    'ogc-1.0': {'id': 'OGC-1.0', 'deprecated': False},
    'ogdl-taiwan-1.0': {'id': 'OGDL-Taiwan-1.0', 'deprecated': False},
    'ogl-canada-2.0': {'id': 'OGL-Canada-2.0', 'deprecated': False},
    'ogl-uk-1.0': {'id': 'OGL-UK-1.0', 'deprecated': False},
    'ogl-uk-2.0': {'id': 'OGL-UK-2.0', 'deprecated': False},
    'ogl-uk-3.0': {'id': 'OGL-UK-3.0', 'deprecated': False},
    'ogtsl': {'id': 'OGTSL', 'deprecated': False},
    'oldap-1.1': {'id': 'OLDAP-1.1', 'deprecated': False},
    'oldap-1.2': {'id': 'OLDAP-1.2', 'deprecated': False},
    'oldap-1.3': {'id': 'OLDAP-1.3', 'deprecated': False},
    'oldap-1.4': {'id': 'OLDAP-1.4', 'deprecated': False},
    'oldap-2.0': {'id': 'OLDAP-2.0', 'deprecated': False},
    'oldap-2.0.1': {'id': 'OLDAP-2.0.1', 'deprecated': False},
    'oldap-2.1': {'id': 'OLDAP-2.1', 'deprecated': False},
    'oldap-2.2': {'id': 'OLDAP-2.2', 'deprecated': False},
    'oldap-2.2.1': {'id': 'OLDAP-2.2.1', 'deprecated': False},
    'oldap-2.2.2': {'id': 'OLDAP-2.2.2', 'deprecated': False},
    'oldap-2.3': {'id': 'OLDAP-2.3', 'deprecated': False},
    'oldap-2.4': {'id': 'OLDAP-2.4', 'deprecated': False},
    'oldap-2.5': {'id': 'OLDAP-2.5', 'deprecated': False},
    'oldap-2.6': {'id': 'OLDAP-2.6', 'deprecated': False},
    'oldap-2.7': {'id': 'OLDAP-2.7', 'deprecated': False},
    'oldap-2.8': {'id': 'OLDAP-2.8', 'deprecated': False},
    'olfl-1.3': {'id': 'OLFL-1.3', 'deprecated': False},
    'oml': {'id': 'OML', 'deprecated': False},
    'openpbs-2.3': {'id': 'OpenPBS-2.3', 'deprecated': False},
    'openssl': {'id': 'OpenSSL', 'deprecated': False},
    'openssl-standalone': {'id': 'OpenSSL-standalone', 'deprecated': False},
    'openvision': {'id': 'OpenVision', 'deprecated': False},
    'opl-1.0': {'id': 'OPL-1.0', 'deprecated': False},
    'opl-uk-3.0': {'id': 'OPL-UK-3.0', 'deprecated': False},
    'opubl-1.0': {'id': 'OPUBL-1.0', 'deprecated': False},
    'oset-pl-2.1': {'id': 'OSET-PL-2.1', 'deprecated': False},
    'osl-1.0': {'id': 'OSL-1.0', 'deprecated': False},
    'osl-1.1': {'id': 'OSL-1.1', 'deprecated': False},
    'osl-2.0': {'id': 'OSL-2.0', 'deprecated': False},
    'osl-2.1': {'id': 'OSL-2.1', 'deprecated': False},
    'osl-3.0': {'id': 'OSL-3.0', 'deprecated': False},
    'padl': {'id': 'PADL', 'deprecated': False},
    'parity-6.0.0': {'id': 'Parity-6.0.0', 'deprecated': False},
    'parity-7.0.0': {'id': 'Parity-7.0.0', 'deprecated': False},
    'pddl-1.0': {'id': 'PDDL-1.0', 'deprecated': False},
    'php-3.0': {'id': 'PHP-3.0', 'deprecated': False},
    'php-3.01': {'id': 'PHP-3.01', 'deprecated': False},
    'pixar': {'id': 'Pixar', 'deprecated': False},
    'pkgconf': {'id': 'pkgconf', 'deprecated': False},
    'plexus': {'id': 'Plexus', 'deprecated': False},
    'pnmstitch': {'id': 'pnmstitch', 'deprecated': False},
    'polyform-noncommercial-1.0.0': {'id': 'PolyForm-Noncommercial-1.0.0', 'deprecated': False},
    'polyform-small-business-1.0.0': {'id': 'PolyForm-Small-Business-1.0.0', 'deprecated': False},
    'postgresql': {'id': 'PostgreSQL', 'deprecated': False},
    'ppl': {'id': 'PPL', 'deprecated': False},
    'psf-2.0': {'id': 'PSF-2.0', 'deprecated': False},
    'psfrag': {'id': 'psfrag', 'deprecated': False},
    'psutils': {'id': 'psutils', 'deprecated': False},
    'python-2.0': {'id': 'Python-2.0', 'deprecated': False},
    'python-2.0.1': {'id': 'Python-2.0.1', 'deprecated': False},
    'python-ldap': {'id': 'python-ldap', 'deprecated': False},
    'qhull': {'id': 'Qhull', 'deprecated': False},
    'qpl-1.0': {'id': 'QPL-1.0', 'deprecated': False},
    'qpl-1.0-inria-2004': {'id': 'QPL-1.0-INRIA-2004', 'deprecated': False},
    'radvd': {'id': 'radvd', 'deprecated': False},
    'rdisc': {'id': 'Rdisc', 'deprecated': False},
    'rhecos-1.1': {'id': 'RHeCos-1.1', 'deprecated': False},
    'rpl-1.1': {'id': 'RPL-1.1', 'deprecated': False},
    'rpl-1.5': {'id': 'RPL-1.5', 'deprecated': False},
    'rpsl-1.0': {'id': 'RPSL-1.0', 'deprecated': False},
    'rsa-md': {'id': 'RSA-MD', 'deprecated': False},
    'rscpl': {'id': 'RSCPL', 'deprecated': False},
    'ruby': {'id': 'Ruby', 'deprecated': False},
    'ruby-pty': {'id': 'Ruby-pty', 'deprecated': False},
    'sax-pd': {'id': 'SAX-PD', 'deprecated': False},
    'sax-pd-2.0': {'id': 'SAX-PD-2.0', 'deprecated': False},
    'saxpath': {'id': 'Saxpath', 'deprecated': False},
    'scea': {'id': 'SCEA', 'deprecated': False},
    'schemereport': {'id': 'SchemeReport', 'deprecated': False},
    'sendmail': {'id': 'Sendmail', 'deprecated': False},
    'sendmail-8.23': {'id': 'Sendmail-8.23', 'deprecated': False},
    'sgi-b-1.0': {'id': 'SGI-B-1.0', 'deprecated': False},
    'sgi-b-1.1': {'id': 'SGI-B-1.1', 'deprecated': False},
    'sgi-b-2.0': {'id': 'SGI-B-2.0', 'deprecated': False},
    'sgi-opengl': {'id': 'SGI-OpenGL', 'deprecated': False},
    'sgp4': {'id': 'SGP4', 'deprecated': False},
    'shl-0.5': {'id': 'SHL-0.5', 'deprecated': False},
    'shl-0.51': {'id': 'SHL-0.51', 'deprecated': False},
    'simpl-2.0': {'id': 'SimPL-2.0', 'deprecated': False},
    'sissl': {'id': 'SISSL', 'deprecated': False},
    'sissl-1.2': {'id': 'SISSL-1.2', 'deprecated': False},
    'sl': {'id': 'SL', 'deprecated': False},
    'sleepycat': {'id': 'Sleepycat', 'deprecated': False},
    'smlnj': {'id': 'SMLNJ', 'deprecated': False},
    'smppl': {'id': 'SMPPL', 'deprecated': False},
    'snia': {'id': 'SNIA', 'deprecated': False},
    'snprintf': {'id': 'snprintf', 'deprecated': False},
    'softsurfer': {'id': 'softSurfer', 'deprecated': False},
    'soundex': {'id': 'Soundex', 'deprecated': False},
    'spencer-86': {'id': 'Spencer-86', 'deprecated': False},
    'spencer-94': {'id': 'Spencer-94', 'deprecated': False},
    'spencer-99': {'id': 'Spencer-99', 'deprecated': False},
    'spl-1.0': {'id': 'SPL-1.0', 'deprecated': False},
    'ssh-keyscan': {'id': 'ssh-keyscan', 'deprecated': False},
    'ssh-openssh': {'id': 'SSH-OpenSSH', 'deprecated': False},
    'ssh-short': {'id': 'SSH-short', 'deprecated': False},
    'ssleay-standalone': {'id': 'SSLeay-standalone', 'deprecated': False},
    'sspl-1.0': {'id': 'SSPL-1.0', 'deprecated': False},
    'standardml-nj': {'id': 'StandardML-NJ', 'deprecated': True},
    'sugarcrm-1.1.3': {'id': 'SugarCRM-1.1.3', 'deprecated': False},
    'sun-ppp': {'id': 'Sun-PPP', 'deprecated': False},
    'sun-ppp-2000': {'id': 'Sun-PPP-2000', 'deprecated': False},
    'sunpro': {'id': 'SunPro', 'deprecated': False},
    'swl': {'id': 'SWL', 'deprecated': False},
    'swrule': {'id': 'swrule', 'deprecated': False},
    'symlinks': {'id': 'Symlinks', 'deprecated': False},
    'tapr-ohl-1.0': {'id': 'TAPR-OHL-1.0', 'deprecated': False},
    'tcl': {'id': 'TCL', 'deprecated': False},
    'tcp-wrappers': {'id': 'TCP-wrappers', 'deprecated': False},
    'termreadkey': {'id': 'TermReadKey', 'deprecated': False},
    'tgppl-1.0': {'id': 'TGPPL-1.0', 'deprecated': False},
    'threeparttable': {'id': 'threeparttable', 'deprecated': False},
    'tmate': {'id': 'TMate', 'deprecated': False},
    'torque-1.1': {'id': 'TORQUE-1.1', 'deprecated': False},
    'tosl': {'id': 'TOSL', 'deprecated': False},
    'tpdl': {'id': 'TPDL', 'deprecated': False},
    'tpl-1.0': {'id': 'TPL-1.0', 'deprecated': False},
    'ttwl': {'id': 'TTWL', 'deprecated': False},
    'ttyp0': {'id': 'TTYP0', 'deprecated': False},
    'tu-berlin-1.0': {'id': 'TU-Berlin-1.0', 'deprecated': False},
    'tu-berlin-2.0': {'id': 'TU-Berlin-2.0', 'deprecated': False},
    'ubuntu-font-1.0': {'id': 'Ubuntu-font-1.0', 'deprecated': False},
    'ucar': {'id': 'UCAR', 'deprecated': False},
    'ucl-1.0': {'id': 'UCL-1.0', 'deprecated': False},
    'ulem': {'id': 'ulem', 'deprecated': False},
    'umich-merit': {'id': 'UMich-Merit', 'deprecated': False},
    'unicode-3.0': {'id': 'Unicode-3.0', 'deprecated': False},
    'unicode-dfs-2015': {'id': 'Unicode-DFS-2015', 'deprecated': False},
    'unicode-dfs-2016': {'id': 'Unicode-DFS-2016', 'deprecated': False},
    'unicode-tou': {'id': 'Unicode-TOU', 'deprecated': False},
    'unixcrypt': {'id': 'UnixCrypt', 'deprecated': False},
    'unlicense': {'id': 'Unlicense', 'deprecated': False},
    'upl-1.0': {'id': 'UPL-1.0', 'deprecated': False},
    'urt-rle': {'id': 'URT-RLE', 'deprecated': False},
    'vim': {'id': 'Vim', 'deprecated': False},
    'vostrom': {'id': 'VOSTROM', 'deprecated': False},
    'vsl-1.0': {'id': 'VSL-1.0', 'deprecated': False},
    'w3c': {'id': 'W3C', 'deprecated': False},
    'w3c-19980720': {'id': 'W3C-19980720', 'deprecated': False},
    'w3c-20150513': {'id': 'W3C-20150513', 'deprecated': False},
    'w3m': {'id': 'w3m', 'deprecated': False},
    'watcom-1.0': {'id': 'Watcom-1.0', 'deprecated': False},
    'widget-workshop': {'id': 'Widget-Workshop', 'deprecated': False},
    'wsuipa': {'id': 'Wsuipa', 'deprecated': False},
    'wtfpl': {'id': 'WTFPL', 'deprecated': False},
    'wxwindows': {'id': 'wxWindows', 'deprecated': True},
    'x11': {'id': 'X11', 'deprecated': False},
    'x11-distribute-modifications-variant': {'id': 'X11-distribute-modifications-variant', 'deprecated': False},
    'x11-swapped': {'id': 'X11-swapped', 'deprecated': False},
    'xdebug-1.03': {'id': 'Xdebug-1.03', 'deprecated': False},
    'xerox': {'id': 'Xerox', 'deprecated': False},
    'xfig': {'id': 'Xfig', 'deprecated': False},
    'xfree86-1.1': {'id': 'XFree86-1.1', 'deprecated': False},
    'xinetd': {'id': 'xinetd', 'deprecated': False},
    'xkeyboard-config-zinoviev': {'id': 'xkeyboard-config-Zinoviev', 'deprecated': False},
    'xlock': {'id': 'xlock', 'deprecated': False},
    'xnet': {'id': 'Xnet', 'deprecated': False},
    'xpp': {'id': 'xpp', 'deprecated': False},
    'xskat': {'id': 'XSkat', 'deprecated': False},
    'xzoom': {'id': 'xzoom', 'deprecated': False},
    'ypl-1.0': {'id': 'YPL-1.0', 'deprecated': False},
    'ypl-1.1': {'id': 'YPL-1.1', 'deprecated': False},
    'zed': {'id': 'Zed', 'deprecated': False},
    'zeeff': {'id': 'Zeeff', 'deprecated': False},
    'zend-2.0': {'id': 'Zend-2.0', 'deprecated': False},
    'zimbra-1.3': {'id': 'Zimbra-1.3', 'deprecated': False},
    'zimbra-1.4': {'id': 'Zimbra-1.4', 'deprecated': False},
    'zlib': {'id': 'Zlib', 'deprecated': False},
    'zlib-acknowledgement': {'id': 'zlib-acknowledgement', 'deprecated': False},
    'zpl-1.1': {'id': 'ZPL-1.1', 'deprecated': False},
    'zpl-2.0': {'id': 'ZPL-2.0', 'deprecated': False},
    'zpl-2.1': {'id': 'ZPL-2.1', 'deprecated': False},
}

EXCEPTIONS: dict[str, SPDXException] = {
    '389-exception': {'id': '389-exception', 'deprecated': False},
    'asterisk-exception': {'id': 'Asterisk-exception', 'deprecated': False},
    'asterisk-linking-protocols-exception': {'id': 'Asterisk-linking-protocols-exception', 'deprecated': False},
    'autoconf-exception-2.0': {'id': 'Autoconf-exception-2.0', 'deprecated': False},
    'autoconf-exception-3.0': {'id': 'Autoconf-exception-3.0', 'deprecated': False},
    'autoconf-exception-generic': {'id': 'Autoconf-exception-generic', 'deprecated': False},
    'autoconf-exception-generic-3.0': {'id': 'Autoconf-exception-generic-3.0', 'deprecated': False},
    'autoconf-exception-macro': {'id': 'Autoconf-exception-macro', 'deprecated': False},
    'bison-exception-1.24': {'id': 'Bison-exception-1.24', 'deprecated': False},
    'bison-exception-2.2': {'id': 'Bison-exception-2.2', 'deprecated': False},
    'bootloader-exception': {'id': 'Bootloader-exception', 'deprecated': False},
    'classpath-exception-2.0': {'id': 'Classpath-exception-2.0', 'deprecated': False},
    'clisp-exception-2.0': {'id': 'CLISP-exception-2.0', 'deprecated': False},
    'cryptsetup-openssl-exception': {'id': 'cryptsetup-OpenSSL-exception', 'deprecated': False},
    'digirule-foss-exception': {'id': 'DigiRule-FOSS-exception', 'deprecated': False},
    'ecos-exception-2.0': {'id': 'eCos-exception-2.0', 'deprecated': False},
    'erlang-otp-linking-exception': {'id': 'erlang-otp-linking-exception', 'deprecated': False},
    'fawkes-runtime-exception': {'id': 'Fawkes-Runtime-exception', 'deprecated': False},
    'fltk-exception': {'id': 'FLTK-exception', 'deprecated': False},
    'fmt-exception': {'id': 'fmt-exception', 'deprecated': False},
    'font-exception-2.0': {'id': 'Font-exception-2.0', 'deprecated': False},
    'freertos-exception-2.0': {'id': 'freertos-exception-2.0', 'deprecated': False},
    'gcc-exception-2.0': {'id': 'GCC-exception-2.0', 'deprecated': False},
    'gcc-exception-2.0-note': {'id': 'GCC-exception-2.0-note', 'deprecated': False},
    'gcc-exception-3.1': {'id': 'GCC-exception-3.1', 'deprecated': False},
    'gmsh-exception': {'id': 'Gmsh-exception', 'deprecated': False},
    'gnat-exception': {'id': 'GNAT-exception', 'deprecated': False},
    'gnome-examples-exception': {'id': 'GNOME-examples-exception', 'deprecated': False},
    'gnu-compiler-exception': {'id': 'GNU-compiler-exception', 'deprecated': False},
    'gnu-javamail-exception': {'id': 'gnu-javamail-exception', 'deprecated': False},
    'gpl-3.0-interface-exception': {'id': 'GPL-3.0-interface-exception', 'deprecated': False},
    'gpl-3.0-linking-exception': {'id': 'GPL-3.0-linking-exception', 'deprecated': False},
    'gpl-3.0-linking-source-exception': {'id': 'GPL-3.0-linking-source-exception', 'deprecated': False},
    'gpl-cc-1.0': {'id': 'GPL-CC-1.0', 'deprecated': False},
    'gstreamer-exception-2005': {'id': 'GStreamer-exception-2005', 'deprecated': False},
    'gstreamer-exception-2008': {'id': 'GStreamer-exception-2008', 'deprecated': False},
    'i2p-gpl-java-exception': {'id': 'i2p-gpl-java-exception', 'deprecated': False},
    'kicad-libraries-exception': {'id': 'KiCad-libraries-exception', 'deprecated': False},
    'lgpl-3.0-linking-exception': {'id': 'LGPL-3.0-linking-exception', 'deprecated': False},
    'libpri-openh323-exception': {'id': 'libpri-OpenH323-exception', 'deprecated': False},
    'libtool-exception': {'id': 'Libtool-exception', 'deprecated': False},
    'linux-syscall-note': {'id': 'Linux-syscall-note', 'deprecated': False},
    'llgpl': {'id': 'LLGPL', 'deprecated': False},
    'llvm-exception': {'id': 'LLVM-exception', 'deprecated': False},
    'lzma-exception': {'id': 'LZMA-exception', 'deprecated': False},
    'mif-exception': {'id': 'mif-exception', 'deprecated': False},
    'nokia-qt-exception-1.1': {'id': 'Nokia-Qt-exception-1.1', 'deprecated': True},
    'ocaml-lgpl-linking-exception': {'id': 'OCaml-LGPL-linking-exception', 'deprecated': False},
    'occt-exception-1.0': {'id': 'OCCT-exception-1.0', 'deprecated': False},
    'openjdk-assembly-exception-1.0': {'id': 'OpenJDK-assembly-exception-1.0', 'deprecated': False},
    'openvpn-openssl-exception': {'id': 'openvpn-openssl-exception', 'deprecated': False},
    'pcre2-exception': {'id': 'PCRE2-exception', 'deprecated': False},
    'ps-or-pdf-font-exception-20170817': {'id': 'PS-or-PDF-font-exception-20170817', 'deprecated': False},
    'qpl-1.0-inria-2004-exception': {'id': 'QPL-1.0-INRIA-2004-exception', 'deprecated': False},
    'qt-gpl-exception-1.0': {'id': 'Qt-GPL-exception-1.0', 'deprecated': False},
    'qt-lgpl-exception-1.1': {'id': 'Qt-LGPL-exception-1.1', 'deprecated': False},
    'qwt-exception-1.0': {'id': 'Qwt-exception-1.0', 'deprecated': False},
    'romic-exception': {'id': 'romic-exception', 'deprecated': False},
    'rrdtool-floss-exception-2.0': {'id': 'RRDtool-FLOSS-exception-2.0', 'deprecated': False},
    'sane-exception': {'id': 'SANE-exception', 'deprecated': False},
    'shl-2.0': {'id': 'SHL-2.0', 'deprecated': False},
    'shl-2.1': {'id': 'SHL-2.1', 'deprecated': False},
    'stunnel-exception': {'id': 'stunnel-exception', 'deprecated': False},
    'swi-exception': {'id': 'SWI-exception', 'deprecated': False},
    'swift-exception': {'id': 'Swift-exception', 'deprecated': False},
    'texinfo-exception': {'id': 'Texinfo-exception', 'deprecated': False},
    'u-boot-exception-2.0': {'id': 'u-boot-exception-2.0', 'deprecated': False},
    'ubdl-exception': {'id': 'UBDL-exception', 'deprecated': False},
    'universal-foss-exception-1.0': {'id': 'Universal-FOSS-exception-1.0', 'deprecated': False},
    'vsftpd-openssl-exception': {'id': 'vsftpd-openssl-exception', 'deprecated': False},
    'wxwindows-exception-3.1': {'id': 'WxWindows-exception-3.1', 'deprecated': False},
    'x11vnc-openssl-exception': {'id': 'x11vnc-openssl-exception', 'deprecated': False},
}
































from __future__ import annotations

import re
from typing import NewType, cast

from pip._vendor.packaging.licenses._spdx import EXCEPTIONS, LICENSES

__all__ = [
    ""InvalidLicenseExpression"",
    ""NormalizedLicenseExpression"",
    ""canonicalize_license_expression"",
]

license_ref_allowed = re.compile(""^[A-Za-z0-9.-]*$"")

NormalizedLicenseExpression = NewType(""NormalizedLicenseExpression"", str)


class InvalidLicenseExpression(ValueError):
    


def canonicalize_license_expression(
    raw_license_expression: str,
) -> NormalizedLicenseExpression:
    if not raw_license_expression:
        message = f""Invalid license expression: {raw_license_expression!r}""
        raise InvalidLicenseExpression(message)

    
    
    license_expression = raw_license_expression.replace(""("", "" ( "").replace("")"", "" ) "")
    licenseref_prefix = ""LicenseRef-""
    license_refs = {
        ref.lower(): ""LicenseRef-"" + ref[len(licenseref_prefix) :]
        for ref in license_expression.split()
        if ref.lower().startswith(licenseref_prefix.lower())
    }

    
    
    license_expression = license_expression.lower()

    tokens = license_expression.split()

    
    
    
    python_tokens = []
    for token in tokens:
        if token not in {""or"", ""and"", ""with"", ""("", "")""}:
            python_tokens.append(""False"")
        elif token == ""with"":
            python_tokens.append(""or"")
        elif token == ""("" and python_tokens and python_tokens[-1] not in {""or"", ""and""}:
            message = f""Invalid license expression: {raw_license_expression!r}""
            raise InvalidLicenseExpression(message)
        else:
            python_tokens.append(token)

    python_expression = "" "".join(python_tokens)
    try:
        invalid = eval(python_expression, globals(), locals())
    except Exception:
        invalid = True

    if invalid is not False:
        message = f""Invalid license expression: {raw_license_expression!r}""
        raise InvalidLicenseExpression(message) from None

    
    normalized_tokens = []
    for token in tokens:
        if token in {""or"", ""and"", ""with"", ""("", "")""}:
            normalized_tokens.append(token.upper())
            continue

        if normalized_tokens and normalized_tokens[-1] == ""WITH"":
            if token not in EXCEPTIONS:
                message = f""Unknown license exception: {token!r}""
                raise InvalidLicenseExpression(message)

            normalized_tokens.append(EXCEPTIONS[token][""id""])
        else:
            if token.endswith(""+""):
                final_token = token[:-1]
                suffix = ""+""
            else:
                final_token = token
                suffix = """"

            if final_token.startswith(""licenseref-""):
                if not license_ref_allowed.match(final_token):
                    message = f""Invalid licenseref: {final_token!r}""
                    raise InvalidLicenseExpression(message)
                normalized_tokens.append(license_refs[final_token] + suffix)
            else:
                if final_token not in LICENSES:
                    message = f""Unknown license: {final_token!r}""
                    raise InvalidLicenseExpression(message)
                normalized_tokens.append(LICENSES[final_token][""id""] + suffix)

    normalized_expression = "" "".join(normalized_tokens)

    return cast(
        NormalizedLicenseExpression,
        normalized_expression.replace(""( "", ""("").replace("" )"", "")""),
    )






from __future__ import annotations

import sys

if sys.version_info < (3, 8):  
    raise RuntimeError(""Python 3.8 or later is required"")

import os
import io
import time
import re
import types
from typing import (
    Any,
    Literal,
    Dict,
    Iterator,
    Mapping,
    MutableSequence,
    NamedTuple,
    NoReturn,
    Tuple,
    Union,
    TYPE_CHECKING,
    Protocol,
    Callable,
    Iterable,
    TypeVar,
    overload,
)
import zipfile
import zipimport
import warnings
import stat
import functools
import pkgutil
import operator
import platform
import collections
import plistlib
import email.parser
import errno
import tempfile
import textwrap
import inspect
import ntpath
import posixpath
import importlib
import importlib.abc
import importlib.machinery
from pkgutil import get_importer

import _imp


from os import utime
from os import open as os_open
from os.path import isdir, split

try:
    from os import mkdir, rename, unlink

    WRITE_SUPPORT = True
except ImportError:
    
    WRITE_SUPPORT = False

from pip._internal.utils._jaraco_text import (
    yield_lines,
    drop_comment,
    join_continuation,
)
from pip._vendor.packaging import markers as _packaging_markers
from pip._vendor.packaging import requirements as _packaging_requirements
from pip._vendor.packaging import utils as _packaging_utils
from pip._vendor.packaging import version as _packaging_version
from pip._vendor.platformdirs import user_cache_dir as _user_cache_dir

if TYPE_CHECKING:
    from _typeshed import BytesPath, StrPath, StrOrBytesPath
    from typing_extensions import Self








_T = TypeVar(""_T"")
_DistributionT = TypeVar(""_DistributionT"", bound=""Distribution"")

_NestedStr = Union[str, Iterable[Union[str, Iterable[""_NestedStr""]]]]
_InstallerTypeT = Callable[[""Requirement""], ""_DistributionT""]
_InstallerType = Callable[[""Requirement""], Union[""Distribution"", None]]
_PkgReqType = Union[str, ""Requirement""]
_EPDistType = Union[""Distribution"", _PkgReqType]
_MetadataType = Union[""IResourceProvider"", None]
_ResolvedEntryPoint = Any  
_ResourceStream = Any  

_ModuleLike = Union[object, types.ModuleType]

_ProviderFactoryType = Callable[[Any], ""IResourceProvider""]
_DistFinderType = Callable[[_T, str, bool], Iterable[""Distribution""]]
_NSHandlerType = Callable[[_T, str, str, types.ModuleType], Union[str, None]]
_AdapterT = TypeVar(
    ""_AdapterT"", _DistFinderType[Any], _ProviderFactoryType, _NSHandlerType[Any]
)



class _LoaderProtocol(Protocol):
    def load_module(self, fullname: str, /) -> types.ModuleType: ...


class _ZipLoaderModule(Protocol):
    __loader__: zipimport.zipimporter


_PEP440_FALLBACK = re.compile(r""^v?(?P<safe>(?:[0-9]+!)?[0-9]+(?:\.[0-9]+)*)"", re.I)


class PEP440Warning(RuntimeWarning):
    


parse_version = _packaging_version.Version


_state_vars: dict[str, str] = {}


def _declare_state(vartype: str, varname: str, initial_value: _T) -> _T:
    _state_vars[varname] = vartype
    return initial_value


def __getstate__() -> dict[str, Any]:
    state = {}
    g = globals()
    for k, v in _state_vars.items():
        state[k] = g['_sget_' + v](g[k])
    return state


def __setstate__(state: dict[str, Any]) -> dict[str, Any]:
    g = globals()
    for k, v in state.items():
        g['_sset_' + _state_vars[k]](k, g[k], v)
    return state


def _sget_dict(val):
    return val.copy()


def _sset_dict(key, ob, state):
    ob.clear()
    ob.update(state)


def _sget_object(val):
    return val.__getstate__()


def _sset_object(key, ob, state):
    ob.__setstate__(state)


_sget_none = _sset_none = lambda *args: None


def get_supported_platform():
    
    plat = get_build_platform()
    m = macosVersionString.match(plat)
    if m is not None and sys.platform == ""darwin"":
        try:
            plat = 'macosx-%s-%s' % ('.'.join(_macos_vers()[:2]), m.group(3))
        except ValueError:
            
            pass
    return plat


__all__ = [
    
    'require',
    'run_script',
    'get_provider',
    'get_distribution',
    'load_entry_point',
    'get_entry_map',
    'get_entry_info',
    'iter_entry_points',
    'resource_string',
    'resource_stream',
    'resource_filename',
    'resource_listdir',
    'resource_exists',
    'resource_isdir',
    
    'declare_namespace',
    'working_set',
    'add_activation_listener',
    'find_distributions',
    'set_extraction_path',
    'cleanup_resources',
    'get_default_cache',
    
    'Environment',
    'WorkingSet',
    'ResourceManager',
    'Distribution',
    'Requirement',
    'EntryPoint',
    
    'ResolutionError',
    'VersionConflict',
    'DistributionNotFound',
    'UnknownExtra',
    'ExtractionError',
    
    'PEP440Warning',
    
    'parse_requirements',
    'parse_version',
    'safe_name',
    'safe_version',
    'get_platform',
    'compatible_platforms',
    'yield_lines',
    'split_sections',
    'safe_extra',
    'to_filename',
    'invalid_marker',
    'evaluate_marker',
    
    'ensure_directory',
    'normalize_path',
    
    'EGG_DIST',
    'BINARY_DIST',
    'SOURCE_DIST',
    'CHECKOUT_DIST',
    'DEVELOP_DIST',
    
    'IMetadataProvider',
    'IResourceProvider',
    'FileMetadata',
    'PathMetadata',
    'EggMetadata',
    'EmptyProvider',
    'empty_provider',
    'NullProvider',
    'EggProvider',
    'DefaultProvider',
    'ZipProvider',
    'register_finder',
    'register_namespace_handler',
    'register_loader_type',
    'fixup_namespace_packages',
    'get_importer',
    
    'PkgResourcesDeprecationWarning',
    
    'run_main',
    'AvailableDistributions',
]


class ResolutionError(Exception):
    

    def __repr__(self):
        return self.__class__.__name__ + repr(self.args)


class VersionConflict(ResolutionError):
    

    _template = ""{self.dist} is installed but {self.req} is required""

    @property
    def dist(self) -> Distribution:
        return self.args[0]

    @property
    def req(self) -> Requirement:
        return self.args[1]

    def report(self):
        return self._template.format(**locals())

    def with_context(self, required_by: set[Distribution | str]):
        
        if not required_by:
            return self
        args = self.args + (required_by,)
        return ContextualVersionConflict(*args)


class ContextualVersionConflict(VersionConflict):
    

    _template = VersionConflict._template + ' by {self.required_by}'

    @property
    def required_by(self) -> set[str]:
        return self.args[2]


class DistributionNotFound(ResolutionError):
    

    _template = (
        ""The '{self.req}' distribution was not found ""
        ""and is required by {self.requirers_str}""
    )

    @property
    def req(self) -> Requirement:
        return self.args[0]

    @property
    def requirers(self) -> set[str] | None:
        return self.args[1]

    @property
    def requirers_str(self):
        if not self.requirers:
            return 'the application'
        return ', '.join(self.requirers)

    def report(self):
        return self._template.format(**locals())

    def __str__(self):
        return self.report()


class UnknownExtra(ResolutionError):
    


_provider_factories: dict[type[_ModuleLike], _ProviderFactoryType] = {}

PY_MAJOR = '{}.{}'.format(*sys.version_info)
EGG_DIST = 3
BINARY_DIST = 2
SOURCE_DIST = 1
CHECKOUT_DIST = 0
DEVELOP_DIST = -1


def register_loader_type(
    loader_type: type[_ModuleLike], provider_factory: _ProviderFactoryType
):
    
    _provider_factories[loader_type] = provider_factory


@overload
def get_provider(moduleOrReq: str) -> IResourceProvider: ...
@overload
def get_provider(moduleOrReq: Requirement) -> Distribution: ...
def get_provider(moduleOrReq: str | Requirement) -> IResourceProvider | Distribution:
    
    if isinstance(moduleOrReq, Requirement):
        return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]
    try:
        module = sys.modules[moduleOrReq]
    except KeyError:
        __import__(moduleOrReq)
        module = sys.modules[moduleOrReq]
    loader = getattr(module, '__loader__', None)
    return _find_adapter(_provider_factories, loader)(module)


@functools.lru_cache(maxsize=None)
def _macos_vers():
    version = platform.mac_ver()[0]
    
    if version == '':
        plist = '/System/Library/CoreServices/SystemVersion.plist'
        if os.path.exists(plist):
            with open(plist, 'rb') as fh:
                plist_content = plistlib.load(fh)
            if 'ProductVersion' in plist_content:
                version = plist_content['ProductVersion']
    return version.split('.')


def _macos_arch(machine):
    return {'PowerPC': 'ppc', 'Power_Macintosh': 'ppc'}.get(machine, machine)


def get_build_platform():
    
    from sysconfig import get_platform

    plat = get_platform()
    if sys.platform == ""darwin"" and not plat.startswith('macosx-'):
        try:
            version = _macos_vers()
            machine = os.uname()[4].replace("" "", ""_"")
            return ""macosx-%d.%d-%s"" % (
                int(version[0]),
                int(version[1]),
                _macos_arch(machine),
            )
        except ValueError:
            
            
            pass
    return plat


macosVersionString = re.compile(r""macosx-(\d+)\.(\d+)-(.*)"")
darwinVersionString = re.compile(r""darwin-(\d+)\.(\d+)\.(\d+)-(.*)"")

get_platform = get_build_platform


def compatible_platforms(provided: str | None, required: str | None):
    
    if provided is None or required is None or provided == required:
        
        return True

    
    reqMac = macosVersionString.match(required)
    if reqMac:
        provMac = macosVersionString.match(provided)

        
        if not provMac:
            
            
            
            provDarwin = darwinVersionString.match(provided)
            if provDarwin:
                dversion = int(provDarwin.group(1))
                macosversion = ""%s.%s"" % (reqMac.group(1), reqMac.group(2))
                if (
                    dversion == 7
                    and macosversion >= ""10.3""
                    or dversion == 8
                    and macosversion >= ""10.4""
                ):
                    return True
            
            return False

        
        if provMac.group(1) != reqMac.group(1) or provMac.group(3) != reqMac.group(3):
            return False

        
        if int(provMac.group(2)) > int(reqMac.group(2)):
            return False

        return True

    
    return False


@overload
def get_distribution(dist: _DistributionT) -> _DistributionT: ...
@overload
def get_distribution(dist: _PkgReqType) -> Distribution: ...
def get_distribution(dist: Distribution | _PkgReqType) -> Distribution:
    
    if isinstance(dist, str):
        dist = Requirement.parse(dist)
    if isinstance(dist, Requirement):
        
        dist = get_provider(dist)  
    if not isinstance(dist, Distribution):
        raise TypeError(""Expected str, Requirement, or Distribution"", dist)
    return dist


def load_entry_point(dist: _EPDistType, group: str, name: str) -> _ResolvedEntryPoint:
    
    return get_distribution(dist).load_entry_point(group, name)


@overload
def get_entry_map(
    dist: _EPDistType, group: None = None
) -> dict[str, dict[str, EntryPoint]]: ...
@overload
def get_entry_map(dist: _EPDistType, group: str) -> dict[str, EntryPoint]: ...
def get_entry_map(dist: _EPDistType, group: str | None = None):
    
    return get_distribution(dist).get_entry_map(group)


def get_entry_info(dist: _EPDistType, group: str, name: str):
    
    return get_distribution(dist).get_entry_info(group, name)


class IMetadataProvider(Protocol):
    def has_metadata(self, name: str) -> bool:
        

    def get_metadata(self, name: str) -> str:
        

    def get_metadata_lines(self, name: str) -> Iterator[str]:
        

    def metadata_isdir(self, name: str) -> bool:
        

    def metadata_listdir(self, name: str) -> list[str]:
        

    def run_script(self, script_name: str, namespace: dict[str, Any]) -> None:
        


class IResourceProvider(IMetadataProvider, Protocol):
    

    def get_resource_filename(
        self, manager: ResourceManager, resource_name: str
    ) -> str:
        

    def get_resource_stream(
        self, manager: ResourceManager, resource_name: str
    ) -> _ResourceStream:
        

    def get_resource_string(
        self, manager: ResourceManager, resource_name: str
    ) -> bytes:
        

    def has_resource(self, resource_name: str) -> bool:
        

    def resource_isdir(self, resource_name: str) -> bool:
        

    def resource_listdir(self, resource_name: str) -> list[str]:
        


class WorkingSet:
    

    def __init__(self, entries: Iterable[str] | None = None):
        
        self.entries: list[str] = []
        self.entry_keys = {}
        self.by_key = {}
        self.normalized_to_canonical_keys = {}
        self.callbacks = []

        if entries is None:
            entries = sys.path

        for entry in entries:
            self.add_entry(entry)

    @classmethod
    def _build_master(cls):
        
        ws = cls()
        try:
            from __main__ import __requires__
        except ImportError:
            
            return ws

        
        try:
            ws.require(__requires__)
        except VersionConflict:
            return cls._build_from_requirements(__requires__)

        return ws

    @classmethod
    def _build_from_requirements(cls, req_spec):
        
        
        
        ws = cls([])
        reqs = parse_requirements(req_spec)
        dists = ws.resolve(reqs, Environment())
        for dist in dists:
            ws.add(dist)

        
        for entry in sys.path:
            if entry not in ws.entries:
                ws.add_entry(entry)

        
        sys.path[:] = ws.entries
        return ws

    def add_entry(self, entry: str):
        
        self.entry_keys.setdefault(entry, [])
        self.entries.append(entry)
        for dist in find_distributions(entry, True):
            self.add(dist, entry, False)

    def __contains__(self, dist: Distribution) -> bool:
        
        return self.by_key.get(dist.key) == dist

    def find(self, req: Requirement) -> Distribution | None:
        
        dist = self.by_key.get(req.key)

        if dist is None:
            canonical_key = self.normalized_to_canonical_keys.get(req.key)

            if canonical_key is not None:
                req.key = canonical_key
                dist = self.by_key.get(canonical_key)

        if dist is not None and dist not in req:
            
            raise VersionConflict(dist, req)
        return dist

    def iter_entry_points(self, group: str, name: str | None = None):
        
        return (
            entry
            for dist in self
            for entry in dist.get_entry_map(group).values()
            if name is None or name == entry.name
        )

    def run_script(self, requires: str, script_name: str):
        
        ns = sys._getframe(1).f_globals
        name = ns['__name__']
        ns.clear()
        ns['__name__'] = name
        self.require(requires)[0].run_script(script_name, ns)

    def __iter__(self) -> Iterator[Distribution]:
        
        seen = set()
        for item in self.entries:
            if item not in self.entry_keys:
                
                continue

            for key in self.entry_keys[item]:
                if key not in seen:
                    seen.add(key)
                    yield self.by_key[key]

    def add(
        self,
        dist: Distribution,
        entry: str | None = None,
        insert: bool = True,
        replace: bool = False,
    ):
        
        if insert:
            dist.insert_on(self.entries, entry, replace=replace)

        if entry is None:
            entry = dist.location
        keys = self.entry_keys.setdefault(entry, [])
        keys2 = self.entry_keys.setdefault(dist.location, [])
        if not replace and dist.key in self.by_key:
            
            return

        self.by_key[dist.key] = dist
        normalized_name = _packaging_utils.canonicalize_name(dist.key)
        self.normalized_to_canonical_keys[normalized_name] = dist.key
        if dist.key not in keys:
            keys.append(dist.key)
        if dist.key not in keys2:
            keys2.append(dist.key)
        self._added_new(dist)

    @overload
    def resolve(
        self,
        requirements: Iterable[Requirement],
        env: Environment | None,
        installer: _InstallerTypeT[_DistributionT],
        replace_conflicting: bool = False,
        extras: tuple[str, ...] | None = None,
    ) -> list[_DistributionT]: ...
    @overload
    def resolve(
        self,
        requirements: Iterable[Requirement],
        env: Environment | None = None,
        *,
        installer: _InstallerTypeT[_DistributionT],
        replace_conflicting: bool = False,
        extras: tuple[str, ...] | None = None,
    ) -> list[_DistributionT]: ...
    @overload
    def resolve(
        self,
        requirements: Iterable[Requirement],
        env: Environment | None = None,
        installer: _InstallerType | None = None,
        replace_conflicting: bool = False,
        extras: tuple[str, ...] | None = None,
    ) -> list[Distribution]: ...
    def resolve(
        self,
        requirements: Iterable[Requirement],
        env: Environment | None = None,
        installer: _InstallerType | None | _InstallerTypeT[_DistributionT] = None,
        replace_conflicting: bool = False,
        extras: tuple[str, ...] | None = None,
    ) -> list[Distribution] | list[_DistributionT]:
        

        
        requirements = list(requirements)[::-1]
        
        processed = set()
        
        best = {}
        to_activate = []

        req_extras = _ReqExtras()

        
        
        required_by = collections.defaultdict(set)

        while requirements:
            
            req = requirements.pop(0)
            if req in processed:
                
                continue

            if not req_extras.markers_pass(req, extras):
                continue

            dist = self._resolve_dist(
                req, best, replace_conflicting, env, installer, required_by, to_activate
            )

            
            new_requirements = dist.requires(req.extras)[::-1]
            requirements.extend(new_requirements)

            
            for new_requirement in new_requirements:
                required_by[new_requirement].add(req.project_name)
                req_extras[new_requirement] = req.extras

            processed.add(req)

        
        return to_activate

    def _resolve_dist(
        self, req, best, replace_conflicting, env, installer, required_by, to_activate
    ) -> Distribution:
        dist = best.get(req.key)
        if dist is None:
            
            dist = self.by_key.get(req.key)
            if dist is None or (dist not in req and replace_conflicting):
                ws = self
                if env is None:
                    if dist is None:
                        env = Environment(self.entries)
                    else:
                        
                        
                        
                        env = Environment([])
                        ws = WorkingSet([])
                dist = best[req.key] = env.best_match(
                    req, ws, installer, replace_conflicting=replace_conflicting
                )
                if dist is None:
                    requirers = required_by.get(req, None)
                    raise DistributionNotFound(req, requirers)
            to_activate.append(dist)
        if dist not in req:
            
            dependent_req = required_by[req]
            raise VersionConflict(dist, req).with_context(dependent_req)
        return dist

    @overload
    def find_plugins(
        self,
        plugin_env: Environment,
        full_env: Environment | None,
        installer: _InstallerTypeT[_DistributionT],
        fallback: bool = True,
    ) -> tuple[list[_DistributionT], dict[Distribution, Exception]]: ...
    @overload
    def find_plugins(
        self,
        plugin_env: Environment,
        full_env: Environment | None = None,
        *,
        installer: _InstallerTypeT[_DistributionT],
        fallback: bool = True,
    ) -> tuple[list[_DistributionT], dict[Distribution, Exception]]: ...
    @overload
    def find_plugins(
        self,
        plugin_env: Environment,
        full_env: Environment | None = None,
        installer: _InstallerType | None = None,
        fallback: bool = True,
    ) -> tuple[list[Distribution], dict[Distribution, Exception]]: ...
    def find_plugins(
        self,
        plugin_env: Environment,
        full_env: Environment | None = None,
        installer: _InstallerType | None | _InstallerTypeT[_DistributionT] = None,
        fallback: bool = True,
    ) -> tuple[
        list[Distribution] | list[_DistributionT],
        dict[Distribution, Exception],
    ]:
        

        plugin_projects = list(plugin_env)
        
        plugin_projects.sort()

        error_info: dict[Distribution, Exception] = {}
        distributions: dict[Distribution, Exception | None] = {}

        if full_env is None:
            env = Environment(self.entries)
            env += plugin_env
        else:
            env = full_env + plugin_env

        shadow_set = self.__class__([])
        
        list(map(shadow_set.add, self))

        for project_name in plugin_projects:
            for dist in plugin_env[project_name]:
                req = [dist.as_requirement()]

                try:
                    resolvees = shadow_set.resolve(req, env, installer)

                except ResolutionError as v:
                    
                    error_info[dist] = v
                    if fallback:
                        
                        continue
                    else:
                        
                        break

                else:
                    list(map(shadow_set.add, resolvees))
                    distributions.update(dict.fromkeys(resolvees))

                    
                    break

        sorted_distributions = list(distributions)
        sorted_distributions.sort()

        return sorted_distributions, error_info

    def require(self, *requirements: _NestedStr):
        
        needed = self.resolve(parse_requirements(requirements))

        for dist in needed:
            self.add(dist)

        return needed

    def subscribe(
        self, callback: Callable[[Distribution], object], existing: bool = True
    ):
        
        if callback in self.callbacks:
            return
        self.callbacks.append(callback)
        if not existing:
            return
        for dist in self:
            callback(dist)

    def _added_new(self, dist):
        for callback in self.callbacks:
            callback(dist)

    def __getstate__(self):
        return (
            self.entries[:],
            self.entry_keys.copy(),
            self.by_key.copy(),
            self.normalized_to_canonical_keys.copy(),
            self.callbacks[:],
        )

    def __setstate__(self, e_k_b_n_c):
        entries, keys, by_key, normalized_to_canonical_keys, callbacks = e_k_b_n_c
        self.entries = entries[:]
        self.entry_keys = keys.copy()
        self.by_key = by_key.copy()
        self.normalized_to_canonical_keys = normalized_to_canonical_keys.copy()
        self.callbacks = callbacks[:]


class _ReqExtras(Dict[""Requirement"", Tuple[str, ...]]):
    

    def markers_pass(self, req: Requirement, extras: tuple[str, ...] | None = None):
        
        extra_evals = (
            req.marker.evaluate({'extra': extra})
            for extra in self.get(req, ()) + (extras or (None,))
        )
        return not req.marker or any(extra_evals)


class Environment:
    

    def __init__(
        self,
        search_path: Iterable[str] | None = None,
        platform: str | None = get_supported_platform(),
        python: str | None = PY_MAJOR,
    ):
        
        self._distmap = {}
        self.platform = platform
        self.python = python
        self.scan(search_path)

    def can_add(self, dist: Distribution):
        
        py_compat = (
            self.python is None
            or dist.py_version is None
            or dist.py_version == self.python
        )
        return py_compat and compatible_platforms(dist.platform, self.platform)

    def remove(self, dist: Distribution):
        
        self._distmap[dist.key].remove(dist)

    def scan(self, search_path: Iterable[str] | None = None):
        
        if search_path is None:
            search_path = sys.path

        for item in search_path:
            for dist in find_distributions(item):
                self.add(dist)

    def __getitem__(self, project_name: str) -> list[Distribution]:
        
        distribution_key = project_name.lower()
        return self._distmap.get(distribution_key, [])

    def add(self, dist: Distribution):
        
        if self.can_add(dist) and dist.has_version():
            dists = self._distmap.setdefault(dist.key, [])
            if dist not in dists:
                dists.append(dist)
                dists.sort(key=operator.attrgetter('hashcmp'), reverse=True)

    @overload
    def best_match(
        self,
        req: Requirement,
        working_set: WorkingSet,
        installer: _InstallerTypeT[_DistributionT],
        replace_conflicting: bool = False,
    ) -> _DistributionT: ...
    @overload
    def best_match(
        self,
        req: Requirement,
        working_set: WorkingSet,
        installer: _InstallerType | None = None,
        replace_conflicting: bool = False,
    ) -> Distribution | None: ...
    def best_match(
        self,
        req: Requirement,
        working_set: WorkingSet,
        installer: _InstallerType | None | _InstallerTypeT[_DistributionT] = None,
        replace_conflicting: bool = False,
    ) -> Distribution | None:
        
        try:
            dist = working_set.find(req)
        except VersionConflict:
            if not replace_conflicting:
                raise
            dist = None
        if dist is not None:
            return dist
        for dist in self[req.key]:
            if dist in req:
                return dist
        
        return self.obtain(req, installer)

    @overload
    def obtain(
        self,
        requirement: Requirement,
        installer: _InstallerTypeT[_DistributionT],
    ) -> _DistributionT: ...
    @overload
    def obtain(
        self,
        requirement: Requirement,
        installer: Callable[[Requirement], None] | None = None,
    ) -> None: ...
    @overload
    def obtain(
        self,
        requirement: Requirement,
        installer: _InstallerType | None = None,
    ) -> Distribution | None: ...
    def obtain(
        self,
        requirement: Requirement,
        installer: Callable[[Requirement], None]
        | _InstallerType
        | None
        | _InstallerTypeT[_DistributionT] = None,
    ) -> Distribution | None:
        
        return installer(requirement) if installer else None

    def __iter__(self) -> Iterator[str]:
        
        for key in self._distmap.keys():
            if self[key]:
                yield key

    def __iadd__(self, other: Distribution | Environment):
        
        if isinstance(other, Distribution):
            self.add(other)
        elif isinstance(other, Environment):
            for project in other:
                for dist in other[project]:
                    self.add(dist)
        else:
            raise TypeError(""Can't add %r to environment"" % (other,))
        return self

    def __add__(self, other: Distribution | Environment):
        
        new = self.__class__([], platform=None, python=None)
        for env in self, other:
            new += env
        return new



AvailableDistributions = Environment


class ExtractionError(RuntimeError):
    

    manager: ResourceManager
    cache_path: str
    original_error: BaseException | None


class ResourceManager:
    

    extraction_path: str | None = None

    def __init__(self):
        self.cached_files = {}

    def resource_exists(self, package_or_requirement: _PkgReqType, resource_name: str):
        
        return get_provider(package_or_requirement).has_resource(resource_name)

    def resource_isdir(self, package_or_requirement: _PkgReqType, resource_name: str):
        
        return get_provider(package_or_requirement).resource_isdir(resource_name)

    def resource_filename(
        self, package_or_requirement: _PkgReqType, resource_name: str
    ):
        
        return get_provider(package_or_requirement).get_resource_filename(
            self, resource_name
        )

    def resource_stream(self, package_or_requirement: _PkgReqType, resource_name: str):
        
        return get_provider(package_or_requirement).get_resource_stream(
            self, resource_name
        )

    def resource_string(
        self, package_or_requirement: _PkgReqType, resource_name: str
    ) -> bytes:
        
        return get_provider(package_or_requirement).get_resource_string(
            self, resource_name
        )

    def resource_listdir(self, package_or_requirement: _PkgReqType, resource_name: str):
        
        return get_provider(package_or_requirement).resource_listdir(resource_name)

    def extraction_error(self) -> NoReturn:
        

        old_exc = sys.exc_info()[1]
        cache_path = self.extraction_path or get_default_cache()

        tmpl = textwrap.dedent(
            
        ).lstrip()
        err = ExtractionError(tmpl.format(**locals()))
        err.manager = self
        err.cache_path = cache_path
        err.original_error = old_exc
        raise err

    def get_cache_path(self, archive_name: str, names: Iterable[StrPath] = ()):
        
        extract_path = self.extraction_path or get_default_cache()
        target_path = os.path.join(extract_path, archive_name + '-tmp', *names)
        try:
            _bypass_ensure_directory(target_path)
        except Exception:
            self.extraction_error()

        self._warn_unsafe_extraction_path(extract_path)

        self.cached_files[target_path] = True
        return target_path

    @staticmethod
    def _warn_unsafe_extraction_path(path):
        
        if os.name == 'nt' and not path.startswith(os.environ['windir']):
            
            
            
            return
        mode = os.stat(path).st_mode
        if mode & stat.S_IWOTH or mode & stat.S_IWGRP:
            msg = (
                ""Extraction path is writable by group/others ""
                ""and vulnerable to attack when ""
                ""used with get_resource_filename ({path}). ""
                ""Consider a more secure ""
                ""location (set with .set_extraction_path or the ""
                ""PYTHON_EGG_CACHE environment variable).""
            ).format(**locals())
            warnings.warn(msg, UserWarning)

    def postprocess(self, tempname: StrOrBytesPath, filename: StrOrBytesPath):
        

        if os.name == 'posix':
            
            mode = ((os.stat(tempname).st_mode) | 0o555) & 0o7777
            os.chmod(tempname, mode)

    def set_extraction_path(self, path: str):
        
        if self.cached_files:
            raise ValueError(""Can't change extraction path, files already extracted"")

        self.extraction_path = path

    def cleanup_resources(self, force: bool = False) -> list[str]:
        
        
        return []


def get_default_cache() -> str:
    
    return os.environ.get('PYTHON_EGG_CACHE') or _user_cache_dir(appname='Python-Eggs')


def safe_name(name: str):
    
    return re.sub('[^A-Za-z0-9.]+', '-', name)


def safe_version(version: str):
    
    try:
        
        return str(_packaging_version.Version(version))
    except _packaging_version.InvalidVersion:
        version = version.replace(' ', '.')
        return re.sub('[^A-Za-z0-9.]+', '-', version)


def _forgiving_version(version):
    
    version = version.replace(' ', '.')
    match = _PEP440_FALLBACK.search(version)
    if match:
        safe = match[""safe""]
        rest = version[len(safe) :]
    else:
        safe = ""0""
        rest = version
    local = f""sanitized.{_safe_segment(rest)}"".strip(""."")
    return f""{safe}.dev0+{local}""


def _safe_segment(segment):
    
    segment = re.sub('[^A-Za-z0-9.]+', '-', segment)
    segment = re.sub('-[^A-Za-z0-9]+', '-', segment)
    return re.sub(r'\.[^A-Za-z0-9]+', '.', segment).strip("".-"")


def safe_extra(extra: str):
    
    return re.sub('[^A-Za-z0-9.-]+', '_', extra).lower()


def to_filename(name: str):
    
    return name.replace('-', '_')


def invalid_marker(text: str):
    
    try:
        evaluate_marker(text)
    except SyntaxError as e:
        e.filename = None
        e.lineno = None
        return e
    return False


def evaluate_marker(text: str, extra: str | None = None) -> bool:
    
    try:
        marker = _packaging_markers.Marker(text)
        return marker.evaluate()
    except _packaging_markers.InvalidMarker as e:
        raise SyntaxError(e) from e


class NullProvider:
    

    egg_name: str | None = None
    egg_info: str | None = None
    loader: _LoaderProtocol | None = None

    def __init__(self, module: _ModuleLike):
        self.loader = getattr(module, '__loader__', None)
        self.module_path = os.path.dirname(getattr(module, '__file__', ''))

    def get_resource_filename(self, manager: ResourceManager, resource_name: str):
        return self._fn(self.module_path, resource_name)

    def get_resource_stream(self, manager: ResourceManager, resource_name: str):
        return io.BytesIO(self.get_resource_string(manager, resource_name))

    def get_resource_string(
        self, manager: ResourceManager, resource_name: str
    ) -> bytes:
        return self._get(self._fn(self.module_path, resource_name))

    def has_resource(self, resource_name: str):
        return self._has(self._fn(self.module_path, resource_name))

    def _get_metadata_path(self, name):
        return self._fn(self.egg_info, name)

    def has_metadata(self, name: str) -> bool:
        if not self.egg_info:
            return False

        path = self._get_metadata_path(name)
        return self._has(path)

    def get_metadata(self, name: str):
        if not self.egg_info:
            return """"
        path = self._get_metadata_path(name)
        value = self._get(path)
        try:
            return value.decode('utf-8')
        except UnicodeDecodeError as exc:
            
            
            exc.reason += ' in {} file at path: {}'.format(name, path)
            raise

    def get_metadata_lines(self, name: str) -> Iterator[str]:
        return yield_lines(self.get_metadata(name))

    def resource_isdir(self, resource_name: str):
        return self._isdir(self._fn(self.module_path, resource_name))

    def metadata_isdir(self, name: str) -> bool:
        return bool(self.egg_info and self._isdir(self._fn(self.egg_info, name)))

    def resource_listdir(self, resource_name: str):
        return self._listdir(self._fn(self.module_path, resource_name))

    def metadata_listdir(self, name: str) -> list[str]:
        if self.egg_info:
            return self._listdir(self._fn(self.egg_info, name))
        return []

    def run_script(self, script_name: str, namespace: dict[str, Any]):
        script = 'scripts/' + script_name
        if not self.has_metadata(script):
            raise ResolutionError(
                ""Script {script!r} not found in metadata at {self.egg_info!r}"".format(
                    **locals()
                ),
            )

        script_text = self.get_metadata(script).replace('\r\n', '\n')
        script_text = script_text.replace('\r', '\n')
        script_filename = self._fn(self.egg_info, script)
        namespace['__file__'] = script_filename
        if os.path.exists(script_filename):
            source = _read_utf8_with_fallback(script_filename)
            code = compile(source, script_filename, 'exec')
            exec(code, namespace, namespace)
        else:
            from linecache import cache

            cache[script_filename] = (
                len(script_text),
                0,
                script_text.split('\n'),
                script_filename,
            )
            script_code = compile(script_text, script_filename, 'exec')
            exec(script_code, namespace, namespace)

    def _has(self, path) -> bool:
        raise NotImplementedError(
            ""Can't perform this operation for unregistered loader type""
        )

    def _isdir(self, path) -> bool:
        raise NotImplementedError(
            ""Can't perform this operation for unregistered loader type""
        )

    def _listdir(self, path) -> list[str]:
        raise NotImplementedError(
            ""Can't perform this operation for unregistered loader type""
        )

    def _fn(self, base: str | None, resource_name: str):
        if base is None:
            raise TypeError(
                ""`base` parameter in `_fn` is `None`. Either override this method or check the parameter first.""
            )
        self._validate_resource_path(resource_name)
        if resource_name:
            return os.path.join(base, *resource_name.split('/'))
        return base

    @staticmethod
    def _validate_resource_path(path):
        
        invalid = (
            os.path.pardir in path.split(posixpath.sep)
            or posixpath.isabs(path)
            or ntpath.isabs(path)
            or path.startswith(""\\"")
        )
        if not invalid:
            return

        msg = ""Use of .. or absolute path in a resource path is not allowed.""

        
        if (path.startswith(""\\"") or ntpath.isabs(path)) and not posixpath.isabs(path):
            raise ValueError(msg)

        
        
        issue_warning(
            msg[:-1] + "" and will raise exceptions in a future release."",
            DeprecationWarning,
        )

    def _get(self, path) -> bytes:
        if hasattr(self.loader, 'get_data') and self.loader:
            
            return self.loader.get_data(path)  
        raise NotImplementedError(
            ""Can't perform this operation for loaders without 'get_data()'""
        )


register_loader_type(object, NullProvider)


def _parents(path):
    
    last = None
    while path != last:
        yield path
        last = path
        path, _ = os.path.split(path)


class EggProvider(NullProvider):
    

    def __init__(self, module: _ModuleLike):
        super().__init__(module)
        self._setup_prefix()

    def _setup_prefix(self):
        
        
        eggs = filter(_is_egg_path, _parents(self.module_path))
        egg = next(eggs, None)
        egg and self._set_egg(egg)

    def _set_egg(self, path: str):
        self.egg_name = os.path.basename(path)
        self.egg_info = os.path.join(path, 'EGG-INFO')
        self.egg_root = path


class DefaultProvider(EggProvider):
    

    def _has(self, path) -> bool:
        return os.path.exists(path)

    def _isdir(self, path) -> bool:
        return os.path.isdir(path)

    def _listdir(self, path):
        return os.listdir(path)

    def get_resource_stream(self, manager: object, resource_name: str):
        return open(self._fn(self.module_path, resource_name), 'rb')

    def _get(self, path) -> bytes:
        with open(path, 'rb') as stream:
            return stream.read()

    @classmethod
    def _register(cls):
        loader_names = (
            'SourceFileLoader',
            'SourcelessFileLoader',
        )
        for name in loader_names:
            loader_cls = getattr(importlib.machinery, name, type(None))
            register_loader_type(loader_cls, cls)


DefaultProvider._register()


class EmptyProvider(NullProvider):
    

    
    module_path: str | None = None  

    _isdir = _has = lambda self, path: False

    def _get(self, path) -> bytes:
        return b''

    def _listdir(self, path):
        return []

    def __init__(self):
        pass


empty_provider = EmptyProvider()


class ZipManifests(Dict[str, ""MemoizedZipManifests.manifest_mod""]):
    

    
    @classmethod
    def build(cls, path: str):
        
        with zipfile.ZipFile(path) as zfile:
            items = (
                (
                    name.replace('/', os.sep),
                    zfile.getinfo(name),
                )
                for name in zfile.namelist()
            )
            return dict(items)

    load = build


class MemoizedZipManifests(ZipManifests):
    

    class manifest_mod(NamedTuple):
        manifest: dict[str, zipfile.ZipInfo]
        mtime: float

    def load(self, path: str) -> dict[str, zipfile.ZipInfo]:  
        
        path = os.path.normpath(path)
        mtime = os.stat(path).st_mtime

        if path not in self or self[path].mtime != mtime:
            manifest = self.build(path)
            self[path] = self.manifest_mod(manifest, mtime)

        return self[path].manifest


class ZipProvider(EggProvider):
    

    eagers: list[str] | None = None
    _zip_manifests = MemoizedZipManifests()
    
    loader: zipimport.zipimporter

    def __init__(self, module: _ZipLoaderModule):
        super().__init__(module)
        self.zip_pre = self.loader.archive + os.sep

    def _zipinfo_name(self, fspath):
        
        
        fspath = fspath.rstrip(os.sep)
        if fspath == self.loader.archive:
            return ''
        if fspath.startswith(self.zip_pre):
            return fspath[len(self.zip_pre) :]
        raise AssertionError(""%s is not a subpath of %s"" % (fspath, self.zip_pre))

    def _parts(self, zip_path):
        
        
        fspath = self.zip_pre + zip_path
        if fspath.startswith(self.egg_root + os.sep):
            return fspath[len(self.egg_root) + 1 :].split(os.sep)
        raise AssertionError(""%s is not a subpath of %s"" % (fspath, self.egg_root))

    @property
    def zipinfo(self):
        return self._zip_manifests.load(self.loader.archive)

    def get_resource_filename(self, manager: ResourceManager, resource_name: str):
        if not self.egg_name:
            raise NotImplementedError(
                ""resource_filename() only supported for .egg, not .zip""
            )
        
        zip_path = self._resource_to_zip(resource_name)
        eagers = self._get_eager_resources()
        if '/'.join(self._parts(zip_path)) in eagers:
            for name in eagers:
                self._extract_resource(manager, self._eager_to_zip(name))
        return self._extract_resource(manager, zip_path)

    @staticmethod
    def _get_date_and_size(zip_stat):
        size = zip_stat.file_size
        
        date_time = zip_stat.date_time + (0, 0, -1)
        
        timestamp = time.mktime(date_time)
        return timestamp, size

    
    def _extract_resource(self, manager: ResourceManager, zip_path) -> str:  
        if zip_path in self._index():
            for name in self._index()[zip_path]:
                last = self._extract_resource(manager, os.path.join(zip_path, name))
            
            return os.path.dirname(last)

        timestamp, size = self._get_date_and_size(self.zipinfo[zip_path])

        if not WRITE_SUPPORT:
            raise OSError(
                '""os.rename"" and ""os.unlink"" are not supported on this platform'
            )
        try:
            if not self.egg_name:
                raise OSError(
                    '""egg_name"" is empty. This likely means no egg could be found from the ""module_path"".'
                )
            real_path = manager.get_cache_path(self.egg_name, self._parts(zip_path))

            if self._is_current(real_path, zip_path):
                return real_path

            outf, tmpnam = _mkstemp(
                "".$extract"",
                dir=os.path.dirname(real_path),
            )
            os.write(outf, self.loader.get_data(zip_path))
            os.close(outf)
            utime(tmpnam, (timestamp, timestamp))
            manager.postprocess(tmpnam, real_path)

            try:
                rename(tmpnam, real_path)

            except OSError:
                if os.path.isfile(real_path):
                    if self._is_current(real_path, zip_path):
                        
                        
                        return real_path
                    
                    elif os.name == 'nt':
                        unlink(real_path)
                        rename(tmpnam, real_path)
                        return real_path
                raise

        except OSError:
            
            manager.extraction_error()

        return real_path

    def _is_current(self, file_path, zip_path):
        
        timestamp, size = self._get_date_and_size(self.zipinfo[zip_path])
        if not os.path.isfile(file_path):
            return False
        stat = os.stat(file_path)
        if stat.st_size != size or stat.st_mtime != timestamp:
            return False
        
        zip_contents = self.loader.get_data(zip_path)
        with open(file_path, 'rb') as f:
            file_contents = f.read()
        return zip_contents == file_contents

    def _get_eager_resources(self):
        if self.eagers is None:
            eagers = []
            for name in ('native_libs.txt', 'eager_resources.txt'):
                if self.has_metadata(name):
                    eagers.extend(self.get_metadata_lines(name))
            self.eagers = eagers
        return self.eagers

    def _index(self):
        try:
            return self._dirindex
        except AttributeError:
            ind = {}
            for path in self.zipinfo:
                parts = path.split(os.sep)
                while parts:
                    parent = os.sep.join(parts[:-1])
                    if parent in ind:
                        ind[parent].append(parts[-1])
                        break
                    else:
                        ind[parent] = [parts.pop()]
            self._dirindex = ind
            return ind

    def _has(self, fspath) -> bool:
        zip_path = self._zipinfo_name(fspath)
        return zip_path in self.zipinfo or zip_path in self._index()

    def _isdir(self, fspath) -> bool:
        return self._zipinfo_name(fspath) in self._index()

    def _listdir(self, fspath):
        return list(self._index().get(self._zipinfo_name(fspath), ()))

    def _eager_to_zip(self, resource_name: str):
        return self._zipinfo_name(self._fn(self.egg_root, resource_name))

    def _resource_to_zip(self, resource_name: str):
        return self._zipinfo_name(self._fn(self.module_path, resource_name))


register_loader_type(zipimport.zipimporter, ZipProvider)


class FileMetadata(EmptyProvider):
    

    def __init__(self, path: StrPath):
        self.path = path

    def _get_metadata_path(self, name):
        return self.path

    def has_metadata(self, name: str) -> bool:
        return name == 'PKG-INFO' and os.path.isfile(self.path)

    def get_metadata(self, name: str):
        if name != 'PKG-INFO':
            raise KeyError(""No metadata except PKG-INFO is available"")

        with open(self.path, encoding='utf-8', errors=""replace"") as f:
            metadata = f.read()
        self._warn_on_replacement(metadata)
        return metadata

    def _warn_on_replacement(self, metadata):
        replacement_char = '�'
        if replacement_char in metadata:
            tmpl = ""{self.path} could not be properly decoded in UTF-8""
            msg = tmpl.format(**locals())
            warnings.warn(msg)

    def get_metadata_lines(self, name: str) -> Iterator[str]:
        return yield_lines(self.get_metadata(name))


class PathMetadata(DefaultProvider):
    

    def __init__(self, path: str, egg_info: str):
        self.module_path = path
        self.egg_info = egg_info


class EggMetadata(ZipProvider):
    

    def __init__(self, importer: zipimport.zipimporter):
        

        self.zip_pre = importer.archive + os.sep
        self.loader = importer
        if importer.prefix:
            self.module_path = os.path.join(importer.archive, importer.prefix)
        else:
            self.module_path = importer.archive
        self._setup_prefix()


_distribution_finders: dict[type, _DistFinderType[Any]] = _declare_state(
    'dict', '_distribution_finders', {}
)


def register_finder(importer_type: type[_T], distribution_finder: _DistFinderType[_T]):
    
    _distribution_finders[importer_type] = distribution_finder


def find_distributions(path_item: str, only: bool = False):
    
    importer = get_importer(path_item)
    finder = _find_adapter(_distribution_finders, importer)
    return finder(importer, path_item, only)


def find_eggs_in_zip(
    importer: zipimport.zipimporter, path_item: str, only: bool = False
) -> Iterator[Distribution]:
    
    if importer.archive.endswith('.whl'):
        
        
        return
    metadata = EggMetadata(importer)
    if metadata.has_metadata('PKG-INFO'):
        yield Distribution.from_filename(path_item, metadata=metadata)
    if only:
        
        return
    for subitem in metadata.resource_listdir(''):
        if _is_egg_path(subitem):
            subpath = os.path.join(path_item, subitem)
            dists = find_eggs_in_zip(zipimport.zipimporter(subpath), subpath)
            yield from dists
        elif subitem.lower().endswith(('.dist-info', '.egg-info')):
            subpath = os.path.join(path_item, subitem)
            submeta = EggMetadata(zipimport.zipimporter(subpath))
            submeta.egg_info = subpath
            yield Distribution.from_location(path_item, subitem, submeta)


register_finder(zipimport.zipimporter, find_eggs_in_zip)


def find_nothing(
    importer: object | None, path_item: str | None, only: bool | None = False
):
    return ()


register_finder(object, find_nothing)


def find_on_path(importer: object | None, path_item, only=False):
    
    path_item = _normalize_cached(path_item)

    if _is_unpacked_egg(path_item):
        yield Distribution.from_filename(
            path_item,
            metadata=PathMetadata(path_item, os.path.join(path_item, 'EGG-INFO')),
        )
        return

    entries = (os.path.join(path_item, child) for child in safe_listdir(path_item))

    
    for entry in sorted(entries):
        fullpath = os.path.join(path_item, entry)
        factory = dist_factory(path_item, entry, only)
        yield from factory(fullpath)


def dist_factory(path_item, entry, only):
    
    lower = entry.lower()
    is_egg_info = lower.endswith('.egg-info')
    is_dist_info = lower.endswith('.dist-info') and os.path.isdir(
        os.path.join(path_item, entry)
    )
    is_meta = is_egg_info or is_dist_info
    return (
        distributions_from_metadata
        if is_meta
        else find_distributions
        if not only and _is_egg_path(entry)
        else resolve_egg_link
        if not only and lower.endswith('.egg-link')
        else NoDists()
    )


class NoDists:
    

    def __bool__(self):
        return False

    def __call__(self, fullpath):
        return iter(())


def safe_listdir(path: StrOrBytesPath):
    
    try:
        return os.listdir(path)
    except (PermissionError, NotADirectoryError):
        pass
    except OSError as e:
        
        
        if e.errno not in (errno.ENOTDIR, errno.EACCES, errno.ENOENT):
            raise
    return ()


def distributions_from_metadata(path: str):
    root = os.path.dirname(path)
    if os.path.isdir(path):
        if len(os.listdir(path)) == 0:
            
            return
        metadata: _MetadataType = PathMetadata(root, path)
    else:
        metadata = FileMetadata(path)
    entry = os.path.basename(path)
    yield Distribution.from_location(
        root,
        entry,
        metadata,
        precedence=DEVELOP_DIST,
    )


def non_empty_lines(path):
    
    for line in _read_utf8_with_fallback(path).splitlines():
        line = line.strip()
        if line:
            yield line


def resolve_egg_link(path):
    
    referenced_paths = non_empty_lines(path)
    resolved_paths = (
        os.path.join(os.path.dirname(path), ref) for ref in referenced_paths
    )
    dist_groups = map(find_distributions, resolved_paths)
    return next(dist_groups, ())


if hasattr(pkgutil, 'ImpImporter'):
    register_finder(pkgutil.ImpImporter, find_on_path)

register_finder(importlib.machinery.FileFinder, find_on_path)

_namespace_handlers: dict[type, _NSHandlerType[Any]] = _declare_state(
    'dict', '_namespace_handlers', {}
)
_namespace_packages: dict[str | None, list[str]] = _declare_state(
    'dict', '_namespace_packages', {}
)


def register_namespace_handler(
    importer_type: type[_T], namespace_handler: _NSHandlerType[_T]
):
    
    _namespace_handlers[importer_type] = namespace_handler


def _handle_ns(packageName, path_item):
    

    importer = get_importer(path_item)
    if importer is None:
        return None

    
    try:
        spec = importer.find_spec(packageName)
    except AttributeError:
        
        with warnings.catch_warnings():
            warnings.simplefilter(""ignore"")
            loader = importer.find_module(packageName)
    else:
        loader = spec.loader if spec else None

    if loader is None:
        return None
    module = sys.modules.get(packageName)
    if module is None:
        module = sys.modules[packageName] = types.ModuleType(packageName)
        module.__path__ = []
        _set_parent_ns(packageName)
    elif not hasattr(module, '__path__'):
        raise TypeError(""Not a package:"", packageName)
    handler = _find_adapter(_namespace_handlers, importer)
    subpath = handler(importer, path_item, packageName, module)
    if subpath is not None:
        path = module.__path__
        path.append(subpath)
        importlib.import_module(packageName)
        _rebuild_mod_path(path, packageName, module)
    return subpath


def _rebuild_mod_path(orig_path, package_name, module: types.ModuleType):
    
    sys_path = [_normalize_cached(p) for p in sys.path]

    def safe_sys_path_index(entry):
        
        try:
            return sys_path.index(entry)
        except ValueError:
            return float('inf')

    def position_in_sys_path(path):
        
        path_parts = path.split(os.sep)
        module_parts = package_name.count('.') + 1
        parts = path_parts[:-module_parts]
        return safe_sys_path_index(_normalize_cached(os.sep.join(parts)))

    new_path = sorted(orig_path, key=position_in_sys_path)
    new_path = [_normalize_cached(p) for p in new_path]

    if isinstance(module.__path__, list):
        module.__path__[:] = new_path
    else:
        module.__path__ = new_path


def declare_namespace(packageName: str):
    

    msg = (
        f""Deprecated call to `pkg_resources.declare_namespace({packageName!r})`.\n""
        ""Implementing implicit namespace packages (as specified in PEP 420) ""
        ""is preferred to `pkg_resources.declare_namespace`. ""
        ""See https://setuptools.pypa.io/en/latest/references/""
        ""keywords.html
    )
    warnings.warn(msg, DeprecationWarning, stacklevel=2)

    _imp.acquire_lock()
    try:
        if packageName in _namespace_packages:
            return

        path: MutableSequence[str] = sys.path
        parent, _, _ = packageName.rpartition('.')

        if parent:
            declare_namespace(parent)
            if parent not in _namespace_packages:
                __import__(parent)
            try:
                path = sys.modules[parent].__path__
            except AttributeError as e:
                raise TypeError(""Not a package:"", parent) from e

        
        
        _namespace_packages.setdefault(parent or None, []).append(packageName)
        _namespace_packages.setdefault(packageName, [])

        for path_item in path:
            
            
            _handle_ns(packageName, path_item)

    finally:
        _imp.release_lock()


def fixup_namespace_packages(path_item: str, parent: str | None = None):
    
    _imp.acquire_lock()
    try:
        for package in _namespace_packages.get(parent, ()):
            subpath = _handle_ns(package, path_item)
            if subpath:
                fixup_namespace_packages(subpath, package)
    finally:
        _imp.release_lock()


def file_ns_handler(
    importer: object,
    path_item: StrPath,
    packageName: str,
    module: types.ModuleType,
):
    

    subpath = os.path.join(path_item, packageName.split('.')[-1])
    normalized = _normalize_cached(subpath)
    for item in module.__path__:
        if _normalize_cached(item) == normalized:
            break
    else:
        
        return subpath


if hasattr(pkgutil, 'ImpImporter'):
    register_namespace_handler(pkgutil.ImpImporter, file_ns_handler)

register_namespace_handler(zipimport.zipimporter, file_ns_handler)
register_namespace_handler(importlib.machinery.FileFinder, file_ns_handler)


def null_ns_handler(
    importer: object,
    path_item: str | None,
    packageName: str | None,
    module: _ModuleLike | None,
):
    return None


register_namespace_handler(object, null_ns_handler)


@overload
def normalize_path(filename: StrPath) -> str: ...
@overload
def normalize_path(filename: BytesPath) -> bytes: ...
def normalize_path(filename: StrOrBytesPath):
    
    return os.path.normcase(os.path.realpath(os.path.normpath(_cygwin_patch(filename))))


def _cygwin_patch(filename: StrOrBytesPath):  
    
    return os.path.abspath(filename) if sys.platform == 'cygwin' else filename


if TYPE_CHECKING:
    
    
    @overload
    def _normalize_cached(filename: StrPath) -> str: ...
    @overload
    def _normalize_cached(filename: BytesPath) -> bytes: ...
    def _normalize_cached(filename: StrOrBytesPath) -> str | bytes: ...
else:

    @functools.lru_cache(maxsize=None)
    def _normalize_cached(filename):
        return normalize_path(filename)


def _is_egg_path(path):
    
    return _is_zip_egg(path) or _is_unpacked_egg(path)


def _is_zip_egg(path):
    return (
        path.lower().endswith('.egg')
        and os.path.isfile(path)
        and zipfile.is_zipfile(path)
    )


def _is_unpacked_egg(path):
    
    return path.lower().endswith('.egg') and os.path.isfile(
        os.path.join(path, 'EGG-INFO', 'PKG-INFO')
    )


def _set_parent_ns(packageName):
    parts = packageName.split('.')
    name = parts.pop()
    if parts:
        parent = '.'.join(parts)
        setattr(sys.modules[parent], name, sys.modules[packageName])


MODULE = re.compile(r""\w+(\.\w+)*$"").match
EGG_NAME = re.compile(
    r,
    re.VERBOSE | re.IGNORECASE,
).match


class EntryPoint:
    

    def __init__(
        self,
        name: str,
        module_name: str,
        attrs: Iterable[str] = (),
        extras: Iterable[str] = (),
        dist: Distribution | None = None,
    ):
        if not MODULE(module_name):
            raise ValueError(""Invalid module name"", module_name)
        self.name = name
        self.module_name = module_name
        self.attrs = tuple(attrs)
        self.extras = tuple(extras)
        self.dist = dist

    def __str__(self):
        s = ""%s = %s"" % (self.name, self.module_name)
        if self.attrs:
            s += ':' + '.'.join(self.attrs)
        if self.extras:
            s += ' [%s]' % ','.join(self.extras)
        return s

    def __repr__(self):
        return ""EntryPoint.parse(%r)"" % str(self)

    @overload
    def load(
        self,
        require: Literal[True] = True,
        env: Environment | None = None,
        installer: _InstallerType | None = None,
    ) -> _ResolvedEntryPoint: ...
    @overload
    def load(
        self,
        require: Literal[False],
        *args: Any,
        **kwargs: Any,
    ) -> _ResolvedEntryPoint: ...
    def load(
        self,
        require: bool = True,
        *args: Environment | _InstallerType | None,
        **kwargs: Environment | _InstallerType | None,
    ) -> _ResolvedEntryPoint:
        
        if not require or args or kwargs:
            warnings.warn(
                ""Parameters to load are deprecated.  Call .resolve and ""
                "".require separately."",
                PkgResourcesDeprecationWarning,
                stacklevel=2,
            )
        if require:
            
            
            self.require(*args, **kwargs)  
        return self.resolve()

    def resolve(self) -> _ResolvedEntryPoint:
        
        module = __import__(self.module_name, fromlist=['__name__'], level=0)
        try:
            return functools.reduce(getattr, self.attrs, module)
        except AttributeError as exc:
            raise ImportError(str(exc)) from exc

    def require(
        self,
        env: Environment | None = None,
        installer: _InstallerType | None = None,
    ):
        if not self.dist:
            error_cls = UnknownExtra if self.extras else AttributeError
            raise error_cls(""Can't require() without a distribution"", self)

        
        
        
        
        
        reqs = self.dist.requires(self.extras)
        items = working_set.resolve(reqs, env, installer, extras=self.extras)
        list(map(working_set.add, items))

    pattern = re.compile(
        r'\s*'
        r'(?P<name>.+?)\s*'
        r'=\s*'
        r'(?P<module>[\w.]+)\s*'
        r'(:\s*(?P<attr>[\w.]+))?\s*'
        r'(?P<extras>\[.*\])?\s*$'
    )

    @classmethod
    def parse(cls, src: str, dist: Distribution | None = None):
        
        m = cls.pattern.match(src)
        if not m:
            msg = ""EntryPoint must be in 'name=module:attrs [extras]' format""
            raise ValueError(msg, src)
        res = m.groupdict()
        extras = cls._parse_extras(res['extras'])
        attrs = res['attr'].split('.') if res['attr'] else ()
        return cls(res['name'], res['module'], attrs, extras, dist)

    @classmethod
    def _parse_extras(cls, extras_spec):
        if not extras_spec:
            return ()
        req = Requirement.parse('x' + extras_spec)
        if req.specs:
            raise ValueError
        return req.extras

    @classmethod
    def parse_group(
        cls,
        group: str,
        lines: _NestedStr,
        dist: Distribution | None = None,
    ):
        
        if not MODULE(group):
            raise ValueError(""Invalid group name"", group)
        this: dict[str, Self] = {}
        for line in yield_lines(lines):
            ep = cls.parse(line, dist)
            if ep.name in this:
                raise ValueError(""Duplicate entry point"", group, ep.name)
            this[ep.name] = ep
        return this

    @classmethod
    def parse_map(
        cls,
        data: str | Iterable[str] | dict[str, str | Iterable[str]],
        dist: Distribution | None = None,
    ):
        
        _data: Iterable[tuple[str | None, str | Iterable[str]]]
        if isinstance(data, dict):
            _data = data.items()
        else:
            _data = split_sections(data)
        maps: dict[str, dict[str, Self]] = {}
        for group, lines in _data:
            if group is None:
                if not lines:
                    continue
                raise ValueError(""Entry points must be listed in groups"")
            group = group.strip()
            if group in maps:
                raise ValueError(""Duplicate group name"", group)
            maps[group] = cls.parse_group(group, lines, dist)
        return maps


def _version_from_file(lines):
    

    def is_version_line(line):
        return line.lower().startswith('version:')

    version_lines = filter(is_version_line, lines)
    line = next(iter(version_lines), '')
    _, _, value = line.partition(':')
    return safe_version(value.strip()) or None


class Distribution:
    

    PKG_INFO = 'PKG-INFO'

    def __init__(
        self,
        location: str | None = None,
        metadata: _MetadataType = None,
        project_name: str | None = None,
        version: str | None = None,
        py_version: str | None = PY_MAJOR,
        platform: str | None = None,
        precedence: int = EGG_DIST,
    ):
        self.project_name = safe_name(project_name or 'Unknown')
        if version is not None:
            self._version = safe_version(version)
        self.py_version = py_version
        self.platform = platform
        self.location = location
        self.precedence = precedence
        self._provider = metadata or empty_provider

    @classmethod
    def from_location(
        cls,
        location: str,
        basename: StrPath,
        metadata: _MetadataType = None,
        **kw: int,  
    ) -> Distribution:
        project_name, version, py_version, platform = [None] * 4
        basename, ext = os.path.splitext(basename)
        if ext.lower() in _distributionImpl:
            cls = _distributionImpl[ext.lower()]

            match = EGG_NAME(basename)
            if match:
                project_name, version, py_version, platform = match.group(
                    'name', 'ver', 'pyver', 'plat'
                )
        return cls(
            location,
            metadata,
            project_name=project_name,
            version=version,
            py_version=py_version,
            platform=platform,
            **kw,
        )._reload_version()

    def _reload_version(self):
        return self

    @property
    def hashcmp(self):
        return (
            self._forgiving_parsed_version,
            self.precedence,
            self.key,
            self.location,
            self.py_version or '',
            self.platform or '',
        )

    def __hash__(self):
        return hash(self.hashcmp)

    def __lt__(self, other: Distribution):
        return self.hashcmp < other.hashcmp

    def __le__(self, other: Distribution):
        return self.hashcmp <= other.hashcmp

    def __gt__(self, other: Distribution):
        return self.hashcmp > other.hashcmp

    def __ge__(self, other: Distribution):
        return self.hashcmp >= other.hashcmp

    def __eq__(self, other: object):
        if not isinstance(other, self.__class__):
            
            return False
        return self.hashcmp == other.hashcmp

    def __ne__(self, other: object):
        return not self == other

    
    
    

    @property
    def key(self):
        try:
            return self._key
        except AttributeError:
            self._key = key = self.project_name.lower()
            return key

    @property
    def parsed_version(self):
        if not hasattr(self, ""_parsed_version""):
            try:
                self._parsed_version = parse_version(self.version)
            except _packaging_version.InvalidVersion as ex:
                info = f""(package: {self.project_name})""
                if hasattr(ex, ""add_note""):
                    ex.add_note(info)  
                    raise
                raise _packaging_version.InvalidVersion(f""{str(ex)} {info}"") from None

        return self._parsed_version

    @property
    def _forgiving_parsed_version(self):
        try:
            return self.parsed_version
        except _packaging_version.InvalidVersion as ex:
            self._parsed_version = parse_version(_forgiving_version(self.version))

            notes = ""\n"".join(getattr(ex, ""__notes__"", []))  
            msg = f
            warnings.warn(msg, DeprecationWarning)

            return self._parsed_version

    @property
    def version(self):
        try:
            return self._version
        except AttributeError as e:
            version = self._get_version()
            if version is None:
                path = self._get_metadata_path_for_display(self.PKG_INFO)
                msg = (""Missing 'Version:' header and/or {} file at path: {}"").format(
                    self.PKG_INFO, path
                )
                raise ValueError(msg, self) from e

            return version

    @property
    def _dep_map(self):
        
        try:
            return self.__dep_map
        except AttributeError:
            self.__dep_map = self._filter_extras(self._build_dep_map())
        return self.__dep_map

    @staticmethod
    def _filter_extras(dm: dict[str | None, list[Requirement]]):
        
        for extra in list(filter(None, dm)):
            new_extra: str | None = extra
            reqs = dm.pop(extra)
            new_extra, _, marker = extra.partition(':')
            fails_marker = marker and (
                invalid_marker(marker) or not evaluate_marker(marker)
            )
            if fails_marker:
                reqs = []
            new_extra = safe_extra(new_extra) or None

            dm.setdefault(new_extra, []).extend(reqs)
        return dm

    def _build_dep_map(self):
        dm = {}
        for name in 'requires.txt', 'depends.txt':
            for extra, reqs in split_sections(self._get_metadata(name)):
                dm.setdefault(extra, []).extend(parse_requirements(reqs))
        return dm

    def requires(self, extras: Iterable[str] = ()):
        
        dm = self._dep_map
        deps: list[Requirement] = []
        deps.extend(dm.get(None, ()))
        for ext in extras:
            try:
                deps.extend(dm[safe_extra(ext)])
            except KeyError as e:
                raise UnknownExtra(
                    ""%s has no such extra feature %r"" % (self, ext)
                ) from e
        return deps

    def _get_metadata_path_for_display(self, name):
        
        try:
            
            
            
            path = self._provider._get_metadata_path(name)

        
        
        except Exception:
            return '[could not detect]'

        return path

    def _get_metadata(self, name):
        if self.has_metadata(name):
            yield from self.get_metadata_lines(name)

    def _get_version(self):
        lines = self._get_metadata(self.PKG_INFO)
        return _version_from_file(lines)

    def activate(self, path: list[str] | None = None, replace: bool = False):
        
        if path is None:
            path = sys.path
        self.insert_on(path, replace=replace)
        if path is sys.path and self.location is not None:
            fixup_namespace_packages(self.location)
            for pkg in self._get_metadata('namespace_packages.txt'):
                if pkg in sys.modules:
                    declare_namespace(pkg)

    def egg_name(self):
        
        filename = ""%s-%s-py%s"" % (
            to_filename(self.project_name),
            to_filename(self.version),
            self.py_version or PY_MAJOR,
        )

        if self.platform:
            filename += '-' + self.platform
        return filename

    def __repr__(self):
        if self.location:
            return ""%s (%s)"" % (self, self.location)
        else:
            return str(self)

    def __str__(self):
        try:
            version = getattr(self, 'version', None)
        except ValueError:
            version = None
        version = version or ""[unknown version]""
        return ""%s %s"" % (self.project_name, version)

    def __getattr__(self, attr):
        
        if attr.startswith('_'):
            raise AttributeError(attr)
        return getattr(self._provider, attr)

    def __dir__(self):
        return list(
            set(super().__dir__())
            | set(attr for attr in self._provider.__dir__() if not attr.startswith('_'))
        )

    @classmethod
    def from_filename(
        cls,
        filename: StrPath,
        metadata: _MetadataType = None,
        **kw: int,  
    ):
        return cls.from_location(
            _normalize_cached(filename), os.path.basename(filename), metadata, **kw
        )

    def as_requirement(self):
        
        if isinstance(self.parsed_version, _packaging_version.Version):
            spec = ""%s==%s"" % (self.project_name, self.parsed_version)
        else:
            spec = ""%s===%s"" % (self.project_name, self.parsed_version)

        return Requirement.parse(spec)

    def load_entry_point(self, group: str, name: str) -> _ResolvedEntryPoint:
        
        ep = self.get_entry_info(group, name)
        if ep is None:
            raise ImportError(""Entry point %r not found"" % ((group, name),))
        return ep.load()

    @overload
    def get_entry_map(self, group: None = None) -> dict[str, dict[str, EntryPoint]]: ...
    @overload
    def get_entry_map(self, group: str) -> dict[str, EntryPoint]: ...
    def get_entry_map(self, group: str | None = None):
        
        if not hasattr(self, ""_ep_map""):
            self._ep_map = EntryPoint.parse_map(
                self._get_metadata('entry_points.txt'), self
            )
        if group is not None:
            return self._ep_map.get(group, {})
        return self._ep_map

    def get_entry_info(self, group: str, name: str):
        
        return self.get_entry_map(group).get(name)

    
    def insert_on(  
        self,
        path: list[str],
        loc=None,
        replace: bool = False,
    ):
        

        loc = loc or self.location
        if not loc:
            return

        nloc = _normalize_cached(loc)
        bdir = os.path.dirname(nloc)
        npath = [(p and _normalize_cached(p) or p) for p in path]

        for p, item in enumerate(npath):
            if item == nloc:
                if replace:
                    break
                else:
                    
                    
                    return
            elif item == bdir and self.precedence == EGG_DIST:
                
                
                if (not replace) and nloc in npath[p:]:
                    return
                if path is sys.path:
                    self.check_version_conflict()
                path.insert(p, loc)
                npath.insert(p, nloc)
                break
        else:
            if path is sys.path:
                self.check_version_conflict()
            if replace:
                path.insert(0, loc)
            else:
                path.append(loc)
            return

        
        while True:
            try:
                np = npath.index(nloc, p + 1)
            except ValueError:
                break
            else:
                del npath[np], path[np]
                
                p = np

        return

    def check_version_conflict(self):
        if self.key == 'setuptools':
            
            return

        nsp = dict.fromkeys(self._get_metadata('namespace_packages.txt'))
        loc = normalize_path(self.location)
        for modname in self._get_metadata('top_level.txt'):
            if (
                modname not in sys.modules
                or modname in nsp
                or modname in _namespace_packages
            ):
                continue
            if modname in ('pkg_resources', 'setuptools', 'site'):
                continue
            fn = getattr(sys.modules[modname], '__file__', None)
            if fn and (
                normalize_path(fn).startswith(loc) or fn.startswith(self.location)
            ):
                continue
            issue_warning(
                ""Module %s was already imported from %s, but %s is being added""
                "" to sys.path"" % (modname, fn, self.location),
            )

    def has_version(self):
        try:
            self.version
        except ValueError:
            issue_warning(""Unbuilt egg for "" + repr(self))
            return False
        except SystemError:
            
            return False
        return True

    def clone(self, **kw: str | int | IResourceProvider | None):
        
        names = 'project_name version py_version platform location precedence'
        for attr in names.split():
            kw.setdefault(attr, getattr(self, attr, None))
        kw.setdefault('metadata', self._provider)
        
        return self.__class__(**kw)  

    @property
    def extras(self):
        return [dep for dep in self._dep_map if dep]


class EggInfoDistribution(Distribution):
    def _reload_version(self):
        
        md_version = self._get_version()
        if md_version:
            self._version = md_version
        return self


class DistInfoDistribution(Distribution):
    

    PKG_INFO = 'METADATA'
    EQEQ = re.compile(r""([\(,])\s*(\d.*?)\s*([,\)])"")

    @property
    def _parsed_pkg_info(self):
        
        try:
            return self._pkg_info
        except AttributeError:
            metadata = self.get_metadata(self.PKG_INFO)
            self._pkg_info = email.parser.Parser().parsestr(metadata)
            return self._pkg_info

    @property
    def _dep_map(self):
        try:
            return self.__dep_map
        except AttributeError:
            self.__dep_map = self._compute_dependencies()
            return self.__dep_map

    def _compute_dependencies(self) -> dict[str | None, list[Requirement]]:
        
        self.__dep_map: dict[str | None, list[Requirement]] = {None: []}

        reqs: list[Requirement] = []
        
        for req in self._parsed_pkg_info.get_all('Requires-Dist') or []:
            reqs.extend(parse_requirements(req))

        def reqs_for_extra(extra):
            for req in reqs:
                if not req.marker or req.marker.evaluate({'extra': extra}):
                    yield req

        common = types.MappingProxyType(dict.fromkeys(reqs_for_extra(None)))
        self.__dep_map[None].extend(common)

        for extra in self._parsed_pkg_info.get_all('Provides-Extra') or []:
            s_extra = safe_extra(extra.strip())
            self.__dep_map[s_extra] = [
                r for r in reqs_for_extra(extra) if r not in common
            ]

        return self.__dep_map


_distributionImpl = {
    '.egg': Distribution,
    '.egg-info': EggInfoDistribution,
    '.dist-info': DistInfoDistribution,
}


def issue_warning(*args, **kw):
    level = 1
    g = globals()
    try:
        
        
        while sys._getframe(level).f_globals is g:
            level += 1
    except ValueError:
        pass
    warnings.warn(stacklevel=level + 1, *args, **kw)


def parse_requirements(strs: _NestedStr):
    
    return map(Requirement, join_continuation(map(drop_comment, yield_lines(strs))))


class RequirementParseError(_packaging_requirements.InvalidRequirement):
    ""Compatibility wrapper for InvalidRequirement""


class Requirement(_packaging_requirements.Requirement):
    def __init__(self, requirement_string: str):
        
        super().__init__(requirement_string)
        self.unsafe_name = self.name
        project_name = safe_name(self.name)
        self.project_name, self.key = project_name, project_name.lower()
        self.specs = [(spec.operator, spec.version) for spec in self.specifier]
        
        self.extras: tuple[str] = tuple(map(safe_extra, self.extras))
        self.hashCmp = (
            self.key,
            self.url,
            self.specifier,
            frozenset(self.extras),
            str(self.marker) if self.marker else None,
        )
        self.__hash = hash(self.hashCmp)

    def __eq__(self, other: object):
        return isinstance(other, Requirement) and self.hashCmp == other.hashCmp

    def __ne__(self, other):
        return not self == other

    def __contains__(self, item: Distribution | str | tuple[str, ...]) -> bool:
        if isinstance(item, Distribution):
            if item.key != self.key:
                return False

            item = item.version

        
        
        
        return self.specifier.contains(item, prereleases=True)

    def __hash__(self):
        return self.__hash

    def __repr__(self):
        return ""Requirement.parse(%r)"" % str(self)

    @staticmethod
    def parse(s: str | Iterable[str]):
        (req,) = parse_requirements(s)
        return req


def _always_object(classes):
    
    if object not in classes:
        return classes + (object,)
    return classes


def _find_adapter(registry: Mapping[type, _AdapterT], ob: object) -> _AdapterT:
    
    types = _always_object(inspect.getmro(getattr(ob, '__class__', type(ob))))
    for t in types:
        if t in registry:
            return registry[t]
    
    
    raise TypeError(f""Could not find adapter for {registry} and {ob}"")


def ensure_directory(path: StrOrBytesPath):
    
    dirname = os.path.dirname(path)
    os.makedirs(dirname, exist_ok=True)


def _bypass_ensure_directory(path):
    
    if not WRITE_SUPPORT:
        raise OSError('""os.mkdir"" not supported on this platform.')
    dirname, filename = split(path)
    if dirname and filename and not isdir(dirname):
        _bypass_ensure_directory(dirname)
        try:
            mkdir(dirname, 0o755)
        except FileExistsError:
            pass


def split_sections(s: _NestedStr) -> Iterator[tuple[str | None, list[str]]]:
    
    section = None
    content = []
    for line in yield_lines(s):
        if line.startswith(""[""):
            if line.endswith(""]""):
                if section or content:
                    yield section, content
                section = line[1:-1].strip()
                content = []
            else:
                raise ValueError(""Invalid section heading"", line)
        else:
            content.append(line)

    
    yield section, content


def _mkstemp(*args, **kw):
    old_open = os.open
    try:
        
        os.open = os_open
        return tempfile.mkstemp(*args, **kw)
    finally:
        
        os.open = old_open






warnings.filterwarnings(""ignore"", category=PEP440Warning, append=True)


class PkgResourcesDeprecationWarning(Warning):
    



_LOCALE_ENCODING = ""locale"" if sys.version_info >= (3, 10) else None


def _read_utf8_with_fallback(file: str, fallback_encoding=_LOCALE_ENCODING) -> str:
    
    try:
        with open(file, ""r"", encoding=""utf-8"") as f:
            return f.read()
    except UnicodeDecodeError:  
        msg = f
        
        
        warnings.warn(msg, PkgResourcesDeprecationWarning, stacklevel=2)
        with open(file, ""r"", encoding=fallback_encoding) as f:
            return f.read()



def _call_aside(f, *args, **kwargs):
    f(*args, **kwargs)
    return f


@_call_aside
def _initialize(g=globals()):
    ""Set up global resource manager (deliberately not state-saved)""
    manager = ResourceManager()
    g['_manager'] = manager
    g.update(
        (name, getattr(manager, name))
        for name in dir(manager)
        if not name.startswith('_')
    )


@_call_aside
def _initialize_master_working_set():
    
    working_set = _declare_state('object', 'working_set', WorkingSet._build_master())

    require = working_set.require
    iter_entry_points = working_set.iter_entry_points
    add_activation_listener = working_set.subscribe
    run_script = working_set.run_script
    
    run_main = run_script
    
    
    
    
    tuple(dist.activate(replace=False) for dist in working_set)
    add_activation_listener(
        lambda dist: dist.activate(replace=True),
        existing=False,
    )
    working_set.entries = []
    
    list(map(working_set.add_entry, sys.path))
    globals().update(locals())


if TYPE_CHECKING:
    
    __resource_manager = ResourceManager()  
    resource_exists = __resource_manager.resource_exists
    resource_isdir = __resource_manager.resource_isdir
    resource_filename = __resource_manager.resource_filename
    resource_stream = __resource_manager.resource_stream
    resource_string = __resource_manager.resource_string
    resource_listdir = __resource_manager.resource_listdir
    set_extraction_path = __resource_manager.set_extraction_path
    cleanup_resources = __resource_manager.cleanup_resources

    working_set = WorkingSet()
    require = working_set.require
    iter_entry_points = working_set.iter_entry_points
    add_activation_listener = working_set.subscribe
    run_script = working_set.run_script
    run_main = run_script



from __future__ import annotations

import os
import re
import sys
from functools import lru_cache
from typing import TYPE_CHECKING, cast

from .api import PlatformDirsABC


class Android(PlatformDirsABC):
    

    @property
    def user_data_dir(self) -> str:
        
        return self._append_app_name_and_version(cast(""str"", _android_folder()), ""files"")

    @property
    def site_data_dir(self) -> str:
        
        return self.user_data_dir

    @property
    def user_config_dir(self) -> str:
        
        return self._append_app_name_and_version(cast(""str"", _android_folder()), ""shared_prefs"")

    @property
    def site_config_dir(self) -> str:
        
        return self.user_config_dir

    @property
    def user_cache_dir(self) -> str:
        
        return self._append_app_name_and_version(cast(""str"", _android_folder()), ""cache"")

    @property
    def site_cache_dir(self) -> str:
        
        return self.user_cache_dir

    @property
    def user_state_dir(self) -> str:
        
        return self.user_data_dir

    @property
    def user_log_dir(self) -> str:
        
        path = self.user_cache_dir
        if self.opinion:
            path = os.path.join(path, ""log"")  
        return path

    @property
    def user_documents_dir(self) -> str:
        
        return _android_documents_folder()

    @property
    def user_downloads_dir(self) -> str:
        
        return _android_downloads_folder()

    @property
    def user_pictures_dir(self) -> str:
        
        return _android_pictures_folder()

    @property
    def user_videos_dir(self) -> str:
        
        return _android_videos_folder()

    @property
    def user_music_dir(self) -> str:
        
        return _android_music_folder()

    @property
    def user_desktop_dir(self) -> str:
        
        return ""/storage/emulated/0/Desktop""

    @property
    def user_runtime_dir(self) -> str:
        
        path = self.user_cache_dir
        if self.opinion:
            path = os.path.join(path, ""tmp"")  
        return path

    @property
    def site_runtime_dir(self) -> str:
        
        return self.user_runtime_dir


@lru_cache(maxsize=1)
def _android_folder() -> str | None:  
    
    result: str | None = None
    
    
    if not TYPE_CHECKING:
        try:
            
            from android import mActivity  

            context = cast(""android.content.Context"", mActivity.getApplicationContext())  
            result = context.getFilesDir().getParentFile().getAbsolutePath()
        except Exception:  
            result = None
    if result is None:
        try:
            
            
            from jnius import autoclass  

            context = autoclass(""android.content.Context"")
            result = context.getFilesDir().getParentFile().getAbsolutePath()
        except Exception:  
            result = None
    if result is None:
        
        
        pattern = re.compile(r""/data/(data|user/\d+)/(.+)/files"")
        for path in sys.path:
            if pattern.match(path):
                result = path.split(""/files"")[0]
                break
        else:
            result = None
    if result is None:
        
        
        pattern = re.compile(r""/mnt/expand/[a-fA-F0-9-]{36}/(data|user/\d+)/(.+)/files"")
        for path in sys.path:
            if pattern.match(path):
                result = path.split(""/files"")[0]
                break
        else:
            result = None
    return result


@lru_cache(maxsize=1)
def _android_documents_folder() -> str:
    
    
    try:
        from jnius import autoclass  

        context = autoclass(""android.content.Context"")
        environment = autoclass(""android.os.Environment"")
        documents_dir: str = context.getExternalFilesDir(environment.DIRECTORY_DOCUMENTS).getAbsolutePath()
    except Exception:  
        documents_dir = ""/storage/emulated/0/Documents""

    return documents_dir


@lru_cache(maxsize=1)
def _android_downloads_folder() -> str:
    
    
    try:
        from jnius import autoclass  

        context = autoclass(""android.content.Context"")
        environment = autoclass(""android.os.Environment"")
        downloads_dir: str = context.getExternalFilesDir(environment.DIRECTORY_DOWNLOADS).getAbsolutePath()
    except Exception:  
        downloads_dir = ""/storage/emulated/0/Downloads""

    return downloads_dir


@lru_cache(maxsize=1)
def _android_pictures_folder() -> str:
    
    
    try:
        from jnius import autoclass  

        context = autoclass(""android.content.Context"")
        environment = autoclass(""android.os.Environment"")
        pictures_dir: str = context.getExternalFilesDir(environment.DIRECTORY_PICTURES).getAbsolutePath()
    except Exception:  
        pictures_dir = ""/storage/emulated/0/Pictures""

    return pictures_dir


@lru_cache(maxsize=1)
def _android_videos_folder() -> str:
    
    
    try:
        from jnius import autoclass  

        context = autoclass(""android.content.Context"")
        environment = autoclass(""android.os.Environment"")
        videos_dir: str = context.getExternalFilesDir(environment.DIRECTORY_DCIM).getAbsolutePath()
    except Exception:  
        videos_dir = ""/storage/emulated/0/DCIM/Camera""

    return videos_dir


@lru_cache(maxsize=1)
def _android_music_folder() -> str:
    
    
    try:
        from jnius import autoclass  

        context = autoclass(""android.content.Context"")
        environment = autoclass(""android.os.Environment"")
        music_dir: str = context.getExternalFilesDir(environment.DIRECTORY_MUSIC).getAbsolutePath()
    except Exception:  
        music_dir = ""/storage/emulated/0/Music""

    return music_dir


__all__ = [
    ""Android"",
]



from __future__ import annotations

import os
from abc import ABC, abstractmethod
from pathlib import Path
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from collections.abc import Iterator
    from typing import Literal


class PlatformDirsABC(ABC):  
    

    def __init__(  
        self,
        appname: str | None = None,
        appauthor: str | Literal[False] | None = None,
        version: str | None = None,
        roaming: bool = False,  
        multipath: bool = False,  
        opinion: bool = True,  
        ensure_exists: bool = False,  
    ) -> None:
        
        self.appname = appname  
        self.appauthor = appauthor
        
        self.version = version
        
        self.roaming = roaming
        
        self.multipath = multipath
        
        self.opinion = opinion  
        self.ensure_exists = ensure_exists
        

    def _append_app_name_and_version(self, *base: str) -> str:
        params = list(base[1:])
        if self.appname:
            params.append(self.appname)
            if self.version:
                params.append(self.version)
        path = os.path.join(base[0], *params)  
        self._optionally_create_directory(path)
        return path

    def _optionally_create_directory(self, path: str) -> None:
        if self.ensure_exists:
            Path(path).mkdir(parents=True, exist_ok=True)

    def _first_item_as_path_if_multipath(self, directory: str) -> Path:
        if self.multipath:
            
            directory = directory.split(os.pathsep)[0]
        return Path(directory)

    @property
    @abstractmethod
    def user_data_dir(self) -> str:
        

    @property
    @abstractmethod
    def site_data_dir(self) -> str:
        

    @property
    @abstractmethod
    def user_config_dir(self) -> str:
        

    @property
    @abstractmethod
    def site_config_dir(self) -> str:
        

    @property
    @abstractmethod
    def user_cache_dir(self) -> str:
        

    @property
    @abstractmethod
    def site_cache_dir(self) -> str:
        

    @property
    @abstractmethod
    def user_state_dir(self) -> str:
        

    @property
    @abstractmethod
    def user_log_dir(self) -> str:
        

    @property
    @abstractmethod
    def user_documents_dir(self) -> str:
        

    @property
    @abstractmethod
    def user_downloads_dir(self) -> str:
        

    @property
    @abstractmethod
    def user_pictures_dir(self) -> str:
        

    @property
    @abstractmethod
    def user_videos_dir(self) -> str:
        

    @property
    @abstractmethod
    def user_music_dir(self) -> str:
        

    @property
    @abstractmethod
    def user_desktop_dir(self) -> str:
        

    @property
    @abstractmethod
    def user_runtime_dir(self) -> str:
        

    @property
    @abstractmethod
    def site_runtime_dir(self) -> str:
        

    @property
    def user_data_path(self) -> Path:
        
        return Path(self.user_data_dir)

    @property
    def site_data_path(self) -> Path:
        
        return Path(self.site_data_dir)

    @property
    def user_config_path(self) -> Path:
        
        return Path(self.user_config_dir)

    @property
    def site_config_path(self) -> Path:
        
        return Path(self.site_config_dir)

    @property
    def user_cache_path(self) -> Path:
        
        return Path(self.user_cache_dir)

    @property
    def site_cache_path(self) -> Path:
        
        return Path(self.site_cache_dir)

    @property
    def user_state_path(self) -> Path:
        
        return Path(self.user_state_dir)

    @property
    def user_log_path(self) -> Path:
        
        return Path(self.user_log_dir)

    @property
    def user_documents_path(self) -> Path:
        
        return Path(self.user_documents_dir)

    @property
    def user_downloads_path(self) -> Path:
        
        return Path(self.user_downloads_dir)

    @property
    def user_pictures_path(self) -> Path:
        
        return Path(self.user_pictures_dir)

    @property
    def user_videos_path(self) -> Path:
        
        return Path(self.user_videos_dir)

    @property
    def user_music_path(self) -> Path:
        
        return Path(self.user_music_dir)

    @property
    def user_desktop_path(self) -> Path:
        
        return Path(self.user_desktop_dir)

    @property
    def user_runtime_path(self) -> Path:
        
        return Path(self.user_runtime_dir)

    @property
    def site_runtime_path(self) -> Path:
        
        return Path(self.site_runtime_dir)

    def iter_config_dirs(self) -> Iterator[str]:
        
        yield self.user_config_dir
        yield self.site_config_dir

    def iter_data_dirs(self) -> Iterator[str]:
        
        yield self.user_data_dir
        yield self.site_data_dir

    def iter_cache_dirs(self) -> Iterator[str]:
        
        yield self.user_cache_dir
        yield self.site_cache_dir

    def iter_runtime_dirs(self) -> Iterator[str]:
        
        yield self.user_runtime_dir
        yield self.site_runtime_dir

    def iter_config_paths(self) -> Iterator[Path]:
        
        for path in self.iter_config_dirs():
            yield Path(path)

    def iter_data_paths(self) -> Iterator[Path]:
        
        for path in self.iter_data_dirs():
            yield Path(path)

    def iter_cache_paths(self) -> Iterator[Path]:
        
        for path in self.iter_cache_dirs():
            yield Path(path)

    def iter_runtime_paths(self) -> Iterator[Path]:
        
        for path in self.iter_runtime_dirs():
            yield Path(path)



from __future__ import annotations

import os.path
import sys
from typing import TYPE_CHECKING

from .api import PlatformDirsABC

if TYPE_CHECKING:
    from pathlib import Path


class MacOS(PlatformDirsABC):
    

    @property
    def user_data_dir(self) -> str:
        
        return self._append_app_name_and_version(os.path.expanduser(""~/Library/Application Support""))  

    @property
    def site_data_dir(self) -> str:
        
        is_homebrew = sys.prefix.startswith(""/opt/homebrew"")
        path_list = [self._append_app_name_and_version(""/opt/homebrew/share"")] if is_homebrew else []
        path_list.append(self._append_app_name_and_version(""/Library/Application Support""))
        if self.multipath:
            return os.pathsep.join(path_list)
        return path_list[0]

    @property
    def site_data_path(self) -> Path:
        
        return self._first_item_as_path_if_multipath(self.site_data_dir)

    @property
    def user_config_dir(self) -> str:
        
        return self.user_data_dir

    @property
    def site_config_dir(self) -> str:
        
        return self.site_data_dir

    @property
    def user_cache_dir(self) -> str:
        
        return self._append_app_name_and_version(os.path.expanduser(""~/Library/Caches""))  

    @property
    def site_cache_dir(self) -> str:
        
        is_homebrew = sys.prefix.startswith(""/opt/homebrew"")
        path_list = [self._append_app_name_and_version(""/opt/homebrew/var/cache"")] if is_homebrew else []
        path_list.append(self._append_app_name_and_version(""/Library/Caches""))
        if self.multipath:
            return os.pathsep.join(path_list)
        return path_list[0]

    @property
    def site_cache_path(self) -> Path:
        
        return self._first_item_as_path_if_multipath(self.site_cache_dir)

    @property
    def user_state_dir(self) -> str:
        
        return self.user_data_dir

    @property
    def user_log_dir(self) -> str:
        
        return self._append_app_name_and_version(os.path.expanduser(""~/Library/Logs""))  

    @property
    def user_documents_dir(self) -> str:
        
        return os.path.expanduser(""~/Documents"")  

    @property
    def user_downloads_dir(self) -> str:
        
        return os.path.expanduser(""~/Downloads"")  

    @property
    def user_pictures_dir(self) -> str:
        
        return os.path.expanduser(""~/Pictures"")  

    @property
    def user_videos_dir(self) -> str:
        
        return os.path.expanduser(""~/Movies"")  

    @property
    def user_music_dir(self) -> str:
        
        return os.path.expanduser(""~/Music"")  

    @property
    def user_desktop_dir(self) -> str:
        
        return os.path.expanduser(""~/Desktop"")  

    @property
    def user_runtime_dir(self) -> str:
        
        return self._append_app_name_and_version(os.path.expanduser(""~/Library/Caches/TemporaryItems""))  

    @property
    def site_runtime_dir(self) -> str:
        
        return self.user_runtime_dir


__all__ = [
    ""MacOS"",
]



from __future__ import annotations

import os
import sys
from configparser import ConfigParser
from pathlib import Path
from typing import TYPE_CHECKING, NoReturn

from .api import PlatformDirsABC

if TYPE_CHECKING:
    from collections.abc import Iterator

if sys.platform == ""win32"":

    def getuid() -> NoReturn:
        msg = ""should only be used on Unix""
        raise RuntimeError(msg)

else:
    from os import getuid


class Unix(PlatformDirsABC):  
    

    @property
    def user_data_dir(self) -> str:
        
        path = os.environ.get(""XDG_DATA_HOME"", """")
        if not path.strip():
            path = os.path.expanduser(""~/.local/share"")  
        return self._append_app_name_and_version(path)

    @property
    def _site_data_dirs(self) -> list[str]:
        path = os.environ.get(""XDG_DATA_DIRS"", """")
        if not path.strip():
            path = f""/usr/local/share{os.pathsep}/usr/share""
        return [self._append_app_name_and_version(p) for p in path.split(os.pathsep)]

    @property
    def site_data_dir(self) -> str:
        
        
        dirs = self._site_data_dirs
        if not self.multipath:
            return dirs[0]
        return os.pathsep.join(dirs)

    @property
    def user_config_dir(self) -> str:
        
        path = os.environ.get(""XDG_CONFIG_HOME"", """")
        if not path.strip():
            path = os.path.expanduser(""~/.config"")  
        return self._append_app_name_and_version(path)

    @property
    def _site_config_dirs(self) -> list[str]:
        path = os.environ.get(""XDG_CONFIG_DIRS"", """")
        if not path.strip():
            path = ""/etc/xdg""
        return [self._append_app_name_and_version(p) for p in path.split(os.pathsep)]

    @property
    def site_config_dir(self) -> str:
        
        
        dirs = self._site_config_dirs
        if not self.multipath:
            return dirs[0]
        return os.pathsep.join(dirs)

    @property
    def user_cache_dir(self) -> str:
        
        path = os.environ.get(""XDG_CACHE_HOME"", """")
        if not path.strip():
            path = os.path.expanduser(""~/.cache"")  
        return self._append_app_name_and_version(path)

    @property
    def site_cache_dir(self) -> str:
        
        return self._append_app_name_and_version(""/var/cache"")

    @property
    def user_state_dir(self) -> str:
        
        path = os.environ.get(""XDG_STATE_HOME"", """")
        if not path.strip():
            path = os.path.expanduser(""~/.local/state"")  
        return self._append_app_name_and_version(path)

    @property
    def user_log_dir(self) -> str:
        
        path = self.user_state_dir
        if self.opinion:
            path = os.path.join(path, ""log"")  
            self._optionally_create_directory(path)
        return path

    @property
    def user_documents_dir(self) -> str:
        
        return _get_user_media_dir(""XDG_DOCUMENTS_DIR"", ""~/Documents"")

    @property
    def user_downloads_dir(self) -> str:
        
        return _get_user_media_dir(""XDG_DOWNLOAD_DIR"", ""~/Downloads"")

    @property
    def user_pictures_dir(self) -> str:
        
        return _get_user_media_dir(""XDG_PICTURES_DIR"", ""~/Pictures"")

    @property
    def user_videos_dir(self) -> str:
        
        return _get_user_media_dir(""XDG_VIDEOS_DIR"", ""~/Videos"")

    @property
    def user_music_dir(self) -> str:
        
        return _get_user_media_dir(""XDG_MUSIC_DIR"", ""~/Music"")

    @property
    def user_desktop_dir(self) -> str:
        
        return _get_user_media_dir(""XDG_DESKTOP_DIR"", ""~/Desktop"")

    @property
    def user_runtime_dir(self) -> str:
        
        path = os.environ.get(""XDG_RUNTIME_DIR"", """")
        if not path.strip():
            if sys.platform.startswith((""freebsd"", ""openbsd"", ""netbsd"")):
                path = f""/var/run/user/{getuid()}""
                if not Path(path).exists():
                    path = f""/tmp/runtime-{getuid()}""  
            else:
                path = f""/run/user/{getuid()}""
        return self._append_app_name_and_version(path)

    @property
    def site_runtime_dir(self) -> str:
        
        path = os.environ.get(""XDG_RUNTIME_DIR"", """")
        if not path.strip():
            if sys.platform.startswith((""freebsd"", ""openbsd"", ""netbsd"")):
                path = ""/var/run""
            else:
                path = ""/run""
        return self._append_app_name_and_version(path)

    @property
    def site_data_path(self) -> Path:
        
        return self._first_item_as_path_if_multipath(self.site_data_dir)

    @property
    def site_config_path(self) -> Path:
        
        return self._first_item_as_path_if_multipath(self.site_config_dir)

    @property
    def site_cache_path(self) -> Path:
        
        return self._first_item_as_path_if_multipath(self.site_cache_dir)

    def iter_config_dirs(self) -> Iterator[str]:
        
        yield self.user_config_dir
        yield from self._site_config_dirs

    def iter_data_dirs(self) -> Iterator[str]:
        
        yield self.user_data_dir
        yield from self._site_data_dirs


def _get_user_media_dir(env_var: str, fallback_tilde_path: str) -> str:
    media_dir = _get_user_dirs_folder(env_var)
    if media_dir is None:
        media_dir = os.environ.get(env_var, """").strip()
        if not media_dir:
            media_dir = os.path.expanduser(fallback_tilde_path)  

    return media_dir


def _get_user_dirs_folder(key: str) -> str | None:
    
    user_dirs_config_path = Path(Unix().user_config_dir) / ""user-dirs.dirs""
    if user_dirs_config_path.exists():
        parser = ConfigParser()

        with user_dirs_config_path.open() as stream:
            
            parser.read_string(f""[top]\n{stream.read()}"")

        if key not in parser[""top""]:
            return None

        path = parser[""top""][key].strip('""')
        
        return path.replace(""$HOME"", os.path.expanduser(""~""))  

    return None


__all__ = [
    ""Unix"",
]




__all__ = [""__version__"", ""__version_tuple__"", ""version"", ""version_tuple""]

TYPE_CHECKING = False
if TYPE_CHECKING:
    from typing import Tuple
    from typing import Union

    VERSION_TUPLE = Tuple[Union[int, str], ...]
else:
    VERSION_TUPLE = object

version: str
__version__: str
__version_tuple__: VERSION_TUPLE
version_tuple: VERSION_TUPLE

__version__ = version = '4.3.8'
__version_tuple__ = version_tuple = (4, 3, 8)



from __future__ import annotations

import os
import sys
from functools import lru_cache
from typing import TYPE_CHECKING

from .api import PlatformDirsABC

if TYPE_CHECKING:
    from collections.abc import Callable


class Windows(PlatformDirsABC):
    

    @property
    def user_data_dir(self) -> str:
        
        const = ""CSIDL_APPDATA"" if self.roaming else ""CSIDL_LOCAL_APPDATA""
        path = os.path.normpath(get_win_folder(const))
        return self._append_parts(path)

    def _append_parts(self, path: str, *, opinion_value: str | None = None) -> str:
        params = []
        if self.appname:
            if self.appauthor is not False:
                author = self.appauthor or self.appname
                params.append(author)
            params.append(self.appname)
            if opinion_value is not None and self.opinion:
                params.append(opinion_value)
            if self.version:
                params.append(self.version)
        path = os.path.join(path, *params)  
        self._optionally_create_directory(path)
        return path

    @property
    def site_data_dir(self) -> str:
        
        path = os.path.normpath(get_win_folder(""CSIDL_COMMON_APPDATA""))
        return self._append_parts(path)

    @property
    def user_config_dir(self) -> str:
        
        return self.user_data_dir

    @property
    def site_config_dir(self) -> str:
        
        return self.site_data_dir

    @property
    def user_cache_dir(self) -> str:
        
        path = os.path.normpath(get_win_folder(""CSIDL_LOCAL_APPDATA""))
        return self._append_parts(path, opinion_value=""Cache"")

    @property
    def site_cache_dir(self) -> str:
        
        path = os.path.normpath(get_win_folder(""CSIDL_COMMON_APPDATA""))
        return self._append_parts(path, opinion_value=""Cache"")

    @property
    def user_state_dir(self) -> str:
        
        return self.user_data_dir

    @property
    def user_log_dir(self) -> str:
        
        path = self.user_data_dir
        if self.opinion:
            path = os.path.join(path, ""Logs"")  
            self._optionally_create_directory(path)
        return path

    @property
    def user_documents_dir(self) -> str:
        
        return os.path.normpath(get_win_folder(""CSIDL_PERSONAL""))

    @property
    def user_downloads_dir(self) -> str:
        
        return os.path.normpath(get_win_folder(""CSIDL_DOWNLOADS""))

    @property
    def user_pictures_dir(self) -> str:
        
        return os.path.normpath(get_win_folder(""CSIDL_MYPICTURES""))

    @property
    def user_videos_dir(self) -> str:
        
        return os.path.normpath(get_win_folder(""CSIDL_MYVIDEO""))

    @property
    def user_music_dir(self) -> str:
        
        return os.path.normpath(get_win_folder(""CSIDL_MYMUSIC""))

    @property
    def user_desktop_dir(self) -> str:
        
        return os.path.normpath(get_win_folder(""CSIDL_DESKTOPDIRECTORY""))

    @property
    def user_runtime_dir(self) -> str:
        
        path = os.path.normpath(os.path.join(get_win_folder(""CSIDL_LOCAL_APPDATA""), ""Temp""))  
        return self._append_parts(path)

    @property
    def site_runtime_dir(self) -> str:
        
        return self.user_runtime_dir


def get_win_folder_from_env_vars(csidl_name: str) -> str:
    
    result = get_win_folder_if_csidl_name_not_env_var(csidl_name)
    if result is not None:
        return result

    env_var_name = {
        ""CSIDL_APPDATA"": ""APPDATA"",
        ""CSIDL_COMMON_APPDATA"": ""ALLUSERSPROFILE"",
        ""CSIDL_LOCAL_APPDATA"": ""LOCALAPPDATA"",
    }.get(csidl_name)
    if env_var_name is None:
        msg = f""Unknown CSIDL name: {csidl_name}""
        raise ValueError(msg)
    result = os.environ.get(env_var_name)
    if result is None:
        msg = f""Unset environment variable: {env_var_name}""
        raise ValueError(msg)
    return result


def get_win_folder_if_csidl_name_not_env_var(csidl_name: str) -> str | None:
    
    if csidl_name == ""CSIDL_PERSONAL"":
        return os.path.join(os.path.normpath(os.environ[""USERPROFILE""]), ""Documents"")  

    if csidl_name == ""CSIDL_DOWNLOADS"":
        return os.path.join(os.path.normpath(os.environ[""USERPROFILE""]), ""Downloads"")  

    if csidl_name == ""CSIDL_MYPICTURES"":
        return os.path.join(os.path.normpath(os.environ[""USERPROFILE""]), ""Pictures"")  

    if csidl_name == ""CSIDL_MYVIDEO"":
        return os.path.join(os.path.normpath(os.environ[""USERPROFILE""]), ""Videos"")  

    if csidl_name == ""CSIDL_MYMUSIC"":
        return os.path.join(os.path.normpath(os.environ[""USERPROFILE""]), ""Music"")  
    return None


def get_win_folder_from_registry(csidl_name: str) -> str:
    
    shell_folder_name = {
        ""CSIDL_APPDATA"": ""AppData"",
        ""CSIDL_COMMON_APPDATA"": ""Common AppData"",
        ""CSIDL_LOCAL_APPDATA"": ""Local AppData"",
        ""CSIDL_PERSONAL"": ""Personal"",
        ""CSIDL_DOWNLOADS"": ""{374DE290-123F-4565-9164-39C4925E467B}"",
        ""CSIDL_MYPICTURES"": ""My Pictures"",
        ""CSIDL_MYVIDEO"": ""My Video"",
        ""CSIDL_MYMUSIC"": ""My Music"",
    }.get(csidl_name)
    if shell_folder_name is None:
        msg = f""Unknown CSIDL name: {csidl_name}""
        raise ValueError(msg)
    if sys.platform != ""win32"":  
        raise NotImplementedError
    import winreg  

    key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, r""Software\Microsoft\Windows\CurrentVersion\Explorer\Shell Folders"")
    directory, _ = winreg.QueryValueEx(key, shell_folder_name)
    return str(directory)


def get_win_folder_via_ctypes(csidl_name: str) -> str:
    
    
    
    

    import ctypes  

    csidl_const = {
        ""CSIDL_APPDATA"": 26,
        ""CSIDL_COMMON_APPDATA"": 35,
        ""CSIDL_LOCAL_APPDATA"": 28,
        ""CSIDL_PERSONAL"": 5,
        ""CSIDL_MYPICTURES"": 39,
        ""CSIDL_MYVIDEO"": 14,
        ""CSIDL_MYMUSIC"": 13,
        ""CSIDL_DOWNLOADS"": 40,
        ""CSIDL_DESKTOPDIRECTORY"": 16,
    }.get(csidl_name)
    if csidl_const is None:
        msg = f""Unknown CSIDL name: {csidl_name}""
        raise ValueError(msg)

    buf = ctypes.create_unicode_buffer(1024)
    windll = getattr(ctypes, ""windll"")  
    windll.shell32.SHGetFolderPathW(None, csidl_const, None, 0, buf)

    
    if any(ord(c) > 255 for c in buf):  
        buf2 = ctypes.create_unicode_buffer(1024)
        if windll.kernel32.GetShortPathNameW(buf.value, buf2, 1024):
            buf = buf2

    if csidl_name == ""CSIDL_DOWNLOADS"":
        return os.path.join(buf.value, ""Downloads"")  

    return buf.value


def _pick_get_win_folder() -> Callable[[str], str]:
    try:
        import ctypes  
    except ImportError:
        pass
    else:
        if hasattr(ctypes, ""windll""):
            return get_win_folder_via_ctypes
    try:
        import winreg  
    except ImportError:
        return get_win_folder_from_env_vars
    else:
        return get_win_folder_from_registry


get_win_folder = lru_cache(maxsize=None)(_pick_get_win_folder())

__all__ = [
    ""Windows"",
]



from __future__ import annotations

import os
import sys
from typing import TYPE_CHECKING

from .api import PlatformDirsABC
from .version import __version__
from .version import __version_tuple__ as __version_info__

if TYPE_CHECKING:
    from pathlib import Path
    from typing import Literal

if sys.platform == ""win32"":
    from pip._vendor.platformdirs.windows import Windows as _Result
elif sys.platform == ""darwin"":
    from pip._vendor.platformdirs.macos import MacOS as _Result
else:
    from pip._vendor.platformdirs.unix import Unix as _Result


def _set_platform_dir_class() -> type[PlatformDirsABC]:
    if os.getenv(""ANDROID_DATA"") == ""/data"" and os.getenv(""ANDROID_ROOT"") == ""/system"":
        if os.getenv(""SHELL"") or os.getenv(""PREFIX""):
            return _Result

        from pip._vendor.platformdirs.android import _android_folder  

        if _android_folder() is not None:
            from pip._vendor.platformdirs.android import Android  

            return Android  

    return _Result


if TYPE_CHECKING:
    
    PlatformDirs = _Result
else:
    PlatformDirs = _set_platform_dir_class()  
AppDirs = PlatformDirs  


def user_data_dir(
    appname: str | None = None,
    appauthor: str | Literal[False] | None = None,
    version: str | None = None,
    roaming: bool = False,  
    ensure_exists: bool = False,  
) -> str:
    
    return PlatformDirs(
        appname=appname,
        appauthor=appauthor,
        version=version,
        roaming=roaming,
        ensure_exists=ensure_exists,
    ).user_data_dir


def site_data_dir(
    appname: str | None = None,
    appauthor: str | Literal[False] | None = None,
    version: str | None = None,
    multipath: bool = False,  
    ensure_exists: bool = False,  
) -> str:
    
    return PlatformDirs(
        appname=appname,
        appauthor=appauthor,
        version=version,
        multipath=multipath,
        ensure_exists=ensure_exists,
    ).site_data_dir


def user_config_dir(
    appname: str | None = None,
    appauthor: str | Literal[False] | None = None,
    version: str | None = None,
    roaming: bool = False,  
    ensure_exists: bool = False,  
) -> str:
    
    return PlatformDirs(
        appname=appname,
        appauthor=appauthor,
        version=version,
        roaming=roaming,
        ensure_exists=ensure_exists,
    ).user_config_dir


def site_config_dir(
    appname: str | None = None,
    appauthor: str | Literal[False] | None = None,
    version: str | None = None,
    multipath: bool = False,  
    ensure_exists: bool = False,  
) -> str:
    
    return PlatformDirs(
        appname=appname,
        appauthor=appauthor,
        version=version,
        multipath=multipath,
        ensure_exists=ensure_exists,
    ).site_config_dir


def user_cache_dir(
    appname: str | None = None,
    appauthor: str | Literal[False] | None = None,
    version: str | None = None,
    opinion: bool = True,  
    ensure_exists: bool = False,  
) -> str:
    
    return PlatformDirs(
        appname=appname,
        appauthor=appauthor,
        version=version,
        opinion=opinion,
        ensure_exists=ensure_exists,
    ).user_cache_dir


def site_cache_dir(
    appname: str | None = None,
    appauthor: str | Literal[False] | None = None,
    version: str | None = None,
    opinion: bool = True,  
    ensure_exists: bool = False,  
) -> str:
    
    return PlatformDirs(
        appname=appname,
        appauthor=appauthor,
        version=version,
        opinion=opinion,
        ensure_exists=ensure_exists,
    ).site_cache_dir


def user_state_dir(
    appname: str | None = None,
    appauthor: str | Literal[False] | None = None,
    version: str | None = None,
    roaming: bool = False,  
    ensure_exists: bool = False,  
) -> str:
    
    return PlatformDirs(
        appname=appname,
        appauthor=appauthor,
        version=version,
        roaming=roaming,
        ensure_exists=ensure_exists,
    ).user_state_dir


def user_log_dir(
    appname: str | None = None,
    appauthor: str | Literal[False] | None = None,
    version: str | None = None,
    opinion: bool = True,  
    ensure_exists: bool = False,  
) -> str:
    
    return PlatformDirs(
        appname=appname,
        appauthor=appauthor,
        version=version,
        opinion=opinion,
        ensure_exists=ensure_exists,
    ).user_log_dir


def user_documents_dir() -> str:
    
    return PlatformDirs().user_documents_dir


def user_downloads_dir() -> str:
    
    return PlatformDirs().user_downloads_dir


def user_pictures_dir() -> str:
    
    return PlatformDirs().user_pictures_dir


def user_videos_dir() -> str:
    
    return PlatformDirs().user_videos_dir


def user_music_dir() -> str:
    
    return PlatformDirs().user_music_dir


def user_desktop_dir() -> str:
    
    return PlatformDirs().user_desktop_dir


def user_runtime_dir(
    appname: str | None = None,
    appauthor: str | Literal[False] | None = None,
    version: str | None = None,
    opinion: bool = True,  
    ensure_exists: bool = False,  
) -> str:
    
    return PlatformDirs(
        appname=appname,
        appauthor=appauthor,
        version=version,
        opinion=opinion,
        ensure_exists=ensure_exists,
    ).user_runtime_dir


def site_runtime_dir(
    appname: str | None = None,
    appauthor: str | Literal[False] | None = None,
    version: str | None = None,
    opinion: bool = True,  
    ensure_exists: bool = False,  
) -> str:
    
    return PlatformDirs(
        appname=appname,
        appauthor=appauthor,
        version=version,
        opinion=opinion,
        ensure_exists=ensure_exists,
    ).site_runtime_dir


def user_data_path(
    appname: str | None = None,
    appauthor: str | Literal[False] | None = None,
    version: str | None = None,
    roaming: bool = False,  
    ensure_exists: bool = False,  
) -> Path:
    
    return PlatformDirs(
        appname=appname,
        appauthor=appauthor,
        version=version,
        roaming=roaming,
        ensure_exists=ensure_exists,
    ).user_data_path


def site_data_path(
    appname: str | None = None,
    appauthor: str | Literal[False] | None = None,
    version: str | None = None,
    multipath: bool = False,  
    ensure_exists: bool = False,  
) -> Path:
    
    return PlatformDirs(
        appname=appname,
        appauthor=appauthor,
        version=version,
        multipath=multipath,
        ensure_exists=ensure_exists,
    ).site_data_path


def user_config_path(
    appname: str | None = None,
    appauthor: str | Literal[False] | None = None,
    version: str | None = None,
    roaming: bool = False,  
    ensure_exists: bool = False,  
) -> Path:
    
    return PlatformDirs(
        appname=appname,
        appauthor=appauthor,
        version=version,
        roaming=roaming,
        ensure_exists=ensure_exists,
    ).user_config_path


def site_config_path(
    appname: str | None = None,
    appauthor: str | Literal[False] | None = None,
    version: str | None = None,
    multipath: bool = False,  
    ensure_exists: bool = False,  
) -> Path:
    
    return PlatformDirs(
        appname=appname,
        appauthor=appauthor,
        version=version,
        multipath=multipath,
        ensure_exists=ensure_exists,
    ).site_config_path


def site_cache_path(
    appname: str | None = None,
    appauthor: str | Literal[False] | None = None,
    version: str | None = None,
    opinion: bool = True,  
    ensure_exists: bool = False,  
) -> Path:
    
    return PlatformDirs(
        appname=appname,
        appauthor=appauthor,
        version=version,
        opinion=opinion,
        ensure_exists=ensure_exists,
    ).site_cache_path


def user_cache_path(
    appname: str | None = None,
    appauthor: str | Literal[False] | None = None,
    version: str | None = None,
    opinion: bool = True,  
    ensure_exists: bool = False,  
) -> Path:
    
    return PlatformDirs(
        appname=appname,
        appauthor=appauthor,
        version=version,
        opinion=opinion,
        ensure_exists=ensure_exists,
    ).user_cache_path


def user_state_path(
    appname: str | None = None,
    appauthor: str | Literal[False] | None = None,
    version: str | None = None,
    roaming: bool = False,  
    ensure_exists: bool = False,  
) -> Path:
    
    return PlatformDirs(
        appname=appname,
        appauthor=appauthor,
        version=version,
        roaming=roaming,
        ensure_exists=ensure_exists,
    ).user_state_path


def user_log_path(
    appname: str | None = None,
    appauthor: str | Literal[False] | None = None,
    version: str | None = None,
    opinion: bool = True,  
    ensure_exists: bool = False,  
) -> Path:
    
    return PlatformDirs(
        appname=appname,
        appauthor=appauthor,
        version=version,
        opinion=opinion,
        ensure_exists=ensure_exists,
    ).user_log_path


def user_documents_path() -> Path:
    
    return PlatformDirs().user_documents_path


def user_downloads_path() -> Path:
    
    return PlatformDirs().user_downloads_path


def user_pictures_path() -> Path:
    
    return PlatformDirs().user_pictures_path


def user_videos_path() -> Path:
    
    return PlatformDirs().user_videos_path


def user_music_path() -> Path:
    
    return PlatformDirs().user_music_path


def user_desktop_path() -> Path:
    
    return PlatformDirs().user_desktop_path


def user_runtime_path(
    appname: str | None = None,
    appauthor: str | Literal[False] | None = None,
    version: str | None = None,
    opinion: bool = True,  
    ensure_exists: bool = False,  
) -> Path:
    
    return PlatformDirs(
        appname=appname,
        appauthor=appauthor,
        version=version,
        opinion=opinion,
        ensure_exists=ensure_exists,
    ).user_runtime_path


def site_runtime_path(
    appname: str | None = None,
    appauthor: str | Literal[False] | None = None,
    version: str | None = None,
    opinion: bool = True,  
    ensure_exists: bool = False,  
) -> Path:
    
    return PlatformDirs(
        appname=appname,
        appauthor=appauthor,
        version=version,
        opinion=opinion,
        ensure_exists=ensure_exists,
    ).site_runtime_path


__all__ = [
    ""AppDirs"",
    ""PlatformDirs"",
    ""PlatformDirsABC"",
    ""__version__"",
    ""__version_info__"",
    ""site_cache_dir"",
    ""site_cache_path"",
    ""site_config_dir"",
    ""site_config_path"",
    ""site_data_dir"",
    ""site_data_path"",
    ""site_runtime_dir"",
    ""site_runtime_path"",
    ""user_cache_dir"",
    ""user_cache_path"",
    ""user_config_dir"",
    ""user_config_path"",
    ""user_data_dir"",
    ""user_data_path"",
    ""user_desktop_dir"",
    ""user_desktop_path"",
    ""user_documents_dir"",
    ""user_documents_path"",
    ""user_downloads_dir"",
    ""user_downloads_path"",
    ""user_log_dir"",
    ""user_log_path"",
    ""user_music_dir"",
    ""user_music_path"",
    ""user_pictures_dir"",
    ""user_pictures_path"",
    ""user_runtime_dir"",
    ""user_runtime_path"",
    ""user_state_dir"",
    ""user_state_path"",
    ""user_videos_dir"",
    ""user_videos_path"",
]



from __future__ import annotations

from pip._vendor.platformdirs import PlatformDirs, __version__

PROPS = (
    ""user_data_dir"",
    ""user_config_dir"",
    ""user_cache_dir"",
    ""user_state_dir"",
    ""user_log_dir"",
    ""user_documents_dir"",
    ""user_downloads_dir"",
    ""user_pictures_dir"",
    ""user_videos_dir"",
    ""user_music_dir"",
    ""user_runtime_dir"",
    ""site_data_dir"",
    ""site_config_dir"",
    ""site_cache_dir"",
    ""site_runtime_dir"",
)


def main() -> None:
    
    app_name = ""MyApp""
    app_author = ""MyCompany""

    print(f""-- platformdirs {__version__} --"")  

    print(""-- app dirs (with optional 'version')"")  
    dirs = PlatformDirs(app_name, app_author, version=""1.0"")
    for prop in PROPS:
        print(f""{prop}: {getattr(dirs, prop)}"")  

    print(""\n-- app dirs (without optional 'version')"")  
    dirs = PlatformDirs(app_name, app_author)
    for prop in PROPS:
        print(f""{prop}: {getattr(dirs, prop)}"")  

    print(""\n-- app dirs (without optional 'appauthor')"")  
    dirs = PlatformDirs(app_name)
    for prop in PROPS:
        print(f""{prop}: {getattr(dirs, prop)}"")  

    print(""\n-- app dirs (with disabled 'appauthor')"")  
    dirs = PlatformDirs(app_name, appauthor=False)
    for prop in PROPS:
        print(f""{prop}: {getattr(dirs, prop)}"")  


if __name__ == ""__main__"":
    main()



esc = ""\x1b[""

codes = {}
codes[""""] = """"
codes[""reset""] = esc + ""39;49;00m""

codes[""bold""] = esc + ""01m""
codes[""faint""] = esc + ""02m""
codes[""standout""] = esc + ""03m""
codes[""underline""] = esc + ""04m""
codes[""blink""] = esc + ""05m""
codes[""overline""] = esc + ""06m""

dark_colors = [""black"", ""red"", ""green"", ""yellow"", ""blue"",
               ""magenta"", ""cyan"", ""gray""]
light_colors = [""brightblack"", ""brightred"", ""brightgreen"", ""brightyellow"", ""brightblue"",
                ""brightmagenta"", ""brightcyan"", ""white""]

x = 30
for dark, light in zip(dark_colors, light_colors):
    codes[dark] = esc + ""%im"" % x
    codes[light] = esc + ""%im"" % (60 + x)
    x += 1

del dark, light, x

codes[""white""] = codes[""bold""]


def reset_color():
    return codes[""reset""]


def colorize(color_key, text):
    return codes[color_key] + text + codes[""reset""]


def ansiformat(attr, text):
    
    result = []
    if attr[:1] == attr[-1:] == '+':
        result.append(codes['blink'])
        attr = attr[1:-1]
    if attr[:1] == attr[-1:] == '*':
        result.append(codes['bold'])
        attr = attr[1:-1]
    if attr[:1] == attr[-1:] == '_':
        result.append(codes['underline'])
        attr = attr[1:-1]
    result.append(codes[attr])
    result.append(text)
    result.append(codes['reset'])
    return ''.join(result)




def apply_filters(stream, filters, lexer=None):
    
    def _apply(filter_, stream):
        yield from filter_.filter(lexer, stream)
    for filter_ in filters:
        stream = _apply(filter_, stream)
    return stream


def simplefilter(f):
    
    return type(f.__name__, (FunctionFilter,), {
        '__module__': getattr(f, '__module__'),
        '__doc__': f.__doc__,
        'function': f,
    })


class Filter:
    

    def __init__(self, **options):
        self.options = options

    def filter(self, lexer, stream):
        raise NotImplementedError()


class FunctionFilter(Filter):
    
    function = None

    def __init__(self, **options):
        if not hasattr(self, 'function'):
            raise TypeError(f'{self.__class__.__name__!r} used without bound function')
        Filter.__init__(self, **options)

    def filter(self, lexer, stream):
        
        yield from self.function(lexer, stream, self.options)



import codecs

from pip._vendor.pygments.util import get_bool_opt
from pip._vendor.pygments.styles import get_style_by_name

__all__ = ['Formatter']


def _lookup_style(style):
    if isinstance(style, str):
        return get_style_by_name(style)
    return style


class Formatter:
    

    
    name = None

    
    
    aliases = []

    
    
    
    filenames = []

    
    
    unicodeoutput = True

    def __init__(self, **options):
        
        self.style = _lookup_style(options.get('style', 'default'))
        self.full = get_bool_opt(options, 'full', False)
        self.title = options.get('title', '')
        self.encoding = options.get('encoding', None) or None
        if self.encoding in ('guess', 'chardet'):
            
            self.encoding = 'utf-8'
        self.encoding = options.get('outencoding') or self.encoding
        self.options = options

    def get_style_defs(self, arg=''):
        
        return ''

    def format(self, tokensource, outfile):
        
        if self.encoding:
            
            outfile = codecs.lookup(self.encoding)[3](outfile)
        return self.format_unencoded(tokensource, outfile)

    
    
    def __class_getitem__(cls, name):
        return cls



import re
import sys
import time

from pip._vendor.pygments.filter import apply_filters, Filter
from pip._vendor.pygments.filters import get_filter_by_name
from pip._vendor.pygments.token import Error, Text, Other, Whitespace, _TokenType
from pip._vendor.pygments.util import get_bool_opt, get_int_opt, get_list_opt, \
    make_analysator, Future, guess_decode
from pip._vendor.pygments.regexopt import regex_opt

__all__ = ['Lexer', 'RegexLexer', 'ExtendedRegexLexer', 'DelegatingLexer',
           'LexerContext', 'include', 'inherit', 'bygroups', 'using', 'this',
           'default', 'words', 'line_re']

line_re = re.compile('.*?\n')

_encoding_map = [(b'\xef\xbb\xbf', 'utf-8'),
                 (b'\xff\xfe\0\0', 'utf-32'),
                 (b'\0\0\xfe\xff', 'utf-32be'),
                 (b'\xff\xfe', 'utf-16'),
                 (b'\xfe\xff', 'utf-16be')]

_default_analyse = staticmethod(lambda x: 0.0)


class LexerMeta(type):
    

    def __new__(mcs, name, bases, d):
        if 'analyse_text' in d:
            d['analyse_text'] = make_analysator(d['analyse_text'])
        return type.__new__(mcs, name, bases, d)


class Lexer(metaclass=LexerMeta):
    

    
    name = None

    
    
    aliases = []

    
    
    
    filenames = []

    
    
    
    
    
    
    alias_filenames = []

    
    mimetypes = []

    
    priority = 0

    
    
    url = None

    
    version_added = None

    
    
    _example = None

    def __init__(self, **options):
        
        self.options = options
        self.stripnl = get_bool_opt(options, 'stripnl', True)
        self.stripall = get_bool_opt(options, 'stripall', False)
        self.ensurenl = get_bool_opt(options, 'ensurenl', True)
        self.tabsize = get_int_opt(options, 'tabsize', 0)
        self.encoding = options.get('encoding', 'guess')
        self.encoding = options.get('inencoding') or self.encoding
        self.filters = []
        for filter_ in get_list_opt(options, 'filters', ()):
            self.add_filter(filter_)

    def __repr__(self):
        if self.options:
            return f'<pygments.lexers.{self.__class__.__name__} with {self.options!r}>'
        else:
            return f'<pygments.lexers.{self.__class__.__name__}>'

    def add_filter(self, filter_, **options):
        
        if not isinstance(filter_, Filter):
            filter_ = get_filter_by_name(filter_, **options)
        self.filters.append(filter_)

    def analyse_text(text):
        

    def _preprocess_lexer_input(self, text):
        

        if not isinstance(text, str):
            if self.encoding == 'guess':
                text, _ = guess_decode(text)
            elif self.encoding == 'chardet':
                try:
                    
                    
                    raise ImportError('chardet is not vendored by pip')
                except ImportError as e:
                    raise ImportError('To enable chardet encoding guessing, '
                                      'please install the chardet library '
                                      'from http://chardet.feedparser.org/') from e
                
                decoded = None
                for bom, encoding in _encoding_map:
                    if text.startswith(bom):
                        decoded = text[len(bom):].decode(encoding, 'replace')
                        break
                
                if decoded is None:
                    enc = chardet.detect(text[:1024])  
                    decoded = text.decode(enc.get('encoding') or 'utf-8',
                                          'replace')
                text = decoded
            else:
                text = text.decode(self.encoding)
                if text.startswith('\ufeff'):
                    text = text[len('\ufeff'):]
        else:
            if text.startswith('\ufeff'):
                text = text[len('\ufeff'):]

        
        text = text.replace('\r\n', '\n')
        text = text.replace('\r', '\n')
        if self.stripall:
            text = text.strip()
        elif self.stripnl:
            text = text.strip('\n')
        if self.tabsize > 0:
            text = text.expandtabs(self.tabsize)
        if self.ensurenl and not text.endswith('\n'):
            text += '\n'

        return text

    def get_tokens(self, text, unfiltered=False):
        
        text = self._preprocess_lexer_input(text)

        def streamer():
            for _, t, v in self.get_tokens_unprocessed(text):
                yield t, v
        stream = streamer()
        if not unfiltered:
            stream = apply_filters(stream, self.filters, self)
        return stream

    def get_tokens_unprocessed(self, text):
        
        raise NotImplementedError


class DelegatingLexer(Lexer):
    

    def __init__(self, _root_lexer, _language_lexer, _needle=Other, **options):
        self.root_lexer = _root_lexer(**options)
        self.language_lexer = _language_lexer(**options)
        self.needle = _needle
        Lexer.__init__(self, **options)

    def get_tokens_unprocessed(self, text):
        buffered = ''
        insertions = []
        lng_buffer = []
        for i, t, v in self.language_lexer.get_tokens_unprocessed(text):
            if t is self.needle:
                if lng_buffer:
                    insertions.append((len(buffered), lng_buffer))
                    lng_buffer = []
                buffered += v
            else:
                lng_buffer.append((i, t, v))
        if lng_buffer:
            insertions.append((len(buffered), lng_buffer))
        return do_insertions(insertions,
                             self.root_lexer.get_tokens_unprocessed(buffered))







class include(str):  
    
    pass


class _inherit:
    
    def __repr__(self):
        return 'inherit'

inherit = _inherit()  


class combined(tuple):  
    

    def __new__(cls, *args):
        return tuple.__new__(cls, args)

    def __init__(self, *args):
        
        pass


class _PseudoMatch:
    

    def __init__(self, start, text):
        self._text = text
        self._start = start

    def start(self, arg=None):
        return self._start

    def end(self, arg=None):
        return self._start + len(self._text)

    def group(self, arg=None):
        if arg:
            raise IndexError('No such group')
        return self._text

    def groups(self):
        return (self._text,)

    def groupdict(self):
        return {}


def bygroups(*args):
    
    def callback(lexer, match, ctx=None):
        for i, action in enumerate(args):
            if action is None:
                continue
            elif type(action) is _TokenType:
                data = match.group(i + 1)
                if data:
                    yield match.start(i + 1), action, data
            else:
                data = match.group(i + 1)
                if data is not None:
                    if ctx:
                        ctx.pos = match.start(i + 1)
                    for item in action(lexer,
                                       _PseudoMatch(match.start(i + 1), data), ctx):
                        if item:
                            yield item
        if ctx:
            ctx.pos = match.end()
    return callback


class _This:
    

this = _This()


def using(_other, **kwargs):
    
    gt_kwargs = {}
    if 'state' in kwargs:
        s = kwargs.pop('state')
        if isinstance(s, (list, tuple)):
            gt_kwargs['stack'] = s
        else:
            gt_kwargs['stack'] = ('root', s)

    if _other is this:
        def callback(lexer, match, ctx=None):
            
            
            if kwargs:
                
                kwargs.update(lexer.options)
                lx = lexer.__class__(**kwargs)
            else:
                lx = lexer
            s = match.start()
            for i, t, v in lx.get_tokens_unprocessed(match.group(), **gt_kwargs):
                yield i + s, t, v
            if ctx:
                ctx.pos = match.end()
    else:
        def callback(lexer, match, ctx=None):
            
            kwargs.update(lexer.options)
            lx = _other(**kwargs)

            s = match.start()
            for i, t, v in lx.get_tokens_unprocessed(match.group(), **gt_kwargs):
                yield i + s, t, v
            if ctx:
                ctx.pos = match.end()
    return callback


class default:
    
    def __init__(self, state):
        self.state = state


class words(Future):
    
    def __init__(self, words, prefix='', suffix=''):
        self.words = words
        self.prefix = prefix
        self.suffix = suffix

    def get(self):
        return regex_opt(self.words, prefix=self.prefix, suffix=self.suffix)


class RegexLexerMeta(LexerMeta):
    

    def _process_regex(cls, regex, rflags, state):
        
        if isinstance(regex, Future):
            regex = regex.get()
        return re.compile(regex, rflags).match

    def _process_token(cls, token):
        
        assert type(token) is _TokenType or callable(token), \
            f'token type must be simple type or callable, not {token!r}'
        return token

    def _process_new_state(cls, new_state, unprocessed, processed):
        
        if isinstance(new_state, str):
            
            if new_state == '
                return -1
            elif new_state in unprocessed:
                return (new_state,)
            elif new_state == '
                return new_state
            elif new_state[:5] == '
                return -int(new_state[5:])
            else:
                assert False, f'unknown new state {new_state!r}'
        elif isinstance(new_state, combined):
            
            tmp_state = '_tmp_%d' % cls._tmpname
            cls._tmpname += 1
            itokens = []
            for istate in new_state:
                assert istate != new_state, f'circular state ref {istate!r}'
                itokens.extend(cls._process_state(unprocessed,
                                                  processed, istate))
            processed[tmp_state] = itokens
            return (tmp_state,)
        elif isinstance(new_state, tuple):
            
            for istate in new_state:
                assert (istate in unprocessed or
                        istate in ('
                    'unknown new state ' + istate
            return new_state
        else:
            assert False, f'unknown new state def {new_state!r}'

    def _process_state(cls, unprocessed, processed, state):
        
        assert isinstance(state, str), f""wrong state name {state!r}""
        assert state[0] != '
        if state in processed:
            return processed[state]
        tokens = processed[state] = []
        rflags = cls.flags
        for tdef in unprocessed[state]:
            if isinstance(tdef, include):
                
                assert tdef != state, f""circular state reference {state!r}""
                tokens.extend(cls._process_state(unprocessed, processed,
                                                 str(tdef)))
                continue
            if isinstance(tdef, _inherit):
                
                
                
                continue
            if isinstance(tdef, default):
                new_state = cls._process_new_state(tdef.state, unprocessed, processed)
                tokens.append((re.compile('').match, None, new_state))
                continue

            assert type(tdef) is tuple, f""wrong rule def {tdef!r}""

            try:
                rex = cls._process_regex(tdef[0], rflags, state)
            except Exception as err:
                raise ValueError(f""uncompilable regex {tdef[0]!r} in state {state!r} of {cls!r}: {err}"") from err

            token = cls._process_token(tdef[1])

            if len(tdef) == 2:
                new_state = None
            else:
                new_state = cls._process_new_state(tdef[2],
                                                   unprocessed, processed)

            tokens.append((rex, token, new_state))
        return tokens

    def process_tokendef(cls, name, tokendefs=None):
        
        processed = cls._all_tokens[name] = {}
        tokendefs = tokendefs or cls.tokens[name]
        for state in list(tokendefs):
            cls._process_state(tokendefs, processed, state)
        return processed

    def get_tokendefs(cls):
        
        tokens = {}
        inheritable = {}
        for c in cls.__mro__:
            toks = c.__dict__.get('tokens', {})

            for state, items in toks.items():
                curitems = tokens.get(state)
                if curitems is None:
                    
                    
                    
                    
                    tokens[state] = items
                    try:
                        inherit_ndx = items.index(inherit)
                    except ValueError:
                        continue
                    inheritable[state] = inherit_ndx
                    continue

                inherit_ndx = inheritable.pop(state, None)
                if inherit_ndx is None:
                    continue

                
                curitems[inherit_ndx:inherit_ndx+1] = items
                try:
                    
                    
                    new_inh_ndx = items.index(inherit)
                except ValueError:
                    pass
                else:
                    inheritable[state] = inherit_ndx + new_inh_ndx

        return tokens

    def __call__(cls, *args, **kwds):
        
        if '_tokens' not in cls.__dict__:
            cls._all_tokens = {}
            cls._tmpname = 0
            if hasattr(cls, 'token_variants') and cls.token_variants:
                
                pass
            else:
                cls._tokens = cls.process_tokendef('', cls.get_tokendefs())

        return type.__call__(cls, *args, **kwds)


class RegexLexer(Lexer, metaclass=RegexLexerMeta):
    

    
    
    flags = re.MULTILINE

    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    tokens = {}

    def get_tokens_unprocessed(self, text, stack=('root',)):
        
        pos = 0
        tokendefs = self._tokens
        statestack = list(stack)
        statetokens = tokendefs[statestack[-1]]
        while 1:
            for rexmatch, action, new_state in statetokens:
                m = rexmatch(text, pos)
                if m:
                    if action is not None:
                        if type(action) is _TokenType:
                            yield pos, action, m.group()
                        else:
                            yield from action(self, m)
                    pos = m.end()
                    if new_state is not None:
                        
                        if isinstance(new_state, tuple):
                            for state in new_state:
                                if state == '
                                    if len(statestack) > 1:
                                        statestack.pop()
                                elif state == '
                                    statestack.append(statestack[-1])
                                else:
                                    statestack.append(state)
                        elif isinstance(new_state, int):
                            
                            
                            
                            if abs(new_state) >= len(statestack):
                                del statestack[1:]
                            else:
                                del statestack[new_state:]
                        elif new_state == '
                            statestack.append(statestack[-1])
                        else:
                            assert False, f""wrong state def: {new_state!r}""
                        statetokens = tokendefs[statestack[-1]]
                    break
            else:
                
                
                try:
                    if text[pos] == '\n':
                        
                        statestack = ['root']
                        statetokens = tokendefs['root']
                        yield pos, Whitespace, '\n'
                        pos += 1
                        continue
                    yield pos, Error, text[pos]
                    pos += 1
                except IndexError:
                    break


class LexerContext:
    

    def __init__(self, text, pos, stack=None, end=None):
        self.text = text
        self.pos = pos
        self.end = end or len(text)  
        self.stack = stack or ['root']

    def __repr__(self):
        return f'LexerContext({self.text!r}, {self.pos!r}, {self.stack!r})'


class ExtendedRegexLexer(RegexLexer):
    

    def get_tokens_unprocessed(self, text=None, context=None):
        
        tokendefs = self._tokens
        if not context:
            ctx = LexerContext(text, 0)
            statetokens = tokendefs['root']
        else:
            ctx = context
            statetokens = tokendefs[ctx.stack[-1]]
            text = ctx.text
        while 1:
            for rexmatch, action, new_state in statetokens:
                m = rexmatch(text, ctx.pos, ctx.end)
                if m:
                    if action is not None:
                        if type(action) is _TokenType:
                            yield ctx.pos, action, m.group()
                            ctx.pos = m.end()
                        else:
                            yield from action(self, m, ctx)
                            if not new_state:
                                
                                statetokens = tokendefs[ctx.stack[-1]]
                    
                    if new_state is not None:
                        
                        if isinstance(new_state, tuple):
                            for state in new_state:
                                if state == '
                                    if len(ctx.stack) > 1:
                                        ctx.stack.pop()
                                elif state == '
                                    ctx.stack.append(ctx.stack[-1])
                                else:
                                    ctx.stack.append(state)
                        elif isinstance(new_state, int):
                            
                            if abs(new_state) >= len(ctx.stack):
                                del ctx.stack[1:]
                            else:
                                del ctx.stack[new_state:]
                        elif new_state == '
                            ctx.stack.append(ctx.stack[-1])
                        else:
                            assert False, f""wrong state def: {new_state!r}""
                        statetokens = tokendefs[ctx.stack[-1]]
                    break
            else:
                try:
                    if ctx.pos >= ctx.end:
                        break
                    if text[ctx.pos] == '\n':
                        
                        ctx.stack = ['root']
                        statetokens = tokendefs['root']
                        yield ctx.pos, Text, '\n'
                        ctx.pos += 1
                        continue
                    yield ctx.pos, Error, text[ctx.pos]
                    ctx.pos += 1
                except IndexError:
                    break


def do_insertions(insertions, tokens):
    
    insertions = iter(insertions)
    try:
        index, itokens = next(insertions)
    except StopIteration:
        
        yield from tokens
        return

    realpos = None
    insleft = True

    
    
    for i, t, v in tokens:
        
        if realpos is None:
            realpos = i
        oldi = 0
        while insleft and i + len(v) >= index:
            tmpval = v[oldi:index - i]
            if tmpval:
                yield realpos, t, tmpval
                realpos += len(tmpval)
            for it_index, it_token, it_value in itokens:
                yield realpos, it_token, it_value
                realpos += len(it_value)
            oldi = index - i
            try:
                index, itokens = next(insertions)
            except StopIteration:
                insleft = False
                break  
        if oldi < len(v):
            yield realpos, t, v[oldi:]
            realpos += len(v) - oldi

    
    while insleft:
        
        realpos = realpos or 0
        for p, t, v in itokens:
            yield realpos, t, v
            realpos += len(v)
        try:
            index, itokens = next(insertions)
        except StopIteration:
            insleft = False
            break  


class ProfilingRegexLexerMeta(RegexLexerMeta):
    

    def _process_regex(cls, regex, rflags, state):
        if isinstance(regex, words):
            rex = regex_opt(regex.words, prefix=regex.prefix,
                            suffix=regex.suffix)
        else:
            rex = regex
        compiled = re.compile(rex, rflags)

        def match_func(text, pos, endpos=sys.maxsize):
            info = cls._prof_data[-1].setdefault((state, rex), [0, 0.0])
            t0 = time.time()
            res = compiled.match(text, pos, endpos)
            t1 = time.time()
            info[0] += 1
            info[1] += t1 - t0
            return res
        return match_func


class ProfilingRegexLexer(RegexLexer, metaclass=ProfilingRegexLexerMeta):
    

    _prof_data = []
    _prof_sort_index = 4  

    def get_tokens_unprocessed(self, text, stack=('root',)):
        
        self.__class__._prof_data.append({})
        yield from RegexLexer.get_tokens_unprocessed(self, text, stack)
        rawdata = self.__class__._prof_data.pop()
        data = sorted(((s, repr(r).strip('u\'').replace('\\\\', '\\')[:65],
                        n, 1000 * t, 1000 * t / n)
                       for ((s, r), (n, t)) in rawdata.items()),
                      key=lambda x: x[self._prof_sort_index],
                      reverse=True)
        sum_total = sum(x[3] for x in data)

        print()
        print('Profiling result for %s lexing %d chars in %.3f ms' %
              (self.__class__.__name__, len(text), sum_total))
        print('=' * 110)
        print('%-20s %-64s ncalls  tottime  percall' % ('state', 'regex'))
        print('-' * 110)
        for d in data:
            print('%-20s %-65s %5d %8.4f %8.4f' % d)
        print('=' * 110)



import re

__all__ = ['get_filetype_from_buffer']


modeline_re = re.compile(r, re.VERBOSE)


def get_filetype_from_line(l): 
    m = modeline_re.search(l)
    if m:
        return m.group(1)


def get_filetype_from_buffer(buf, max_lines=5):
    
    lines = buf.splitlines()
    for line in lines[-1:-max_lines-1:-1]:
        ret = get_filetype_from_line(line)
        if ret:
            return ret
    for i in range(max_lines, -1, -1):
        if i < len(lines):
            ret = get_filetype_from_line(lines[i])
            if ret:
                return ret

    return None


from importlib.metadata import entry_points

LEXER_ENTRY_POINT = 'pygments.lexers'
FORMATTER_ENTRY_POINT = 'pygments.formatters'
STYLE_ENTRY_POINT = 'pygments.styles'
FILTER_ENTRY_POINT = 'pygments.filters'


def iter_entry_points(group_name):
    groups = entry_points()
    if hasattr(groups, 'select'):
        
        
        return groups.select(group=group_name)
    else:
        
        
        return groups.get(group_name, [])


def find_plugin_lexers():
    for entrypoint in iter_entry_points(LEXER_ENTRY_POINT):
        yield entrypoint.load()


def find_plugin_formatters():
    for entrypoint in iter_entry_points(FORMATTER_ENTRY_POINT):
        yield entrypoint.name, entrypoint.load()


def find_plugin_styles():
    for entrypoint in iter_entry_points(STYLE_ENTRY_POINT):
        yield entrypoint.name, entrypoint.load()


def find_plugin_filters():
    for entrypoint in iter_entry_points(FILTER_ENTRY_POINT):
        yield entrypoint.name, entrypoint.load()



import re
from re import escape
from os.path import commonprefix
from itertools import groupby
from operator import itemgetter

CS_ESCAPE = re.compile(r'[\[\^\\\-\]]')
FIRST_ELEMENT = itemgetter(0)


def make_charset(letters):
    return '[' + CS_ESCAPE.sub(lambda m: '\\' + m.group(), ''.join(letters)) + ']'


def regex_opt_inner(strings, open_paren):
    
    close_paren = open_paren and ')' or ''
    
    if not strings:
        
        return ''
    first = strings[0]
    if len(strings) == 1:
        
        return open_paren + escape(first) + close_paren
    if not first:
        
        return open_paren + regex_opt_inner(strings[1:], '(?:') \
            + '?' + close_paren
    if len(first) == 1:
        
        oneletter = []
        rest = []
        for s in strings:
            if len(s) == 1:
                oneletter.append(s)
            else:
                rest.append(s)
        if len(oneletter) > 1:  
            if rest:
                
                return open_paren + regex_opt_inner(rest, '') + '|' \
                    + make_charset(oneletter) + close_paren
            
            return open_paren + make_charset(oneletter) + close_paren
    prefix = commonprefix(strings)
    if prefix:
        plen = len(prefix)
        
        
        return open_paren + escape(prefix) \
            + regex_opt_inner([s[plen:] for s in strings], '(?:') \
            + close_paren
    
    strings_rev = [s[::-1] for s in strings]
    suffix = commonprefix(strings_rev)
    if suffix:
        slen = len(suffix)
        
        return open_paren \
            + regex_opt_inner(sorted(s[:-slen] for s in strings), '(?:') \
            + escape(suffix[::-1]) + close_paren
    
    
    return open_paren + \
        '|'.join(regex_opt_inner(list(group[1]), '')
                 for group in groupby(strings, lambda s: s[0] == first[0])) \
        + close_paren


def regex_opt(strings, prefix='', suffix=''):
    
    strings = sorted(strings)
    return prefix + regex_opt_inner(strings, '(') + suffix


import re


class EndOfText(RuntimeError):
    


class Scanner:
    

    def __init__(self, text, flags=0):
        
        self.data = text
        self.data_length = len(text)
        self.start_pos = 0
        self.pos = 0
        self.flags = flags
        self.last = None
        self.match = None
        self._re_cache = {}

    def eos(self):
        
        return self.pos >= self.data_length
    eos = property(eos, eos.__doc__)

    def check(self, pattern):
        
        if self.eos:
            raise EndOfText()
        if pattern not in self._re_cache:
            self._re_cache[pattern] = re.compile(pattern, self.flags)
        return self._re_cache[pattern].match(self.data, self.pos)

    def test(self, pattern):
        
        return self.check(pattern) is not None

    def scan(self, pattern):
        
        if self.eos:
            raise EndOfText()
        if pattern not in self._re_cache:
            self._re_cache[pattern] = re.compile(pattern, self.flags)
        self.last = self.match
        m = self._re_cache[pattern].match(self.data, self.pos)
        if m is None:
            return False
        self.start_pos = m.start()
        self.pos = m.end()
        self.match = m.group()
        return True

    def get_char(self):
        
        self.scan('.')

    def __repr__(self):
        return '<%s %d/%d>' % (
            self.__class__.__name__,
            self.pos,
            self.data_length
        )



import sys

from docutils import nodes
from docutils.statemachine import ViewList
from docutils.parsers.rst import Directive
from sphinx.util.nodes import nested_parse_with_titles


MODULEDOC = 

LEXERDOC = 

FMTERDOC = 

FILTERDOC = 


class PygmentsDoc(Directive):
    
    has_content = False
    required_arguments = 1
    optional_arguments = 0
    final_argument_whitespace = False
    option_spec = {}

    def run(self):
        self.filenames = set()
        if self.arguments[0] == 'lexers':
            out = self.document_lexers()
        elif self.arguments[0] == 'formatters':
            out = self.document_formatters()
        elif self.arguments[0] == 'filters':
            out = self.document_filters()
        elif self.arguments[0] == 'lexers_overview':
            out = self.document_lexers_overview()
        else:
            raise Exception('invalid argument for ""pygmentsdoc"" directive')
        node = nodes.compound()
        vl = ViewList(out.split('\n'), source='')
        nested_parse_with_titles(self.state, vl, node)
        for fn in self.filenames:
            self.state.document.settings.record_dependencies.add(fn)
        return node.children

    def document_lexers_overview(self):
        
        from pip._vendor.pygments.lexers._mapping import LEXERS
        from pip._vendor.pygments.lexers import find_lexer_class
        out = []

        table = []

        def format_link(name, url):
            if url:
                return f'`{name} <{url}>`_'
            return name

        for classname, data in sorted(LEXERS.items(), key=lambda x: x[1][1].lower()):
            lexer_cls = find_lexer_class(data[1])
            extensions = lexer_cls.filenames + lexer_cls.alias_filenames

            table.append({
                'name': format_link(data[1], lexer_cls.url),
                'extensions': ', '.join(extensions).replace('*', '\\*').replace('_', '\\') or 'None',
                'aliases': ', '.join(data[2]),
                'class': f'{data[0]}.{classname}'
            })

        column_names = ['name', 'extensions', 'aliases', 'class']
        column_lengths = [max([len(row[column]) for row in table if row[column]])
                          for column in column_names]

        def write_row(*columns):
            
            out = []
            for length, col in zip(column_lengths, columns):
                if col:
                    out.append(col.ljust(length))
                else:
                    out.append(' '*length)

            return ' '.join(out)

        def write_seperator():
            
            sep = ['='*c for c in column_lengths]
            return write_row(*sep)

        out.append(write_seperator())
        out.append(write_row('Name', 'Extension(s)', 'Short name(s)', 'Lexer class'))
        out.append(write_seperator())
        for row in table:
            out.append(write_row(
                row['name'],
                row['extensions'],
                row['aliases'],
                f':class:`~{row[""class""]}`'))
        out.append(write_seperator())

        return '\n'.join(out)

    def document_lexers(self):
        from pip._vendor.pygments.lexers._mapping import LEXERS
        from pip._vendor import pygments
        import inspect
        import pathlib

        out = []
        modules = {}
        moduledocstrings = {}
        for classname, data in sorted(LEXERS.items(), key=lambda x: x[0]):
            module = data[0]
            mod = __import__(module, None, None, [classname])
            self.filenames.add(mod.__file__)
            cls = getattr(mod, classname)
            if not cls.__doc__:
                print(f""Warning: {classname} does not have a docstring."")
            docstring = cls.__doc__
            if isinstance(docstring, bytes):
                docstring = docstring.decode('utf8')

            example_file = getattr(cls, '_example', None)
            if example_file:
                p = pathlib.Path(inspect.getabsfile(pygments)).parent.parent /\
                    'tests' / 'examplefiles' / example_file
                content = p.read_text(encoding='utf-8')
                if not content:
                    raise Exception(
                        f""Empty example file '{example_file}' for lexer ""
                        f""{classname}"")

                if data[2]:
                    lexer_name = data[2][0]
                    docstring += '\n\n    .. admonition:: Example\n'
                    docstring += f'\n      .. code-block:: {lexer_name}\n\n'
                    for line in content.splitlines():
                        docstring += f'          {line}\n'

            if cls.version_added:
                version_line = f'.. versionadded:: {cls.version_added}'
            else:
                version_line = ''

            modules.setdefault(module, []).append((
                classname,
                ', '.join(data[2]) or 'None',
                ', '.join(data[3]).replace('*', '\\*').replace('_', '\\') or 'None',
                ', '.join(data[4]) or 'None',
                docstring,
                version_line))
            if module not in moduledocstrings:
                moddoc = mod.__doc__
                if isinstance(moddoc, bytes):
                    moddoc = moddoc.decode('utf8')
                moduledocstrings[module] = moddoc

        for module, lexers in sorted(modules.items(), key=lambda x: x[0]):
            if moduledocstrings[module] is None:
                raise Exception(f""Missing docstring for {module}"")
            heading = moduledocstrings[module].splitlines()[4].strip().rstrip('.')
            out.append(MODULEDOC % (module, heading, '-'*len(heading)))
            for data in lexers:
                out.append(LEXERDOC % data)

        return ''.join(out)

    def document_formatters(self):
        from pip._vendor.pygments.formatters import FORMATTERS

        out = []
        for classname, data in sorted(FORMATTERS.items(), key=lambda x: x[0]):
            module = data[0]
            mod = __import__(module, None, None, [classname])
            self.filenames.add(mod.__file__)
            cls = getattr(mod, classname)
            docstring = cls.__doc__
            if isinstance(docstring, bytes):
                docstring = docstring.decode('utf8')
            heading = cls.__name__
            out.append(FMTERDOC % (heading, ', '.join(data[2]) or 'None',
                                   ', '.join(data[3]).replace('*', '\\*') or 'None',
                                   docstring))
        return ''.join(out)

    def document_filters(self):
        from pip._vendor.pygments.filters import FILTERS

        out = []
        for name, cls in FILTERS.items():
            self.filenames.add(sys.modules[cls.__module__].__file__)
            docstring = cls.__doc__
            if isinstance(docstring, bytes):
                docstring = docstring.decode('utf8')
            out.append(FILTERDOC % (cls.__name__, name, docstring))
        return ''.join(out)


def setup(app):
    app.add_directive('pygmentsdoc', PygmentsDoc)



from pip._vendor.pygments.token import Token, STANDARD_TYPES


_ansimap = {
    
    'ansiblack': '000000',
    'ansired': '7f0000',
    'ansigreen': '007f00',
    'ansiyellow': '7f7fe0',
    'ansiblue': '00007f',
    'ansimagenta': '7f007f',
    'ansicyan': '007f7f',
    'ansigray': 'e5e5e5',
    
    'ansibrightblack': '555555',
    'ansibrightred': 'ff0000',
    'ansibrightgreen': '00ff00',
    'ansibrightyellow': 'ffff00',
    'ansibrightblue': '0000ff',
    'ansibrightmagenta': 'ff00ff',
    'ansibrightcyan': '00ffff',
    'ansiwhite': 'ffffff',
}

_deprecated_ansicolors = {
    
    '
    '
    '
    '
    '
    '
    '
    '
    
    '
    '
    '
    '
    '
    '
    '
    '
}
ansicolors = set(_ansimap)


class StyleMeta(type):

    def __new__(mcs, name, bases, dct):
        obj = type.__new__(mcs, name, bases, dct)
        for token in STANDARD_TYPES:
            if token not in obj.styles:
                obj.styles[token] = ''

        def colorformat(text):
            if text in ansicolors:
                return text
            if text[0:1] == '
                col = text[1:]
                if len(col) == 6:
                    return col
                elif len(col) == 3:
                    return col[0] * 2 + col[1] * 2 + col[2] * 2
            elif text == '':
                return ''
            elif text.startswith('var') or text.startswith('calc'):
                return text
            assert False, f""wrong color format {text!r}""

        _styles = obj._styles = {}

        for ttype in obj.styles:
            for token in ttype.split():
                if token in _styles:
                    continue
                ndef = _styles.get(token.parent, None)
                styledefs = obj.styles.get(token, '').split()
                if not ndef or token is None:
                    ndef = ['', 0, 0, 0, '', '', 0, 0, 0]
                elif 'noinherit' in styledefs and token is not Token:
                    ndef = _styles[Token][:]
                else:
                    ndef = ndef[:]
                _styles[token] = ndef
                for styledef in obj.styles.get(token, '').split():
                    if styledef == 'noinherit':
                        pass
                    elif styledef == 'bold':
                        ndef[1] = 1
                    elif styledef == 'nobold':
                        ndef[1] = 0
                    elif styledef == 'italic':
                        ndef[2] = 1
                    elif styledef == 'noitalic':
                        ndef[2] = 0
                    elif styledef == 'underline':
                        ndef[3] = 1
                    elif styledef == 'nounderline':
                        ndef[3] = 0
                    elif styledef[:3] == 'bg:':
                        ndef[4] = colorformat(styledef[3:])
                    elif styledef[:7] == 'border:':
                        ndef[5] = colorformat(styledef[7:])
                    elif styledef == 'roman':
                        ndef[6] = 1
                    elif styledef == 'sans':
                        ndef[7] = 1
                    elif styledef == 'mono':
                        ndef[8] = 1
                    else:
                        ndef[0] = colorformat(styledef)

        return obj

    def style_for_token(cls, token):
        t = cls._styles[token]
        ansicolor = bgansicolor = None
        color = t[0]
        if color in _deprecated_ansicolors:
            color = _deprecated_ansicolors[color]
        if color in ansicolors:
            ansicolor = color
            color = _ansimap[color]
        bgcolor = t[4]
        if bgcolor in _deprecated_ansicolors:
            bgcolor = _deprecated_ansicolors[bgcolor]
        if bgcolor in ansicolors:
            bgansicolor = bgcolor
            bgcolor = _ansimap[bgcolor]

        return {
            'color':        color or None,
            'bold':         bool(t[1]),
            'italic':       bool(t[2]),
            'underline':    bool(t[3]),
            'bgcolor':      bgcolor or None,
            'border':       t[5] or None,
            'roman':        bool(t[6]) or None,
            'sans':         bool(t[7]) or None,
            'mono':         bool(t[8]) or None,
            'ansicolor':    ansicolor,
            'bgansicolor':  bgansicolor,
        }

    def list_styles(cls):
        return list(cls)

    def styles_token(cls, ttype):
        return ttype in cls._styles

    def __iter__(cls):
        for token in cls._styles:
            yield token, cls.style_for_token(token)

    def __len__(cls):
        return len(cls._styles)


class Style(metaclass=StyleMeta):

    
    background_color = '

    
    highlight_color = '

    
    line_number_color = 'inherit'

    
    line_number_background_color = 'transparent'

    
    line_number_special_color = '

    
    line_number_special_background_color = '

    
    styles = {}

    
    
    name = 'unnamed'

    aliases = []

    
    
    
    
    web_style_gallery_exclude = False




class _TokenType(tuple):
    parent = None

    def split(self):
        buf = []
        node = self
        while node is not None:
            buf.append(node)
            node = node.parent
        buf.reverse()
        return buf

    def __init__(self, *args):
        
        self.subtypes = set()

    def __contains__(self, val):
        return self is val or (
            type(val) is self.__class__ and
            val[:len(self)] == self
        )

    def __getattr__(self, val):
        if not val or not val[0].isupper():
            return tuple.__getattribute__(self, val)
        new = _TokenType(self + (val,))
        setattr(self, val, new)
        self.subtypes.add(new)
        new.parent = self
        return new

    def __repr__(self):
        return 'Token' + (self and '.' or '') + '.'.join(self)

    def __copy__(self):
        
        return self

    def __deepcopy__(self, memo):
        
        return self


Token = _TokenType()


Text = Token.Text
Whitespace = Text.Whitespace
Escape = Token.Escape
Error = Token.Error

Other = Token.Other


Keyword = Token.Keyword
Name = Token.Name
Literal = Token.Literal
String = Literal.String
Number = Literal.Number
Punctuation = Token.Punctuation
Operator = Token.Operator
Comment = Token.Comment


Generic = Token.Generic



Token.Token = Token
Token.String = String
Token.Number = Number


def is_token_subtype(ttype, other):
    
    return ttype in other


def string_to_tokentype(s):
    
    if isinstance(s, _TokenType):
        return s
    if not s:
        return Token
    node = Token
    for item in s.split('.'):
        node = getattr(node, item)
    return node





STANDARD_TYPES = {
    Token:                         '',

    Text:                          '',
    Whitespace:                    'w',
    Escape:                        'esc',
    Error:                         'err',
    Other:                         'x',

    Keyword:                       'k',
    Keyword.Constant:              'kc',
    Keyword.Declaration:           'kd',
    Keyword.Namespace:             'kn',
    Keyword.Pseudo:                'kp',
    Keyword.Reserved:              'kr',
    Keyword.Type:                  'kt',

    Name:                          'n',
    Name.Attribute:                'na',
    Name.Builtin:                  'nb',
    Name.Builtin.Pseudo:           'bp',
    Name.Class:                    'nc',
    Name.Constant:                 'no',
    Name.Decorator:                'nd',
    Name.Entity:                   'ni',
    Name.Exception:                'ne',
    Name.Function:                 'nf',
    Name.Function.Magic:           'fm',
    Name.Property:                 'py',
    Name.Label:                    'nl',
    Name.Namespace:                'nn',
    Name.Other:                    'nx',
    Name.Tag:                      'nt',
    Name.Variable:                 'nv',
    Name.Variable.Class:           'vc',
    Name.Variable.Global:          'vg',
    Name.Variable.Instance:        'vi',
    Name.Variable.Magic:           'vm',

    Literal:                       'l',
    Literal.Date:                  'ld',

    String:                        's',
    String.Affix:                  'sa',
    String.Backtick:               'sb',
    String.Char:                   'sc',
    String.Delimiter:              'dl',
    String.Doc:                    'sd',
    String.Double:                 's2',
    String.Escape:                 'se',
    String.Heredoc:                'sh',
    String.Interpol:               'si',
    String.Other:                  'sx',
    String.Regex:                  'sr',
    String.Single:                 's1',
    String.Symbol:                 'ss',

    Number:                        'm',
    Number.Bin:                    'mb',
    Number.Float:                  'mf',
    Number.Hex:                    'mh',
    Number.Integer:                'mi',
    Number.Integer.Long:           'il',
    Number.Oct:                    'mo',

    Operator:                      'o',
    Operator.Word:                 'ow',

    Punctuation:                   'p',
    Punctuation.Marker:            'pm',

    Comment:                       'c',
    Comment.Hashbang:              'ch',
    Comment.Multiline:             'cm',
    Comment.Preproc:               'cp',
    Comment.PreprocFile:           'cpf',
    Comment.Single:                'c1',
    Comment.Special:               'cs',

    Generic:                       'g',
    Generic.Deleted:               'gd',
    Generic.Emph:                  'ge',
    Generic.Error:                 'gr',
    Generic.Heading:               'gh',
    Generic.Inserted:              'gi',
    Generic.Output:                'go',
    Generic.Prompt:                'gp',
    Generic.Strong:                'gs',
    Generic.Subheading:            'gu',
    Generic.EmphStrong:            'ges',
    Generic.Traceback:             'gt',
}



Cc = '\x00-\x1f\x7f-\x9f'

Cf = '\xad\u0600-\u0605\u061c\u06dd\u070f\u08e2\u180e\u200b-\u200f\u202a-\u202e\u2060-\u2064\u2066-\u206f\ufeff\ufff9-\ufffb\U000110bd\U000110cd\U0001bca0-\U0001bca3\U0001d173-\U0001d17a\U000e0001\U000e0020-\U000e007f'

Cn = '\u0378-\u0379\u0380-\u0383\u038b\u038d\u03a2\u0530\u0557-\u0558\u058b-\u058c\u0590\u05c8-\u05cf\u05eb-\u05ee\u05f5-\u05ff\u061d\u070e\u074b-\u074c\u07b2-\u07bf\u07fb-\u07fc\u082e-\u082f\u083f\u085c-\u085d\u085f\u086b-\u089f\u08b5\u08be-\u08d2\u0984\u098d-\u098e\u0991-\u0992\u09a9\u09b1\u09b3-\u09b5\u09ba-\u09bb\u09c5-\u09c6\u09c9-\u09ca\u09cf-\u09d6\u09d8-\u09db\u09de\u09e4-\u09e5\u09ff-\u0a00\u0a04\u0a0b-\u0a0e\u0a11-\u0a12\u0a29\u0a31\u0a34\u0a37\u0a3a-\u0a3b\u0a3d\u0a43-\u0a46\u0a49-\u0a4a\u0a4e-\u0a50\u0a52-\u0a58\u0a5d\u0a5f-\u0a65\u0a77-\u0a80\u0a84\u0a8e\u0a92\u0aa9\u0ab1\u0ab4\u0aba-\u0abb\u0ac6\u0aca\u0ace-\u0acf\u0ad1-\u0adf\u0ae4-\u0ae5\u0af2-\u0af8\u0b00\u0b04\u0b0d-\u0b0e\u0b11-\u0b12\u0b29\u0b31\u0b34\u0b3a-\u0b3b\u0b45-\u0b46\u0b49-\u0b4a\u0b4e-\u0b55\u0b58-\u0b5b\u0b5e\u0b64-\u0b65\u0b78-\u0b81\u0b84\u0b8b-\u0b8d\u0b91\u0b96-\u0b98\u0b9b\u0b9d\u0ba0-\u0ba2\u0ba5-\u0ba7\u0bab-\u0bad\u0bba-\u0bbd\u0bc3-\u0bc5\u0bc9\u0bce-\u0bcf\u0bd1-\u0bd6\u0bd8-\u0be5\u0bfb-\u0bff\u0c0d\u0c11\u0c29\u0c3a-\u0c3c\u0c45\u0c49\u0c4e-\u0c54\u0c57\u0c5b-\u0c5f\u0c64-\u0c65\u0c70-\u0c77\u0c8d\u0c91\u0ca9\u0cb4\u0cba-\u0cbb\u0cc5\u0cc9\u0cce-\u0cd4\u0cd7-\u0cdd\u0cdf\u0ce4-\u0ce5\u0cf0\u0cf3-\u0cff\u0d04\u0d0d\u0d11\u0d45\u0d49\u0d50-\u0d53\u0d64-\u0d65\u0d80-\u0d81\u0d84\u0d97-\u0d99\u0db2\u0dbc\u0dbe-\u0dbf\u0dc7-\u0dc9\u0dcb-\u0dce\u0dd5\u0dd7\u0de0-\u0de5\u0df0-\u0df1\u0df5-\u0e00\u0e3b-\u0e3e\u0e5c-\u0e80\u0e83\u0e85-\u0e86\u0e89\u0e8b-\u0e8c\u0e8e-\u0e93\u0e98\u0ea0\u0ea4\u0ea6\u0ea8-\u0ea9\u0eac\u0eba\u0ebe-\u0ebf\u0ec5\u0ec7\u0ece-\u0ecf\u0eda-\u0edb\u0ee0-\u0eff\u0f48\u0f6d-\u0f70\u0f98\u0fbd\u0fcd\u0fdb-\u0fff\u10c6\u10c8-\u10cc\u10ce-\u10cf\u1249\u124e-\u124f\u1257\u1259\u125e-\u125f\u1289\u128e-\u128f\u12b1\u12b6-\u12b7\u12bf\u12c1\u12c6-\u12c7\u12d7\u1311\u1316-\u1317\u135b-\u135c\u137d-\u137f\u139a-\u139f\u13f6-\u13f7\u13fe-\u13ff\u169d-\u169f\u16f9-\u16ff\u170d\u1715-\u171f\u1737-\u173f\u1754-\u175f\u176d\u1771\u1774-\u177f\u17de-\u17df\u17ea-\u17ef\u17fa-\u17ff\u180f\u181a-\u181f\u1879-\u187f\u18ab-\u18af\u18f6-\u18ff\u191f\u192c-\u192f\u193c-\u193f\u1941-\u1943\u196e-\u196f\u1975-\u197f\u19ac-\u19af\u19ca-\u19cf\u19db-\u19dd\u1a1c-\u1a1d\u1a5f\u1a7d-\u1a7e\u1a8a-\u1a8f\u1a9a-\u1a9f\u1aae-\u1aaf\u1abf-\u1aff\u1b4c-\u1b4f\u1b7d-\u1b7f\u1bf4-\u1bfb\u1c38-\u1c3a\u1c4a-\u1c4c\u1c89-\u1c8f\u1cbb-\u1cbc\u1cc8-\u1ccf\u1cfa-\u1cff\u1dfa\u1f16-\u1f17\u1f1e-\u1f1f\u1f46-\u1f47\u1f4e-\u1f4f\u1f58\u1f5a\u1f5c\u1f5e\u1f7e-\u1f7f\u1fb5\u1fc5\u1fd4-\u1fd5\u1fdc\u1ff0-\u1ff1\u1ff5\u1fff\u2065\u2072-\u2073\u208f\u209d-\u209f\u20c0-\u20cf\u20f1-\u20ff\u218c-\u218f\u2427-\u243f\u244b-\u245f\u2b74-\u2b75\u2b96-\u2b97\u2bc9\u2bff\u2c2f\u2c5f\u2cf4-\u2cf8\u2d26\u2d28-\u2d2c\u2d2e-\u2d2f\u2d68-\u2d6e\u2d71-\u2d7e\u2d97-\u2d9f\u2da7\u2daf\u2db7\u2dbf\u2dc7\u2dcf\u2dd7\u2ddf\u2e4f-\u2e7f\u2e9a\u2ef4-\u2eff\u2fd6-\u2fef\u2ffc-\u2fff\u3040\u3097-\u3098\u3100-\u3104\u3130\u318f\u31bb-\u31bf\u31e4-\u31ef\u321f\u32ff\u4db6-\u4dbf\u9ff0-\u9fff\ua48d-\ua48f\ua4c7-\ua4cf\ua62c-\ua63f\ua6f8-\ua6ff\ua7ba-\ua7f6\ua82c-\ua82f\ua83a-\ua83f\ua878-\ua87f\ua8c6-\ua8cd\ua8da-\ua8df\ua954-\ua95e\ua97d-\ua97f\ua9ce\ua9da-\ua9dd\ua9ff\uaa37-\uaa3f\uaa4e-\uaa4f\uaa5a-\uaa5b\uaac3-\uaada\uaaf7-\uab00\uab07-\uab08\uab0f-\uab10\uab17-\uab1f\uab27\uab2f\uab66-\uab6f\uabee-\uabef\uabfa-\uabff\ud7a4-\ud7af\ud7c7-\ud7ca\ud7fc-\ud7ff\ufa6e-\ufa6f\ufada-\ufaff\ufb07-\ufb12\ufb18-\ufb1c\ufb37\ufb3d\ufb3f\ufb42\ufb45\ufbc2-\ufbd2\ufd40-\ufd4f\ufd90-\ufd91\ufdc8-\ufdef\ufdfe-\ufdff\ufe1a-\ufe1f\ufe53\ufe67\ufe6c-\ufe6f\ufe75\ufefd-\ufefe\uff00\uffbf-\uffc1\uffc8-\uffc9\uffd0-\uffd1\uffd8-\uffd9\uffdd-\uffdf\uffe7\uffef-\ufff8\ufffe-\uffff\U0001000c\U00010027\U0001003b\U0001003e\U0001004e-\U0001004f\U0001005e-\U0001007f\U000100fb-\U000100ff\U00010103-\U00010106\U00010134-\U00010136\U0001018f\U0001019c-\U0001019f\U000101a1-\U000101cf\U000101fe-\U0001027f\U0001029d-\U0001029f\U000102d1-\U000102df\U000102fc-\U000102ff\U00010324-\U0001032c\U0001034b-\U0001034f\U0001037b-\U0001037f\U0001039e\U000103c4-\U000103c7\U000103d6-\U000103ff\U0001049e-\U0001049f\U000104aa-\U000104af\U000104d4-\U000104d7\U000104fc-\U000104ff\U00010528-\U0001052f\U00010564-\U0001056e\U00010570-\U000105ff\U00010737-\U0001073f\U00010756-\U0001075f\U00010768-\U000107ff\U00010806-\U00010807\U00010809\U00010836\U00010839-\U0001083b\U0001083d-\U0001083e\U00010856\U0001089f-\U000108a6\U000108b0-\U000108df\U000108f3\U000108f6-\U000108fa\U0001091c-\U0001091e\U0001093a-\U0001093e\U00010940-\U0001097f\U000109b8-\U000109bb\U000109d0-\U000109d1\U00010a04\U00010a07-\U00010a0b\U00010a14\U00010a18\U00010a36-\U00010a37\U00010a3b-\U00010a3e\U00010a49-\U00010a4f\U00010a59-\U00010a5f\U00010aa0-\U00010abf\U00010ae7-\U00010aea\U00010af7-\U00010aff\U00010b36-\U00010b38\U00010b56-\U00010b57\U00010b73-\U00010b77\U00010b92-\U00010b98\U00010b9d-\U00010ba8\U00010bb0-\U00010bff\U00010c49-\U00010c7f\U00010cb3-\U00010cbf\U00010cf3-\U00010cf9\U00010d28-\U00010d2f\U00010d3a-\U00010e5f\U00010e7f-\U00010eff\U00010f28-\U00010f2f\U00010f5a-\U00010fff\U0001104e-\U00011051\U00011070-\U0001107e\U000110c2-\U000110cc\U000110ce-\U000110cf\U000110e9-\U000110ef\U000110fa-\U000110ff\U00011135\U00011147-\U0001114f\U00011177-\U0001117f\U000111ce-\U000111cf\U000111e0\U000111f5-\U000111ff\U00011212\U0001123f-\U0001127f\U00011287\U00011289\U0001128e\U0001129e\U000112aa-\U000112af\U000112eb-\U000112ef\U000112fa-\U000112ff\U00011304\U0001130d-\U0001130e\U00011311-\U00011312\U00011329\U00011331\U00011334\U0001133a\U00011345-\U00011346\U00011349-\U0001134a\U0001134e-\U0001134f\U00011351-\U00011356\U00011358-\U0001135c\U00011364-\U00011365\U0001136d-\U0001136f\U00011375-\U000113ff\U0001145a\U0001145c\U0001145f-\U0001147f\U000114c8-\U000114cf\U000114da-\U0001157f\U000115b6-\U000115b7\U000115de-\U000115ff\U00011645-\U0001164f\U0001165a-\U0001165f\U0001166d-\U0001167f\U000116b8-\U000116bf\U000116ca-\U000116ff\U0001171b-\U0001171c\U0001172c-\U0001172f\U00011740-\U000117ff\U0001183c-\U0001189f\U000118f3-\U000118fe\U00011900-\U000119ff\U00011a48-\U00011a4f\U00011a84-\U00011a85\U00011aa3-\U00011abf\U00011af9-\U00011bff\U00011c09\U00011c37\U00011c46-\U00011c4f\U00011c6d-\U00011c6f\U00011c90-\U00011c91\U00011ca8\U00011cb7-\U00011cff\U00011d07\U00011d0a\U00011d37-\U00011d39\U00011d3b\U00011d3e\U00011d48-\U00011d4f\U00011d5a-\U00011d5f\U00011d66\U00011d69\U00011d8f\U00011d92\U00011d99-\U00011d9f\U00011daa-\U00011edf\U00011ef9-\U00011fff\U0001239a-\U000123ff\U0001246f\U00012475-\U0001247f\U00012544-\U00012fff\U0001342f-\U000143ff\U00014647-\U000167ff\U00016a39-\U00016a3f\U00016a5f\U00016a6a-\U00016a6d\U00016a70-\U00016acf\U00016aee-\U00016aef\U00016af6-\U00016aff\U00016b46-\U00016b4f\U00016b5a\U00016b62\U00016b78-\U00016b7c\U00016b90-\U00016e3f\U00016e9b-\U00016eff\U00016f45-\U00016f4f\U00016f7f-\U00016f8e\U00016fa0-\U00016fdf\U00016fe2-\U00016fff\U000187f2-\U000187ff\U00018af3-\U0001afff\U0001b11f-\U0001b16f\U0001b2fc-\U0001bbff\U0001bc6b-\U0001bc6f\U0001bc7d-\U0001bc7f\U0001bc89-\U0001bc8f\U0001bc9a-\U0001bc9b\U0001bca4-\U0001cfff\U0001d0f6-\U0001d0ff\U0001d127-\U0001d128\U0001d1e9-\U0001d1ff\U0001d246-\U0001d2df\U0001d2f4-\U0001d2ff\U0001d357-\U0001d35f\U0001d379-\U0001d3ff\U0001d455\U0001d49d\U0001d4a0-\U0001d4a1\U0001d4a3-\U0001d4a4\U0001d4a7-\U0001d4a8\U0001d4ad\U0001d4ba\U0001d4bc\U0001d4c4\U0001d506\U0001d50b-\U0001d50c\U0001d515\U0001d51d\U0001d53a\U0001d53f\U0001d545\U0001d547-\U0001d549\U0001d551\U0001d6a6-\U0001d6a7\U0001d7cc-\U0001d7cd\U0001da8c-\U0001da9a\U0001daa0\U0001dab0-\U0001dfff\U0001e007\U0001e019-\U0001e01a\U0001e022\U0001e025\U0001e02b-\U0001e7ff\U0001e8c5-\U0001e8c6\U0001e8d7-\U0001e8ff\U0001e94b-\U0001e94f\U0001e95a-\U0001e95d\U0001e960-\U0001ec70\U0001ecb5-\U0001edff\U0001ee04\U0001ee20\U0001ee23\U0001ee25-\U0001ee26\U0001ee28\U0001ee33\U0001ee38\U0001ee3a\U0001ee3c-\U0001ee41\U0001ee43-\U0001ee46\U0001ee48\U0001ee4a\U0001ee4c\U0001ee50\U0001ee53\U0001ee55-\U0001ee56\U0001ee58\U0001ee5a\U0001ee5c\U0001ee5e\U0001ee60\U0001ee63\U0001ee65-\U0001ee66\U0001ee6b\U0001ee73\U0001ee78\U0001ee7d\U0001ee7f\U0001ee8a\U0001ee9c-\U0001eea0\U0001eea4\U0001eeaa\U0001eebc-\U0001eeef\U0001eef2-\U0001efff\U0001f02c-\U0001f02f\U0001f094-\U0001f09f\U0001f0af-\U0001f0b0\U0001f0c0\U0001f0d0\U0001f0f6-\U0001f0ff\U0001f10d-\U0001f10f\U0001f16c-\U0001f16f\U0001f1ad-\U0001f1e5\U0001f203-\U0001f20f\U0001f23c-\U0001f23f\U0001f249-\U0001f24f\U0001f252-\U0001f25f\U0001f266-\U0001f2ff\U0001f6d5-\U0001f6df\U0001f6ed-\U0001f6ef\U0001f6fa-\U0001f6ff\U0001f774-\U0001f77f\U0001f7d9-\U0001f7ff\U0001f80c-\U0001f80f\U0001f848-\U0001f84f\U0001f85a-\U0001f85f\U0001f888-\U0001f88f\U0001f8ae-\U0001f8ff\U0001f90c-\U0001f90f\U0001f93f\U0001f971-\U0001f972\U0001f977-\U0001f979\U0001f97b\U0001f9a3-\U0001f9af\U0001f9ba-\U0001f9bf\U0001f9c3-\U0001f9cf\U0001fa00-\U0001fa5f\U0001fa6e-\U0001ffff\U0002a6d7-\U0002a6ff\U0002b735-\U0002b73f\U0002b81e-\U0002b81f\U0002cea2-\U0002ceaf\U0002ebe1-\U0002f7ff\U0002fa1e-\U000e0000\U000e0002-\U000e001f\U000e0080-\U000e00ff\U000e01f0-\U000effff\U000ffffe-\U000fffff\U0010fffe-\U0010ffff'

Co = '\ue000-\uf8ff\U000f0000-\U000ffffd\U00100000-\U0010fffd'

Cs = '\ud800-\udbff\\\udc00\udc01-\udfff'

Ll = 'a-z\xb5\xdf-\xf6\xf8-\xff\u0101\u0103\u0105\u0107\u0109\u010b\u010d\u010f\u0111\u0113\u0115\u0117\u0119\u011b\u011d\u011f\u0121\u0123\u0125\u0127\u0129\u012b\u012d\u012f\u0131\u0133\u0135\u0137-\u0138\u013a\u013c\u013e\u0140\u0142\u0144\u0146\u0148-\u0149\u014b\u014d\u014f\u0151\u0153\u0155\u0157\u0159\u015b\u015d\u015f\u0161\u0163\u0165\u0167\u0169\u016b\u016d\u016f\u0171\u0173\u0175\u0177\u017a\u017c\u017e-\u0180\u0183\u0185\u0188\u018c-\u018d\u0192\u0195\u0199-\u019b\u019e\u01a1\u01a3\u01a5\u01a8\u01aa-\u01ab\u01ad\u01b0\u01b4\u01b6\u01b9-\u01ba\u01bd-\u01bf\u01c6\u01c9\u01cc\u01ce\u01d0\u01d2\u01d4\u01d6\u01d8\u01da\u01dc-\u01dd\u01df\u01e1\u01e3\u01e5\u01e7\u01e9\u01eb\u01ed\u01ef-\u01f0\u01f3\u01f5\u01f9\u01fb\u01fd\u01ff\u0201\u0203\u0205\u0207\u0209\u020b\u020d\u020f\u0211\u0213\u0215\u0217\u0219\u021b\u021d\u021f\u0221\u0223\u0225\u0227\u0229\u022b\u022d\u022f\u0231\u0233-\u0239\u023c\u023f-\u0240\u0242\u0247\u0249\u024b\u024d\u024f-\u0293\u0295-\u02af\u0371\u0373\u0377\u037b-\u037d\u0390\u03ac-\u03ce\u03d0-\u03d1\u03d5-\u03d7\u03d9\u03db\u03dd\u03df\u03e1\u03e3\u03e5\u03e7\u03e9\u03eb\u03ed\u03ef-\u03f3\u03f5\u03f8\u03fb-\u03fc\u0430-\u045f\u0461\u0463\u0465\u0467\u0469\u046b\u046d\u046f\u0471\u0473\u0475\u0477\u0479\u047b\u047d\u047f\u0481\u048b\u048d\u048f\u0491\u0493\u0495\u0497\u0499\u049b\u049d\u049f\u04a1\u04a3\u04a5\u04a7\u04a9\u04ab\u04ad\u04af\u04b1\u04b3\u04b5\u04b7\u04b9\u04bb\u04bd\u04bf\u04c2\u04c4\u04c6\u04c8\u04ca\u04cc\u04ce-\u04cf\u04d1\u04d3\u04d5\u04d7\u04d9\u04db\u04dd\u04df\u04e1\u04e3\u04e5\u04e7\u04e9\u04eb\u04ed\u04ef\u04f1\u04f3\u04f5\u04f7\u04f9\u04fb\u04fd\u04ff\u0501\u0503\u0505\u0507\u0509\u050b\u050d\u050f\u0511\u0513\u0515\u0517\u0519\u051b\u051d\u051f\u0521\u0523\u0525\u0527\u0529\u052b\u052d\u052f\u0560-\u0588\u10d0-\u10fa\u10fd-\u10ff\u13f8-\u13fd\u1c80-\u1c88\u1d00-\u1d2b\u1d6b-\u1d77\u1d79-\u1d9a\u1e01\u1e03\u1e05\u1e07\u1e09\u1e0b\u1e0d\u1e0f\u1e11\u1e13\u1e15\u1e17\u1e19\u1e1b\u1e1d\u1e1f\u1e21\u1e23\u1e25\u1e27\u1e29\u1e2b\u1e2d\u1e2f\u1e31\u1e33\u1e35\u1e37\u1e39\u1e3b\u1e3d\u1e3f\u1e41\u1e43\u1e45\u1e47\u1e49\u1e4b\u1e4d\u1e4f\u1e51\u1e53\u1e55\u1e57\u1e59\u1e5b\u1e5d\u1e5f\u1e61\u1e63\u1e65\u1e67\u1e69\u1e6b\u1e6d\u1e6f\u1e71\u1e73\u1e75\u1e77\u1e79\u1e7b\u1e7d\u1e7f\u1e81\u1e83\u1e85\u1e87\u1e89\u1e8b\u1e8d\u1e8f\u1e91\u1e93\u1e95-\u1e9d\u1e9f\u1ea1\u1ea3\u1ea5\u1ea7\u1ea9\u1eab\u1ead\u1eaf\u1eb1\u1eb3\u1eb5\u1eb7\u1eb9\u1ebb\u1ebd\u1ebf\u1ec1\u1ec3\u1ec5\u1ec7\u1ec9\u1ecb\u1ecd\u1ecf\u1ed1\u1ed3\u1ed5\u1ed7\u1ed9\u1edb\u1edd\u1edf\u1ee1\u1ee3\u1ee5\u1ee7\u1ee9\u1eeb\u1eed\u1eef\u1ef1\u1ef3\u1ef5\u1ef7\u1ef9\u1efb\u1efd\u1eff-\u1f07\u1f10-\u1f15\u1f20-\u1f27\u1f30-\u1f37\u1f40-\u1f45\u1f50-\u1f57\u1f60-\u1f67\u1f70-\u1f7d\u1f80-\u1f87\u1f90-\u1f97\u1fa0-\u1fa7\u1fb0-\u1fb4\u1fb6-\u1fb7\u1fbe\u1fc2-\u1fc4\u1fc6-\u1fc7\u1fd0-\u1fd3\u1fd6-\u1fd7\u1fe0-\u1fe7\u1ff2-\u1ff4\u1ff6-\u1ff7\u210a\u210e-\u210f\u2113\u212f\u2134\u2139\u213c-\u213d\u2146-\u2149\u214e\u2184\u2c30-\u2c5e\u2c61\u2c65-\u2c66\u2c68\u2c6a\u2c6c\u2c71\u2c73-\u2c74\u2c76-\u2c7b\u2c81\u2c83\u2c85\u2c87\u2c89\u2c8b\u2c8d\u2c8f\u2c91\u2c93\u2c95\u2c97\u2c99\u2c9b\u2c9d\u2c9f\u2ca1\u2ca3\u2ca5\u2ca7\u2ca9\u2cab\u2cad\u2caf\u2cb1\u2cb3\u2cb5\u2cb7\u2cb9\u2cbb\u2cbd\u2cbf\u2cc1\u2cc3\u2cc5\u2cc7\u2cc9\u2ccb\u2ccd\u2ccf\u2cd1\u2cd3\u2cd5\u2cd7\u2cd9\u2cdb\u2cdd\u2cdf\u2ce1\u2ce3-\u2ce4\u2cec\u2cee\u2cf3\u2d00-\u2d25\u2d27\u2d2d\ua641\ua643\ua645\ua647\ua649\ua64b\ua64d\ua64f\ua651\ua653\ua655\ua657\ua659\ua65b\ua65d\ua65f\ua661\ua663\ua665\ua667\ua669\ua66b\ua66d\ua681\ua683\ua685\ua687\ua689\ua68b\ua68d\ua68f\ua691\ua693\ua695\ua697\ua699\ua69b\ua723\ua725\ua727\ua729\ua72b\ua72d\ua72f-\ua731\ua733\ua735\ua737\ua739\ua73b\ua73d\ua73f\ua741\ua743\ua745\ua747\ua749\ua74b\ua74d\ua74f\ua751\ua753\ua755\ua757\ua759\ua75b\ua75d\ua75f\ua761\ua763\ua765\ua767\ua769\ua76b\ua76d\ua76f\ua771-\ua778\ua77a\ua77c\ua77f\ua781\ua783\ua785\ua787\ua78c\ua78e\ua791\ua793-\ua795\ua797\ua799\ua79b\ua79d\ua79f\ua7a1\ua7a3\ua7a5\ua7a7\ua7a9\ua7af\ua7b5\ua7b7\ua7b9\ua7fa\uab30-\uab5a\uab60-\uab65\uab70-\uabbf\ufb00-\ufb06\ufb13-\ufb17\uff41-\uff5a\U00010428-\U0001044f\U000104d8-\U000104fb\U00010cc0-\U00010cf2\U000118c0-\U000118df\U00016e60-\U00016e7f\U0001d41a-\U0001d433\U0001d44e-\U0001d454\U0001d456-\U0001d467\U0001d482-\U0001d49b\U0001d4b6-\U0001d4b9\U0001d4bb\U0001d4bd-\U0001d4c3\U0001d4c5-\U0001d4cf\U0001d4ea-\U0001d503\U0001d51e-\U0001d537\U0001d552-\U0001d56b\U0001d586-\U0001d59f\U0001d5ba-\U0001d5d3\U0001d5ee-\U0001d607\U0001d622-\U0001d63b\U0001d656-\U0001d66f\U0001d68a-\U0001d6a5\U0001d6c2-\U0001d6da\U0001d6dc-\U0001d6e1\U0001d6fc-\U0001d714\U0001d716-\U0001d71b\U0001d736-\U0001d74e\U0001d750-\U0001d755\U0001d770-\U0001d788\U0001d78a-\U0001d78f\U0001d7aa-\U0001d7c2\U0001d7c4-\U0001d7c9\U0001d7cb\U0001e922-\U0001e943'

Lm = '\u02b0-\u02c1\u02c6-\u02d1\u02e0-\u02e4\u02ec\u02ee\u0374\u037a\u0559\u0640\u06e5-\u06e6\u07f4-\u07f5\u07fa\u081a\u0824\u0828\u0971\u0e46\u0ec6\u10fc\u17d7\u1843\u1aa7\u1c78-\u1c7d\u1d2c-\u1d6a\u1d78\u1d9b-\u1dbf\u2071\u207f\u2090-\u209c\u2c7c-\u2c7d\u2d6f\u2e2f\u3005\u3031-\u3035\u303b\u309d-\u309e\u30fc-\u30fe\ua015\ua4f8-\ua4fd\ua60c\ua67f\ua69c-\ua69d\ua717-\ua71f\ua770\ua788\ua7f8-\ua7f9\ua9cf\ua9e6\uaa70\uaadd\uaaf3-\uaaf4\uab5c-\uab5f\uff70\uff9e-\uff9f\U00016b40-\U00016b43\U00016f93-\U00016f9f\U00016fe0-\U00016fe1'

Lo = '\xaa\xba\u01bb\u01c0-\u01c3\u0294\u05d0-\u05ea\u05ef-\u05f2\u0620-\u063f\u0641-\u064a\u066e-\u066f\u0671-\u06d3\u06d5\u06ee-\u06ef\u06fa-\u06fc\u06ff\u0710\u0712-\u072f\u074d-\u07a5\u07b1\u07ca-\u07ea\u0800-\u0815\u0840-\u0858\u0860-\u086a\u08a0-\u08b4\u08b6-\u08bd\u0904-\u0939\u093d\u0950\u0958-\u0961\u0972-\u0980\u0985-\u098c\u098f-\u0990\u0993-\u09a8\u09aa-\u09b0\u09b2\u09b6-\u09b9\u09bd\u09ce\u09dc-\u09dd\u09df-\u09e1\u09f0-\u09f1\u09fc\u0a05-\u0a0a\u0a0f-\u0a10\u0a13-\u0a28\u0a2a-\u0a30\u0a32-\u0a33\u0a35-\u0a36\u0a38-\u0a39\u0a59-\u0a5c\u0a5e\u0a72-\u0a74\u0a85-\u0a8d\u0a8f-\u0a91\u0a93-\u0aa8\u0aaa-\u0ab0\u0ab2-\u0ab3\u0ab5-\u0ab9\u0abd\u0ad0\u0ae0-\u0ae1\u0af9\u0b05-\u0b0c\u0b0f-\u0b10\u0b13-\u0b28\u0b2a-\u0b30\u0b32-\u0b33\u0b35-\u0b39\u0b3d\u0b5c-\u0b5d\u0b5f-\u0b61\u0b71\u0b83\u0b85-\u0b8a\u0b8e-\u0b90\u0b92-\u0b95\u0b99-\u0b9a\u0b9c\u0b9e-\u0b9f\u0ba3-\u0ba4\u0ba8-\u0baa\u0bae-\u0bb9\u0bd0\u0c05-\u0c0c\u0c0e-\u0c10\u0c12-\u0c28\u0c2a-\u0c39\u0c3d\u0c58-\u0c5a\u0c60-\u0c61\u0c80\u0c85-\u0c8c\u0c8e-\u0c90\u0c92-\u0ca8\u0caa-\u0cb3\u0cb5-\u0cb9\u0cbd\u0cde\u0ce0-\u0ce1\u0cf1-\u0cf2\u0d05-\u0d0c\u0d0e-\u0d10\u0d12-\u0d3a\u0d3d\u0d4e\u0d54-\u0d56\u0d5f-\u0d61\u0d7a-\u0d7f\u0d85-\u0d96\u0d9a-\u0db1\u0db3-\u0dbb\u0dbd\u0dc0-\u0dc6\u0e01-\u0e30\u0e32-\u0e33\u0e40-\u0e45\u0e81-\u0e82\u0e84\u0e87-\u0e88\u0e8a\u0e8d\u0e94-\u0e97\u0e99-\u0e9f\u0ea1-\u0ea3\u0ea5\u0ea7\u0eaa-\u0eab\u0ead-\u0eb0\u0eb2-\u0eb3\u0ebd\u0ec0-\u0ec4\u0edc-\u0edf\u0f00\u0f40-\u0f47\u0f49-\u0f6c\u0f88-\u0f8c\u1000-\u102a\u103f\u1050-\u1055\u105a-\u105d\u1061\u1065-\u1066\u106e-\u1070\u1075-\u1081\u108e\u1100-\u1248\u124a-\u124d\u1250-\u1256\u1258\u125a-\u125d\u1260-\u1288\u128a-\u128d\u1290-\u12b0\u12b2-\u12b5\u12b8-\u12be\u12c0\u12c2-\u12c5\u12c8-\u12d6\u12d8-\u1310\u1312-\u1315\u1318-\u135a\u1380-\u138f\u1401-\u166c\u166f-\u167f\u1681-\u169a\u16a0-\u16ea\u16f1-\u16f8\u1700-\u170c\u170e-\u1711\u1720-\u1731\u1740-\u1751\u1760-\u176c\u176e-\u1770\u1780-\u17b3\u17dc\u1820-\u1842\u1844-\u1878\u1880-\u1884\u1887-\u18a8\u18aa\u18b0-\u18f5\u1900-\u191e\u1950-\u196d\u1970-\u1974\u1980-\u19ab\u19b0-\u19c9\u1a00-\u1a16\u1a20-\u1a54\u1b05-\u1b33\u1b45-\u1b4b\u1b83-\u1ba0\u1bae-\u1baf\u1bba-\u1be5\u1c00-\u1c23\u1c4d-\u1c4f\u1c5a-\u1c77\u1ce9-\u1cec\u1cee-\u1cf1\u1cf5-\u1cf6\u2135-\u2138\u2d30-\u2d67\u2d80-\u2d96\u2da0-\u2da6\u2da8-\u2dae\u2db0-\u2db6\u2db8-\u2dbe\u2dc0-\u2dc6\u2dc8-\u2dce\u2dd0-\u2dd6\u2dd8-\u2dde\u3006\u303c\u3041-\u3096\u309f\u30a1-\u30fa\u30ff\u3105-\u312f\u3131-\u318e\u31a0-\u31ba\u31f0-\u31ff\u3400-\u4db5\u4e00-\u9fef\ua000-\ua014\ua016-\ua48c\ua4d0-\ua4f7\ua500-\ua60b\ua610-\ua61f\ua62a-\ua62b\ua66e\ua6a0-\ua6e5\ua78f\ua7f7\ua7fb-\ua801\ua803-\ua805\ua807-\ua80a\ua80c-\ua822\ua840-\ua873\ua882-\ua8b3\ua8f2-\ua8f7\ua8fb\ua8fd-\ua8fe\ua90a-\ua925\ua930-\ua946\ua960-\ua97c\ua984-\ua9b2\ua9e0-\ua9e4\ua9e7-\ua9ef\ua9fa-\ua9fe\uaa00-\uaa28\uaa40-\uaa42\uaa44-\uaa4b\uaa60-\uaa6f\uaa71-\uaa76\uaa7a\uaa7e-\uaaaf\uaab1\uaab5-\uaab6\uaab9-\uaabd\uaac0\uaac2\uaadb-\uaadc\uaae0-\uaaea\uaaf2\uab01-\uab06\uab09-\uab0e\uab11-\uab16\uab20-\uab26\uab28-\uab2e\uabc0-\uabe2\uac00-\ud7a3\ud7b0-\ud7c6\ud7cb-\ud7fb\uf900-\ufa6d\ufa70-\ufad9\ufb1d\ufb1f-\ufb28\ufb2a-\ufb36\ufb38-\ufb3c\ufb3e\ufb40-\ufb41\ufb43-\ufb44\ufb46-\ufbb1\ufbd3-\ufd3d\ufd50-\ufd8f\ufd92-\ufdc7\ufdf0-\ufdfb\ufe70-\ufe74\ufe76-\ufefc\uff66-\uff6f\uff71-\uff9d\uffa0-\uffbe\uffc2-\uffc7\uffca-\uffcf\uffd2-\uffd7\uffda-\uffdc\U00010000-\U0001000b\U0001000d-\U00010026\U00010028-\U0001003a\U0001003c-\U0001003d\U0001003f-\U0001004d\U00010050-\U0001005d\U00010080-\U000100fa\U00010280-\U0001029c\U000102a0-\U000102d0\U00010300-\U0001031f\U0001032d-\U00010340\U00010342-\U00010349\U00010350-\U00010375\U00010380-\U0001039d\U000103a0-\U000103c3\U000103c8-\U000103cf\U00010450-\U0001049d\U00010500-\U00010527\U00010530-\U00010563\U00010600-\U00010736\U00010740-\U00010755\U00010760-\U00010767\U00010800-\U00010805\U00010808\U0001080a-\U00010835\U00010837-\U00010838\U0001083c\U0001083f-\U00010855\U00010860-\U00010876\U00010880-\U0001089e\U000108e0-\U000108f2\U000108f4-\U000108f5\U00010900-\U00010915\U00010920-\U00010939\U00010980-\U000109b7\U000109be-\U000109bf\U00010a00\U00010a10-\U00010a13\U00010a15-\U00010a17\U00010a19-\U00010a35\U00010a60-\U00010a7c\U00010a80-\U00010a9c\U00010ac0-\U00010ac7\U00010ac9-\U00010ae4\U00010b00-\U00010b35\U00010b40-\U00010b55\U00010b60-\U00010b72\U00010b80-\U00010b91\U00010c00-\U00010c48\U00010d00-\U00010d23\U00010f00-\U00010f1c\U00010f27\U00010f30-\U00010f45\U00011003-\U00011037\U00011083-\U000110af\U000110d0-\U000110e8\U00011103-\U00011126\U00011144\U00011150-\U00011172\U00011176\U00011183-\U000111b2\U000111c1-\U000111c4\U000111da\U000111dc\U00011200-\U00011211\U00011213-\U0001122b\U00011280-\U00011286\U00011288\U0001128a-\U0001128d\U0001128f-\U0001129d\U0001129f-\U000112a8\U000112b0-\U000112de\U00011305-\U0001130c\U0001130f-\U00011310\U00011313-\U00011328\U0001132a-\U00011330\U00011332-\U00011333\U00011335-\U00011339\U0001133d\U00011350\U0001135d-\U00011361\U00011400-\U00011434\U00011447-\U0001144a\U00011480-\U000114af\U000114c4-\U000114c5\U000114c7\U00011580-\U000115ae\U000115d8-\U000115db\U00011600-\U0001162f\U00011644\U00011680-\U000116aa\U00011700-\U0001171a\U00011800-\U0001182b\U000118ff\U00011a00\U00011a0b-\U00011a32\U00011a3a\U00011a50\U00011a5c-\U00011a83\U00011a86-\U00011a89\U00011a9d\U00011ac0-\U00011af8\U00011c00-\U00011c08\U00011c0a-\U00011c2e\U00011c40\U00011c72-\U00011c8f\U00011d00-\U00011d06\U00011d08-\U00011d09\U00011d0b-\U00011d30\U00011d46\U00011d60-\U00011d65\U00011d67-\U00011d68\U00011d6a-\U00011d89\U00011d98\U00011ee0-\U00011ef2\U00012000-\U00012399\U00012480-\U00012543\U00013000-\U0001342e\U00014400-\U00014646\U00016800-\U00016a38\U00016a40-\U00016a5e\U00016ad0-\U00016aed\U00016b00-\U00016b2f\U00016b63-\U00016b77\U00016b7d-\U00016b8f\U00016f00-\U00016f44\U00016f50\U00017000-\U000187f1\U00018800-\U00018af2\U0001b000-\U0001b11e\U0001b170-\U0001b2fb\U0001bc00-\U0001bc6a\U0001bc70-\U0001bc7c\U0001bc80-\U0001bc88\U0001bc90-\U0001bc99\U0001e800-\U0001e8c4\U0001ee00-\U0001ee03\U0001ee05-\U0001ee1f\U0001ee21-\U0001ee22\U0001ee24\U0001ee27\U0001ee29-\U0001ee32\U0001ee34-\U0001ee37\U0001ee39\U0001ee3b\U0001ee42\U0001ee47\U0001ee49\U0001ee4b\U0001ee4d-\U0001ee4f\U0001ee51-\U0001ee52\U0001ee54\U0001ee57\U0001ee59\U0001ee5b\U0001ee5d\U0001ee5f\U0001ee61-\U0001ee62\U0001ee64\U0001ee67-\U0001ee6a\U0001ee6c-\U0001ee72\U0001ee74-\U0001ee77\U0001ee79-\U0001ee7c\U0001ee7e\U0001ee80-\U0001ee89\U0001ee8b-\U0001ee9b\U0001eea1-\U0001eea3\U0001eea5-\U0001eea9\U0001eeab-\U0001eebb\U00020000-\U0002a6d6\U0002a700-\U0002b734\U0002b740-\U0002b81d\U0002b820-\U0002cea1\U0002ceb0-\U0002ebe0\U0002f800-\U0002fa1d'

Lt = '\u01c5\u01c8\u01cb\u01f2\u1f88-\u1f8f\u1f98-\u1f9f\u1fa8-\u1faf\u1fbc\u1fcc\u1ffc'

Lu = 'A-Z\xc0-\xd6\xd8-\xde\u0100\u0102\u0104\u0106\u0108\u010a\u010c\u010e\u0110\u0112\u0114\u0116\u0118\u011a\u011c\u011e\u0120\u0122\u0124\u0126\u0128\u012a\u012c\u012e\u0130\u0132\u0134\u0136\u0139\u013b\u013d\u013f\u0141\u0143\u0145\u0147\u014a\u014c\u014e\u0150\u0152\u0154\u0156\u0158\u015a\u015c\u015e\u0160\u0162\u0164\u0166\u0168\u016a\u016c\u016e\u0170\u0172\u0174\u0176\u0178-\u0179\u017b\u017d\u0181-\u0182\u0184\u0186-\u0187\u0189-\u018b\u018e-\u0191\u0193-\u0194\u0196-\u0198\u019c-\u019d\u019f-\u01a0\u01a2\u01a4\u01a6-\u01a7\u01a9\u01ac\u01ae-\u01af\u01b1-\u01b3\u01b5\u01b7-\u01b8\u01bc\u01c4\u01c7\u01ca\u01cd\u01cf\u01d1\u01d3\u01d5\u01d7\u01d9\u01db\u01de\u01e0\u01e2\u01e4\u01e6\u01e8\u01ea\u01ec\u01ee\u01f1\u01f4\u01f6-\u01f8\u01fa\u01fc\u01fe\u0200\u0202\u0204\u0206\u0208\u020a\u020c\u020e\u0210\u0212\u0214\u0216\u0218\u021a\u021c\u021e\u0220\u0222\u0224\u0226\u0228\u022a\u022c\u022e\u0230\u0232\u023a-\u023b\u023d-\u023e\u0241\u0243-\u0246\u0248\u024a\u024c\u024e\u0370\u0372\u0376\u037f\u0386\u0388-\u038a\u038c\u038e-\u038f\u0391-\u03a1\u03a3-\u03ab\u03cf\u03d2-\u03d4\u03d8\u03da\u03dc\u03de\u03e0\u03e2\u03e4\u03e6\u03e8\u03ea\u03ec\u03ee\u03f4\u03f7\u03f9-\u03fa\u03fd-\u042f\u0460\u0462\u0464\u0466\u0468\u046a\u046c\u046e\u0470\u0472\u0474\u0476\u0478\u047a\u047c\u047e\u0480\u048a\u048c\u048e\u0490\u0492\u0494\u0496\u0498\u049a\u049c\u049e\u04a0\u04a2\u04a4\u04a6\u04a8\u04aa\u04ac\u04ae\u04b0\u04b2\u04b4\u04b6\u04b8\u04ba\u04bc\u04be\u04c0-\u04c1\u04c3\u04c5\u04c7\u04c9\u04cb\u04cd\u04d0\u04d2\u04d4\u04d6\u04d8\u04da\u04dc\u04de\u04e0\u04e2\u04e4\u04e6\u04e8\u04ea\u04ec\u04ee\u04f0\u04f2\u04f4\u04f6\u04f8\u04fa\u04fc\u04fe\u0500\u0502\u0504\u0506\u0508\u050a\u050c\u050e\u0510\u0512\u0514\u0516\u0518\u051a\u051c\u051e\u0520\u0522\u0524\u0526\u0528\u052a\u052c\u052e\u0531-\u0556\u10a0-\u10c5\u10c7\u10cd\u13a0-\u13f5\u1c90-\u1cba\u1cbd-\u1cbf\u1e00\u1e02\u1e04\u1e06\u1e08\u1e0a\u1e0c\u1e0e\u1e10\u1e12\u1e14\u1e16\u1e18\u1e1a\u1e1c\u1e1e\u1e20\u1e22\u1e24\u1e26\u1e28\u1e2a\u1e2c\u1e2e\u1e30\u1e32\u1e34\u1e36\u1e38\u1e3a\u1e3c\u1e3e\u1e40\u1e42\u1e44\u1e46\u1e48\u1e4a\u1e4c\u1e4e\u1e50\u1e52\u1e54\u1e56\u1e58\u1e5a\u1e5c\u1e5e\u1e60\u1e62\u1e64\u1e66\u1e68\u1e6a\u1e6c\u1e6e\u1e70\u1e72\u1e74\u1e76\u1e78\u1e7a\u1e7c\u1e7e\u1e80\u1e82\u1e84\u1e86\u1e88\u1e8a\u1e8c\u1e8e\u1e90\u1e92\u1e94\u1e9e\u1ea0\u1ea2\u1ea4\u1ea6\u1ea8\u1eaa\u1eac\u1eae\u1eb0\u1eb2\u1eb4\u1eb6\u1eb8\u1eba\u1ebc\u1ebe\u1ec0\u1ec2\u1ec4\u1ec6\u1ec8\u1eca\u1ecc\u1ece\u1ed0\u1ed2\u1ed4\u1ed6\u1ed8\u1eda\u1edc\u1ede\u1ee0\u1ee2\u1ee4\u1ee6\u1ee8\u1eea\u1eec\u1eee\u1ef0\u1ef2\u1ef4\u1ef6\u1ef8\u1efa\u1efc\u1efe\u1f08-\u1f0f\u1f18-\u1f1d\u1f28-\u1f2f\u1f38-\u1f3f\u1f48-\u1f4d\u1f59\u1f5b\u1f5d\u1f5f\u1f68-\u1f6f\u1fb8-\u1fbb\u1fc8-\u1fcb\u1fd8-\u1fdb\u1fe8-\u1fec\u1ff8-\u1ffb\u2102\u2107\u210b-\u210d\u2110-\u2112\u2115\u2119-\u211d\u2124\u2126\u2128\u212a-\u212d\u2130-\u2133\u213e-\u213f\u2145\u2183\u2c00-\u2c2e\u2c60\u2c62-\u2c64\u2c67\u2c69\u2c6b\u2c6d-\u2c70\u2c72\u2c75\u2c7e-\u2c80\u2c82\u2c84\u2c86\u2c88\u2c8a\u2c8c\u2c8e\u2c90\u2c92\u2c94\u2c96\u2c98\u2c9a\u2c9c\u2c9e\u2ca0\u2ca2\u2ca4\u2ca6\u2ca8\u2caa\u2cac\u2cae\u2cb0\u2cb2\u2cb4\u2cb6\u2cb8\u2cba\u2cbc\u2cbe\u2cc0\u2cc2\u2cc4\u2cc6\u2cc8\u2cca\u2ccc\u2cce\u2cd0\u2cd2\u2cd4\u2cd6\u2cd8\u2cda\u2cdc\u2cde\u2ce0\u2ce2\u2ceb\u2ced\u2cf2\ua640\ua642\ua644\ua646\ua648\ua64a\ua64c\ua64e\ua650\ua652\ua654\ua656\ua658\ua65a\ua65c\ua65e\ua660\ua662\ua664\ua666\ua668\ua66a\ua66c\ua680\ua682\ua684\ua686\ua688\ua68a\ua68c\ua68e\ua690\ua692\ua694\ua696\ua698\ua69a\ua722\ua724\ua726\ua728\ua72a\ua72c\ua72e\ua732\ua734\ua736\ua738\ua73a\ua73c\ua73e\ua740\ua742\ua744\ua746\ua748\ua74a\ua74c\ua74e\ua750\ua752\ua754\ua756\ua758\ua75a\ua75c\ua75e\ua760\ua762\ua764\ua766\ua768\ua76a\ua76c\ua76e\ua779\ua77b\ua77d-\ua77e\ua780\ua782\ua784\ua786\ua78b\ua78d\ua790\ua792\ua796\ua798\ua79a\ua79c\ua79e\ua7a0\ua7a2\ua7a4\ua7a6\ua7a8\ua7aa-\ua7ae\ua7b0-\ua7b4\ua7b6\ua7b8\uff21-\uff3a\U00010400-\U00010427\U000104b0-\U000104d3\U00010c80-\U00010cb2\U000118a0-\U000118bf\U00016e40-\U00016e5f\U0001d400-\U0001d419\U0001d434-\U0001d44d\U0001d468-\U0001d481\U0001d49c\U0001d49e-\U0001d49f\U0001d4a2\U0001d4a5-\U0001d4a6\U0001d4a9-\U0001d4ac\U0001d4ae-\U0001d4b5\U0001d4d0-\U0001d4e9\U0001d504-\U0001d505\U0001d507-\U0001d50a\U0001d50d-\U0001d514\U0001d516-\U0001d51c\U0001d538-\U0001d539\U0001d53b-\U0001d53e\U0001d540-\U0001d544\U0001d546\U0001d54a-\U0001d550\U0001d56c-\U0001d585\U0001d5a0-\U0001d5b9\U0001d5d4-\U0001d5ed\U0001d608-\U0001d621\U0001d63c-\U0001d655\U0001d670-\U0001d689\U0001d6a8-\U0001d6c0\U0001d6e2-\U0001d6fa\U0001d71c-\U0001d734\U0001d756-\U0001d76e\U0001d790-\U0001d7a8\U0001d7ca\U0001e900-\U0001e921'

Mc = '\u0903\u093b\u093e-\u0940\u0949-\u094c\u094e-\u094f\u0982-\u0983\u09be-\u09c0\u09c7-\u09c8\u09cb-\u09cc\u09d7\u0a03\u0a3e-\u0a40\u0a83\u0abe-\u0ac0\u0ac9\u0acb-\u0acc\u0b02-\u0b03\u0b3e\u0b40\u0b47-\u0b48\u0b4b-\u0b4c\u0b57\u0bbe-\u0bbf\u0bc1-\u0bc2\u0bc6-\u0bc8\u0bca-\u0bcc\u0bd7\u0c01-\u0c03\u0c41-\u0c44\u0c82-\u0c83\u0cbe\u0cc0-\u0cc4\u0cc7-\u0cc8\u0cca-\u0ccb\u0cd5-\u0cd6\u0d02-\u0d03\u0d3e-\u0d40\u0d46-\u0d48\u0d4a-\u0d4c\u0d57\u0d82-\u0d83\u0dcf-\u0dd1\u0dd8-\u0ddf\u0df2-\u0df3\u0f3e-\u0f3f\u0f7f\u102b-\u102c\u1031\u1038\u103b-\u103c\u1056-\u1057\u1062-\u1064\u1067-\u106d\u1083-\u1084\u1087-\u108c\u108f\u109a-\u109c\u17b6\u17be-\u17c5\u17c7-\u17c8\u1923-\u1926\u1929-\u192b\u1930-\u1931\u1933-\u1938\u1a19-\u1a1a\u1a55\u1a57\u1a61\u1a63-\u1a64\u1a6d-\u1a72\u1b04\u1b35\u1b3b\u1b3d-\u1b41\u1b43-\u1b44\u1b82\u1ba1\u1ba6-\u1ba7\u1baa\u1be7\u1bea-\u1bec\u1bee\u1bf2-\u1bf3\u1c24-\u1c2b\u1c34-\u1c35\u1ce1\u1cf2-\u1cf3\u1cf7\u302e-\u302f\ua823-\ua824\ua827\ua880-\ua881\ua8b4-\ua8c3\ua952-\ua953\ua983\ua9b4-\ua9b5\ua9ba-\ua9bb\ua9bd-\ua9c0\uaa2f-\uaa30\uaa33-\uaa34\uaa4d\uaa7b\uaa7d\uaaeb\uaaee-\uaaef\uaaf5\uabe3-\uabe4\uabe6-\uabe7\uabe9-\uabea\uabec\U00011000\U00011002\U00011082\U000110b0-\U000110b2\U000110b7-\U000110b8\U0001112c\U00011145-\U00011146\U00011182\U000111b3-\U000111b5\U000111bf-\U000111c0\U0001122c-\U0001122e\U00011232-\U00011233\U00011235\U000112e0-\U000112e2\U00011302-\U00011303\U0001133e-\U0001133f\U00011341-\U00011344\U00011347-\U00011348\U0001134b-\U0001134d\U00011357\U00011362-\U00011363\U00011435-\U00011437\U00011440-\U00011441\U00011445\U000114b0-\U000114b2\U000114b9\U000114bb-\U000114be\U000114c1\U000115af-\U000115b1\U000115b8-\U000115bb\U000115be\U00011630-\U00011632\U0001163b-\U0001163c\U0001163e\U000116ac\U000116ae-\U000116af\U000116b6\U00011720-\U00011721\U00011726\U0001182c-\U0001182e\U00011838\U00011a39\U00011a57-\U00011a58\U00011a97\U00011c2f\U00011c3e\U00011ca9\U00011cb1\U00011cb4\U00011d8a-\U00011d8e\U00011d93-\U00011d94\U00011d96\U00011ef5-\U00011ef6\U00016f51-\U00016f7e\U0001d165-\U0001d166\U0001d16d-\U0001d172'

Me = '\u0488-\u0489\u1abe\u20dd-\u20e0\u20e2-\u20e4\ua670-\ua672'

Mn = '\u0300-\u036f\u0483-\u0487\u0591-\u05bd\u05bf\u05c1-\u05c2\u05c4-\u05c5\u05c7\u0610-\u061a\u064b-\u065f\u0670\u06d6-\u06dc\u06df-\u06e4\u06e7-\u06e8\u06ea-\u06ed\u0711\u0730-\u074a\u07a6-\u07b0\u07eb-\u07f3\u07fd\u0816-\u0819\u081b-\u0823\u0825-\u0827\u0829-\u082d\u0859-\u085b\u08d3-\u08e1\u08e3-\u0902\u093a\u093c\u0941-\u0948\u094d\u0951-\u0957\u0962-\u0963\u0981\u09bc\u09c1-\u09c4\u09cd\u09e2-\u09e3\u09fe\u0a01-\u0a02\u0a3c\u0a41-\u0a42\u0a47-\u0a48\u0a4b-\u0a4d\u0a51\u0a70-\u0a71\u0a75\u0a81-\u0a82\u0abc\u0ac1-\u0ac5\u0ac7-\u0ac8\u0acd\u0ae2-\u0ae3\u0afa-\u0aff\u0b01\u0b3c\u0b3f\u0b41-\u0b44\u0b4d\u0b56\u0b62-\u0b63\u0b82\u0bc0\u0bcd\u0c00\u0c04\u0c3e-\u0c40\u0c46-\u0c48\u0c4a-\u0c4d\u0c55-\u0c56\u0c62-\u0c63\u0c81\u0cbc\u0cbf\u0cc6\u0ccc-\u0ccd\u0ce2-\u0ce3\u0d00-\u0d01\u0d3b-\u0d3c\u0d41-\u0d44\u0d4d\u0d62-\u0d63\u0dca\u0dd2-\u0dd4\u0dd6\u0e31\u0e34-\u0e3a\u0e47-\u0e4e\u0eb1\u0eb4-\u0eb9\u0ebb-\u0ebc\u0ec8-\u0ecd\u0f18-\u0f19\u0f35\u0f37\u0f39\u0f71-\u0f7e\u0f80-\u0f84\u0f86-\u0f87\u0f8d-\u0f97\u0f99-\u0fbc\u0fc6\u102d-\u1030\u1032-\u1037\u1039-\u103a\u103d-\u103e\u1058-\u1059\u105e-\u1060\u1071-\u1074\u1082\u1085-\u1086\u108d\u109d\u135d-\u135f\u1712-\u1714\u1732-\u1734\u1752-\u1753\u1772-\u1773\u17b4-\u17b5\u17b7-\u17bd\u17c6\u17c9-\u17d3\u17dd\u180b-\u180d\u1885-\u1886\u18a9\u1920-\u1922\u1927-\u1928\u1932\u1939-\u193b\u1a17-\u1a18\u1a1b\u1a56\u1a58-\u1a5e\u1a60\u1a62\u1a65-\u1a6c\u1a73-\u1a7c\u1a7f\u1ab0-\u1abd\u1b00-\u1b03\u1b34\u1b36-\u1b3a\u1b3c\u1b42\u1b6b-\u1b73\u1b80-\u1b81\u1ba2-\u1ba5\u1ba8-\u1ba9\u1bab-\u1bad\u1be6\u1be8-\u1be9\u1bed\u1bef-\u1bf1\u1c2c-\u1c33\u1c36-\u1c37\u1cd0-\u1cd2\u1cd4-\u1ce0\u1ce2-\u1ce8\u1ced\u1cf4\u1cf8-\u1cf9\u1dc0-\u1df9\u1dfb-\u1dff\u20d0-\u20dc\u20e1\u20e5-\u20f0\u2cef-\u2cf1\u2d7f\u2de0-\u2dff\u302a-\u302d\u3099-\u309a\ua66f\ua674-\ua67d\ua69e-\ua69f\ua6f0-\ua6f1\ua802\ua806\ua80b\ua825-\ua826\ua8c4-\ua8c5\ua8e0-\ua8f1\ua8ff\ua926-\ua92d\ua947-\ua951\ua980-\ua982\ua9b3\ua9b6-\ua9b9\ua9bc\ua9e5\uaa29-\uaa2e\uaa31-\uaa32\uaa35-\uaa36\uaa43\uaa4c\uaa7c\uaab0\uaab2-\uaab4\uaab7-\uaab8\uaabe-\uaabf\uaac1\uaaec-\uaaed\uaaf6\uabe5\uabe8\uabed\ufb1e\ufe00-\ufe0f\ufe20-\ufe2f\U000101fd\U000102e0\U00010376-\U0001037a\U00010a01-\U00010a03\U00010a05-\U00010a06\U00010a0c-\U00010a0f\U00010a38-\U00010a3a\U00010a3f\U00010ae5-\U00010ae6\U00010d24-\U00010d27\U00010f46-\U00010f50\U00011001\U00011038-\U00011046\U0001107f-\U00011081\U000110b3-\U000110b6\U000110b9-\U000110ba\U00011100-\U00011102\U00011127-\U0001112b\U0001112d-\U00011134\U00011173\U00011180-\U00011181\U000111b6-\U000111be\U000111c9-\U000111cc\U0001122f-\U00011231\U00011234\U00011236-\U00011237\U0001123e\U000112df\U000112e3-\U000112ea\U00011300-\U00011301\U0001133b-\U0001133c\U00011340\U00011366-\U0001136c\U00011370-\U00011374\U00011438-\U0001143f\U00011442-\U00011444\U00011446\U0001145e\U000114b3-\U000114b8\U000114ba\U000114bf-\U000114c0\U000114c2-\U000114c3\U000115b2-\U000115b5\U000115bc-\U000115bd\U000115bf-\U000115c0\U000115dc-\U000115dd\U00011633-\U0001163a\U0001163d\U0001163f-\U00011640\U000116ab\U000116ad\U000116b0-\U000116b5\U000116b7\U0001171d-\U0001171f\U00011722-\U00011725\U00011727-\U0001172b\U0001182f-\U00011837\U00011839-\U0001183a\U00011a01-\U00011a0a\U00011a33-\U00011a38\U00011a3b-\U00011a3e\U00011a47\U00011a51-\U00011a56\U00011a59-\U00011a5b\U00011a8a-\U00011a96\U00011a98-\U00011a99\U00011c30-\U00011c36\U00011c38-\U00011c3d\U00011c3f\U00011c92-\U00011ca7\U00011caa-\U00011cb0\U00011cb2-\U00011cb3\U00011cb5-\U00011cb6\U00011d31-\U00011d36\U00011d3a\U00011d3c-\U00011d3d\U00011d3f-\U00011d45\U00011d47\U00011d90-\U00011d91\U00011d95\U00011d97\U00011ef3-\U00011ef4\U00016af0-\U00016af4\U00016b30-\U00016b36\U00016f8f-\U00016f92\U0001bc9d-\U0001bc9e\U0001d167-\U0001d169\U0001d17b-\U0001d182\U0001d185-\U0001d18b\U0001d1aa-\U0001d1ad\U0001d242-\U0001d244\U0001da00-\U0001da36\U0001da3b-\U0001da6c\U0001da75\U0001da84\U0001da9b-\U0001da9f\U0001daa1-\U0001daaf\U0001e000-\U0001e006\U0001e008-\U0001e018\U0001e01b-\U0001e021\U0001e023-\U0001e024\U0001e026-\U0001e02a\U0001e8d0-\U0001e8d6\U0001e944-\U0001e94a\U000e0100-\U000e01ef'

Nd = '0-9\u0660-\u0669\u06f0-\u06f9\u07c0-\u07c9\u0966-\u096f\u09e6-\u09ef\u0a66-\u0a6f\u0ae6-\u0aef\u0b66-\u0b6f\u0be6-\u0bef\u0c66-\u0c6f\u0ce6-\u0cef\u0d66-\u0d6f\u0de6-\u0def\u0e50-\u0e59\u0ed0-\u0ed9\u0f20-\u0f29\u1040-\u1049\u1090-\u1099\u17e0-\u17e9\u1810-\u1819\u1946-\u194f\u19d0-\u19d9\u1a80-\u1a89\u1a90-\u1a99\u1b50-\u1b59\u1bb0-\u1bb9\u1c40-\u1c49\u1c50-\u1c59\ua620-\ua629\ua8d0-\ua8d9\ua900-\ua909\ua9d0-\ua9d9\ua9f0-\ua9f9\uaa50-\uaa59\uabf0-\uabf9\uff10-\uff19\U000104a0-\U000104a9\U00010d30-\U00010d39\U00011066-\U0001106f\U000110f0-\U000110f9\U00011136-\U0001113f\U000111d0-\U000111d9\U000112f0-\U000112f9\U00011450-\U00011459\U000114d0-\U000114d9\U00011650-\U00011659\U000116c0-\U000116c9\U00011730-\U00011739\U000118e0-\U000118e9\U00011c50-\U00011c59\U00011d50-\U00011d59\U00011da0-\U00011da9\U00016a60-\U00016a69\U00016b50-\U00016b59\U0001d7ce-\U0001d7ff\U0001e950-\U0001e959'

Nl = '\u16ee-\u16f0\u2160-\u2182\u2185-\u2188\u3007\u3021-\u3029\u3038-\u303a\ua6e6-\ua6ef\U00010140-\U00010174\U00010341\U0001034a\U000103d1-\U000103d5\U00012400-\U0001246e'

No = '\xb2-\xb3\xb9\xbc-\xbe\u09f4-\u09f9\u0b72-\u0b77\u0bf0-\u0bf2\u0c78-\u0c7e\u0d58-\u0d5e\u0d70-\u0d78\u0f2a-\u0f33\u1369-\u137c\u17f0-\u17f9\u19da\u2070\u2074-\u2079\u2080-\u2089\u2150-\u215f\u2189\u2460-\u249b\u24ea-\u24ff\u2776-\u2793\u2cfd\u3192-\u3195\u3220-\u3229\u3248-\u324f\u3251-\u325f\u3280-\u3289\u32b1-\u32bf\ua830-\ua835\U00010107-\U00010133\U00010175-\U00010178\U0001018a-\U0001018b\U000102e1-\U000102fb\U00010320-\U00010323\U00010858-\U0001085f\U00010879-\U0001087f\U000108a7-\U000108af\U000108fb-\U000108ff\U00010916-\U0001091b\U000109bc-\U000109bd\U000109c0-\U000109cf\U000109d2-\U000109ff\U00010a40-\U00010a48\U00010a7d-\U00010a7e\U00010a9d-\U00010a9f\U00010aeb-\U00010aef\U00010b58-\U00010b5f\U00010b78-\U00010b7f\U00010ba9-\U00010baf\U00010cfa-\U00010cff\U00010e60-\U00010e7e\U00010f1d-\U00010f26\U00010f51-\U00010f54\U00011052-\U00011065\U000111e1-\U000111f4\U0001173a-\U0001173b\U000118ea-\U000118f2\U00011c5a-\U00011c6c\U00016b5b-\U00016b61\U00016e80-\U00016e96\U0001d2e0-\U0001d2f3\U0001d360-\U0001d378\U0001e8c7-\U0001e8cf\U0001ec71-\U0001ecab\U0001ecad-\U0001ecaf\U0001ecb1-\U0001ecb4\U0001f100-\U0001f10c'

Pc = '_\u203f-\u2040\u2054\ufe33-\ufe34\ufe4d-\ufe4f\uff3f'

Pd = '\\-\u058a\u05be\u1400\u1806\u2010-\u2015\u2e17\u2e1a\u2e3a-\u2e3b\u2e40\u301c\u3030\u30a0\ufe31-\ufe32\ufe58\ufe63\uff0d'

Pe = ')\\]}\u0f3b\u0f3d\u169c\u2046\u207e\u208e\u2309\u230b\u232a\u2769\u276b\u276d\u276f\u2771\u2773\u2775\u27c6\u27e7\u27e9\u27eb\u27ed\u27ef\u2984\u2986\u2988\u298a\u298c\u298e\u2990\u2992\u2994\u2996\u2998\u29d9\u29db\u29fd\u2e23\u2e25\u2e27\u2e29\u3009\u300b\u300d\u300f\u3011\u3015\u3017\u3019\u301b\u301e-\u301f\ufd3e\ufe18\ufe36\ufe38\ufe3a\ufe3c\ufe3e\ufe40\ufe42\ufe44\ufe48\ufe5a\ufe5c\ufe5e\uff09\uff3d\uff5d\uff60\uff63'

Pf = '\xbb\u2019\u201d\u203a\u2e03\u2e05\u2e0a\u2e0d\u2e1d\u2e21'

Pi = '\xab\u2018\u201b-\u201c\u201f\u2039\u2e02\u2e04\u2e09\u2e0c\u2e1c\u2e20'

Po = ""!-

Ps = '(\\[{\u0f3a\u0f3c\u169b\u201a\u201e\u2045\u207d\u208d\u2308\u230a\u2329\u2768\u276a\u276c\u276e\u2770\u2772\u2774\u27c5\u27e6\u27e8\u27ea\u27ec\u27ee\u2983\u2985\u2987\u2989\u298b\u298d\u298f\u2991\u2993\u2995\u2997\u29d8\u29da\u29fc\u2e22\u2e24\u2e26\u2e28\u2e42\u3008\u300a\u300c\u300e\u3010\u3014\u3016\u3018\u301a\u301d\ufd3f\ufe17\ufe35\ufe37\ufe39\ufe3b\ufe3d\ufe3f\ufe41\ufe43\ufe47\ufe59\ufe5b\ufe5d\uff08\uff3b\uff5b\uff5f\uff62'

Sc = '$\xa2-\xa5\u058f\u060b\u07fe-\u07ff\u09f2-\u09f3\u09fb\u0af1\u0bf9\u0e3f\u17db\u20a0-\u20bf\ua838\ufdfc\ufe69\uff04\uffe0-\uffe1\uffe5-\uffe6\U0001ecb0'

Sk = '\\^`\xa8\xaf\xb4\xb8\u02c2-\u02c5\u02d2-\u02df\u02e5-\u02eb\u02ed\u02ef-\u02ff\u0375\u0384-\u0385\u1fbd\u1fbf-\u1fc1\u1fcd-\u1fcf\u1fdd-\u1fdf\u1fed-\u1fef\u1ffd-\u1ffe\u309b-\u309c\ua700-\ua716\ua720-\ua721\ua789-\ua78a\uab5b\ufbb2-\ufbc1\uff3e\uff40\uffe3\U0001f3fb-\U0001f3ff'

Sm = '+<->|~\xac\xb1\xd7\xf7\u03f6\u0606-\u0608\u2044\u2052\u207a-\u207c\u208a-\u208c\u2118\u2140-\u2144\u214b\u2190-\u2194\u219a-\u219b\u21a0\u21a3\u21a6\u21ae\u21ce-\u21cf\u21d2\u21d4\u21f4-\u22ff\u2320-\u2321\u237c\u239b-\u23b3\u23dc-\u23e1\u25b7\u25c1\u25f8-\u25ff\u266f\u27c0-\u27c4\u27c7-\u27e5\u27f0-\u27ff\u2900-\u2982\u2999-\u29d7\u29dc-\u29fb\u29fe-\u2aff\u2b30-\u2b44\u2b47-\u2b4c\ufb29\ufe62\ufe64-\ufe66\uff0b\uff1c-\uff1e\uff5c\uff5e\uffe2\uffe9-\uffec\U0001d6c1\U0001d6db\U0001d6fb\U0001d715\U0001d735\U0001d74f\U0001d76f\U0001d789\U0001d7a9\U0001d7c3\U0001eef0-\U0001eef1'

So = '\xa6\xa9\xae\xb0\u0482\u058d-\u058e\u060e-\u060f\u06de\u06e9\u06fd-\u06fe\u07f6\u09fa\u0b70\u0bf3-\u0bf8\u0bfa\u0c7f\u0d4f\u0d79\u0f01-\u0f03\u0f13\u0f15-\u0f17\u0f1a-\u0f1f\u0f34\u0f36\u0f38\u0fbe-\u0fc5\u0fc7-\u0fcc\u0fce-\u0fcf\u0fd5-\u0fd8\u109e-\u109f\u1390-\u1399\u1940\u19de-\u19ff\u1b61-\u1b6a\u1b74-\u1b7c\u2100-\u2101\u2103-\u2106\u2108-\u2109\u2114\u2116-\u2117\u211e-\u2123\u2125\u2127\u2129\u212e\u213a-\u213b\u214a\u214c-\u214d\u214f\u218a-\u218b\u2195-\u2199\u219c-\u219f\u21a1-\u21a2\u21a4-\u21a5\u21a7-\u21ad\u21af-\u21cd\u21d0-\u21d1\u21d3\u21d5-\u21f3\u2300-\u2307\u230c-\u231f\u2322-\u2328\u232b-\u237b\u237d-\u239a\u23b4-\u23db\u23e2-\u2426\u2440-\u244a\u249c-\u24e9\u2500-\u25b6\u25b8-\u25c0\u25c2-\u25f7\u2600-\u266e\u2670-\u2767\u2794-\u27bf\u2800-\u28ff\u2b00-\u2b2f\u2b45-\u2b46\u2b4d-\u2b73\u2b76-\u2b95\u2b98-\u2bc8\u2bca-\u2bfe\u2ce5-\u2cea\u2e80-\u2e99\u2e9b-\u2ef3\u2f00-\u2fd5\u2ff0-\u2ffb\u3004\u3012-\u3013\u3020\u3036-\u3037\u303e-\u303f\u3190-\u3191\u3196-\u319f\u31c0-\u31e3\u3200-\u321e\u322a-\u3247\u3250\u3260-\u327f\u328a-\u32b0\u32c0-\u32fe\u3300-\u33ff\u4dc0-\u4dff\ua490-\ua4c6\ua828-\ua82b\ua836-\ua837\ua839\uaa77-\uaa79\ufdfd\uffe4\uffe8\uffed-\uffee\ufffc-\ufffd\U00010137-\U0001013f\U00010179-\U00010189\U0001018c-\U0001018e\U00010190-\U0001019b\U000101a0\U000101d0-\U000101fc\U00010877-\U00010878\U00010ac8\U0001173f\U00016b3c-\U00016b3f\U00016b45\U0001bc9c\U0001d000-\U0001d0f5\U0001d100-\U0001d126\U0001d129-\U0001d164\U0001d16a-\U0001d16c\U0001d183-\U0001d184\U0001d18c-\U0001d1a9\U0001d1ae-\U0001d1e8\U0001d200-\U0001d241\U0001d245\U0001d300-\U0001d356\U0001d800-\U0001d9ff\U0001da37-\U0001da3a\U0001da6d-\U0001da74\U0001da76-\U0001da83\U0001da85-\U0001da86\U0001ecac\U0001f000-\U0001f02b\U0001f030-\U0001f093\U0001f0a0-\U0001f0ae\U0001f0b1-\U0001f0bf\U0001f0c1-\U0001f0cf\U0001f0d1-\U0001f0f5\U0001f110-\U0001f16b\U0001f170-\U0001f1ac\U0001f1e6-\U0001f202\U0001f210-\U0001f23b\U0001f240-\U0001f248\U0001f250-\U0001f251\U0001f260-\U0001f265\U0001f300-\U0001f3fa\U0001f400-\U0001f6d4\U0001f6e0-\U0001f6ec\U0001f6f0-\U0001f6f9\U0001f700-\U0001f773\U0001f780-\U0001f7d8\U0001f800-\U0001f80b\U0001f810-\U0001f847\U0001f850-\U0001f859\U0001f860-\U0001f887\U0001f890-\U0001f8ad\U0001f900-\U0001f90b\U0001f910-\U0001f93e\U0001f940-\U0001f970\U0001f973-\U0001f976\U0001f97a\U0001f97c-\U0001f9a2\U0001f9b0-\U0001f9b9\U0001f9c0-\U0001f9c2\U0001f9d0-\U0001f9ff\U0001fa60-\U0001fa6d'

Zl = '\u2028'

Zp = '\u2029'

Zs = ' \xa0\u1680\u2000-\u200a\u202f\u205f\u3000'

xid_continue = '0-9A-Z_a-z\xaa\xb5\xb7\xba\xc0-\xd6\xd8-\xf6\xf8-\u02c1\u02c6-\u02d1\u02e0-\u02e4\u02ec\u02ee\u0300-\u0374\u0376-\u0377\u037b-\u037d\u037f\u0386-\u038a\u038c\u038e-\u03a1\u03a3-\u03f5\u03f7-\u0481\u0483-\u0487\u048a-\u052f\u0531-\u0556\u0559\u0560-\u0588\u0591-\u05bd\u05bf\u05c1-\u05c2\u05c4-\u05c5\u05c7\u05d0-\u05ea\u05ef-\u05f2\u0610-\u061a\u0620-\u0669\u066e-\u06d3\u06d5-\u06dc\u06df-\u06e8\u06ea-\u06fc\u06ff\u0710-\u074a\u074d-\u07b1\u07c0-\u07f5\u07fa\u07fd\u0800-\u082d\u0840-\u085b\u0860-\u086a\u08a0-\u08b4\u08b6-\u08bd\u08d3-\u08e1\u08e3-\u0963\u0966-\u096f\u0971-\u0983\u0985-\u098c\u098f-\u0990\u0993-\u09a8\u09aa-\u09b0\u09b2\u09b6-\u09b9\u09bc-\u09c4\u09c7-\u09c8\u09cb-\u09ce\u09d7\u09dc-\u09dd\u09df-\u09e3\u09e6-\u09f1\u09fc\u09fe\u0a01-\u0a03\u0a05-\u0a0a\u0a0f-\u0a10\u0a13-\u0a28\u0a2a-\u0a30\u0a32-\u0a33\u0a35-\u0a36\u0a38-\u0a39\u0a3c\u0a3e-\u0a42\u0a47-\u0a48\u0a4b-\u0a4d\u0a51\u0a59-\u0a5c\u0a5e\u0a66-\u0a75\u0a81-\u0a83\u0a85-\u0a8d\u0a8f-\u0a91\u0a93-\u0aa8\u0aaa-\u0ab0\u0ab2-\u0ab3\u0ab5-\u0ab9\u0abc-\u0ac5\u0ac7-\u0ac9\u0acb-\u0acd\u0ad0\u0ae0-\u0ae3\u0ae6-\u0aef\u0af9-\u0aff\u0b01-\u0b03\u0b05-\u0b0c\u0b0f-\u0b10\u0b13-\u0b28\u0b2a-\u0b30\u0b32-\u0b33\u0b35-\u0b39\u0b3c-\u0b44\u0b47-\u0b48\u0b4b-\u0b4d\u0b56-\u0b57\u0b5c-\u0b5d\u0b5f-\u0b63\u0b66-\u0b6f\u0b71\u0b82-\u0b83\u0b85-\u0b8a\u0b8e-\u0b90\u0b92-\u0b95\u0b99-\u0b9a\u0b9c\u0b9e-\u0b9f\u0ba3-\u0ba4\u0ba8-\u0baa\u0bae-\u0bb9\u0bbe-\u0bc2\u0bc6-\u0bc8\u0bca-\u0bcd\u0bd0\u0bd7\u0be6-\u0bef\u0c00-\u0c0c\u0c0e-\u0c10\u0c12-\u0c28\u0c2a-\u0c39\u0c3d-\u0c44\u0c46-\u0c48\u0c4a-\u0c4d\u0c55-\u0c56\u0c58-\u0c5a\u0c60-\u0c63\u0c66-\u0c6f\u0c80-\u0c83\u0c85-\u0c8c\u0c8e-\u0c90\u0c92-\u0ca8\u0caa-\u0cb3\u0cb5-\u0cb9\u0cbc-\u0cc4\u0cc6-\u0cc8\u0cca-\u0ccd\u0cd5-\u0cd6\u0cde\u0ce0-\u0ce3\u0ce6-\u0cef\u0cf1-\u0cf2\u0d00-\u0d03\u0d05-\u0d0c\u0d0e-\u0d10\u0d12-\u0d44\u0d46-\u0d48\u0d4a-\u0d4e\u0d54-\u0d57\u0d5f-\u0d63\u0d66-\u0d6f\u0d7a-\u0d7f\u0d82-\u0d83\u0d85-\u0d96\u0d9a-\u0db1\u0db3-\u0dbb\u0dbd\u0dc0-\u0dc6\u0dca\u0dcf-\u0dd4\u0dd6\u0dd8-\u0ddf\u0de6-\u0def\u0df2-\u0df3\u0e01-\u0e3a\u0e40-\u0e4e\u0e50-\u0e59\u0e81-\u0e82\u0e84\u0e87-\u0e88\u0e8a\u0e8d\u0e94-\u0e97\u0e99-\u0e9f\u0ea1-\u0ea3\u0ea5\u0ea7\u0eaa-\u0eab\u0ead-\u0eb9\u0ebb-\u0ebd\u0ec0-\u0ec4\u0ec6\u0ec8-\u0ecd\u0ed0-\u0ed9\u0edc-\u0edf\u0f00\u0f18-\u0f19\u0f20-\u0f29\u0f35\u0f37\u0f39\u0f3e-\u0f47\u0f49-\u0f6c\u0f71-\u0f84\u0f86-\u0f97\u0f99-\u0fbc\u0fc6\u1000-\u1049\u1050-\u109d\u10a0-\u10c5\u10c7\u10cd\u10d0-\u10fa\u10fc-\u1248\u124a-\u124d\u1250-\u1256\u1258\u125a-\u125d\u1260-\u1288\u128a-\u128d\u1290-\u12b0\u12b2-\u12b5\u12b8-\u12be\u12c0\u12c2-\u12c5\u12c8-\u12d6\u12d8-\u1310\u1312-\u1315\u1318-\u135a\u135d-\u135f\u1369-\u1371\u1380-\u138f\u13a0-\u13f5\u13f8-\u13fd\u1401-\u166c\u166f-\u167f\u1681-\u169a\u16a0-\u16ea\u16ee-\u16f8\u1700-\u170c\u170e-\u1714\u1720-\u1734\u1740-\u1753\u1760-\u176c\u176e-\u1770\u1772-\u1773\u1780-\u17d3\u17d7\u17dc-\u17dd\u17e0-\u17e9\u180b-\u180d\u1810-\u1819\u1820-\u1878\u1880-\u18aa\u18b0-\u18f5\u1900-\u191e\u1920-\u192b\u1930-\u193b\u1946-\u196d\u1970-\u1974\u1980-\u19ab\u19b0-\u19c9\u19d0-\u19da\u1a00-\u1a1b\u1a20-\u1a5e\u1a60-\u1a7c\u1a7f-\u1a89\u1a90-\u1a99\u1aa7\u1ab0-\u1abd\u1b00-\u1b4b\u1b50-\u1b59\u1b6b-\u1b73\u1b80-\u1bf3\u1c00-\u1c37\u1c40-\u1c49\u1c4d-\u1c7d\u1c80-\u1c88\u1c90-\u1cba\u1cbd-\u1cbf\u1cd0-\u1cd2\u1cd4-\u1cf9\u1d00-\u1df9\u1dfb-\u1f15\u1f18-\u1f1d\u1f20-\u1f45\u1f48-\u1f4d\u1f50-\u1f57\u1f59\u1f5b\u1f5d\u1f5f-\u1f7d\u1f80-\u1fb4\u1fb6-\u1fbc\u1fbe\u1fc2-\u1fc4\u1fc6-\u1fcc\u1fd0-\u1fd3\u1fd6-\u1fdb\u1fe0-\u1fec\u1ff2-\u1ff4\u1ff6-\u1ffc\u203f-\u2040\u2054\u2071\u207f\u2090-\u209c\u20d0-\u20dc\u20e1\u20e5-\u20f0\u2102\u2107\u210a-\u2113\u2115\u2118-\u211d\u2124\u2126\u2128\u212a-\u2139\u213c-\u213f\u2145-\u2149\u214e\u2160-\u2188\u2c00-\u2c2e\u2c30-\u2c5e\u2c60-\u2ce4\u2ceb-\u2cf3\u2d00-\u2d25\u2d27\u2d2d\u2d30-\u2d67\u2d6f\u2d7f-\u2d96\u2da0-\u2da6\u2da8-\u2dae\u2db0-\u2db6\u2db8-\u2dbe\u2dc0-\u2dc6\u2dc8-\u2dce\u2dd0-\u2dd6\u2dd8-\u2dde\u2de0-\u2dff\u3005-\u3007\u3021-\u302f\u3031-\u3035\u3038-\u303c\u3041-\u3096\u3099-\u309a\u309d-\u309f\u30a1-\u30fa\u30fc-\u30ff\u3105-\u312f\u3131-\u318e\u31a0-\u31ba\u31f0-\u31ff\u3400-\u4db5\u4e00-\u9fef\ua000-\ua48c\ua4d0-\ua4fd\ua500-\ua60c\ua610-\ua62b\ua640-\ua66f\ua674-\ua67d\ua67f-\ua6f1\ua717-\ua71f\ua722-\ua788\ua78b-\ua7b9\ua7f7-\ua827\ua840-\ua873\ua880-\ua8c5\ua8d0-\ua8d9\ua8e0-\ua8f7\ua8fb\ua8fd-\ua92d\ua930-\ua953\ua960-\ua97c\ua980-\ua9c0\ua9cf-\ua9d9\ua9e0-\ua9fe\uaa00-\uaa36\uaa40-\uaa4d\uaa50-\uaa59\uaa60-\uaa76\uaa7a-\uaac2\uaadb-\uaadd\uaae0-\uaaef\uaaf2-\uaaf6\uab01-\uab06\uab09-\uab0e\uab11-\uab16\uab20-\uab26\uab28-\uab2e\uab30-\uab5a\uab5c-\uab65\uab70-\uabea\uabec-\uabed\uabf0-\uabf9\uac00-\ud7a3\ud7b0-\ud7c6\ud7cb-\ud7fb\uf900-\ufa6d\ufa70-\ufad9\ufb00-\ufb06\ufb13-\ufb17\ufb1d-\ufb28\ufb2a-\ufb36\ufb38-\ufb3c\ufb3e\ufb40-\ufb41\ufb43-\ufb44\ufb46-\ufbb1\ufbd3-\ufc5d\ufc64-\ufd3d\ufd50-\ufd8f\ufd92-\ufdc7\ufdf0-\ufdf9\ufe00-\ufe0f\ufe20-\ufe2f\ufe33-\ufe34\ufe4d-\ufe4f\ufe71\ufe73\ufe77\ufe79\ufe7b\ufe7d\ufe7f-\ufefc\uff10-\uff19\uff21-\uff3a\uff3f\uff41-\uff5a\uff66-\uffbe\uffc2-\uffc7\uffca-\uffcf\uffd2-\uffd7\uffda-\uffdc\U00010000-\U0001000b\U0001000d-\U00010026\U00010028-\U0001003a\U0001003c-\U0001003d\U0001003f-\U0001004d\U00010050-\U0001005d\U00010080-\U000100fa\U00010140-\U00010174\U000101fd\U00010280-\U0001029c\U000102a0-\U000102d0\U000102e0\U00010300-\U0001031f\U0001032d-\U0001034a\U00010350-\U0001037a\U00010380-\U0001039d\U000103a0-\U000103c3\U000103c8-\U000103cf\U000103d1-\U000103d5\U00010400-\U0001049d\U000104a0-\U000104a9\U000104b0-\U000104d3\U000104d8-\U000104fb\U00010500-\U00010527\U00010530-\U00010563\U00010600-\U00010736\U00010740-\U00010755\U00010760-\U00010767\U00010800-\U00010805\U00010808\U0001080a-\U00010835\U00010837-\U00010838\U0001083c\U0001083f-\U00010855\U00010860-\U00010876\U00010880-\U0001089e\U000108e0-\U000108f2\U000108f4-\U000108f5\U00010900-\U00010915\U00010920-\U00010939\U00010980-\U000109b7\U000109be-\U000109bf\U00010a00-\U00010a03\U00010a05-\U00010a06\U00010a0c-\U00010a13\U00010a15-\U00010a17\U00010a19-\U00010a35\U00010a38-\U00010a3a\U00010a3f\U00010a60-\U00010a7c\U00010a80-\U00010a9c\U00010ac0-\U00010ac7\U00010ac9-\U00010ae6\U00010b00-\U00010b35\U00010b40-\U00010b55\U00010b60-\U00010b72\U00010b80-\U00010b91\U00010c00-\U00010c48\U00010c80-\U00010cb2\U00010cc0-\U00010cf2\U00010d00-\U00010d27\U00010d30-\U00010d39\U00010f00-\U00010f1c\U00010f27\U00010f30-\U00010f50\U00011000-\U00011046\U00011066-\U0001106f\U0001107f-\U000110ba\U000110d0-\U000110e8\U000110f0-\U000110f9\U00011100-\U00011134\U00011136-\U0001113f\U00011144-\U00011146\U00011150-\U00011173\U00011176\U00011180-\U000111c4\U000111c9-\U000111cc\U000111d0-\U000111da\U000111dc\U00011200-\U00011211\U00011213-\U00011237\U0001123e\U00011280-\U00011286\U00011288\U0001128a-\U0001128d\U0001128f-\U0001129d\U0001129f-\U000112a8\U000112b0-\U000112ea\U000112f0-\U000112f9\U00011300-\U00011303\U00011305-\U0001130c\U0001130f-\U00011310\U00011313-\U00011328\U0001132a-\U00011330\U00011332-\U00011333\U00011335-\U00011339\U0001133b-\U00011344\U00011347-\U00011348\U0001134b-\U0001134d\U00011350\U00011357\U0001135d-\U00011363\U00011366-\U0001136c\U00011370-\U00011374\U00011400-\U0001144a\U00011450-\U00011459\U0001145e\U00011480-\U000114c5\U000114c7\U000114d0-\U000114d9\U00011580-\U000115b5\U000115b8-\U000115c0\U000115d8-\U000115dd\U00011600-\U00011640\U00011644\U00011650-\U00011659\U00011680-\U000116b7\U000116c0-\U000116c9\U00011700-\U0001171a\U0001171d-\U0001172b\U00011730-\U00011739\U00011800-\U0001183a\U000118a0-\U000118e9\U000118ff\U00011a00-\U00011a3e\U00011a47\U00011a50-\U00011a83\U00011a86-\U00011a99\U00011a9d\U00011ac0-\U00011af8\U00011c00-\U00011c08\U00011c0a-\U00011c36\U00011c38-\U00011c40\U00011c50-\U00011c59\U00011c72-\U00011c8f\U00011c92-\U00011ca7\U00011ca9-\U00011cb6\U00011d00-\U00011d06\U00011d08-\U00011d09\U00011d0b-\U00011d36\U00011d3a\U00011d3c-\U00011d3d\U00011d3f-\U00011d47\U00011d50-\U00011d59\U00011d60-\U00011d65\U00011d67-\U00011d68\U00011d6a-\U00011d8e\U00011d90-\U00011d91\U00011d93-\U00011d98\U00011da0-\U00011da9\U00011ee0-\U00011ef6\U00012000-\U00012399\U00012400-\U0001246e\U00012480-\U00012543\U00013000-\U0001342e\U00014400-\U00014646\U00016800-\U00016a38\U00016a40-\U00016a5e\U00016a60-\U00016a69\U00016ad0-\U00016aed\U00016af0-\U00016af4\U00016b00-\U00016b36\U00016b40-\U00016b43\U00016b50-\U00016b59\U00016b63-\U00016b77\U00016b7d-\U00016b8f\U00016e40-\U00016e7f\U00016f00-\U00016f44\U00016f50-\U00016f7e\U00016f8f-\U00016f9f\U00016fe0-\U00016fe1\U00017000-\U000187f1\U00018800-\U00018af2\U0001b000-\U0001b11e\U0001b170-\U0001b2fb\U0001bc00-\U0001bc6a\U0001bc70-\U0001bc7c\U0001bc80-\U0001bc88\U0001bc90-\U0001bc99\U0001bc9d-\U0001bc9e\U0001d165-\U0001d169\U0001d16d-\U0001d172\U0001d17b-\U0001d182\U0001d185-\U0001d18b\U0001d1aa-\U0001d1ad\U0001d242-\U0001d244\U0001d400-\U0001d454\U0001d456-\U0001d49c\U0001d49e-\U0001d49f\U0001d4a2\U0001d4a5-\U0001d4a6\U0001d4a9-\U0001d4ac\U0001d4ae-\U0001d4b9\U0001d4bb\U0001d4bd-\U0001d4c3\U0001d4c5-\U0001d505\U0001d507-\U0001d50a\U0001d50d-\U0001d514\U0001d516-\U0001d51c\U0001d51e-\U0001d539\U0001d53b-\U0001d53e\U0001d540-\U0001d544\U0001d546\U0001d54a-\U0001d550\U0001d552-\U0001d6a5\U0001d6a8-\U0001d6c0\U0001d6c2-\U0001d6da\U0001d6dc-\U0001d6fa\U0001d6fc-\U0001d714\U0001d716-\U0001d734\U0001d736-\U0001d74e\U0001d750-\U0001d76e\U0001d770-\U0001d788\U0001d78a-\U0001d7a8\U0001d7aa-\U0001d7c2\U0001d7c4-\U0001d7cb\U0001d7ce-\U0001d7ff\U0001da00-\U0001da36\U0001da3b-\U0001da6c\U0001da75\U0001da84\U0001da9b-\U0001da9f\U0001daa1-\U0001daaf\U0001e000-\U0001e006\U0001e008-\U0001e018\U0001e01b-\U0001e021\U0001e023-\U0001e024\U0001e026-\U0001e02a\U0001e800-\U0001e8c4\U0001e8d0-\U0001e8d6\U0001e900-\U0001e94a\U0001e950-\U0001e959\U0001ee00-\U0001ee03\U0001ee05-\U0001ee1f\U0001ee21-\U0001ee22\U0001ee24\U0001ee27\U0001ee29-\U0001ee32\U0001ee34-\U0001ee37\U0001ee39\U0001ee3b\U0001ee42\U0001ee47\U0001ee49\U0001ee4b\U0001ee4d-\U0001ee4f\U0001ee51-\U0001ee52\U0001ee54\U0001ee57\U0001ee59\U0001ee5b\U0001ee5d\U0001ee5f\U0001ee61-\U0001ee62\U0001ee64\U0001ee67-\U0001ee6a\U0001ee6c-\U0001ee72\U0001ee74-\U0001ee77\U0001ee79-\U0001ee7c\U0001ee7e\U0001ee80-\U0001ee89\U0001ee8b-\U0001ee9b\U0001eea1-\U0001eea3\U0001eea5-\U0001eea9\U0001eeab-\U0001eebb\U00020000-\U0002a6d6\U0002a700-\U0002b734\U0002b740-\U0002b81d\U0002b820-\U0002cea1\U0002ceb0-\U0002ebe0\U0002f800-\U0002fa1d\U000e0100-\U000e01ef'

xid_start = 'A-Z_a-z\xaa\xb5\xba\xc0-\xd6\xd8-\xf6\xf8-\u02c1\u02c6-\u02d1\u02e0-\u02e4\u02ec\u02ee\u0370-\u0374\u0376-\u0377\u037b-\u037d\u037f\u0386\u0388-\u038a\u038c\u038e-\u03a1\u03a3-\u03f5\u03f7-\u0481\u048a-\u052f\u0531-\u0556\u0559\u0560-\u0588\u05d0-\u05ea\u05ef-\u05f2\u0620-\u064a\u066e-\u066f\u0671-\u06d3\u06d5\u06e5-\u06e6\u06ee-\u06ef\u06fa-\u06fc\u06ff\u0710\u0712-\u072f\u074d-\u07a5\u07b1\u07ca-\u07ea\u07f4-\u07f5\u07fa\u0800-\u0815\u081a\u0824\u0828\u0840-\u0858\u0860-\u086a\u08a0-\u08b4\u08b6-\u08bd\u0904-\u0939\u093d\u0950\u0958-\u0961\u0971-\u0980\u0985-\u098c\u098f-\u0990\u0993-\u09a8\u09aa-\u09b0\u09b2\u09b6-\u09b9\u09bd\u09ce\u09dc-\u09dd\u09df-\u09e1\u09f0-\u09f1\u09fc\u0a05-\u0a0a\u0a0f-\u0a10\u0a13-\u0a28\u0a2a-\u0a30\u0a32-\u0a33\u0a35-\u0a36\u0a38-\u0a39\u0a59-\u0a5c\u0a5e\u0a72-\u0a74\u0a85-\u0a8d\u0a8f-\u0a91\u0a93-\u0aa8\u0aaa-\u0ab0\u0ab2-\u0ab3\u0ab5-\u0ab9\u0abd\u0ad0\u0ae0-\u0ae1\u0af9\u0b05-\u0b0c\u0b0f-\u0b10\u0b13-\u0b28\u0b2a-\u0b30\u0b32-\u0b33\u0b35-\u0b39\u0b3d\u0b5c-\u0b5d\u0b5f-\u0b61\u0b71\u0b83\u0b85-\u0b8a\u0b8e-\u0b90\u0b92-\u0b95\u0b99-\u0b9a\u0b9c\u0b9e-\u0b9f\u0ba3-\u0ba4\u0ba8-\u0baa\u0bae-\u0bb9\u0bd0\u0c05-\u0c0c\u0c0e-\u0c10\u0c12-\u0c28\u0c2a-\u0c39\u0c3d\u0c58-\u0c5a\u0c60-\u0c61\u0c80\u0c85-\u0c8c\u0c8e-\u0c90\u0c92-\u0ca8\u0caa-\u0cb3\u0cb5-\u0cb9\u0cbd\u0cde\u0ce0-\u0ce1\u0cf1-\u0cf2\u0d05-\u0d0c\u0d0e-\u0d10\u0d12-\u0d3a\u0d3d\u0d4e\u0d54-\u0d56\u0d5f-\u0d61\u0d7a-\u0d7f\u0d85-\u0d96\u0d9a-\u0db1\u0db3-\u0dbb\u0dbd\u0dc0-\u0dc6\u0e01-\u0e30\u0e32\u0e40-\u0e46\u0e81-\u0e82\u0e84\u0e87-\u0e88\u0e8a\u0e8d\u0e94-\u0e97\u0e99-\u0e9f\u0ea1-\u0ea3\u0ea5\u0ea7\u0eaa-\u0eab\u0ead-\u0eb0\u0eb2\u0ebd\u0ec0-\u0ec4\u0ec6\u0edc-\u0edf\u0f00\u0f40-\u0f47\u0f49-\u0f6c\u0f88-\u0f8c\u1000-\u102a\u103f\u1050-\u1055\u105a-\u105d\u1061\u1065-\u1066\u106e-\u1070\u1075-\u1081\u108e\u10a0-\u10c5\u10c7\u10cd\u10d0-\u10fa\u10fc-\u1248\u124a-\u124d\u1250-\u1256\u1258\u125a-\u125d\u1260-\u1288\u128a-\u128d\u1290-\u12b0\u12b2-\u12b5\u12b8-\u12be\u12c0\u12c2-\u12c5\u12c8-\u12d6\u12d8-\u1310\u1312-\u1315\u1318-\u135a\u1380-\u138f\u13a0-\u13f5\u13f8-\u13fd\u1401-\u166c\u166f-\u167f\u1681-\u169a\u16a0-\u16ea\u16ee-\u16f8\u1700-\u170c\u170e-\u1711\u1720-\u1731\u1740-\u1751\u1760-\u176c\u176e-\u1770\u1780-\u17b3\u17d7\u17dc\u1820-\u1878\u1880-\u18a8\u18aa\u18b0-\u18f5\u1900-\u191e\u1950-\u196d\u1970-\u1974\u1980-\u19ab\u19b0-\u19c9\u1a00-\u1a16\u1a20-\u1a54\u1aa7\u1b05-\u1b33\u1b45-\u1b4b\u1b83-\u1ba0\u1bae-\u1baf\u1bba-\u1be5\u1c00-\u1c23\u1c4d-\u1c4f\u1c5a-\u1c7d\u1c80-\u1c88\u1c90-\u1cba\u1cbd-\u1cbf\u1ce9-\u1cec\u1cee-\u1cf1\u1cf5-\u1cf6\u1d00-\u1dbf\u1e00-\u1f15\u1f18-\u1f1d\u1f20-\u1f45\u1f48-\u1f4d\u1f50-\u1f57\u1f59\u1f5b\u1f5d\u1f5f-\u1f7d\u1f80-\u1fb4\u1fb6-\u1fbc\u1fbe\u1fc2-\u1fc4\u1fc6-\u1fcc\u1fd0-\u1fd3\u1fd6-\u1fdb\u1fe0-\u1fec\u1ff2-\u1ff4\u1ff6-\u1ffc\u2071\u207f\u2090-\u209c\u2102\u2107\u210a-\u2113\u2115\u2118-\u211d\u2124\u2126\u2128\u212a-\u2139\u213c-\u213f\u2145-\u2149\u214e\u2160-\u2188\u2c00-\u2c2e\u2c30-\u2c5e\u2c60-\u2ce4\u2ceb-\u2cee\u2cf2-\u2cf3\u2d00-\u2d25\u2d27\u2d2d\u2d30-\u2d67\u2d6f\u2d80-\u2d96\u2da0-\u2da6\u2da8-\u2dae\u2db0-\u2db6\u2db8-\u2dbe\u2dc0-\u2dc6\u2dc8-\u2dce\u2dd0-\u2dd6\u2dd8-\u2dde\u3005-\u3007\u3021-\u3029\u3031-\u3035\u3038-\u303c\u3041-\u3096\u309d-\u309f\u30a1-\u30fa\u30fc-\u30ff\u3105-\u312f\u3131-\u318e\u31a0-\u31ba\u31f0-\u31ff\u3400-\u4db5\u4e00-\u9fef\ua000-\ua48c\ua4d0-\ua4fd\ua500-\ua60c\ua610-\ua61f\ua62a-\ua62b\ua640-\ua66e\ua67f-\ua69d\ua6a0-\ua6ef\ua717-\ua71f\ua722-\ua788\ua78b-\ua7b9\ua7f7-\ua801\ua803-\ua805\ua807-\ua80a\ua80c-\ua822\ua840-\ua873\ua882-\ua8b3\ua8f2-\ua8f7\ua8fb\ua8fd-\ua8fe\ua90a-\ua925\ua930-\ua946\ua960-\ua97c\ua984-\ua9b2\ua9cf\ua9e0-\ua9e4\ua9e6-\ua9ef\ua9fa-\ua9fe\uaa00-\uaa28\uaa40-\uaa42\uaa44-\uaa4b\uaa60-\uaa76\uaa7a\uaa7e-\uaaaf\uaab1\uaab5-\uaab6\uaab9-\uaabd\uaac0\uaac2\uaadb-\uaadd\uaae0-\uaaea\uaaf2-\uaaf4\uab01-\uab06\uab09-\uab0e\uab11-\uab16\uab20-\uab26\uab28-\uab2e\uab30-\uab5a\uab5c-\uab65\uab70-\uabe2\uac00-\ud7a3\ud7b0-\ud7c6\ud7cb-\ud7fb\uf900-\ufa6d\ufa70-\ufad9\ufb00-\ufb06\ufb13-\ufb17\ufb1d\ufb1f-\ufb28\ufb2a-\ufb36\ufb38-\ufb3c\ufb3e\ufb40-\ufb41\ufb43-\ufb44\ufb46-\ufbb1\ufbd3-\ufc5d\ufc64-\ufd3d\ufd50-\ufd8f\ufd92-\ufdc7\ufdf0-\ufdf9\ufe71\ufe73\ufe77\ufe79\ufe7b\ufe7d\ufe7f-\ufefc\uff21-\uff3a\uff41-\uff5a\uff66-\uff9d\uffa0-\uffbe\uffc2-\uffc7\uffca-\uffcf\uffd2-\uffd7\uffda-\uffdc\U00010000-\U0001000b\U0001000d-\U00010026\U00010028-\U0001003a\U0001003c-\U0001003d\U0001003f-\U0001004d\U00010050-\U0001005d\U00010080-\U000100fa\U00010140-\U00010174\U00010280-\U0001029c\U000102a0-\U000102d0\U00010300-\U0001031f\U0001032d-\U0001034a\U00010350-\U00010375\U00010380-\U0001039d\U000103a0-\U000103c3\U000103c8-\U000103cf\U000103d1-\U000103d5\U00010400-\U0001049d\U000104b0-\U000104d3\U000104d8-\U000104fb\U00010500-\U00010527\U00010530-\U00010563\U00010600-\U00010736\U00010740-\U00010755\U00010760-\U00010767\U00010800-\U00010805\U00010808\U0001080a-\U00010835\U00010837-\U00010838\U0001083c\U0001083f-\U00010855\U00010860-\U00010876\U00010880-\U0001089e\U000108e0-\U000108f2\U000108f4-\U000108f5\U00010900-\U00010915\U00010920-\U00010939\U00010980-\U000109b7\U000109be-\U000109bf\U00010a00\U00010a10-\U00010a13\U00010a15-\U00010a17\U00010a19-\U00010a35\U00010a60-\U00010a7c\U00010a80-\U00010a9c\U00010ac0-\U00010ac7\U00010ac9-\U00010ae4\U00010b00-\U00010b35\U00010b40-\U00010b55\U00010b60-\U00010b72\U00010b80-\U00010b91\U00010c00-\U00010c48\U00010c80-\U00010cb2\U00010cc0-\U00010cf2\U00010d00-\U00010d23\U00010f00-\U00010f1c\U00010f27\U00010f30-\U00010f45\U00011003-\U00011037\U00011083-\U000110af\U000110d0-\U000110e8\U00011103-\U00011126\U00011144\U00011150-\U00011172\U00011176\U00011183-\U000111b2\U000111c1-\U000111c4\U000111da\U000111dc\U00011200-\U00011211\U00011213-\U0001122b\U00011280-\U00011286\U00011288\U0001128a-\U0001128d\U0001128f-\U0001129d\U0001129f-\U000112a8\U000112b0-\U000112de\U00011305-\U0001130c\U0001130f-\U00011310\U00011313-\U00011328\U0001132a-\U00011330\U00011332-\U00011333\U00011335-\U00011339\U0001133d\U00011350\U0001135d-\U00011361\U00011400-\U00011434\U00011447-\U0001144a\U00011480-\U000114af\U000114c4-\U000114c5\U000114c7\U00011580-\U000115ae\U000115d8-\U000115db\U00011600-\U0001162f\U00011644\U00011680-\U000116aa\U00011700-\U0001171a\U00011800-\U0001182b\U000118a0-\U000118df\U000118ff\U00011a00\U00011a0b-\U00011a32\U00011a3a\U00011a50\U00011a5c-\U00011a83\U00011a86-\U00011a89\U00011a9d\U00011ac0-\U00011af8\U00011c00-\U00011c08\U00011c0a-\U00011c2e\U00011c40\U00011c72-\U00011c8f\U00011d00-\U00011d06\U00011d08-\U00011d09\U00011d0b-\U00011d30\U00011d46\U00011d60-\U00011d65\U00011d67-\U00011d68\U00011d6a-\U00011d89\U00011d98\U00011ee0-\U00011ef2\U00012000-\U00012399\U00012400-\U0001246e\U00012480-\U00012543\U00013000-\U0001342e\U00014400-\U00014646\U00016800-\U00016a38\U00016a40-\U00016a5e\U00016ad0-\U00016aed\U00016b00-\U00016b2f\U00016b40-\U00016b43\U00016b63-\U00016b77\U00016b7d-\U00016b8f\U00016e40-\U00016e7f\U00016f00-\U00016f44\U00016f50\U00016f93-\U00016f9f\U00016fe0-\U00016fe1\U00017000-\U000187f1\U00018800-\U00018af2\U0001b000-\U0001b11e\U0001b170-\U0001b2fb\U0001bc00-\U0001bc6a\U0001bc70-\U0001bc7c\U0001bc80-\U0001bc88\U0001bc90-\U0001bc99\U0001d400-\U0001d454\U0001d456-\U0001d49c\U0001d49e-\U0001d49f\U0001d4a2\U0001d4a5-\U0001d4a6\U0001d4a9-\U0001d4ac\U0001d4ae-\U0001d4b9\U0001d4bb\U0001d4bd-\U0001d4c3\U0001d4c5-\U0001d505\U0001d507-\U0001d50a\U0001d50d-\U0001d514\U0001d516-\U0001d51c\U0001d51e-\U0001d539\U0001d53b-\U0001d53e\U0001d540-\U0001d544\U0001d546\U0001d54a-\U0001d550\U0001d552-\U0001d6a5\U0001d6a8-\U0001d6c0\U0001d6c2-\U0001d6da\U0001d6dc-\U0001d6fa\U0001d6fc-\U0001d714\U0001d716-\U0001d734\U0001d736-\U0001d74e\U0001d750-\U0001d76e\U0001d770-\U0001d788\U0001d78a-\U0001d7a8\U0001d7aa-\U0001d7c2\U0001d7c4-\U0001d7cb\U0001e800-\U0001e8c4\U0001e900-\U0001e943\U0001ee00-\U0001ee03\U0001ee05-\U0001ee1f\U0001ee21-\U0001ee22\U0001ee24\U0001ee27\U0001ee29-\U0001ee32\U0001ee34-\U0001ee37\U0001ee39\U0001ee3b\U0001ee42\U0001ee47\U0001ee49\U0001ee4b\U0001ee4d-\U0001ee4f\U0001ee51-\U0001ee52\U0001ee54\U0001ee57\U0001ee59\U0001ee5b\U0001ee5d\U0001ee5f\U0001ee61-\U0001ee62\U0001ee64\U0001ee67-\U0001ee6a\U0001ee6c-\U0001ee72\U0001ee74-\U0001ee77\U0001ee79-\U0001ee7c\U0001ee7e\U0001ee80-\U0001ee89\U0001ee8b-\U0001ee9b\U0001eea1-\U0001eea3\U0001eea5-\U0001eea9\U0001eeab-\U0001eebb\U00020000-\U0002a6d6\U0002a700-\U0002b734\U0002b740-\U0002b81d\U0002b820-\U0002cea1\U0002ceb0-\U0002ebe0\U0002f800-\U0002fa1d'

cats = ['Cc', 'Cf', 'Cn', 'Co', 'Cs', 'Ll', 'Lm', 'Lo', 'Lt', 'Lu', 'Mc', 'Me', 'Mn', 'Nd', 'Nl', 'No', 'Pc', 'Pd', 'Pe', 'Pf', 'Pi', 'Po', 'Ps', 'Sc', 'Sk', 'Sm', 'So', 'Zl', 'Zp', 'Zs']



def combine(*args):
    return ''.join(globals()[cat] for cat in args)


def allexcept(*args):
    newcats = cats[:]
    for arg in args:
        newcats.remove(arg)
    return ''.join(globals()[cat] for cat in newcats)


def _handle_runs(char_list):  
    buf = []
    for c in char_list:
        if len(c) == 1:
            if buf and buf[-1][1] == chr(ord(c)-1):
                buf[-1] = (buf[-1][0], c)
            else:
                buf.append((c, c))
        else:
            buf.append((c, c))
    for a, b in buf:
        if a == b:
            yield a
        else:
            yield f'{a}-{b}'


if __name__ == '__main__':  
    import unicodedata

    categories = {'xid_start': [], 'xid_continue': []}

    with open(__file__, encoding='utf-8') as fp:
        content = fp.read()

    header = content[:content.find('Cc =')]
    footer = content[content.find(""def combine(""):]

    for code in range(0x110000):
        c = chr(code)
        cat = unicodedata.category(c)
        if ord(c) == 0xdc00:
            
            
            c = '\\' + c
        elif ord(c) in (0x2d, 0x5b, 0x5c, 0x5d, 0x5e):
            
            c = '\\' + c
        categories.setdefault(cat, []).append(c)
        
        
        if c.isidentifier():
            categories['xid_start'].append(c)
        if ('a' + c).isidentifier():
            categories['xid_continue'].append(c)

    with open(__file__, 'w', encoding='utf-8') as fp:
        fp.write(header)

        for cat in sorted(categories):
            val = ''.join(_handle_runs(categories[cat]))
            fp.write(f'{cat} = {val!a}\n\n')

        cats = sorted(categories)
        cats.remove('xid_start')
        cats.remove('xid_continue')
        fp.write(f'cats = {cats!r}\n\n')

        fp.write(f'

        fp.write(footer)



import re
from io import TextIOWrapper


split_path_re = re.compile(r'[/\\ ]')
doctype_lookup_re = re.compile(r, re.DOTALL | re.MULTILINE | re.VERBOSE)
tag_re = re.compile(r'<(.+?)(\s.*?)?>.*?</.+?>',
                    re.IGNORECASE | re.DOTALL | re.MULTILINE)
xml_decl_re = re.compile(r'\s*<\?xml[^>]*\?>', re.I)


class ClassNotFound(ValueError):
    


class OptionError(Exception):
    

def get_choice_opt(options, optname, allowed, default=None, normcase=False):
    
    string = options.get(optname, default)
    if normcase:
        string = string.lower()
    if string not in allowed:
        raise OptionError('Value for option {} must be one of {}'.format(optname, ', '.join(map(str, allowed))))
    return string


def get_bool_opt(options, optname, default=None):
    
    string = options.get(optname, default)
    if isinstance(string, bool):
        return string
    elif isinstance(string, int):
        return bool(string)
    elif not isinstance(string, str):
        raise OptionError(f'Invalid type {string!r} for option {optname}; use '
                          '1/0, yes/no, true/false, on/off')
    elif string.lower() in ('1', 'yes', 'true', 'on'):
        return True
    elif string.lower() in ('0', 'no', 'false', 'off'):
        return False
    else:
        raise OptionError(f'Invalid value {string!r} for option {optname}; use '
                          '1/0, yes/no, true/false, on/off')


def get_int_opt(options, optname, default=None):
    
    string = options.get(optname, default)
    try:
        return int(string)
    except TypeError:
        raise OptionError(f'Invalid type {string!r} for option {optname}; you '
                          'must give an integer value')
    except ValueError:
        raise OptionError(f'Invalid value {string!r} for option {optname}; you '
                          'must give an integer value')

def get_list_opt(options, optname, default=None):
    
    val = options.get(optname, default)
    if isinstance(val, str):
        return val.split()
    elif isinstance(val, (list, tuple)):
        return list(val)
    else:
        raise OptionError(f'Invalid type {val!r} for option {optname}; you '
                          'must give a list value')


def docstring_headline(obj):
    if not obj.__doc__:
        return ''
    res = []
    for line in obj.__doc__.strip().splitlines():
        if line.strip():
            res.append("" "" + line.strip())
        else:
            break
    return ''.join(res).lstrip()


def make_analysator(f):
    
    def text_analyse(text):
        try:
            rv = f(text)
        except Exception:
            return 0.0
        if not rv:
            return 0.0
        try:
            return min(1.0, max(0.0, float(rv)))
        except (ValueError, TypeError):
            return 0.0
    text_analyse.__doc__ = f.__doc__
    return staticmethod(text_analyse)


def shebang_matches(text, regex):
    r
    index = text.find('\n')
    if index >= 0:
        first_line = text[:index].lower()
    else:
        first_line = text.lower()
    if first_line.startswith('
        try:
            found = [x for x in split_path_re.split(first_line[2:].strip())
                     if x and not x.startswith('-')][-1]
        except IndexError:
            return False
        regex = re.compile(rf'^{regex}(\.(exe|cmd|bat|bin))?$', re.IGNORECASE)
        if regex.search(found) is not None:
            return True
    return False


def doctype_matches(text, regex):
    
    m = doctype_lookup_re.search(text)
    if m is None:
        return False
    doctype = m.group(1)
    return re.compile(regex, re.I).match(doctype.strip()) is not None


def html_doctype_matches(text):
    
    return doctype_matches(text, r'html')


_looks_like_xml_cache = {}


def looks_like_xml(text):
    
    if xml_decl_re.match(text):
        return True
    key = hash(text)
    try:
        return _looks_like_xml_cache[key]
    except KeyError:
        m = doctype_lookup_re.search(text)
        if m is not None:
            return True
        rv = tag_re.search(text[:1000]) is not None
        _looks_like_xml_cache[key] = rv
        return rv


def surrogatepair(c):
    
    
    
    return (0xd7c0 + (c >> 10), (0xdc00 + (c & 0x3ff)))


def format_lines(var_name, seq, raw=False, indent_level=0):
    
    lines = []
    base_indent = ' ' * indent_level * 4
    inner_indent = ' ' * (indent_level + 1) * 4
    lines.append(base_indent + var_name + ' = (')
    if raw:
        
        for i in seq:
            lines.append(inner_indent + i + ',')
    else:
        for i in seq:
            
            r = repr(i + '""')
            lines.append(inner_indent + r[:-2] + r[-1] + ',')
    lines.append(base_indent + ')')
    return '\n'.join(lines)


def duplicates_removed(it, already_seen=()):
    
    lst = []
    seen = set()
    for i in it:
        if i in seen or i in already_seen:
            continue
        lst.append(i)
        seen.add(i)
    return lst


class Future:
    
    def get(self):
        raise NotImplementedError


def guess_decode(text):
    
    try:
        text = text.decode('utf-8')
        return text, 'utf-8'
    except UnicodeDecodeError:
        try:
            import locale
            prefencoding = locale.getpreferredencoding()
            text = text.decode()
            return text, prefencoding
        except (UnicodeDecodeError, LookupError):
            text = text.decode('latin1')
            return text, 'latin1'


def guess_decode_from_terminal(text, term):
    
    if getattr(term, 'encoding', None):
        try:
            text = text.decode(term.encoding)
        except UnicodeDecodeError:
            pass
        else:
            return text, term.encoding
    return guess_decode(text)


def terminal_encoding(term):
    
    if getattr(term, 'encoding', None):
        return term.encoding
    import locale
    return locale.getpreferredencoding()


class UnclosingTextIOWrapper(TextIOWrapper):
    
    def close(self):
        self.flush()


from io import StringIO, BytesIO

__version__ = '2.19.2'
__docformat__ = 'restructuredtext'

__all__ = ['lex', 'format', 'highlight']


def lex(code, lexer):
    
    try:
        return lexer.get_tokens(code)
    except TypeError:
        
        from pip._vendor.pygments.lexer import RegexLexer
        if isinstance(lexer, type) and issubclass(lexer, RegexLexer):
            raise TypeError('lex() argument must be a lexer instance, '
                            'not a class')
        raise


def format(tokens, formatter, outfile=None):  
    
    try:
        if not outfile:
            realoutfile = getattr(formatter, 'encoding', None) and BytesIO() or StringIO()
            formatter.format(tokens, realoutfile)
            return realoutfile.getvalue()
        else:
            formatter.format(tokens, outfile)
    except TypeError:
        
        from pip._vendor.pygments.formatter import Formatter
        if isinstance(formatter, type) and issubclass(formatter, Formatter):
            raise TypeError('format() argument must be a formatter instance, '
                            'not a class')
        raise


def highlight(code, lexer, formatter, outfile=None):
    
    return format(lex(code, lexer), formatter, outfile)



import sys
from pip._vendor.pygments.cmdline import main

try:
    sys.exit(main(sys.argv))
except KeyboardInterrupt:
    sys.exit(1)



import re

from pip._vendor.pygments.token import String, Comment, Keyword, Name, Error, Whitespace, \
    string_to_tokentype
from pip._vendor.pygments.filter import Filter
from pip._vendor.pygments.util import get_list_opt, get_int_opt, get_bool_opt, \
    get_choice_opt, ClassNotFound, OptionError
from pip._vendor.pygments.plugin import find_plugin_filters


def find_filter_class(filtername):
    
    if filtername in FILTERS:
        return FILTERS[filtername]
    for name, cls in find_plugin_filters():
        if name == filtername:
            return cls
    return None


def get_filter_by_name(filtername, **options):
    
    cls = find_filter_class(filtername)
    if cls:
        return cls(**options)
    else:
        raise ClassNotFound(f'filter {filtername!r} not found')


def get_all_filters():
    
    yield from FILTERS
    for name, _ in find_plugin_filters():
        yield name


def _replace_special(ttype, value, regex, specialttype,
                     replacefunc=lambda x: x):
    last = 0
    for match in regex.finditer(value):
        start, end = match.start(), match.end()
        if start != last:
            yield ttype, value[last:start]
        yield specialttype, replacefunc(value[start:end])
        last = end
    if last != len(value):
        yield ttype, value[last:]


class CodeTagFilter(Filter):
    

    def __init__(self, **options):
        Filter.__init__(self, **options)
        tags = get_list_opt(options, 'codetags',
                            ['XXX', 'TODO', 'FIXME', 'BUG', 'NOTE'])
        self.tag_re = re.compile(r'\b({})\b'.format('|'.join([
            re.escape(tag) for tag in tags if tag
        ])))

    def filter(self, lexer, stream):
        regex = self.tag_re
        for ttype, value in stream:
            if ttype in String.Doc or \
               ttype in Comment and \
               ttype not in Comment.Preproc:
                yield from _replace_special(ttype, value, regex, Comment.Special)
            else:
                yield ttype, value


class SymbolFilter(Filter):
    

    latex_symbols = {
        '\\alpha'                : '\U000003b1',
        '\\beta'                 : '\U000003b2',
        '\\gamma'                : '\U000003b3',
        '\\delta'                : '\U000003b4',
        '\\varepsilon'           : '\U000003b5',
        '\\zeta'                 : '\U000003b6',
        '\\eta'                  : '\U000003b7',
        '\\vartheta'             : '\U000003b8',
        '\\iota'                 : '\U000003b9',
        '\\kappa'                : '\U000003ba',
        '\\lambda'               : '\U000003bb',
        '\\mu'                   : '\U000003bc',
        '\\nu'                   : '\U000003bd',
        '\\xi'                   : '\U000003be',
        '\\pi'                   : '\U000003c0',
        '\\varrho'               : '\U000003c1',
        '\\sigma'                : '\U000003c3',
        '\\tau'                  : '\U000003c4',
        '\\upsilon'              : '\U000003c5',
        '\\varphi'               : '\U000003c6',
        '\\chi'                  : '\U000003c7',
        '\\psi'                  : '\U000003c8',
        '\\omega'                : '\U000003c9',
        '\\Gamma'                : '\U00000393',
        '\\Delta'                : '\U00000394',
        '\\Theta'                : '\U00000398',
        '\\Lambda'               : '\U0000039b',
        '\\Xi'                   : '\U0000039e',
        '\\Pi'                   : '\U000003a0',
        '\\Sigma'                : '\U000003a3',
        '\\Upsilon'              : '\U000003a5',
        '\\Phi'                  : '\U000003a6',
        '\\Psi'                  : '\U000003a8',
        '\\Omega'                : '\U000003a9',
        '\\leftarrow'            : '\U00002190',
        '\\longleftarrow'        : '\U000027f5',
        '\\rightarrow'           : '\U00002192',
        '\\longrightarrow'       : '\U000027f6',
        '\\Leftarrow'            : '\U000021d0',
        '\\Longleftarrow'        : '\U000027f8',
        '\\Rightarrow'           : '\U000021d2',
        '\\Longrightarrow'       : '\U000027f9',
        '\\leftrightarrow'       : '\U00002194',
        '\\longleftrightarrow'   : '\U000027f7',
        '\\Leftrightarrow'       : '\U000021d4',
        '\\Longleftrightarrow'   : '\U000027fa',
        '\\mapsto'               : '\U000021a6',
        '\\longmapsto'           : '\U000027fc',
        '\\relbar'               : '\U00002500',
        '\\Relbar'               : '\U00002550',
        '\\hookleftarrow'        : '\U000021a9',
        '\\hookrightarrow'       : '\U000021aa',
        '\\leftharpoondown'      : '\U000021bd',
        '\\rightharpoondown'     : '\U000021c1',
        '\\leftharpoonup'        : '\U000021bc',
        '\\rightharpoonup'       : '\U000021c0',
        '\\rightleftharpoons'    : '\U000021cc',
        '\\leadsto'              : '\U0000219d',
        '\\downharpoonleft'      : '\U000021c3',
        '\\downharpoonright'     : '\U000021c2',
        '\\upharpoonleft'        : '\U000021bf',
        '\\upharpoonright'       : '\U000021be',
        '\\restriction'          : '\U000021be',
        '\\uparrow'              : '\U00002191',
        '\\Uparrow'              : '\U000021d1',
        '\\downarrow'            : '\U00002193',
        '\\Downarrow'            : '\U000021d3',
        '\\updownarrow'          : '\U00002195',
        '\\Updownarrow'          : '\U000021d5',
        '\\langle'               : '\U000027e8',
        '\\rangle'               : '\U000027e9',
        '\\lceil'                : '\U00002308',
        '\\rceil'                : '\U00002309',
        '\\lfloor'               : '\U0000230a',
        '\\rfloor'               : '\U0000230b',
        '\\flqq'                 : '\U000000ab',
        '\\frqq'                 : '\U000000bb',
        '\\bot'                  : '\U000022a5',
        '\\top'                  : '\U000022a4',
        '\\wedge'                : '\U00002227',
        '\\bigwedge'             : '\U000022c0',
        '\\vee'                  : '\U00002228',
        '\\bigvee'               : '\U000022c1',
        '\\forall'               : '\U00002200',
        '\\exists'               : '\U00002203',
        '\\nexists'              : '\U00002204',
        '\\neg'                  : '\U000000ac',
        '\\Box'                  : '\U000025a1',
        '\\Diamond'              : '\U000025c7',
        '\\vdash'                : '\U000022a2',
        '\\models'               : '\U000022a8',
        '\\dashv'                : '\U000022a3',
        '\\surd'                 : '\U0000221a',
        '\\le'                   : '\U00002264',
        '\\ge'                   : '\U00002265',
        '\\ll'                   : '\U0000226a',
        '\\gg'                   : '\U0000226b',
        '\\lesssim'              : '\U00002272',
        '\\gtrsim'               : '\U00002273',
        '\\lessapprox'           : '\U00002a85',
        '\\gtrapprox'            : '\U00002a86',
        '\\in'                   : '\U00002208',
        '\\notin'                : '\U00002209',
        '\\subset'               : '\U00002282',
        '\\supset'               : '\U00002283',
        '\\subseteq'             : '\U00002286',
        '\\supseteq'             : '\U00002287',
        '\\sqsubset'             : '\U0000228f',
        '\\sqsupset'             : '\U00002290',
        '\\sqsubseteq'           : '\U00002291',
        '\\sqsupseteq'           : '\U00002292',
        '\\cap'                  : '\U00002229',
        '\\bigcap'               : '\U000022c2',
        '\\cup'                  : '\U0000222a',
        '\\bigcup'               : '\U000022c3',
        '\\sqcup'                : '\U00002294',
        '\\bigsqcup'             : '\U00002a06',
        '\\sqcap'                : '\U00002293',
        '\\Bigsqcap'             : '\U00002a05',
        '\\setminus'             : '\U00002216',
        '\\propto'               : '\U0000221d',
        '\\uplus'                : '\U0000228e',
        '\\bigplus'              : '\U00002a04',
        '\\sim'                  : '\U0000223c',
        '\\doteq'                : '\U00002250',
        '\\simeq'                : '\U00002243',
        '\\approx'               : '\U00002248',
        '\\asymp'                : '\U0000224d',
        '\\cong'                 : '\U00002245',
        '\\equiv'                : '\U00002261',
        '\\Join'                 : '\U000022c8',
        '\\bowtie'               : '\U00002a1d',
        '\\prec'                 : '\U0000227a',
        '\\succ'                 : '\U0000227b',
        '\\preceq'               : '\U0000227c',
        '\\succeq'               : '\U0000227d',
        '\\parallel'             : '\U00002225',
        '\\mid'                  : '\U000000a6',
        '\\pm'                   : '\U000000b1',
        '\\mp'                   : '\U00002213',
        '\\times'                : '\U000000d7',
        '\\div'                  : '\U000000f7',
        '\\cdot'                 : '\U000022c5',
        '\\star'                 : '\U000022c6',
        '\\circ'                 : '\U00002218',
        '\\dagger'               : '\U00002020',
        '\\ddagger'              : '\U00002021',
        '\\lhd'                  : '\U000022b2',
        '\\rhd'                  : '\U000022b3',
        '\\unlhd'                : '\U000022b4',
        '\\unrhd'                : '\U000022b5',
        '\\triangleleft'         : '\U000025c3',
        '\\triangleright'        : '\U000025b9',
        '\\triangle'             : '\U000025b3',
        '\\triangleq'            : '\U0000225c',
        '\\oplus'                : '\U00002295',
        '\\bigoplus'             : '\U00002a01',
        '\\otimes'               : '\U00002297',
        '\\bigotimes'            : '\U00002a02',
        '\\odot'                 : '\U00002299',
        '\\bigodot'              : '\U00002a00',
        '\\ominus'               : '\U00002296',
        '\\oslash'               : '\U00002298',
        '\\dots'                 : '\U00002026',
        '\\cdots'                : '\U000022ef',
        '\\sum'                  : '\U00002211',
        '\\prod'                 : '\U0000220f',
        '\\coprod'               : '\U00002210',
        '\\infty'                : '\U0000221e',
        '\\int'                  : '\U0000222b',
        '\\oint'                 : '\U0000222e',
        '\\clubsuit'             : '\U00002663',
        '\\diamondsuit'          : '\U00002662',
        '\\heartsuit'            : '\U00002661',
        '\\spadesuit'            : '\U00002660',
        '\\aleph'                : '\U00002135',
        '\\emptyset'             : '\U00002205',
        '\\nabla'                : '\U00002207',
        '\\partial'              : '\U00002202',
        '\\flat'                 : '\U0000266d',
        '\\natural'              : '\U0000266e',
        '\\sharp'                : '\U0000266f',
        '\\angle'                : '\U00002220',
        '\\copyright'            : '\U000000a9',
        '\\textregistered'       : '\U000000ae',
        '\\textonequarter'       : '\U000000bc',
        '\\textonehalf'          : '\U000000bd',
        '\\textthreequarters'    : '\U000000be',
        '\\textordfeminine'      : '\U000000aa',
        '\\textordmasculine'     : '\U000000ba',
        '\\euro'                 : '\U000020ac',
        '\\pounds'               : '\U000000a3',
        '\\yen'                  : '\U000000a5',
        '\\textcent'             : '\U000000a2',
        '\\textcurrency'         : '\U000000a4',
        '\\textdegree'           : '\U000000b0',
    }

    isabelle_symbols = {
        '\\<zero>'                 : '\U0001d7ec',
        '\\<one>'                  : '\U0001d7ed',
        '\\<two>'                  : '\U0001d7ee',
        '\\<three>'                : '\U0001d7ef',
        '\\<four>'                 : '\U0001d7f0',
        '\\<five>'                 : '\U0001d7f1',
        '\\<six>'                  : '\U0001d7f2',
        '\\<seven>'                : '\U0001d7f3',
        '\\<eight>'                : '\U0001d7f4',
        '\\<nine>'                 : '\U0001d7f5',
        '\\<A>'                    : '\U0001d49c',
        '\\<B>'                    : '\U0000212c',
        '\\<C>'                    : '\U0001d49e',
        '\\<D>'                    : '\U0001d49f',
        '\\<E>'                    : '\U00002130',
        '\\<F>'                    : '\U00002131',
        '\\<G>'                    : '\U0001d4a2',
        '\\<H>'                    : '\U0000210b',
        '\\<I>'                    : '\U00002110',
        '\\<J>'                    : '\U0001d4a5',
        '\\<K>'                    : '\U0001d4a6',
        '\\<L>'                    : '\U00002112',
        '\\<M>'                    : '\U00002133',
        '\\<N>'                    : '\U0001d4a9',
        '\\<O>'                    : '\U0001d4aa',
        '\\<P>'                    : '\U0001d4ab',
        '\\<Q>'                    : '\U0001d4ac',
        '\\<R>'                    : '\U0000211b',
        '\\<S>'                    : '\U0001d4ae',
        '\\<T>'                    : '\U0001d4af',
        '\\<U>'                    : '\U0001d4b0',
        '\\<V>'                    : '\U0001d4b1',
        '\\<W>'                    : '\U0001d4b2',
        '\\<X>'                    : '\U0001d4b3',
        '\\<Y>'                    : '\U0001d4b4',
        '\\<Z>'                    : '\U0001d4b5',
        '\\<a>'                    : '\U0001d5ba',
        '\\<b>'                    : '\U0001d5bb',
        '\\<c>'                    : '\U0001d5bc',
        '\\<d>'                    : '\U0001d5bd',
        '\\<e>'                    : '\U0001d5be',
        '\\<f>'                    : '\U0001d5bf',
        '\\<g>'                    : '\U0001d5c0',
        '\\<h>'                    : '\U0001d5c1',
        '\\<i>'                    : '\U0001d5c2',
        '\\<j>'                    : '\U0001d5c3',
        '\\<k>'                    : '\U0001d5c4',
        '\\<l>'                    : '\U0001d5c5',
        '\\<m>'                    : '\U0001d5c6',
        '\\<n>'                    : '\U0001d5c7',
        '\\<o>'                    : '\U0001d5c8',
        '\\<p>'                    : '\U0001d5c9',
        '\\<q>'                    : '\U0001d5ca',
        '\\<r>'                    : '\U0001d5cb',
        '\\<s>'                    : '\U0001d5cc',
        '\\<t>'                    : '\U0001d5cd',
        '\\<u>'                    : '\U0001d5ce',
        '\\<v>'                    : '\U0001d5cf',
        '\\<w>'                    : '\U0001d5d0',
        '\\<x>'                    : '\U0001d5d1',
        '\\<y>'                    : '\U0001d5d2',
        '\\<z>'                    : '\U0001d5d3',
        '\\<AA>'                   : '\U0001d504',
        '\\<BB>'                   : '\U0001d505',
        '\\<CC>'                   : '\U0000212d',
        '\\<DD>'                   : '\U0001d507',
        '\\<EE>'                   : '\U0001d508',
        '\\<FF>'                   : '\U0001d509',
        '\\<GG>'                   : '\U0001d50a',
        '\\<HH>'                   : '\U0000210c',
        '\\<II>'                   : '\U00002111',
        '\\<JJ>'                   : '\U0001d50d',
        '\\<KK>'                   : '\U0001d50e',
        '\\<LL>'                   : '\U0001d50f',
        '\\<MM>'                   : '\U0001d510',
        '\\<NN>'                   : '\U0001d511',
        '\\<OO>'                   : '\U0001d512',
        '\\<PP>'                   : '\U0001d513',
        '\\<QQ>'                   : '\U0001d514',
        '\\<RR>'                   : '\U0000211c',
        '\\<SS>'                   : '\U0001d516',
        '\\<TT>'                   : '\U0001d517',
        '\\<UU>'                   : '\U0001d518',
        '\\<VV>'                   : '\U0001d519',
        '\\<WW>'                   : '\U0001d51a',
        '\\<XX>'                   : '\U0001d51b',
        '\\<YY>'                   : '\U0001d51c',
        '\\<ZZ>'                   : '\U00002128',
        '\\<aa>'                   : '\U0001d51e',
        '\\<bb>'                   : '\U0001d51f',
        '\\<cc>'                   : '\U0001d520',
        '\\<dd>'                   : '\U0001d521',
        '\\<ee>'                   : '\U0001d522',
        '\\<ff>'                   : '\U0001d523',
        '\\<gg>'                   : '\U0001d524',
        '\\<hh>'                   : '\U0001d525',
        '\\<ii>'                   : '\U0001d526',
        '\\<jj>'                   : '\U0001d527',
        '\\<kk>'                   : '\U0001d528',
        '\\<ll>'                   : '\U0001d529',
        '\\<mm>'                   : '\U0001d52a',
        '\\<nn>'                   : '\U0001d52b',
        '\\<oo>'                   : '\U0001d52c',
        '\\<pp>'                   : '\U0001d52d',
        '\\<qq>'                   : '\U0001d52e',
        '\\<rr>'                   : '\U0001d52f',
        '\\<ss>'                   : '\U0001d530',
        '\\<tt>'                   : '\U0001d531',
        '\\<uu>'                   : '\U0001d532',
        '\\<vv>'                   : '\U0001d533',
        '\\<ww>'                   : '\U0001d534',
        '\\<xx>'                   : '\U0001d535',
        '\\<yy>'                   : '\U0001d536',
        '\\<zz>'                   : '\U0001d537',
        '\\<alpha>'                : '\U000003b1',
        '\\<beta>'                 : '\U000003b2',
        '\\<gamma>'                : '\U000003b3',
        '\\<delta>'                : '\U000003b4',
        '\\<epsilon>'              : '\U000003b5',
        '\\<zeta>'                 : '\U000003b6',
        '\\<eta>'                  : '\U000003b7',
        '\\<theta>'                : '\U000003b8',
        '\\<iota>'                 : '\U000003b9',
        '\\<kappa>'                : '\U000003ba',
        '\\<lambda>'               : '\U000003bb',
        '\\<mu>'                   : '\U000003bc',
        '\\<nu>'                   : '\U000003bd',
        '\\<xi>'                   : '\U000003be',
        '\\<pi>'                   : '\U000003c0',
        '\\<rho>'                  : '\U000003c1',
        '\\<sigma>'                : '\U000003c3',
        '\\<tau>'                  : '\U000003c4',
        '\\<upsilon>'              : '\U000003c5',
        '\\<phi>'                  : '\U000003c6',
        '\\<chi>'                  : '\U000003c7',
        '\\<psi>'                  : '\U000003c8',
        '\\<omega>'                : '\U000003c9',
        '\\<Gamma>'                : '\U00000393',
        '\\<Delta>'                : '\U00000394',
        '\\<Theta>'                : '\U00000398',
        '\\<Lambda>'               : '\U0000039b',
        '\\<Xi>'                   : '\U0000039e',
        '\\<Pi>'                   : '\U000003a0',
        '\\<Sigma>'                : '\U000003a3',
        '\\<Upsilon>'              : '\U000003a5',
        '\\<Phi>'                  : '\U000003a6',
        '\\<Psi>'                  : '\U000003a8',
        '\\<Omega>'                : '\U000003a9',
        '\\<bool>'                 : '\U0001d539',
        '\\<complex>'              : '\U00002102',
        '\\<nat>'                  : '\U00002115',
        '\\<rat>'                  : '\U0000211a',
        '\\<real>'                 : '\U0000211d',
        '\\<int>'                  : '\U00002124',
        '\\<leftarrow>'            : '\U00002190',
        '\\<longleftarrow>'        : '\U000027f5',
        '\\<rightarrow>'           : '\U00002192',
        '\\<longrightarrow>'       : '\U000027f6',
        '\\<Leftarrow>'            : '\U000021d0',
        '\\<Longleftarrow>'        : '\U000027f8',
        '\\<Rightarrow>'           : '\U000021d2',
        '\\<Longrightarrow>'       : '\U000027f9',
        '\\<leftrightarrow>'       : '\U00002194',
        '\\<longleftrightarrow>'   : '\U000027f7',
        '\\<Leftrightarrow>'       : '\U000021d4',
        '\\<Longleftrightarrow>'   : '\U000027fa',
        '\\<mapsto>'               : '\U000021a6',
        '\\<longmapsto>'           : '\U000027fc',
        '\\<midarrow>'             : '\U00002500',
        '\\<Midarrow>'             : '\U00002550',
        '\\<hookleftarrow>'        : '\U000021a9',
        '\\<hookrightarrow>'       : '\U000021aa',
        '\\<leftharpoondown>'      : '\U000021bd',
        '\\<rightharpoondown>'     : '\U000021c1',
        '\\<leftharpoonup>'        : '\U000021bc',
        '\\<rightharpoonup>'       : '\U000021c0',
        '\\<rightleftharpoons>'    : '\U000021cc',
        '\\<leadsto>'              : '\U0000219d',
        '\\<downharpoonleft>'      : '\U000021c3',
        '\\<downharpoonright>'     : '\U000021c2',
        '\\<upharpoonleft>'        : '\U000021bf',
        '\\<upharpoonright>'       : '\U000021be',
        '\\<restriction>'          : '\U000021be',
        '\\<Colon>'                : '\U00002237',
        '\\<up>'                   : '\U00002191',
        '\\<Up>'                   : '\U000021d1',
        '\\<down>'                 : '\U00002193',
        '\\<Down>'                 : '\U000021d3',
        '\\<updown>'               : '\U00002195',
        '\\<Updown>'               : '\U000021d5',
        '\\<langle>'               : '\U000027e8',
        '\\<rangle>'               : '\U000027e9',
        '\\<lceil>'                : '\U00002308',
        '\\<rceil>'                : '\U00002309',
        '\\<lfloor>'               : '\U0000230a',
        '\\<rfloor>'               : '\U0000230b',
        '\\<lparr>'                : '\U00002987',
        '\\<rparr>'                : '\U00002988',
        '\\<lbrakk>'               : '\U000027e6',
        '\\<rbrakk>'               : '\U000027e7',
        '\\<lbrace>'               : '\U00002983',
        '\\<rbrace>'               : '\U00002984',
        '\\<guillemotleft>'        : '\U000000ab',
        '\\<guillemotright>'       : '\U000000bb',
        '\\<bottom>'               : '\U000022a5',
        '\\<top>'                  : '\U000022a4',
        '\\<and>'                  : '\U00002227',
        '\\<And>'                  : '\U000022c0',
        '\\<or>'                   : '\U00002228',
        '\\<Or>'                   : '\U000022c1',
        '\\<forall>'               : '\U00002200',
        '\\<exists>'               : '\U00002203',
        '\\<nexists>'              : '\U00002204',
        '\\<not>'                  : '\U000000ac',
        '\\<box>'                  : '\U000025a1',
        '\\<diamond>'              : '\U000025c7',
        '\\<turnstile>'            : '\U000022a2',
        '\\<Turnstile>'            : '\U000022a8',
        '\\<tturnstile>'           : '\U000022a9',
        '\\<TTurnstile>'           : '\U000022ab',
        '\\<stileturn>'            : '\U000022a3',
        '\\<surd>'                 : '\U0000221a',
        '\\<le>'                   : '\U00002264',
        '\\<ge>'                   : '\U00002265',
        '\\<lless>'                : '\U0000226a',
        '\\<ggreater>'             : '\U0000226b',
        '\\<lesssim>'              : '\U00002272',
        '\\<greatersim>'           : '\U00002273',
        '\\<lessapprox>'           : '\U00002a85',
        '\\<greaterapprox>'        : '\U00002a86',
        '\\<in>'                   : '\U00002208',
        '\\<notin>'                : '\U00002209',
        '\\<subset>'               : '\U00002282',
        '\\<supset>'               : '\U00002283',
        '\\<subseteq>'             : '\U00002286',
        '\\<supseteq>'             : '\U00002287',
        '\\<sqsubset>'             : '\U0000228f',
        '\\<sqsupset>'             : '\U00002290',
        '\\<sqsubseteq>'           : '\U00002291',
        '\\<sqsupseteq>'           : '\U00002292',
        '\\<inter>'                : '\U00002229',
        '\\<Inter>'                : '\U000022c2',
        '\\<union>'                : '\U0000222a',
        '\\<Union>'                : '\U000022c3',
        '\\<squnion>'              : '\U00002294',
        '\\<Squnion>'              : '\U00002a06',
        '\\<sqinter>'              : '\U00002293',
        '\\<Sqinter>'              : '\U00002a05',
        '\\<setminus>'             : '\U00002216',
        '\\<propto>'               : '\U0000221d',
        '\\<uplus>'                : '\U0000228e',
        '\\<Uplus>'                : '\U00002a04',
        '\\<noteq>'                : '\U00002260',
        '\\<sim>'                  : '\U0000223c',
        '\\<doteq>'                : '\U00002250',
        '\\<simeq>'                : '\U00002243',
        '\\<approx>'               : '\U00002248',
        '\\<asymp>'                : '\U0000224d',
        '\\<cong>'                 : '\U00002245',
        '\\<smile>'                : '\U00002323',
        '\\<equiv>'                : '\U00002261',
        '\\<frown>'                : '\U00002322',
        '\\<Join>'                 : '\U000022c8',
        '\\<bowtie>'               : '\U00002a1d',
        '\\<prec>'                 : '\U0000227a',
        '\\<succ>'                 : '\U0000227b',
        '\\<preceq>'               : '\U0000227c',
        '\\<succeq>'               : '\U0000227d',
        '\\<parallel>'             : '\U00002225',
        '\\<bar>'                  : '\U000000a6',
        '\\<plusminus>'            : '\U000000b1',
        '\\<minusplus>'            : '\U00002213',
        '\\<times>'                : '\U000000d7',
        '\\<div>'                  : '\U000000f7',
        '\\<cdot>'                 : '\U000022c5',
        '\\<star>'                 : '\U000022c6',
        '\\<bullet>'               : '\U00002219',
        '\\<circ>'                 : '\U00002218',
        '\\<dagger>'               : '\U00002020',
        '\\<ddagger>'              : '\U00002021',
        '\\<lhd>'                  : '\U000022b2',
        '\\<rhd>'                  : '\U000022b3',
        '\\<unlhd>'                : '\U000022b4',
        '\\<unrhd>'                : '\U000022b5',
        '\\<triangleleft>'         : '\U000025c3',
        '\\<triangleright>'        : '\U000025b9',
        '\\<triangle>'             : '\U000025b3',
        '\\<triangleq>'            : '\U0000225c',
        '\\<oplus>'                : '\U00002295',
        '\\<Oplus>'                : '\U00002a01',
        '\\<otimes>'               : '\U00002297',
        '\\<Otimes>'               : '\U00002a02',
        '\\<odot>'                 : '\U00002299',
        '\\<Odot>'                 : '\U00002a00',
        '\\<ominus>'               : '\U00002296',
        '\\<oslash>'               : '\U00002298',
        '\\<dots>'                 : '\U00002026',
        '\\<cdots>'                : '\U000022ef',
        '\\<Sum>'                  : '\U00002211',
        '\\<Prod>'                 : '\U0000220f',
        '\\<Coprod>'               : '\U00002210',
        '\\<infinity>'             : '\U0000221e',
        '\\<integral>'             : '\U0000222b',
        '\\<ointegral>'            : '\U0000222e',
        '\\<clubsuit>'             : '\U00002663',
        '\\<diamondsuit>'          : '\U00002662',
        '\\<heartsuit>'            : '\U00002661',
        '\\<spadesuit>'            : '\U00002660',
        '\\<aleph>'                : '\U00002135',
        '\\<emptyset>'             : '\U00002205',
        '\\<nabla>'                : '\U00002207',
        '\\<partial>'              : '\U00002202',
        '\\<flat>'                 : '\U0000266d',
        '\\<natural>'              : '\U0000266e',
        '\\<sharp>'                : '\U0000266f',
        '\\<angle>'                : '\U00002220',
        '\\<copyright>'            : '\U000000a9',
        '\\<registered>'           : '\U000000ae',
        '\\<hyphen>'               : '\U000000ad',
        '\\<inverse>'              : '\U000000af',
        '\\<onequarter>'           : '\U000000bc',
        '\\<onehalf>'              : '\U000000bd',
        '\\<threequarters>'        : '\U000000be',
        '\\<ordfeminine>'          : '\U000000aa',
        '\\<ordmasculine>'         : '\U000000ba',
        '\\<section>'              : '\U000000a7',
        '\\<paragraph>'            : '\U000000b6',
        '\\<exclamdown>'           : '\U000000a1',
        '\\<questiondown>'         : '\U000000bf',
        '\\<euro>'                 : '\U000020ac',
        '\\<pounds>'               : '\U000000a3',
        '\\<yen>'                  : '\U000000a5',
        '\\<cent>'                 : '\U000000a2',
        '\\<currency>'             : '\U000000a4',
        '\\<degree>'               : '\U000000b0',
        '\\<amalg>'                : '\U00002a3f',
        '\\<mho>'                  : '\U00002127',
        '\\<lozenge>'              : '\U000025ca',
        '\\<wp>'                   : '\U00002118',
        '\\<wrong>'                : '\U00002240',
        '\\<struct>'               : '\U000022c4',
        '\\<acute>'                : '\U000000b4',
        '\\<index>'                : '\U00000131',
        '\\<dieresis>'             : '\U000000a8',
        '\\<cedilla>'              : '\U000000b8',
        '\\<hungarumlaut>'         : '\U000002dd',
        '\\<some>'                 : '\U000003f5',
        '\\<newline>'              : '\U000023ce',
        '\\<open>'                 : '\U00002039',
        '\\<close>'                : '\U0000203a',
        '\\<here>'                 : '\U00002302',
        '\\<^sub>'                 : '\U000021e9',
        '\\<^sup>'                 : '\U000021e7',
        '\\<^bold>'                : '\U00002759',
        '\\<^bsub>'                : '\U000021d8',
        '\\<^esub>'                : '\U000021d9',
        '\\<^bsup>'                : '\U000021d7',
        '\\<^esup>'                : '\U000021d6',
    }

    lang_map = {'isabelle' : isabelle_symbols, 'latex' : latex_symbols}

    def __init__(self, **options):
        Filter.__init__(self, **options)
        lang = get_choice_opt(options, 'lang',
                              ['isabelle', 'latex'], 'isabelle')
        self.symbols = self.lang_map[lang]

    def filter(self, lexer, stream):
        for ttype, value in stream:
            if value in self.symbols:
                yield ttype, self.symbols[value]
            else:
                yield ttype, value


class KeywordCaseFilter(Filter):
    

    def __init__(self, **options):
        Filter.__init__(self, **options)
        case = get_choice_opt(options, 'case',
                              ['lower', 'upper', 'capitalize'], 'lower')
        self.convert = getattr(str, case)

    def filter(self, lexer, stream):
        for ttype, value in stream:
            if ttype in Keyword:
                yield ttype, self.convert(value)
            else:
                yield ttype, value


class NameHighlightFilter(Filter):
    

    def __init__(self, **options):
        Filter.__init__(self, **options)
        self.names = set(get_list_opt(options, 'names', []))
        tokentype = options.get('tokentype')
        if tokentype:
            self.tokentype = string_to_tokentype(tokentype)
        else:
            self.tokentype = Name.Function

    def filter(self, lexer, stream):
        for ttype, value in stream:
            if ttype in Name and value in self.names:
                yield self.tokentype, value
            else:
                yield ttype, value


class ErrorToken(Exception):
    pass


class RaiseOnErrorTokenFilter(Filter):
    

    def __init__(self, **options):
        Filter.__init__(self, **options)
        self.exception = options.get('excclass', ErrorToken)
        try:
            
            if not issubclass(self.exception, Exception):
                raise TypeError
        except TypeError:
            raise OptionError('excclass option is not an exception class')

    def filter(self, lexer, stream):
        for ttype, value in stream:
            if ttype is Error:
                raise self.exception(value)
            yield ttype, value


class VisibleWhitespaceFilter(Filter):
    

    def __init__(self, **options):
        Filter.__init__(self, **options)
        for name, default in [('spaces',   '·'),
                              ('tabs',     '»'),
                              ('newlines', '¶')]:
            opt = options.get(name, False)
            if isinstance(opt, str) and len(opt) == 1:
                setattr(self, name, opt)
            else:
                setattr(self, name, (opt and default or ''))
        tabsize = get_int_opt(options, 'tabsize', 8)
        if self.tabs:
            self.tabs += ' ' * (tabsize - 1)
        if self.newlines:
            self.newlines += '\n'
        self.wstt = get_bool_opt(options, 'wstokentype', True)

    def filter(self, lexer, stream):
        if self.wstt:
            spaces = self.spaces or ' '
            tabs = self.tabs or '\t'
            newlines = self.newlines or '\n'
            regex = re.compile(r'\s')

            def replacefunc(wschar):
                if wschar == ' ':
                    return spaces
                elif wschar == '\t':
                    return tabs
                elif wschar == '\n':
                    return newlines
                return wschar

            for ttype, value in stream:
                yield from _replace_special(ttype, value, regex, Whitespace,
                                            replacefunc)
        else:
            spaces, tabs, newlines = self.spaces, self.tabs, self.newlines
            
            for ttype, value in stream:
                if spaces:
                    value = value.replace(' ', spaces)
                if tabs:
                    value = value.replace('\t', tabs)
                if newlines:
                    value = value.replace('\n', newlines)
                yield ttype, value


class GobbleFilter(Filter):
    
    def __init__(self, **options):
        Filter.__init__(self, **options)
        self.n = get_int_opt(options, 'n', 0)

    def gobble(self, value, left):
        if left < len(value):
            return value[left:], 0
        else:
            return '', left - len(value)

    def filter(self, lexer, stream):
        n = self.n
        left = n  
        for ttype, value in stream:
            
            parts = value.split('\n')
            (parts[0], left) = self.gobble(parts[0], left)
            for i in range(1, len(parts)):
                (parts[i], left) = self.gobble(parts[i], n)
            value = '\n'.join(parts)

            if value != '':
                yield ttype, value


class TokenMergeFilter(Filter):
    
    def __init__(self, **options):
        Filter.__init__(self, **options)

    def filter(self, lexer, stream):
        current_type = None
        current_value = None
        for ttype, value in stream:
            if ttype is current_type:
                current_value += value
            else:
                if current_type is not None:
                    yield current_type, current_value
                current_type = ttype
                current_value = value
        if current_type is not None:
            yield current_type, current_value


FILTERS = {
    'codetagify':     CodeTagFilter,
    'keywordcase':    KeywordCaseFilter,
    'highlight':      NameHighlightFilter,
    'raiseonerror':   RaiseOnErrorTokenFilter,
    'whitespace':     VisibleWhitespaceFilter,
    'gobble':         GobbleFilter,
    'tokenmerge':     TokenMergeFilter,
    'symbols':        SymbolFilter,
}




FORMATTERS = {
    'BBCodeFormatter': ('pygments.formatters.bbcode', 'BBCode', ('bbcode', 'bb'), (), 'Format tokens with BBcodes. These formatting codes are used by many bulletin boards, so you can highlight your sourcecode with pygments before posting it there.'),
    'BmpImageFormatter': ('pygments.formatters.img', 'img_bmp', ('bmp', 'bitmap'), ('*.bmp',), 'Create a bitmap image from source code. This uses the Python Imaging Library to generate a pixmap from the source code.'),
    'GifImageFormatter': ('pygments.formatters.img', 'img_gif', ('gif',), ('*.gif',), 'Create a GIF image from source code. This uses the Python Imaging Library to generate a pixmap from the source code.'),
    'GroffFormatter': ('pygments.formatters.groff', 'groff', ('groff', 'troff', 'roff'), (), 'Format tokens with groff escapes to change their color and font style.'),
    'HtmlFormatter': ('pygments.formatters.html', 'HTML', ('html',), ('*.html', '*.htm'), ""Format tokens as HTML 4 ``<span>`` tags. By default, the content is enclosed in a ``<pre>`` tag, itself wrapped in a ``<div>`` tag (but see the `nowrap` option). The ``<div>``'s CSS class can be set by the `cssclass` option.""),
    'IRCFormatter': ('pygments.formatters.irc', 'IRC', ('irc', 'IRC'), (), 'Format tokens with IRC color sequences'),
    'ImageFormatter': ('pygments.formatters.img', 'img', ('img', 'IMG', 'png'), ('*.png',), 'Create a PNG image from source code. This uses the Python Imaging Library to generate a pixmap from the source code.'),
    'JpgImageFormatter': ('pygments.formatters.img', 'img_jpg', ('jpg', 'jpeg'), ('*.jpg',), 'Create a JPEG image from source code. This uses the Python Imaging Library to generate a pixmap from the source code.'),
    'LatexFormatter': ('pygments.formatters.latex', 'LaTeX', ('latex', 'tex'), ('*.tex',), 'Format tokens as LaTeX code. This needs the `fancyvrb` and `color` standard packages.'),
    'NullFormatter': ('pygments.formatters.other', 'Text only', ('text', 'null'), ('*.txt',), 'Output the text unchanged without any formatting.'),
    'PangoMarkupFormatter': ('pygments.formatters.pangomarkup', 'Pango Markup', ('pango', 'pangomarkup'), (), 'Format tokens as Pango Markup code. It can then be rendered to an SVG.'),
    'RawTokenFormatter': ('pygments.formatters.other', 'Raw tokens', ('raw', 'tokens'), ('*.raw',), 'Format tokens as a raw representation for storing token streams.'),
    'RtfFormatter': ('pygments.formatters.rtf', 'RTF', ('rtf',), ('*.rtf',), 'Format tokens as RTF markup. This formatter automatically outputs full RTF documents with color information and other useful stuff. Perfect for Copy and Paste into Microsoft(R) Word(R) documents.'),
    'SvgFormatter': ('pygments.formatters.svg', 'SVG', ('svg',), ('*.svg',), 'Format tokens as an SVG graphics file.  This formatter is still experimental. Each line of code is a ``<text>`` element with explicit ``x`` and ``y`` coordinates containing ``<tspan>`` elements with the individual token styles.'),
    'Terminal256Formatter': ('pygments.formatters.terminal256', 'Terminal256', ('terminal256', 'console256', '256'), (), 'Format tokens with ANSI color sequences, for output in a 256-color terminal or console.  Like in `TerminalFormatter` color sequences are terminated at newlines, so that paging the output works correctly.'),
    'TerminalFormatter': ('pygments.formatters.terminal', 'Terminal', ('terminal', 'console'), (), 'Format tokens with ANSI color sequences, for output in a text console. Color sequences are terminated at newlines, so that paging the output works correctly.'),
    'TerminalTrueColorFormatter': ('pygments.formatters.terminal256', 'TerminalTrueColor', ('terminal16m', 'console16m', '16m'), (), 'Format tokens with ANSI color sequences, for output in a true-color terminal or console.  Like in `TerminalFormatter` color sequences are terminated at newlines, so that paging the output works correctly.'),
    'TestcaseFormatter': ('pygments.formatters.other', 'Testcase', ('testcase',), (), 'Format tokens as appropriate for a new testcase.'),
}



import re
import sys
import types
import fnmatch
from os.path import basename

from pip._vendor.pygments.formatters._mapping import FORMATTERS
from pip._vendor.pygments.plugin import find_plugin_formatters
from pip._vendor.pygments.util import ClassNotFound

__all__ = ['get_formatter_by_name', 'get_formatter_for_filename',
           'get_all_formatters', 'load_formatter_from_file'] + list(FORMATTERS)

_formatter_cache = {}  
_pattern_cache = {}


def _fn_matches(fn, glob):
    
    if glob not in _pattern_cache:
        pattern = _pattern_cache[glob] = re.compile(fnmatch.translate(glob))
        return pattern.match(fn)
    return _pattern_cache[glob].match(fn)


def _load_formatters(module_name):
    
    mod = __import__(module_name, None, None, ['__all__'])
    for formatter_name in mod.__all__:
        cls = getattr(mod, formatter_name)
        _formatter_cache[cls.name] = cls


def get_all_formatters():
    
    
    for info in FORMATTERS.values():
        if info[1] not in _formatter_cache:
            _load_formatters(info[0])
        yield _formatter_cache[info[1]]
    for _, formatter in find_plugin_formatters():
        yield formatter


def find_formatter_class(alias):
    
    for module_name, name, aliases, _, _ in FORMATTERS.values():
        if alias in aliases:
            if name not in _formatter_cache:
                _load_formatters(module_name)
            return _formatter_cache[name]
    for _, cls in find_plugin_formatters():
        if alias in cls.aliases:
            return cls


def get_formatter_by_name(_alias, **options):
    
    cls = find_formatter_class(_alias)
    if cls is None:
        raise ClassNotFound(f""no formatter found for name {_alias!r}"")
    return cls(**options)


def load_formatter_from_file(filename, formattername=""CustomFormatter"", **options):
    
    try:
        
        custom_namespace = {}
        with open(filename, 'rb') as f:
            exec(f.read(), custom_namespace)
        
        if formattername not in custom_namespace:
            raise ClassNotFound(f'no valid {formattername} class found in {filename}')
        formatter_class = custom_namespace[formattername]
        
        return formatter_class(**options)
    except OSError as err:
        raise ClassNotFound(f'cannot read {filename}: {err}')
    except ClassNotFound:
        raise
    except Exception as err:
        raise ClassNotFound(f'error when loading custom formatter: {err}')


def get_formatter_for_filename(fn, **options):
    
    fn = basename(fn)
    for modname, name, _, filenames, _ in FORMATTERS.values():
        for filename in filenames:
            if _fn_matches(fn, filename):
                if name not in _formatter_cache:
                    _load_formatters(modname)
                return _formatter_cache[name](**options)
    for _name, cls in find_plugin_formatters():
        for filename in cls.filenames:
            if _fn_matches(fn, filename):
                return cls(**options)
    raise ClassNotFound(f""no formatter found for file name {fn!r}"")


class _automodule(types.ModuleType):
    

    def __getattr__(self, name):
        info = FORMATTERS.get(name)
        if info:
            _load_formatters(info[0])
            cls = _formatter_cache[info[1]]
            setattr(self, name, cls)
            return cls
        raise AttributeError(name)


oldmod = sys.modules[__name__]
newmod = _automodule(__name__)
newmod.__dict__.update(oldmod.__dict__)
sys.modules[__name__] = newmod
del newmod.newmod, newmod.oldmod, newmod.sys, newmod.types



import keyword

from pip._vendor.pygments.lexer import DelegatingLexer, RegexLexer, include, \
    bygroups, using, default, words, combined, this
from pip._vendor.pygments.util import get_bool_opt, shebang_matches
from pip._vendor.pygments.token import Text, Comment, Operator, Keyword, Name, String, \
    Number, Punctuation, Generic, Other, Error, Whitespace
from pip._vendor.pygments import unistring as uni

__all__ = ['PythonLexer', 'PythonConsoleLexer', 'PythonTracebackLexer',
           'Python2Lexer', 'Python2TracebackLexer',
           'CythonLexer', 'DgLexer', 'NumPyLexer']


class PythonLexer(RegexLexer):
    

    name = 'Python'
    url = 'https://www.python.org'
    aliases = ['python', 'py', 'sage', 'python3', 'py3', 'bazel', 'starlark', 'pyi']
    filenames = [
        '*.py',
        '*.pyw',
        
        '*.pyi',
        
        '*.jy',
        
        '*.sage',
        
        '*.sc',
        'SConstruct',
        'SConscript',
        
        '*.bzl',
        'BUCK',
        'BUILD',
        'BUILD.bazel',
        'WORKSPACE',
        
        '*.tac',
    ]
    mimetypes = ['text/x-python', 'application/x-python',
                 'text/x-python3', 'application/x-python3']
    version_added = '0.10'

    uni_name = f""[{uni.xid_start}][{uni.xid_continue}]*""

    def innerstring_rules(ttype):
        return [
            
            (r'%(\(\w+\))?[-
             '[hlL]?[E-GXc-giorsaux%]', String.Interpol),
            
            (r'\{'
             r'((\w+)((\.\w+)|(\[[^\]]+\]))*)?'  
             r'(\![sra])?'                       
             r'(\:(.?[<>=\^])?[-+ ]?
             r'\}', String.Interpol),

            
            (r'[^\\\'""%{\n]+', ttype),
            (r'[\'""\\]', ttype),
            
            (r'%|(\{{1,2})', ttype)
            
        ]

    def fstring_rules(ttype):
        return [
            
            
            
            
            (r'\}', String.Interpol),
            (r'\{', String.Interpol, 'expr-inside-fstring'),
            
            (r'[^\\\'""{}\n]+', ttype),
            (r'[\'""\\]', ttype),
            
        ]

    tokens = {
        'root': [
            (r'\n', Whitespace),
            (r'^(\s*)([rRuUbB]{,2})()',
             bygroups(Whitespace, String.Affix, String.Doc)),
            (r""^(\s*)([rRuUbB]{,2})()"",
             bygroups(Whitespace, String.Affix, String.Doc)),
            (r'\A
            (r'
            (r'\\\n', Text),
            (r'\\', Text),
            include('keywords'),
            include('soft-keywords'),
            (r'(def)((?:\s|\\\s)+)', bygroups(Keyword, Whitespace), 'funcname'),
            (r'(class)((?:\s|\\\s)+)', bygroups(Keyword, Whitespace), 'classname'),
            (r'(from)((?:\s|\\\s)+)', bygroups(Keyword.Namespace, Whitespace),
             'fromimport'),
            (r'(import)((?:\s|\\\s)+)', bygroups(Keyword.Namespace, Whitespace),
             'import'),
            include('expr'),
        ],
        'expr': [
            
            ('(?i)(rf|fr)()',
             bygroups(String.Affix, String.Double), 'tdqs'),
            (""(?i)(rb|br|r)()"", bygroups(String.Affix, String.Single),
             combined('stringescape', 'tsqs')),
            ('([uU]?)("")', bygroups(String.Affix, String.Double),
             combined('stringescape', 'dqs')),
            (""([uU]?)(')"", bygroups(String.Affix, String.Single),
             combined('stringescape', 'sqs')),
            
            ('([bB])(', String.Double, '
            include('strings-double'),
            (r'\n', String.Double)
        ],
        'tsqs': [
            (r""(?:.|\n)*?)"",
             bygroups(String.Affix, String.Single), 'tsqs'),
            ('([rR]|[uUbB][rR]|[rR][uUbB])("")',
             bygroups(String.Affix, String.Double), 'dqs'),
            (""([rR]|[uUbB][rR]|[rR][uUbB])(')"",
             bygroups(String.Affix, String.Single), 'sqs'),
            ('([uUbB]?)(Auxiliary lexer for `PythonConsoleLexer`.

    Code tokens are output as ``Token.Other.Code``, traceback tokens as
    ``Token.Other.Traceback``.
    
    For Python console output or doctests, such as:

    .. sourcecode:: pycon

        >>> a = 'foo'
        >>> print(a)
        foo
        >>> 1 / 0
        Traceback (most recent call last):
          File ""<stdin>"", line 1, in <module>
        ZeroDivisionError: integer division or modulo by zero

    Additional options:

    `python3`
        Use Python 3 lexer for code.  Default is ``True``.

        .. versionadded:: 1.0
        .. versionchanged:: 2.5
           Now defaults to ``True``.
    
    For Python 3.x tracebacks, with support for chained exceptions.

    .. versionchanged:: 2.5
       This is now the default ``PythonTracebackLexer``.  It is still available
       as the alias ``Python3TracebackLexer``.
    
    For Python tracebacks.

    .. versionchanged:: 2.5
       This class has been renamed from ``PythonTracebackLexer``.
       ``PythonTracebackLexer`` now refers to the Python 3 variant.
    
    For Pyrex and Cython source code.
    (?:.|\n)*?', String, 'tdqs'),
            (""(?:[rR]|[uU][rR]|[rR][uU])"", String, combined('stringescape', 'tsqs')),
            ('[uU]?""', String, combined('stringescape', 'dqs')),
            (""[uU]?'"", String, combined('stringescape', 'sqs')),
            include('name'),
            include('numbers'),
        ],
        'keywords': [
            (words((
                'assert', 'async', 'await', 'break', 'by', 'continue', 'ctypedef', 'del', 'elif',
                'else', 'except', 'except?', 'exec', 'finally', 'for', 'fused', 'gil',
                'global', 'if', 'include', 'lambda', 'nogil', 'pass', 'print',
                'raise', 'return', 'try', 'while', 'yield', 'as', 'with'), suffix=r'\b'),
             Keyword),
            (r'(DEF|IF|ELIF|ELSE)\b', Comment.Preproc),
        ],
        'builtins': [
            (words((
                '__import__', 'abs', 'all', 'any', 'apply', 'basestring', 'bin', 'bint',
                'bool', 'buffer', 'bytearray', 'bytes', 'callable', 'chr',
                'classmethod', 'cmp', 'coerce', 'compile', 'complex', 'delattr',
                'dict', 'dir', 'divmod', 'enumerate', 'eval', 'execfile', 'exit',
                'file', 'filter', 'float', 'frozenset', 'getattr', 'globals',
                'hasattr', 'hash', 'hex', 'id', 'input', 'int', 'intern', 'isinstance',
                'issubclass', 'iter', 'len', 'list', 'locals', 'long', 'map', 'max',
                'min', 'next', 'object', 'oct', 'open', 'ord', 'pow', 'property', 'Py_ssize_t',
                'range', 'raw_input', 'reduce', 'reload', 'repr', 'reversed',
                'round', 'set', 'setattr', 'slice', 'sorted', 'staticmethod',
                'str', 'sum', 'super', 'tuple', 'type', 'unichr', 'unicode', 'unsigned',
                'vars', 'xrange', 'zip'), prefix=r'(?<!\.)', suffix=r'\b'),
             Name.Builtin),
            (r'(?<!\.)(self|None|Ellipsis|NotImplemented|False|True|NULL'
             r')\b', Name.Builtin.Pseudo),
            (words((
                'ArithmeticError', 'AssertionError', 'AttributeError',
                'BaseException', 'DeprecationWarning', 'EOFError', 'EnvironmentError',
                'Exception', 'FloatingPointError', 'FutureWarning', 'GeneratorExit',
                'IOError', 'ImportError', 'ImportWarning', 'IndentationError',
                'IndexError', 'KeyError', 'KeyboardInterrupt', 'LookupError',
                'MemoryError', 'NameError', 'NotImplemented', 'NotImplementedError',
                'OSError', 'OverflowError', 'OverflowWarning',
                'PendingDeprecationWarning', 'ReferenceError', 'RuntimeError',
                'RuntimeWarning', 'StandardError', 'StopIteration', 'SyntaxError',
                'SyntaxWarning', 'SystemError', 'SystemExit', 'TabError',
                'TypeError', 'UnboundLocalError', 'UnicodeDecodeError',
                'UnicodeEncodeError', 'UnicodeError', 'UnicodeTranslateError',
                'UnicodeWarning', 'UserWarning', 'ValueError', 'Warning',
                'ZeroDivisionError'), prefix=r'(?<!\.)', suffix=r'\b'),
             Name.Exception),
        ],
        'numbers': [
            (r'(\d+\.?\d*|\d*\.\d+)([eE][+-]?[0-9]+)?', Number.Float),
            (r'0\d+', Number.Oct),
            (r'0[xX][a-fA-F0-9]+', Number.Hex),
            (r'\d+L', Number.Integer.Long),
            (r'\d+', Number.Integer)
        ],
        'backtick': [
            ('`.*?`', String.Backtick),
        ],
        'name': [
            (r'@\w+', Name.Decorator),
            (r'[a-zA-Z_]\w*', Name),
        ],
        'funcname': [
            (r'[a-zA-Z_]\w*', Name.Function, '
        ],
        'cdef': [
            (r'(public|readonly|extern|api|inline)\b', Keyword.Reserved),
            (r'(struct|enum|union|class)\b', Keyword),
            (r'([a-zA-Z_]\w*)(\s*)(?=[(:
             bygroups(Name.Function, Whitespace), '
            (r'([a-zA-Z_]\w*)(\s*)(,)',
             bygroups(Name.Function, Whitespace, Punctuation)),
            (r'from\b', Keyword, '
            (r'as\b', Keyword),
            (r':', Punctuation, '
            (r'(?=[""\'])', Text, '
            (r'[a-zA-Z_]\w*', Keyword.Type),
            (r'.', Text),
        ],
        'classname': [
            (r'[a-zA-Z_]\w*', Name.Class, '
        ],
        'import': [
            (r'(\s+)(as)(\s+)', bygroups(Whitespace, Keyword, Whitespace)),
            (r'[a-zA-Z_][\w.]*', Name.Namespace),
            (r'(\s*)(,)(\s*)', bygroups(Whitespace, Operator, Whitespace)),
            default('
        ],
        'fromimport': [
            (r'(\s+)(c?import)\b', bygroups(Whitespace, Keyword), '
            (r'[a-zA-Z_.][\w.]*', Name.Namespace),
            
            default('
        ],
        'stringescape': [
            (r'\\([\\abfnrtv""\']|\n|N\{.*?\}|u[a-fA-F0-9]{4}|'
             r'U[a-fA-F0-9]{8}|x[a-fA-F0-9]{2}|[0-7]{1,3})', String.Escape)
        ],
        'strings': [
            (r'%(\([a-zA-Z0-9]+\))?[-
             '[hlL]?[E-GXc-giorsux%]', String.Interpol),
            (r'[^\\\'""%\n]+', String),
            
            (r'[\'""\\]', String),
            
            (r'%', String)
            
        ],
        'nl': [
            (r'\n', String)
        ],
        'dqs': [
            (r'""', String, '
            (r'\\\\|\\""|\\\n', String.Escape),  
            include('strings')
        ],
        'sqs': [
            (r""'"", String, '
            (r""\\\\|\\'|\\\n"", String.Escape),  
            include('strings')
        ],
        'tdqs': [
            (r'', String, combined('stringescape', 'tdqs', 'string')),
            (r""(?i)(br|r?b?)'"", String, combined('stringescape', 'sqs', 'string')),
            (r'(?i)(br|r?b?)""', String, combined('stringescape', 'dqs', 'string')),

            (r""`\w+'*`"", Operator),
            (r'\b(and|in|is|or|where)\b', Operator.Word),
            (r'[!$%&*+\-./:<-@\\^|~;,]+', Operator),

            (words((
                'bool', 'bytearray', 'bytes', 'classmethod', 'complex', 'dict', 'dict\'',
                'float', 'frozenset', 'int', 'list', 'list\'', 'memoryview', 'object',
                'property', 'range', 'set', 'set\'', 'slice', 'staticmethod', 'str',
                'super', 'tuple', 'tuple\'', 'type'),
                   prefix=r'(?<!\.)', suffix=r'(?![\'\w])'),
             Name.Builtin),
            (words((
                '__import__', 'abs', 'all', 'any', 'bin', 'bind', 'chr', 'cmp', 'compile',
                'complex', 'delattr', 'dir', 'divmod', 'drop', 'dropwhile', 'enumerate',
                'eval', 'exhaust', 'filter', 'flip', 'foldl1?', 'format', 'fst',
                'getattr', 'globals', 'hasattr', 'hash', 'head', 'hex', 'id', 'init',
                'input', 'isinstance', 'issubclass', 'iter', 'iterate', 'last', 'len',
                'locals', 'map', 'max', 'min', 'next', 'oct', 'open', 'ord', 'pow',
                'print', 'repr', 'reversed', 'round', 'setattr', 'scanl1?', 'snd',
                'sorted', 'sum', 'tail', 'take', 'takewhile', 'vars', 'zip'),
                   prefix=r'(?<!\.)', suffix=r'(?![\'\w])'),
             Name.Builtin),
            (r""(?<!\.)(self|Ellipsis|NotImplemented|None|True|False)(?!['\w])"",
             Name.Builtin.Pseudo),

            (r""(?<!\.)[A-Z]\w*(Error|Exception|Warning)'*(?!['\w])"",
             Name.Exception),
            (r""(?<!\.)(Exception|GeneratorExit|KeyboardInterrupt|StopIteration|""
             r""SystemExit)(?!['\w])"", Name.Exception),

            (r""(?<![\w.])(except|finally|for|if|import|not|otherwise|raise|""
             r""subclass|while|with|yield)(?!['\w])"", Keyword.Reserved),

            (r""[A-Z_]+'*(?!['\w])"", Name),
            (r""[A-Z]\w+'*(?!['\w])"", Keyword.Type),
            (r""\w+'*"", Name),

            (r'[()]', Punctuation),
            (r'.', Error),
        ],
        'stringescape': [
            (r'\\([\\abfnrtv""\']|\n|N\{.*?\}|u[a-fA-F0-9]{4}|'
             r'U[a-fA-F0-9]{8}|x[a-fA-F0-9]{2}|[0-7]{1,3})', String.Escape)
        ],
        'string': [
            (r'%(\(\w+\))?[-
             '[hlL]?[E-GXc-giorsux%]', String.Interpol),
            (r'[^\\\'""%\n]+', String),
            
            (r'[\'""\\]', String),
            
            (r'%', String),
            (r'\n', String)
        ],
        'dqs': [
            (r'""', String, '
        ],
        'sqs': [
            (r""'"", String, '
        ],
        'tdqs': [
            (r'
    A Python lexer recognizing Numerical Python builtins.
    """"""

    name = 'NumPy'
    url = 'https://numpy.org/'
    aliases = ['numpy']
    version_added = '0.10'

    
    mimetypes = []
    filenames = []

    EXTRA_KEYWORDS = {
        'abs', 'absolute', 'accumulate', 'add', 'alen', 'all', 'allclose',
        'alltrue', 'alterdot', 'amax', 'amin', 'angle', 'any', 'append',
        'apply_along_axis', 'apply_over_axes', 'arange', 'arccos', 'arccosh',
        'arcsin', 'arcsinh', 'arctan', 'arctan2', 'arctanh', 'argmax', 'argmin',
        'argsort', 'argwhere', 'around', 'array', 'array2string', 'array_equal',
        'array_equiv', 'array_repr', 'array_split', 'array_str', 'arrayrange',
        'asanyarray', 'asarray', 'asarray_chkfinite', 'ascontiguousarray',
        'asfarray', 'asfortranarray', 'asmatrix', 'asscalar', 'astype',
        'atleast_1d', 'atleast_2d', 'atleast_3d', 'average', 'bartlett',
        'base_repr', 'beta', 'binary_repr', 'bincount', 'binomial',
        'bitwise_and', 'bitwise_not', 'bitwise_or', 'bitwise_xor', 'blackman',
        'bmat', 'broadcast', 'byte_bounds', 'bytes', 'byteswap', 'c_',
        'can_cast', 'ceil', 'choose', 'clip', 'column_stack', 'common_type',
        'compare_chararrays', 'compress', 'concatenate', 'conj', 'conjugate',
        'convolve', 'copy', 'corrcoef', 'correlate', 'cos', 'cosh', 'cov',
        'cross', 'cumprod', 'cumproduct', 'cumsum', 'delete', 'deprecate',
        'diag', 'diagflat', 'diagonal', 'diff', 'digitize', 'disp', 'divide',
        'dot', 'dsplit', 'dstack', 'dtype', 'dump', 'dumps', 'ediff1d', 'empty',
        'empty_like', 'equal', 'exp', 'expand_dims', 'expm1', 'extract', 'eye',
        'fabs', 'fastCopyAndTranspose', 'fft', 'fftfreq', 'fftshift', 'fill',
        'finfo', 'fix', 'flat', 'flatnonzero', 'flatten', 'fliplr', 'flipud',
        'floor', 'floor_divide', 'fmod', 'frexp', 'fromarrays', 'frombuffer',
        'fromfile', 'fromfunction', 'fromiter', 'frompyfunc', 'fromstring',
        'generic', 'get_array_wrap', 'get_include', 'get_numarray_include',
        'get_numpy_include', 'get_printoptions', 'getbuffer', 'getbufsize',
        'geterr', 'geterrcall', 'geterrobj', 'getfield', 'gradient', 'greater',
        'greater_equal', 'gumbel', 'hamming', 'hanning', 'histogram',
        'histogram2d', 'histogramdd', 'hsplit', 'hstack', 'hypot', 'i0',
        'identity', 'ifft', 'imag', 'index_exp', 'indices', 'inf', 'info',
        'inner', 'insert', 'int_asbuffer', 'interp', 'intersect1d',
        'intersect1d_nu', 'inv', 'invert', 'iscomplex', 'iscomplexobj',
        'isfinite', 'isfortran', 'isinf', 'isnan', 'isneginf', 'isposinf',
        'isreal', 'isrealobj', 'isscalar', 'issctype', 'issubclass_',
        'issubdtype', 'issubsctype', 'item', 'itemset', 'iterable', 'ix_',
        'kaiser', 'kron', 'ldexp', 'left_shift', 'less', 'less_equal', 'lexsort',
        'linspace', 'load', 'loads', 'loadtxt', 'log', 'log10', 'log1p', 'log2',
        'logical_and', 'logical_not', 'logical_or', 'logical_xor', 'logspace',
        'lstsq', 'mat', 'matrix', 'max', 'maximum', 'maximum_sctype',
        'may_share_memory', 'mean', 'median', 'meshgrid', 'mgrid', 'min',
        'minimum', 'mintypecode', 'mod', 'modf', 'msort', 'multiply', 'nan',
        'nan_to_num', 'nanargmax', 'nanargmin', 'nanmax', 'nanmin', 'nansum',
        'ndenumerate', 'ndim', 'ndindex', 'negative', 'newaxis', 'newbuffer',
        'newbyteorder', 'nonzero', 'not_equal', 'obj2sctype', 'ogrid', 'ones',
        'ones_like', 'outer', 'permutation', 'piecewise', 'pinv', 'pkgload',
        'place', 'poisson', 'poly', 'poly1d', 'polyadd', 'polyder', 'polydiv',
        'polyfit', 'polyint', 'polymul', 'polysub', 'polyval', 'power', 'prod',
        'product', 'ptp', 'put', 'putmask', 'r_', 'randint', 'random_integers',
        'random_sample', 'ranf', 'rank', 'ravel', 'real', 'real_if_close',
        'recarray', 'reciprocal', 'reduce', 'remainder', 'repeat', 'require',
        'reshape', 'resize', 'restoredot', 'right_shift', 'rint', 'roll',
        'rollaxis', 'roots', 'rot90', 'round', 'round_', 'row_stack', 's_',
        'sample', 'savetxt', 'sctype2char', 'searchsorted', 'seed', 'select',
        'set_numeric_ops', 'set_printoptions', 'set_string_function',
        'setbufsize', 'setdiff1d', 'seterr', 'seterrcall', 'seterrobj',
        'setfield', 'setflags', 'setmember1d', 'setxor1d', 'shape',
        'show_config', 'shuffle', 'sign', 'signbit', 'sin', 'sinc', 'sinh',
        'size', 'slice', 'solve', 'sometrue', 'sort', 'sort_complex', 'source',
        'split', 'sqrt', 'square', 'squeeze', 'standard_normal', 'std',
        'subtract', 'sum', 'svd', 'swapaxes', 'take', 'tan', 'tanh', 'tensordot',
        'test', 'tile', 'tofile', 'tolist', 'tostring', 'trace', 'transpose',
        'trapz', 'tri', 'tril', 'trim_zeros', 'triu', 'true_divide', 'typeDict',
        'typename', 'uniform', 'union1d', 'unique', 'unique1d', 'unravel_index',
        'unwrap', 'vander', 'var', 'vdot', 'vectorize', 'view', 'vonmises',
        'vsplit', 'vstack', 'weibull', 'where', 'who', 'zeros', 'zeros_like'
    }

    def get_tokens_unprocessed(self, text):
        for index, token, value in \
                PythonLexer.get_tokens_unprocessed(self, text):
            if token is Name and value in self.EXTRA_KEYWORDS:
                yield index, Keyword.Pseudo, value
            else:
                yield index, token, value

    def analyse_text(text):
        ltext = text[:1000]
        return (shebang_matches(text, r'pythonw?(3(\.\d)?)?') or
                'import ' in ltext) \
            and ('import numpy' in ltext or 'from numpy import' in ltext)




LEXERS = {
    'ABAPLexer': ('pip._vendor.pygments.lexers.business', 'ABAP', ('abap',), ('*.abap', '*.ABAP'), ('text/x-abap',)),
    'AMDGPULexer': ('pip._vendor.pygments.lexers.amdgpu', 'AMDGPU', ('amdgpu',), ('*.isa',), ()),
    'APLLexer': ('pip._vendor.pygments.lexers.apl', 'APL', ('apl',), ('*.apl', '*.aplf', '*.aplo', '*.apln', '*.aplc', '*.apli', '*.dyalog'), ()),
    'AbnfLexer': ('pip._vendor.pygments.lexers.grammar_notation', 'ABNF', ('abnf',), ('*.abnf',), ('text/x-abnf',)),
    'ActionScript3Lexer': ('pip._vendor.pygments.lexers.actionscript', 'ActionScript 3', ('actionscript3', 'as3'), ('*.as',), ('application/x-actionscript3', 'text/x-actionscript3', 'text/actionscript3')),
    'ActionScriptLexer': ('pip._vendor.pygments.lexers.actionscript', 'ActionScript', ('actionscript', 'as'), ('*.as',), ('application/x-actionscript', 'text/x-actionscript', 'text/actionscript')),
    'AdaLexer': ('pip._vendor.pygments.lexers.ada', 'Ada', ('ada', 'ada95', 'ada2005'), ('*.adb', '*.ads', '*.ada'), ('text/x-ada',)),
    'AdlLexer': ('pip._vendor.pygments.lexers.archetype', 'ADL', ('adl',), ('*.adl', '*.adls', '*.adlf', '*.adlx'), ()),
    'AgdaLexer': ('pip._vendor.pygments.lexers.haskell', 'Agda', ('agda',), ('*.agda',), ('text/x-agda',)),
    'AheuiLexer': ('pip._vendor.pygments.lexers.esoteric', 'Aheui', ('aheui',), ('*.aheui',), ()),
    'AlloyLexer': ('pip._vendor.pygments.lexers.dsls', 'Alloy', ('alloy',), ('*.als',), ('text/x-alloy',)),
    'AmbientTalkLexer': ('pip._vendor.pygments.lexers.ambient', 'AmbientTalk', ('ambienttalk', 'ambienttalk/2', 'at'), ('*.at',), ('text/x-ambienttalk',)),
    'AmplLexer': ('pip._vendor.pygments.lexers.ampl', 'Ampl', ('ampl',), ('*.run',), ()),
    'Angular2HtmlLexer': ('pip._vendor.pygments.lexers.templates', 'HTML + Angular2', ('html+ng2',), ('*.ng2',), ()),
    'Angular2Lexer': ('pip._vendor.pygments.lexers.templates', 'Angular2', ('ng2',), (), ()),
    'AntlrActionScriptLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR With ActionScript Target', ('antlr-actionscript', 'antlr-as'), ('*.G', '*.g'), ()),
    'AntlrCSharpLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR With C
    'AntlrCppLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR With CPP Target', ('antlr-cpp',), ('*.G', '*.g'), ()),
    'AntlrJavaLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR With Java Target', ('antlr-java',), ('*.G', '*.g'), ()),
    'AntlrLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR', ('antlr',), (), ()),
    'AntlrObjectiveCLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR With ObjectiveC Target', ('antlr-objc',), ('*.G', '*.g'), ()),
    'AntlrPerlLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR With Perl Target', ('antlr-perl',), ('*.G', '*.g'), ()),
    'AntlrPythonLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR With Python Target', ('antlr-python',), ('*.G', '*.g'), ()),
    'AntlrRubyLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR With Ruby Target', ('antlr-ruby', 'antlr-rb'), ('*.G', '*.g'), ()),
    'ApacheConfLexer': ('pip._vendor.pygments.lexers.configs', 'ApacheConf', ('apacheconf', 'aconf', 'apache'), ('.htaccess', 'apache.conf', 'apache2.conf'), ('text/x-apacheconf',)),
    'AppleScriptLexer': ('pip._vendor.pygments.lexers.scripting', 'AppleScript', ('applescript',), ('*.applescript',), ()),
    'ArduinoLexer': ('pip._vendor.pygments.lexers.c_like', 'Arduino', ('arduino',), ('*.ino',), ('text/x-arduino',)),
    'ArrowLexer': ('pip._vendor.pygments.lexers.arrow', 'Arrow', ('arrow',), ('*.arw',), ()),
    'ArturoLexer': ('pip._vendor.pygments.lexers.arturo', 'Arturo', ('arturo', 'art'), ('*.art',), ()),
    'AscLexer': ('pip._vendor.pygments.lexers.asc', 'ASCII armored', ('asc', 'pem'), ('*.asc', '*.pem', 'id_dsa', 'id_ecdsa', 'id_ecdsa_sk', 'id_ed25519', 'id_ed25519_sk', 'id_rsa'), ('application/pgp-keys', 'application/pgp-encrypted', 'application/pgp-signature', 'application/pem-certificate-chain')),
    'Asn1Lexer': ('pip._vendor.pygments.lexers.asn1', 'ASN.1', ('asn1',), ('*.asn1',), ()),
    'AspectJLexer': ('pip._vendor.pygments.lexers.jvm', 'AspectJ', ('aspectj',), ('*.aj',), ('text/x-aspectj',)),
    'AsymptoteLexer': ('pip._vendor.pygments.lexers.graphics', 'Asymptote', ('asymptote', 'asy'), ('*.asy',), ('text/x-asymptote',)),
    'AugeasLexer': ('pip._vendor.pygments.lexers.configs', 'Augeas', ('augeas',), ('*.aug',), ()),
    'AutoItLexer': ('pip._vendor.pygments.lexers.automation', 'AutoIt', ('autoit',), ('*.au3',), ('text/x-autoit',)),
    'AutohotkeyLexer': ('pip._vendor.pygments.lexers.automation', 'autohotkey', ('autohotkey', 'ahk'), ('*.ahk', '*.ahkl'), ('text/x-autohotkey',)),
    'AwkLexer': ('pip._vendor.pygments.lexers.textedit', 'Awk', ('awk', 'gawk', 'mawk', 'nawk'), ('*.awk',), ('application/x-awk',)),
    'BBCBasicLexer': ('pip._vendor.pygments.lexers.basic', 'BBC Basic', ('bbcbasic',), ('*.bbc',), ()),
    'BBCodeLexer': ('pip._vendor.pygments.lexers.markup', 'BBCode', ('bbcode',), (), ('text/x-bbcode',)),
    'BCLexer': ('pip._vendor.pygments.lexers.algebra', 'BC', ('bc',), ('*.bc',), ()),
    'BQNLexer': ('pip._vendor.pygments.lexers.bqn', 'BQN', ('bqn',), ('*.bqn',), ()),
    'BSTLexer': ('pip._vendor.pygments.lexers.bibtex', 'BST', ('bst', 'bst-pybtex'), ('*.bst',), ()),
    'BareLexer': ('pip._vendor.pygments.lexers.bare', 'BARE', ('bare',), ('*.bare',), ()),
    'BaseMakefileLexer': ('pip._vendor.pygments.lexers.make', 'Base Makefile', ('basemake',), (), ()),
    'BashLexer': ('pip._vendor.pygments.lexers.shell', 'Bash', ('bash', 'sh', 'ksh', 'zsh', 'shell', 'openrc'), ('*.sh', '*.ksh', '*.bash', '*.ebuild', '*.eclass', '*.exheres-0', '*.exlib', '*.zsh', '.bashrc', 'bashrc', '.bash_*', 'bash_*', 'zshrc', '.zshrc', '.kshrc', 'kshrc', 'PKGBUILD'), ('application/x-sh', 'application/x-shellscript', 'text/x-shellscript')),
    'BashSessionLexer': ('pip._vendor.pygments.lexers.shell', 'Bash Session', ('console', 'shell-session'), ('*.sh-session', '*.shell-session'), ('application/x-shell-session', 'application/x-sh-session')),
    'BatchLexer': ('pip._vendor.pygments.lexers.shell', 'Batchfile', ('batch', 'bat', 'dosbatch', 'winbatch'), ('*.bat', '*.cmd'), ('application/x-dos-batch',)),
    'BddLexer': ('pip._vendor.pygments.lexers.bdd', 'Bdd', ('bdd',), ('*.feature',), ('text/x-bdd',)),
    'BefungeLexer': ('pip._vendor.pygments.lexers.esoteric', 'Befunge', ('befunge',), ('*.befunge',), ('application/x-befunge',)),
    'BerryLexer': ('pip._vendor.pygments.lexers.berry', 'Berry', ('berry', 'be'), ('*.be',), ('text/x-berry', 'application/x-berry')),
    'BibTeXLexer': ('pip._vendor.pygments.lexers.bibtex', 'BibTeX', ('bibtex', 'bib'), ('*.bib',), ('text/x-bibtex',)),
    'BlitzBasicLexer': ('pip._vendor.pygments.lexers.basic', 'BlitzBasic', ('blitzbasic', 'b3d', 'bplus'), ('*.bb', '*.decls'), ('text/x-bb',)),
    'BlitzMaxLexer': ('pip._vendor.pygments.lexers.basic', 'BlitzMax', ('blitzmax', 'bmax'), ('*.bmx',), ('text/x-bmx',)),
    'BlueprintLexer': ('pip._vendor.pygments.lexers.blueprint', 'Blueprint', ('blueprint',), ('*.blp',), ('text/x-blueprint',)),
    'BnfLexer': ('pip._vendor.pygments.lexers.grammar_notation', 'BNF', ('bnf',), ('*.bnf',), ('text/x-bnf',)),
    'BoaLexer': ('pip._vendor.pygments.lexers.boa', 'Boa', ('boa',), ('*.boa',), ()),
    'BooLexer': ('pip._vendor.pygments.lexers.dotnet', 'Boo', ('boo',), ('*.boo',), ('text/x-boo',)),
    'BoogieLexer': ('pip._vendor.pygments.lexers.verification', 'Boogie', ('boogie',), ('*.bpl',), ()),
    'BrainfuckLexer': ('pip._vendor.pygments.lexers.esoteric', 'Brainfuck', ('brainfuck', 'bf'), ('*.bf', '*.b'), ('application/x-brainfuck',)),
    'BugsLexer': ('pip._vendor.pygments.lexers.modeling', 'BUGS', ('bugs', 'winbugs', 'openbugs'), ('*.bug',), ()),
    'CAmkESLexer': ('pip._vendor.pygments.lexers.esoteric', 'CAmkES', ('camkes', 'idl4'), ('*.camkes', '*.idl4'), ()),
    'CLexer': ('pip._vendor.pygments.lexers.c_cpp', 'C', ('c',), ('*.c', '*.h', '*.idc', '*.x[bp]m'), ('text/x-chdr', 'text/x-csrc', 'image/x-xbitmap', 'image/x-xpixmap')),
    'CMakeLexer': ('pip._vendor.pygments.lexers.make', 'CMake', ('cmake',), ('*.cmake', 'CMakeLists.txt'), ('text/x-cmake',)),
    'CObjdumpLexer': ('pip._vendor.pygments.lexers.asm', 'c-objdump', ('c-objdump',), ('*.c-objdump',), ('text/x-c-objdump',)),
    'CPSALexer': ('pip._vendor.pygments.lexers.lisp', 'CPSA', ('cpsa',), ('*.cpsa',), ()),
    'CSSUL4Lexer': ('pip._vendor.pygments.lexers.ul4', 'CSS+UL4', ('css+ul4',), ('*.cssul4',), ()),
    'CSharpAspxLexer': ('pip._vendor.pygments.lexers.dotnet', 'aspx-cs', ('aspx-cs',), ('*.aspx', '*.asax', '*.ascx', '*.ashx', '*.asmx', '*.axd'), ()),
    'CSharpLexer': ('pip._vendor.pygments.lexers.dotnet', 'C
    'Ca65Lexer': ('pip._vendor.pygments.lexers.asm', 'ca65 assembler', ('ca65',), ('*.s',), ()),
    'CadlLexer': ('pip._vendor.pygments.lexers.archetype', 'cADL', ('cadl',), ('*.cadl',), ()),
    'CapDLLexer': ('pip._vendor.pygments.lexers.esoteric', 'CapDL', ('capdl',), ('*.cdl',), ()),
    'CapnProtoLexer': ('pip._vendor.pygments.lexers.capnproto', ""Cap'n Proto"", ('capnp',), ('*.capnp',), ()),
    'CarbonLexer': ('pip._vendor.pygments.lexers.carbon', 'Carbon', ('carbon',), ('*.carbon',), ('text/x-carbon',)),
    'CbmBasicV2Lexer': ('pip._vendor.pygments.lexers.basic', 'CBM BASIC V2', ('cbmbas',), ('*.bas',), ()),
    'CddlLexer': ('pip._vendor.pygments.lexers.cddl', 'CDDL', ('cddl',), ('*.cddl',), ('text/x-cddl',)),
    'CeylonLexer': ('pip._vendor.pygments.lexers.jvm', 'Ceylon', ('ceylon',), ('*.ceylon',), ('text/x-ceylon',)),
    'Cfengine3Lexer': ('pip._vendor.pygments.lexers.configs', 'CFEngine3', ('cfengine3', 'cf3'), ('*.cf',), ()),
    'ChaiscriptLexer': ('pip._vendor.pygments.lexers.scripting', 'ChaiScript', ('chaiscript', 'chai'), ('*.chai',), ('text/x-chaiscript', 'application/x-chaiscript')),
    'ChapelLexer': ('pip._vendor.pygments.lexers.chapel', 'Chapel', ('chapel', 'chpl'), ('*.chpl',), ()),
    'CharmciLexer': ('pip._vendor.pygments.lexers.c_like', 'Charmci', ('charmci',), ('*.ci',), ()),
    'CheetahHtmlLexer': ('pip._vendor.pygments.lexers.templates', 'HTML+Cheetah', ('html+cheetah', 'html+spitfire', 'htmlcheetah'), (), ('text/html+cheetah', 'text/html+spitfire')),
    'CheetahJavascriptLexer': ('pip._vendor.pygments.lexers.templates', 'JavaScript+Cheetah', ('javascript+cheetah', 'js+cheetah', 'javascript+spitfire', 'js+spitfire'), (), ('application/x-javascript+cheetah', 'text/x-javascript+cheetah', 'text/javascript+cheetah', 'application/x-javascript+spitfire', 'text/x-javascript+spitfire', 'text/javascript+spitfire')),
    'CheetahLexer': ('pip._vendor.pygments.lexers.templates', 'Cheetah', ('cheetah', 'spitfire'), ('*.tmpl', '*.spt'), ('application/x-cheetah', 'application/x-spitfire')),
    'CheetahXmlLexer': ('pip._vendor.pygments.lexers.templates', 'XML+Cheetah', ('xml+cheetah', 'xml+spitfire'), (), ('application/xml+cheetah', 'application/xml+spitfire')),
    'CirruLexer': ('pip._vendor.pygments.lexers.webmisc', 'Cirru', ('cirru',), ('*.cirru',), ('text/x-cirru',)),
    'ClayLexer': ('pip._vendor.pygments.lexers.c_like', 'Clay', ('clay',), ('*.clay',), ('text/x-clay',)),
    'CleanLexer': ('pip._vendor.pygments.lexers.clean', 'Clean', ('clean',), ('*.icl', '*.dcl'), ()),
    'ClojureLexer': ('pip._vendor.pygments.lexers.jvm', 'Clojure', ('clojure', 'clj'), ('*.clj', '*.cljc'), ('text/x-clojure', 'application/x-clojure')),
    'ClojureScriptLexer': ('pip._vendor.pygments.lexers.jvm', 'ClojureScript', ('clojurescript', 'cljs'), ('*.cljs',), ('text/x-clojurescript', 'application/x-clojurescript')),
    'CobolFreeformatLexer': ('pip._vendor.pygments.lexers.business', 'COBOLFree', ('cobolfree',), ('*.cbl', '*.CBL'), ()),
    'CobolLexer': ('pip._vendor.pygments.lexers.business', 'COBOL', ('cobol',), ('*.cob', '*.COB', '*.cpy', '*.CPY'), ('text/x-cobol',)),
    'CodeQLLexer': ('pip._vendor.pygments.lexers.codeql', 'CodeQL', ('codeql', 'ql'), ('*.ql', '*.qll'), ()),
    'CoffeeScriptLexer': ('pip._vendor.pygments.lexers.javascript', 'CoffeeScript', ('coffeescript', 'coffee-script', 'coffee'), ('*.coffee',), ('text/coffeescript',)),
    'ColdfusionCFCLexer': ('pip._vendor.pygments.lexers.templates', 'Coldfusion CFC', ('cfc',), ('*.cfc',), ()),
    'ColdfusionHtmlLexer': ('pip._vendor.pygments.lexers.templates', 'Coldfusion HTML', ('cfm',), ('*.cfm', '*.cfml'), ('application/x-coldfusion',)),
    'ColdfusionLexer': ('pip._vendor.pygments.lexers.templates', 'cfstatement', ('cfs',), (), ()),
    'Comal80Lexer': ('pip._vendor.pygments.lexers.comal', 'COMAL-80', ('comal', 'comal80'), ('*.cml', '*.comal'), ()),
    'CommonLispLexer': ('pip._vendor.pygments.lexers.lisp', 'Common Lisp', ('common-lisp', 'cl', 'lisp'), ('*.cl', '*.lisp'), ('text/x-common-lisp',)),
    'ComponentPascalLexer': ('pip._vendor.pygments.lexers.oberon', 'Component Pascal', ('componentpascal', 'cp'), ('*.cp', '*.cps'), ('text/x-component-pascal',)),
    'CoqLexer': ('pip._vendor.pygments.lexers.theorem', 'Coq', ('coq',), ('*.v',), ('text/x-coq',)),
    'CplintLexer': ('pip._vendor.pygments.lexers.cplint', 'cplint', ('cplint',), ('*.ecl', '*.prolog', '*.pro', '*.pl', '*.P', '*.lpad', '*.cpl'), ('text/x-cplint',)),
    'CppLexer': ('pip._vendor.pygments.lexers.c_cpp', 'C++', ('cpp', 'c++'), ('*.cpp', '*.hpp', '*.c++', '*.h++', '*.cc', '*.hh', '*.cxx', '*.hxx', '*.C', '*.H', '*.cp', '*.CPP', '*.tpp'), ('text/x-c++hdr', 'text/x-c++src')),
    'CppObjdumpLexer': ('pip._vendor.pygments.lexers.asm', 'cpp-objdump', ('cpp-objdump', 'c++-objdumb', 'cxx-objdump'), ('*.cpp-objdump', '*.c++-objdump', '*.cxx-objdump'), ('text/x-cpp-objdump',)),
    'CrmshLexer': ('pip._vendor.pygments.lexers.dsls', 'Crmsh', ('crmsh', 'pcmk'), ('*.crmsh', '*.pcmk'), ()),
    'CrocLexer': ('pip._vendor.pygments.lexers.d', 'Croc', ('croc',), ('*.croc',), ('text/x-crocsrc',)),
    'CryptolLexer': ('pip._vendor.pygments.lexers.haskell', 'Cryptol', ('cryptol', 'cry'), ('*.cry',), ('text/x-cryptol',)),
    'CrystalLexer': ('pip._vendor.pygments.lexers.crystal', 'Crystal', ('cr', 'crystal'), ('*.cr',), ('text/x-crystal',)),
    'CsoundDocumentLexer': ('pip._vendor.pygments.lexers.csound', 'Csound Document', ('csound-document', 'csound-csd'), ('*.csd',), ()),
    'CsoundOrchestraLexer': ('pip._vendor.pygments.lexers.csound', 'Csound Orchestra', ('csound', 'csound-orc'), ('*.orc', '*.udo'), ()),
    'CsoundScoreLexer': ('pip._vendor.pygments.lexers.csound', 'Csound Score', ('csound-score', 'csound-sco'), ('*.sco',), ()),
    'CssDjangoLexer': ('pip._vendor.pygments.lexers.templates', 'CSS+Django/Jinja', ('css+django', 'css+jinja'), ('*.css.j2', '*.css.jinja2'), ('text/css+django', 'text/css+jinja')),
    'CssErbLexer': ('pip._vendor.pygments.lexers.templates', 'CSS+Ruby', ('css+ruby', 'css+erb'), (), ('text/css+ruby',)),
    'CssGenshiLexer': ('pip._vendor.pygments.lexers.templates', 'CSS+Genshi Text', ('css+genshitext', 'css+genshi'), (), ('text/css+genshi',)),
    'CssLexer': ('pip._vendor.pygments.lexers.css', 'CSS', ('css',), ('*.css',), ('text/css',)),
    'CssPhpLexer': ('pip._vendor.pygments.lexers.templates', 'CSS+PHP', ('css+php',), (), ('text/css+php',)),
    'CssSmartyLexer': ('pip._vendor.pygments.lexers.templates', 'CSS+Smarty', ('css+smarty',), (), ('text/css+smarty',)),
    'CudaLexer': ('pip._vendor.pygments.lexers.c_like', 'CUDA', ('cuda', 'cu'), ('*.cu', '*.cuh'), ('text/x-cuda',)),
    'CypherLexer': ('pip._vendor.pygments.lexers.graph', 'Cypher', ('cypher',), ('*.cyp', '*.cypher'), ()),
    'CythonLexer': ('pip._vendor.pygments.lexers.python', 'Cython', ('cython', 'pyx', 'pyrex'), ('*.pyx', '*.pxd', '*.pxi'), ('text/x-cython', 'application/x-cython')),
    'DLexer': ('pip._vendor.pygments.lexers.d', 'D', ('d',), ('*.d', '*.di'), ('text/x-dsrc',)),
    'DObjdumpLexer': ('pip._vendor.pygments.lexers.asm', 'd-objdump', ('d-objdump',), ('*.d-objdump',), ('text/x-d-objdump',)),
    'DarcsPatchLexer': ('pip._vendor.pygments.lexers.diff', 'Darcs Patch', ('dpatch',), ('*.dpatch', '*.darcspatch'), ()),
    'DartLexer': ('pip._vendor.pygments.lexers.javascript', 'Dart', ('dart',), ('*.dart',), ('text/x-dart',)),
    'Dasm16Lexer': ('pip._vendor.pygments.lexers.asm', 'DASM16', ('dasm16',), ('*.dasm16', '*.dasm'), ('text/x-dasm16',)),
    'DaxLexer': ('pip._vendor.pygments.lexers.dax', 'Dax', ('dax',), ('*.dax',), ()),
    'DebianControlLexer': ('pip._vendor.pygments.lexers.installers', 'Debian Control file', ('debcontrol', 'control'), ('control',), ()),
    'DebianSourcesLexer': ('pip._vendor.pygments.lexers.installers', 'Debian Sources file', ('debian.sources',), ('*.sources',), ()),
    'DelphiLexer': ('pip._vendor.pygments.lexers.pascal', 'Delphi', ('delphi', 'pas', 'pascal', 'objectpascal'), ('*.pas', '*.dpr'), ('text/x-pascal',)),
    'DesktopLexer': ('pip._vendor.pygments.lexers.configs', 'Desktop file', ('desktop',), ('*.desktop',), ('application/x-desktop',)),
    'DevicetreeLexer': ('pip._vendor.pygments.lexers.devicetree', 'Devicetree', ('devicetree', 'dts'), ('*.dts', '*.dtsi'), ('text/x-c',)),
    'DgLexer': ('pip._vendor.pygments.lexers.python', 'dg', ('dg',), ('*.dg',), ('text/x-dg',)),
    'DiffLexer': ('pip._vendor.pygments.lexers.diff', 'Diff', ('diff', 'udiff'), ('*.diff', '*.patch'), ('text/x-diff', 'text/x-patch')),
    'DjangoLexer': ('pip._vendor.pygments.lexers.templates', 'Django/Jinja', ('django', 'jinja'), (), ('application/x-django-templating', 'application/x-jinja')),
    'DnsZoneLexer': ('pip._vendor.pygments.lexers.dns', 'Zone', ('zone',), ('*.zone',), ('text/dns',)),
    'DockerLexer': ('pip._vendor.pygments.lexers.configs', 'Docker', ('docker', 'dockerfile'), ('Dockerfile', '*.docker'), ('text/x-dockerfile-config',)),
    'DtdLexer': ('pip._vendor.pygments.lexers.html', 'DTD', ('dtd',), ('*.dtd',), ('application/xml-dtd',)),
    'DuelLexer': ('pip._vendor.pygments.lexers.webmisc', 'Duel', ('duel', 'jbst', 'jsonml+bst'), ('*.duel', '*.jbst'), ('text/x-duel', 'text/x-jbst')),
    'DylanConsoleLexer': ('pip._vendor.pygments.lexers.dylan', 'Dylan session', ('dylan-console', 'dylan-repl'), ('*.dylan-console',), ('text/x-dylan-console',)),
    'DylanLexer': ('pip._vendor.pygments.lexers.dylan', 'Dylan', ('dylan',), ('*.dylan', '*.dyl', '*.intr'), ('text/x-dylan',)),
    'DylanLidLexer': ('pip._vendor.pygments.lexers.dylan', 'DylanLID', ('dylan-lid', 'lid'), ('*.lid', '*.hdp'), ('text/x-dylan-lid',)),
    'ECLLexer': ('pip._vendor.pygments.lexers.ecl', 'ECL', ('ecl',), ('*.ecl',), ('application/x-ecl',)),
    'ECLexer': ('pip._vendor.pygments.lexers.c_like', 'eC', ('ec',), ('*.ec', '*.eh'), ('text/x-echdr', 'text/x-ecsrc')),
    'EarlGreyLexer': ('pip._vendor.pygments.lexers.javascript', 'Earl Grey', ('earl-grey', 'earlgrey', 'eg'), ('*.eg',), ('text/x-earl-grey',)),
    'EasytrieveLexer': ('pip._vendor.pygments.lexers.scripting', 'Easytrieve', ('easytrieve',), ('*.ezt', '*.mac'), ('text/x-easytrieve',)),
    'EbnfLexer': ('pip._vendor.pygments.lexers.parsers', 'EBNF', ('ebnf',), ('*.ebnf',), ('text/x-ebnf',)),
    'EiffelLexer': ('pip._vendor.pygments.lexers.eiffel', 'Eiffel', ('eiffel',), ('*.e',), ('text/x-eiffel',)),
    'ElixirConsoleLexer': ('pip._vendor.pygments.lexers.erlang', 'Elixir iex session', ('iex',), (), ('text/x-elixir-shellsession',)),
    'ElixirLexer': ('pip._vendor.pygments.lexers.erlang', 'Elixir', ('elixir', 'ex', 'exs'), ('*.ex', '*.eex', '*.exs', '*.leex'), ('text/x-elixir',)),
    'ElmLexer': ('pip._vendor.pygments.lexers.elm', 'Elm', ('elm',), ('*.elm',), ('text/x-elm',)),
    'ElpiLexer': ('pip._vendor.pygments.lexers.elpi', 'Elpi', ('elpi',), ('*.elpi',), ('text/x-elpi',)),
    'EmacsLispLexer': ('pip._vendor.pygments.lexers.lisp', 'EmacsLisp', ('emacs-lisp', 'elisp', 'emacs'), ('*.el',), ('text/x-elisp', 'application/x-elisp')),
    'EmailLexer': ('pip._vendor.pygments.lexers.email', 'E-mail', ('email', 'eml'), ('*.eml',), ('message/rfc822',)),
    'ErbLexer': ('pip._vendor.pygments.lexers.templates', 'ERB', ('erb',), (), ('application/x-ruby-templating',)),
    'ErlangLexer': ('pip._vendor.pygments.lexers.erlang', 'Erlang', ('erlang',), ('*.erl', '*.hrl', '*.es', '*.escript'), ('text/x-erlang',)),
    'ErlangShellLexer': ('pip._vendor.pygments.lexers.erlang', 'Erlang erl session', ('erl',), ('*.erl-sh',), ('text/x-erl-shellsession',)),
    'EvoqueHtmlLexer': ('pip._vendor.pygments.lexers.templates', 'HTML+Evoque', ('html+evoque',), (), ('text/html+evoque',)),
    'EvoqueLexer': ('pip._vendor.pygments.lexers.templates', 'Evoque', ('evoque',), ('*.evoque',), ('application/x-evoque',)),
    'EvoqueXmlLexer': ('pip._vendor.pygments.lexers.templates', 'XML+Evoque', ('xml+evoque',), (), ('application/xml+evoque',)),
    'ExeclineLexer': ('pip._vendor.pygments.lexers.shell', 'execline', ('execline',), ('*.exec',), ()),
    'EzhilLexer': ('pip._vendor.pygments.lexers.ezhil', 'Ezhil', ('ezhil',), ('*.n',), ('text/x-ezhil',)),
    'FSharpLexer': ('pip._vendor.pygments.lexers.dotnet', 'F
    'FStarLexer': ('pip._vendor.pygments.lexers.ml', 'FStar', ('fstar',), ('*.fst', '*.fsti'), ('text/x-fstar',)),
    'FactorLexer': ('pip._vendor.pygments.lexers.factor', 'Factor', ('factor',), ('*.factor',), ('text/x-factor',)),
    'FancyLexer': ('pip._vendor.pygments.lexers.ruby', 'Fancy', ('fancy', 'fy'), ('*.fy', '*.fancypack'), ('text/x-fancysrc',)),
    'FantomLexer': ('pip._vendor.pygments.lexers.fantom', 'Fantom', ('fan',), ('*.fan',), ('application/x-fantom',)),
    'FelixLexer': ('pip._vendor.pygments.lexers.felix', 'Felix', ('felix', 'flx'), ('*.flx', '*.flxh'), ('text/x-felix',)),
    'FennelLexer': ('pip._vendor.pygments.lexers.lisp', 'Fennel', ('fennel', 'fnl'), ('*.fnl',), ()),
    'FiftLexer': ('pip._vendor.pygments.lexers.fift', 'Fift', ('fift', 'fif'), ('*.fif',), ()),
    'FishShellLexer': ('pip._vendor.pygments.lexers.shell', 'Fish', ('fish', 'fishshell'), ('*.fish', '*.load'), ('application/x-fish',)),
    'FlatlineLexer': ('pip._vendor.pygments.lexers.dsls', 'Flatline', ('flatline',), (), ('text/x-flatline',)),
    'FloScriptLexer': ('pip._vendor.pygments.lexers.floscript', 'FloScript', ('floscript', 'flo'), ('*.flo',), ()),
    'ForthLexer': ('pip._vendor.pygments.lexers.forth', 'Forth', ('forth',), ('*.frt', '*.fs'), ('application/x-forth',)),
    'FortranFixedLexer': ('pip._vendor.pygments.lexers.fortran', 'FortranFixed', ('fortranfixed',), ('*.f', '*.F'), ()),
    'FortranLexer': ('pip._vendor.pygments.lexers.fortran', 'Fortran', ('fortran', 'f90'), ('*.f03', '*.f90', '*.F03', '*.F90'), ('text/x-fortran',)),
    'FoxProLexer': ('pip._vendor.pygments.lexers.foxpro', 'FoxPro', ('foxpro', 'vfp', 'clipper', 'xbase'), ('*.PRG', '*.prg'), ()),
    'FreeFemLexer': ('pip._vendor.pygments.lexers.freefem', 'Freefem', ('freefem',), ('*.edp',), ('text/x-freefem',)),
    'FuncLexer': ('pip._vendor.pygments.lexers.func', 'FunC', ('func', 'fc'), ('*.fc', '*.func'), ()),
    'FutharkLexer': ('pip._vendor.pygments.lexers.futhark', 'Futhark', ('futhark',), ('*.fut',), ('text/x-futhark',)),
    'GAPConsoleLexer': ('pip._vendor.pygments.lexers.algebra', 'GAP session', ('gap-console', 'gap-repl'), ('*.tst',), ()),
    'GAPLexer': ('pip._vendor.pygments.lexers.algebra', 'GAP', ('gap',), ('*.g', '*.gd', '*.gi', '*.gap'), ()),
    'GDScriptLexer': ('pip._vendor.pygments.lexers.gdscript', 'GDScript', ('gdscript', 'gd'), ('*.gd',), ('text/x-gdscript', 'application/x-gdscript')),
    'GLShaderLexer': ('pip._vendor.pygments.lexers.graphics', 'GLSL', ('glsl',), ('*.vert', '*.frag', '*.geo'), ('text/x-glslsrc',)),
    'GSQLLexer': ('pip._vendor.pygments.lexers.gsql', 'GSQL', ('gsql',), ('*.gsql',), ()),
    'GasLexer': ('pip._vendor.pygments.lexers.asm', 'GAS', ('gas', 'asm'), ('*.s', '*.S'), ('text/x-gas',)),
    'GcodeLexer': ('pip._vendor.pygments.lexers.gcodelexer', 'g-code', ('gcode',), ('*.gcode',), ()),
    'GenshiLexer': ('pip._vendor.pygments.lexers.templates', 'Genshi', ('genshi', 'kid', 'xml+genshi', 'xml+kid'), ('*.kid',), ('application/x-genshi', 'application/x-kid')),
    'GenshiTextLexer': ('pip._vendor.pygments.lexers.templates', 'Genshi Text', ('genshitext',), (), ('application/x-genshi-text', 'text/x-genshi')),
    'GettextLexer': ('pip._vendor.pygments.lexers.textfmts', 'Gettext Catalog', ('pot', 'po'), ('*.pot', '*.po'), ('application/x-gettext', 'text/x-gettext', 'text/gettext')),
    'GherkinLexer': ('pip._vendor.pygments.lexers.testing', 'Gherkin', ('gherkin', 'cucumber'), ('*.feature',), ('text/x-gherkin',)),
    'GleamLexer': ('pip._vendor.pygments.lexers.gleam', 'Gleam', ('gleam',), ('*.gleam',), ('text/x-gleam',)),
    'GnuplotLexer': ('pip._vendor.pygments.lexers.graphics', 'Gnuplot', ('gnuplot',), ('*.plot', '*.plt'), ('text/x-gnuplot',)),
    'GoLexer': ('pip._vendor.pygments.lexers.go', 'Go', ('go', 'golang'), ('*.go',), ('text/x-gosrc',)),
    'GoloLexer': ('pip._vendor.pygments.lexers.jvm', 'Golo', ('golo',), ('*.golo',), ()),
    'GoodDataCLLexer': ('pip._vendor.pygments.lexers.business', 'GoodData-CL', ('gooddata-cl',), ('*.gdc',), ('text/x-gooddata-cl',)),
    'GoogleSqlLexer': ('pip._vendor.pygments.lexers.sql', 'GoogleSQL', ('googlesql', 'zetasql'), ('*.googlesql', '*.googlesql.sql'), ('text/x-google-sql', 'text/x-google-sql-aux')),
    'GosuLexer': ('pip._vendor.pygments.lexers.jvm', 'Gosu', ('gosu',), ('*.gs', '*.gsx', '*.gsp', '*.vark'), ('text/x-gosu',)),
    'GosuTemplateLexer': ('pip._vendor.pygments.lexers.jvm', 'Gosu Template', ('gst',), ('*.gst',), ('text/x-gosu-template',)),
    'GraphQLLexer': ('pip._vendor.pygments.lexers.graphql', 'GraphQL', ('graphql',), ('*.graphql',), ()),
    'GraphvizLexer': ('pip._vendor.pygments.lexers.graphviz', 'Graphviz', ('graphviz', 'dot'), ('*.gv', '*.dot'), ('text/x-graphviz', 'text/vnd.graphviz')),
    'GroffLexer': ('pip._vendor.pygments.lexers.markup', 'Groff', ('groff', 'nroff', 'man'), ('*.[1-9]', '*.man', '*.1p', '*.3pm'), ('application/x-troff', 'text/troff')),
    'GroovyLexer': ('pip._vendor.pygments.lexers.jvm', 'Groovy', ('groovy',), ('*.groovy', '*.gradle'), ('text/x-groovy',)),
    'HLSLShaderLexer': ('pip._vendor.pygments.lexers.graphics', 'HLSL', ('hlsl',), ('*.hlsl', '*.hlsli'), ('text/x-hlsl',)),
    'HTMLUL4Lexer': ('pip._vendor.pygments.lexers.ul4', 'HTML+UL4', ('html+ul4',), ('*.htmlul4',), ()),
    'HamlLexer': ('pip._vendor.pygments.lexers.html', 'Haml', ('haml',), ('*.haml',), ('text/x-haml',)),
    'HandlebarsHtmlLexer': ('pip._vendor.pygments.lexers.templates', 'HTML+Handlebars', ('html+handlebars',), ('*.handlebars', '*.hbs'), ('text/html+handlebars', 'text/x-handlebars-template')),
    'HandlebarsLexer': ('pip._vendor.pygments.lexers.templates', 'Handlebars', ('handlebars',), (), ()),
    'HareLexer': ('pip._vendor.pygments.lexers.hare', 'Hare', ('hare',), ('*.ha',), ('text/x-hare',)),
    'HaskellLexer': ('pip._vendor.pygments.lexers.haskell', 'Haskell', ('haskell', 'hs'), ('*.hs',), ('text/x-haskell',)),
    'HaxeLexer': ('pip._vendor.pygments.lexers.haxe', 'Haxe', ('haxe', 'hxsl', 'hx'), ('*.hx', '*.hxsl'), ('text/haxe', 'text/x-haxe', 'text/x-hx')),
    'HexdumpLexer': ('pip._vendor.pygments.lexers.hexdump', 'Hexdump', ('hexdump',), (), ()),
    'HsailLexer': ('pip._vendor.pygments.lexers.asm', 'HSAIL', ('hsail', 'hsa'), ('*.hsail',), ('text/x-hsail',)),
    'HspecLexer': ('pip._vendor.pygments.lexers.haskell', 'Hspec', ('hspec',), ('*Spec.hs',), ()),
    'HtmlDjangoLexer': ('pip._vendor.pygments.lexers.templates', 'HTML+Django/Jinja', ('html+django', 'html+jinja', 'htmldjango'), ('*.html.j2', '*.htm.j2', '*.xhtml.j2', '*.html.jinja2', '*.htm.jinja2', '*.xhtml.jinja2'), ('text/html+django', 'text/html+jinja')),
    'HtmlGenshiLexer': ('pip._vendor.pygments.lexers.templates', 'HTML+Genshi', ('html+genshi', 'html+kid'), (), ('text/html+genshi',)),
    'HtmlLexer': ('pip._vendor.pygments.lexers.html', 'HTML', ('html',), ('*.html', '*.htm', '*.xhtml', '*.xslt'), ('text/html', 'application/xhtml+xml')),
    'HtmlPhpLexer': ('pip._vendor.pygments.lexers.templates', 'HTML+PHP', ('html+php',), ('*.phtml',), ('application/x-php', 'application/x-httpd-php', 'application/x-httpd-php3', 'application/x-httpd-php4', 'application/x-httpd-php5')),
    'HtmlSmartyLexer': ('pip._vendor.pygments.lexers.templates', 'HTML+Smarty', ('html+smarty',), (), ('text/html+smarty',)),
    'HttpLexer': ('pip._vendor.pygments.lexers.textfmts', 'HTTP', ('http',), (), ()),
    'HxmlLexer': ('pip._vendor.pygments.lexers.haxe', 'Hxml', ('haxeml', 'hxml'), ('*.hxml',), ()),
    'HyLexer': ('pip._vendor.pygments.lexers.lisp', 'Hy', ('hylang', 'hy'), ('*.hy',), ('text/x-hy', 'application/x-hy')),
    'HybrisLexer': ('pip._vendor.pygments.lexers.scripting', 'Hybris', ('hybris',), ('*.hyb',), ('text/x-hybris', 'application/x-hybris')),
    'IDLLexer': ('pip._vendor.pygments.lexers.idl', 'IDL', ('idl',), ('*.pro',), ('text/idl',)),
    'IconLexer': ('pip._vendor.pygments.lexers.unicon', 'Icon', ('icon',), ('*.icon', '*.ICON'), ()),
    'IdrisLexer': ('pip._vendor.pygments.lexers.haskell', 'Idris', ('idris', 'idr'), ('*.idr',), ('text/x-idris',)),
    'IgorLexer': ('pip._vendor.pygments.lexers.igor', 'Igor', ('igor', 'igorpro'), ('*.ipf',), ('text/ipf',)),
    'Inform6Lexer': ('pip._vendor.pygments.lexers.int_fiction', 'Inform 6', ('inform6', 'i6'), ('*.inf',), ()),
    'Inform6TemplateLexer': ('pip._vendor.pygments.lexers.int_fiction', 'Inform 6 template', ('i6t',), ('*.i6t',), ()),
    'Inform7Lexer': ('pip._vendor.pygments.lexers.int_fiction', 'Inform 7', ('inform7', 'i7'), ('*.ni', '*.i7x'), ()),
    'IniLexer': ('pip._vendor.pygments.lexers.configs', 'INI', ('ini', 'cfg', 'dosini'), ('*.ini', '*.cfg', '*.inf', '.editorconfig'), ('text/x-ini', 'text/inf')),
    'IoLexer': ('pip._vendor.pygments.lexers.iolang', 'Io', ('io',), ('*.io',), ('text/x-iosrc',)),
    'IokeLexer': ('pip._vendor.pygments.lexers.jvm', 'Ioke', ('ioke', 'ik'), ('*.ik',), ('text/x-iokesrc',)),
    'IrcLogsLexer': ('pip._vendor.pygments.lexers.textfmts', 'IRC logs', ('irc',), ('*.weechatlog',), ('text/x-irclog',)),
    'IsabelleLexer': ('pip._vendor.pygments.lexers.theorem', 'Isabelle', ('isabelle',), ('*.thy',), ('text/x-isabelle',)),
    'JLexer': ('pip._vendor.pygments.lexers.j', 'J', ('j',), ('*.ijs',), ('text/x-j',)),
    'JMESPathLexer': ('pip._vendor.pygments.lexers.jmespath', 'JMESPath', ('jmespath', 'jp'), ('*.jp',), ()),
    'JSLTLexer': ('pip._vendor.pygments.lexers.jslt', 'JSLT', ('jslt',), ('*.jslt',), ('text/x-jslt',)),
    'JagsLexer': ('pip._vendor.pygments.lexers.modeling', 'JAGS', ('jags',), ('*.jag', '*.bug'), ()),
    'JanetLexer': ('pip._vendor.pygments.lexers.lisp', 'Janet', ('janet',), ('*.janet', '*.jdn'), ('text/x-janet', 'application/x-janet')),
    'JasminLexer': ('pip._vendor.pygments.lexers.jvm', 'Jasmin', ('jasmin', 'jasminxt'), ('*.j',), ()),
    'JavaLexer': ('pip._vendor.pygments.lexers.jvm', 'Java', ('java',), ('*.java',), ('text/x-java',)),
    'JavascriptDjangoLexer': ('pip._vendor.pygments.lexers.templates', 'JavaScript+Django/Jinja', ('javascript+django', 'js+django', 'javascript+jinja', 'js+jinja'), ('*.js.j2', '*.js.jinja2'), ('application/x-javascript+django', 'application/x-javascript+jinja', 'text/x-javascript+django', 'text/x-javascript+jinja', 'text/javascript+django', 'text/javascript+jinja')),
    'JavascriptErbLexer': ('pip._vendor.pygments.lexers.templates', 'JavaScript+Ruby', ('javascript+ruby', 'js+ruby', 'javascript+erb', 'js+erb'), (), ('application/x-javascript+ruby', 'text/x-javascript+ruby', 'text/javascript+ruby')),
    'JavascriptGenshiLexer': ('pip._vendor.pygments.lexers.templates', 'JavaScript+Genshi Text', ('js+genshitext', 'js+genshi', 'javascript+genshitext', 'javascript+genshi'), (), ('application/x-javascript+genshi', 'text/x-javascript+genshi', 'text/javascript+genshi')),
    'JavascriptLexer': ('pip._vendor.pygments.lexers.javascript', 'JavaScript', ('javascript', 'js'), ('*.js', '*.jsm', '*.mjs', '*.cjs'), ('application/javascript', 'application/x-javascript', 'text/x-javascript', 'text/javascript')),
    'JavascriptPhpLexer': ('pip._vendor.pygments.lexers.templates', 'JavaScript+PHP', ('javascript+php', 'js+php'), (), ('application/x-javascript+php', 'text/x-javascript+php', 'text/javascript+php')),
    'JavascriptSmartyLexer': ('pip._vendor.pygments.lexers.templates', 'JavaScript+Smarty', ('javascript+smarty', 'js+smarty'), (), ('application/x-javascript+smarty', 'text/x-javascript+smarty', 'text/javascript+smarty')),
    'JavascriptUL4Lexer': ('pip._vendor.pygments.lexers.ul4', 'Javascript+UL4', ('js+ul4',), ('*.jsul4',), ()),
    'JclLexer': ('pip._vendor.pygments.lexers.scripting', 'JCL', ('jcl',), ('*.jcl',), ('text/x-jcl',)),
    'JsgfLexer': ('pip._vendor.pygments.lexers.grammar_notation', 'JSGF', ('jsgf',), ('*.jsgf',), ('application/jsgf', 'application/x-jsgf', 'text/jsgf')),
    'Json5Lexer': ('pip._vendor.pygments.lexers.json5', 'JSON5', ('json5',), ('*.json5',), ()),
    'JsonBareObjectLexer': ('pip._vendor.pygments.lexers.data', 'JSONBareObject', (), (), ()),
    'JsonLdLexer': ('pip._vendor.pygments.lexers.data', 'JSON-LD', ('jsonld', 'json-ld'), ('*.jsonld',), ('application/ld+json',)),
    'JsonLexer': ('pip._vendor.pygments.lexers.data', 'JSON', ('json', 'json-object'), ('*.json', '*.jsonl', '*.ndjson', 'Pipfile.lock'), ('application/json', 'application/json-object', 'application/x-ndjson', 'application/jsonl', 'application/json-seq')),
    'JsonnetLexer': ('pip._vendor.pygments.lexers.jsonnet', 'Jsonnet', ('jsonnet',), ('*.jsonnet', '*.libsonnet'), ()),
    'JspLexer': ('pip._vendor.pygments.lexers.templates', 'Java Server Page', ('jsp',), ('*.jsp',), ('application/x-jsp',)),
    'JsxLexer': ('pip._vendor.pygments.lexers.jsx', 'JSX', ('jsx', 'react'), ('*.jsx', '*.react'), ('text/jsx', 'text/typescript-jsx')),
    'JuliaConsoleLexer': ('pip._vendor.pygments.lexers.julia', 'Julia console', ('jlcon', 'julia-repl'), (), ()),
    'JuliaLexer': ('pip._vendor.pygments.lexers.julia', 'Julia', ('julia', 'jl'), ('*.jl',), ('text/x-julia', 'application/x-julia')),
    'JuttleLexer': ('pip._vendor.pygments.lexers.javascript', 'Juttle', ('juttle',), ('*.juttle',), ('application/juttle', 'application/x-juttle', 'text/x-juttle', 'text/juttle')),
    'KLexer': ('pip._vendor.pygments.lexers.q', 'K', ('k',), ('*.k',), ()),
    'KalLexer': ('pip._vendor.pygments.lexers.javascript', 'Kal', ('kal',), ('*.kal',), ('text/kal', 'application/kal')),
    'KconfigLexer': ('pip._vendor.pygments.lexers.configs', 'Kconfig', ('kconfig', 'menuconfig', 'linux-config', 'kernel-config'), ('Kconfig*', '*Config.in*', 'external.in*', 'standard-modules.in'), ('text/x-kconfig',)),
    'KernelLogLexer': ('pip._vendor.pygments.lexers.textfmts', 'Kernel log', ('kmsg', 'dmesg'), ('*.kmsg', '*.dmesg'), ()),
    'KokaLexer': ('pip._vendor.pygments.lexers.haskell', 'Koka', ('koka',), ('*.kk', '*.kki'), ('text/x-koka',)),
    'KotlinLexer': ('pip._vendor.pygments.lexers.jvm', 'Kotlin', ('kotlin',), ('*.kt', '*.kts'), ('text/x-kotlin',)),
    'KuinLexer': ('pip._vendor.pygments.lexers.kuin', 'Kuin', ('kuin',), ('*.kn',), ()),
    'KustoLexer': ('pip._vendor.pygments.lexers.kusto', 'Kusto', ('kql', 'kusto'), ('*.kql', '*.kusto', '.csl'), ()),
    'LSLLexer': ('pip._vendor.pygments.lexers.scripting', 'LSL', ('lsl',), ('*.lsl',), ('text/x-lsl',)),
    'LassoCssLexer': ('pip._vendor.pygments.lexers.templates', 'CSS+Lasso', ('css+lasso',), (), ('text/css+lasso',)),
    'LassoHtmlLexer': ('pip._vendor.pygments.lexers.templates', 'HTML+Lasso', ('html+lasso',), (), ('text/html+lasso', 'application/x-httpd-lasso', 'application/x-httpd-lasso[89]')),
    'LassoJavascriptLexer': ('pip._vendor.pygments.lexers.templates', 'JavaScript+Lasso', ('javascript+lasso', 'js+lasso'), (), ('application/x-javascript+lasso', 'text/x-javascript+lasso', 'text/javascript+lasso')),
    'LassoLexer': ('pip._vendor.pygments.lexers.javascript', 'Lasso', ('lasso', 'lassoscript'), ('*.lasso', '*.lasso[89]'), ('text/x-lasso',)),
    'LassoXmlLexer': ('pip._vendor.pygments.lexers.templates', 'XML+Lasso', ('xml+lasso',), (), ('application/xml+lasso',)),
    'LdaprcLexer': ('pip._vendor.pygments.lexers.ldap', 'LDAP configuration file', ('ldapconf', 'ldaprc'), ('.ldaprc', 'ldaprc', 'ldap.conf'), ('text/x-ldapconf',)),
    'LdifLexer': ('pip._vendor.pygments.lexers.ldap', 'LDIF', ('ldif',), ('*.ldif',), ('text/x-ldif',)),
    'Lean3Lexer': ('pip._vendor.pygments.lexers.lean', 'Lean', ('lean', 'lean3'), ('*.lean',), ('text/x-lean', 'text/x-lean3')),
    'Lean4Lexer': ('pip._vendor.pygments.lexers.lean', 'Lean4', ('lean4',), ('*.lean',), ('text/x-lean4',)),
    'LessCssLexer': ('pip._vendor.pygments.lexers.css', 'LessCss', ('less',), ('*.less',), ('text/x-less-css',)),
    'LighttpdConfLexer': ('pip._vendor.pygments.lexers.configs', 'Lighttpd configuration file', ('lighttpd', 'lighty'), ('lighttpd.conf',), ('text/x-lighttpd-conf',)),
    'LilyPondLexer': ('pip._vendor.pygments.lexers.lilypond', 'LilyPond', ('lilypond',), ('*.ly',), ()),
    'LimboLexer': ('pip._vendor.pygments.lexers.inferno', 'Limbo', ('limbo',), ('*.b',), ('text/limbo',)),
    'LiquidLexer': ('pip._vendor.pygments.lexers.templates', 'liquid', ('liquid',), ('*.liquid',), ()),
    'LiterateAgdaLexer': ('pip._vendor.pygments.lexers.haskell', 'Literate Agda', ('literate-agda', 'lagda'), ('*.lagda',), ('text/x-literate-agda',)),
    'LiterateCryptolLexer': ('pip._vendor.pygments.lexers.haskell', 'Literate Cryptol', ('literate-cryptol', 'lcryptol', 'lcry'), ('*.lcry',), ('text/x-literate-cryptol',)),
    'LiterateHaskellLexer': ('pip._vendor.pygments.lexers.haskell', 'Literate Haskell', ('literate-haskell', 'lhaskell', 'lhs'), ('*.lhs',), ('text/x-literate-haskell',)),
    'LiterateIdrisLexer': ('pip._vendor.pygments.lexers.haskell', 'Literate Idris', ('literate-idris', 'lidris', 'lidr'), ('*.lidr',), ('text/x-literate-idris',)),
    'LiveScriptLexer': ('pip._vendor.pygments.lexers.javascript', 'LiveScript', ('livescript', 'live-script'), ('*.ls',), ('text/livescript',)),
    'LlvmLexer': ('pip._vendor.pygments.lexers.asm', 'LLVM', ('llvm',), ('*.ll',), ('text/x-llvm',)),
    'LlvmMirBodyLexer': ('pip._vendor.pygments.lexers.asm', 'LLVM-MIR Body', ('llvm-mir-body',), (), ()),
    'LlvmMirLexer': ('pip._vendor.pygments.lexers.asm', 'LLVM-MIR', ('llvm-mir',), ('*.mir',), ()),
    'LogosLexer': ('pip._vendor.pygments.lexers.objective', 'Logos', ('logos',), ('*.x', '*.xi', '*.xm', '*.xmi'), ('text/x-logos',)),
    'LogtalkLexer': ('pip._vendor.pygments.lexers.prolog', 'Logtalk', ('logtalk',), ('*.lgt', '*.logtalk'), ('text/x-logtalk',)),
    'LuaLexer': ('pip._vendor.pygments.lexers.scripting', 'Lua', ('lua',), ('*.lua', '*.wlua'), ('text/x-lua', 'application/x-lua')),
    'LuauLexer': ('pip._vendor.pygments.lexers.scripting', 'Luau', ('luau',), ('*.luau',), ()),
    'MCFunctionLexer': ('pip._vendor.pygments.lexers.minecraft', 'MCFunction', ('mcfunction', 'mcf'), ('*.mcfunction',), ('text/mcfunction',)),
    'MCSchemaLexer': ('pip._vendor.pygments.lexers.minecraft', 'MCSchema', ('mcschema',), ('*.mcschema',), ('text/mcschema',)),
    'MIMELexer': ('pip._vendor.pygments.lexers.mime', 'MIME', ('mime',), (), ('multipart/mixed', 'multipart/related', 'multipart/alternative')),
    'MIPSLexer': ('pip._vendor.pygments.lexers.mips', 'MIPS', ('mips',), ('*.mips', '*.MIPS'), ()),
    'MOOCodeLexer': ('pip._vendor.pygments.lexers.scripting', 'MOOCode', ('moocode', 'moo'), ('*.moo',), ('text/x-moocode',)),
    'MSDOSSessionLexer': ('pip._vendor.pygments.lexers.shell', 'MSDOS Session', ('doscon',), (), ()),
    'Macaulay2Lexer': ('pip._vendor.pygments.lexers.macaulay2', 'Macaulay2', ('macaulay2',), ('*.m2',), ()),
    'MakefileLexer': ('pip._vendor.pygments.lexers.make', 'Makefile', ('make', 'makefile', 'mf', 'bsdmake'), ('*.mak', '*.mk', 'Makefile', 'makefile', 'Makefile.*', 'GNUmakefile'), ('text/x-makefile',)),
    'MakoCssLexer': ('pip._vendor.pygments.lexers.templates', 'CSS+Mako', ('css+mako',), (), ('text/css+mako',)),
    'MakoHtmlLexer': ('pip._vendor.pygments.lexers.templates', 'HTML+Mako', ('html+mako',), (), ('text/html+mako',)),
    'MakoJavascriptLexer': ('pip._vendor.pygments.lexers.templates', 'JavaScript+Mako', ('javascript+mako', 'js+mako'), (), ('application/x-javascript+mako', 'text/x-javascript+mako', 'text/javascript+mako')),
    'MakoLexer': ('pip._vendor.pygments.lexers.templates', 'Mako', ('mako',), ('*.mao',), ('application/x-mako',)),
    'MakoXmlLexer': ('pip._vendor.pygments.lexers.templates', 'XML+Mako', ('xml+mako',), (), ('application/xml+mako',)),
    'MapleLexer': ('pip._vendor.pygments.lexers.maple', 'Maple', ('maple',), ('*.mpl', '*.mi', '*.mm'), ('text/x-maple',)),
    'MaqlLexer': ('pip._vendor.pygments.lexers.business', 'MAQL', ('maql',), ('*.maql',), ('text/x-gooddata-maql', 'application/x-gooddata-maql')),
    'MarkdownLexer': ('pip._vendor.pygments.lexers.markup', 'Markdown', ('markdown', 'md'), ('*.md', '*.markdown'), ('text/x-markdown',)),
    'MaskLexer': ('pip._vendor.pygments.lexers.javascript', 'Mask', ('mask',), ('*.mask',), ('text/x-mask',)),
    'MasonLexer': ('pip._vendor.pygments.lexers.templates', 'Mason', ('mason',), ('*.m', '*.mhtml', '*.mc', '*.mi', 'autohandler', 'dhandler'), ('application/x-mason',)),
    'MathematicaLexer': ('pip._vendor.pygments.lexers.algebra', 'Mathematica', ('mathematica', 'mma', 'nb'), ('*.nb', '*.cdf', '*.nbp', '*.ma'), ('application/mathematica', 'application/vnd.wolfram.mathematica', 'application/vnd.wolfram.mathematica.package', 'application/vnd.wolfram.cdf')),
    'MatlabLexer': ('pip._vendor.pygments.lexers.matlab', 'Matlab', ('matlab',), ('*.m',), ('text/matlab',)),
    'MatlabSessionLexer': ('pip._vendor.pygments.lexers.matlab', 'Matlab session', ('matlabsession',), (), ()),
    'MaximaLexer': ('pip._vendor.pygments.lexers.maxima', 'Maxima', ('maxima', 'macsyma'), ('*.mac', '*.max'), ()),
    'MesonLexer': ('pip._vendor.pygments.lexers.meson', 'Meson', ('meson', 'meson.build'), ('meson.build', 'meson_options.txt'), ('text/x-meson',)),
    'MiniDLexer': ('pip._vendor.pygments.lexers.d', 'MiniD', ('minid',), (), ('text/x-minidsrc',)),
    'MiniScriptLexer': ('pip._vendor.pygments.lexers.scripting', 'MiniScript', ('miniscript', 'ms'), ('*.ms',), ('text/x-minicript', 'application/x-miniscript')),
    'ModelicaLexer': ('pip._vendor.pygments.lexers.modeling', 'Modelica', ('modelica',), ('*.mo',), ('text/x-modelica',)),
    'Modula2Lexer': ('pip._vendor.pygments.lexers.modula2', 'Modula-2', ('modula2', 'm2'), ('*.def', '*.mod'), ('text/x-modula2',)),
    'MoinWikiLexer': ('pip._vendor.pygments.lexers.markup', 'MoinMoin/Trac Wiki markup', ('trac-wiki', 'moin'), (), ('text/x-trac-wiki',)),
    'MojoLexer': ('pip._vendor.pygments.lexers.mojo', 'Mojo', ('mojo', '🔥'), ('*.mojo', '*.🔥'), ('text/x-mojo', 'application/x-mojo')),
    'MonkeyLexer': ('pip._vendor.pygments.lexers.basic', 'Monkey', ('monkey',), ('*.monkey',), ('text/x-monkey',)),
    'MonteLexer': ('pip._vendor.pygments.lexers.monte', 'Monte', ('monte',), ('*.mt',), ()),
    'MoonScriptLexer': ('pip._vendor.pygments.lexers.scripting', 'MoonScript', ('moonscript', 'moon'), ('*.moon',), ('text/x-moonscript', 'application/x-moonscript')),
    'MoselLexer': ('pip._vendor.pygments.lexers.mosel', 'Mosel', ('mosel',), ('*.mos',), ()),
    'MozPreprocCssLexer': ('pip._vendor.pygments.lexers.markup', 'CSS+mozpreproc', ('css+mozpreproc',), ('*.css.in',), ()),
    'MozPreprocHashLexer': ('pip._vendor.pygments.lexers.markup', 'mozhashpreproc', ('mozhashpreproc',), (), ()),
    'MozPreprocJavascriptLexer': ('pip._vendor.pygments.lexers.markup', 'Javascript+mozpreproc', ('javascript+mozpreproc',), ('*.js.in',), ()),
    'MozPreprocPercentLexer': ('pip._vendor.pygments.lexers.markup', 'mozpercentpreproc', ('mozpercentpreproc',), (), ()),
    'MozPreprocXulLexer': ('pip._vendor.pygments.lexers.markup', 'XUL+mozpreproc', ('xul+mozpreproc',), ('*.xul.in',), ()),
    'MqlLexer': ('pip._vendor.pygments.lexers.c_like', 'MQL', ('mql', 'mq4', 'mq5', 'mql4', 'mql5'), ('*.mq4', '*.mq5', '*.mqh'), ('text/x-mql',)),
    'MscgenLexer': ('pip._vendor.pygments.lexers.dsls', 'Mscgen', ('mscgen', 'msc'), ('*.msc',), ()),
    'MuPADLexer': ('pip._vendor.pygments.lexers.algebra', 'MuPAD', ('mupad',), ('*.mu',), ()),
    'MxmlLexer': ('pip._vendor.pygments.lexers.actionscript', 'MXML', ('mxml',), ('*.mxml',), ()),
    'MySqlLexer': ('pip._vendor.pygments.lexers.sql', 'MySQL', ('mysql',), (), ('text/x-mysql',)),
    'MyghtyCssLexer': ('pip._vendor.pygments.lexers.templates', 'CSS+Myghty', ('css+myghty',), (), ('text/css+myghty',)),
    'MyghtyHtmlLexer': ('pip._vendor.pygments.lexers.templates', 'HTML+Myghty', ('html+myghty',), (), ('text/html+myghty',)),
    'MyghtyJavascriptLexer': ('pip._vendor.pygments.lexers.templates', 'JavaScript+Myghty', ('javascript+myghty', 'js+myghty'), (), ('application/x-javascript+myghty', 'text/x-javascript+myghty', 'text/javascript+mygthy')),
    'MyghtyLexer': ('pip._vendor.pygments.lexers.templates', 'Myghty', ('myghty',), ('*.myt', 'autodelegate'), ('application/x-myghty',)),
    'MyghtyXmlLexer': ('pip._vendor.pygments.lexers.templates', 'XML+Myghty', ('xml+myghty',), (), ('application/xml+myghty',)),
    'NCLLexer': ('pip._vendor.pygments.lexers.ncl', 'NCL', ('ncl',), ('*.ncl',), ('text/ncl',)),
    'NSISLexer': ('pip._vendor.pygments.lexers.installers', 'NSIS', ('nsis', 'nsi', 'nsh'), ('*.nsi', '*.nsh'), ('text/x-nsis',)),
    'NasmLexer': ('pip._vendor.pygments.lexers.asm', 'NASM', ('nasm',), ('*.asm', '*.ASM', '*.nasm'), ('text/x-nasm',)),
    'NasmObjdumpLexer': ('pip._vendor.pygments.lexers.asm', 'objdump-nasm', ('objdump-nasm',), ('*.objdump-intel',), ('text/x-nasm-objdump',)),
    'NemerleLexer': ('pip._vendor.pygments.lexers.dotnet', 'Nemerle', ('nemerle',), ('*.n',), ('text/x-nemerle',)),
    'NesCLexer': ('pip._vendor.pygments.lexers.c_like', 'nesC', ('nesc',), ('*.nc',), ('text/x-nescsrc',)),
    'NestedTextLexer': ('pip._vendor.pygments.lexers.configs', 'NestedText', ('nestedtext', 'nt'), ('*.nt',), ()),
    'NewLispLexer': ('pip._vendor.pygments.lexers.lisp', 'NewLisp', ('newlisp',), ('*.lsp', '*.nl', '*.kif'), ('text/x-newlisp', 'application/x-newlisp')),
    'NewspeakLexer': ('pip._vendor.pygments.lexers.smalltalk', 'Newspeak', ('newspeak',), ('*.ns2',), ('text/x-newspeak',)),
    'NginxConfLexer': ('pip._vendor.pygments.lexers.configs', 'Nginx configuration file', ('nginx',), ('nginx.conf',), ('text/x-nginx-conf',)),
    'NimrodLexer': ('pip._vendor.pygments.lexers.nimrod', 'Nimrod', ('nimrod', 'nim'), ('*.nim', '*.nimrod'), ('text/x-nim',)),
    'NitLexer': ('pip._vendor.pygments.lexers.nit', 'Nit', ('nit',), ('*.nit',), ()),
    'NixLexer': ('pip._vendor.pygments.lexers.nix', 'Nix', ('nixos', 'nix'), ('*.nix',), ('text/x-nix',)),
    'NodeConsoleLexer': ('pip._vendor.pygments.lexers.javascript', 'Node.js REPL console session', ('nodejsrepl',), (), ('text/x-nodejsrepl',)),
    'NotmuchLexer': ('pip._vendor.pygments.lexers.textfmts', 'Notmuch', ('notmuch',), (), ()),
    'NuSMVLexer': ('pip._vendor.pygments.lexers.smv', 'NuSMV', ('nusmv',), ('*.smv',), ()),
    'NumPyLexer': ('pip._vendor.pygments.lexers.python', 'NumPy', ('numpy',), (), ()),
    'NumbaIRLexer': ('pip._vendor.pygments.lexers.numbair', 'Numba_IR', ('numba_ir', 'numbair'), ('*.numba_ir',), ('text/x-numba_ir', 'text/x-numbair')),
    'ObjdumpLexer': ('pip._vendor.pygments.lexers.asm', 'objdump', ('objdump',), ('*.objdump',), ('text/x-objdump',)),
    'ObjectiveCLexer': ('pip._vendor.pygments.lexers.objective', 'Objective-C', ('objective-c', 'objectivec', 'obj-c', 'objc'), ('*.m', '*.h'), ('text/x-objective-c',)),
    'ObjectiveCppLexer': ('pip._vendor.pygments.lexers.objective', 'Objective-C++', ('objective-c++', 'objectivec++', 'obj-c++', 'objc++'), ('*.mm', '*.hh'), ('text/x-objective-c++',)),
    'ObjectiveJLexer': ('pip._vendor.pygments.lexers.javascript', 'Objective-J', ('objective-j', 'objectivej', 'obj-j', 'objj'), ('*.j',), ('text/x-objective-j',)),
    'OcamlLexer': ('pip._vendor.pygments.lexers.ml', 'OCaml', ('ocaml',), ('*.ml', '*.mli', '*.mll', '*.mly'), ('text/x-ocaml',)),
    'OctaveLexer': ('pip._vendor.pygments.lexers.matlab', 'Octave', ('octave',), ('*.m',), ('text/octave',)),
    'OdinLexer': ('pip._vendor.pygments.lexers.archetype', 'ODIN', ('odin',), ('*.odin',), ('text/odin',)),
    'OmgIdlLexer': ('pip._vendor.pygments.lexers.c_like', 'OMG Interface Definition Language', ('omg-idl',), ('*.idl', '*.pidl'), ()),
    'OocLexer': ('pip._vendor.pygments.lexers.ooc', 'Ooc', ('ooc',), ('*.ooc',), ('text/x-ooc',)),
    'OpaLexer': ('pip._vendor.pygments.lexers.ml', 'Opa', ('opa',), ('*.opa',), ('text/x-opa',)),
    'OpenEdgeLexer': ('pip._vendor.pygments.lexers.business', 'OpenEdge ABL', ('openedge', 'abl', 'progress'), ('*.p', '*.cls'), ('text/x-openedge', 'application/x-openedge')),
    'OpenScadLexer': ('pip._vendor.pygments.lexers.openscad', 'OpenSCAD', ('openscad',), ('*.scad',), ('application/x-openscad',)),
    'OrgLexer': ('pip._vendor.pygments.lexers.markup', 'Org Mode', ('org', 'orgmode', 'org-mode'), ('*.org',), ('text/org',)),
    'OutputLexer': ('pip._vendor.pygments.lexers.special', 'Text output', ('output',), (), ()),
    'PacmanConfLexer': ('pip._vendor.pygments.lexers.configs', 'PacmanConf', ('pacmanconf',), ('pacman.conf',), ()),
    'PanLexer': ('pip._vendor.pygments.lexers.dsls', 'Pan', ('pan',), ('*.pan',), ()),
    'ParaSailLexer': ('pip._vendor.pygments.lexers.parasail', 'ParaSail', ('parasail',), ('*.psi', '*.psl'), ('text/x-parasail',)),
    'PawnLexer': ('pip._vendor.pygments.lexers.pawn', 'Pawn', ('pawn',), ('*.p', '*.pwn', '*.inc'), ('text/x-pawn',)),
    'PddlLexer': ('pip._vendor.pygments.lexers.pddl', 'PDDL', ('pddl',), ('*.pddl',), ()),
    'PegLexer': ('pip._vendor.pygments.lexers.grammar_notation', 'PEG', ('peg',), ('*.peg',), ('text/x-peg',)),
    'Perl6Lexer': ('pip._vendor.pygments.lexers.perl', 'Perl6', ('perl6', 'pl6', 'raku'), ('*.pl', '*.pm', '*.nqp', '*.p6', '*.6pl', '*.p6l', '*.pl6', '*.6pm', '*.p6m', '*.pm6', '*.t', '*.raku', '*.rakumod', '*.rakutest', '*.rakudoc'), ('text/x-perl6', 'application/x-perl6')),
    'PerlLexer': ('pip._vendor.pygments.lexers.perl', 'Perl', ('perl', 'pl'), ('*.pl', '*.pm', '*.t', '*.perl'), ('text/x-perl', 'application/x-perl')),
    'PhixLexer': ('pip._vendor.pygments.lexers.phix', 'Phix', ('phix',), ('*.exw',), ('text/x-phix',)),
    'PhpLexer': ('pip._vendor.pygments.lexers.php', 'PHP', ('php', 'php3', 'php4', 'php5'), ('*.php', '*.php[345]', '*.inc'), ('text/x-php',)),
    'PigLexer': ('pip._vendor.pygments.lexers.jvm', 'Pig', ('pig',), ('*.pig',), ('text/x-pig',)),
    'PikeLexer': ('pip._vendor.pygments.lexers.c_like', 'Pike', ('pike',), ('*.pike', '*.pmod'), ('text/x-pike',)),
    'PkgConfigLexer': ('pip._vendor.pygments.lexers.configs', 'PkgConfig', ('pkgconfig',), ('*.pc',), ()),
    'PlPgsqlLexer': ('pip._vendor.pygments.lexers.sql', 'PL/pgSQL', ('plpgsql',), (), ('text/x-plpgsql',)),
    'PointlessLexer': ('pip._vendor.pygments.lexers.pointless', 'Pointless', ('pointless',), ('*.ptls',), ()),
    'PonyLexer': ('pip._vendor.pygments.lexers.pony', 'Pony', ('pony',), ('*.pony',), ()),
    'PortugolLexer': ('pip._vendor.pygments.lexers.pascal', 'Portugol', ('portugol',), ('*.alg', '*.portugol'), ()),
    'PostScriptLexer': ('pip._vendor.pygments.lexers.graphics', 'PostScript', ('postscript', 'postscr'), ('*.ps', '*.eps'), ('application/postscript',)),
    'PostgresConsoleLexer': ('pip._vendor.pygments.lexers.sql', 'PostgreSQL console (psql)', ('psql', 'postgresql-console', 'postgres-console'), (), ('text/x-postgresql-psql',)),
    'PostgresExplainLexer': ('pip._vendor.pygments.lexers.sql', 'PostgreSQL EXPLAIN dialect', ('postgres-explain',), ('*.explain',), ('text/x-postgresql-explain',)),
    'PostgresLexer': ('pip._vendor.pygments.lexers.sql', 'PostgreSQL SQL dialect', ('postgresql', 'postgres'), (), ('text/x-postgresql',)),
    'PovrayLexer': ('pip._vendor.pygments.lexers.graphics', 'POVRay', ('pov',), ('*.pov', '*.inc'), ('text/x-povray',)),
    'PowerShellLexer': ('pip._vendor.pygments.lexers.shell', 'PowerShell', ('powershell', 'pwsh', 'posh', 'ps1', 'psm1'), ('*.ps1', '*.psm1'), ('text/x-powershell',)),
    'PowerShellSessionLexer': ('pip._vendor.pygments.lexers.shell', 'PowerShell Session', ('pwsh-session', 'ps1con'), (), ()),
    'PraatLexer': ('pip._vendor.pygments.lexers.praat', 'Praat', ('praat',), ('*.praat', '*.proc', '*.psc'), ()),
    'ProcfileLexer': ('pip._vendor.pygments.lexers.procfile', 'Procfile', ('procfile',), ('Procfile',), ()),
    'PrologLexer': ('pip._vendor.pygments.lexers.prolog', 'Prolog', ('prolog',), ('*.ecl', '*.prolog', '*.pro', '*.pl'), ('text/x-prolog',)),
    'PromQLLexer': ('pip._vendor.pygments.lexers.promql', 'PromQL', ('promql',), ('*.promql',), ()),
    'PromelaLexer': ('pip._vendor.pygments.lexers.c_like', 'Promela', ('promela',), ('*.pml', '*.prom', '*.prm', '*.promela', '*.pr', '*.pm'), ('text/x-promela',)),
    'PropertiesLexer': ('pip._vendor.pygments.lexers.configs', 'Properties', ('properties', 'jproperties'), ('*.properties',), ('text/x-java-properties',)),
    'ProtoBufLexer': ('pip._vendor.pygments.lexers.dsls', 'Protocol Buffer', ('protobuf', 'proto'), ('*.proto',), ()),
    'PrqlLexer': ('pip._vendor.pygments.lexers.prql', 'PRQL', ('prql',), ('*.prql',), ('application/prql', 'application/x-prql')),
    'PsyshConsoleLexer': ('pip._vendor.pygments.lexers.php', 'PsySH console session for PHP', ('psysh',), (), ()),
    'PtxLexer': ('pip._vendor.pygments.lexers.ptx', 'PTX', ('ptx',), ('*.ptx',), ('text/x-ptx',)),
    'PugLexer': ('pip._vendor.pygments.lexers.html', 'Pug', ('pug', 'jade'), ('*.pug', '*.jade'), ('text/x-pug', 'text/x-jade')),
    'PuppetLexer': ('pip._vendor.pygments.lexers.dsls', 'Puppet', ('puppet',), ('*.pp',), ()),
    'PyPyLogLexer': ('pip._vendor.pygments.lexers.console', 'PyPy Log', ('pypylog', 'pypy'), ('*.pypylog',), ('application/x-pypylog',)),
    'Python2Lexer': ('pip._vendor.pygments.lexers.python', 'Python 2.x', ('python2', 'py2'), (), ('text/x-python2', 'application/x-python2')),
    'Python2TracebackLexer': ('pip._vendor.pygments.lexers.python', 'Python 2.x Traceback', ('py2tb',), ('*.py2tb',), ('text/x-python2-traceback',)),
    'PythonConsoleLexer': ('pip._vendor.pygments.lexers.python', 'Python console session', ('pycon', 'python-console'), (), ('text/x-python-doctest',)),
    'PythonLexer': ('pip._vendor.pygments.lexers.python', 'Python', ('python', 'py', 'sage', 'python3', 'py3', 'bazel', 'starlark', 'pyi'), ('*.py', '*.pyw', '*.pyi', '*.jy', '*.sage', '*.sc', 'SConstruct', 'SConscript', '*.bzl', 'BUCK', 'BUILD', 'BUILD.bazel', 'WORKSPACE', '*.tac'), ('text/x-python', 'application/x-python', 'text/x-python3', 'application/x-python3')),
    'PythonTracebackLexer': ('pip._vendor.pygments.lexers.python', 'Python Traceback', ('pytb', 'py3tb'), ('*.pytb', '*.py3tb'), ('text/x-python-traceback', 'text/x-python3-traceback')),
    'PythonUL4Lexer': ('pip._vendor.pygments.lexers.ul4', 'Python+UL4', ('py+ul4',), ('*.pyul4',), ()),
    'QBasicLexer': ('pip._vendor.pygments.lexers.basic', 'QBasic', ('qbasic', 'basic'), ('*.BAS', '*.bas'), ('text/basic',)),
    'QLexer': ('pip._vendor.pygments.lexers.q', 'Q', ('q',), ('*.q',), ()),
    'QVToLexer': ('pip._vendor.pygments.lexers.qvt', 'QVTO', ('qvto', 'qvt'), ('*.qvto',), ()),
    'QlikLexer': ('pip._vendor.pygments.lexers.qlik', 'Qlik', ('qlik', 'qlikview', 'qliksense', 'qlikscript'), ('*.qvs', '*.qvw'), ()),
    'QmlLexer': ('pip._vendor.pygments.lexers.webmisc', 'QML', ('qml', 'qbs'), ('*.qml', '*.qbs'), ('application/x-qml', 'application/x-qt.qbs+qml')),
    'RConsoleLexer': ('pip._vendor.pygments.lexers.r', 'RConsole', ('rconsole', 'rout'), ('*.Rout',), ()),
    'RNCCompactLexer': ('pip._vendor.pygments.lexers.rnc', 'Relax-NG Compact', ('rng-compact', 'rnc'), ('*.rnc',), ()),
    'RPMSpecLexer': ('pip._vendor.pygments.lexers.installers', 'RPMSpec', ('spec',), ('*.spec',), ('text/x-rpm-spec',)),
    'RacketLexer': ('pip._vendor.pygments.lexers.lisp', 'Racket', ('racket', 'rkt'), ('*.rkt', '*.rktd', '*.rktl'), ('text/x-racket', 'application/x-racket')),
    'RagelCLexer': ('pip._vendor.pygments.lexers.parsers', 'Ragel in C Host', ('ragel-c',), ('*.rl',), ()),
    'RagelCppLexer': ('pip._vendor.pygments.lexers.parsers', 'Ragel in CPP Host', ('ragel-cpp',), ('*.rl',), ()),
    'RagelDLexer': ('pip._vendor.pygments.lexers.parsers', 'Ragel in D Host', ('ragel-d',), ('*.rl',), ()),
    'RagelEmbeddedLexer': ('pip._vendor.pygments.lexers.parsers', 'Embedded Ragel', ('ragel-em',), ('*.rl',), ()),
    'RagelJavaLexer': ('pip._vendor.pygments.lexers.parsers', 'Ragel in Java Host', ('ragel-java',), ('*.rl',), ()),
    'RagelLexer': ('pip._vendor.pygments.lexers.parsers', 'Ragel', ('ragel',), (), ()),
    'RagelObjectiveCLexer': ('pip._vendor.pygments.lexers.parsers', 'Ragel in Objective C Host', ('ragel-objc',), ('*.rl',), ()),
    'RagelRubyLexer': ('pip._vendor.pygments.lexers.parsers', 'Ragel in Ruby Host', ('ragel-ruby', 'ragel-rb'), ('*.rl',), ()),
    'RawTokenLexer': ('pip._vendor.pygments.lexers.special', 'Raw token data', (), (), ('application/x-pygments-tokens',)),
    'RdLexer': ('pip._vendor.pygments.lexers.r', 'Rd', ('rd',), ('*.Rd',), ('text/x-r-doc',)),
    'ReasonLexer': ('pip._vendor.pygments.lexers.ml', 'ReasonML', ('reasonml', 'reason'), ('*.re', '*.rei'), ('text/x-reasonml',)),
    'RebolLexer': ('pip._vendor.pygments.lexers.rebol', 'REBOL', ('rebol',), ('*.r', '*.r3', '*.reb'), ('text/x-rebol',)),
    'RedLexer': ('pip._vendor.pygments.lexers.rebol', 'Red', ('red', 'red/system'), ('*.red', '*.reds'), ('text/x-red', 'text/x-red-system')),
    'RedcodeLexer': ('pip._vendor.pygments.lexers.esoteric', 'Redcode', ('redcode',), ('*.cw',), ()),
    'RegeditLexer': ('pip._vendor.pygments.lexers.configs', 'reg', ('registry',), ('*.reg',), ('text/x-windows-registry',)),
    'RegoLexer': ('pip._vendor.pygments.lexers.rego', 'Rego', ('rego',), ('*.rego',), ('text/x-rego',)),
    'ResourceLexer': ('pip._vendor.pygments.lexers.resource', 'ResourceBundle', ('resourcebundle', 'resource'), (), ()),
    'RexxLexer': ('pip._vendor.pygments.lexers.scripting', 'Rexx', ('rexx', 'arexx'), ('*.rexx', '*.rex', '*.rx', '*.arexx'), ('text/x-rexx',)),
    'RhtmlLexer': ('pip._vendor.pygments.lexers.templates', 'RHTML', ('rhtml', 'html+erb', 'html+ruby'), ('*.rhtml',), ('text/html+ruby',)),
    'RideLexer': ('pip._vendor.pygments.lexers.ride', 'Ride', ('ride',), ('*.ride',), ('text/x-ride',)),
    'RitaLexer': ('pip._vendor.pygments.lexers.rita', 'Rita', ('rita',), ('*.rita',), ('text/rita',)),
    'RoboconfGraphLexer': ('pip._vendor.pygments.lexers.roboconf', 'Roboconf Graph', ('roboconf-graph',), ('*.graph',), ()),
    'RoboconfInstancesLexer': ('pip._vendor.pygments.lexers.roboconf', 'Roboconf Instances', ('roboconf-instances',), ('*.instances',), ()),
    'RobotFrameworkLexer': ('pip._vendor.pygments.lexers.robotframework', 'RobotFramework', ('robotframework',), ('*.robot', '*.resource'), ('text/x-robotframework',)),
    'RqlLexer': ('pip._vendor.pygments.lexers.sql', 'RQL', ('rql',), ('*.rql',), ('text/x-rql',)),
    'RslLexer': ('pip._vendor.pygments.lexers.dsls', 'RSL', ('rsl',), ('*.rsl',), ('text/rsl',)),
    'RstLexer': ('pip._vendor.pygments.lexers.markup', 'reStructuredText', ('restructuredtext', 'rst', 'rest'), ('*.rst', '*.rest'), ('text/x-rst', 'text/prs.fallenstein.rst')),
    'RtsLexer': ('pip._vendor.pygments.lexers.trafficscript', 'TrafficScript', ('trafficscript', 'rts'), ('*.rts',), ()),
    'RubyConsoleLexer': ('pip._vendor.pygments.lexers.ruby', 'Ruby irb session', ('rbcon', 'irb'), (), ('text/x-ruby-shellsession',)),
    'RubyLexer': ('pip._vendor.pygments.lexers.ruby', 'Ruby', ('ruby', 'rb', 'duby'), ('*.rb', '*.rbw', 'Rakefile', '*.rake', '*.gemspec', '*.rbx', '*.duby', 'Gemfile', 'Vagrantfile'), ('text/x-ruby', 'application/x-ruby')),
    'RustLexer': ('pip._vendor.pygments.lexers.rust', 'Rust', ('rust', 'rs'), ('*.rs', '*.rs.in'), ('text/rust', 'text/x-rust')),
    'SASLexer': ('pip._vendor.pygments.lexers.sas', 'SAS', ('sas',), ('*.SAS', '*.sas'), ('text/x-sas', 'text/sas', 'application/x-sas')),
    'SLexer': ('pip._vendor.pygments.lexers.r', 'S', ('splus', 's', 'r'), ('*.S', '*.R', '.Rhistory', '.Rprofile', '.Renviron'), ('text/S-plus', 'text/S', 'text/x-r-source', 'text/x-r', 'text/x-R', 'text/x-r-history', 'text/x-r-profile')),
    'SMLLexer': ('pip._vendor.pygments.lexers.ml', 'Standard ML', ('sml',), ('*.sml', '*.sig', '*.fun'), ('text/x-standardml', 'application/x-standardml')),
    'SNBTLexer': ('pip._vendor.pygments.lexers.minecraft', 'SNBT', ('snbt',), ('*.snbt',), ('text/snbt',)),
    'SarlLexer': ('pip._vendor.pygments.lexers.jvm', 'SARL', ('sarl',), ('*.sarl',), ('text/x-sarl',)),
    'SassLexer': ('pip._vendor.pygments.lexers.css', 'Sass', ('sass',), ('*.sass',), ('text/x-sass',)),
    'SaviLexer': ('pip._vendor.pygments.lexers.savi', 'Savi', ('savi',), ('*.savi',), ()),
    'ScalaLexer': ('pip._vendor.pygments.lexers.jvm', 'Scala', ('scala',), ('*.scala',), ('text/x-scala',)),
    'ScamlLexer': ('pip._vendor.pygments.lexers.html', 'Scaml', ('scaml',), ('*.scaml',), ('text/x-scaml',)),
    'ScdocLexer': ('pip._vendor.pygments.lexers.scdoc', 'scdoc', ('scdoc', 'scd'), ('*.scd', '*.scdoc'), ()),
    'SchemeLexer': ('pip._vendor.pygments.lexers.lisp', 'Scheme', ('scheme', 'scm'), ('*.scm', '*.ss'), ('text/x-scheme', 'application/x-scheme')),
    'ScilabLexer': ('pip._vendor.pygments.lexers.matlab', 'Scilab', ('scilab',), ('*.sci', '*.sce', '*.tst'), ('text/scilab',)),
    'ScssLexer': ('pip._vendor.pygments.lexers.css', 'SCSS', ('scss',), ('*.scss',), ('text/x-scss',)),
    'SedLexer': ('pip._vendor.pygments.lexers.textedit', 'Sed', ('sed', 'gsed', 'ssed'), ('*.sed', '*.[gs]sed'), ('text/x-sed',)),
    'ShExCLexer': ('pip._vendor.pygments.lexers.rdf', 'ShExC', ('shexc', 'shex'), ('*.shex',), ('text/shex',)),
    'ShenLexer': ('pip._vendor.pygments.lexers.lisp', 'Shen', ('shen',), ('*.shen',), ('text/x-shen', 'application/x-shen')),
    'SieveLexer': ('pip._vendor.pygments.lexers.sieve', 'Sieve', ('sieve',), ('*.siv', '*.sieve'), ()),
    'SilverLexer': ('pip._vendor.pygments.lexers.verification', 'Silver', ('silver',), ('*.sil', '*.vpr'), ()),
    'SingularityLexer': ('pip._vendor.pygments.lexers.configs', 'Singularity', ('singularity',), ('*.def', 'Singularity'), ()),
    'SlashLexer': ('pip._vendor.pygments.lexers.slash', 'Slash', ('slash',), ('*.sla',), ()),
    'SlimLexer': ('pip._vendor.pygments.lexers.webmisc', 'Slim', ('slim',), ('*.slim',), ('text/x-slim',)),
    'SlurmBashLexer': ('pip._vendor.pygments.lexers.shell', 'Slurm', ('slurm', 'sbatch'), ('*.sl',), ()),
    'SmaliLexer': ('pip._vendor.pygments.lexers.dalvik', 'Smali', ('smali',), ('*.smali',), ('text/smali',)),
    'SmalltalkLexer': ('pip._vendor.pygments.lexers.smalltalk', 'Smalltalk', ('smalltalk', 'squeak', 'st'), ('*.st',), ('text/x-smalltalk',)),
    'SmartGameFormatLexer': ('pip._vendor.pygments.lexers.sgf', 'SmartGameFormat', ('sgf',), ('*.sgf',), ()),
    'SmartyLexer': ('pip._vendor.pygments.lexers.templates', 'Smarty', ('smarty',), ('*.tpl',), ('application/x-smarty',)),
    'SmithyLexer': ('pip._vendor.pygments.lexers.smithy', 'Smithy', ('smithy',), ('*.smithy',), ()),
    'SnobolLexer': ('pip._vendor.pygments.lexers.snobol', 'Snobol', ('snobol',), ('*.snobol',), ('text/x-snobol',)),
    'SnowballLexer': ('pip._vendor.pygments.lexers.dsls', 'Snowball', ('snowball',), ('*.sbl',), ()),
    'SolidityLexer': ('pip._vendor.pygments.lexers.solidity', 'Solidity', ('solidity',), ('*.sol',), ()),
    'SoongLexer': ('pip._vendor.pygments.lexers.soong', 'Soong', ('androidbp', 'bp', 'soong'), ('Android.bp',), ()),
    'SophiaLexer': ('pip._vendor.pygments.lexers.sophia', 'Sophia', ('sophia',), ('*.aes',), ()),
    'SourcePawnLexer': ('pip._vendor.pygments.lexers.pawn', 'SourcePawn', ('sp',), ('*.sp',), ('text/x-sourcepawn',)),
    'SourcesListLexer': ('pip._vendor.pygments.lexers.installers', 'Debian Sourcelist', ('debsources', 'sourceslist', 'sources.list'), ('sources.list',), ()),
    'SparqlLexer': ('pip._vendor.pygments.lexers.rdf', 'SPARQL', ('sparql',), ('*.rq', '*.sparql'), ('application/sparql-query',)),
    'SpiceLexer': ('pip._vendor.pygments.lexers.spice', 'Spice', ('spice', 'spicelang'), ('*.spice',), ('text/x-spice',)),
    'SqlJinjaLexer': ('pip._vendor.pygments.lexers.templates', 'SQL+Jinja', ('sql+jinja',), ('*.sql', '*.sql.j2', '*.sql.jinja2'), ()),
    'SqlLexer': ('pip._vendor.pygments.lexers.sql', 'SQL', ('sql',), ('*.sql',), ('text/x-sql',)),
    'SqliteConsoleLexer': ('pip._vendor.pygments.lexers.sql', 'sqlite3con', ('sqlite3',), ('*.sqlite3-console',), ('text/x-sqlite3-console',)),
    'SquidConfLexer': ('pip._vendor.pygments.lexers.configs', 'SquidConf', ('squidconf', 'squid.conf', 'squid'), ('squid.conf',), ('text/x-squidconf',)),
    'SrcinfoLexer': ('pip._vendor.pygments.lexers.srcinfo', 'Srcinfo', ('srcinfo',), ('.SRCINFO',), ()),
    'SspLexer': ('pip._vendor.pygments.lexers.templates', 'Scalate Server Page', ('ssp',), ('*.ssp',), ('application/x-ssp',)),
    'StanLexer': ('pip._vendor.pygments.lexers.modeling', 'Stan', ('stan',), ('*.stan',), ()),
    'StataLexer': ('pip._vendor.pygments.lexers.stata', 'Stata', ('stata', 'do'), ('*.do', '*.ado'), ('text/x-stata', 'text/stata', 'application/x-stata')),
    'SuperColliderLexer': ('pip._vendor.pygments.lexers.supercollider', 'SuperCollider', ('supercollider', 'sc'), ('*.sc', '*.scd'), ('application/supercollider', 'text/supercollider')),
    'SwiftLexer': ('pip._vendor.pygments.lexers.objective', 'Swift', ('swift',), ('*.swift',), ('text/x-swift',)),
    'SwigLexer': ('pip._vendor.pygments.lexers.c_like', 'SWIG', ('swig',), ('*.swg', '*.i'), ('text/swig',)),
    'SystemVerilogLexer': ('pip._vendor.pygments.lexers.hdl', 'systemverilog', ('systemverilog', 'sv'), ('*.sv', '*.svh'), ('text/x-systemverilog',)),
    'SystemdLexer': ('pip._vendor.pygments.lexers.configs', 'Systemd', ('systemd',), ('*.service', '*.socket', '*.device', '*.mount', '*.automount', '*.swap', '*.target', '*.path', '*.timer', '*.slice', '*.scope'), ()),
    'TAPLexer': ('pip._vendor.pygments.lexers.testing', 'TAP', ('tap',), ('*.tap',), ()),
    'TNTLexer': ('pip._vendor.pygments.lexers.tnt', 'Typographic Number Theory', ('tnt',), ('*.tnt',), ()),
    'TOMLLexer': ('pip._vendor.pygments.lexers.configs', 'TOML', ('toml',), ('*.toml', 'Pipfile', 'poetry.lock'), ('application/toml',)),
    'TableGenLexer': ('pip._vendor.pygments.lexers.tablegen', 'TableGen', ('tablegen', 'td'), ('*.td',), ()),
    'TactLexer': ('pip._vendor.pygments.lexers.tact', 'Tact', ('tact',), ('*.tact',), ()),
    'Tads3Lexer': ('pip._vendor.pygments.lexers.int_fiction', 'TADS 3', ('tads3',), ('*.t',), ()),
    'TalLexer': ('pip._vendor.pygments.lexers.tal', 'Tal', ('tal', 'uxntal'), ('*.tal',), ('text/x-uxntal',)),
    'TasmLexer': ('pip._vendor.pygments.lexers.asm', 'TASM', ('tasm',), ('*.asm', '*.ASM', '*.tasm'), ('text/x-tasm',)),
    'TclLexer': ('pip._vendor.pygments.lexers.tcl', 'Tcl', ('tcl',), ('*.tcl', '*.rvt'), ('text/x-tcl', 'text/x-script.tcl', 'application/x-tcl')),
    'TcshLexer': ('pip._vendor.pygments.lexers.shell', 'Tcsh', ('tcsh', 'csh'), ('*.tcsh', '*.csh'), ('application/x-csh',)),
    'TcshSessionLexer': ('pip._vendor.pygments.lexers.shell', 'Tcsh Session', ('tcshcon',), (), ()),
    'TeaTemplateLexer': ('pip._vendor.pygments.lexers.templates', 'Tea', ('tea',), ('*.tea',), ('text/x-tea',)),
    'TealLexer': ('pip._vendor.pygments.lexers.teal', 'teal', ('teal',), ('*.teal',), ()),
    'TeraTermLexer': ('pip._vendor.pygments.lexers.teraterm', 'Tera Term macro', ('teratermmacro', 'teraterm', 'ttl'), ('*.ttl',), ('text/x-teratermmacro',)),
    'TermcapLexer': ('pip._vendor.pygments.lexers.configs', 'Termcap', ('termcap',), ('termcap', 'termcap.src'), ()),
    'TerminfoLexer': ('pip._vendor.pygments.lexers.configs', 'Terminfo', ('terminfo',), ('terminfo', 'terminfo.src'), ()),
    'TerraformLexer': ('pip._vendor.pygments.lexers.configs', 'Terraform', ('terraform', 'tf', 'hcl'), ('*.tf', '*.hcl'), ('application/x-tf', 'application/x-terraform')),
    'TexLexer': ('pip._vendor.pygments.lexers.markup', 'TeX', ('tex', 'latex'), ('*.tex', '*.aux', '*.toc'), ('text/x-tex', 'text/x-latex')),
    'TextLexer': ('pip._vendor.pygments.lexers.special', 'Text only', ('text',), ('*.txt',), ('text/plain',)),
    'ThingsDBLexer': ('pip._vendor.pygments.lexers.thingsdb', 'ThingsDB', ('ti', 'thingsdb'), ('*.ti',), ()),
    'ThriftLexer': ('pip._vendor.pygments.lexers.dsls', 'Thrift', ('thrift',), ('*.thrift',), ('application/x-thrift',)),
    'TiddlyWiki5Lexer': ('pip._vendor.pygments.lexers.markup', 'tiddler', ('tid',), ('*.tid',), ('text/vnd.tiddlywiki',)),
    'TlbLexer': ('pip._vendor.pygments.lexers.tlb', 'Tl-b', ('tlb',), ('*.tlb',), ()),
    'TlsLexer': ('pip._vendor.pygments.lexers.tls', 'TLS Presentation Language', ('tls',), (), ()),
    'TodotxtLexer': ('pip._vendor.pygments.lexers.textfmts', 'Todotxt', ('todotxt',), ('todo.txt', '*.todotxt'), ('text/x-todo',)),
    'TransactSqlLexer': ('pip._vendor.pygments.lexers.sql', 'Transact-SQL', ('tsql', 't-sql'), ('*.sql',), ('text/x-tsql',)),
    'TreetopLexer': ('pip._vendor.pygments.lexers.parsers', 'Treetop', ('treetop',), ('*.treetop', '*.tt'), ()),
    'TsxLexer': ('pip._vendor.pygments.lexers.jsx', 'TSX', ('tsx',), ('*.tsx',), ('text/typescript-tsx',)),
    'TurtleLexer': ('pip._vendor.pygments.lexers.rdf', 'Turtle', ('turtle',), ('*.ttl',), ('text/turtle', 'application/x-turtle')),
    'TwigHtmlLexer': ('pip._vendor.pygments.lexers.templates', 'HTML+Twig', ('html+twig',), ('*.twig',), ('text/html+twig',)),
    'TwigLexer': ('pip._vendor.pygments.lexers.templates', 'Twig', ('twig',), (), ('application/x-twig',)),
    'TypeScriptLexer': ('pip._vendor.pygments.lexers.javascript', 'TypeScript', ('typescript', 'ts'), ('*.ts',), ('application/x-typescript', 'text/x-typescript')),
    'TypoScriptCssDataLexer': ('pip._vendor.pygments.lexers.typoscript', 'TypoScriptCssData', ('typoscriptcssdata',), (), ()),
    'TypoScriptHtmlDataLexer': ('pip._vendor.pygments.lexers.typoscript', 'TypoScriptHtmlData', ('typoscripthtmldata',), (), ()),
    'TypoScriptLexer': ('pip._vendor.pygments.lexers.typoscript', 'TypoScript', ('typoscript',), ('*.typoscript',), ('text/x-typoscript',)),
    'TypstLexer': ('pip._vendor.pygments.lexers.typst', 'Typst', ('typst',), ('*.typ',), ('text/x-typst',)),
    'UL4Lexer': ('pip._vendor.pygments.lexers.ul4', 'UL4', ('ul4',), ('*.ul4',), ()),
    'UcodeLexer': ('pip._vendor.pygments.lexers.unicon', 'ucode', ('ucode',), ('*.u', '*.u1', '*.u2'), ()),
    'UniconLexer': ('pip._vendor.pygments.lexers.unicon', 'Unicon', ('unicon',), ('*.icn',), ('text/unicon',)),
    'UnixConfigLexer': ('pip._vendor.pygments.lexers.configs', 'Unix/Linux config files', ('unixconfig', 'linuxconfig'), (), ()),
    'UrbiscriptLexer': ('pip._vendor.pygments.lexers.urbi', 'UrbiScript', ('urbiscript',), ('*.u',), ('application/x-urbiscript',)),
    'UrlEncodedLexer': ('pip._vendor.pygments.lexers.html', 'urlencoded', ('urlencoded',), (), ('application/x-www-form-urlencoded',)),
    'UsdLexer': ('pip._vendor.pygments.lexers.usd', 'USD', ('usd', 'usda'), ('*.usd', '*.usda'), ()),
    'VBScriptLexer': ('pip._vendor.pygments.lexers.basic', 'VBScript', ('vbscript',), ('*.vbs', '*.VBS'), ()),
    'VCLLexer': ('pip._vendor.pygments.lexers.varnish', 'VCL', ('vcl',), ('*.vcl',), ('text/x-vclsrc',)),
    'VCLSnippetLexer': ('pip._vendor.pygments.lexers.varnish', 'VCLSnippets', ('vclsnippets', 'vclsnippet'), (), ('text/x-vclsnippet',)),
    'VCTreeStatusLexer': ('pip._vendor.pygments.lexers.console', 'VCTreeStatus', ('vctreestatus',), (), ()),
    'VGLLexer': ('pip._vendor.pygments.lexers.dsls', 'VGL', ('vgl',), ('*.rpf',), ()),
    'ValaLexer': ('pip._vendor.pygments.lexers.c_like', 'Vala', ('vala', 'vapi'), ('*.vala', '*.vapi'), ('text/x-vala',)),
    'VbNetAspxLexer': ('pip._vendor.pygments.lexers.dotnet', 'aspx-vb', ('aspx-vb',), ('*.aspx', '*.asax', '*.ascx', '*.ashx', '*.asmx', '*.axd'), ()),
    'VbNetLexer': ('pip._vendor.pygments.lexers.dotnet', 'VB.net', ('vb.net', 'vbnet', 'lobas', 'oobas', 'sobas', 'visual-basic', 'visualbasic'), ('*.vb', '*.bas'), ('text/x-vbnet', 'text/x-vba')),
    'VelocityHtmlLexer': ('pip._vendor.pygments.lexers.templates', 'HTML+Velocity', ('html+velocity',), (), ('text/html+velocity',)),
    'VelocityLexer': ('pip._vendor.pygments.lexers.templates', 'Velocity', ('velocity',), ('*.vm', '*.fhtml'), ()),
    'VelocityXmlLexer': ('pip._vendor.pygments.lexers.templates', 'XML+Velocity', ('xml+velocity',), (), ('application/xml+velocity',)),
    'VerifpalLexer': ('pip._vendor.pygments.lexers.verifpal', 'Verifpal', ('verifpal',), ('*.vp',), ('text/x-verifpal',)),
    'VerilogLexer': ('pip._vendor.pygments.lexers.hdl', 'verilog', ('verilog', 'v'), ('*.v',), ('text/x-verilog',)),
    'VhdlLexer': ('pip._vendor.pygments.lexers.hdl', 'vhdl', ('vhdl',), ('*.vhdl', '*.vhd'), ('text/x-vhdl',)),
    'VimLexer': ('pip._vendor.pygments.lexers.textedit', 'VimL', ('vim',), ('*.vim', '.vimrc', '.exrc', '.gvimrc', '_vimrc', '_exrc', '_gvimrc', 'vimrc', 'gvimrc'), ('text/x-vim',)),
    'VisualPrologGrammarLexer': ('pip._vendor.pygments.lexers.vip', 'Visual Prolog Grammar', ('visualprologgrammar',), ('*.vipgrm',), ()),
    'VisualPrologLexer': ('pip._vendor.pygments.lexers.vip', 'Visual Prolog', ('visualprolog',), ('*.pro', '*.cl', '*.i', '*.pack', '*.ph'), ()),
    'VueLexer': ('pip._vendor.pygments.lexers.html', 'Vue', ('vue',), ('*.vue',), ()),
    'VyperLexer': ('pip._vendor.pygments.lexers.vyper', 'Vyper', ('vyper',), ('*.vy',), ()),
    'WDiffLexer': ('pip._vendor.pygments.lexers.diff', 'WDiff', ('wdiff',), ('*.wdiff',), ()),
    'WatLexer': ('pip._vendor.pygments.lexers.webassembly', 'WebAssembly', ('wast', 'wat'), ('*.wat', '*.wast'), ()),
    'WebIDLLexer': ('pip._vendor.pygments.lexers.webidl', 'Web IDL', ('webidl',), ('*.webidl',), ()),
    'WgslLexer': ('pip._vendor.pygments.lexers.wgsl', 'WebGPU Shading Language', ('wgsl',), ('*.wgsl',), ('text/wgsl',)),
    'WhileyLexer': ('pip._vendor.pygments.lexers.whiley', 'Whiley', ('whiley',), ('*.whiley',), ('text/x-whiley',)),
    'WikitextLexer': ('pip._vendor.pygments.lexers.markup', 'Wikitext', ('wikitext', 'mediawiki'), (), ('text/x-wiki',)),
    'WoWTocLexer': ('pip._vendor.pygments.lexers.wowtoc', 'World of Warcraft TOC', ('wowtoc',), ('*.toc',), ()),
    'WrenLexer': ('pip._vendor.pygments.lexers.wren', 'Wren', ('wren',), ('*.wren',), ()),
    'X10Lexer': ('pip._vendor.pygments.lexers.x10', 'X10', ('x10', 'xten'), ('*.x10',), ('text/x-x10',)),
    'XMLUL4Lexer': ('pip._vendor.pygments.lexers.ul4', 'XML+UL4', ('xml+ul4',), ('*.xmlul4',), ()),
    'XQueryLexer': ('pip._vendor.pygments.lexers.webmisc', 'XQuery', ('xquery', 'xqy', 'xq', 'xql', 'xqm'), ('*.xqy', '*.xquery', '*.xq', '*.xql', '*.xqm'), ('text/xquery', 'application/xquery')),
    'XmlDjangoLexer': ('pip._vendor.pygments.lexers.templates', 'XML+Django/Jinja', ('xml+django', 'xml+jinja'), ('*.xml.j2', '*.xml.jinja2'), ('application/xml+django', 'application/xml+jinja')),
    'XmlErbLexer': ('pip._vendor.pygments.lexers.templates', 'XML+Ruby', ('xml+ruby', 'xml+erb'), (), ('application/xml+ruby',)),
    'XmlLexer': ('pip._vendor.pygments.lexers.html', 'XML', ('xml',), ('*.xml', '*.xsl', '*.rss', '*.xslt', '*.xsd', '*.wsdl', '*.wsf'), ('text/xml', 'application/xml', 'image/svg+xml', 'application/rss+xml', 'application/atom+xml')),
    'XmlPhpLexer': ('pip._vendor.pygments.lexers.templates', 'XML+PHP', ('xml+php',), (), ('application/xml+php',)),
    'XmlSmartyLexer': ('pip._vendor.pygments.lexers.templates', 'XML+Smarty', ('xml+smarty',), (), ('application/xml+smarty',)),
    'XorgLexer': ('pip._vendor.pygments.lexers.xorg', 'Xorg', ('xorg.conf',), ('xorg.conf',), ()),
    'XppLexer': ('pip._vendor.pygments.lexers.dotnet', 'X++', ('xpp', 'x++'), ('*.xpp',), ()),
    'XsltLexer': ('pip._vendor.pygments.lexers.html', 'XSLT', ('xslt',), ('*.xsl', '*.xslt', '*.xpl'), ('application/xsl+xml', 'application/xslt+xml')),
    'XtendLexer': ('pip._vendor.pygments.lexers.jvm', 'Xtend', ('xtend',), ('*.xtend',), ('text/x-xtend',)),
    'XtlangLexer': ('pip._vendor.pygments.lexers.lisp', 'xtlang', ('extempore',), ('*.xtm',), ()),
    'YamlJinjaLexer': ('pip._vendor.pygments.lexers.templates', 'YAML+Jinja', ('yaml+jinja', 'salt', 'sls'), ('*.sls', '*.yaml.j2', '*.yml.j2', '*.yaml.jinja2', '*.yml.jinja2'), ('text/x-yaml+jinja', 'text/x-sls')),
    'YamlLexer': ('pip._vendor.pygments.lexers.data', 'YAML', ('yaml',), ('*.yaml', '*.yml'), ('text/x-yaml',)),
    'YangLexer': ('pip._vendor.pygments.lexers.yang', 'YANG', ('yang',), ('*.yang',), ('application/yang',)),
    'YaraLexer': ('pip._vendor.pygments.lexers.yara', 'YARA', ('yara', 'yar'), ('*.yar',), ('text/x-yara',)),
    'ZeekLexer': ('pip._vendor.pygments.lexers.dsls', 'Zeek', ('zeek', 'bro'), ('*.zeek', '*.bro'), ()),
    'ZephirLexer': ('pip._vendor.pygments.lexers.php', 'Zephir', ('zephir',), ('*.zep',), ()),
    'ZigLexer': ('pip._vendor.pygments.lexers.zig', 'Zig', ('zig',), ('*.zig',), ('text/zig',)),
    'apdlexer': ('pip._vendor.pygments.lexers.apdlexer', 'ANSYS parametric design language', ('ansys', 'apdl'), ('*.ans',), ()),
}



import re
import sys
import types
import fnmatch
from os.path import basename

from pip._vendor.pygments.lexers._mapping import LEXERS
from pip._vendor.pygments.modeline import get_filetype_from_buffer
from pip._vendor.pygments.plugin import find_plugin_lexers
from pip._vendor.pygments.util import ClassNotFound, guess_decode

COMPAT = {
    'Python3Lexer': 'PythonLexer',
    'Python3TracebackLexer': 'PythonTracebackLexer',
    'LeanLexer': 'Lean3Lexer',
}

__all__ = ['get_lexer_by_name', 'get_lexer_for_filename', 'find_lexer_class',
           'guess_lexer', 'load_lexer_from_file'] + list(LEXERS) + list(COMPAT)

_lexer_cache = {}
_pattern_cache = {}


def _fn_matches(fn, glob):
    
    if glob not in _pattern_cache:
        pattern = _pattern_cache[glob] = re.compile(fnmatch.translate(glob))
        return pattern.match(fn)
    return _pattern_cache[glob].match(fn)


def _load_lexers(module_name):
    
    mod = __import__(module_name, None, None, ['__all__'])
    for lexer_name in mod.__all__:
        cls = getattr(mod, lexer_name)
        _lexer_cache[cls.name] = cls


def get_all_lexers(plugins=True):
    
    for item in LEXERS.values():
        yield item[1:]
    if plugins:
        for lexer in find_plugin_lexers():
            yield lexer.name, lexer.aliases, lexer.filenames, lexer.mimetypes


def find_lexer_class(name):
    
    if name in _lexer_cache:
        return _lexer_cache[name]
    
    for module_name, lname, aliases, _, _ in LEXERS.values():
        if name == lname:
            _load_lexers(module_name)
            return _lexer_cache[name]
    
    for cls in find_plugin_lexers():
        if cls.name == name:
            return cls


def find_lexer_class_by_name(_alias):
    
    if not _alias:
        raise ClassNotFound(f'no lexer for alias {_alias!r} found')
    
    for module_name, name, aliases, _, _ in LEXERS.values():
        if _alias.lower() in aliases:
            if name not in _lexer_cache:
                _load_lexers(module_name)
            return _lexer_cache[name]
    
    for cls in find_plugin_lexers():
        if _alias.lower() in cls.aliases:
            return cls
    raise ClassNotFound(f'no lexer for alias {_alias!r} found')


def get_lexer_by_name(_alias, **options):
    
    if not _alias:
        raise ClassNotFound(f'no lexer for alias {_alias!r} found')

    
    for module_name, name, aliases, _, _ in LEXERS.values():
        if _alias.lower() in aliases:
            if name not in _lexer_cache:
                _load_lexers(module_name)
            return _lexer_cache[name](**options)
    
    for cls in find_plugin_lexers():
        if _alias.lower() in cls.aliases:
            return cls(**options)
    raise ClassNotFound(f'no lexer for alias {_alias!r} found')


def load_lexer_from_file(filename, lexername=""CustomLexer"", **options):
    
    try:
        
        custom_namespace = {}
        with open(filename, 'rb') as f:
            exec(f.read(), custom_namespace)
        
        if lexername not in custom_namespace:
            raise ClassNotFound(f'no valid {lexername} class found in {filename}')
        lexer_class = custom_namespace[lexername]
        
        return lexer_class(**options)
    except OSError as err:
        raise ClassNotFound(f'cannot read {filename}: {err}')
    except ClassNotFound:
        raise
    except Exception as err:
        raise ClassNotFound(f'error when loading custom lexer: {err}')


def find_lexer_class_for_filename(_fn, code=None):
    
    matches = []
    fn = basename(_fn)
    for modname, name, _, filenames, _ in LEXERS.values():
        for filename in filenames:
            if _fn_matches(fn, filename):
                if name not in _lexer_cache:
                    _load_lexers(modname)
                matches.append((_lexer_cache[name], filename))
    for cls in find_plugin_lexers():
        for filename in cls.filenames:
            if _fn_matches(fn, filename):
                matches.append((cls, filename))

    if isinstance(code, bytes):
        
        code = guess_decode(code)

    def get_rating(info):
        cls, filename = info
        
        bonus = '*' not in filename and 0.5 or 0
        
        
        
        
        if code:
            return cls.analyse_text(code) + bonus, cls.__name__
        return cls.priority + bonus, cls.__name__

    if matches:
        matches.sort(key=get_rating)
        
        return matches[-1][0]


def get_lexer_for_filename(_fn, code=None, **options):
    
    res = find_lexer_class_for_filename(_fn, code)
    if not res:
        raise ClassNotFound(f'no lexer for filename {_fn!r} found')
    return res(**options)


def get_lexer_for_mimetype(_mime, **options):
    
    for modname, name, _, _, mimetypes in LEXERS.values():
        if _mime in mimetypes:
            if name not in _lexer_cache:
                _load_lexers(modname)
            return _lexer_cache[name](**options)
    for cls in find_plugin_lexers():
        if _mime in cls.mimetypes:
            return cls(**options)
    raise ClassNotFound(f'no lexer for mimetype {_mime!r} found')


def _iter_lexerclasses(plugins=True):
    
    for key in sorted(LEXERS):
        module_name, name = LEXERS[key][:2]
        if name not in _lexer_cache:
            _load_lexers(module_name)
        yield _lexer_cache[name]
    if plugins:
        yield from find_plugin_lexers()


def guess_lexer_for_filename(_fn, _text, **options):
    
    fn = basename(_fn)
    primary = {}
    matching_lexers = set()
    for lexer in _iter_lexerclasses():
        for filename in lexer.filenames:
            if _fn_matches(fn, filename):
                matching_lexers.add(lexer)
                primary[lexer] = True
        for filename in lexer.alias_filenames:
            if _fn_matches(fn, filename):
                matching_lexers.add(lexer)
                primary[lexer] = False
    if not matching_lexers:
        raise ClassNotFound(f'no lexer for filename {fn!r} found')
    if len(matching_lexers) == 1:
        return matching_lexers.pop()(**options)
    result = []
    for lexer in matching_lexers:
        rv = lexer.analyse_text(_text)
        if rv == 1.0:
            return lexer(**options)
        result.append((rv, lexer))

    def type_sort(t):
        
        
        
        
        
        return (t[0], primary[t[1]], t[1].priority, t[1].__name__)
    result.sort(key=type_sort)

    return result[-1][1](**options)


def guess_lexer(_text, **options):
    

    if not isinstance(_text, str):
        inencoding = options.get('inencoding', options.get('encoding'))
        if inencoding:
            _text = _text.decode(inencoding or 'utf8')
        else:
            _text, _ = guess_decode(_text)

    
    ft = get_filetype_from_buffer(_text)

    if ft is not None:
        try:
            return get_lexer_by_name(ft, **options)
        except ClassNotFound:
            pass

    best_lexer = [0.0, None]
    for lexer in _iter_lexerclasses():
        rv = lexer.analyse_text(_text)
        if rv == 1.0:
            return lexer(**options)
        if rv > best_lexer[0]:
            best_lexer[:] = (rv, lexer)
    if not best_lexer[0] or best_lexer[1] is None:
        raise ClassNotFound('no lexer matching the text found')
    return best_lexer[1](**options)


class _automodule(types.ModuleType):
    

    def __getattr__(self, name):
        info = LEXERS.get(name)
        if info:
            _load_lexers(info[0])
            cls = _lexer_cache[info[1]]
            setattr(self, name, cls)
            return cls
        if name in COMPAT:
            return getattr(self, COMPAT[name])
        raise AttributeError(name)


oldmod = sys.modules[__name__]
newmod = _automodule(__name__)
newmod.__dict__.update(oldmod.__dict__)
sys.modules[__name__] = newmod
del newmod.newmod, newmod.oldmod, newmod.sys, newmod.types




STYLES = {
    'AbapStyle': ('pygments.styles.abap', 'abap', ()),
    'AlgolStyle': ('pygments.styles.algol', 'algol', ()),
    'Algol_NuStyle': ('pygments.styles.algol_nu', 'algol_nu', ()),
    'ArduinoStyle': ('pygments.styles.arduino', 'arduino', ()),
    'AutumnStyle': ('pygments.styles.autumn', 'autumn', ()),
    'BlackWhiteStyle': ('pygments.styles.bw', 'bw', ()),
    'BorlandStyle': ('pygments.styles.borland', 'borland', ()),
    'CoffeeStyle': ('pygments.styles.coffee', 'coffee', ()),
    'ColorfulStyle': ('pygments.styles.colorful', 'colorful', ()),
    'DefaultStyle': ('pygments.styles.default', 'default', ()),
    'DraculaStyle': ('pygments.styles.dracula', 'dracula', ()),
    'EmacsStyle': ('pygments.styles.emacs', 'emacs', ()),
    'FriendlyGrayscaleStyle': ('pygments.styles.friendly_grayscale', 'friendly_grayscale', ()),
    'FriendlyStyle': ('pygments.styles.friendly', 'friendly', ()),
    'FruityStyle': ('pygments.styles.fruity', 'fruity', ()),
    'GhDarkStyle': ('pygments.styles.gh_dark', 'github-dark', ()),
    'GruvboxDarkStyle': ('pygments.styles.gruvbox', 'gruvbox-dark', ()),
    'GruvboxLightStyle': ('pygments.styles.gruvbox', 'gruvbox-light', ()),
    'IgorStyle': ('pygments.styles.igor', 'igor', ()),
    'InkPotStyle': ('pygments.styles.inkpot', 'inkpot', ()),
    'LightbulbStyle': ('pygments.styles.lightbulb', 'lightbulb', ()),
    'LilyPondStyle': ('pygments.styles.lilypond', 'lilypond', ()),
    'LovelaceStyle': ('pygments.styles.lovelace', 'lovelace', ()),
    'ManniStyle': ('pygments.styles.manni', 'manni', ()),
    'MaterialStyle': ('pygments.styles.material', 'material', ()),
    'MonokaiStyle': ('pygments.styles.monokai', 'monokai', ()),
    'MurphyStyle': ('pygments.styles.murphy', 'murphy', ()),
    'NativeStyle': ('pygments.styles.native', 'native', ()),
    'NordDarkerStyle': ('pygments.styles.nord', 'nord-darker', ()),
    'NordStyle': ('pygments.styles.nord', 'nord', ()),
    'OneDarkStyle': ('pygments.styles.onedark', 'one-dark', ()),
    'ParaisoDarkStyle': ('pygments.styles.paraiso_dark', 'paraiso-dark', ()),
    'ParaisoLightStyle': ('pygments.styles.paraiso_light', 'paraiso-light', ()),
    'PastieStyle': ('pygments.styles.pastie', 'pastie', ()),
    'PerldocStyle': ('pygments.styles.perldoc', 'perldoc', ()),
    'RainbowDashStyle': ('pygments.styles.rainbow_dash', 'rainbow_dash', ()),
    'RrtStyle': ('pygments.styles.rrt', 'rrt', ()),
    'SasStyle': ('pygments.styles.sas', 'sas', ()),
    'SolarizedDarkStyle': ('pygments.styles.solarized', 'solarized-dark', ()),
    'SolarizedLightStyle': ('pygments.styles.solarized', 'solarized-light', ()),
    'StarofficeStyle': ('pygments.styles.staroffice', 'staroffice', ()),
    'StataDarkStyle': ('pygments.styles.stata_dark', 'stata-dark', ()),
    'StataLightStyle': ('pygments.styles.stata_light', 'stata-light', ()),
    'TangoStyle': ('pygments.styles.tango', 'tango', ()),
    'TracStyle': ('pygments.styles.trac', 'trac', ()),
    'VimStyle': ('pygments.styles.vim', 'vim', ()),
    'VisualStudioStyle': ('pygments.styles.vs', 'vs', ()),
    'XcodeStyle': ('pygments.styles.xcode', 'xcode', ()),
    'ZenburnStyle': ('pygments.styles.zenburn', 'zenburn', ()),
}



from pip._vendor.pygments.plugin import find_plugin_styles
from pip._vendor.pygments.util import ClassNotFound
from pip._vendor.pygments.styles._mapping import STYLES




STYLE_MAP = {v[1]: v[0].split('.')[-1] + '::' + k for k, v in STYLES.items()}


_STYLE_NAME_TO_MODULE_MAP = {v[1]: (v[0], k) for k, v in STYLES.items()}


def get_style_by_name(name):
    
    if name in _STYLE_NAME_TO_MODULE_MAP:
        mod, cls = _STYLE_NAME_TO_MODULE_MAP[name]
        builtin = ""yes""
    else:
        for found_name, style in find_plugin_styles():
            if name == found_name:
                return style
        
        builtin = """"
        mod = 'pygments.styles.' + name
        cls = name.title() + ""Style""

    try:
        mod = __import__(mod, None, None, [cls])
    except ImportError:
        raise ClassNotFound(f""Could not find style module {mod!r}"" +
                            (builtin and "", though it should be builtin"")
                            + ""."")
    try:
        return getattr(mod, cls)
    except AttributeError:
        raise ClassNotFound(f""Could not find style class {cls!r} in style module."")


def get_all_styles():
    
    for v in STYLES.values():
        yield v[1]
    for name, _ in find_plugin_styles():
        yield name

import json
import os
import sys
import tempfile
from contextlib import contextmanager
from os.path import abspath
from os.path import join as pjoin
from subprocess import STDOUT, check_call, check_output
from typing import TYPE_CHECKING, Any, Iterator, Mapping, Optional, Sequence

from ._in_process import _in_proc_script_path

if TYPE_CHECKING:
    from typing import Protocol

    class SubprocessRunner(Protocol):
        

        def __call__(
            self,
            cmd: Sequence[str],
            cwd: Optional[str] = None,
            extra_environ: Optional[Mapping[str, str]] = None,
        ) -> None:
            ...


def write_json(obj: Mapping[str, Any], path: str, **kwargs) -> None:
    with open(path, ""w"", encoding=""utf-8"") as f:
        json.dump(obj, f, **kwargs)


def read_json(path: str) -> Mapping[str, Any]:
    with open(path, encoding=""utf-8"") as f:
        return json.load(f)


class BackendUnavailable(Exception):
    

    def __init__(
        self,
        traceback: str,
        message: Optional[str] = None,
        backend_name: Optional[str] = None,
        backend_path: Optional[Sequence[str]] = None,
    ) -> None:
        
        self.backend_name = backend_name
        self.backend_path = backend_path
        self.traceback = traceback
        super().__init__(message or ""Error while importing backend"")


class HookMissing(Exception):
    

    def __init__(self, hook_name: str) -> None:
        super().__init__(hook_name)
        self.hook_name = hook_name


class UnsupportedOperation(Exception):
    

    def __init__(self, traceback: str) -> None:
        self.traceback = traceback


def default_subprocess_runner(
    cmd: Sequence[str],
    cwd: Optional[str] = None,
    extra_environ: Optional[Mapping[str, str]] = None,
) -> None:
    
    env = os.environ.copy()
    if extra_environ:
        env.update(extra_environ)

    check_call(cmd, cwd=cwd, env=env)


def quiet_subprocess_runner(
    cmd: Sequence[str],
    cwd: Optional[str] = None,
    extra_environ: Optional[Mapping[str, str]] = None,
) -> None:
    
    env = os.environ.copy()
    if extra_environ:
        env.update(extra_environ)

    check_output(cmd, cwd=cwd, env=env, stderr=STDOUT)


def norm_and_check(source_tree: str, requested: str) -> str:
    
    if os.path.isabs(requested):
        raise ValueError(""paths must be relative"")

    abs_source = os.path.abspath(source_tree)
    abs_requested = os.path.normpath(os.path.join(abs_source, requested))
    
    
    
    norm_source = os.path.normcase(abs_source)
    norm_requested = os.path.normcase(abs_requested)
    if os.path.commonprefix([norm_source, norm_requested]) != norm_source:
        raise ValueError(""paths must be inside source tree"")

    return abs_requested


class BuildBackendHookCaller:
    

    def __init__(
        self,
        source_dir: str,
        build_backend: str,
        backend_path: Optional[Sequence[str]] = None,
        runner: Optional[""SubprocessRunner""] = None,
        python_executable: Optional[str] = None,
    ) -> None:
        
        if runner is None:
            runner = default_subprocess_runner

        self.source_dir = abspath(source_dir)
        self.build_backend = build_backend
        if backend_path:
            backend_path = [norm_and_check(self.source_dir, p) for p in backend_path]
        self.backend_path = backend_path
        self._subprocess_runner = runner
        if not python_executable:
            python_executable = sys.executable
        self.python_executable = python_executable

    @contextmanager
    def subprocess_runner(self, runner: ""SubprocessRunner"") -> Iterator[None]:
        
        prev = self._subprocess_runner
        self._subprocess_runner = runner
        try:
            yield
        finally:
            self._subprocess_runner = prev

    def _supported_features(self) -> Sequence[str]:
        
        return self._call_hook(""_supported_features"", {})

    def get_requires_for_build_wheel(
        self,
        config_settings: Optional[Mapping[str, Any]] = None,
    ) -> Sequence[str]:
        
        return self._call_hook(
            ""get_requires_for_build_wheel"", {""config_settings"": config_settings}
        )

    def prepare_metadata_for_build_wheel(
        self,
        metadata_directory: str,
        config_settings: Optional[Mapping[str, Any]] = None,
        _allow_fallback: bool = True,
    ) -> str:
        
        return self._call_hook(
            ""prepare_metadata_for_build_wheel"",
            {
                ""metadata_directory"": abspath(metadata_directory),
                ""config_settings"": config_settings,
                ""_allow_fallback"": _allow_fallback,
            },
        )

    def build_wheel(
        self,
        wheel_directory: str,
        config_settings: Optional[Mapping[str, Any]] = None,
        metadata_directory: Optional[str] = None,
    ) -> str:
        
        if metadata_directory is not None:
            metadata_directory = abspath(metadata_directory)
        return self._call_hook(
            ""build_wheel"",
            {
                ""wheel_directory"": abspath(wheel_directory),
                ""config_settings"": config_settings,
                ""metadata_directory"": metadata_directory,
            },
        )

    def get_requires_for_build_editable(
        self,
        config_settings: Optional[Mapping[str, Any]] = None,
    ) -> Sequence[str]:
        
        return self._call_hook(
            ""get_requires_for_build_editable"", {""config_settings"": config_settings}
        )

    def prepare_metadata_for_build_editable(
        self,
        metadata_directory: str,
        config_settings: Optional[Mapping[str, Any]] = None,
        _allow_fallback: bool = True,
    ) -> Optional[str]:
        
        return self._call_hook(
            ""prepare_metadata_for_build_editable"",
            {
                ""metadata_directory"": abspath(metadata_directory),
                ""config_settings"": config_settings,
                ""_allow_fallback"": _allow_fallback,
            },
        )

    def build_editable(
        self,
        wheel_directory: str,
        config_settings: Optional[Mapping[str, Any]] = None,
        metadata_directory: Optional[str] = None,
    ) -> str:
        
        if metadata_directory is not None:
            metadata_directory = abspath(metadata_directory)
        return self._call_hook(
            ""build_editable"",
            {
                ""wheel_directory"": abspath(wheel_directory),
                ""config_settings"": config_settings,
                ""metadata_directory"": metadata_directory,
            },
        )

    def get_requires_for_build_sdist(
        self,
        config_settings: Optional[Mapping[str, Any]] = None,
    ) -> Sequence[str]:
        
        return self._call_hook(
            ""get_requires_for_build_sdist"", {""config_settings"": config_settings}
        )

    def build_sdist(
        self,
        sdist_directory: str,
        config_settings: Optional[Mapping[str, Any]] = None,
    ) -> str:
        
        return self._call_hook(
            ""build_sdist"",
            {
                ""sdist_directory"": abspath(sdist_directory),
                ""config_settings"": config_settings,
            },
        )

    def _call_hook(self, hook_name: str, kwargs: Mapping[str, Any]) -> Any:
        extra_environ = {""_PYPROJECT_HOOKS_BUILD_BACKEND"": self.build_backend}

        if self.backend_path:
            backend_path = os.pathsep.join(self.backend_path)
            extra_environ[""_PYPROJECT_HOOKS_BACKEND_PATH""] = backend_path

        with tempfile.TemporaryDirectory() as td:
            hook_input = {""kwargs"": kwargs}
            write_json(hook_input, pjoin(td, ""input.json""), indent=2)

            
            with _in_proc_script_path() as script:
                python = self.python_executable
                self._subprocess_runner(
                    [python, abspath(str(script)), hook_name, td],
                    cwd=self.source_dir,
                    extra_environ=extra_environ,
                )

            data = read_json(pjoin(td, ""output.json""))
            if data.get(""unsupported""):
                raise UnsupportedOperation(data.get(""traceback"", """"))
            if data.get(""no_backend""):
                raise BackendUnavailable(
                    data.get(""traceback"", """"),
                    message=data.get(""backend_error"", """"),
                    backend_name=self.build_backend,
                    backend_path=self.backend_path,
                )
            if data.get(""hook_missing""):
                raise HookMissing(data.get(""missing_hook_name"") or hook_name)
            return data[""return_val""]



from typing import TYPE_CHECKING

from ._impl import (
    BackendUnavailable,
    BuildBackendHookCaller,
    HookMissing,
    UnsupportedOperation,
    default_subprocess_runner,
    quiet_subprocess_runner,
)

__version__ = ""1.2.0""
__all__ = [
    ""BackendUnavailable"",
    ""BackendInvalid"",
    ""HookMissing"",
    ""UnsupportedOperation"",
    ""default_subprocess_runner"",
    ""quiet_subprocess_runner"",
    ""BuildBackendHookCaller"",
]

BackendInvalid = BackendUnavailable  

if TYPE_CHECKING:
    from ._impl import SubprocessRunner

    __all__ += [""SubprocessRunner""]


import json
import os
import os.path
import re
import shutil
import sys
import traceback
from glob import glob
from importlib import import_module
from importlib.machinery import PathFinder
from os.path import join as pjoin





def write_json(obj, path, **kwargs):
    with open(path, ""w"", encoding=""utf-8"") as f:
        json.dump(obj, f, **kwargs)


def read_json(path):
    with open(path, encoding=""utf-8"") as f:
        return json.load(f)


class BackendUnavailable(Exception):
    

    def __init__(self, message, traceback=None):
        super().__init__(message)
        self.message = message
        self.traceback = traceback


class HookMissing(Exception):
    

    def __init__(self, hook_name=None):
        super().__init__(hook_name)
        self.hook_name = hook_name


def _build_backend():
    
    backend_path = os.environ.get(""_PYPROJECT_HOOKS_BACKEND_PATH"")
    ep = os.environ[""_PYPROJECT_HOOKS_BUILD_BACKEND""]
    mod_path, _, obj_path = ep.partition("":"")

    if backend_path:
        
        extra_pathitems = backend_path.split(os.pathsep)
        sys.meta_path.insert(0, _BackendPathFinder(extra_pathitems, mod_path))

    try:
        obj = import_module(mod_path)
    except ImportError:
        msg = f""Cannot import {mod_path!r}""
        raise BackendUnavailable(msg, traceback.format_exc())

    if obj_path:
        for path_part in obj_path.split("".""):
            obj = getattr(obj, path_part)
    return obj


class _BackendPathFinder:
    

    def __init__(self, backend_path, backend_module):
        self.backend_path = backend_path
        self.backend_module = backend_module
        self.backend_parent, _, _ = backend_module.partition(""."")

    def find_spec(self, fullname, _path, _target=None):
        if ""."" in fullname:
            
            return None

        
        spec = PathFinder.find_spec(fullname, path=self.backend_path)
        if spec is None and fullname == self.backend_parent:
            
            
            msg = f""Cannot find module {self.backend_module!r} in {self.backend_path!r}""
            raise BackendUnavailable(msg)

        return spec

    if sys.version_info >= (3, 8):

        def find_distributions(self, context=None):
            
            from importlib.metadata import DistributionFinder, MetadataPathFinder

            context = DistributionFinder.Context(path=self.backend_path)
            return MetadataPathFinder.find_distributions(context=context)


def _supported_features():
    
    backend = _build_backend()
    features = []
    if hasattr(backend, ""build_editable""):
        features.append(""build_editable"")
    return features


def get_requires_for_build_wheel(config_settings):
    
    backend = _build_backend()
    try:
        hook = backend.get_requires_for_build_wheel
    except AttributeError:
        return []
    else:
        return hook(config_settings)


def get_requires_for_build_editable(config_settings):
    
    backend = _build_backend()
    try:
        hook = backend.get_requires_for_build_editable
    except AttributeError:
        return []
    else:
        return hook(config_settings)


def prepare_metadata_for_build_wheel(
    metadata_directory, config_settings, _allow_fallback
):
    
    backend = _build_backend()
    try:
        hook = backend.prepare_metadata_for_build_wheel
    except AttributeError:
        if not _allow_fallback:
            raise HookMissing()
    else:
        return hook(metadata_directory, config_settings)
    
    
    whl_basename = backend.build_wheel(metadata_directory, config_settings)
    return _get_wheel_metadata_from_wheel(
        whl_basename, metadata_directory, config_settings
    )


def prepare_metadata_for_build_editable(
    metadata_directory, config_settings, _allow_fallback
):
    
    backend = _build_backend()
    try:
        hook = backend.prepare_metadata_for_build_editable
    except AttributeError:
        if not _allow_fallback:
            raise HookMissing()
        try:
            build_hook = backend.build_editable
        except AttributeError:
            raise HookMissing(hook_name=""build_editable"")
        else:
            whl_basename = build_hook(metadata_directory, config_settings)
            return _get_wheel_metadata_from_wheel(
                whl_basename, metadata_directory, config_settings
            )
    else:
        return hook(metadata_directory, config_settings)


WHEEL_BUILT_MARKER = ""PYPROJECT_HOOKS_ALREADY_BUILT_WHEEL""


def _dist_info_files(whl_zip):
    
    res = []
    for path in whl_zip.namelist():
        m = re.match(r""[^/\\]+-[^/\\]+\.dist-info/"", path)
        if m:
            res.append(path)
    if res:
        return res
    raise Exception(""No .dist-info folder found in wheel"")


def _get_wheel_metadata_from_wheel(whl_basename, metadata_directory, config_settings):
    
    from zipfile import ZipFile

    with open(os.path.join(metadata_directory, WHEEL_BUILT_MARKER), ""wb""):
        pass  

    whl_file = os.path.join(metadata_directory, whl_basename)
    with ZipFile(whl_file) as zipf:
        dist_info = _dist_info_files(zipf)
        zipf.extractall(path=metadata_directory, members=dist_info)
    return dist_info[0].split(""/"")[0]


def _find_already_built_wheel(metadata_directory):
    
    if not metadata_directory:
        return None
    metadata_parent = os.path.dirname(metadata_directory)
    if not os.path.isfile(pjoin(metadata_parent, WHEEL_BUILT_MARKER)):
        return None

    whl_files = glob(os.path.join(metadata_parent, ""*.whl""))
    if not whl_files:
        print(""Found wheel built marker, but no .whl files"")
        return None
    if len(whl_files) > 1:
        print(
            ""Found multiple .whl files; unspecified behaviour. ""
            ""Will call build_wheel.""
        )
        return None

    
    return whl_files[0]


def build_wheel(wheel_directory, config_settings, metadata_directory=None):
    
    prebuilt_whl = _find_already_built_wheel(metadata_directory)
    if prebuilt_whl:
        shutil.copy2(prebuilt_whl, wheel_directory)
        return os.path.basename(prebuilt_whl)

    return _build_backend().build_wheel(
        wheel_directory, config_settings, metadata_directory
    )


def build_editable(wheel_directory, config_settings, metadata_directory=None):
    
    backend = _build_backend()
    try:
        hook = backend.build_editable
    except AttributeError:
        raise HookMissing()
    else:
        prebuilt_whl = _find_already_built_wheel(metadata_directory)
        if prebuilt_whl:
            shutil.copy2(prebuilt_whl, wheel_directory)
            return os.path.basename(prebuilt_whl)

        return hook(wheel_directory, config_settings, metadata_directory)


def get_requires_for_build_sdist(config_settings):
    
    backend = _build_backend()
    try:
        hook = backend.get_requires_for_build_sdist
    except AttributeError:
        return []
    else:
        return hook(config_settings)


class _DummyException(Exception):
    


class GotUnsupportedOperation(Exception):
    

    def __init__(self, traceback):
        self.traceback = traceback


def build_sdist(sdist_directory, config_settings):
    
    backend = _build_backend()
    try:
        return backend.build_sdist(sdist_directory, config_settings)
    except getattr(backend, ""UnsupportedOperation"", _DummyException):
        raise GotUnsupportedOperation(traceback.format_exc())


HOOK_NAMES = {
    ""get_requires_for_build_wheel"",
    ""prepare_metadata_for_build_wheel"",
    ""build_wheel"",
    ""get_requires_for_build_editable"",
    ""prepare_metadata_for_build_editable"",
    ""build_editable"",
    ""get_requires_for_build_sdist"",
    ""build_sdist"",
    ""_supported_features"",
}


def main():
    if len(sys.argv) < 3:
        sys.exit(""Needs args: hook_name, control_dir"")
    hook_name = sys.argv[1]
    control_dir = sys.argv[2]
    if hook_name not in HOOK_NAMES:
        sys.exit(""Unknown hook: %s"" % hook_name)

    
    
    here = os.path.dirname(__file__)
    if here in sys.path:
        sys.path.remove(here)

    hook = globals()[hook_name]

    hook_input = read_json(pjoin(control_dir, ""input.json""))

    json_out = {""unsupported"": False, ""return_val"": None}
    try:
        json_out[""return_val""] = hook(**hook_input[""kwargs""])
    except BackendUnavailable as e:
        json_out[""no_backend""] = True
        json_out[""traceback""] = e.traceback
        json_out[""backend_error""] = e.message
    except GotUnsupportedOperation as e:
        json_out[""unsupported""] = True
        json_out[""traceback""] = e.traceback
    except HookMissing as e:
        json_out[""hook_missing""] = True
        json_out[""missing_hook_name""] = e.hook_name or hook_name

    write_json(json_out, pjoin(control_dir, ""output.json""), indent=2)


if __name__ == ""__main__"":
    main()



import importlib.resources as resources

try:
    resources.files
except AttributeError:
    
    def _in_proc_script_path():
        return resources.path(__package__, ""_in_process.py"")

else:

    def _in_proc_script_path():
        return resources.as_file(
            resources.files(__package__).joinpath(""_in_process.py"")
        )



import os.path
import socket  
import typing
import warnings

from pip._vendor.urllib3.exceptions import ClosedPoolError, ConnectTimeoutError
from pip._vendor.urllib3.exceptions import HTTPError as _HTTPError
from pip._vendor.urllib3.exceptions import InvalidHeader as _InvalidHeader
from pip._vendor.urllib3.exceptions import (
    LocationValueError,
    MaxRetryError,
    NewConnectionError,
    ProtocolError,
)
from pip._vendor.urllib3.exceptions import ProxyError as _ProxyError
from pip._vendor.urllib3.exceptions import ReadTimeoutError, ResponseError
from pip._vendor.urllib3.exceptions import SSLError as _SSLError
from pip._vendor.urllib3.poolmanager import PoolManager, proxy_from_url
from pip._vendor.urllib3.util import Timeout as TimeoutSauce
from pip._vendor.urllib3.util import parse_url
from pip._vendor.urllib3.util.retry import Retry
from pip._vendor.urllib3.util.ssl_ import create_urllib3_context

from .auth import _basic_auth_str
from .compat import basestring, urlparse
from .cookies import extract_cookies_to_jar
from .exceptions import (
    ConnectionError,
    ConnectTimeout,
    InvalidHeader,
    InvalidProxyURL,
    InvalidSchema,
    InvalidURL,
    ProxyError,
    ReadTimeout,
    RetryError,
    SSLError,
)
from .models import Response
from .structures import CaseInsensitiveDict
from .utils import (
    DEFAULT_CA_BUNDLE_PATH,
    extract_zipped_paths,
    get_auth_from_url,
    get_encoding_from_headers,
    prepend_scheme_if_needed,
    select_proxy,
    urldefragauth,
)

try:
    from pip._vendor.urllib3.contrib.socks import SOCKSProxyManager
except ImportError:

    def SOCKSProxyManager(*args, **kwargs):
        raise InvalidSchema(""Missing dependencies for SOCKS support."")


if typing.TYPE_CHECKING:
    from .models import PreparedRequest


DEFAULT_POOLBLOCK = False
DEFAULT_POOLSIZE = 10
DEFAULT_RETRIES = 0
DEFAULT_POOL_TIMEOUT = None


try:
    import ssl  

    _preloaded_ssl_context = create_urllib3_context()
    _preloaded_ssl_context.load_verify_locations(
        extract_zipped_paths(DEFAULT_CA_BUNDLE_PATH)
    )
except ImportError:
    
    
    _preloaded_ssl_context = None


def _urllib3_request_context(
    request: ""PreparedRequest"",
    verify: ""bool | str | None"",
    client_cert: ""typing.Tuple[str, str] | str | None"",
    poolmanager: ""PoolManager"",
) -> ""(typing.Dict[str, typing.Any], typing.Dict[str, typing.Any])"":
    host_params = {}
    pool_kwargs = {}
    parsed_request_url = urlparse(request.url)
    scheme = parsed_request_url.scheme.lower()
    port = parsed_request_url.port

    
    
    poolmanager_kwargs = getattr(poolmanager, ""connection_pool_kw"", {})
    has_poolmanager_ssl_context = poolmanager_kwargs.get(""ssl_context"")
    should_use_default_ssl_context = (
        _preloaded_ssl_context is not None and not has_poolmanager_ssl_context
    )

    cert_reqs = ""CERT_REQUIRED""
    if verify is False:
        cert_reqs = ""CERT_NONE""
    elif verify is True and should_use_default_ssl_context:
        pool_kwargs[""ssl_context""] = _preloaded_ssl_context
    elif isinstance(verify, str):
        if not os.path.isdir(verify):
            pool_kwargs[""ca_certs""] = verify
        else:
            pool_kwargs[""ca_cert_dir""] = verify
    pool_kwargs[""cert_reqs""] = cert_reqs
    if client_cert is not None:
        if isinstance(client_cert, tuple) and len(client_cert) == 2:
            pool_kwargs[""cert_file""] = client_cert[0]
            pool_kwargs[""key_file""] = client_cert[1]
        else:
            
            
            pool_kwargs[""cert_file""] = client_cert
    host_params = {
        ""scheme"": scheme,
        ""host"": parsed_request_url.hostname,
        ""port"": port,
    }
    return host_params, pool_kwargs


class BaseAdapter:
    

    def __init__(self):
        super().__init__()

    def send(
        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None
    ):
        
        raise NotImplementedError

    def close(self):
        
        raise NotImplementedError


class HTTPAdapter(BaseAdapter):
    

    __attrs__ = [
        ""max_retries"",
        ""config"",
        ""_pool_connections"",
        ""_pool_maxsize"",
        ""_pool_block"",
    ]

    def __init__(
        self,
        pool_connections=DEFAULT_POOLSIZE,
        pool_maxsize=DEFAULT_POOLSIZE,
        max_retries=DEFAULT_RETRIES,
        pool_block=DEFAULT_POOLBLOCK,
    ):
        if max_retries == DEFAULT_RETRIES:
            self.max_retries = Retry(0, read=False)
        else:
            self.max_retries = Retry.from_int(max_retries)
        self.config = {}
        self.proxy_manager = {}

        super().__init__()

        self._pool_connections = pool_connections
        self._pool_maxsize = pool_maxsize
        self._pool_block = pool_block

        self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)

    def __getstate__(self):
        return {attr: getattr(self, attr, None) for attr in self.__attrs__}

    def __setstate__(self, state):
        
        
        self.proxy_manager = {}
        self.config = {}

        for attr, value in state.items():
            setattr(self, attr, value)

        self.init_poolmanager(
            self._pool_connections, self._pool_maxsize, block=self._pool_block
        )

    def init_poolmanager(
        self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs
    ):
        
        
        self._pool_connections = connections
        self._pool_maxsize = maxsize
        self._pool_block = block

        self.poolmanager = PoolManager(
            num_pools=connections,
            maxsize=maxsize,
            block=block,
            **pool_kwargs,
        )

    def proxy_manager_for(self, proxy, **proxy_kwargs):
        
        if proxy in self.proxy_manager:
            manager = self.proxy_manager[proxy]
        elif proxy.lower().startswith(""socks""):
            username, password = get_auth_from_url(proxy)
            manager = self.proxy_manager[proxy] = SOCKSProxyManager(
                proxy,
                username=username,
                password=password,
                num_pools=self._pool_connections,
                maxsize=self._pool_maxsize,
                block=self._pool_block,
                **proxy_kwargs,
            )
        else:
            proxy_headers = self.proxy_headers(proxy)
            manager = self.proxy_manager[proxy] = proxy_from_url(
                proxy,
                proxy_headers=proxy_headers,
                num_pools=self._pool_connections,
                maxsize=self._pool_maxsize,
                block=self._pool_block,
                **proxy_kwargs,
            )

        return manager

    def cert_verify(self, conn, url, verify, cert):
        
        if url.lower().startswith(""https"") and verify:
            conn.cert_reqs = ""CERT_REQUIRED""

            
            
            
            
            if verify is not True:
                
                cert_loc = verify

                if not os.path.exists(cert_loc):
                    raise OSError(
                        f""Could not find a suitable TLS CA certificate bundle, ""
                        f""invalid path: {cert_loc}""
                    )

                if not os.path.isdir(cert_loc):
                    conn.ca_certs = cert_loc
                else:
                    conn.ca_cert_dir = cert_loc
        else:
            conn.cert_reqs = ""CERT_NONE""
            conn.ca_certs = None
            conn.ca_cert_dir = None

        if cert:
            if not isinstance(cert, basestring):
                conn.cert_file = cert[0]
                conn.key_file = cert[1]
            else:
                conn.cert_file = cert
                conn.key_file = None
            if conn.cert_file and not os.path.exists(conn.cert_file):
                raise OSError(
                    f""Could not find the TLS certificate file, ""
                    f""invalid path: {conn.cert_file}""
                )
            if conn.key_file and not os.path.exists(conn.key_file):
                raise OSError(
                    f""Could not find the TLS key file, invalid path: {conn.key_file}""
                )

    def build_response(self, req, resp):
        
        response = Response()

        
        response.status_code = getattr(resp, ""status"", None)

        
        response.headers = CaseInsensitiveDict(getattr(resp, ""headers"", {}))

        
        response.encoding = get_encoding_from_headers(response.headers)
        response.raw = resp
        response.reason = response.raw.reason

        if isinstance(req.url, bytes):
            response.url = req.url.decode(""utf-8"")
        else:
            response.url = req.url

        
        extract_cookies_to_jar(response.cookies, req, resp)

        
        response.request = req
        response.connection = self

        return response

    def build_connection_pool_key_attributes(self, request, verify, cert=None):
        
        return _urllib3_request_context(request, verify, cert, self.poolmanager)

    def get_connection_with_tls_context(self, request, verify, proxies=None, cert=None):
        
        proxy = select_proxy(request.url, proxies)
        try:
            host_params, pool_kwargs = self.build_connection_pool_key_attributes(
                request,
                verify,
                cert,
            )
        except ValueError as e:
            raise InvalidURL(e, request=request)
        if proxy:
            proxy = prepend_scheme_if_needed(proxy, ""http"")
            proxy_url = parse_url(proxy)
            if not proxy_url.host:
                raise InvalidProxyURL(
                    ""Please check proxy URL. It is malformed ""
                    ""and could be missing the host.""
                )
            proxy_manager = self.proxy_manager_for(proxy)
            conn = proxy_manager.connection_from_host(
                **host_params, pool_kwargs=pool_kwargs
            )
        else:
            
            conn = self.poolmanager.connection_from_host(
                **host_params, pool_kwargs=pool_kwargs
            )

        return conn

    def get_connection(self, url, proxies=None):
        
        warnings.warn(
            (
                ""`get_connection` has been deprecated in favor of ""
                ""`get_connection_with_tls_context`. Custom HTTPAdapter subclasses ""
                ""will need to migrate for Requests>=2.32.2. Please see ""
                ""https://github.com/psf/requests/pull/6710 for more details.""
            ),
            DeprecationWarning,
        )
        proxy = select_proxy(url, proxies)

        if proxy:
            proxy = prepend_scheme_if_needed(proxy, ""http"")
            proxy_url = parse_url(proxy)
            if not proxy_url.host:
                raise InvalidProxyURL(
                    ""Please check proxy URL. It is malformed ""
                    ""and could be missing the host.""
                )
            proxy_manager = self.proxy_manager_for(proxy)
            conn = proxy_manager.connection_from_url(url)
        else:
            
            parsed = urlparse(url)
            url = parsed.geturl()
            conn = self.poolmanager.connection_from_url(url)

        return conn

    def close(self):
        
        self.poolmanager.clear()
        for proxy in self.proxy_manager.values():
            proxy.clear()

    def request_url(self, request, proxies):
        
        proxy = select_proxy(request.url, proxies)
        scheme = urlparse(request.url).scheme

        is_proxied_http_request = proxy and scheme != ""https""
        using_socks_proxy = False
        if proxy:
            proxy_scheme = urlparse(proxy).scheme.lower()
            using_socks_proxy = proxy_scheme.startswith(""socks"")

        url = request.path_url
        if url.startswith(""//""):  
            url = f""/{url.lstrip('/')}""

        if is_proxied_http_request and not using_socks_proxy:
            url = urldefragauth(request.url)

        return url

    def add_headers(self, request, **kwargs):
        
        pass

    def proxy_headers(self, proxy):
        
        headers = {}
        username, password = get_auth_from_url(proxy)

        if username:
            headers[""Proxy-Authorization""] = _basic_auth_str(username, password)

        return headers

    def send(
        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None
    ):
        

        try:
            conn = self.get_connection_with_tls_context(
                request, verify, proxies=proxies, cert=cert
            )
        except LocationValueError as e:
            raise InvalidURL(e, request=request)

        self.cert_verify(conn, request.url, verify, cert)
        url = self.request_url(request, proxies)
        self.add_headers(
            request,
            stream=stream,
            timeout=timeout,
            verify=verify,
            cert=cert,
            proxies=proxies,
        )

        chunked = not (request.body is None or ""Content-Length"" in request.headers)

        if isinstance(timeout, tuple):
            try:
                connect, read = timeout
                timeout = TimeoutSauce(connect=connect, read=read)
            except ValueError:
                raise ValueError(
                    f""Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, ""
                    f""or a single float to set both timeouts to the same value.""
                )
        elif isinstance(timeout, TimeoutSauce):
            pass
        else:
            timeout = TimeoutSauce(connect=timeout, read=timeout)

        try:
            resp = conn.urlopen(
                method=request.method,
                url=url,
                body=request.body,
                headers=request.headers,
                redirect=False,
                assert_same_host=False,
                preload_content=False,
                decode_content=False,
                retries=self.max_retries,
                timeout=timeout,
                chunked=chunked,
            )

        except (ProtocolError, OSError) as err:
            raise ConnectionError(err, request=request)

        except MaxRetryError as e:
            if isinstance(e.reason, ConnectTimeoutError):
                
                if not isinstance(e.reason, NewConnectionError):
                    raise ConnectTimeout(e, request=request)

            if isinstance(e.reason, ResponseError):
                raise RetryError(e, request=request)

            if isinstance(e.reason, _ProxyError):
                raise ProxyError(e, request=request)

            if isinstance(e.reason, _SSLError):
                
                raise SSLError(e, request=request)

            raise ConnectionError(e, request=request)

        except ClosedPoolError as e:
            raise ConnectionError(e, request=request)

        except _ProxyError as e:
            raise ProxyError(e)

        except (_SSLError, _HTTPError) as e:
            if isinstance(e, _SSLError):
                
                raise SSLError(e, request=request)
            elif isinstance(e, ReadTimeoutError):
                raise ReadTimeout(e, request=request)
            elif isinstance(e, _InvalidHeader):
                raise InvalidHeader(e, request=request)
            else:
                raise

        return self.build_response(request, resp)



from . import sessions


def request(method, url, **kwargs):
    

    
    
    
    with sessions.Session() as session:
        return session.request(method=method, url=url, **kwargs)


def get(url, params=None, **kwargs):
    r

    return request(""get"", url, params=params, **kwargs)


def options(url, **kwargs):
    r

    return request(""options"", url, **kwargs)


def head(url, **kwargs):
    r

    kwargs.setdefault(""allow_redirects"", False)
    return request(""head"", url, **kwargs)


def post(url, data=None, json=None, **kwargs):
    r

    return request(""post"", url, data=data, json=json, **kwargs)


def put(url, data=None, **kwargs):
    r

    return request(""put"", url, data=data, **kwargs)


def patch(url, data=None, **kwargs):
    r

    return request(""patch"", url, data=data, **kwargs)


def delete(url, **kwargs):
    r

    return request(""delete"", url, **kwargs)



import hashlib
import os
import re
import threading
import time
import warnings
from base64 import b64encode

from ._internal_utils import to_native_string
from .compat import basestring, str, urlparse
from .cookies import extract_cookies_to_jar
from .utils import parse_dict_header

CONTENT_TYPE_FORM_URLENCODED = ""application/x-www-form-urlencoded""
CONTENT_TYPE_MULTI_PART = ""multipart/form-data""


def _basic_auth_str(username, password):
    

    
    
    
    
    
    
    
    if not isinstance(username, basestring):
        warnings.warn(
            ""Non-string usernames will no longer be supported in Requests ""
            ""3.0.0. Please convert the object you've passed in ({!r}) to ""
            ""a string or bytes object in the near future to avoid ""
            ""problems."".format(username),
            category=DeprecationWarning,
        )
        username = str(username)

    if not isinstance(password, basestring):
        warnings.warn(
            ""Non-string passwords will no longer be supported in Requests ""
            ""3.0.0. Please convert the object you've passed in ({!r}) to ""
            ""a string or bytes object in the near future to avoid ""
            ""problems."".format(type(password)),
            category=DeprecationWarning,
        )
        password = str(password)
    

    if isinstance(username, str):
        username = username.encode(""latin1"")

    if isinstance(password, str):
        password = password.encode(""latin1"")

    authstr = ""Basic "" + to_native_string(
        b64encode(b"":"".join((username, password))).strip()
    )

    return authstr


class AuthBase:
    

    def __call__(self, r):
        raise NotImplementedError(""Auth hooks must be callable."")


class HTTPBasicAuth(AuthBase):
    

    def __init__(self, username, password):
        self.username = username
        self.password = password

    def __eq__(self, other):
        return all(
            [
                self.username == getattr(other, ""username"", None),
                self.password == getattr(other, ""password"", None),
            ]
        )

    def __ne__(self, other):
        return not self == other

    def __call__(self, r):
        r.headers[""Authorization""] = _basic_auth_str(self.username, self.password)
        return r


class HTTPProxyAuth(HTTPBasicAuth):
    

    def __call__(self, r):
        r.headers[""Proxy-Authorization""] = _basic_auth_str(self.username, self.password)
        return r


class HTTPDigestAuth(AuthBase):
    

    def __init__(self, username, password):
        self.username = username
        self.password = password
        
        self._thread_local = threading.local()

    def init_per_thread_state(self):
        
        if not hasattr(self._thread_local, ""init""):
            self._thread_local.init = True
            self._thread_local.last_nonce = """"
            self._thread_local.nonce_count = 0
            self._thread_local.chal = {}
            self._thread_local.pos = None
            self._thread_local.num_401_calls = None

    def build_digest_header(self, method, url):
        

        realm = self._thread_local.chal[""realm""]
        nonce = self._thread_local.chal[""nonce""]
        qop = self._thread_local.chal.get(""qop"")
        algorithm = self._thread_local.chal.get(""algorithm"")
        opaque = self._thread_local.chal.get(""opaque"")
        hash_utf8 = None

        if algorithm is None:
            _algorithm = ""MD5""
        else:
            _algorithm = algorithm.upper()
        
        if _algorithm == ""MD5"" or _algorithm == ""MD5-SESS"":

            def md5_utf8(x):
                if isinstance(x, str):
                    x = x.encode(""utf-8"")
                return hashlib.md5(x).hexdigest()

            hash_utf8 = md5_utf8
        elif _algorithm == ""SHA"":

            def sha_utf8(x):
                if isinstance(x, str):
                    x = x.encode(""utf-8"")
                return hashlib.sha1(x).hexdigest()

            hash_utf8 = sha_utf8
        elif _algorithm == ""SHA-256"":

            def sha256_utf8(x):
                if isinstance(x, str):
                    x = x.encode(""utf-8"")
                return hashlib.sha256(x).hexdigest()

            hash_utf8 = sha256_utf8
        elif _algorithm == ""SHA-512"":

            def sha512_utf8(x):
                if isinstance(x, str):
                    x = x.encode(""utf-8"")
                return hashlib.sha512(x).hexdigest()

            hash_utf8 = sha512_utf8

        KD = lambda s, d: hash_utf8(f""{s}:{d}"")  

        if hash_utf8 is None:
            return None

        
        entdig = None
        p_parsed = urlparse(url)
        
        path = p_parsed.path or ""/""
        if p_parsed.query:
            path += f""?{p_parsed.query}""

        A1 = f""{self.username}:{realm}:{self.password}""
        A2 = f""{method}:{path}""

        HA1 = hash_utf8(A1)
        HA2 = hash_utf8(A2)

        if nonce == self._thread_local.last_nonce:
            self._thread_local.nonce_count += 1
        else:
            self._thread_local.nonce_count = 1
        ncvalue = f""{self._thread_local.nonce_count:08x}""
        s = str(self._thread_local.nonce_count).encode(""utf-8"")
        s += nonce.encode(""utf-8"")
        s += time.ctime().encode(""utf-8"")
        s += os.urandom(8)

        cnonce = hashlib.sha1(s).hexdigest()[:16]
        if _algorithm == ""MD5-SESS"":
            HA1 = hash_utf8(f""{HA1}:{nonce}:{cnonce}"")

        if not qop:
            respdig = KD(HA1, f""{nonce}:{HA2}"")
        elif qop == ""auth"" or ""auth"" in qop.split("",""):
            noncebit = f""{nonce}:{ncvalue}:{cnonce}:auth:{HA2}""
            respdig = KD(HA1, noncebit)
        else:
            
            return None

        self._thread_local.last_nonce = nonce

        
        base = (
            f'username=""{self.username}"", realm=""{realm}"", nonce=""{nonce}"", '
            f'uri=""{path}"", response=""{respdig}""'
        )
        if opaque:
            base += f', opaque=""{opaque}""'
        if algorithm:
            base += f', algorithm=""{algorithm}""'
        if entdig:
            base += f', digest=""{entdig}""'
        if qop:
            base += f', qop=""auth"", nc={ncvalue}, cnonce=""{cnonce}""'

        return f""Digest {base}""

    def handle_redirect(self, r, **kwargs):
        
        if r.is_redirect:
            self._thread_local.num_401_calls = 1

    def handle_401(self, r, **kwargs):
        

        
        
        if not 400 <= r.status_code < 500:
            self._thread_local.num_401_calls = 1
            return r

        if self._thread_local.pos is not None:
            
            
            r.request.body.seek(self._thread_local.pos)
        s_auth = r.headers.get(""www-authenticate"", """")

        if ""digest"" in s_auth.lower() and self._thread_local.num_401_calls < 2:
            self._thread_local.num_401_calls += 1
            pat = re.compile(r""digest "", flags=re.IGNORECASE)
            self._thread_local.chal = parse_dict_header(pat.sub("""", s_auth, count=1))

            
            
            r.content
            r.close()
            prep = r.request.copy()
            extract_cookies_to_jar(prep._cookies, r.request, r.raw)
            prep.prepare_cookies(prep._cookies)

            prep.headers[""Authorization""] = self.build_digest_header(
                prep.method, prep.url
            )
            _r = r.connection.send(prep, **kwargs)
            _r.history.append(r)
            _r.request = prep

            return _r

        self._thread_local.num_401_calls = 1
        return r

    def __call__(self, r):
        
        self.init_per_thread_state()
        
        if self._thread_local.last_nonce:
            r.headers[""Authorization""] = self.build_digest_header(r.method, r.url)
        try:
            self._thread_local.pos = r.body.tell()
        except AttributeError:
            
            
            
            
            self._thread_local.pos = None
        r.register_hook(""response"", self.handle_401)
        r.register_hook(""response"", self.handle_redirect)
        self._thread_local.num_401_calls = 1

        return r

    def __eq__(self, other):
        return all(
            [
                self.username == getattr(other, ""username"", None),
                self.password == getattr(other, ""password"", None),
            ]
        )

    def __ne__(self, other):
        return not self == other




from pip._vendor.certifi import where

if __name__ == ""__main__"":
    print(where())



import sys




from pip._vendor.urllib3 import __version__ as urllib3_version


try:
    is_urllib3_1 = int(urllib3_version.split(""."")[0]) == 1
except (TypeError, AttributeError):
    
    is_urllib3_1 = True






def _resolve_char_detection():
    
    chardet = None
    return chardet


chardet = _resolve_char_detection()






_ver = sys.version_info


is_py2 = _ver[0] == 2


is_py3 = _ver[0] == 3



import json
from json import JSONDecodeError


from collections import OrderedDict
from collections.abc import Callable, Mapping, MutableMapping
from http import cookiejar as cookielib
from http.cookies import Morsel
from io import StringIO




from urllib.parse import (
    quote,
    quote_plus,
    unquote,
    unquote_plus,
    urldefrag,
    urlencode,
    urljoin,
    urlparse,
    urlsplit,
    urlunparse,
)
from urllib.request import (
    getproxies,
    getproxies_environment,
    parse_http_list,
    proxy_bypass,
    proxy_bypass_environment,
)

builtin_str = str
str = str
bytes = bytes
basestring = (str, bytes)
numeric_types = (int, float)
integer_types = (int,)



import calendar
import copy
import time

from ._internal_utils import to_native_string
from .compat import Morsel, MutableMapping, cookielib, urlparse, urlunparse

try:
    import threading
except ImportError:
    import dummy_threading as threading


class MockRequest:
    

    def __init__(self, request):
        self._r = request
        self._new_headers = {}
        self.type = urlparse(self._r.url).scheme

    def get_type(self):
        return self.type

    def get_host(self):
        return urlparse(self._r.url).netloc

    def get_origin_req_host(self):
        return self.get_host()

    def get_full_url(self):
        
        
        if not self._r.headers.get(""Host""):
            return self._r.url
        
        host = to_native_string(self._r.headers[""Host""], encoding=""utf-8"")
        parsed = urlparse(self._r.url)
        
        return urlunparse(
            [
                parsed.scheme,
                host,
                parsed.path,
                parsed.params,
                parsed.query,
                parsed.fragment,
            ]
        )

    def is_unverifiable(self):
        return True

    def has_header(self, name):
        return name in self._r.headers or name in self._new_headers

    def get_header(self, name, default=None):
        return self._r.headers.get(name, self._new_headers.get(name, default))

    def add_header(self, key, val):
        
        raise NotImplementedError(
            ""Cookie headers should be added with add_unredirected_header()""
        )

    def add_unredirected_header(self, name, value):
        self._new_headers[name] = value

    def get_new_headers(self):
        return self._new_headers

    @property
    def unverifiable(self):
        return self.is_unverifiable()

    @property
    def origin_req_host(self):
        return self.get_origin_req_host()

    @property
    def host(self):
        return self.get_host()


class MockResponse:
    

    def __init__(self, headers):
        
        self._headers = headers

    def info(self):
        return self._headers

    def getheaders(self, name):
        self._headers.getheaders(name)


def extract_cookies_to_jar(jar, request, response):
    
    if not (hasattr(response, ""_original_response"") and response._original_response):
        return
    
    req = MockRequest(request)
    
    res = MockResponse(response._original_response.msg)
    jar.extract_cookies(res, req)


def get_cookie_header(jar, request):
    
    r = MockRequest(request)
    jar.add_cookie_header(r)
    return r.get_new_headers().get(""Cookie"")


def remove_cookie_by_name(cookiejar, name, domain=None, path=None):
    
    clearables = []
    for cookie in cookiejar:
        if cookie.name != name:
            continue
        if domain is not None and domain != cookie.domain:
            continue
        if path is not None and path != cookie.path:
            continue
        clearables.append((cookie.domain, cookie.path, cookie.name))

    for domain, path, name in clearables:
        cookiejar.clear(domain, path, name)


class CookieConflictError(RuntimeError):
    


class RequestsCookieJar(cookielib.CookieJar, MutableMapping):
    

    def get(self, name, default=None, domain=None, path=None):
        
        try:
            return self._find_no_duplicates(name, domain, path)
        except KeyError:
            return default

    def set(self, name, value, **kwargs):
        
        
        if value is None:
            remove_cookie_by_name(
                self, name, domain=kwargs.get(""domain""), path=kwargs.get(""path"")
            )
            return

        if isinstance(value, Morsel):
            c = morsel_to_cookie(value)
        else:
            c = create_cookie(name, value, **kwargs)
        self.set_cookie(c)
        return c

    def iterkeys(self):
        
        for cookie in iter(self):
            yield cookie.name

    def keys(self):
        
        return list(self.iterkeys())

    def itervalues(self):
        
        for cookie in iter(self):
            yield cookie.value

    def values(self):
        
        return list(self.itervalues())

    def iteritems(self):
        
        for cookie in iter(self):
            yield cookie.name, cookie.value

    def items(self):
        
        return list(self.iteritems())

    def list_domains(self):
        
        domains = []
        for cookie in iter(self):
            if cookie.domain not in domains:
                domains.append(cookie.domain)
        return domains

    def list_paths(self):
        
        paths = []
        for cookie in iter(self):
            if cookie.path not in paths:
                paths.append(cookie.path)
        return paths

    def multiple_domains(self):
        
        domains = []
        for cookie in iter(self):
            if cookie.domain is not None and cookie.domain in domains:
                return True
            domains.append(cookie.domain)
        return False  

    def get_dict(self, domain=None, path=None):
        
        dictionary = {}
        for cookie in iter(self):
            if (domain is None or cookie.domain == domain) and (
                path is None or cookie.path == path
            ):
                dictionary[cookie.name] = cookie.value
        return dictionary

    def __contains__(self, name):
        try:
            return super().__contains__(name)
        except CookieConflictError:
            return True

    def __getitem__(self, name):
        
        return self._find_no_duplicates(name)

    def __setitem__(self, name, value):
        
        self.set(name, value)

    def __delitem__(self, name):
        
        remove_cookie_by_name(self, name)

    def set_cookie(self, cookie, *args, **kwargs):
        if (
            hasattr(cookie.value, ""startswith"")
            and cookie.value.startswith('""')
            and cookie.value.endswith('""')
        ):
            cookie.value = cookie.value.replace('\\""', """")
        return super().set_cookie(cookie, *args, **kwargs)

    def update(self, other):
        
        if isinstance(other, cookielib.CookieJar):
            for cookie in other:
                self.set_cookie(copy.copy(cookie))
        else:
            super().update(other)

    def _find(self, name, domain=None, path=None):
        
        for cookie in iter(self):
            if cookie.name == name:
                if domain is None or cookie.domain == domain:
                    if path is None or cookie.path == path:
                        return cookie.value

        raise KeyError(f""name={name!r}, domain={domain!r}, path={path!r}"")

    def _find_no_duplicates(self, name, domain=None, path=None):
        
        toReturn = None
        for cookie in iter(self):
            if cookie.name == name:
                if domain is None or cookie.domain == domain:
                    if path is None or cookie.path == path:
                        if toReturn is not None:
                            
                            raise CookieConflictError(
                                f""There are multiple cookies with name, {name!r}""
                            )
                        
                        toReturn = cookie.value

        if toReturn:
            return toReturn
        raise KeyError(f""name={name!r}, domain={domain!r}, path={path!r}"")

    def __getstate__(self):
        
        state = self.__dict__.copy()
        
        state.pop(""_cookies_lock"")
        return state

    def __setstate__(self, state):
        
        self.__dict__.update(state)
        if ""_cookies_lock"" not in self.__dict__:
            self._cookies_lock = threading.RLock()

    def copy(self):
        
        new_cj = RequestsCookieJar()
        new_cj.set_policy(self.get_policy())
        new_cj.update(self)
        return new_cj

    def get_policy(self):
        
        return self._policy


def _copy_cookie_jar(jar):
    if jar is None:
        return None

    if hasattr(jar, ""copy""):
        
        return jar.copy()
    
    new_jar = copy.copy(jar)
    new_jar.clear()
    for cookie in jar:
        new_jar.set_cookie(copy.copy(cookie))
    return new_jar


def create_cookie(name, value, **kwargs):
    
    result = {
        ""version"": 0,
        ""name"": name,
        ""value"": value,
        ""port"": None,
        ""domain"": """",
        ""path"": ""/"",
        ""secure"": False,
        ""expires"": None,
        ""discard"": True,
        ""comment"": None,
        ""comment_url"": None,
        ""rest"": {""HttpOnly"": None},
        ""rfc2109"": False,
    }

    badargs = set(kwargs) - set(result)
    if badargs:
        raise TypeError(
            f""create_cookie() got unexpected keyword arguments: {list(badargs)}""
        )

    result.update(kwargs)
    result[""port_specified""] = bool(result[""port""])
    result[""domain_specified""] = bool(result[""domain""])
    result[""domain_initial_dot""] = result[""domain""].startswith(""."")
    result[""path_specified""] = bool(result[""path""])

    return cookielib.Cookie(**result)


def morsel_to_cookie(morsel):
    

    expires = None
    if morsel[""max-age""]:
        try:
            expires = int(time.time() + int(morsel[""max-age""]))
        except ValueError:
            raise TypeError(f""max-age: {morsel['max-age']} must be integer"")
    elif morsel[""expires""]:
        time_template = ""%a, %d-%b-%Y %H:%M:%S GMT""
        expires = calendar.timegm(time.strptime(morsel[""expires""], time_template))
    return create_cookie(
        comment=morsel[""comment""],
        comment_url=bool(morsel[""comment""]),
        discard=False,
        domain=morsel[""domain""],
        expires=expires,
        name=morsel.key,
        path=morsel[""path""],
        port=None,
        rest={""HttpOnly"": morsel[""httponly""]},
        rfc2109=False,
        secure=bool(morsel[""secure""]),
        value=morsel.value,
        version=morsel[""version""] or 0,
    )


def cookiejar_from_dict(cookie_dict, cookiejar=None, overwrite=True):
    
    if cookiejar is None:
        cookiejar = RequestsCookieJar()

    if cookie_dict is not None:
        names_from_jar = [cookie.name for cookie in cookiejar]
        for name in cookie_dict:
            if overwrite or (name not in names_from_jar):
                cookiejar.set_cookie(create_cookie(name, cookie_dict[name]))

    return cookiejar


def merge_cookies(cookiejar, cookies):
    
    if not isinstance(cookiejar, cookielib.CookieJar):
        raise ValueError(""You can only merge into CookieJar"")

    if isinstance(cookies, dict):
        cookiejar = cookiejar_from_dict(cookies, cookiejar=cookiejar, overwrite=False)
    elif isinstance(cookies, cookielib.CookieJar):
        try:
            cookiejar.update(cookies)
        except AttributeError:
            for cookie_in_jar in cookies:
                cookiejar.set_cookie(cookie_in_jar)

    return cookiejar


from pip._vendor.urllib3.exceptions import HTTPError as BaseHTTPError

from .compat import JSONDecodeError as CompatJSONDecodeError


class RequestException(IOError):
    

    def __init__(self, *args, **kwargs):
        
        response = kwargs.pop(""response"", None)
        self.response = response
        self.request = kwargs.pop(""request"", None)
        if response is not None and not self.request and hasattr(response, ""request""):
            self.request = self.response.request
        super().__init__(*args, **kwargs)


class InvalidJSONError(RequestException):
    


class JSONDecodeError(InvalidJSONError, CompatJSONDecodeError):
    

    def __init__(self, *args, **kwargs):
        
        CompatJSONDecodeError.__init__(self, *args)
        InvalidJSONError.__init__(self, *self.args, **kwargs)

    def __reduce__(self):
        
        return CompatJSONDecodeError.__reduce__(self)


class HTTPError(RequestException):
    


class ConnectionError(RequestException):
    


class ProxyError(ConnectionError):
    


class SSLError(ConnectionError):
    


class Timeout(RequestException):
    


class ConnectTimeout(ConnectionError, Timeout):
    


class ReadTimeout(Timeout):
    


class URLRequired(RequestException):
    


class TooManyRedirects(RequestException):
    


class MissingSchema(RequestException, ValueError):
    


class InvalidSchema(RequestException, ValueError):
    


class InvalidURL(RequestException, ValueError):
    


class InvalidHeader(RequestException, ValueError):
    


class InvalidProxyURL(InvalidURL):
    


class ChunkedEncodingError(RequestException):
    


class ContentDecodingError(RequestException, BaseHTTPError):
    


class StreamConsumedError(RequestException, TypeError):
    


class RetryError(RequestException):
    


class UnrewindableBodyError(RequestException):
    





class RequestsWarning(Warning):
    


class FileModeWarning(RequestsWarning, DeprecationWarning):
    


class RequestsDependencyWarning(RequestsWarning):
    



import json
import platform
import ssl
import sys

from pip._vendor import idna
from pip._vendor import urllib3

from . import __version__ as requests_version

charset_normalizer = None
chardet = None

try:
    from pip._vendor.urllib3.contrib import pyopenssl
except ImportError:
    pyopenssl = None
    OpenSSL = None
    cryptography = None
else:
    import cryptography
    import OpenSSL


def _implementation():
    
    implementation = platform.python_implementation()

    if implementation == ""CPython"":
        implementation_version = platform.python_version()
    elif implementation == ""PyPy"":
        implementation_version = ""{}.{}.{}"".format(
            sys.pypy_version_info.major,
            sys.pypy_version_info.minor,
            sys.pypy_version_info.micro,
        )
        if sys.pypy_version_info.releaselevel != ""final"":
            implementation_version = """".join(
                [implementation_version, sys.pypy_version_info.releaselevel]
            )
    elif implementation == ""Jython"":
        implementation_version = platform.python_version()  
    elif implementation == ""IronPython"":
        implementation_version = platform.python_version()  
    else:
        implementation_version = ""Unknown""

    return {""name"": implementation, ""version"": implementation_version}


def info():
    
    try:
        platform_info = {
            ""system"": platform.system(),
            ""release"": platform.release(),
        }
    except OSError:
        platform_info = {
            ""system"": ""Unknown"",
            ""release"": ""Unknown"",
        }

    implementation_info = _implementation()
    urllib3_info = {""version"": urllib3.__version__}
    charset_normalizer_info = {""version"": None}
    chardet_info = {""version"": None}
    if charset_normalizer:
        charset_normalizer_info = {""version"": charset_normalizer.__version__}
    if chardet:
        chardet_info = {""version"": chardet.__version__}

    pyopenssl_info = {
        ""version"": None,
        ""openssl_version"": """",
    }
    if OpenSSL:
        pyopenssl_info = {
            ""version"": OpenSSL.__version__,
            ""openssl_version"": f""{OpenSSL.SSL.OPENSSL_VERSION_NUMBER:x}"",
        }
    cryptography_info = {
        ""version"": getattr(cryptography, ""__version__"", """"),
    }
    idna_info = {
        ""version"": getattr(idna, ""__version__"", """"),
    }

    system_ssl = ssl.OPENSSL_VERSION_NUMBER
    system_ssl_info = {""version"": f""{system_ssl:x}"" if system_ssl is not None else """"}

    return {
        ""platform"": platform_info,
        ""implementation"": implementation_info,
        ""system_ssl"": system_ssl_info,
        ""using_pyopenssl"": pyopenssl is not None,
        ""using_charset_normalizer"": chardet is None,
        ""pyOpenSSL"": pyopenssl_info,
        ""urllib3"": urllib3_info,
        ""chardet"": chardet_info,
        ""charset_normalizer"": charset_normalizer_info,
        ""cryptography"": cryptography_info,
        ""idna"": idna_info,
        ""requests"": {
            ""version"": requests_version,
        },
    }


def main():
    
    print(json.dumps(info(), sort_keys=True, indent=2))


if __name__ == ""__main__"":
    main()


HOOKS = [""response""]


def default_hooks():
    return {event: [] for event in HOOKS}





def dispatch_hook(key, hooks, hook_data, **kwargs):
    
    hooks = hooks or {}
    hooks = hooks.get(key)
    if hooks:
        if hasattr(hooks, ""__call__""):
            hooks = [hooks]
        for hook in hooks:
            _hook_data = hook(hook_data, **kwargs)
            if _hook_data is not None:
                hook_data = _hook_data
    return hook_data



import datetime




import encodings.idna  
from io import UnsupportedOperation

from pip._vendor.urllib3.exceptions import (
    DecodeError,
    LocationParseError,
    ProtocolError,
    ReadTimeoutError,
    SSLError,
)
from pip._vendor.urllib3.fields import RequestField
from pip._vendor.urllib3.filepost import encode_multipart_formdata
from pip._vendor.urllib3.util import parse_url

from ._internal_utils import to_native_string, unicode_is_ascii
from .auth import HTTPBasicAuth
from .compat import (
    Callable,
    JSONDecodeError,
    Mapping,
    basestring,
    builtin_str,
    chardet,
    cookielib,
)
from .compat import json as complexjson
from .compat import urlencode, urlsplit, urlunparse
from .cookies import _copy_cookie_jar, cookiejar_from_dict, get_cookie_header
from .exceptions import (
    ChunkedEncodingError,
    ConnectionError,
    ContentDecodingError,
    HTTPError,
    InvalidJSONError,
    InvalidURL,
)
from .exceptions import JSONDecodeError as RequestsJSONDecodeError
from .exceptions import MissingSchema
from .exceptions import SSLError as RequestsSSLError
from .exceptions import StreamConsumedError
from .hooks import default_hooks
from .status_codes import codes
from .structures import CaseInsensitiveDict
from .utils import (
    check_header_validity,
    get_auth_from_url,
    guess_filename,
    guess_json_utf,
    iter_slices,
    parse_header_links,
    requote_uri,
    stream_decode_response_unicode,
    super_len,
    to_key_val_list,
)



REDIRECT_STATI = (
    codes.moved,  
    codes.found,  
    codes.other,  
    codes.temporary_redirect,  
    codes.permanent_redirect,  
)

DEFAULT_REDIRECT_LIMIT = 30
CONTENT_CHUNK_SIZE = 10 * 1024
ITER_CHUNK_SIZE = 512


class RequestEncodingMixin:
    @property
    def path_url(self):
        

        url = []

        p = urlsplit(self.url)

        path = p.path
        if not path:
            path = ""/""

        url.append(path)

        query = p.query
        if query:
            url.append(""?"")
            url.append(query)

        return """".join(url)

    @staticmethod
    def _encode_params(data):
        

        if isinstance(data, (str, bytes)):
            return data
        elif hasattr(data, ""read""):
            return data
        elif hasattr(data, ""__iter__""):
            result = []
            for k, vs in to_key_val_list(data):
                if isinstance(vs, basestring) or not hasattr(vs, ""__iter__""):
                    vs = [vs]
                for v in vs:
                    if v is not None:
                        result.append(
                            (
                                k.encode(""utf-8"") if isinstance(k, str) else k,
                                v.encode(""utf-8"") if isinstance(v, str) else v,
                            )
                        )
            return urlencode(result, doseq=True)
        else:
            return data

    @staticmethod
    def _encode_files(files, data):
        
        if not files:
            raise ValueError(""Files must be provided."")
        elif isinstance(data, basestring):
            raise ValueError(""Data must not be a string."")

        new_fields = []
        fields = to_key_val_list(data or {})
        files = to_key_val_list(files or {})

        for field, val in fields:
            if isinstance(val, basestring) or not hasattr(val, ""__iter__""):
                val = [val]
            for v in val:
                if v is not None:
                    
                    if not isinstance(v, bytes):
                        v = str(v)

                    new_fields.append(
                        (
                            field.decode(""utf-8"")
                            if isinstance(field, bytes)
                            else field,
                            v.encode(""utf-8"") if isinstance(v, str) else v,
                        )
                    )

        for k, v in files:
            
            ft = None
            fh = None
            if isinstance(v, (tuple, list)):
                if len(v) == 2:
                    fn, fp = v
                elif len(v) == 3:
                    fn, fp, ft = v
                else:
                    fn, fp, ft, fh = v
            else:
                fn = guess_filename(v) or k
                fp = v

            if isinstance(fp, (str, bytes, bytearray)):
                fdata = fp
            elif hasattr(fp, ""read""):
                fdata = fp.read()
            elif fp is None:
                continue
            else:
                fdata = fp

            rf = RequestField(name=k, data=fdata, filename=fn, headers=fh)
            rf.make_multipart(content_type=ft)
            new_fields.append(rf)

        body, content_type = encode_multipart_formdata(new_fields)

        return body, content_type


class RequestHooksMixin:
    def register_hook(self, event, hook):
        

        if event not in self.hooks:
            raise ValueError(f'Unsupported event specified, with event name ""{event}""')

        if isinstance(hook, Callable):
            self.hooks[event].append(hook)
        elif hasattr(hook, ""__iter__""):
            self.hooks[event].extend(h for h in hook if isinstance(h, Callable))

    def deregister_hook(self, event, hook):
        

        try:
            self.hooks[event].remove(hook)
            return True
        except ValueError:
            return False


class Request(RequestHooksMixin):
    

    def __init__(
        self,
        method=None,
        url=None,
        headers=None,
        files=None,
        data=None,
        params=None,
        auth=None,
        cookies=None,
        hooks=None,
        json=None,
    ):
        
        data = [] if data is None else data
        files = [] if files is None else files
        headers = {} if headers is None else headers
        params = {} if params is None else params
        hooks = {} if hooks is None else hooks

        self.hooks = default_hooks()
        for k, v in list(hooks.items()):
            self.register_hook(event=k, hook=v)

        self.method = method
        self.url = url
        self.headers = headers
        self.files = files
        self.data = data
        self.json = json
        self.params = params
        self.auth = auth
        self.cookies = cookies

    def __repr__(self):
        return f""<Request [{self.method}]>""

    def prepare(self):
        
        p = PreparedRequest()
        p.prepare(
            method=self.method,
            url=self.url,
            headers=self.headers,
            files=self.files,
            data=self.data,
            json=self.json,
            params=self.params,
            auth=self.auth,
            cookies=self.cookies,
            hooks=self.hooks,
        )
        return p


class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):
    

    def __init__(self):
        
        self.method = None
        
        self.url = None
        
        self.headers = None
        
        
        self._cookies = None
        
        self.body = None
        
        self.hooks = default_hooks()
        
        self._body_position = None

    def prepare(
        self,
        method=None,
        url=None,
        headers=None,
        files=None,
        data=None,
        params=None,
        auth=None,
        cookies=None,
        hooks=None,
        json=None,
    ):
        

        self.prepare_method(method)
        self.prepare_url(url, params)
        self.prepare_headers(headers)
        self.prepare_cookies(cookies)
        self.prepare_body(data, files, json)
        self.prepare_auth(auth, url)

        
        

        
        self.prepare_hooks(hooks)

    def __repr__(self):
        return f""<PreparedRequest [{self.method}]>""

    def copy(self):
        p = PreparedRequest()
        p.method = self.method
        p.url = self.url
        p.headers = self.headers.copy() if self.headers is not None else None
        p._cookies = _copy_cookie_jar(self._cookies)
        p.body = self.body
        p.hooks = self.hooks
        p._body_position = self._body_position
        return p

    def prepare_method(self, method):
        
        self.method = method
        if self.method is not None:
            self.method = to_native_string(self.method.upper())

    @staticmethod
    def _get_idna_encoded_host(host):
        from pip._vendor import idna

        try:
            host = idna.encode(host, uts46=True).decode(""utf-8"")
        except idna.IDNAError:
            raise UnicodeError
        return host

    def prepare_url(self, url, params):
        
        
        
        
        
        
        if isinstance(url, bytes):
            url = url.decode(""utf8"")
        else:
            url = str(url)

        
        url = url.lstrip()

        
        
        
        if "":"" in url and not url.lower().startswith(""http""):
            self.url = url
            return

        
        try:
            scheme, auth, host, port, path, query, fragment = parse_url(url)
        except LocationParseError as e:
            raise InvalidURL(*e.args)

        if not scheme:
            raise MissingSchema(
                f""Invalid URL {url!r}: No scheme supplied. ""
                f""Perhaps you meant https://{url}?""
            )

        if not host:
            raise InvalidURL(f""Invalid URL {url!r}: No host supplied"")

        
        
        
        
        if not unicode_is_ascii(host):
            try:
                host = self._get_idna_encoded_host(host)
            except UnicodeError:
                raise InvalidURL(""URL has an invalid label."")
        elif host.startswith((""*"", ""."")):
            raise InvalidURL(""URL has an invalid label."")

        
        netloc = auth or """"
        if netloc:
            netloc += ""@""
        netloc += host
        if port:
            netloc += f"":{port}""

        
        if not path:
            path = ""/""

        if isinstance(params, (str, bytes)):
            params = to_native_string(params)

        enc_params = self._encode_params(params)
        if enc_params:
            if query:
                query = f""{query}&{enc_params}""
            else:
                query = enc_params

        url = requote_uri(urlunparse([scheme, netloc, path, None, query, fragment]))
        self.url = url

    def prepare_headers(self, headers):
        

        self.headers = CaseInsensitiveDict()
        if headers:
            for header in headers.items():
                
                check_header_validity(header)
                name, value = header
                self.headers[to_native_string(name)] = value

    def prepare_body(self, data, files, json=None):
        

        
        

        
        body = None
        content_type = None

        if not data and json is not None:
            
            
            content_type = ""application/json""

            try:
                body = complexjson.dumps(json, allow_nan=False)
            except ValueError as ve:
                raise InvalidJSONError(ve, request=self)

            if not isinstance(body, bytes):
                body = body.encode(""utf-8"")

        is_stream = all(
            [
                hasattr(data, ""__iter__""),
                not isinstance(data, (basestring, list, tuple, Mapping)),
            ]
        )

        if is_stream:
            try:
                length = super_len(data)
            except (TypeError, AttributeError, UnsupportedOperation):
                length = None

            body = data

            if getattr(body, ""tell"", None) is not None:
                
                
                
                try:
                    self._body_position = body.tell()
                except OSError:
                    
                    
                    self._body_position = object()

            if files:
                raise NotImplementedError(
                    ""Streamed bodies and files are mutually exclusive.""
                )

            if length:
                self.headers[""Content-Length""] = builtin_str(length)
            else:
                self.headers[""Transfer-Encoding""] = ""chunked""
        else:
            
            if files:
                (body, content_type) = self._encode_files(files, data)
            else:
                if data:
                    body = self._encode_params(data)
                    if isinstance(data, basestring) or hasattr(data, ""read""):
                        content_type = None
                    else:
                        content_type = ""application/x-www-form-urlencoded""

            self.prepare_content_length(body)

            
            if content_type and (""content-type"" not in self.headers):
                self.headers[""Content-Type""] = content_type

        self.body = body

    def prepare_content_length(self, body):
        
        if body is not None:
            length = super_len(body)
            if length:
                
                
                self.headers[""Content-Length""] = builtin_str(length)
        elif (
            self.method not in (""GET"", ""HEAD"")
            and self.headers.get(""Content-Length"") is None
        ):
            
            
            self.headers[""Content-Length""] = ""0""

    def prepare_auth(self, auth, url=""""):
        

        
        if auth is None:
            url_auth = get_auth_from_url(self.url)
            auth = url_auth if any(url_auth) else None

        if auth:
            if isinstance(auth, tuple) and len(auth) == 2:
                
                auth = HTTPBasicAuth(*auth)

            
            r = auth(self)

            
            self.__dict__.update(r.__dict__)

            
            self.prepare_content_length(self.body)

    def prepare_cookies(self, cookies):
        
        if isinstance(cookies, cookielib.CookieJar):
            self._cookies = cookies
        else:
            self._cookies = cookiejar_from_dict(cookies)

        cookie_header = get_cookie_header(self._cookies, self)
        if cookie_header is not None:
            self.headers[""Cookie""] = cookie_header

    def prepare_hooks(self, hooks):
        
        
        
        
        hooks = hooks or []
        for event in hooks:
            self.register_hook(event, hooks[event])


class Response:
    

    __attrs__ = [
        ""_content"",
        ""status_code"",
        ""headers"",
        ""url"",
        ""history"",
        ""encoding"",
        ""reason"",
        ""cookies"",
        ""elapsed"",
        ""request"",
    ]

    def __init__(self):
        self._content = False
        self._content_consumed = False
        self._next = None

        
        self.status_code = None

        
        
        
        self.headers = CaseInsensitiveDict()

        
        
        
        self.raw = None

        
        self.url = None

        
        self.encoding = None

        
        
        
        self.history = []

        
        self.reason = None

        
        self.cookies = cookiejar_from_dict({})

        
        
        
        
        
        
        self.elapsed = datetime.timedelta(0)

        
        
        self.request = None

    def __enter__(self):
        return self

    def __exit__(self, *args):
        self.close()

    def __getstate__(self):
        
        
        if not self._content_consumed:
            self.content

        return {attr: getattr(self, attr, None) for attr in self.__attrs__}

    def __setstate__(self, state):
        for name, value in state.items():
            setattr(self, name, value)

        
        setattr(self, ""_content_consumed"", True)
        setattr(self, ""raw"", None)

    def __repr__(self):
        return f""<Response [{self.status_code}]>""

    def __bool__(self):
        
        return self.ok

    def __nonzero__(self):
        
        return self.ok

    def __iter__(self):
        
        return self.iter_content(128)

    @property
    def ok(self):
        
        try:
            self.raise_for_status()
        except HTTPError:
            return False
        return True

    @property
    def is_redirect(self):
        
        return ""location"" in self.headers and self.status_code in REDIRECT_STATI

    @property
    def is_permanent_redirect(self):
        
        return ""location"" in self.headers and self.status_code in (
            codes.moved_permanently,
            codes.permanent_redirect,
        )

    @property
    def next(self):
        
        return self._next

    @property
    def apparent_encoding(self):
        
        if chardet is not None:
            return chardet.detect(self.content)[""encoding""]
        else:
            
            
            return ""utf-8""

    def iter_content(self, chunk_size=1, decode_unicode=False):
        

        def generate():
            
            if hasattr(self.raw, ""stream""):
                try:
                    yield from self.raw.stream(chunk_size, decode_content=True)
                except ProtocolError as e:
                    raise ChunkedEncodingError(e)
                except DecodeError as e:
                    raise ContentDecodingError(e)
                except ReadTimeoutError as e:
                    raise ConnectionError(e)
                except SSLError as e:
                    raise RequestsSSLError(e)
            else:
                
                while True:
                    chunk = self.raw.read(chunk_size)
                    if not chunk:
                        break
                    yield chunk

            self._content_consumed = True

        if self._content_consumed and isinstance(self._content, bool):
            raise StreamConsumedError()
        elif chunk_size is not None and not isinstance(chunk_size, int):
            raise TypeError(
                f""chunk_size must be an int, it is instead a {type(chunk_size)}.""
            )
        
        reused_chunks = iter_slices(self._content, chunk_size)

        stream_chunks = generate()

        chunks = reused_chunks if self._content_consumed else stream_chunks

        if decode_unicode:
            chunks = stream_decode_response_unicode(chunks, self)

        return chunks

    def iter_lines(
        self, chunk_size=ITER_CHUNK_SIZE, decode_unicode=False, delimiter=None
    ):
        

        pending = None

        for chunk in self.iter_content(
            chunk_size=chunk_size, decode_unicode=decode_unicode
        ):
            if pending is not None:
                chunk = pending + chunk

            if delimiter:
                lines = chunk.split(delimiter)
            else:
                lines = chunk.splitlines()

            if lines and lines[-1] and chunk and lines[-1][-1] == chunk[-1]:
                pending = lines.pop()
            else:
                pending = None

            yield from lines

        if pending is not None:
            yield pending

    @property
    def content(self):
        

        if self._content is False:
            
            if self._content_consumed:
                raise RuntimeError(""The content for this response was already consumed"")

            if self.status_code == 0 or self.raw is None:
                self._content = None
            else:
                self._content = b"""".join(self.iter_content(CONTENT_CHUNK_SIZE)) or b""""

        self._content_consumed = True
        
        
        return self._content

    @property
    def text(self):
        

        
        content = None
        encoding = self.encoding

        if not self.content:
            return """"

        
        if self.encoding is None:
            encoding = self.apparent_encoding

        
        try:
            content = str(self.content, encoding, errors=""replace"")
        except (LookupError, TypeError):
            
            
            
            
            
            
            content = str(self.content, errors=""replace"")

        return content

    def json(self, **kwargs):
        r

        if not self.encoding and self.content and len(self.content) > 3:
            
            
            
            
            encoding = guess_json_utf(self.content)
            if encoding is not None:
                try:
                    return complexjson.loads(self.content.decode(encoding), **kwargs)
                except UnicodeDecodeError:
                    
                    
                    
                    
                    pass
                except JSONDecodeError as e:
                    raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)

        try:
            return complexjson.loads(self.text, **kwargs)
        except JSONDecodeError as e:
            
            
            raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)

    @property
    def links(self):
        

        header = self.headers.get(""link"")

        resolved_links = {}

        if header:
            links = parse_header_links(header)

            for link in links:
                key = link.get(""rel"") or link.get(""url"")
                resolved_links[key] = link

        return resolved_links

    def raise_for_status(self):
        

        http_error_msg = """"
        if isinstance(self.reason, bytes):
            
            
            
            
            try:
                reason = self.reason.decode(""utf-8"")
            except UnicodeDecodeError:
                reason = self.reason.decode(""iso-8859-1"")
        else:
            reason = self.reason

        if 400 <= self.status_code < 500:
            http_error_msg = (
                f""{self.status_code} Client Error: {reason} for url: {self.url}""
            )

        elif 500 <= self.status_code < 600:
            http_error_msg = (
                f""{self.status_code} Server Error: {reason} for url: {self.url}""
            )

        if http_error_msg:
            raise HTTPError(http_error_msg, response=self)

    def close(self):
        
        if not self._content_consumed:
            self.raw.close()

        release_conn = getattr(self.raw, ""release_conn"", None)
        if release_conn is not None:
            release_conn()

import sys

from .compat import chardet




for package in (""urllib3"", ""idna""):
    vendored_package = ""pip._vendor."" + package
    locals()[package] = __import__(vendored_package)
    
    
    for mod in list(sys.modules):
        if mod == vendored_package or mod.startswith(vendored_package + '.'):
            unprefixed_mod = mod[len(""pip._vendor.""):]
            sys.modules['pip._vendor.requests.packages.' + unprefixed_mod] = sys.modules[mod]

if chardet is not None:
    target = chardet.__name__
    for mod in list(sys.modules):
        if mod == target or mod.startswith(f""{target}.""):
            imported_mod = sys.modules[mod]
            sys.modules[f""requests.packages.{mod}""] = imported_mod
            mod = mod.replace(target, ""chardet"")
            sys.modules[f""requests.packages.{mod}""] = imported_mod


import os
import sys
import time
from collections import OrderedDict
from datetime import timedelta

from ._internal_utils import to_native_string
from .adapters import HTTPAdapter
from .auth import _basic_auth_str
from .compat import Mapping, cookielib, urljoin, urlparse
from .cookies import (
    RequestsCookieJar,
    cookiejar_from_dict,
    extract_cookies_to_jar,
    merge_cookies,
)
from .exceptions import (
    ChunkedEncodingError,
    ContentDecodingError,
    InvalidSchema,
    TooManyRedirects,
)
from .hooks import default_hooks, dispatch_hook


from .models import (  
    DEFAULT_REDIRECT_LIMIT,
    REDIRECT_STATI,
    PreparedRequest,
    Request,
)
from .status_codes import codes
from .structures import CaseInsensitiveDict
from .utils import (  
    DEFAULT_PORTS,
    default_headers,
    get_auth_from_url,
    get_environ_proxies,
    get_netrc_auth,
    requote_uri,
    resolve_proxies,
    rewind_body,
    should_bypass_proxies,
    to_key_val_list,
)


if sys.platform == ""win32"":
    preferred_clock = time.perf_counter
else:
    preferred_clock = time.time


def merge_setting(request_setting, session_setting, dict_class=OrderedDict):
    

    if session_setting is None:
        return request_setting

    if request_setting is None:
        return session_setting

    
    if not (
        isinstance(session_setting, Mapping) and isinstance(request_setting, Mapping)
    ):
        return request_setting

    merged_setting = dict_class(to_key_val_list(session_setting))
    merged_setting.update(to_key_val_list(request_setting))

    
    
    none_keys = [k for (k, v) in merged_setting.items() if v is None]
    for key in none_keys:
        del merged_setting[key]

    return merged_setting


def merge_hooks(request_hooks, session_hooks, dict_class=OrderedDict):
    
    if session_hooks is None or session_hooks.get(""response"") == []:
        return request_hooks

    if request_hooks is None or request_hooks.get(""response"") == []:
        return session_hooks

    return merge_setting(request_hooks, session_hooks, dict_class)


class SessionRedirectMixin:
    def get_redirect_target(self, resp):
        
        
        
        
        
        
        
        if resp.is_redirect:
            location = resp.headers[""location""]
            
            
            
            
            
            
            location = location.encode(""latin1"")
            return to_native_string(location, ""utf8"")
        return None

    def should_strip_auth(self, old_url, new_url):
        
        old_parsed = urlparse(old_url)
        new_parsed = urlparse(new_url)
        if old_parsed.hostname != new_parsed.hostname:
            return True
        
        
        
        
        if (
            old_parsed.scheme == ""http""
            and old_parsed.port in (80, None)
            and new_parsed.scheme == ""https""
            and new_parsed.port in (443, None)
        ):
            return False

        
        changed_port = old_parsed.port != new_parsed.port
        changed_scheme = old_parsed.scheme != new_parsed.scheme
        default_port = (DEFAULT_PORTS.get(old_parsed.scheme, None), None)
        if (
            not changed_scheme
            and old_parsed.port in default_port
            and new_parsed.port in default_port
        ):
            return False

        
        return changed_port or changed_scheme

    def resolve_redirects(
        self,
        resp,
        req,
        stream=False,
        timeout=None,
        verify=True,
        cert=None,
        proxies=None,
        yield_requests=False,
        **adapter_kwargs,
    ):
        

        hist = []  

        url = self.get_redirect_target(resp)
        previous_fragment = urlparse(req.url).fragment
        while url:
            prepared_request = req.copy()

            
            
            hist.append(resp)
            resp.history = hist[1:]

            try:
                resp.content  
            except (ChunkedEncodingError, ContentDecodingError, RuntimeError):
                resp.raw.read(decode_content=False)

            if len(resp.history) >= self.max_redirects:
                raise TooManyRedirects(
                    f""Exceeded {self.max_redirects} redirects."", response=resp
                )

            
            resp.close()

            
            if url.startswith(""//""):
                parsed_rurl = urlparse(resp.url)
                url = "":"".join([to_native_string(parsed_rurl.scheme), url])

            
            parsed = urlparse(url)
            if parsed.fragment == """" and previous_fragment:
                parsed = parsed._replace(fragment=previous_fragment)
            elif parsed.fragment:
                previous_fragment = parsed.fragment
            url = parsed.geturl()

            
            
            
            if not parsed.netloc:
                url = urljoin(resp.url, requote_uri(url))
            else:
                url = requote_uri(url)

            prepared_request.url = to_native_string(url)

            self.rebuild_method(prepared_request, resp)

            
            if resp.status_code not in (
                codes.temporary_redirect,
                codes.permanent_redirect,
            ):
                
                purged_headers = (""Content-Length"", ""Content-Type"", ""Transfer-Encoding"")
                for header in purged_headers:
                    prepared_request.headers.pop(header, None)
                prepared_request.body = None

            headers = prepared_request.headers
            headers.pop(""Cookie"", None)

            
            
            
            extract_cookies_to_jar(prepared_request._cookies, req, resp.raw)
            merge_cookies(prepared_request._cookies, self.cookies)
            prepared_request.prepare_cookies(prepared_request._cookies)

            
            proxies = self.rebuild_proxies(prepared_request, proxies)
            self.rebuild_auth(prepared_request, resp)

            
            
            
            rewindable = prepared_request._body_position is not None and (
                ""Content-Length"" in headers or ""Transfer-Encoding"" in headers
            )

            
            if rewindable:
                rewind_body(prepared_request)

            
            req = prepared_request

            if yield_requests:
                yield req
            else:
                resp = self.send(
                    req,
                    stream=stream,
                    timeout=timeout,
                    verify=verify,
                    cert=cert,
                    proxies=proxies,
                    allow_redirects=False,
                    **adapter_kwargs,
                )

                extract_cookies_to_jar(self.cookies, prepared_request, resp.raw)

                
                url = self.get_redirect_target(resp)
                yield resp

    def rebuild_auth(self, prepared_request, response):
        
        headers = prepared_request.headers
        url = prepared_request.url

        if ""Authorization"" in headers and self.should_strip_auth(
            response.request.url, url
        ):
            
            
            del headers[""Authorization""]

        
        new_auth = get_netrc_auth(url) if self.trust_env else None
        if new_auth is not None:
            prepared_request.prepare_auth(new_auth)

    def rebuild_proxies(self, prepared_request, proxies):
        
        headers = prepared_request.headers
        scheme = urlparse(prepared_request.url).scheme
        new_proxies = resolve_proxies(prepared_request, proxies, self.trust_env)

        if ""Proxy-Authorization"" in headers:
            del headers[""Proxy-Authorization""]

        try:
            username, password = get_auth_from_url(new_proxies[scheme])
        except KeyError:
            username, password = None, None

        
        
        if not scheme.startswith(""https"") and username and password:
            headers[""Proxy-Authorization""] = _basic_auth_str(username, password)

        return new_proxies

    def rebuild_method(self, prepared_request, response):
        
        method = prepared_request.method

        
        if response.status_code == codes.see_other and method != ""HEAD"":
            method = ""GET""

        
        
        if response.status_code == codes.found and method != ""HEAD"":
            method = ""GET""

        
        
        if response.status_code == codes.moved and method == ""POST"":
            method = ""GET""

        prepared_request.method = method


class Session(SessionRedirectMixin):
    

    __attrs__ = [
        ""headers"",
        ""cookies"",
        ""auth"",
        ""proxies"",
        ""hooks"",
        ""params"",
        ""verify"",
        ""cert"",
        ""adapters"",
        ""stream"",
        ""trust_env"",
        ""max_redirects"",
    ]

    def __init__(self):
        
        
        
        self.headers = default_headers()

        
        
        self.auth = None

        
        
        
        self.proxies = {}

        
        self.hooks = default_hooks()

        
        
        
        self.params = {}

        
        self.stream = False

        
        
        
        
        
        
        
        
        self.verify = True

        
        
        self.cert = None

        
        
        
        
        self.max_redirects = DEFAULT_REDIRECT_LIMIT

        
        
        self.trust_env = True

        
        
        
        
        self.cookies = cookiejar_from_dict({})

        
        self.adapters = OrderedDict()
        self.mount(""https://"", HTTPAdapter())
        self.mount(""http://"", HTTPAdapter())

    def __enter__(self):
        return self

    def __exit__(self, *args):
        self.close()

    def prepare_request(self, request):
        
        cookies = request.cookies or {}

        
        if not isinstance(cookies, cookielib.CookieJar):
            cookies = cookiejar_from_dict(cookies)

        
        merged_cookies = merge_cookies(
            merge_cookies(RequestsCookieJar(), self.cookies), cookies
        )

        
        auth = request.auth
        if self.trust_env and not auth and not self.auth:
            auth = get_netrc_auth(request.url)

        p = PreparedRequest()
        p.prepare(
            method=request.method.upper(),
            url=request.url,
            files=request.files,
            data=request.data,
            json=request.json,
            headers=merge_setting(
                request.headers, self.headers, dict_class=CaseInsensitiveDict
            ),
            params=merge_setting(request.params, self.params),
            auth=merge_setting(auth, self.auth),
            cookies=merged_cookies,
            hooks=merge_hooks(request.hooks, self.hooks),
        )
        return p

    def request(
        self,
        method,
        url,
        params=None,
        data=None,
        headers=None,
        cookies=None,
        files=None,
        auth=None,
        timeout=None,
        allow_redirects=True,
        proxies=None,
        hooks=None,
        stream=None,
        verify=None,
        cert=None,
        json=None,
    ):
        
        
        req = Request(
            method=method.upper(),
            url=url,
            headers=headers,
            files=files,
            data=data or {},
            json=json,
            params=params or {},
            auth=auth,
            cookies=cookies,
            hooks=hooks,
        )
        prep = self.prepare_request(req)

        proxies = proxies or {}

        settings = self.merge_environment_settings(
            prep.url, proxies, stream, verify, cert
        )

        
        send_kwargs = {
            ""timeout"": timeout,
            ""allow_redirects"": allow_redirects,
        }
        send_kwargs.update(settings)
        resp = self.send(prep, **send_kwargs)

        return resp

    def get(self, url, **kwargs):
        r

        kwargs.setdefault(""allow_redirects"", True)
        return self.request(""GET"", url, **kwargs)

    def options(self, url, **kwargs):
        r

        kwargs.setdefault(""allow_redirects"", True)
        return self.request(""OPTIONS"", url, **kwargs)

    def head(self, url, **kwargs):
        r

        kwargs.setdefault(""allow_redirects"", False)
        return self.request(""HEAD"", url, **kwargs)

    def post(self, url, data=None, json=None, **kwargs):
        r

        return self.request(""POST"", url, data=data, json=json, **kwargs)

    def put(self, url, data=None, **kwargs):
        r

        return self.request(""PUT"", url, data=data, **kwargs)

    def patch(self, url, data=None, **kwargs):
        r

        return self.request(""PATCH"", url, data=data, **kwargs)

    def delete(self, url, **kwargs):
        r

        return self.request(""DELETE"", url, **kwargs)

    def send(self, request, **kwargs):
        
        
        
        kwargs.setdefault(""stream"", self.stream)
        kwargs.setdefault(""verify"", self.verify)
        kwargs.setdefault(""cert"", self.cert)
        if ""proxies"" not in kwargs:
            kwargs[""proxies""] = resolve_proxies(request, self.proxies, self.trust_env)

        
        
        if isinstance(request, Request):
            raise ValueError(""You can only send PreparedRequests."")

        
        allow_redirects = kwargs.pop(""allow_redirects"", True)
        stream = kwargs.get(""stream"")
        hooks = request.hooks

        
        adapter = self.get_adapter(url=request.url)

        
        start = preferred_clock()

        
        r = adapter.send(request, **kwargs)

        
        elapsed = preferred_clock() - start
        r.elapsed = timedelta(seconds=elapsed)

        
        r = dispatch_hook(""response"", hooks, r, **kwargs)

        
        if r.history:
            
            for resp in r.history:
                extract_cookies_to_jar(self.cookies, resp.request, resp.raw)

        extract_cookies_to_jar(self.cookies, request, r.raw)

        
        if allow_redirects:
            
            gen = self.resolve_redirects(r, request, **kwargs)
            history = [resp for resp in gen]
        else:
            history = []

        
        if history:
            
            history.insert(0, r)
            
            r = history.pop()
            r.history = history

        
        if not allow_redirects:
            try:
                r._next = next(
                    self.resolve_redirects(r, request, yield_requests=True, **kwargs)
                )
            except StopIteration:
                pass

        if not stream:
            r.content

        return r

    def merge_environment_settings(self, url, proxies, stream, verify, cert):
        
        
        if self.trust_env:
            
            no_proxy = proxies.get(""no_proxy"") if proxies is not None else None
            env_proxies = get_environ_proxies(url, no_proxy=no_proxy)
            for k, v in env_proxies.items():
                proxies.setdefault(k, v)

            
            
            if verify is True or verify is None:
                verify = (
                    os.environ.get(""REQUESTS_CA_BUNDLE"")
                    or os.environ.get(""CURL_CA_BUNDLE"")
                    or verify
                )

        
        proxies = merge_setting(proxies, self.proxies)
        stream = merge_setting(stream, self.stream)
        verify = merge_setting(verify, self.verify)
        cert = merge_setting(cert, self.cert)

        return {""proxies"": proxies, ""stream"": stream, ""verify"": verify, ""cert"": cert}

    def get_adapter(self, url):
        
        for prefix, adapter in self.adapters.items():
            if url.lower().startswith(prefix.lower()):
                return adapter

        
        raise InvalidSchema(f""No connection adapters were found for {url!r}"")

    def close(self):
        
        for v in self.adapters.values():
            v.close()

    def mount(self, prefix, adapter):
        
        self.adapters[prefix] = adapter
        keys_to_move = [k for k in self.adapters if len(k) < len(prefix)]

        for key in keys_to_move:
            self.adapters[key] = self.adapters.pop(key)

    def __getstate__(self):
        state = {attr: getattr(self, attr, None) for attr in self.__attrs__}
        return state

    def __setstate__(self, state):
        for attr, value in state.items():
            setattr(self, attr, value)


def session():
    
    return Session()

r

from .structures import LookupDict

_codes = {
    
    100: (""continue"",),
    101: (""switching_protocols"",),
    102: (""processing"", ""early-hints""),
    103: (""checkpoint"",),
    122: (""uri_too_long"", ""request_uri_too_long""),
    200: (""ok"", ""okay"", ""all_ok"", ""all_okay"", ""all_good"", ""\\o/"", ""✓""),
    201: (""created"",),
    202: (""accepted"",),
    203: (""non_authoritative_info"", ""non_authoritative_information""),
    204: (""no_content"",),
    205: (""reset_content"", ""reset""),
    206: (""partial_content"", ""partial""),
    207: (""multi_status"", ""multiple_status"", ""multi_stati"", ""multiple_stati""),
    208: (""already_reported"",),
    226: (""im_used"",),
    
    300: (""multiple_choices"",),
    301: (""moved_permanently"", ""moved"", ""\\o-""),
    302: (""found"",),
    303: (""see_other"", ""other""),
    304: (""not_modified"",),
    305: (""use_proxy"",),
    306: (""switch_proxy"",),
    307: (""temporary_redirect"", ""temporary_moved"", ""temporary""),
    308: (
        ""permanent_redirect"",
        ""resume_incomplete"",
        ""resume"",
    ),  
    
    400: (""bad_request"", ""bad""),
    401: (""unauthorized"",),
    402: (""payment_required"", ""payment""),
    403: (""forbidden"",),
    404: (""not_found"", ""-o-""),
    405: (""method_not_allowed"", ""not_allowed""),
    406: (""not_acceptable"",),
    407: (""proxy_authentication_required"", ""proxy_auth"", ""proxy_authentication""),
    408: (""request_timeout"", ""timeout""),
    409: (""conflict"",),
    410: (""gone"",),
    411: (""length_required"",),
    412: (""precondition_failed"", ""precondition""),
    413: (""request_entity_too_large"", ""content_too_large""),
    414: (""request_uri_too_large"", ""uri_too_long""),
    415: (""unsupported_media_type"", ""unsupported_media"", ""media_type""),
    416: (
        ""requested_range_not_satisfiable"",
        ""requested_range"",
        ""range_not_satisfiable"",
    ),
    417: (""expectation_failed"",),
    418: (""im_a_teapot"", ""teapot"", ""i_am_a_teapot""),
    421: (""misdirected_request"",),
    422: (""unprocessable_entity"", ""unprocessable"", ""unprocessable_content""),
    423: (""locked"",),
    424: (""failed_dependency"", ""dependency""),
    425: (""unordered_collection"", ""unordered"", ""too_early""),
    426: (""upgrade_required"", ""upgrade""),
    428: (""precondition_required"", ""precondition""),
    429: (""too_many_requests"", ""too_many""),
    431: (""header_fields_too_large"", ""fields_too_large""),
    444: (""no_response"", ""none""),
    449: (""retry_with"", ""retry""),
    450: (""blocked_by_windows_parental_controls"", ""parental_controls""),
    451: (""unavailable_for_legal_reasons"", ""legal_reasons""),
    499: (""client_closed_request"",),
    
    500: (""internal_server_error"", ""server_error"", ""/o\\"", ""✗""),
    501: (""not_implemented"",),
    502: (""bad_gateway"",),
    503: (""service_unavailable"", ""unavailable""),
    504: (""gateway_timeout"",),
    505: (""http_version_not_supported"", ""http_version""),
    506: (""variant_also_negotiates"",),
    507: (""insufficient_storage"",),
    509: (""bandwidth_limit_exceeded"", ""bandwidth""),
    510: (""not_extended"",),
    511: (""network_authentication_required"", ""network_auth"", ""network_authentication""),
}

codes = LookupDict(name=""status_codes"")


def _init():
    for code, titles in _codes.items():
        for title in titles:
            setattr(codes, title, code)
            if not title.startswith((""\\"", ""/"")):
                setattr(codes, title.upper(), code)

    def doc(code):
        names = "", "".join(f""``{n}``"" for n in _codes[code])
        return ""* %d: %s"" % (code, names)

    global __doc__
    __doc__ = (
        __doc__ + ""\n"" + ""\n"".join(doc(code) for code in sorted(_codes))
        if __doc__ is not None
        else None
    )


_init()



from collections import OrderedDict

from .compat import Mapping, MutableMapping


class CaseInsensitiveDict(MutableMapping):
    

    def __init__(self, data=None, **kwargs):
        self._store = OrderedDict()
        if data is None:
            data = {}
        self.update(data, **kwargs)

    def __setitem__(self, key, value):
        
        
        self._store[key.lower()] = (key, value)

    def __getitem__(self, key):
        return self._store[key.lower()][1]

    def __delitem__(self, key):
        del self._store[key.lower()]

    def __iter__(self):
        return (casedkey for casedkey, mappedvalue in self._store.values())

    def __len__(self):
        return len(self._store)

    def lower_items(self):
        
        return ((lowerkey, keyval[1]) for (lowerkey, keyval) in self._store.items())

    def __eq__(self, other):
        if isinstance(other, Mapping):
            other = CaseInsensitiveDict(other)
        else:
            return NotImplemented
        
        return dict(self.lower_items()) == dict(other.lower_items())

    
    def copy(self):
        return CaseInsensitiveDict(self._store.values())

    def __repr__(self):
        return str(dict(self.items()))


class LookupDict(dict):
    

    def __init__(self, name=None):
        self.name = name
        super().__init__()

    def __repr__(self):
        return f""<lookup '{self.name}'>""

    def __getitem__(self, key):
        

        return self.__dict__.get(key, None)

    def get(self, key, default=None):
        return self.__dict__.get(key, default)



import codecs
import contextlib
import io
import os
import re
import socket
import struct
import sys
import tempfile
import warnings
import zipfile
from collections import OrderedDict

from pip._vendor.urllib3.util import make_headers, parse_url

from . import certs
from .__version__ import __version__


from ._internal_utils import (  
    _HEADER_VALIDATORS_BYTE,
    _HEADER_VALIDATORS_STR,
    HEADER_VALIDATORS,
    to_native_string,
)
from .compat import (
    Mapping,
    basestring,
    bytes,
    getproxies,
    getproxies_environment,
    integer_types,
    is_urllib3_1,
)
from .compat import parse_http_list as _parse_list_header
from .compat import (
    proxy_bypass,
    proxy_bypass_environment,
    quote,
    str,
    unquote,
    urlparse,
    urlunparse,
)
from .cookies import cookiejar_from_dict
from .exceptions import (
    FileModeWarning,
    InvalidHeader,
    InvalidURL,
    UnrewindableBodyError,
)
from .structures import CaseInsensitiveDict

NETRC_FILES = ("".netrc"", ""_netrc"")

DEFAULT_CA_BUNDLE_PATH = certs.where()

DEFAULT_PORTS = {""http"": 80, ""https"": 443}


DEFAULT_ACCEPT_ENCODING = "", "".join(
    re.split(r"",\s*"", make_headers(accept_encoding=True)[""accept-encoding""])
)


if sys.platform == ""win32"":
    

    def proxy_bypass_registry(host):
        try:
            import winreg
        except ImportError:
            return False

        try:
            internetSettings = winreg.OpenKey(
                winreg.HKEY_CURRENT_USER,
                r""Software\Microsoft\Windows\CurrentVersion\Internet Settings"",
            )
            
            proxyEnable = int(winreg.QueryValueEx(internetSettings, ""ProxyEnable"")[0])
            
            proxyOverride = winreg.QueryValueEx(internetSettings, ""ProxyOverride"")[0]
        except (OSError, ValueError):
            return False
        if not proxyEnable or not proxyOverride:
            return False

        
        
        
        proxyOverride = proxyOverride.split("";"")
        
        proxyOverride = filter(None, proxyOverride)
        
        for test in proxyOverride:
            if test == ""<local>"":
                if ""."" not in host:
                    return True
            test = test.replace(""."", r""\."")  
            test = test.replace(""*"", r"".*"")  
            test = test.replace(""?"", r""."")  
            if re.match(test, host, re.I):
                return True
        return False

    def proxy_bypass(host):  
        
        if getproxies_environment():
            return proxy_bypass_environment(host)
        else:
            return proxy_bypass_registry(host)


def dict_to_sequence(d):
    

    if hasattr(d, ""items""):
        d = d.items()

    return d


def super_len(o):
    total_length = None
    current_position = 0

    if not is_urllib3_1 and isinstance(o, str):
        
        
        o = o.encode(""utf-8"")

    if hasattr(o, ""__len__""):
        total_length = len(o)

    elif hasattr(o, ""len""):
        total_length = o.len

    elif hasattr(o, ""fileno""):
        try:
            fileno = o.fileno()
        except (io.UnsupportedOperation, AttributeError):
            
            
            
            pass
        else:
            total_length = os.fstat(fileno).st_size

            
            
            if ""b"" not in o.mode:
                warnings.warn(
                    (
                        ""Requests has determined the content-length for this ""
                        ""request using the binary size of the file: however, the ""
                        ""file has been opened in text mode (i.e. without the 'b' ""
                        ""flag in the mode). This may lead to an incorrect ""
                        ""content-length. In Requests 3.0, support will be removed ""
                        ""for files in text mode.""
                    ),
                    FileModeWarning,
                )

    if hasattr(o, ""tell""):
        try:
            current_position = o.tell()
        except OSError:
            
            
            
            
            if total_length is not None:
                current_position = total_length
        else:
            if hasattr(o, ""seek"") and total_length is None:
                
                try:
                    
                    o.seek(0, 2)
                    total_length = o.tell()

                    
                    
                    o.seek(current_position or 0)
                except OSError:
                    total_length = 0

    if total_length is None:
        total_length = 0

    return max(0, total_length - current_position)


def get_netrc_auth(url, raise_errors=False):
    

    netrc_file = os.environ.get(""NETRC"")
    if netrc_file is not None:
        netrc_locations = (netrc_file,)
    else:
        netrc_locations = (f""~/{f}"" for f in NETRC_FILES)

    try:
        from netrc import NetrcParseError, netrc

        netrc_path = None

        for f in netrc_locations:
            loc = os.path.expanduser(f)
            if os.path.exists(loc):
                netrc_path = loc
                break

        
        if netrc_path is None:
            return

        ri = urlparse(url)
        host = ri.hostname

        try:
            _netrc = netrc(netrc_path).authenticators(host)
            if _netrc:
                
                login_i = 0 if _netrc[0] else 1
                return (_netrc[login_i], _netrc[2])
        except (NetrcParseError, OSError):
            
            
            if raise_errors:
                raise

    
    except (ImportError, AttributeError):
        pass


def guess_filename(obj):
    
    name = getattr(obj, ""name"", None)
    if name and isinstance(name, basestring) and name[0] != ""<"" and name[-1] != "">"":
        return os.path.basename(name)


def extract_zipped_paths(path):
    
    if os.path.exists(path):
        
        return path

    
    
    archive, member = os.path.split(path)
    while archive and not os.path.exists(archive):
        archive, prefix = os.path.split(archive)
        if not prefix:
            
            
            break
        member = ""/"".join([prefix, member])

    if not zipfile.is_zipfile(archive):
        return path

    zip_file = zipfile.ZipFile(archive)
    if member not in zip_file.namelist():
        return path

    
    tmp = tempfile.gettempdir()
    extracted_path = os.path.join(tmp, member.split(""/"")[-1])
    if not os.path.exists(extracted_path):
        
        with atomic_open(extracted_path) as file_handler:
            file_handler.write(zip_file.read(member))
    return extracted_path


@contextlib.contextmanager
def atomic_open(filename):
    
    tmp_descriptor, tmp_name = tempfile.mkstemp(dir=os.path.dirname(filename))
    try:
        with os.fdopen(tmp_descriptor, ""wb"") as tmp_handler:
            yield tmp_handler
        os.replace(tmp_name, filename)
    except BaseException:
        os.remove(tmp_name)
        raise


def from_key_val_list(value):
    
    if value is None:
        return None

    if isinstance(value, (str, bytes, bool, int)):
        raise ValueError(""cannot encode objects that are not 2-tuples"")

    return OrderedDict(value)


def to_key_val_list(value):
    
    if value is None:
        return None

    if isinstance(value, (str, bytes, bool, int)):
        raise ValueError(""cannot encode objects that are not 2-tuples"")

    if isinstance(value, Mapping):
        value = value.items()

    return list(value)



def parse_list_header(value):
    
    result = []
    for item in _parse_list_header(value):
        if item[:1] == item[-1:] == '""':
            item = unquote_header_value(item[1:-1])
        result.append(item)
    return result



def parse_dict_header(value):
    
    result = {}
    for item in _parse_list_header(value):
        if ""="" not in item:
            result[item] = None
            continue
        name, value = item.split(""="", 1)
        if value[:1] == value[-1:] == '""':
            value = unquote_header_value(value[1:-1])
        result[name] = value
    return result



def unquote_header_value(value, is_filename=False):
    r
    if value and value[0] == value[-1] == '""':
        
        
        
        
        value = value[1:-1]

        
        
        
        
        
        if not is_filename or value[:2] != ""\\\\"":
            return value.replace(""\\\\"", ""\\"").replace('\\""', '""')
    return value


def dict_from_cookiejar(cj):
    

    cookie_dict = {cookie.name: cookie.value for cookie in cj}
    return cookie_dict


def add_dict_to_cookiejar(cj, cookie_dict):
    

    return cookiejar_from_dict(cookie_dict, cj)


def get_encodings_from_content(content):
    
    warnings.warn(
        (
            ""In requests 3.0, get_encodings_from_content will be removed. For ""
            ""more information, please see the discussion on issue 
            "" warning should only appear once.)""
        ),
        DeprecationWarning,
    )

    charset_re = re.compile(r'<meta.*?charset=[""\']*(.+?)[""\'>]', flags=re.I)
    pragma_re = re.compile(r'<meta.*?content=[""\']*;?charset=(.+?)[""\'>]', flags=re.I)
    xml_re = re.compile(r'^<\?xml.*?encoding=[""\']*(.+?)[""\'>]')

    return (
        charset_re.findall(content)
        + pragma_re.findall(content)
        + xml_re.findall(content)
    )


def _parse_content_type_header(header):
    

    tokens = header.split("";"")
    content_type, params = tokens[0].strip(), tokens[1:]
    params_dict = {}
    items_to_strip = ""\""' ""

    for param in params:
        param = param.strip()
        if param:
            key, value = param, True
            index_of_equals = param.find(""="")
            if index_of_equals != -1:
                key = param[:index_of_equals].strip(items_to_strip)
                value = param[index_of_equals + 1 :].strip(items_to_strip)
            params_dict[key.lower()] = value
    return content_type, params_dict


def get_encoding_from_headers(headers):
    

    content_type = headers.get(""content-type"")

    if not content_type:
        return None

    content_type, params = _parse_content_type_header(content_type)

    if ""charset"" in params:
        return params[""charset""].strip(""'\"""")

    if ""text"" in content_type:
        return ""ISO-8859-1""

    if ""application/json"" in content_type:
        
        return ""utf-8""


def stream_decode_response_unicode(iterator, r):
    

    if r.encoding is None:
        yield from iterator
        return

    decoder = codecs.getincrementaldecoder(r.encoding)(errors=""replace"")
    for chunk in iterator:
        rv = decoder.decode(chunk)
        if rv:
            yield rv
    rv = decoder.decode(b"""", final=True)
    if rv:
        yield rv


def iter_slices(string, slice_length):
    
    pos = 0
    if slice_length is None or slice_length <= 0:
        slice_length = len(string)
    while pos < len(string):
        yield string[pos : pos + slice_length]
        pos += slice_length


def get_unicode_from_response(r):
    
    warnings.warn(
        (
            ""In requests 3.0, get_unicode_from_response will be removed. For ""
            ""more information, please see the discussion on issue 
            "" warning should only appear once.)""
        ),
        DeprecationWarning,
    )

    tried_encodings = []

    
    encoding = get_encoding_from_headers(r.headers)

    if encoding:
        try:
            return str(r.content, encoding)
        except UnicodeError:
            tried_encodings.append(encoding)

    
    try:
        return str(r.content, encoding, errors=""replace"")
    except TypeError:
        return r.content



UNRESERVED_SET = frozenset(
    ""ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz"" + ""0123456789-._~""
)


def unquote_unreserved(uri):
    
    parts = uri.split(""%"")
    for i in range(1, len(parts)):
        h = parts[i][0:2]
        if len(h) == 2 and h.isalnum():
            try:
                c = chr(int(h, 16))
            except ValueError:
                raise InvalidURL(f""Invalid percent-escape sequence: '{h}'"")

            if c in UNRESERVED_SET:
                parts[i] = c + parts[i][2:]
            else:
                parts[i] = f""%{parts[i]}""
        else:
            parts[i] = f""%{parts[i]}""
    return """".join(parts)


def requote_uri(uri):
    
    safe_with_percent = ""!
    safe_without_percent = ""!
    try:
        
        
        
        return quote(unquote_unreserved(uri), safe=safe_with_percent)
    except InvalidURL:
        
        
        
        return quote(uri, safe=safe_without_percent)


def address_in_network(ip, net):
    
    ipaddr = struct.unpack(""=L"", socket.inet_aton(ip))[0]
    netaddr, bits = net.split(""/"")
    netmask = struct.unpack(""=L"", socket.inet_aton(dotted_netmask(int(bits))))[0]
    network = struct.unpack(""=L"", socket.inet_aton(netaddr))[0] & netmask
    return (ipaddr & netmask) == (network & netmask)


def dotted_netmask(mask):
    
    bits = 0xFFFFFFFF ^ (1 << 32 - mask) - 1
    return socket.inet_ntoa(struct.pack("">I"", bits))


def is_ipv4_address(string_ip):
    
    try:
        socket.inet_aton(string_ip)
    except OSError:
        return False
    return True


def is_valid_cidr(string_network):
    
    if string_network.count(""/"") == 1:
        try:
            mask = int(string_network.split(""/"")[1])
        except ValueError:
            return False

        if mask < 1 or mask > 32:
            return False

        try:
            socket.inet_aton(string_network.split(""/"")[0])
        except OSError:
            return False
    else:
        return False
    return True


@contextlib.contextmanager
def set_environ(env_name, value):
    
    value_changed = value is not None
    if value_changed:
        old_value = os.environ.get(env_name)
        os.environ[env_name] = value
    try:
        yield
    finally:
        if value_changed:
            if old_value is None:
                del os.environ[env_name]
            else:
                os.environ[env_name] = old_value


def should_bypass_proxies(url, no_proxy):
    

    
    
    def get_proxy(key):
        return os.environ.get(key) or os.environ.get(key.upper())

    
    
    no_proxy_arg = no_proxy
    if no_proxy is None:
        no_proxy = get_proxy(""no_proxy"")
    parsed = urlparse(url)

    if parsed.hostname is None:
        
        return True

    if no_proxy:
        
        
        no_proxy = (host for host in no_proxy.replace("" "", """").split("","") if host)

        if is_ipv4_address(parsed.hostname):
            for proxy_ip in no_proxy:
                if is_valid_cidr(proxy_ip):
                    if address_in_network(parsed.hostname, proxy_ip):
                        return True
                elif parsed.hostname == proxy_ip:
                    
                    
                    return True
        else:
            host_with_port = parsed.hostname
            if parsed.port:
                host_with_port += f"":{parsed.port}""

            for host in no_proxy:
                if parsed.hostname.endswith(host) or host_with_port.endswith(host):
                    
                    
                    return True

    with set_environ(""no_proxy"", no_proxy_arg):
        
        try:
            bypass = proxy_bypass(parsed.hostname)
        except (TypeError, socket.gaierror):
            bypass = False

    if bypass:
        return True

    return False


def get_environ_proxies(url, no_proxy=None):
    
    if should_bypass_proxies(url, no_proxy=no_proxy):
        return {}
    else:
        return getproxies()


def select_proxy(url, proxies):
    
    proxies = proxies or {}
    urlparts = urlparse(url)
    if urlparts.hostname is None:
        return proxies.get(urlparts.scheme, proxies.get(""all""))

    proxy_keys = [
        urlparts.scheme + ""://"" + urlparts.hostname,
        urlparts.scheme,
        ""all://"" + urlparts.hostname,
        ""all"",
    ]
    proxy = None
    for proxy_key in proxy_keys:
        if proxy_key in proxies:
            proxy = proxies[proxy_key]
            break

    return proxy


def resolve_proxies(request, proxies, trust_env=True):
    
    proxies = proxies if proxies is not None else {}
    url = request.url
    scheme = urlparse(url).scheme
    no_proxy = proxies.get(""no_proxy"")
    new_proxies = proxies.copy()

    if trust_env and not should_bypass_proxies(url, no_proxy=no_proxy):
        environ_proxies = get_environ_proxies(url, no_proxy=no_proxy)

        proxy = environ_proxies.get(scheme, environ_proxies.get(""all""))

        if proxy:
            new_proxies.setdefault(scheme, proxy)
    return new_proxies


def default_user_agent(name=""python-requests""):
    
    return f""{name}/{__version__}""


def default_headers():
    
    return CaseInsensitiveDict(
        {
            ""User-Agent"": default_user_agent(),
            ""Accept-Encoding"": DEFAULT_ACCEPT_ENCODING,
            ""Accept"": ""*/*"",
            ""Connection"": ""keep-alive"",
        }
    )


def parse_header_links(value):
    

    links = []

    replace_chars = "" '\""""

    value = value.strip(replace_chars)
    if not value:
        return links

    for val in re.split("", *<"", value):
        try:
            url, params = val.split("";"", 1)
        except ValueError:
            url, params = val, """"

        link = {""url"": url.strip(""<> '\"""")}

        for param in params.split("";""):
            try:
                key, value = param.split(""="")
            except ValueError:
                break

            link[key.strip(replace_chars)] = value.strip(replace_chars)

        links.append(link)

    return links



_null = ""\x00"".encode(""ascii"")  
_null2 = _null * 2
_null3 = _null * 3


def guess_json_utf(data):
    
    
    
    
    sample = data[:4]
    if sample in (codecs.BOM_UTF32_LE, codecs.BOM_UTF32_BE):
        return ""utf-32""  
    if sample[:3] == codecs.BOM_UTF8:
        return ""utf-8-sig""  
    if sample[:2] in (codecs.BOM_UTF16_LE, codecs.BOM_UTF16_BE):
        return ""utf-16""  
    nullcount = sample.count(_null)
    if nullcount == 0:
        return ""utf-8""
    if nullcount == 2:
        if sample[::2] == _null2:  
            return ""utf-16-be""
        if sample[1::2] == _null2:  
            return ""utf-16-le""
        
    if nullcount == 3:
        if sample[:3] == _null3:
            return ""utf-32-be""
        if sample[1:] == _null3:
            return ""utf-32-le""
        
    return None


def prepend_scheme_if_needed(url, new_scheme):
    
    parsed = parse_url(url)
    scheme, auth, host, port, path, query, fragment = parsed

    
    
    
    
    netloc = parsed.netloc
    if not netloc:
        netloc, path = path, netloc

    if auth:
        
        
        netloc = ""@"".join([auth, netloc])
    if scheme is None:
        scheme = new_scheme
    if path is None:
        path = """"

    return urlunparse((scheme, netloc, path, """", query, fragment))


def get_auth_from_url(url):
    
    parsed = urlparse(url)

    try:
        auth = (unquote(parsed.username), unquote(parsed.password))
    except (AttributeError, TypeError):
        auth = ("""", """")

    return auth


def check_header_validity(header):
    
    name, value = header
    _validate_header_part(header, name, 0)
    _validate_header_part(header, value, 1)


def _validate_header_part(header, header_part, header_validator_index):
    if isinstance(header_part, str):
        validator = _HEADER_VALIDATORS_STR[header_validator_index]
    elif isinstance(header_part, bytes):
        validator = _HEADER_VALIDATORS_BYTE[header_validator_index]
    else:
        raise InvalidHeader(
            f""Header part ({header_part!r}) from {header} ""
            f""must be of type str or bytes, not {type(header_part)}""
        )

    if not validator.match(header_part):
        header_kind = ""name"" if header_validator_index == 0 else ""value""
        raise InvalidHeader(
            f""Invalid leading whitespace, reserved character(s), or return ""
            f""character(s) in header {header_kind}: {header_part!r}""
        )


def urldefragauth(url):
    
    scheme, netloc, path, params, query, fragment = urlparse(url)

    
    if not netloc:
        netloc, path = path, netloc

    netloc = netloc.rsplit(""@"", 1)[-1]

    return urlunparse((scheme, netloc, path, params, query, """"))


def rewind_body(prepared_request):
    
    body_seek = getattr(prepared_request.body, ""seek"", None)
    if body_seek is not None and isinstance(
        prepared_request._body_position, integer_types
    ):
        try:
            body_seek(prepared_request._body_position)
        except OSError:
            raise UnrewindableBodyError(
                ""An error occurred when rewinding request body for redirect.""
            )
    else:
        raise UnrewindableBodyError(""Unable to rewind request body for redirect."")


import re

from .compat import builtin_str

_VALID_HEADER_NAME_RE_BYTE = re.compile(rb""^[^:\s][^:\r\n]*$"")
_VALID_HEADER_NAME_RE_STR = re.compile(r""^[^:\s][^:\r\n]*$"")
_VALID_HEADER_VALUE_RE_BYTE = re.compile(rb""^\S[^\r\n]*$|^$"")
_VALID_HEADER_VALUE_RE_STR = re.compile(r""^\S[^\r\n]*$|^$"")

_HEADER_VALIDATORS_STR = (_VALID_HEADER_NAME_RE_STR, _VALID_HEADER_VALUE_RE_STR)
_HEADER_VALIDATORS_BYTE = (_VALID_HEADER_NAME_RE_BYTE, _VALID_HEADER_VALUE_RE_BYTE)
HEADER_VALIDATORS = {
    bytes: _HEADER_VALIDATORS_BYTE,
    str: _HEADER_VALIDATORS_STR,
}


def to_native_string(string, encoding=""ascii""):
    
    if isinstance(string, builtin_str):
        out = string
    else:
        out = string.decode(encoding)

    return out


def unicode_is_ascii(u_string):
    
    assert isinstance(u_string, str)
    try:
        u_string.encode(""ascii"")
        return True
    except UnicodeEncodeError:
        return False








import warnings

from pip._vendor import urllib3

from .exceptions import RequestsDependencyWarning

charset_normalizer_version = None
chardet_version = None


def check_compatibility(urllib3_version, chardet_version, charset_normalizer_version):
    urllib3_version = urllib3_version.split(""."")
    assert urllib3_version != [""dev""]  

    
    if len(urllib3_version) == 2:
        urllib3_version.append(""0"")

    
    major, minor, patch = urllib3_version  
    major, minor, patch = int(major), int(minor), int(patch)
    
    assert major >= 1
    if major == 1:
        assert minor >= 21

    
    if chardet_version:
        major, minor, patch = chardet_version.split(""."")[:3]
        major, minor, patch = int(major), int(minor), int(patch)
        
        assert (3, 0, 2) <= (major, minor, patch) < (6, 0, 0)
    elif charset_normalizer_version:
        major, minor, patch = charset_normalizer_version.split(""."")[:3]
        major, minor, patch = int(major), int(minor), int(patch)
        
        assert (2, 0, 0) <= (major, minor, patch) < (4, 0, 0)
    else:
        
        pass


def _check_cryptography(cryptography_version):
    
    try:
        cryptography_version = list(map(int, cryptography_version.split(""."")))
    except ValueError:
        return

    if cryptography_version < [1, 3, 4]:
        warning = ""Old version of cryptography ({}) may cause slowdown."".format(
            cryptography_version
        )
        warnings.warn(warning, RequestsDependencyWarning)



try:
    check_compatibility(
        urllib3.__version__, chardet_version, charset_normalizer_version
    )
except (AssertionError, ValueError):
    warnings.warn(
        ""urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported ""
        ""version!"".format(
            urllib3.__version__, chardet_version, charset_normalizer_version
        ),
        RequestsDependencyWarning,
    )




try:
    
    
    from pip._internal.utils.compat import WINDOWS
    if not WINDOWS:
        raise ImportError(""pip internals: don't import cryptography on Windows"")
    try:
        import ssl
    except ImportError:
        ssl = None

    if not getattr(ssl, ""HAS_SNI"", False):
        from pip._vendor.urllib3.contrib import pyopenssl

        pyopenssl.inject_into_urllib3()

        
        from cryptography import __version__ as cryptography_version

        _check_cryptography(cryptography_version)
except ImportError:
    pass


from pip._vendor.urllib3.exceptions import DependencyWarning

warnings.simplefilter(""ignore"", DependencyWarning)


import logging
from logging import NullHandler

from . import packages, utils
from .__version__ import (
    __author__,
    __author_email__,
    __build__,
    __cake__,
    __copyright__,
    __description__,
    __license__,
    __title__,
    __url__,
    __version__,
)
from .api import delete, get, head, options, patch, post, put, request
from .exceptions import (
    ConnectionError,
    ConnectTimeout,
    FileModeWarning,
    HTTPError,
    JSONDecodeError,
    ReadTimeout,
    RequestException,
    Timeout,
    TooManyRedirects,
    URLRequired,
)
from .models import PreparedRequest, Request, Response
from .sessions import Session, session
from .status_codes import codes

logging.getLogger(__name__).addHandler(NullHandler())


warnings.simplefilter(""default"", FileModeWarning, append=True)





__title__ = ""requests""
__description__ = ""Python HTTP for Humans.""
__url__ = ""https://requests.readthedocs.io""
__version__ = ""2.32.4""
__build__ = 0x023204
__author__ = ""Kenneth Reitz""
__author_email__ = ""me@kennethreitz.org""
__license__ = ""Apache-2.0""
__copyright__ = ""Copyright Kenneth Reitz""
__cake__ = ""\u2728 \U0001f370 \u2728""

from __future__ import annotations

from typing import (
    TYPE_CHECKING,
    Generic,
    Iterable,
    Iterator,
    Mapping,
    Sequence,
)

from .structs import CT, KT, RT, Matches, RequirementInformation

if TYPE_CHECKING:
    from typing import Any, Protocol

    class Preference(Protocol):
        def __lt__(self, __other: Any) -> bool: ...


class AbstractProvider(Generic[RT, CT, KT]):
    

    def identify(self, requirement_or_candidate: RT | CT) -> KT:
        
        raise NotImplementedError

    def get_preference(
        self,
        identifier: KT,
        resolutions: Mapping[KT, CT],
        candidates: Mapping[KT, Iterator[CT]],
        information: Mapping[KT, Iterator[RequirementInformation[RT, CT]]],
        backtrack_causes: Sequence[RequirementInformation[RT, CT]],
    ) -> Preference:
        
        raise NotImplementedError

    def find_matches(
        self,
        identifier: KT,
        requirements: Mapping[KT, Iterator[RT]],
        incompatibilities: Mapping[KT, Iterator[CT]],
    ) -> Matches[CT]:
        
        raise NotImplementedError

    def is_satisfied_by(self, requirement: RT, candidate: CT) -> bool:
        
        raise NotImplementedError

    def get_dependencies(self, candidate: CT) -> Iterable[RT]:
        
        raise NotImplementedError

    def narrow_requirement_selection(
        self,
        identifiers: Iterable[KT],
        resolutions: Mapping[KT, CT],
        candidates: Mapping[KT, Iterator[CT]],
        information: Mapping[KT, Iterator[RequirementInformation[RT, CT]]],
        backtrack_causes: Sequence[RequirementInformation[RT, CT]],
    ) -> Iterable[KT]:
        
        return identifiers

from __future__ import annotations

from typing import TYPE_CHECKING, Collection, Generic

from .structs import CT, KT, RT, RequirementInformation, State

if TYPE_CHECKING:
    from .resolvers import Criterion


class BaseReporter(Generic[RT, CT, KT]):
    

    def starting(self) -> None:
        

    def starting_round(self, index: int) -> None:
        

    def ending_round(self, index: int, state: State[RT, CT, KT]) -> None:
        

    def ending(self, state: State[RT, CT, KT]) -> None:
        

    def adding_requirement(self, requirement: RT, parent: CT | None) -> None:
        

    def resolving_conflicts(
        self, causes: Collection[RequirementInformation[RT, CT]]
    ) -> None:
        

    def rejecting_candidate(self, criterion: Criterion[RT, CT], candidate: CT) -> None:
        

    def pinning(self, candidate: CT) -> None:
        

from __future__ import annotations

import itertools
from collections import namedtuple
from typing import (
    TYPE_CHECKING,
    Callable,
    Generic,
    Iterable,
    Iterator,
    Mapping,
    NamedTuple,
    Sequence,
    TypeVar,
    Union,
)

KT = TypeVar(""KT"")  
RT = TypeVar(""RT"")  
CT = TypeVar(""CT"")  

Matches = Union[Iterable[CT], Callable[[], Iterable[CT]]]

if TYPE_CHECKING:
    from .resolvers.criterion import Criterion

    class RequirementInformation(NamedTuple, Generic[RT, CT]):
        requirement: RT
        parent: CT | None

    class State(NamedTuple, Generic[RT, CT, KT]):
        

        mapping: dict[KT, CT]
        criteria: dict[KT, Criterion[RT, CT]]
        backtrack_causes: list[RequirementInformation[RT, CT]]

else:
    RequirementInformation = namedtuple(
        ""RequirementInformation"", [""requirement"", ""parent""]
    )
    State = namedtuple(""State"", [""mapping"", ""criteria"", ""backtrack_causes""])


class DirectedGraph(Generic[KT]):
    

    def __init__(self) -> None:
        self._vertices: set[KT] = set()
        self._forwards: dict[KT, set[KT]] = {}  
        self._backwards: dict[KT, set[KT]] = {}  

    def __iter__(self) -> Iterator[KT]:
        return iter(self._vertices)

    def __len__(self) -> int:
        return len(self._vertices)

    def __contains__(self, key: KT) -> bool:
        return key in self._vertices

    def copy(self) -> DirectedGraph[KT]:
        
        other = type(self)()
        other._vertices = set(self._vertices)
        other._forwards = {k: set(v) for k, v in self._forwards.items()}
        other._backwards = {k: set(v) for k, v in self._backwards.items()}
        return other

    def add(self, key: KT) -> None:
        
        if key in self._vertices:
            raise ValueError(""vertex exists"")
        self._vertices.add(key)
        self._forwards[key] = set()
        self._backwards[key] = set()

    def remove(self, key: KT) -> None:
        
        self._vertices.remove(key)
        for f in self._forwards.pop(key):
            self._backwards[f].remove(key)
        for t in self._backwards.pop(key):
            self._forwards[t].remove(key)

    def connected(self, f: KT, t: KT) -> bool:
        return f in self._backwards[t] and t in self._forwards[f]

    def connect(self, f: KT, t: KT) -> None:
        
        if t not in self._vertices:
            raise KeyError(t)
        self._forwards[f].add(t)
        self._backwards[t].add(f)

    def iter_edges(self) -> Iterator[tuple[KT, KT]]:
        for f, children in self._forwards.items():
            for t in children:
                yield f, t

    def iter_children(self, key: KT) -> Iterator[KT]:
        return iter(self._forwards[key])

    def iter_parents(self, key: KT) -> Iterator[KT]:
        return iter(self._backwards[key])


class IteratorMapping(Mapping[KT, Iterator[CT]], Generic[RT, CT, KT]):
    def __init__(
        self,
        mapping: Mapping[KT, RT],
        accessor: Callable[[RT], Iterable[CT]],
        appends: Mapping[KT, Iterable[CT]] | None = None,
    ) -> None:
        self._mapping = mapping
        self._accessor = accessor
        self._appends: Mapping[KT, Iterable[CT]] = appends or {}

    def __repr__(self) -> str:
        return ""IteratorMapping({!r}, {!r}, {!r})"".format(
            self._mapping,
            self._accessor,
            self._appends,
        )

    def __bool__(self) -> bool:
        return bool(self._mapping or self._appends)

    def __contains__(self, key: object) -> bool:
        return key in self._mapping or key in self._appends

    def __getitem__(self, k: KT) -> Iterator[CT]:
        try:
            v = self._mapping[k]
        except KeyError:
            return iter(self._appends[k])
        return itertools.chain(self._accessor(v), self._appends.get(k, ()))

    def __iter__(self) -> Iterator[KT]:
        more = (k for k in self._appends if k not in self._mapping)
        return itertools.chain(self._mapping, more)

    def __len__(self) -> int:
        more = sum(1 for k in self._appends if k not in self._mapping)
        return len(self._mapping) + more


class _FactoryIterableView(Iterable[RT]):
    

    def __init__(self, factory: Callable[[], Iterable[RT]]) -> None:
        self._factory = factory
        self._iterable: Iterable[RT] | None = None

    def __repr__(self) -> str:
        return f""{type(self).__name__}({list(self)})""

    def __bool__(self) -> bool:
        try:
            next(iter(self))
        except StopIteration:
            return False
        return True

    def __iter__(self) -> Iterator[RT]:
        iterable = self._factory() if self._iterable is None else self._iterable
        self._iterable, current = itertools.tee(iterable)
        return current


class _SequenceIterableView(Iterable[RT]):
    

    def __init__(self, sequence: Sequence[RT]):
        self._sequence = sequence

    def __repr__(self) -> str:
        return f""{type(self).__name__}({self._sequence})""

    def __bool__(self) -> bool:
        return bool(self._sequence)

    def __iter__(self) -> Iterator[RT]:
        return iter(self._sequence)


def build_iter_view(matches: Matches[CT]) -> Iterable[CT]:
    
    if callable(matches):
        return _FactoryIterableView(matches)
    if not isinstance(matches, Sequence):
        matches = list(matches)
    return _SequenceIterableView(matches)


IterableView = Iterable

__all__ = [
    ""AbstractProvider"",
    ""AbstractResolver"",
    ""BaseReporter"",
    ""InconsistentCandidate"",
    ""RequirementsConflicted"",
    ""ResolutionError"",
    ""ResolutionImpossible"",
    ""ResolutionTooDeep"",
    ""Resolver"",
    ""__version__"",
]

__version__ = ""1.2.0""


from .providers import AbstractProvider
from .reporters import BaseReporter
from .resolvers import (
    AbstractResolver,
    InconsistentCandidate,
    RequirementsConflicted,
    ResolutionError,
    ResolutionImpossible,
    ResolutionTooDeep,
    Resolver,
)

from __future__ import annotations

import collections
from typing import TYPE_CHECKING, Any, Generic, Iterable, Mapping, NamedTuple

from ..structs import CT, KT, RT, DirectedGraph

if TYPE_CHECKING:
    from ..providers import AbstractProvider
    from ..reporters import BaseReporter
    from .criterion import Criterion

    class Result(NamedTuple, Generic[RT, CT, KT]):
        mapping: Mapping[KT, CT]
        graph: DirectedGraph[KT | None]
        criteria: Mapping[KT, Criterion[RT, CT]]

else:
    Result = collections.namedtuple(""Result"", [""mapping"", ""graph"", ""criteria""])


class AbstractResolver(Generic[RT, CT, KT]):
    

    base_exception = Exception

    def __init__(
        self,
        provider: AbstractProvider[RT, CT, KT],
        reporter: BaseReporter[RT, CT, KT],
    ) -> None:
        self.provider = provider
        self.reporter = reporter

    def resolve(self, requirements: Iterable[RT], **kwargs: Any) -> Result[RT, CT, KT]:
        
        raise NotImplementedError

from __future__ import annotations

from typing import Collection, Generic, Iterable, Iterator

from ..structs import CT, RT, RequirementInformation


class Criterion(Generic[RT, CT]):
    

    def __init__(
        self,
        candidates: Iterable[CT],
        information: Collection[RequirementInformation[RT, CT]],
        incompatibilities: Collection[CT],
    ) -> None:
        self.candidates = candidates
        self.information = information
        self.incompatibilities = incompatibilities

    def __repr__(self) -> str:
        requirements = "", "".join(
            f""({req!r}, via={parent!r})"" for req, parent in self.information
        )
        return f""Criterion({requirements})""

    def iter_requirement(self) -> Iterator[RT]:
        return (i.requirement for i in self.information)

    def iter_parent(self) -> Iterator[CT | None]:
        return (i.parent for i in self.information)

from __future__ import annotations

from typing import TYPE_CHECKING, Collection, Generic

from ..structs import CT, RT, RequirementInformation

if TYPE_CHECKING:
    from .criterion import Criterion


class ResolverException(Exception):
    


class RequirementsConflicted(ResolverException, Generic[RT, CT]):
    def __init__(self, criterion: Criterion[RT, CT]) -> None:
        super().__init__(criterion)
        self.criterion = criterion

    def __str__(self) -> str:
        return ""Requirements conflict: {}"".format(
            "", "".join(repr(r) for r in self.criterion.iter_requirement()),
        )


class InconsistentCandidate(ResolverException, Generic[RT, CT]):
    def __init__(self, candidate: CT, criterion: Criterion[RT, CT]):
        super().__init__(candidate, criterion)
        self.candidate = candidate
        self.criterion = criterion

    def __str__(self) -> str:
        return ""Provided candidate {!r} does not satisfy {}"".format(
            self.candidate,
            "", "".join(repr(r) for r in self.criterion.iter_requirement()),
        )


class ResolutionError(ResolverException):
    pass


class ResolutionImpossible(ResolutionError, Generic[RT, CT]):
    def __init__(self, causes: Collection[RequirementInformation[RT, CT]]):
        super().__init__(causes)
        
        self.causes = causes


class ResolutionTooDeep(ResolutionError):
    def __init__(self, round_count: int) -> None:
        super().__init__(round_count)
        self.round_count = round_count

from __future__ import annotations

import collections
import itertools
import operator
from typing import TYPE_CHECKING, Generic

from ..structs import (
    CT,
    KT,
    RT,
    DirectedGraph,
    IterableView,
    IteratorMapping,
    RequirementInformation,
    State,
    build_iter_view,
)
from .abstract import AbstractResolver, Result
from .criterion import Criterion
from .exceptions import (
    InconsistentCandidate,
    RequirementsConflicted,
    ResolutionImpossible,
    ResolutionTooDeep,
    ResolverException,
)

if TYPE_CHECKING:
    from collections.abc import Collection, Iterable, Mapping

    from ..providers import AbstractProvider, Preference
    from ..reporters import BaseReporter

_OPTIMISTIC_BACKJUMPING_RATIO: float = 0.1


def _build_result(state: State[RT, CT, KT]) -> Result[RT, CT, KT]:
    mapping = state.mapping
    all_keys: dict[int, KT | None] = {id(v): k for k, v in mapping.items()}
    all_keys[id(None)] = None

    graph: DirectedGraph[KT | None] = DirectedGraph()
    graph.add(None)  

    connected: set[KT | None] = {None}
    for key, criterion in state.criteria.items():
        if not _has_route_to_root(state.criteria, key, all_keys, connected):
            continue
        if key not in graph:
            graph.add(key)
        for p in criterion.iter_parent():
            try:
                pkey = all_keys[id(p)]
            except KeyError:
                continue
            if pkey not in graph:
                graph.add(pkey)
            graph.connect(pkey, key)

    return Result(
        mapping={k: v for k, v in mapping.items() if k in connected},
        graph=graph,
        criteria=state.criteria,
    )


class Resolution(Generic[RT, CT, KT]):
    

    def __init__(
        self,
        provider: AbstractProvider[RT, CT, KT],
        reporter: BaseReporter[RT, CT, KT],
    ) -> None:
        self._p = provider
        self._r = reporter
        self._states: list[State[RT, CT, KT]] = []

        
        self._optimistic_backjumping_ratio = _OPTIMISTIC_BACKJUMPING_RATIO
        self._save_states: list[State[RT, CT, KT]] | None = None
        self._optimistic_start_round: int | None = None

    @property
    def state(self) -> State[RT, CT, KT]:
        try:
            return self._states[-1]
        except IndexError as e:
            raise AttributeError(""state"") from e

    def _push_new_state(self) -> None:
        
        base = self._states[-1]
        state = State(
            mapping=base.mapping.copy(),
            criteria=base.criteria.copy(),
            backtrack_causes=base.backtrack_causes[:],
        )
        self._states.append(state)

    def _add_to_criteria(
        self,
        criteria: dict[KT, Criterion[RT, CT]],
        requirement: RT,
        parent: CT | None,
    ) -> None:
        self._r.adding_requirement(requirement=requirement, parent=parent)

        identifier = self._p.identify(requirement_or_candidate=requirement)
        criterion = criteria.get(identifier)
        if criterion:
            incompatibilities = list(criterion.incompatibilities)
        else:
            incompatibilities = []

        matches = self._p.find_matches(
            identifier=identifier,
            requirements=IteratorMapping(
                criteria,
                operator.methodcaller(""iter_requirement""),
                {identifier: [requirement]},
            ),
            incompatibilities=IteratorMapping(
                criteria,
                operator.attrgetter(""incompatibilities""),
                {identifier: incompatibilities},
            ),
        )

        if criterion:
            information = list(criterion.information)
            information.append(RequirementInformation(requirement, parent))
        else:
            information = [RequirementInformation(requirement, parent)]

        criterion = Criterion(
            candidates=build_iter_view(matches),
            information=information,
            incompatibilities=incompatibilities,
        )
        if not criterion.candidates:
            raise RequirementsConflicted(criterion)
        criteria[identifier] = criterion

    def _remove_information_from_criteria(
        self, criteria: dict[KT, Criterion[RT, CT]], parents: Collection[KT]
    ) -> None:
        
        if not parents:
            return
        for key, criterion in criteria.items():
            criteria[key] = Criterion(
                criterion.candidates,
                [
                    information
                    for information in criterion.information
                    if (
                        information.parent is None
                        or self._p.identify(information.parent) not in parents
                    )
                ],
                criterion.incompatibilities,
            )

    def _get_preference(self, name: KT) -> Preference:
        return self._p.get_preference(
            identifier=name,
            resolutions=self.state.mapping,
            candidates=IteratorMapping(
                self.state.criteria,
                operator.attrgetter(""candidates""),
            ),
            information=IteratorMapping(
                self.state.criteria,
                operator.attrgetter(""information""),
            ),
            backtrack_causes=self.state.backtrack_causes,
        )

    def _is_current_pin_satisfying(
        self, name: KT, criterion: Criterion[RT, CT]
    ) -> bool:
        try:
            current_pin = self.state.mapping[name]
        except KeyError:
            return False
        return all(
            self._p.is_satisfied_by(requirement=r, candidate=current_pin)
            for r in criterion.iter_requirement()
        )

    def _get_updated_criteria(self, candidate: CT) -> dict[KT, Criterion[RT, CT]]:
        criteria = self.state.criteria.copy()
        for requirement in self._p.get_dependencies(candidate=candidate):
            self._add_to_criteria(criteria, requirement, parent=candidate)
        return criteria

    def _attempt_to_pin_criterion(self, name: KT) -> list[Criterion[RT, CT]]:
        criterion = self.state.criteria[name]

        causes: list[Criterion[RT, CT]] = []
        for candidate in criterion.candidates:
            try:
                criteria = self._get_updated_criteria(candidate)
            except RequirementsConflicted as e:
                self._r.rejecting_candidate(e.criterion, candidate)
                causes.append(e.criterion)
                continue

            
            
            
            
            satisfied = all(
                self._p.is_satisfied_by(requirement=r, candidate=candidate)
                for r in criterion.iter_requirement()
            )
            if not satisfied:
                raise InconsistentCandidate(candidate, criterion)

            self._r.pinning(candidate=candidate)
            self.state.criteria.update(criteria)

            
            
            self.state.mapping.pop(name, None)
            self.state.mapping[name] = candidate

            return []

        
        
        return causes

    def _patch_criteria(
        self, incompatibilities_from_broken: list[tuple[KT, list[CT]]]
    ) -> bool:
        
        
        for k, incompatibilities in incompatibilities_from_broken:
            if not incompatibilities:
                continue
            try:
                criterion = self.state.criteria[k]
            except KeyError:
                continue
            matches = self._p.find_matches(
                identifier=k,
                requirements=IteratorMapping(
                    self.state.criteria,
                    operator.methodcaller(""iter_requirement""),
                ),
                incompatibilities=IteratorMapping(
                    self.state.criteria,
                    operator.attrgetter(""incompatibilities""),
                    {k: incompatibilities},
                ),
            )
            candidates: IterableView[CT] = build_iter_view(matches)
            if not candidates:
                return False
            incompatibilities.extend(criterion.incompatibilities)
            self.state.criteria[k] = Criterion(
                candidates=candidates,
                information=list(criterion.information),
                incompatibilities=incompatibilities,
            )
        return True

    def _save_state(self) -> None:
        
        if self._save_states is None:
            self._save_states = [
                State(
                    mapping=s.mapping.copy(),
                    criteria=s.criteria.copy(),
                    backtrack_causes=s.backtrack_causes[:],
                )
                for s in self._states
            ]

    def _rollback_states(self) -> None:
        
        self._optimistic_backjumping_ratio = 0.0
        if self._save_states:
            self._states = self._save_states
            self._save_states = None

    def _backjump(self, causes: list[RequirementInformation[RT, CT]]) -> bool:
        
        incompatible_reqs: Iterable[CT | RT] = itertools.chain(
            (c.parent for c in causes if c.parent is not None),
            (c.requirement for c in causes),
        )
        incompatible_deps = {self._p.identify(r) for r in incompatible_reqs}
        while len(self._states) >= 3:
            
            del self._states[-1]

            
            broken_state = self.state
            while True:
                
                try:
                    broken_state = self._states.pop()
                    name, candidate = broken_state.mapping.popitem()
                except (IndexError, KeyError):
                    raise ResolutionImpossible(causes) from None

                if (
                    not self._optimistic_backjumping_ratio
                    and name not in incompatible_deps
                ):
                    
                    
                    break

                
                
                if (
                    self._optimistic_backjumping_ratio
                    and self._save_states is None
                    and name not in incompatible_deps
                ):
                    self._save_state()

                
                
                
                current_dependencies = {
                    self._p.identify(d) for d in self._p.get_dependencies(candidate)
                }
                if not current_dependencies.isdisjoint(incompatible_deps):
                    break

                
                
                
                if not broken_state.mapping:
                    break

            incompatibilities_from_broken = [
                (k, list(v.incompatibilities)) for k, v in broken_state.criteria.items()
            ]

            
            incompatibilities_from_broken.append((name, [candidate]))

            self._push_new_state()
            success = self._patch_criteria(incompatibilities_from_broken)

            
            if success:
                return True

            
            

        
        return False

    def _extract_causes(
        self, criteron: list[Criterion[RT, CT]]
    ) -> list[RequirementInformation[RT, CT]]:
        
        return list({id(i): i for c in criteron for i in c.information}.values())

    def resolve(self, requirements: Iterable[RT], max_rounds: int) -> State[RT, CT, KT]:
        if self._states:
            raise RuntimeError(""already resolved"")

        self._r.starting()

        
        self._states = [
            State(
                mapping=collections.OrderedDict(),
                criteria={},
                backtrack_causes=[],
            )
        ]
        for r in requirements:
            try:
                self._add_to_criteria(self.state.criteria, r, parent=None)
            except RequirementsConflicted as e:
                raise ResolutionImpossible(e.criterion.information) from e

        
        
        
        self._push_new_state()

        
        optimistic_rounds_cutoff: int | None = None
        optimistic_backjumping_start_round: int | None = None

        for round_index in range(max_rounds):
            self._r.starting_round(index=round_index)

            
            if self._optimistic_backjumping_ratio and self._save_states is not None:
                if optimistic_backjumping_start_round is None:
                    optimistic_backjumping_start_round = round_index
                    optimistic_rounds_cutoff = int(
                        (max_rounds - round_index) * self._optimistic_backjumping_ratio
                    )

                    if optimistic_rounds_cutoff <= 0:
                        self._rollback_states()
                        continue
                elif optimistic_rounds_cutoff is not None:
                    if (
                        round_index - optimistic_backjumping_start_round
                        >= optimistic_rounds_cutoff
                    ):
                        self._rollback_states()
                        continue

            unsatisfied_names = [
                key
                for key, criterion in self.state.criteria.items()
                if not self._is_current_pin_satisfying(key, criterion)
            ]

            
            if not unsatisfied_names:
                self._r.ending(state=self.state)
                return self.state

            
            satisfied_names = set(self.state.criteria.keys()) - set(unsatisfied_names)

            if len(unsatisfied_names) > 1:
                narrowed_unstatisfied_names = list(
                    self._p.narrow_requirement_selection(
                        identifiers=unsatisfied_names,
                        resolutions=self.state.mapping,
                        candidates=IteratorMapping(
                            self.state.criteria,
                            operator.attrgetter(""candidates""),
                        ),
                        information=IteratorMapping(
                            self.state.criteria,
                            operator.attrgetter(""information""),
                        ),
                        backtrack_causes=self.state.backtrack_causes,
                    )
                )
            else:
                narrowed_unstatisfied_names = unsatisfied_names

            
            if not narrowed_unstatisfied_names:
                raise RuntimeError(""narrow_requirement_selection returned 0 names"")

            
            if len(narrowed_unstatisfied_names) > 1:
                
                name = min(narrowed_unstatisfied_names, key=self._get_preference)
            else:
                name = narrowed_unstatisfied_names[0]

            failure_criterion = self._attempt_to_pin_criterion(name)

            if failure_criterion:
                causes = self._extract_causes(failure_criterion)
                
                
                self._r.resolving_conflicts(causes=causes)

                try:
                    success = self._backjump(causes)
                except ResolutionImpossible:
                    if self._optimistic_backjumping_ratio and self._save_states:
                        failed_optimistic_backjumping = True
                    else:
                        raise
                else:
                    failed_optimistic_backjumping = bool(
                        not success
                        and self._optimistic_backjumping_ratio
                        and self._save_states
                    )

                if failed_optimistic_backjumping and self._save_states:
                    self._rollback_states()
                else:
                    self.state.backtrack_causes[:] = causes

                    
                    if not success:
                        raise ResolutionImpossible(self.state.backtrack_causes)
            else:
                
                
                newly_unsatisfied_names = {
                    key
                    for key, criterion in self.state.criteria.items()
                    if key in satisfied_names
                    and not self._is_current_pin_satisfying(key, criterion)
                }
                self._remove_information_from_criteria(
                    self.state.criteria, newly_unsatisfied_names
                )
                
                self._push_new_state()

            self._r.ending_round(index=round_index, state=self.state)

        raise ResolutionTooDeep(max_rounds)


class Resolver(AbstractResolver[RT, CT, KT]):
    

    base_exception = ResolverException

    def resolve(  
        self,
        requirements: Iterable[RT],
        max_rounds: int = 100,
    ) -> Result[RT, CT, KT]:
        
        resolution = Resolution(self.provider, self.reporter)
        state = resolution.resolve(requirements, max_rounds=max_rounds)
        return _build_result(state)


def _has_route_to_root(
    criteria: Mapping[KT, Criterion[RT, CT]],
    key: KT | None,
    all_keys: dict[int, KT | None],
    connected: set[KT | None],
) -> bool:
    if key in connected:
        return True
    if key not in criteria:
        return False
    assert key is not None
    for p in criteria[key].iter_parent():
        try:
            pkey = all_keys[id(p)]
        except KeyError:
            continue
        if pkey in connected:
            connected.add(key)
            return True
        if _has_route_to_root(criteria, pkey, all_keys, connected):
            connected.add(key)
            return True
    return False

from ..structs import RequirementInformation
from .abstract import AbstractResolver, Result
from .criterion import Criterion
from .exceptions import (
    InconsistentCandidate,
    RequirementsConflicted,
    ResolutionError,
    ResolutionImpossible,
    ResolutionTooDeep,
    ResolverException,
)
from .resolution import Resolution, Resolver

__all__ = [
    ""AbstractResolver"",
    ""Criterion"",
    ""InconsistentCandidate"",
    ""RequirementInformation"",
    ""RequirementsConflicted"",
    ""Resolution"",
    ""ResolutionError"",
    ""ResolutionImpossible"",
    ""ResolutionTooDeep"",
    ""Resolver"",
    ""ResolverException"",
    ""Result"",
]

from abc import ABC


class RichRenderable(ABC):
    

    @classmethod
    def __subclasshook__(cls, other: type) -> bool:
        
        return hasattr(other, ""__rich_console__"") or hasattr(other, ""__rich__"")


if __name__ == ""__main__"":  
    from pip._vendor.rich.text import Text

    t = Text()
    print(isinstance(Text, RichRenderable))
    print(isinstance(t, RichRenderable))

    class Foo:
        pass

    f = Foo()
    print(isinstance(f, RichRenderable))
    print(isinstance("""", RichRenderable))

from itertools import chain
from typing import TYPE_CHECKING, Iterable, Optional, Literal

from .constrain import Constrain
from .jupyter import JupyterMixin
from .measure import Measurement
from .segment import Segment
from .style import StyleType

if TYPE_CHECKING:
    from .console import Console, ConsoleOptions, RenderableType, RenderResult

AlignMethod = Literal[""left"", ""center"", ""right""]
VerticalAlignMethod = Literal[""top"", ""middle"", ""bottom""]


class Align(JupyterMixin):
    

    def __init__(
        self,
        renderable: ""RenderableType"",
        align: AlignMethod = ""left"",
        style: Optional[StyleType] = None,
        *,
        vertical: Optional[VerticalAlignMethod] = None,
        pad: bool = True,
        width: Optional[int] = None,
        height: Optional[int] = None,
    ) -> None:
        if align not in (""left"", ""center"", ""right""):
            raise ValueError(
                f'invalid value for align, expected ""left"", ""center"", or ""right"" (not {align!r})'
            )
        if vertical is not None and vertical not in (""top"", ""middle"", ""bottom""):
            raise ValueError(
                f'invalid value for vertical, expected ""top"", ""middle"", or ""bottom"" (not {vertical!r})'
            )
        self.renderable = renderable
        self.align = align
        self.style = style
        self.vertical = vertical
        self.pad = pad
        self.width = width
        self.height = height

    def __repr__(self) -> str:
        return f""Align({self.renderable!r}, {self.align!r})""

    @classmethod
    def left(
        cls,
        renderable: ""RenderableType"",
        style: Optional[StyleType] = None,
        *,
        vertical: Optional[VerticalAlignMethod] = None,
        pad: bool = True,
        width: Optional[int] = None,
        height: Optional[int] = None,
    ) -> ""Align"":
        
        return cls(
            renderable,
            ""left"",
            style=style,
            vertical=vertical,
            pad=pad,
            width=width,
            height=height,
        )

    @classmethod
    def center(
        cls,
        renderable: ""RenderableType"",
        style: Optional[StyleType] = None,
        *,
        vertical: Optional[VerticalAlignMethod] = None,
        pad: bool = True,
        width: Optional[int] = None,
        height: Optional[int] = None,
    ) -> ""Align"":
        
        return cls(
            renderable,
            ""center"",
            style=style,
            vertical=vertical,
            pad=pad,
            width=width,
            height=height,
        )

    @classmethod
    def right(
        cls,
        renderable: ""RenderableType"",
        style: Optional[StyleType] = None,
        *,
        vertical: Optional[VerticalAlignMethod] = None,
        pad: bool = True,
        width: Optional[int] = None,
        height: Optional[int] = None,
    ) -> ""Align"":
        
        return cls(
            renderable,
            ""right"",
            style=style,
            vertical=vertical,
            pad=pad,
            width=width,
            height=height,
        )

    def __rich_console__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> ""RenderResult"":
        align = self.align
        width = console.measure(self.renderable, options=options).maximum
        rendered = console.render(
            Constrain(
                self.renderable, width if self.width is None else min(width, self.width)
            ),
            options.update(height=None),
        )
        lines = list(Segment.split_lines(rendered))
        width, height = Segment.get_shape(lines)
        lines = Segment.set_shape(lines, width, height)
        new_line = Segment.line()
        excess_space = options.max_width - width
        style = console.get_style(self.style) if self.style is not None else None

        def generate_segments() -> Iterable[Segment]:
            if excess_space <= 0:
                
                for line in lines:
                    yield from line
                    yield new_line

            elif align == ""left"":
                
                pad = Segment("" "" * excess_space, style) if self.pad else None
                for line in lines:
                    yield from line
                    if pad:
                        yield pad
                    yield new_line

            elif align == ""center"":
                
                left = excess_space // 2
                pad = Segment("" "" * left, style)
                pad_right = (
                    Segment("" "" * (excess_space - left), style) if self.pad else None
                )
                for line in lines:
                    if left:
                        yield pad
                    yield from line
                    if pad_right:
                        yield pad_right
                    yield new_line

            elif align == ""right"":
                
                pad = Segment("" "" * excess_space, style)
                for line in lines:
                    yield pad
                    yield from line
                    yield new_line

        blank_line = (
            Segment(f""{' ' * (self.width or options.max_width)}\n"", style)
            if self.pad
            else Segment(""\n"")
        )

        def blank_lines(count: int) -> Iterable[Segment]:
            if count > 0:
                for _ in range(count):
                    yield blank_line

        vertical_height = self.height or options.height
        iter_segments: Iterable[Segment]
        if self.vertical and vertical_height is not None:
            if self.vertical == ""top"":
                bottom_space = vertical_height - height
                iter_segments = chain(generate_segments(), blank_lines(bottom_space))
            elif self.vertical == ""middle"":
                top_space = (vertical_height - height) // 2
                bottom_space = vertical_height - top_space - height
                iter_segments = chain(
                    blank_lines(top_space),
                    generate_segments(),
                    blank_lines(bottom_space),
                )
            else:  
                top_space = vertical_height - height
                iter_segments = chain(blank_lines(top_space), generate_segments())
        else:
            iter_segments = generate_segments()
        if self.style:
            style = console.get_style(self.style)
            iter_segments = Segment.apply_style(iter_segments, style)
        yield from iter_segments

    def __rich_measure__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> Measurement:
        measurement = Measurement.get(console, options, self.renderable)
        return measurement


class VerticalCenter(JupyterMixin):
    

    def __init__(
        self,
        renderable: ""RenderableType"",
        style: Optional[StyleType] = None,
    ) -> None:
        self.renderable = renderable
        self.style = style

    def __repr__(self) -> str:
        return f""VerticalCenter({self.renderable!r})""

    def __rich_console__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> ""RenderResult"":
        style = console.get_style(self.style) if self.style is not None else None
        lines = console.render_lines(
            self.renderable, options.update(height=None), pad=False
        )
        width, _height = Segment.get_shape(lines)
        new_line = Segment.line()
        height = options.height or options.size.height
        top_space = (height - len(lines)) // 2
        bottom_space = height - top_space - len(lines)
        blank_line = Segment(f""{' ' * width}"", style)

        def blank_lines(count: int) -> Iterable[Segment]:
            for _ in range(count):
                yield blank_line
                yield new_line

        if top_space > 0:
            yield from blank_lines(top_space)
        for line in lines:
            yield from line
            yield new_line
        if bottom_space > 0:
            yield from blank_lines(bottom_space)

    def __rich_measure__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> Measurement:
        measurement = Measurement.get(console, options, self.renderable)
        return measurement


if __name__ == ""__main__"":  
    from pip._vendor.rich.console import Console, Group
    from pip._vendor.rich.highlighter import ReprHighlighter
    from pip._vendor.rich.panel import Panel

    highlighter = ReprHighlighter()
    console = Console()

    panel = Panel(
        Group(
            Align.left(highlighter(""align='left'"")),
            Align.center(highlighter(""align='center'"")),
            Align.right(highlighter(""align='right'"")),
        ),
        width=60,
        style=""on dark_blue"",
        title=""Align"",
    )

    console.print(
        Align.center(panel, vertical=""middle"", style=""on red"", height=console.height)
    )

import re
import sys
from contextlib import suppress
from typing import Iterable, NamedTuple, Optional

from .color import Color
from .style import Style
from .text import Text

re_ansi = re.compile(
    r,
    re.VERBOSE,
)


class _AnsiToken(NamedTuple):
    

    plain: str = """"
    sgr: Optional[str] = """"
    osc: Optional[str] = """"


def _ansi_tokenize(ansi_text: str) -> Iterable[_AnsiToken]:
    

    position = 0
    sgr: Optional[str]
    osc: Optional[str]
    for match in re_ansi.finditer(ansi_text):
        start, end = match.span(0)
        osc, sgr = match.groups()
        if start > position:
            yield _AnsiToken(ansi_text[position:start])
        if sgr:
            if sgr == ""("":
                position = end + 1
                continue
            if sgr.endswith(""m""):
                yield _AnsiToken("""", sgr[1:-1], osc)
        else:
            yield _AnsiToken("""", sgr, osc)
        position = end
    if position < len(ansi_text):
        yield _AnsiToken(ansi_text[position:])


SGR_STYLE_MAP = {
    1: ""bold"",
    2: ""dim"",
    3: ""italic"",
    4: ""underline"",
    5: ""blink"",
    6: ""blink2"",
    7: ""reverse"",
    8: ""conceal"",
    9: ""strike"",
    21: ""underline2"",
    22: ""not dim not bold"",
    23: ""not italic"",
    24: ""not underline"",
    25: ""not blink"",
    26: ""not blink2"",
    27: ""not reverse"",
    28: ""not conceal"",
    29: ""not strike"",
    30: ""color(0)"",
    31: ""color(1)"",
    32: ""color(2)"",
    33: ""color(3)"",
    34: ""color(4)"",
    35: ""color(5)"",
    36: ""color(6)"",
    37: ""color(7)"",
    39: ""default"",
    40: ""on color(0)"",
    41: ""on color(1)"",
    42: ""on color(2)"",
    43: ""on color(3)"",
    44: ""on color(4)"",
    45: ""on color(5)"",
    46: ""on color(6)"",
    47: ""on color(7)"",
    49: ""on default"",
    51: ""frame"",
    52: ""encircle"",
    53: ""overline"",
    54: ""not frame not encircle"",
    55: ""not overline"",
    90: ""color(8)"",
    91: ""color(9)"",
    92: ""color(10)"",
    93: ""color(11)"",
    94: ""color(12)"",
    95: ""color(13)"",
    96: ""color(14)"",
    97: ""color(15)"",
    100: ""on color(8)"",
    101: ""on color(9)"",
    102: ""on color(10)"",
    103: ""on color(11)"",
    104: ""on color(12)"",
    105: ""on color(13)"",
    106: ""on color(14)"",
    107: ""on color(15)"",
}


class AnsiDecoder:
    

    def __init__(self) -> None:
        self.style = Style.null()

    def decode(self, terminal_text: str) -> Iterable[Text]:
        
        for line in terminal_text.splitlines():
            yield self.decode_line(line)

    def decode_line(self, line: str) -> Text:
        
        from_ansi = Color.from_ansi
        from_rgb = Color.from_rgb
        _Style = Style
        text = Text()
        append = text.append
        line = line.rsplit(""\r"", 1)[-1]
        for plain_text, sgr, osc in _ansi_tokenize(line):
            if plain_text:
                append(plain_text, self.style or None)
            elif osc is not None:
                if osc.startswith(""8;""):
                    _params, semicolon, link = osc[2:].partition("";"")
                    if semicolon:
                        self.style = self.style.update_link(link or None)
            elif sgr is not None:
                
                
                codes = [
                    min(255, int(_code) if _code else 0)
                    for _code in sgr.split("";"")
                    if _code.isdigit() or _code == """"
                ]
                iter_codes = iter(codes)
                for code in iter_codes:
                    if code == 0:
                        
                        self.style = _Style.null()
                    elif code in SGR_STYLE_MAP:
                        
                        self.style += _Style.parse(SGR_STYLE_MAP[code])
                    elif code == 38:
                        
                        with suppress(StopIteration):
                            color_type = next(iter_codes)
                            if color_type == 5:
                                self.style += _Style.from_color(
                                    from_ansi(next(iter_codes))
                                )
                            elif color_type == 2:
                                self.style += _Style.from_color(
                                    from_rgb(
                                        next(iter_codes),
                                        next(iter_codes),
                                        next(iter_codes),
                                    )
                                )
                    elif code == 48:
                        
                        with suppress(StopIteration):
                            color_type = next(iter_codes)
                            if color_type == 5:
                                self.style += _Style.from_color(
                                    None, from_ansi(next(iter_codes))
                                )
                            elif color_type == 2:
                                self.style += _Style.from_color(
                                    None,
                                    from_rgb(
                                        next(iter_codes),
                                        next(iter_codes),
                                        next(iter_codes),
                                    ),
                                )

        return text


if sys.platform != ""win32"" and __name__ == ""__main__"":  
    import io
    import os
    import pty
    import sys

    decoder = AnsiDecoder()

    stdout = io.BytesIO()

    def read(fd: int) -> bytes:
        data = os.read(fd, 1024)
        stdout.write(data)
        return data

    pty.spawn(sys.argv[1:], read)

    from .console import Console

    console = Console(record=True)

    stdout_result = stdout.getvalue().decode(""utf-8"")
    print(stdout_result)

    for line in decoder.decode(stdout_result):
        console.print(line)

    console.save_html(""stdout.html"")

from typing import Optional, Union

from .color import Color
from .console import Console, ConsoleOptions, RenderResult
from .jupyter import JupyterMixin
from .measure import Measurement
from .segment import Segment
from .style import Style



BEGIN_BLOCK_ELEMENTS = [""█"", ""█"", ""█"", ""▐"", ""▐"", ""▐"", ""▕"", ""▕""]
END_BLOCK_ELEMENTS = ["" "", ""▏"", ""▎"", ""▍"", ""▌"", ""▋"", ""▊"", ""▉""]
FULL_BLOCK = ""█""


class Bar(JupyterMixin):
    

    def __init__(
        self,
        size: float,
        begin: float,
        end: float,
        *,
        width: Optional[int] = None,
        color: Union[Color, str] = ""default"",
        bgcolor: Union[Color, str] = ""default"",
    ):
        self.size = size
        self.begin = max(begin, 0)
        self.end = min(end, size)
        self.width = width
        self.style = Style(color=color, bgcolor=bgcolor)

    def __repr__(self) -> str:
        return f""Bar({self.size}, {self.begin}, {self.end})""

    def __rich_console__(
        self, console: Console, options: ConsoleOptions
    ) -> RenderResult:
        width = min(
            self.width if self.width is not None else options.max_width,
            options.max_width,
        )

        if self.begin >= self.end:
            yield Segment("" "" * width, self.style)
            yield Segment.line()
            return

        prefix_complete_eights = int(width * 8 * self.begin / self.size)
        prefix_bar_count = prefix_complete_eights // 8
        prefix_eights_count = prefix_complete_eights % 8

        body_complete_eights = int(width * 8 * self.end / self.size)
        body_bar_count = body_complete_eights // 8
        body_eights_count = body_complete_eights % 8

        
        
        

        prefix = "" "" * prefix_bar_count
        if prefix_eights_count:
            prefix += BEGIN_BLOCK_ELEMENTS[prefix_eights_count]

        body = FULL_BLOCK * body_bar_count
        if body_eights_count:
            body += END_BLOCK_ELEMENTS[body_eights_count]

        suffix = "" "" * (width - len(body))

        yield Segment(prefix + body[len(prefix) :] + suffix, self.style)
        yield Segment.line()

    def __rich_measure__(
        self, console: Console, options: ConsoleOptions
    ) -> Measurement:
        return (
            Measurement(self.width, self.width)
            if self.width is not None
            else Measurement(4, options.max_width)
        )

from typing import TYPE_CHECKING, Iterable, List, Literal


from ._loop import loop_last

if TYPE_CHECKING:
    from pip._vendor.rich.console import ConsoleOptions


class Box:
    

    def __init__(self, box: str, *, ascii: bool = False) -> None:
        self._box = box
        self.ascii = ascii
        line1, line2, line3, line4, line5, line6, line7, line8 = box.splitlines()
        
        self.top_left, self.top, self.top_divider, self.top_right = iter(line1)
        
        self.head_left, _, self.head_vertical, self.head_right = iter(line2)
        
        (
            self.head_row_left,
            self.head_row_horizontal,
            self.head_row_cross,
            self.head_row_right,
        ) = iter(line3)

        
        self.mid_left, _, self.mid_vertical, self.mid_right = iter(line4)
        
        self.row_left, self.row_horizontal, self.row_cross, self.row_right = iter(line5)
        
        (
            self.foot_row_left,
            self.foot_row_horizontal,
            self.foot_row_cross,
            self.foot_row_right,
        ) = iter(line6)
        
        self.foot_left, _, self.foot_vertical, self.foot_right = iter(line7)
        
        self.bottom_left, self.bottom, self.bottom_divider, self.bottom_right = iter(
            line8
        )

    def __repr__(self) -> str:
        return ""Box(...)""

    def __str__(self) -> str:
        return self._box

    def substitute(self, options: ""ConsoleOptions"", safe: bool = True) -> ""Box"":
        
        box = self
        if options.legacy_windows and safe:
            box = LEGACY_WINDOWS_SUBSTITUTIONS.get(box, box)
        if options.ascii_only and not box.ascii:
            box = ASCII
        return box

    def get_plain_headed_box(self) -> ""Box"":
        
        return PLAIN_HEADED_SUBSTITUTIONS.get(self, self)

    def get_top(self, widths: Iterable[int]) -> str:
        

        parts: List[str] = []
        append = parts.append
        append(self.top_left)
        for last, width in loop_last(widths):
            append(self.top * width)
            if not last:
                append(self.top_divider)
        append(self.top_right)
        return """".join(parts)

    def get_row(
        self,
        widths: Iterable[int],
        level: Literal[""head"", ""row"", ""foot"", ""mid""] = ""row"",
        edge: bool = True,
    ) -> str:
        
        if level == ""head"":
            left = self.head_row_left
            horizontal = self.head_row_horizontal
            cross = self.head_row_cross
            right = self.head_row_right
        elif level == ""row"":
            left = self.row_left
            horizontal = self.row_horizontal
            cross = self.row_cross
            right = self.row_right
        elif level == ""mid"":
            left = self.mid_left
            horizontal = "" ""
            cross = self.mid_vertical
            right = self.mid_right
        elif level == ""foot"":
            left = self.foot_row_left
            horizontal = self.foot_row_horizontal
            cross = self.foot_row_cross
            right = self.foot_row_right
        else:
            raise ValueError(""level must be 'head', 'row' or 'foot'"")

        parts: List[str] = []
        append = parts.append
        if edge:
            append(left)
        for last, width in loop_last(widths):
            append(horizontal * width)
            if not last:
                append(cross)
        if edge:
            append(right)
        return """".join(parts)

    def get_bottom(self, widths: Iterable[int]) -> str:
        

        parts: List[str] = []
        append = parts.append
        append(self.bottom_left)
        for last, width in loop_last(widths):
            append(self.bottom * width)
            if not last:
                append(self.bottom_divider)
        append(self.bottom_right)
        return """".join(parts)



ASCII: Box = Box(
    ""+--+\n""
    ""| ||\n""
    ""|-+|\n""
    ""| ||\n""
    ""|-+|\n""
    ""|-+|\n""
    ""| ||\n""
    ""+--+\n"",
    ascii=True,
)

ASCII2: Box = Box(
    ""+-++\n""
    ""| ||\n""
    ""+-++\n""
    ""| ||\n""
    ""+-++\n""
    ""+-++\n""
    ""| ||\n""
    ""+-++\n"",
    ascii=True,
)

ASCII_DOUBLE_HEAD: Box = Box(
    ""+-++\n""
    ""| ||\n""
    ""+=++\n""
    ""| ||\n""
    ""+-++\n""
    ""+-++\n""
    ""| ||\n""
    ""+-++\n"",
    ascii=True,
)

SQUARE: Box = Box(
    ""┌─┬┐\n""
    ""│ ││\n""
    ""├─┼┤\n""
    ""│ ││\n""
    ""├─┼┤\n""
    ""├─┼┤\n""
    ""│ ││\n""
    ""└─┴┘\n""
)

SQUARE_DOUBLE_HEAD: Box = Box(
    ""┌─┬┐\n""
    ""│ ││\n""
    ""╞═╪╡\n""
    ""│ ││\n""
    ""├─┼┤\n""
    ""├─┼┤\n""
    ""│ ││\n""
    ""└─┴┘\n""
)

MINIMAL: Box = Box(
    ""  ╷ \n""
    ""  │ \n""
    ""╶─┼╴\n""
    ""  │ \n""
    ""╶─┼╴\n""
    ""╶─┼╴\n""
    ""  │ \n""
    ""  ╵ \n""
)


MINIMAL_HEAVY_HEAD: Box = Box(
    ""  ╷ \n""
    ""  │ \n""
    ""╺━┿╸\n""
    ""  │ \n""
    ""╶─┼╴\n""
    ""╶─┼╴\n""
    ""  │ \n""
    ""  ╵ \n""
)

MINIMAL_DOUBLE_HEAD: Box = Box(
    ""  ╷ \n""
    ""  │ \n""
    "" ═╪ \n""
    ""  │ \n""
    "" ─┼ \n""
    "" ─┼ \n""
    ""  │ \n""
    ""  ╵ \n""
)


SIMPLE: Box = Box(
    ""    \n""
    ""    \n""
    "" ── \n""
    ""    \n""
    ""    \n""
    "" ── \n""
    ""    \n""
    ""    \n""
)

SIMPLE_HEAD: Box = Box(
    ""    \n""
    ""    \n""
    "" ── \n""
    ""    \n""
    ""    \n""
    ""    \n""
    ""    \n""
    ""    \n""
)


SIMPLE_HEAVY: Box = Box(
    ""    \n""
    ""    \n""
    "" ━━ \n""
    ""    \n""
    ""    \n""
    "" ━━ \n""
    ""    \n""
    ""    \n""
)


HORIZONTALS: Box = Box(
    "" ── \n""
    ""    \n""
    "" ── \n""
    ""    \n""
    "" ── \n""
    "" ── \n""
    ""    \n""
    "" ── \n""
)

ROUNDED: Box = Box(
    ""╭─┬╮\n""
    ""│ ││\n""
    ""├─┼┤\n""
    ""│ ││\n""
    ""├─┼┤\n""
    ""├─┼┤\n""
    ""│ ││\n""
    ""╰─┴╯\n""
)

HEAVY: Box = Box(
    ""┏━┳┓\n""
    ""┃ ┃┃\n""
    ""┣━╋┫\n""
    ""┃ ┃┃\n""
    ""┣━╋┫\n""
    ""┣━╋┫\n""
    ""┃ ┃┃\n""
    ""┗━┻┛\n""
)

HEAVY_EDGE: Box = Box(
    ""┏━┯┓\n""
    ""┃ │┃\n""
    ""┠─┼┨\n""
    ""┃ │┃\n""
    ""┠─┼┨\n""
    ""┠─┼┨\n""
    ""┃ │┃\n""
    ""┗━┷┛\n""
)

HEAVY_HEAD: Box = Box(
    ""┏━┳┓\n""
    ""┃ ┃┃\n""
    ""┡━╇┩\n""
    ""│ ││\n""
    ""├─┼┤\n""
    ""├─┼┤\n""
    ""│ ││\n""
    ""└─┴┘\n""
)

DOUBLE: Box = Box(
    ""╔═╦╗\n""
    ""║ ║║\n""
    ""╠═╬╣\n""
    ""║ ║║\n""
    ""╠═╬╣\n""
    ""╠═╬╣\n""
    ""║ ║║\n""
    ""╚═╩╝\n""
)

DOUBLE_EDGE: Box = Box(
    ""╔═╤╗\n""
    ""║ │║\n""
    ""╟─┼╢\n""
    ""║ │║\n""
    ""╟─┼╢\n""
    ""╟─┼╢\n""
    ""║ │║\n""
    ""╚═╧╝\n""
)

MARKDOWN: Box = Box(
    ""    \n""
    ""| ||\n""
    ""|-||\n""
    ""| ||\n""
    ""|-||\n""
    ""|-||\n""
    ""| ||\n""
    ""    \n"",
    ascii=True,
)



LEGACY_WINDOWS_SUBSTITUTIONS = {
    ROUNDED: SQUARE,
    MINIMAL_HEAVY_HEAD: MINIMAL,
    SIMPLE_HEAVY: SIMPLE,
    HEAVY: SQUARE,
    HEAVY_EDGE: SQUARE,
    HEAVY_HEAD: SQUARE,
}


PLAIN_HEADED_SUBSTITUTIONS = {
    HEAVY_HEAD: SQUARE,
    SQUARE_DOUBLE_HEAD: SQUARE,
    MINIMAL_DOUBLE_HEAD: MINIMAL,
    MINIMAL_HEAVY_HEAD: MINIMAL,
    ASCII_DOUBLE_HEAD: ASCII2,
}


if __name__ == ""__main__"":  
    from pip._vendor.rich.columns import Columns
    from pip._vendor.rich.panel import Panel

    from . import box as box
    from .console import Console
    from .table import Table
    from .text import Text

    console = Console(record=True)

    BOXES = [
        ""ASCII"",
        ""ASCII2"",
        ""ASCII_DOUBLE_HEAD"",
        ""SQUARE"",
        ""SQUARE_DOUBLE_HEAD"",
        ""MINIMAL"",
        ""MINIMAL_HEAVY_HEAD"",
        ""MINIMAL_DOUBLE_HEAD"",
        ""SIMPLE"",
        ""SIMPLE_HEAD"",
        ""SIMPLE_HEAVY"",
        ""HORIZONTALS"",
        ""ROUNDED"",
        ""HEAVY"",
        ""HEAVY_EDGE"",
        ""HEAVY_HEAD"",
        ""DOUBLE"",
        ""DOUBLE_EDGE"",
        ""MARKDOWN"",
    ]

    console.print(Panel(""[bold green]Box Constants"", style=""green""), justify=""center"")
    console.print()

    columns = Columns(expand=True, padding=2)
    for box_name in sorted(BOXES):
        table = Table(
            show_footer=True, style=""dim"", border_style=""not dim"", expand=True
        )
        table.add_column(""Header 1"", ""Footer 1"")
        table.add_column(""Header 2"", ""Footer 2"")
        table.add_row(""Cell"", ""Cell"")
        table.add_row(""Cell"", ""Cell"")
        table.box = getattr(box, box_name)
        table.title = Text(f""box.{box_name}"", style=""magenta"")
        columns.add_renderable(table)
    console.print(columns)

    

from __future__ import annotations

from functools import lru_cache
from typing import Callable

from ._cell_widths import CELL_WIDTHS



_SINGLE_CELL_UNICODE_RANGES: list[tuple[int, int]] = [
    (0x20, 0x7E),  
    (0xA0, 0xAC),
    (0xAE, 0x002FF),
    (0x00370, 0x00482),  
    (0x02500, 0x025FC),  
    (0x02800, 0x028FF),  
]


_SINGLE_CELLS = frozenset(
    [
        character
        for _start, _end in _SINGLE_CELL_UNICODE_RANGES
        for character in map(chr, range(_start, _end + 1))
    ]
)



_is_single_cell_widths: Callable[[str], bool] = _SINGLE_CELLS.issuperset


@lru_cache(4096)
def cached_cell_len(text: str) -> int:
    
    if _is_single_cell_widths(text):
        return len(text)
    return sum(map(get_character_cell_size, text))


def cell_len(text: str, _cell_len: Callable[[str], int] = cached_cell_len) -> int:
    
    if len(text) < 512:
        return _cell_len(text)
    if _is_single_cell_widths(text):
        return len(text)
    return sum(map(get_character_cell_size, text))


@lru_cache(maxsize=4096)
def get_character_cell_size(character: str) -> int:
    
    codepoint = ord(character)
    _table = CELL_WIDTHS
    lower_bound = 0
    upper_bound = len(_table) - 1
    index = (lower_bound + upper_bound) // 2
    while True:
        start, end, width = _table[index]
        if codepoint < start:
            upper_bound = index - 1
        elif codepoint > end:
            lower_bound = index + 1
        else:
            return 0 if width == -1 else width
        if upper_bound < lower_bound:
            break
        index = (lower_bound + upper_bound) // 2
    return 1


def set_cell_size(text: str, total: int) -> str:
    

    if _is_single_cell_widths(text):
        size = len(text)
        if size < total:
            return text + "" "" * (total - size)
        return text[:total]

    if total <= 0:
        return """"
    cell_size = cell_len(text)
    if cell_size == total:
        return text
    if cell_size < total:
        return text + "" "" * (total - cell_size)

    start = 0
    end = len(text)

    
    while True:
        pos = (start + end) // 2
        before = text[: pos + 1]
        before_len = cell_len(before)
        if before_len == total + 1 and cell_len(before[-1]) == 2:
            return before[:-1] + "" ""
        if before_len == total:
            return before
        if before_len > total:
            end = pos
        else:
            start = pos


def chop_cells(
    text: str,
    width: int,
) -> list[str]:
    
    _get_character_cell_size = get_character_cell_size
    lines: list[list[str]] = [[]]

    append_new_line = lines.append
    append_to_last_line = lines[-1].append

    total_width = 0

    for character in text:
        cell_width = _get_character_cell_size(character)
        char_doesnt_fit = total_width + cell_width > width

        if char_doesnt_fit:
            append_new_line([character])
            append_to_last_line = lines[-1].append
            total_width = cell_width
        else:
            append_to_last_line(character)
            total_width += cell_width

    return ["""".join(line) for line in lines]


if __name__ == ""__main__"":  
    print(get_character_cell_size(""😽""))
    for line in chop_cells(, 8):
        print(line)
    for n in range(80, 1, -1):
        print(set_cell_size(, n) + ""|"")
        print(""x"" * n)

import re
import sys
from colorsys import rgb_to_hls
from enum import IntEnum
from functools import lru_cache
from typing import TYPE_CHECKING, NamedTuple, Optional, Tuple

from ._palettes import EIGHT_BIT_PALETTE, STANDARD_PALETTE, WINDOWS_PALETTE
from .color_triplet import ColorTriplet
from .repr import Result, rich_repr
from .terminal_theme import DEFAULT_TERMINAL_THEME

if TYPE_CHECKING:  
    from .terminal_theme import TerminalTheme
    from .text import Text


WINDOWS = sys.platform == ""win32""


class ColorSystem(IntEnum):
    

    STANDARD = 1
    EIGHT_BIT = 2
    TRUECOLOR = 3
    WINDOWS = 4

    def __repr__(self) -> str:
        return f""ColorSystem.{self.name}""

    def __str__(self) -> str:
        return repr(self)


class ColorType(IntEnum):
    

    DEFAULT = 0
    STANDARD = 1
    EIGHT_BIT = 2
    TRUECOLOR = 3
    WINDOWS = 4

    def __repr__(self) -> str:
        return f""ColorType.{self.name}""


ANSI_COLOR_NAMES = {
    ""black"": 0,
    ""red"": 1,
    ""green"": 2,
    ""yellow"": 3,
    ""blue"": 4,
    ""magenta"": 5,
    ""cyan"": 6,
    ""white"": 7,
    ""bright_black"": 8,
    ""bright_red"": 9,
    ""bright_green"": 10,
    ""bright_yellow"": 11,
    ""bright_blue"": 12,
    ""bright_magenta"": 13,
    ""bright_cyan"": 14,
    ""bright_white"": 15,
    ""grey0"": 16,
    ""gray0"": 16,
    ""navy_blue"": 17,
    ""dark_blue"": 18,
    ""blue3"": 20,
    ""blue1"": 21,
    ""dark_green"": 22,
    ""deep_sky_blue4"": 25,
    ""dodger_blue3"": 26,
    ""dodger_blue2"": 27,
    ""green4"": 28,
    ""spring_green4"": 29,
    ""turquoise4"": 30,
    ""deep_sky_blue3"": 32,
    ""dodger_blue1"": 33,
    ""green3"": 40,
    ""spring_green3"": 41,
    ""dark_cyan"": 36,
    ""light_sea_green"": 37,
    ""deep_sky_blue2"": 38,
    ""deep_sky_blue1"": 39,
    ""spring_green2"": 47,
    ""cyan3"": 43,
    ""dark_turquoise"": 44,
    ""turquoise2"": 45,
    ""green1"": 46,
    ""spring_green1"": 48,
    ""medium_spring_green"": 49,
    ""cyan2"": 50,
    ""cyan1"": 51,
    ""dark_red"": 88,
    ""deep_pink4"": 125,
    ""purple4"": 55,
    ""purple3"": 56,
    ""blue_violet"": 57,
    ""orange4"": 94,
    ""grey37"": 59,
    ""gray37"": 59,
    ""medium_purple4"": 60,
    ""slate_blue3"": 62,
    ""royal_blue1"": 63,
    ""chartreuse4"": 64,
    ""dark_sea_green4"": 71,
    ""pale_turquoise4"": 66,
    ""steel_blue"": 67,
    ""steel_blue3"": 68,
    ""cornflower_blue"": 69,
    ""chartreuse3"": 76,
    ""cadet_blue"": 73,
    ""sky_blue3"": 74,
    ""steel_blue1"": 81,
    ""pale_green3"": 114,
    ""sea_green3"": 78,
    ""aquamarine3"": 79,
    ""medium_turquoise"": 80,
    ""chartreuse2"": 112,
    ""sea_green2"": 83,
    ""sea_green1"": 85,
    ""aquamarine1"": 122,
    ""dark_slate_gray2"": 87,
    ""dark_magenta"": 91,
    ""dark_violet"": 128,
    ""purple"": 129,
    ""light_pink4"": 95,
    ""plum4"": 96,
    ""medium_purple3"": 98,
    ""slate_blue1"": 99,
    ""yellow4"": 106,
    ""wheat4"": 101,
    ""grey53"": 102,
    ""gray53"": 102,
    ""light_slate_grey"": 103,
    ""light_slate_gray"": 103,
    ""medium_purple"": 104,
    ""light_slate_blue"": 105,
    ""dark_olive_green3"": 149,
    ""dark_sea_green"": 108,
    ""light_sky_blue3"": 110,
    ""sky_blue2"": 111,
    ""dark_sea_green3"": 150,
    ""dark_slate_gray3"": 116,
    ""sky_blue1"": 117,
    ""chartreuse1"": 118,
    ""light_green"": 120,
    ""pale_green1"": 156,
    ""dark_slate_gray1"": 123,
    ""red3"": 160,
    ""medium_violet_red"": 126,
    ""magenta3"": 164,
    ""dark_orange3"": 166,
    ""indian_red"": 167,
    ""hot_pink3"": 168,
    ""medium_orchid3"": 133,
    ""medium_orchid"": 134,
    ""medium_purple2"": 140,
    ""dark_goldenrod"": 136,
    ""light_salmon3"": 173,
    ""rosy_brown"": 138,
    ""grey63"": 139,
    ""gray63"": 139,
    ""medium_purple1"": 141,
    ""gold3"": 178,
    ""dark_khaki"": 143,
    ""navajo_white3"": 144,
    ""grey69"": 145,
    ""gray69"": 145,
    ""light_steel_blue3"": 146,
    ""light_steel_blue"": 147,
    ""yellow3"": 184,
    ""dark_sea_green2"": 157,
    ""light_cyan3"": 152,
    ""light_sky_blue1"": 153,
    ""green_yellow"": 154,
    ""dark_olive_green2"": 155,
    ""dark_sea_green1"": 193,
    ""pale_turquoise1"": 159,
    ""deep_pink3"": 162,
    ""magenta2"": 200,
    ""hot_pink2"": 169,
    ""orchid"": 170,
    ""medium_orchid1"": 207,
    ""orange3"": 172,
    ""light_pink3"": 174,
    ""pink3"": 175,
    ""plum3"": 176,
    ""violet"": 177,
    ""light_goldenrod3"": 179,
    ""tan"": 180,
    ""misty_rose3"": 181,
    ""thistle3"": 182,
    ""plum2"": 183,
    ""khaki3"": 185,
    ""light_goldenrod2"": 222,
    ""light_yellow3"": 187,
    ""grey84"": 188,
    ""gray84"": 188,
    ""light_steel_blue1"": 189,
    ""yellow2"": 190,
    ""dark_olive_green1"": 192,
    ""honeydew2"": 194,
    ""light_cyan1"": 195,
    ""red1"": 196,
    ""deep_pink2"": 197,
    ""deep_pink1"": 199,
    ""magenta1"": 201,
    ""orange_red1"": 202,
    ""indian_red1"": 204,
    ""hot_pink"": 206,
    ""dark_orange"": 208,
    ""salmon1"": 209,
    ""light_coral"": 210,
    ""pale_violet_red1"": 211,
    ""orchid2"": 212,
    ""orchid1"": 213,
    ""orange1"": 214,
    ""sandy_brown"": 215,
    ""light_salmon1"": 216,
    ""light_pink1"": 217,
    ""pink1"": 218,
    ""plum1"": 219,
    ""gold1"": 220,
    ""navajo_white1"": 223,
    ""misty_rose1"": 224,
    ""thistle1"": 225,
    ""yellow1"": 226,
    ""light_goldenrod1"": 227,
    ""khaki1"": 228,
    ""wheat1"": 229,
    ""cornsilk1"": 230,
    ""grey100"": 231,
    ""gray100"": 231,
    ""grey3"": 232,
    ""gray3"": 232,
    ""grey7"": 233,
    ""gray7"": 233,
    ""grey11"": 234,
    ""gray11"": 234,
    ""grey15"": 235,
    ""gray15"": 235,
    ""grey19"": 236,
    ""gray19"": 236,
    ""grey23"": 237,
    ""gray23"": 237,
    ""grey27"": 238,
    ""gray27"": 238,
    ""grey30"": 239,
    ""gray30"": 239,
    ""grey35"": 240,
    ""gray35"": 240,
    ""grey39"": 241,
    ""gray39"": 241,
    ""grey42"": 242,
    ""gray42"": 242,
    ""grey46"": 243,
    ""gray46"": 243,
    ""grey50"": 244,
    ""gray50"": 244,
    ""grey54"": 245,
    ""gray54"": 245,
    ""grey58"": 246,
    ""gray58"": 246,
    ""grey62"": 247,
    ""gray62"": 247,
    ""grey66"": 248,
    ""gray66"": 248,
    ""grey70"": 249,
    ""gray70"": 249,
    ""grey74"": 250,
    ""gray74"": 250,
    ""grey78"": 251,
    ""gray78"": 251,
    ""grey82"": 252,
    ""gray82"": 252,
    ""grey85"": 253,
    ""gray85"": 253,
    ""grey89"": 254,
    ""gray89"": 254,
    ""grey93"": 255,
    ""gray93"": 255,
}


class ColorParseError(Exception):
    


RE_COLOR = re.compile(
    r,
    re.VERBOSE,
)


@rich_repr
class Color(NamedTuple):
    

    name: str
    
    type: ColorType
    
    number: Optional[int] = None
    
    triplet: Optional[ColorTriplet] = None
    

    def __rich__(self) -> ""Text"":
        
        from .style import Style
        from .text import Text

        return Text.assemble(
            f""<color {self.name!r} ({self.type.name.lower()})"",
            (""⬤"", Style(color=self)),
            "" >"",
        )

    def __rich_repr__(self) -> Result:
        yield self.name
        yield self.type
        yield ""number"", self.number, None
        yield ""triplet"", self.triplet, None

    @property
    def system(self) -> ColorSystem:
        
        if self.type == ColorType.DEFAULT:
            return ColorSystem.STANDARD
        return ColorSystem(int(self.type))

    @property
    def is_system_defined(self) -> bool:
        
        return self.system not in (ColorSystem.EIGHT_BIT, ColorSystem.TRUECOLOR)

    @property
    def is_default(self) -> bool:
        
        return self.type == ColorType.DEFAULT

    def get_truecolor(
        self, theme: Optional[""TerminalTheme""] = None, foreground: bool = True
    ) -> ColorTriplet:
        

        if theme is None:
            theme = DEFAULT_TERMINAL_THEME
        if self.type == ColorType.TRUECOLOR:
            assert self.triplet is not None
            return self.triplet
        elif self.type == ColorType.EIGHT_BIT:
            assert self.number is not None
            return EIGHT_BIT_PALETTE[self.number]
        elif self.type == ColorType.STANDARD:
            assert self.number is not None
            return theme.ansi_colors[self.number]
        elif self.type == ColorType.WINDOWS:
            assert self.number is not None
            return WINDOWS_PALETTE[self.number]
        else:  
            assert self.number is None
            return theme.foreground_color if foreground else theme.background_color

    @classmethod
    def from_ansi(cls, number: int) -> ""Color"":
        
        return cls(
            name=f""color({number})"",
            type=(ColorType.STANDARD if number < 16 else ColorType.EIGHT_BIT),
            number=number,
        )

    @classmethod
    def from_triplet(cls, triplet: ""ColorTriplet"") -> ""Color"":
        
        return cls(name=triplet.hex, type=ColorType.TRUECOLOR, triplet=triplet)

    @classmethod
    def from_rgb(cls, red: float, green: float, blue: float) -> ""Color"":
        
        return cls.from_triplet(ColorTriplet(int(red), int(green), int(blue)))

    @classmethod
    def default(cls) -> ""Color"":
        
        return cls(name=""default"", type=ColorType.DEFAULT)

    @classmethod
    @lru_cache(maxsize=1024)
    def parse(cls, color: str) -> ""Color"":
        
        original_color = color
        color = color.lower().strip()

        if color == ""default"":
            return cls(color, type=ColorType.DEFAULT)

        color_number = ANSI_COLOR_NAMES.get(color)
        if color_number is not None:
            return cls(
                color,
                type=(ColorType.STANDARD if color_number < 16 else ColorType.EIGHT_BIT),
                number=color_number,
            )

        color_match = RE_COLOR.match(color)
        if color_match is None:
            raise ColorParseError(f""{original_color!r} is not a valid color"")

        color_24, color_8, color_rgb = color_match.groups()
        if color_24:
            triplet = ColorTriplet(
                int(color_24[0:2], 16), int(color_24[2:4], 16), int(color_24[4:6], 16)
            )
            return cls(color, ColorType.TRUECOLOR, triplet=triplet)

        elif color_8:
            number = int(color_8)
            if number > 255:
                raise ColorParseError(f""color number must be <= 255 in {color!r}"")
            return cls(
                color,
                type=(ColorType.STANDARD if number < 16 else ColorType.EIGHT_BIT),
                number=number,
            )

        else:  
            components = color_rgb.split("","")
            if len(components) != 3:
                raise ColorParseError(
                    f""expected three components in {original_color!r}""
                )
            red, green, blue = components
            triplet = ColorTriplet(int(red), int(green), int(blue))
            if not all(component <= 255 for component in triplet):
                raise ColorParseError(
                    f""color components must be <= 255 in {original_color!r}""
                )
            return cls(color, ColorType.TRUECOLOR, triplet=triplet)

    @lru_cache(maxsize=1024)
    def get_ansi_codes(self, foreground: bool = True) -> Tuple[str, ...]:
        
        _type = self.type
        if _type == ColorType.DEFAULT:
            return (""39"" if foreground else ""49"",)

        elif _type == ColorType.WINDOWS:
            number = self.number
            assert number is not None
            fore, back = (30, 40) if number < 8 else (82, 92)
            return (str(fore + number if foreground else back + number),)

        elif _type == ColorType.STANDARD:
            number = self.number
            assert number is not None
            fore, back = (30, 40) if number < 8 else (82, 92)
            return (str(fore + number if foreground else back + number),)

        elif _type == ColorType.EIGHT_BIT:
            assert self.number is not None
            return (""38"" if foreground else ""48"", ""5"", str(self.number))

        else:  
            assert self.triplet is not None
            red, green, blue = self.triplet
            return (""38"" if foreground else ""48"", ""2"", str(red), str(green), str(blue))

    @lru_cache(maxsize=1024)
    def downgrade(self, system: ColorSystem) -> ""Color"":
        

        if self.type in (ColorType.DEFAULT, system):
            return self
        
        if system == ColorSystem.EIGHT_BIT and self.system == ColorSystem.TRUECOLOR:
            assert self.triplet is not None
            _h, l, s = rgb_to_hls(*self.triplet.normalized)
            
            if s < 0.15:
                gray = round(l * 25.0)
                if gray == 0:
                    color_number = 16
                elif gray == 25:
                    color_number = 231
                else:
                    color_number = 231 + gray
                return Color(self.name, ColorType.EIGHT_BIT, number=color_number)

            red, green, blue = self.triplet
            six_red = red / 95 if red < 95 else 1 + (red - 95) / 40
            six_green = green / 95 if green < 95 else 1 + (green - 95) / 40
            six_blue = blue / 95 if blue < 95 else 1 + (blue - 95) / 40

            color_number = (
                16 + 36 * round(six_red) + 6 * round(six_green) + round(six_blue)
            )
            return Color(self.name, ColorType.EIGHT_BIT, number=color_number)

        
        elif system == ColorSystem.STANDARD:
            if self.system == ColorSystem.TRUECOLOR:
                assert self.triplet is not None
                triplet = self.triplet
            else:  
                assert self.number is not None
                triplet = ColorTriplet(*EIGHT_BIT_PALETTE[self.number])

            color_number = STANDARD_PALETTE.match(triplet)
            return Color(self.name, ColorType.STANDARD, number=color_number)

        elif system == ColorSystem.WINDOWS:
            if self.system == ColorSystem.TRUECOLOR:
                assert self.triplet is not None
                triplet = self.triplet
            else:  
                assert self.number is not None
                if self.number < 16:
                    return Color(self.name, ColorType.WINDOWS, number=self.number)
                triplet = ColorTriplet(*EIGHT_BIT_PALETTE[self.number])

            color_number = WINDOWS_PALETTE.match(triplet)
            return Color(self.name, ColorType.WINDOWS, number=color_number)

        return self


def parse_rgb_hex(hex_color: str) -> ColorTriplet:
    
    assert len(hex_color) == 6, ""must be 6 characters""
    color = ColorTriplet(
        int(hex_color[0:2], 16), int(hex_color[2:4], 16), int(hex_color[4:6], 16)
    )
    return color


def blend_rgb(
    color1: ColorTriplet, color2: ColorTriplet, cross_fade: float = 0.5
) -> ColorTriplet:
    
    r1, g1, b1 = color1
    r2, g2, b2 = color2
    new_color = ColorTriplet(
        int(r1 + (r2 - r1) * cross_fade),
        int(g1 + (g2 - g1) * cross_fade),
        int(b1 + (b2 - b1) * cross_fade),
    )
    return new_color


if __name__ == ""__main__"":  
    from .console import Console
    from .table import Table
    from .text import Text

    console = Console()

    table = Table(show_footer=False, show_edge=True)
    table.add_column(""Color"", width=10, overflow=""ellipsis"")
    table.add_column(""Number"", justify=""right"", style=""yellow"")
    table.add_column(""Name"", style=""green"")
    table.add_column(""Hex"", style=""blue"")
    table.add_column(""RGB"", style=""magenta"")

    colors = sorted((v, k) for k, v in ANSI_COLOR_NAMES.items())
    for color_number, name in colors:
        if ""grey"" in name:
            continue
        color_cell = Text("" "" * 10, style=f""on {name}"")
        if color_number < 16:
            table.add_row(color_cell, f""{color_number}"", Text(f'""{name}""'))
        else:
            color = EIGHT_BIT_PALETTE[color_number]  
            table.add_row(
                color_cell, str(color_number), Text(f'""{name}""'), color.hex, color.rgb
            )

    console.print(table)

from typing import NamedTuple, Tuple


class ColorTriplet(NamedTuple):
    

    red: int
    
    green: int
    
    blue: int
    

    @property
    def hex(self) -> str:
        
        red, green, blue = self
        return f""

    @property
    def rgb(self) -> str:
        
        red, green, blue = self
        return f""rgb({red},{green},{blue})""

    @property
    def normalized(self) -> Tuple[float, float, float]:
        
        red, green, blue = self
        return red / 255.0, green / 255.0, blue / 255.0

from collections import defaultdict
from itertools import chain
from operator import itemgetter
from typing import Dict, Iterable, List, Optional, Tuple

from .align import Align, AlignMethod
from .console import Console, ConsoleOptions, RenderableType, RenderResult
from .constrain import Constrain
from .measure import Measurement
from .padding import Padding, PaddingDimensions
from .table import Table
from .text import TextType
from .jupyter import JupyterMixin


class Columns(JupyterMixin):
    

    def __init__(
        self,
        renderables: Optional[Iterable[RenderableType]] = None,
        padding: PaddingDimensions = (0, 1),
        *,
        width: Optional[int] = None,
        expand: bool = False,
        equal: bool = False,
        column_first: bool = False,
        right_to_left: bool = False,
        align: Optional[AlignMethod] = None,
        title: Optional[TextType] = None,
    ) -> None:
        self.renderables = list(renderables or [])
        self.width = width
        self.padding = padding
        self.expand = expand
        self.equal = equal
        self.column_first = column_first
        self.right_to_left = right_to_left
        self.align: Optional[AlignMethod] = align
        self.title = title

    def add_renderable(self, renderable: RenderableType) -> None:
        
        self.renderables.append(renderable)

    def __rich_console__(
        self, console: Console, options: ConsoleOptions
    ) -> RenderResult:
        render_str = console.render_str
        renderables = [
            render_str(renderable) if isinstance(renderable, str) else renderable
            for renderable in self.renderables
        ]
        if not renderables:
            return
        _top, right, _bottom, left = Padding.unpack(self.padding)
        width_padding = max(left, right)
        max_width = options.max_width
        widths: Dict[int, int] = defaultdict(int)
        column_count = len(renderables)

        get_measurement = Measurement.get
        renderable_widths = [
            get_measurement(console, options, renderable).maximum
            for renderable in renderables
        ]
        if self.equal:
            renderable_widths = [max(renderable_widths)] * len(renderable_widths)

        def iter_renderables(
            column_count: int,
        ) -> Iterable[Tuple[int, Optional[RenderableType]]]:
            item_count = len(renderables)
            if self.column_first:
                width_renderables = list(zip(renderable_widths, renderables))

                column_lengths: List[int] = [item_count // column_count] * column_count
                for col_no in range(item_count % column_count):
                    column_lengths[col_no] += 1

                row_count = (item_count + column_count - 1) // column_count
                cells = [[-1] * column_count for _ in range(row_count)]
                row = col = 0
                for index in range(item_count):
                    cells[row][col] = index
                    column_lengths[col] -= 1
                    if column_lengths[col]:
                        row += 1
                    else:
                        col += 1
                        row = 0
                for index in chain.from_iterable(cells):
                    if index == -1:
                        break
                    yield width_renderables[index]
            else:
                yield from zip(renderable_widths, renderables)
            
            if item_count % column_count:
                for _ in range(column_count - (item_count % column_count)):
                    yield 0, None

        table = Table.grid(padding=self.padding, collapse_padding=True, pad_edge=False)
        table.expand = self.expand
        table.title = self.title

        if self.width is not None:
            column_count = (max_width) // (self.width + width_padding)
            for _ in range(column_count):
                table.add_column(width=self.width)
        else:
            while column_count > 1:
                widths.clear()
                column_no = 0
                for renderable_width, _ in iter_renderables(column_count):
                    widths[column_no] = max(widths[column_no], renderable_width)
                    total_width = sum(widths.values()) + width_padding * (
                        len(widths) - 1
                    )
                    if total_width > max_width:
                        column_count = len(widths) - 1
                        break
                    else:
                        column_no = (column_no + 1) % column_count
                else:
                    break

        get_renderable = itemgetter(1)
        _renderables = [
            get_renderable(_renderable)
            for _renderable in iter_renderables(column_count)
        ]
        if self.equal:
            _renderables = [
                None
                if renderable is None
                else Constrain(renderable, renderable_widths[0])
                for renderable in _renderables
            ]
        if self.align:
            align = self.align
            _Align = Align
            _renderables = [
                None if renderable is None else _Align(renderable, align)
                for renderable in _renderables
            ]

        right_to_left = self.right_to_left
        add_row = table.add_row
        for start in range(0, len(_renderables), column_count):
            row = _renderables[start : start + column_count]
            if right_to_left:
                row = row[::-1]
            add_row(*row)
        yield table


if __name__ == ""__main__"":  
    import os

    console = Console()

    files = [f""{i} {s}"" for i, s in enumerate(sorted(os.listdir()))]
    columns = Columns(files, padding=(0, 1), expand=False, equal=False)
    console.print(columns)
    console.rule()
    columns.column_first = True
    console.print(columns)
    columns.right_to_left = True
    console.rule()
    console.print(columns)

import inspect
import os
import sys
import threading
import zlib
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from datetime import datetime
from functools import wraps
from getpass import getpass
from html import escape
from inspect import isclass
from itertools import islice
from math import ceil
from time import monotonic
from types import FrameType, ModuleType, TracebackType
from typing import (
    IO,
    TYPE_CHECKING,
    Any,
    Callable,
    Dict,
    Iterable,
    List,
    Literal,
    Mapping,
    NamedTuple,
    Optional,
    Protocol,
    TextIO,
    Tuple,
    Type,
    Union,
    cast,
    runtime_checkable,
)

from pip._vendor.rich._null_file import NULL_FILE

from . import errors, themes
from ._emoji_replace import _emoji_replace
from ._export_format import CONSOLE_HTML_FORMAT, CONSOLE_SVG_FORMAT
from ._fileno import get_fileno
from ._log_render import FormatTimeCallable, LogRender
from .align import Align, AlignMethod
from .color import ColorSystem, blend_rgb
from .control import Control
from .emoji import EmojiVariant
from .highlighter import NullHighlighter, ReprHighlighter
from .markup import render as render_markup
from .measure import Measurement, measure_renderables
from .pager import Pager, SystemPager
from .pretty import Pretty, is_expandable
from .protocol import rich_cast
from .region import Region
from .scope import render_scope
from .screen import Screen
from .segment import Segment
from .style import Style, StyleType
from .styled import Styled
from .terminal_theme import DEFAULT_TERMINAL_THEME, SVG_EXPORT_THEME, TerminalTheme
from .text import Text, TextType
from .theme import Theme, ThemeStack

if TYPE_CHECKING:
    from ._windows import WindowsConsoleFeatures
    from .live import Live
    from .status import Status

JUPYTER_DEFAULT_COLUMNS = 115
JUPYTER_DEFAULT_LINES = 100
WINDOWS = sys.platform == ""win32""

HighlighterType = Callable[[Union[str, ""Text""]], ""Text""]
JustifyMethod = Literal[""default"", ""left"", ""center"", ""right"", ""full""]
OverflowMethod = Literal[""fold"", ""crop"", ""ellipsis"", ""ignore""]


class NoChange:
    pass


NO_CHANGE = NoChange()

try:
    _STDIN_FILENO = sys.__stdin__.fileno()  
except Exception:
    _STDIN_FILENO = 0
try:
    _STDOUT_FILENO = sys.__stdout__.fileno()  
except Exception:
    _STDOUT_FILENO = 1
try:
    _STDERR_FILENO = sys.__stderr__.fileno()  
except Exception:
    _STDERR_FILENO = 2

_STD_STREAMS = (_STDIN_FILENO, _STDOUT_FILENO, _STDERR_FILENO)
_STD_STREAMS_OUTPUT = (_STDOUT_FILENO, _STDERR_FILENO)


_TERM_COLORS = {
    ""kitty"": ColorSystem.EIGHT_BIT,
    ""256color"": ColorSystem.EIGHT_BIT,
    ""16color"": ColorSystem.STANDARD,
}


class ConsoleDimensions(NamedTuple):
    

    width: int
    
    height: int
    


@dataclass
class ConsoleOptions:
    

    size: ConsoleDimensions
    
    legacy_windows: bool
    
    min_width: int
    
    max_width: int
    
    is_terminal: bool
    
    encoding: str
    
    max_height: int
    
    justify: Optional[JustifyMethod] = None
    
    overflow: Optional[OverflowMethod] = None
    
    no_wrap: Optional[bool] = False
    
    highlight: Optional[bool] = None
    
    markup: Optional[bool] = None
    
    height: Optional[int] = None

    @property
    def ascii_only(self) -> bool:
        
        return not self.encoding.startswith(""utf"")

    def copy(self) -> ""ConsoleOptions"":
        
        options: ConsoleOptions = ConsoleOptions.__new__(ConsoleOptions)
        options.__dict__ = self.__dict__.copy()
        return options

    def update(
        self,
        *,
        width: Union[int, NoChange] = NO_CHANGE,
        min_width: Union[int, NoChange] = NO_CHANGE,
        max_width: Union[int, NoChange] = NO_CHANGE,
        justify: Union[Optional[JustifyMethod], NoChange] = NO_CHANGE,
        overflow: Union[Optional[OverflowMethod], NoChange] = NO_CHANGE,
        no_wrap: Union[Optional[bool], NoChange] = NO_CHANGE,
        highlight: Union[Optional[bool], NoChange] = NO_CHANGE,
        markup: Union[Optional[bool], NoChange] = NO_CHANGE,
        height: Union[Optional[int], NoChange] = NO_CHANGE,
    ) -> ""ConsoleOptions"":
        
        options = self.copy()
        if not isinstance(width, NoChange):
            options.min_width = options.max_width = max(0, width)
        if not isinstance(min_width, NoChange):
            options.min_width = min_width
        if not isinstance(max_width, NoChange):
            options.max_width = max_width
        if not isinstance(justify, NoChange):
            options.justify = justify
        if not isinstance(overflow, NoChange):
            options.overflow = overflow
        if not isinstance(no_wrap, NoChange):
            options.no_wrap = no_wrap
        if not isinstance(highlight, NoChange):
            options.highlight = highlight
        if not isinstance(markup, NoChange):
            options.markup = markup
        if not isinstance(height, NoChange):
            if height is not None:
                options.max_height = height
            options.height = None if height is None else max(0, height)
        return options

    def update_width(self, width: int) -> ""ConsoleOptions"":
        
        options = self.copy()
        options.min_width = options.max_width = max(0, width)
        return options

    def update_height(self, height: int) -> ""ConsoleOptions"":
        
        options = self.copy()
        options.max_height = options.height = height
        return options

    def reset_height(self) -> ""ConsoleOptions"":
        
        options = self.copy()
        options.height = None
        return options

    def update_dimensions(self, width: int, height: int) -> ""ConsoleOptions"":
        
        options = self.copy()
        options.min_width = options.max_width = max(0, width)
        options.height = options.max_height = height
        return options


@runtime_checkable
class RichCast(Protocol):
    

    def __rich__(
        self,
    ) -> Union[""ConsoleRenderable"", ""RichCast"", str]:  
        ...


@runtime_checkable
class ConsoleRenderable(Protocol):
    

    def __rich_console__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> ""RenderResult"":  
        ...



RenderableType = Union[ConsoleRenderable, RichCast, str]



RenderResult = Iterable[Union[RenderableType, Segment]]

_null_highlighter = NullHighlighter()


class CaptureError(Exception):
    


class NewLine:
    

    def __init__(self, count: int = 1) -> None:
        self.count = count

    def __rich_console__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> Iterable[Segment]:
        yield Segment(""\n"" * self.count)


class ScreenUpdate:
    

    def __init__(self, lines: List[List[Segment]], x: int, y: int) -> None:
        self._lines = lines
        self.x = x
        self.y = y

    def __rich_console__(
        self, console: ""Console"", options: ConsoleOptions
    ) -> RenderResult:
        x = self.x
        move_to = Control.move_to
        for offset, line in enumerate(self._lines, self.y):
            yield move_to(x, offset)
            yield from line


class Capture:
    

    def __init__(self, console: ""Console"") -> None:
        self._console = console
        self._result: Optional[str] = None

    def __enter__(self) -> ""Capture"":
        self._console.begin_capture()
        return self

    def __exit__(
        self,
        exc_type: Optional[Type[BaseException]],
        exc_val: Optional[BaseException],
        exc_tb: Optional[TracebackType],
    ) -> None:
        self._result = self._console.end_capture()

    def get(self) -> str:
        
        if self._result is None:
            raise CaptureError(
                ""Capture result is not available until context manager exits.""
            )
        return self._result


class ThemeContext:
    

    def __init__(self, console: ""Console"", theme: Theme, inherit: bool = True) -> None:
        self.console = console
        self.theme = theme
        self.inherit = inherit

    def __enter__(self) -> ""ThemeContext"":
        self.console.push_theme(self.theme)
        return self

    def __exit__(
        self,
        exc_type: Optional[Type[BaseException]],
        exc_val: Optional[BaseException],
        exc_tb: Optional[TracebackType],
    ) -> None:
        self.console.pop_theme()


class PagerContext:
    

    def __init__(
        self,
        console: ""Console"",
        pager: Optional[Pager] = None,
        styles: bool = False,
        links: bool = False,
    ) -> None:
        self._console = console
        self.pager = SystemPager() if pager is None else pager
        self.styles = styles
        self.links = links

    def __enter__(self) -> ""PagerContext"":
        self._console._enter_buffer()
        return self

    def __exit__(
        self,
        exc_type: Optional[Type[BaseException]],
        exc_val: Optional[BaseException],
        exc_tb: Optional[TracebackType],
    ) -> None:
        if exc_type is None:
            with self._console._lock:
                buffer: List[Segment] = self._console._buffer[:]
                del self._console._buffer[:]
                segments: Iterable[Segment] = buffer
                if not self.styles:
                    segments = Segment.strip_styles(segments)
                elif not self.links:
                    segments = Segment.strip_links(segments)
                content = self._console._render_buffer(segments)
            self.pager.show(content)
        self._console._exit_buffer()


class ScreenContext:
    

    def __init__(
        self, console: ""Console"", hide_cursor: bool, style: StyleType = """"
    ) -> None:
        self.console = console
        self.hide_cursor = hide_cursor
        self.screen = Screen(style=style)
        self._changed = False

    def update(
        self, *renderables: RenderableType, style: Optional[StyleType] = None
    ) -> None:
        
        if renderables:
            self.screen.renderable = (
                Group(*renderables) if len(renderables) > 1 else renderables[0]
            )
        if style is not None:
            self.screen.style = style
        self.console.print(self.screen, end="""")

    def __enter__(self) -> ""ScreenContext"":
        self._changed = self.console.set_alt_screen(True)
        if self._changed and self.hide_cursor:
            self.console.show_cursor(False)
        return self

    def __exit__(
        self,
        exc_type: Optional[Type[BaseException]],
        exc_val: Optional[BaseException],
        exc_tb: Optional[TracebackType],
    ) -> None:
        if self._changed:
            self.console.set_alt_screen(False)
            if self.hide_cursor:
                self.console.show_cursor(True)


class Group:
    

    def __init__(self, *renderables: ""RenderableType"", fit: bool = True) -> None:
        self._renderables = renderables
        self.fit = fit
        self._render: Optional[List[RenderableType]] = None

    @property
    def renderables(self) -> List[""RenderableType""]:
        if self._render is None:
            self._render = list(self._renderables)
        return self._render

    def __rich_measure__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> ""Measurement"":
        if self.fit:
            return measure_renderables(console, options, self.renderables)
        else:
            return Measurement(options.max_width, options.max_width)

    def __rich_console__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> RenderResult:
        yield from self.renderables


def group(fit: bool = True) -> Callable[..., Callable[..., Group]]:
    

    def decorator(
        method: Callable[..., Iterable[RenderableType]],
    ) -> Callable[..., Group]:
        

        @wraps(method)
        def _replace(*args: Any, **kwargs: Any) -> Group:
            renderables = method(*args, **kwargs)
            return Group(*renderables, fit=fit)

        return _replace

    return decorator


def _is_jupyter() -> bool:  
    
    try:
        get_ipython  
    except NameError:
        return False
    ipython = get_ipython()  
    shell = ipython.__class__.__name__
    if (
        ""google.colab"" in str(ipython.__class__)
        or os.getenv(""DATABRICKS_RUNTIME_VERSION"")
        or shell == ""ZMQInteractiveShell""
    ):
        return True  
    elif shell == ""TerminalInteractiveShell"":
        return False  
    else:
        return False  


COLOR_SYSTEMS = {
    ""standard"": ColorSystem.STANDARD,
    ""256"": ColorSystem.EIGHT_BIT,
    ""truecolor"": ColorSystem.TRUECOLOR,
    ""windows"": ColorSystem.WINDOWS,
}

_COLOR_SYSTEMS_NAMES = {system: name for name, system in COLOR_SYSTEMS.items()}


@dataclass
class ConsoleThreadLocals(threading.local):
    

    theme_stack: ThemeStack
    buffer: List[Segment] = field(default_factory=list)
    buffer_index: int = 0


class RenderHook(ABC):
    

    @abstractmethod
    def process_renderables(
        self, renderables: List[ConsoleRenderable]
    ) -> List[ConsoleRenderable]:
        


_windows_console_features: Optional[""WindowsConsoleFeatures""] = None


def get_windows_console_features() -> ""WindowsConsoleFeatures"":  
    global _windows_console_features
    if _windows_console_features is not None:
        return _windows_console_features
    from ._windows import get_windows_console_features

    _windows_console_features = get_windows_console_features()
    return _windows_console_features


def detect_legacy_windows() -> bool:
    
    return WINDOWS and not get_windows_console_features().vt


class Console:
    

    _environ: Mapping[str, str] = os.environ

    def __init__(
        self,
        *,
        color_system: Optional[
            Literal[""auto"", ""standard"", ""256"", ""truecolor"", ""windows""]
        ] = ""auto"",
        force_terminal: Optional[bool] = None,
        force_jupyter: Optional[bool] = None,
        force_interactive: Optional[bool] = None,
        soft_wrap: bool = False,
        theme: Optional[Theme] = None,
        stderr: bool = False,
        file: Optional[IO[str]] = None,
        quiet: bool = False,
        width: Optional[int] = None,
        height: Optional[int] = None,
        style: Optional[StyleType] = None,
        no_color: Optional[bool] = None,
        tab_size: int = 8,
        record: bool = False,
        markup: bool = True,
        emoji: bool = True,
        emoji_variant: Optional[EmojiVariant] = None,
        highlight: bool = True,
        log_time: bool = True,
        log_path: bool = True,
        log_time_format: Union[str, FormatTimeCallable] = ""[%X]"",
        highlighter: Optional[""HighlighterType""] = ReprHighlighter(),
        legacy_windows: Optional[bool] = None,
        safe_box: bool = True,
        get_datetime: Optional[Callable[[], datetime]] = None,
        get_time: Optional[Callable[[], float]] = None,
        _environ: Optional[Mapping[str, str]] = None,
    ):
        
        if _environ is not None:
            self._environ = _environ

        self.is_jupyter = _is_jupyter() if force_jupyter is None else force_jupyter
        if self.is_jupyter:
            if width is None:
                jupyter_columns = self._environ.get(""JUPYTER_COLUMNS"")
                if jupyter_columns is not None and jupyter_columns.isdigit():
                    width = int(jupyter_columns)
                else:
                    width = JUPYTER_DEFAULT_COLUMNS
            if height is None:
                jupyter_lines = self._environ.get(""JUPYTER_LINES"")
                if jupyter_lines is not None and jupyter_lines.isdigit():
                    height = int(jupyter_lines)
                else:
                    height = JUPYTER_DEFAULT_LINES

        self.tab_size = tab_size
        self.record = record
        self._markup = markup
        self._emoji = emoji
        self._emoji_variant: Optional[EmojiVariant] = emoji_variant
        self._highlight = highlight
        self.legacy_windows: bool = (
            (detect_legacy_windows() and not self.is_jupyter)
            if legacy_windows is None
            else legacy_windows
        )

        if width is None:
            columns = self._environ.get(""COLUMNS"")
            if columns is not None and columns.isdigit():
                width = int(columns) - self.legacy_windows
        if height is None:
            lines = self._environ.get(""LINES"")
            if lines is not None and lines.isdigit():
                height = int(lines)

        self.soft_wrap = soft_wrap
        self._width = width
        self._height = height

        self._color_system: Optional[ColorSystem]

        self._force_terminal = None
        if force_terminal is not None:
            self._force_terminal = force_terminal

        self._file = file
        self.quiet = quiet
        self.stderr = stderr

        if color_system is None:
            self._color_system = None
        elif color_system == ""auto"":
            self._color_system = self._detect_color_system()
        else:
            self._color_system = COLOR_SYSTEMS[color_system]

        self._lock = threading.RLock()
        self._log_render = LogRender(
            show_time=log_time,
            show_path=log_path,
            time_format=log_time_format,
        )
        self.highlighter: HighlighterType = highlighter or _null_highlighter
        self.safe_box = safe_box
        self.get_datetime = get_datetime or datetime.now
        self.get_time = get_time or monotonic
        self.style = style
        self.no_color = (
            no_color
            if no_color is not None
            else self._environ.get(""NO_COLOR"", """") != """"
        )
        if force_interactive is None:
            tty_interactive = self._environ.get(""TTY_INTERACTIVE"", None)
            if tty_interactive is not None:
                if tty_interactive == ""0"":
                    force_interactive = False
                elif tty_interactive == ""1"":
                    force_interactive = True

        self.is_interactive = (
            (self.is_terminal and not self.is_dumb_terminal)
            if force_interactive is None
            else force_interactive
        )

        self._record_buffer_lock = threading.RLock()
        self._thread_locals = ConsoleThreadLocals(
            theme_stack=ThemeStack(themes.DEFAULT if theme is None else theme)
        )
        self._record_buffer: List[Segment] = []
        self._render_hooks: List[RenderHook] = []
        self._live_stack: List[Live] = []
        self._is_alt_screen = False

    def __repr__(self) -> str:
        return f""<console width={self.width} {self._color_system!s}>""

    @property
    def file(self) -> IO[str]:
        
        file = self._file or (sys.stderr if self.stderr else sys.stdout)
        file = getattr(file, ""rich_proxied_file"", file)
        if file is None:
            file = NULL_FILE
        return file

    @file.setter
    def file(self, new_file: IO[str]) -> None:
        
        self._file = new_file

    @property
    def _buffer(self) -> List[Segment]:
        
        return self._thread_locals.buffer

    @property
    def _buffer_index(self) -> int:
        
        return self._thread_locals.buffer_index

    @_buffer_index.setter
    def _buffer_index(self, value: int) -> None:
        self._thread_locals.buffer_index = value

    @property
    def _theme_stack(self) -> ThemeStack:
        
        return self._thread_locals.theme_stack

    def _detect_color_system(self) -> Optional[ColorSystem]:
        
        if self.is_jupyter:
            return ColorSystem.TRUECOLOR
        if not self.is_terminal or self.is_dumb_terminal:
            return None
        if WINDOWS:  
            if self.legacy_windows:  
                return ColorSystem.WINDOWS
            windows_console_features = get_windows_console_features()
            return (
                ColorSystem.TRUECOLOR
                if windows_console_features.truecolor
                else ColorSystem.EIGHT_BIT
            )
        else:
            color_term = self._environ.get(""COLORTERM"", """").strip().lower()
            if color_term in (""truecolor"", ""24bit""):
                return ColorSystem.TRUECOLOR
            term = self._environ.get(""TERM"", """").strip().lower()
            _term_name, _hyphen, colors = term.rpartition(""-"")
            color_system = _TERM_COLORS.get(colors, ColorSystem.STANDARD)
            return color_system

    def _enter_buffer(self) -> None:
        
        self._buffer_index += 1

    def _exit_buffer(self) -> None:
        
        self._buffer_index -= 1
        self._check_buffer()

    def set_live(self, live: ""Live"") -> bool:
        
        with self._lock:
            self._live_stack.append(live)
            return len(self._live_stack) == 1

    def clear_live(self) -> None:
        
        with self._lock:
            self._live_stack.pop()

    def push_render_hook(self, hook: RenderHook) -> None:
        
        with self._lock:
            self._render_hooks.append(hook)

    def pop_render_hook(self) -> None:
        
        with self._lock:
            self._render_hooks.pop()

    def __enter__(self) -> ""Console"":
        
        self._enter_buffer()
        return self

    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -> None:
        
        self._exit_buffer()

    def begin_capture(self) -> None:
        
        self._enter_buffer()

    def end_capture(self) -> str:
        
        render_result = self._render_buffer(self._buffer)
        del self._buffer[:]
        self._exit_buffer()
        return render_result

    def push_theme(self, theme: Theme, *, inherit: bool = True) -> None:
        
        self._theme_stack.push_theme(theme, inherit=inherit)

    def pop_theme(self) -> None:
        
        self._theme_stack.pop_theme()

    def use_theme(self, theme: Theme, *, inherit: bool = True) -> ThemeContext:
        
        return ThemeContext(self, theme, inherit)

    @property
    def color_system(self) -> Optional[str]:
        

        if self._color_system is not None:
            return _COLOR_SYSTEMS_NAMES[self._color_system]
        else:
            return None

    @property
    def encoding(self) -> str:
        
        return (getattr(self.file, ""encoding"", ""utf-8"") or ""utf-8"").lower()

    @property
    def is_terminal(self) -> bool:
        
        
        if self._force_terminal is not None:
            return self._force_terminal

        
        if hasattr(sys.stdin, ""__module__"") and sys.stdin.__module__.startswith(
            ""idlelib""
        ):
            
            return False

        if self.is_jupyter:
            
            return False

        environ = self._environ

        tty_compatible = environ.get(""TTY_COMPATIBLE"", """")
        
        if tty_compatible == ""0"":
            return False
        
        if tty_compatible == ""1"":
            return True

        
        force_color = environ.get(""FORCE_COLOR"")
        if force_color is not None:
            return force_color != """"

        
        isatty: Optional[Callable[[], bool]] = getattr(self.file, ""isatty"", None)
        try:
            return False if isatty is None else isatty()
        except ValueError:
            
            
            
            return False

    @property
    def is_dumb_terminal(self) -> bool:
        
        _term = self._environ.get(""TERM"", """")
        is_dumb = _term.lower() in (""dumb"", ""unknown"")
        return self.is_terminal and is_dumb

    @property
    def options(self) -> ConsoleOptions:
        
        size = self.size
        return ConsoleOptions(
            max_height=size.height,
            size=size,
            legacy_windows=self.legacy_windows,
            min_width=1,
            max_width=size.width,
            encoding=self.encoding,
            is_terminal=self.is_terminal,
        )

    @property
    def size(self) -> ConsoleDimensions:
        

        if self._width is not None and self._height is not None:
            return ConsoleDimensions(self._width - self.legacy_windows, self._height)

        if self.is_dumb_terminal:
            return ConsoleDimensions(80, 25)

        width: Optional[int] = None
        height: Optional[int] = None

        streams = _STD_STREAMS_OUTPUT if WINDOWS else _STD_STREAMS
        for file_descriptor in streams:
            try:
                width, height = os.get_terminal_size(file_descriptor)
            except (AttributeError, ValueError, OSError):  
                pass
            else:
                break

        columns = self._environ.get(""COLUMNS"")
        if columns is not None and columns.isdigit():
            width = int(columns)
        lines = self._environ.get(""LINES"")
        if lines is not None and lines.isdigit():
            height = int(lines)

        
        width = width or 80
        height = height or 25
        return ConsoleDimensions(
            width - self.legacy_windows if self._width is None else self._width,
            height if self._height is None else self._height,
        )

    @size.setter
    def size(self, new_size: Tuple[int, int]) -> None:
        
        width, height = new_size
        self._width = width
        self._height = height

    @property
    def width(self) -> int:
        
        return self.size.width

    @width.setter
    def width(self, width: int) -> None:
        
        self._width = width

    @property
    def height(self) -> int:
        
        return self.size.height

    @height.setter
    def height(self, height: int) -> None:
        
        self._height = height

    def bell(self) -> None:
        
        self.control(Control.bell())

    def capture(self) -> Capture:
        
        capture = Capture(self)
        return capture

    def pager(
        self, pager: Optional[Pager] = None, styles: bool = False, links: bool = False
    ) -> PagerContext:
        
        return PagerContext(self, pager=pager, styles=styles, links=links)

    def line(self, count: int = 1) -> None:
        

        assert count >= 0, ""count must be >= 0""
        self.print(NewLine(count))

    def clear(self, home: bool = True) -> None:
        
        if home:
            self.control(Control.clear(), Control.home())
        else:
            self.control(Control.clear())

    def status(
        self,
        status: RenderableType,
        *,
        spinner: str = ""dots"",
        spinner_style: StyleType = ""status.spinner"",
        speed: float = 1.0,
        refresh_per_second: float = 12.5,
    ) -> ""Status"":
        
        from .status import Status

        status_renderable = Status(
            status,
            console=self,
            spinner=spinner,
            spinner_style=spinner_style,
            speed=speed,
            refresh_per_second=refresh_per_second,
        )
        return status_renderable

    def show_cursor(self, show: bool = True) -> bool:
        
        if self.is_terminal:
            self.control(Control.show_cursor(show))
            return True
        return False

    def set_alt_screen(self, enable: bool = True) -> bool:
        
        changed = False
        if self.is_terminal and not self.legacy_windows:
            self.control(Control.alt_screen(enable))
            changed = True
            self._is_alt_screen = enable
        return changed

    @property
    def is_alt_screen(self) -> bool:
        
        return self._is_alt_screen

    def set_window_title(self, title: str) -> bool:
        
        if self.is_terminal:
            self.control(Control.title(title))
            return True
        return False

    def screen(
        self, hide_cursor: bool = True, style: Optional[StyleType] = None
    ) -> ""ScreenContext"":
        
        return ScreenContext(self, hide_cursor=hide_cursor, style=style or """")

    def measure(
        self, renderable: RenderableType, *, options: Optional[ConsoleOptions] = None
    ) -> Measurement:
        
        measurement = Measurement.get(self, options or self.options, renderable)
        return measurement

    def render(
        self, renderable: RenderableType, options: Optional[ConsoleOptions] = None
    ) -> Iterable[Segment]:
        

        _options = options or self.options
        if _options.max_width < 1:
            
            return
        render_iterable: RenderResult

        renderable = rich_cast(renderable)
        if hasattr(renderable, ""__rich_console__"") and not isclass(renderable):
            render_iterable = renderable.__rich_console__(self, _options)
        elif isinstance(renderable, str):
            text_renderable = self.render_str(
                renderable, highlight=_options.highlight, markup=_options.markup
            )
            render_iterable = text_renderable.__rich_console__(self, _options)
        else:
            raise errors.NotRenderableError(
                f""Unable to render {renderable!r}; ""
                ""A str, Segment or object with __rich_console__ method is required""
            )

        try:
            iter_render = iter(render_iterable)
        except TypeError:
            raise errors.NotRenderableError(
                f""object {render_iterable!r} is not renderable""
            )
        _Segment = Segment
        _options = _options.reset_height()
        for render_output in iter_render:
            if isinstance(render_output, _Segment):
                yield render_output
            else:
                yield from self.render(render_output, _options)

    def render_lines(
        self,
        renderable: RenderableType,
        options: Optional[ConsoleOptions] = None,
        *,
        style: Optional[Style] = None,
        pad: bool = True,
        new_lines: bool = False,
    ) -> List[List[Segment]]:
        
        with self._lock:
            render_options = options or self.options
            _rendered = self.render(renderable, render_options)
            if style:
                _rendered = Segment.apply_style(_rendered, style)

            render_height = render_options.height
            if render_height is not None:
                render_height = max(0, render_height)

            lines = list(
                islice(
                    Segment.split_and_crop_lines(
                        _rendered,
                        render_options.max_width,
                        include_new_lines=new_lines,
                        pad=pad,
                        style=style,
                    ),
                    None,
                    render_height,
                )
            )
            if render_options.height is not None:
                extra_lines = render_options.height - len(lines)
                if extra_lines > 0:
                    pad_line = [
                        (
                            [
                                Segment("" "" * render_options.max_width, style),
                                Segment(""\n""),
                            ]
                            if new_lines
                            else [Segment("" "" * render_options.max_width, style)]
                        )
                    ]
                    lines.extend(pad_line * extra_lines)

            return lines

    def render_str(
        self,
        text: str,
        *,
        style: Union[str, Style] = """",
        justify: Optional[JustifyMethod] = None,
        overflow: Optional[OverflowMethod] = None,
        emoji: Optional[bool] = None,
        markup: Optional[bool] = None,
        highlight: Optional[bool] = None,
        highlighter: Optional[HighlighterType] = None,
    ) -> ""Text"":
        
        emoji_enabled = emoji or (emoji is None and self._emoji)
        markup_enabled = markup or (markup is None and self._markup)
        highlight_enabled = highlight or (highlight is None and self._highlight)

        if markup_enabled:
            rich_text = render_markup(
                text,
                style=style,
                emoji=emoji_enabled,
                emoji_variant=self._emoji_variant,
            )
            rich_text.justify = justify
            rich_text.overflow = overflow
        else:
            rich_text = Text(
                (
                    _emoji_replace(text, default_variant=self._emoji_variant)
                    if emoji_enabled
                    else text
                ),
                justify=justify,
                overflow=overflow,
                style=style,
            )

        _highlighter = (highlighter or self.highlighter) if highlight_enabled else None
        if _highlighter is not None:
            highlight_text = _highlighter(str(rich_text))
            highlight_text.copy_styles(rich_text)
            return highlight_text

        return rich_text

    def get_style(
        self, name: Union[str, Style], *, default: Optional[Union[Style, str]] = None
    ) -> Style:
        
        if isinstance(name, Style):
            return name

        try:
            style = self._theme_stack.get(name)
            if style is None:
                style = Style.parse(name)
            return style.copy() if style.link else style
        except errors.StyleSyntaxError as error:
            if default is not None:
                return self.get_style(default)
            raise errors.MissingStyle(
                f""Failed to get style {name!r}; {error}""
            ) from None

    def _collect_renderables(
        self,
        objects: Iterable[Any],
        sep: str,
        end: str,
        *,
        justify: Optional[JustifyMethod] = None,
        emoji: Optional[bool] = None,
        markup: Optional[bool] = None,
        highlight: Optional[bool] = None,
    ) -> List[ConsoleRenderable]:
        
        renderables: List[ConsoleRenderable] = []
        _append = renderables.append
        text: List[Text] = []
        append_text = text.append

        append = _append
        if justify in (""left"", ""center"", ""right""):

            def align_append(renderable: RenderableType) -> None:
                _append(Align(renderable, cast(AlignMethod, justify)))

            append = align_append

        _highlighter: HighlighterType = _null_highlighter
        if highlight or (highlight is None and self._highlight):
            _highlighter = self.highlighter

        def check_text() -> None:
            if text:
                sep_text = Text(sep, justify=justify, end=end)
                append(sep_text.join(text))
                text.clear()

        for renderable in objects:
            renderable = rich_cast(renderable)
            if isinstance(renderable, str):
                append_text(
                    self.render_str(
                        renderable,
                        emoji=emoji,
                        markup=markup,
                        highlight=highlight,
                        highlighter=_highlighter,
                    )
                )
            elif isinstance(renderable, Text):
                append_text(renderable)
            elif isinstance(renderable, ConsoleRenderable):
                check_text()
                append(renderable)
            elif is_expandable(renderable):
                check_text()
                append(Pretty(renderable, highlighter=_highlighter))
            else:
                append_text(_highlighter(str(renderable)))

        check_text()

        if self.style is not None:
            style = self.get_style(self.style)
            renderables = [Styled(renderable, style) for renderable in renderables]

        return renderables

    def rule(
        self,
        title: TextType = """",
        *,
        characters: str = ""─"",
        style: Union[str, Style] = ""rule.line"",
        align: AlignMethod = ""center"",
    ) -> None:
        
        from .rule import Rule

        rule = Rule(title=title, characters=characters, style=style, align=align)
        self.print(rule)

    def control(self, *control: Control) -> None:
        
        if not self.is_dumb_terminal:
            with self:
                self._buffer.extend(_control.segment for _control in control)

    def out(
        self,
        *objects: Any,
        sep: str = "" "",
        end: str = ""\n"",
        style: Optional[Union[str, Style]] = None,
        highlight: Optional[bool] = None,
    ) -> None:
        
        raw_output: str = sep.join(str(_object) for _object in objects)
        self.print(
            raw_output,
            style=style,
            highlight=highlight,
            emoji=False,
            markup=False,
            no_wrap=True,
            overflow=""ignore"",
            crop=False,
            end=end,
        )

    def print(
        self,
        *objects: Any,
        sep: str = "" "",
        end: str = ""\n"",
        style: Optional[Union[str, Style]] = None,
        justify: Optional[JustifyMethod] = None,
        overflow: Optional[OverflowMethod] = None,
        no_wrap: Optional[bool] = None,
        emoji: Optional[bool] = None,
        markup: Optional[bool] = None,
        highlight: Optional[bool] = None,
        width: Optional[int] = None,
        height: Optional[int] = None,
        crop: bool = True,
        soft_wrap: Optional[bool] = None,
        new_line_start: bool = False,
    ) -> None:
        
        if not objects:
            objects = (NewLine(),)

        if soft_wrap is None:
            soft_wrap = self.soft_wrap
        if soft_wrap:
            if no_wrap is None:
                no_wrap = True
            if overflow is None:
                overflow = ""ignore""
            crop = False
        render_hooks = self._render_hooks[:]
        with self:
            renderables = self._collect_renderables(
                objects,
                sep,
                end,
                justify=justify,
                emoji=emoji,
                markup=markup,
                highlight=highlight,
            )
            for hook in render_hooks:
                renderables = hook.process_renderables(renderables)
            render_options = self.options.update(
                justify=justify,
                overflow=overflow,
                width=min(width, self.width) if width is not None else NO_CHANGE,
                height=height,
                no_wrap=no_wrap,
                markup=markup,
                highlight=highlight,
            )

            new_segments: List[Segment] = []
            extend = new_segments.extend
            render = self.render
            if style is None:
                for renderable in renderables:
                    extend(render(renderable, render_options))
            else:
                for renderable in renderables:
                    extend(
                        Segment.apply_style(
                            render(renderable, render_options), self.get_style(style)
                        )
                    )
            if new_line_start:
                if (
                    len("""".join(segment.text for segment in new_segments).splitlines())
                    > 1
                ):
                    new_segments.insert(0, Segment.line())
            if crop:
                buffer_extend = self._buffer.extend
                for line in Segment.split_and_crop_lines(
                    new_segments, self.width, pad=False
                ):
                    buffer_extend(line)
            else:
                self._buffer.extend(new_segments)

    def print_json(
        self,
        json: Optional[str] = None,
        *,
        data: Any = None,
        indent: Union[None, int, str] = 2,
        highlight: bool = True,
        skip_keys: bool = False,
        ensure_ascii: bool = False,
        check_circular: bool = True,
        allow_nan: bool = True,
        default: Optional[Callable[[Any], Any]] = None,
        sort_keys: bool = False,
    ) -> None:
        
        from pip._vendor.rich.json import JSON

        if json is None:
            json_renderable = JSON.from_data(
                data,
                indent=indent,
                highlight=highlight,
                skip_keys=skip_keys,
                ensure_ascii=ensure_ascii,
                check_circular=check_circular,
                allow_nan=allow_nan,
                default=default,
                sort_keys=sort_keys,
            )
        else:
            if not isinstance(json, str):
                raise TypeError(
                    f""json must be str. Did you mean print_json(data={json!r}) ?""
                )
            json_renderable = JSON(
                json,
                indent=indent,
                highlight=highlight,
                skip_keys=skip_keys,
                ensure_ascii=ensure_ascii,
                check_circular=check_circular,
                allow_nan=allow_nan,
                default=default,
                sort_keys=sort_keys,
            )
        self.print(json_renderable, soft_wrap=True)

    def update_screen(
        self,
        renderable: RenderableType,
        *,
        region: Optional[Region] = None,
        options: Optional[ConsoleOptions] = None,
    ) -> None:
        
        if not self.is_alt_screen:
            raise errors.NoAltScreen(""Alt screen must be enabled to call update_screen"")
        render_options = options or self.options
        if region is None:
            x = y = 0
            render_options = render_options.update_dimensions(
                render_options.max_width, render_options.height or self.height
            )
        else:
            x, y, width, height = region
            render_options = render_options.update_dimensions(width, height)

        lines = self.render_lines(renderable, options=render_options)
        self.update_screen_lines(lines, x, y)

    def update_screen_lines(
        self, lines: List[List[Segment]], x: int = 0, y: int = 0
    ) -> None:
        
        if not self.is_alt_screen:
            raise errors.NoAltScreen(""Alt screen must be enabled to call update_screen"")
        screen_update = ScreenUpdate(lines, x, y)
        segments = self.render(screen_update)
        self._buffer.extend(segments)
        self._check_buffer()

    def print_exception(
        self,
        *,
        width: Optional[int] = 100,
        extra_lines: int = 3,
        theme: Optional[str] = None,
        word_wrap: bool = False,
        show_locals: bool = False,
        suppress: Iterable[Union[str, ModuleType]] = (),
        max_frames: int = 100,
    ) -> None:
        
        from .traceback import Traceback

        traceback = Traceback(
            width=width,
            extra_lines=extra_lines,
            theme=theme,
            word_wrap=word_wrap,
            show_locals=show_locals,
            suppress=suppress,
            max_frames=max_frames,
        )
        self.print(traceback)

    @staticmethod
    def _caller_frame_info(
        offset: int,
        currentframe: Callable[[], Optional[FrameType]] = inspect.currentframe,
    ) -> Tuple[str, int, Dict[str, Any]]:
        
        
        offset += 1

        frame = currentframe()
        if frame is not None:
            
            while offset and frame is not None:
                frame = frame.f_back
                offset -= 1
            assert frame is not None
            return frame.f_code.co_filename, frame.f_lineno, frame.f_locals
        else:
            
            frame_info = inspect.stack()[offset]
            return frame_info.filename, frame_info.lineno, frame_info.frame.f_locals

    def log(
        self,
        *objects: Any,
        sep: str = "" "",
        end: str = ""\n"",
        style: Optional[Union[str, Style]] = None,
        justify: Optional[JustifyMethod] = None,
        emoji: Optional[bool] = None,
        markup: Optional[bool] = None,
        highlight: Optional[bool] = None,
        log_locals: bool = False,
        _stack_offset: int = 1,
    ) -> None:
        
        if not objects:
            objects = (NewLine(),)

        render_hooks = self._render_hooks[:]

        with self:
            renderables = self._collect_renderables(
                objects,
                sep,
                end,
                justify=justify,
                emoji=emoji,
                markup=markup,
                highlight=highlight,
            )
            if style is not None:
                renderables = [Styled(renderable, style) for renderable in renderables]

            filename, line_no, locals = self._caller_frame_info(_stack_offset)
            link_path = None if filename.startswith(""<"") else os.path.abspath(filename)
            path = filename.rpartition(os.sep)[-1]
            if log_locals:
                locals_map = {
                    key: value
                    for key, value in locals.items()
                    if not key.startswith(""__"")
                }
                renderables.append(render_scope(locals_map, title=""[i]locals""))

            renderables = [
                self._log_render(
                    self,
                    renderables,
                    log_time=self.get_datetime(),
                    path=path,
                    line_no=line_no,
                    link_path=link_path,
                )
            ]
            for hook in render_hooks:
                renderables = hook.process_renderables(renderables)
            new_segments: List[Segment] = []
            extend = new_segments.extend
            render = self.render
            render_options = self.options
            for renderable in renderables:
                extend(render(renderable, render_options))
            buffer_extend = self._buffer.extend
            for line in Segment.split_and_crop_lines(
                new_segments, self.width, pad=False
            ):
                buffer_extend(line)

    def on_broken_pipe(self) -> None:
        
        self.quiet = True
        devnull = os.open(os.devnull, os.O_WRONLY)
        os.dup2(devnull, sys.stdout.fileno())
        raise SystemExit(1)

    def _check_buffer(self) -> None:
        
        if self.quiet:
            del self._buffer[:]
            return

        try:
            self._write_buffer()
        except BrokenPipeError:
            self.on_broken_pipe()

    def _write_buffer(self) -> None:
        

        with self._lock:
            if self.record and not self._buffer_index:
                with self._record_buffer_lock:
                    self._record_buffer.extend(self._buffer[:])

            if self._buffer_index == 0:
                if self.is_jupyter:  
                    from .jupyter import display

                    display(self._buffer, self._render_buffer(self._buffer[:]))
                    del self._buffer[:]
                else:
                    if WINDOWS:
                        use_legacy_windows_render = False
                        if self.legacy_windows:
                            fileno = get_fileno(self.file)
                            if fileno is not None:
                                use_legacy_windows_render = (
                                    fileno in _STD_STREAMS_OUTPUT
                                )

                        if use_legacy_windows_render:
                            from pip._vendor.rich._win32_console import LegacyWindowsTerm
                            from pip._vendor.rich._windows_renderer import legacy_windows_render

                            buffer = self._buffer[:]
                            if self.no_color and self._color_system:
                                buffer = list(Segment.remove_color(buffer))

                            legacy_windows_render(buffer, LegacyWindowsTerm(self.file))
                        else:
                            
                            text = self._render_buffer(self._buffer[:])
                            
                            
                            
                            write = self.file.write
                            
                            MAX_WRITE = 32 * 1024 // 4
                            try:
                                if len(text) <= MAX_WRITE:
                                    write(text)
                                else:
                                    batch: List[str] = []
                                    batch_append = batch.append
                                    size = 0
                                    for line in text.splitlines(True):
                                        if size + len(line) > MAX_WRITE and batch:
                                            write("""".join(batch))
                                            batch.clear()
                                            size = 0
                                        batch_append(line)
                                        size += len(line)
                                    if batch:
                                        write("""".join(batch))
                                        batch.clear()
                            except UnicodeEncodeError as error:
                                error.reason = f""{error.reason}\n*** You may need to add PYTHONIOENCODING=utf-8 to your environment ***""
                                raise
                    else:
                        text = self._render_buffer(self._buffer[:])
                        try:
                            self.file.write(text)
                        except UnicodeEncodeError as error:
                            error.reason = f""{error.reason}\n*** You may need to add PYTHONIOENCODING=utf-8 to your environment ***""
                            raise

                    self.file.flush()
                    del self._buffer[:]

    def _render_buffer(self, buffer: Iterable[Segment]) -> str:
        
        output: List[str] = []
        append = output.append
        color_system = self._color_system
        legacy_windows = self.legacy_windows
        not_terminal = not self.is_terminal
        if self.no_color and color_system:
            buffer = Segment.remove_color(buffer)
        for text, style, control in buffer:
            if style:
                append(
                    style.render(
                        text,
                        color_system=color_system,
                        legacy_windows=legacy_windows,
                    )
                )
            elif not (not_terminal and control):
                append(text)

        rendered = """".join(output)
        return rendered

    def input(
        self,
        prompt: TextType = """",
        *,
        markup: bool = True,
        emoji: bool = True,
        password: bool = False,
        stream: Optional[TextIO] = None,
    ) -> str:
        
        if prompt:
            self.print(prompt, markup=markup, emoji=emoji, end="""")
        if password:
            result = getpass("""", stream=stream)
        else:
            if stream:
                result = stream.readline()
            else:
                result = input()
        return result

    def export_text(self, *, clear: bool = True, styles: bool = False) -> str:
        
        assert (
            self.record
        ), ""To export console contents set record=True in the constructor or instance""

        with self._record_buffer_lock:
            if styles:
                text = """".join(
                    (style.render(text) if style else text)
                    for text, style, _ in self._record_buffer
                )
            else:
                text = """".join(
                    segment.text
                    for segment in self._record_buffer
                    if not segment.control
                )
            if clear:
                del self._record_buffer[:]
        return text

    def save_text(self, path: str, *, clear: bool = True, styles: bool = False) -> None:
        
        text = self.export_text(clear=clear, styles=styles)
        with open(path, ""w"", encoding=""utf-8"") as write_file:
            write_file.write(text)

    def export_html(
        self,
        *,
        theme: Optional[TerminalTheme] = None,
        clear: bool = True,
        code_format: Optional[str] = None,
        inline_styles: bool = False,
    ) -> str:
        
        assert (
            self.record
        ), ""To export console contents set record=True in the constructor or instance""
        fragments: List[str] = []
        append = fragments.append
        _theme = theme or DEFAULT_TERMINAL_THEME
        stylesheet = """"

        render_code_format = CONSOLE_HTML_FORMAT if code_format is None else code_format

        with self._record_buffer_lock:
            if inline_styles:
                for text, style, _ in Segment.filter_control(
                    Segment.simplify(self._record_buffer)
                ):
                    text = escape(text)
                    if style:
                        rule = style.get_html_style(_theme)
                        if style.link:
                            text = f'<a href=""{style.link}"">{text}</a>'
                        text = f'<span style=""{rule}"">{text}</span>' if rule else text
                    append(text)
            else:
                styles: Dict[str, int] = {}
                for text, style, _ in Segment.filter_control(
                    Segment.simplify(self._record_buffer)
                ):
                    text = escape(text)
                    if style:
                        rule = style.get_html_style(_theme)
                        style_number = styles.setdefault(rule, len(styles) + 1)
                        if style.link:
                            text = f'<a class=""r{style_number}"" href=""{style.link}"">{text}</a>'
                        else:
                            text = f'<span class=""r{style_number}"">{text}</span>'
                    append(text)
                stylesheet_rules: List[str] = []
                stylesheet_append = stylesheet_rules.append
                for style_rule, style_number in styles.items():
                    if style_rule:
                        stylesheet_append(f"".r{style_number} {{{style_rule}}}"")
                stylesheet = ""\n"".join(stylesheet_rules)

            rendered_code = render_code_format.format(
                code="""".join(fragments),
                stylesheet=stylesheet,
                foreground=_theme.foreground_color.hex,
                background=_theme.background_color.hex,
            )
            if clear:
                del self._record_buffer[:]
        return rendered_code

    def save_html(
        self,
        path: str,
        *,
        theme: Optional[TerminalTheme] = None,
        clear: bool = True,
        code_format: str = CONSOLE_HTML_FORMAT,
        inline_styles: bool = False,
    ) -> None:
        
        html = self.export_html(
            theme=theme,
            clear=clear,
            code_format=code_format,
            inline_styles=inline_styles,
        )
        with open(path, ""w"", encoding=""utf-8"") as write_file:
            write_file.write(html)

    def export_svg(
        self,
        *,
        title: str = ""Rich"",
        theme: Optional[TerminalTheme] = None,
        clear: bool = True,
        code_format: str = CONSOLE_SVG_FORMAT,
        font_aspect_ratio: float = 0.61,
        unique_id: Optional[str] = None,
    ) -> str:
        

        from pip._vendor.rich.cells import cell_len

        style_cache: Dict[Style, str] = {}

        def get_svg_style(style: Style) -> str:
            
            if style in style_cache:
                return style_cache[style]
            css_rules = []
            color = (
                _theme.foreground_color
                if (style.color is None or style.color.is_default)
                else style.color.get_truecolor(_theme)
            )
            bgcolor = (
                _theme.background_color
                if (style.bgcolor is None or style.bgcolor.is_default)
                else style.bgcolor.get_truecolor(_theme)
            )
            if style.reverse:
                color, bgcolor = bgcolor, color
            if style.dim:
                color = blend_rgb(color, bgcolor, 0.4)
            css_rules.append(f""fill: {color.hex}"")
            if style.bold:
                css_rules.append(""font-weight: bold"")
            if style.italic:
                css_rules.append(""font-style: italic;"")
            if style.underline:
                css_rules.append(""text-decoration: underline;"")
            if style.strike:
                css_rules.append(""text-decoration: line-through;"")

            css = "";"".join(css_rules)
            style_cache[style] = css
            return css

        _theme = theme or SVG_EXPORT_THEME

        width = self.width
        char_height = 20
        char_width = char_height * font_aspect_ratio
        line_height = char_height * 1.22

        margin_top = 1
        margin_right = 1
        margin_bottom = 1
        margin_left = 1

        padding_top = 40
        padding_right = 8
        padding_bottom = 8
        padding_left = 8

        padding_width = padding_left + padding_right
        padding_height = padding_top + padding_bottom
        margin_width = margin_left + margin_right
        margin_height = margin_top + margin_bottom

        text_backgrounds: List[str] = []
        text_group: List[str] = []
        classes: Dict[str, int] = {}
        style_no = 1

        def escape_text(text: str) -> str:
            
            return escape(text).replace("" "", ""&

        def make_tag(
            name: str, content: Optional[str] = None, **attribs: object
        ) -> str:
            

            def stringify(value: object) -> str:
                if isinstance(value, (float)):
                    return format(value, ""g"")
                return str(value)

            tag_attribs = "" "".join(
                f'{k.lstrip(""_"").replace(""_"", ""-"")}=""{stringify(v)}""'
                for k, v in attribs.items()
            )
            return (
                f""<{name} {tag_attribs}>{content}</{name}>""
                if content
                else f""<{name} {tag_attribs}/>""
            )

        with self._record_buffer_lock:
            segments = list(Segment.filter_control(self._record_buffer))
            if clear:
                self._record_buffer.clear()

        if unique_id is None:
            unique_id = ""terminal-"" + str(
                zlib.adler32(
                    ("""".join(repr(segment) for segment in segments)).encode(
                        ""utf-8"",
                        ""ignore"",
                    )
                    + title.encode(""utf-8"", ""ignore"")
                )
            )
        y = 0
        for y, line in enumerate(Segment.split_and_crop_lines(segments, length=width)):
            x = 0
            for text, style, _control in line:
                style = style or Style()
                rules = get_svg_style(style)
                if rules not in classes:
                    classes[rules] = style_no
                    style_no += 1
                class_name = f""r{classes[rules]}""

                if style.reverse:
                    has_background = True
                    background = (
                        _theme.foreground_color.hex
                        if style.color is None
                        else style.color.get_truecolor(_theme).hex
                    )
                else:
                    bgcolor = style.bgcolor
                    has_background = bgcolor is not None and not bgcolor.is_default
                    background = (
                        _theme.background_color.hex
                        if style.bgcolor is None
                        else style.bgcolor.get_truecolor(_theme).hex
                    )

                text_length = cell_len(text)
                if has_background:
                    text_backgrounds.append(
                        make_tag(
                            ""rect"",
                            fill=background,
                            x=x * char_width,
                            y=y * line_height + 1.5,
                            width=char_width * text_length,
                            height=line_height + 0.25,
                            shape_rendering=""crispEdges"",
                        )
                    )

                if text != "" "" * len(text):
                    text_group.append(
                        make_tag(
                            ""text"",
                            escape_text(text),
                            _class=f""{unique_id}-{class_name}"",
                            x=x * char_width,
                            y=y * line_height + char_height,
                            textLength=char_width * len(text),
                            clip_path=f""url(
                        )
                    )
                x += cell_len(text)

        line_offsets = [line_no * line_height + 1.5 for line_no in range(y)]
        lines = ""\n"".join(
            f
            for line_no, offset in enumerate(line_offsets)
        )

        styles = ""\n"".join(
            f"".{unique_id}-r{rule_no} {{ {css} }}"" for css, rule_no in classes.items()
        )
        backgrounds = """".join(text_backgrounds)
        matrix = """".join(text_group)

        terminal_width = ceil(width * char_width + padding_width)
        terminal_height = (y + 1) * line_height + padding_height
        chrome = make_tag(
            ""rect"",
            fill=_theme.background_color.hex,
            stroke=""rgba(255,255,255,0.35)"",
            stroke_width=""1"",
            x=margin_left,
            y=margin_top,
            width=terminal_width,
            height=terminal_height,
            rx=8,
        )

        title_color = _theme.foreground_color.hex
        if title:
            chrome += make_tag(
                ""text"",
                escape_text(title),
                _class=f""{unique_id}-title"",
                fill=title_color,
                text_anchor=""middle"",
                x=terminal_width // 2,
                y=margin_top + char_height + 6,
            )
        chrome += f

        svg = code_format.format(
            unique_id=unique_id,
            char_width=char_width,
            char_height=char_height,
            line_height=line_height,
            terminal_width=char_width * width - 1,
            terminal_height=(y + 1) * line_height - 1,
            width=terminal_width + margin_width,
            height=terminal_height + margin_height,
            terminal_x=margin_left + padding_left,
            terminal_y=margin_top + padding_top,
            styles=styles,
            chrome=chrome,
            backgrounds=backgrounds,
            matrix=matrix,
            lines=lines,
        )
        return svg

    def save_svg(
        self,
        path: str,
        *,
        title: str = ""Rich"",
        theme: Optional[TerminalTheme] = None,
        clear: bool = True,
        code_format: str = CONSOLE_SVG_FORMAT,
        font_aspect_ratio: float = 0.61,
        unique_id: Optional[str] = None,
    ) -> None:
        
        svg = self.export_svg(
            title=title,
            theme=theme,
            clear=clear,
            code_format=code_format,
            font_aspect_ratio=font_aspect_ratio,
            unique_id=unique_id,
        )
        with open(path, ""w"", encoding=""utf-8"") as write_file:
            write_file.write(svg)


def _svg_hash(svg_main_code: str) -> str:
    
    return str(zlib.adler32(svg_main_code.encode()))


if __name__ == ""__main__"":  
    console = Console(record=True)

    console.log(
        ""JSONRPC [i]request[/i]"",
        5,
        1.3,
        True,
        False,
        None,
        {
            ""jsonrpc"": ""2.0"",
            ""method"": ""subtract"",
            ""params"": {""minuend"": 42, ""subtrahend"": 23},
            ""id"": 3,
        },
    )

    console.log(""Hello, World!"", ""{'a': 1}"", repr(console))

    console.print(
        {
            ""name"": None,
            ""empty"": [],
            ""quiz"": {
                ""sport"": {
                    ""answered"": True,
                    ""q1"": {
                        ""question"": ""Which one is correct team name in NBA?"",
                        ""options"": [
                            ""New York Bulls"",
                            ""Los Angeles Kings"",
                            ""Golden State Warriors"",
                            ""Huston Rocket"",
                        ],
                        ""answer"": ""Huston Rocket"",
                    },
                },
                ""maths"": {
                    ""answered"": False,
                    ""q1"": {
                        ""question"": ""5 + 7 = ?"",
                        ""options"": [10, 11, 12, 13],
                        ""answer"": 12,
                    },
                    ""q2"": {
                        ""question"": ""12 - 8 = ?"",
                        ""options"": [1, 2, 3, 4],
                        ""answer"": 4,
                    },
                },
            },
        }
    )

from typing import Optional, TYPE_CHECKING

from .jupyter import JupyterMixin
from .measure import Measurement

if TYPE_CHECKING:
    from .console import Console, ConsoleOptions, RenderableType, RenderResult


class Constrain(JupyterMixin):
    

    def __init__(self, renderable: ""RenderableType"", width: Optional[int] = 80) -> None:
        self.renderable = renderable
        self.width = width

    def __rich_console__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> ""RenderResult"":
        if self.width is None:
            yield self.renderable
        else:
            child_options = options.update_width(min(self.width, options.max_width))
            yield from console.render(self.renderable, child_options)

    def __rich_measure__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> ""Measurement"":
        if self.width is not None:
            options = options.update_width(self.width)
        measurement = Measurement.get(console, options, self.renderable)
        return measurement

from itertools import zip_longest
from typing import (
    TYPE_CHECKING,
    Iterable,
    Iterator,
    List,
    Optional,
    TypeVar,
    Union,
    overload,
)

if TYPE_CHECKING:
    from .console import (
        Console,
        ConsoleOptions,
        JustifyMethod,
        OverflowMethod,
        RenderResult,
        RenderableType,
    )
    from .text import Text

from .cells import cell_len
from .measure import Measurement

T = TypeVar(""T"")


class Renderables:
    

    def __init__(
        self, renderables: Optional[Iterable[""RenderableType""]] = None
    ) -> None:
        self._renderables: List[""RenderableType""] = (
            list(renderables) if renderables is not None else []
        )

    def __rich_console__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> ""RenderResult"":
        
        yield from self._renderables

    def __rich_measure__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> ""Measurement"":
        dimensions = [
            Measurement.get(console, options, renderable)
            for renderable in self._renderables
        ]
        if not dimensions:
            return Measurement(1, 1)
        _min = max(dimension.minimum for dimension in dimensions)
        _max = max(dimension.maximum for dimension in dimensions)
        return Measurement(_min, _max)

    def append(self, renderable: ""RenderableType"") -> None:
        self._renderables.append(renderable)

    def __iter__(self) -> Iterable[""RenderableType""]:
        return iter(self._renderables)


class Lines:
    

    def __init__(self, lines: Iterable[""Text""] = ()) -> None:
        self._lines: List[""Text""] = list(lines)

    def __repr__(self) -> str:
        return f""Lines({self._lines!r})""

    def __iter__(self) -> Iterator[""Text""]:
        return iter(self._lines)

    @overload
    def __getitem__(self, index: int) -> ""Text"":
        ...

    @overload
    def __getitem__(self, index: slice) -> List[""Text""]:
        ...

    def __getitem__(self, index: Union[slice, int]) -> Union[""Text"", List[""Text""]]:
        return self._lines[index]

    def __setitem__(self, index: int, value: ""Text"") -> ""Lines"":
        self._lines[index] = value
        return self

    def __len__(self) -> int:
        return self._lines.__len__()

    def __rich_console__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> ""RenderResult"":
        
        yield from self._lines

    def append(self, line: ""Text"") -> None:
        self._lines.append(line)

    def extend(self, lines: Iterable[""Text""]) -> None:
        self._lines.extend(lines)

    def pop(self, index: int = -1) -> ""Text"":
        return self._lines.pop(index)

    def justify(
        self,
        console: ""Console"",
        width: int,
        justify: ""JustifyMethod"" = ""left"",
        overflow: ""OverflowMethod"" = ""fold"",
    ) -> None:
        
        from .text import Text

        if justify == ""left"":
            for line in self._lines:
                line.truncate(width, overflow=overflow, pad=True)
        elif justify == ""center"":
            for line in self._lines:
                line.rstrip()
                line.truncate(width, overflow=overflow)
                line.pad_left((width - cell_len(line.plain)) // 2)
                line.pad_right(width - cell_len(line.plain))
        elif justify == ""right"":
            for line in self._lines:
                line.rstrip()
                line.truncate(width, overflow=overflow)
                line.pad_left(width - cell_len(line.plain))
        elif justify == ""full"":
            for line_index, line in enumerate(self._lines):
                if line_index == len(self._lines) - 1:
                    break
                words = line.split("" "")
                words_size = sum(cell_len(word.plain) for word in words)
                num_spaces = len(words) - 1
                spaces = [1 for _ in range(num_spaces)]
                index = 0
                if spaces:
                    while words_size + num_spaces < width:
                        spaces[len(spaces) - index - 1] += 1
                        num_spaces += 1
                        index = (index + 1) % len(spaces)
                tokens: List[Text] = []
                for index, (word, next_word) in enumerate(
                    zip_longest(words, words[1:])
                ):
                    tokens.append(word)
                    if index < len(spaces):
                        style = word.get_style_at_offset(console, -1)
                        next_style = next_word.get_style_at_offset(console, 0)
                        space_style = style if style == next_style else line.style
                        tokens.append(Text("" "" * spaces[index], style=space_style))
                self[line_index] = Text("""").join(tokens)

import time
from typing import TYPE_CHECKING, Callable, Dict, Iterable, List, Union, Final

from .segment import ControlCode, ControlType, Segment

if TYPE_CHECKING:
    from .console import Console, ConsoleOptions, RenderResult

STRIP_CONTROL_CODES: Final = [
    7,  
    8,  
    11,  
    12,  
    13,  
]
_CONTROL_STRIP_TRANSLATE: Final = {
    _codepoint: None for _codepoint in STRIP_CONTROL_CODES
}

CONTROL_ESCAPE: Final = {
    7: ""\\a"",
    8: ""\\b"",
    11: ""\\v"",
    12: ""\\f"",
    13: ""\\r"",
}

CONTROL_CODES_FORMAT: Dict[int, Callable[..., str]] = {
    ControlType.BELL: lambda: ""\x07"",
    ControlType.CARRIAGE_RETURN: lambda: ""\r"",
    ControlType.HOME: lambda: ""\x1b[H"",
    ControlType.CLEAR: lambda: ""\x1b[2J"",
    ControlType.ENABLE_ALT_SCREEN: lambda: ""\x1b[?1049h"",
    ControlType.DISABLE_ALT_SCREEN: lambda: ""\x1b[?1049l"",
    ControlType.SHOW_CURSOR: lambda: ""\x1b[?25h"",
    ControlType.HIDE_CURSOR: lambda: ""\x1b[?25l"",
    ControlType.CURSOR_UP: lambda param: f""\x1b[{param}A"",
    ControlType.CURSOR_DOWN: lambda param: f""\x1b[{param}B"",
    ControlType.CURSOR_FORWARD: lambda param: f""\x1b[{param}C"",
    ControlType.CURSOR_BACKWARD: lambda param: f""\x1b[{param}D"",
    ControlType.CURSOR_MOVE_TO_COLUMN: lambda param: f""\x1b[{param+1}G"",
    ControlType.ERASE_IN_LINE: lambda param: f""\x1b[{param}K"",
    ControlType.CURSOR_MOVE_TO: lambda x, y: f""\x1b[{y+1};{x+1}H"",
    ControlType.SET_WINDOW_TITLE: lambda title: f""\x1b]0;{title}\x07"",
}


class Control:
    

    __slots__ = [""segment""]

    def __init__(self, *codes: Union[ControlType, ControlCode]) -> None:
        control_codes: List[ControlCode] = [
            (code,) if isinstance(code, ControlType) else code for code in codes
        ]
        _format_map = CONTROL_CODES_FORMAT
        rendered_codes = """".join(
            _format_map[code](*parameters) for code, *parameters in control_codes
        )
        self.segment = Segment(rendered_codes, None, control_codes)

    @classmethod
    def bell(cls) -> ""Control"":
        
        return cls(ControlType.BELL)

    @classmethod
    def home(cls) -> ""Control"":
        
        return cls(ControlType.HOME)

    @classmethod
    def move(cls, x: int = 0, y: int = 0) -> ""Control"":
        

        def get_codes() -> Iterable[ControlCode]:
            control = ControlType
            if x:
                yield (
                    control.CURSOR_FORWARD if x > 0 else control.CURSOR_BACKWARD,
                    abs(x),
                )
            if y:
                yield (
                    control.CURSOR_DOWN if y > 0 else control.CURSOR_UP,
                    abs(y),
                )

        control = cls(*get_codes())
        return control

    @classmethod
    def move_to_column(cls, x: int, y: int = 0) -> ""Control"":
        

        return (
            cls(
                (ControlType.CURSOR_MOVE_TO_COLUMN, x),
                (
                    ControlType.CURSOR_DOWN if y > 0 else ControlType.CURSOR_UP,
                    abs(y),
                ),
            )
            if y
            else cls((ControlType.CURSOR_MOVE_TO_COLUMN, x))
        )

    @classmethod
    def move_to(cls, x: int, y: int) -> ""Control"":
        
        return cls((ControlType.CURSOR_MOVE_TO, x, y))

    @classmethod
    def clear(cls) -> ""Control"":
        
        return cls(ControlType.CLEAR)

    @classmethod
    def show_cursor(cls, show: bool) -> ""Control"":
        
        return cls(ControlType.SHOW_CURSOR if show else ControlType.HIDE_CURSOR)

    @classmethod
    def alt_screen(cls, enable: bool) -> ""Control"":
        
        if enable:
            return cls(ControlType.ENABLE_ALT_SCREEN, ControlType.HOME)
        else:
            return cls(ControlType.DISABLE_ALT_SCREEN)

    @classmethod
    def title(cls, title: str) -> ""Control"":
        
        return cls((ControlType.SET_WINDOW_TITLE, title))

    def __str__(self) -> str:
        return self.segment.text

    def __rich_console__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> ""RenderResult"":
        if self.segment.text:
            yield self.segment


def strip_control_codes(
    text: str, _translate_table: Dict[int, None] = _CONTROL_STRIP_TRANSLATE
) -> str:
    
    return text.translate(_translate_table)


def escape_control_codes(
    text: str,
    _translate_table: Dict[int, str] = CONTROL_ESCAPE,
) -> str:
    
    return text.translate(_translate_table)


if __name__ == ""__main__"":  
    from pip._vendor.rich.console import Console

    console = Console()
    console.print(""Look at the title of your terminal window ^"")
    
    for i in range(10):
        console.set_window_title(""🚀 Loading"" + ""."" * i)
        time.sleep(0.5)

from typing import Dict

from .style import Style

DEFAULT_STYLES: Dict[str, Style] = {
    ""none"": Style.null(),
    ""reset"": Style(
        color=""default"",
        bgcolor=""default"",
        dim=False,
        bold=False,
        italic=False,
        underline=False,
        blink=False,
        blink2=False,
        reverse=False,
        conceal=False,
        strike=False,
    ),
    ""dim"": Style(dim=True),
    ""bright"": Style(dim=False),
    ""bold"": Style(bold=True),
    ""strong"": Style(bold=True),
    ""code"": Style(reverse=True, bold=True),
    ""italic"": Style(italic=True),
    ""emphasize"": Style(italic=True),
    ""underline"": Style(underline=True),
    ""blink"": Style(blink=True),
    ""blink2"": Style(blink2=True),
    ""reverse"": Style(reverse=True),
    ""strike"": Style(strike=True),
    ""black"": Style(color=""black""),
    ""red"": Style(color=""red""),
    ""green"": Style(color=""green""),
    ""yellow"": Style(color=""yellow""),
    ""magenta"": Style(color=""magenta""),
    ""cyan"": Style(color=""cyan""),
    ""white"": Style(color=""white""),
    ""inspect.attr"": Style(color=""yellow"", italic=True),
    ""inspect.attr.dunder"": Style(color=""yellow"", italic=True, dim=True),
    ""inspect.callable"": Style(bold=True, color=""red""),
    ""inspect.async_def"": Style(italic=True, color=""bright_cyan""),
    ""inspect.def"": Style(italic=True, color=""bright_cyan""),
    ""inspect.class"": Style(italic=True, color=""bright_cyan""),
    ""inspect.error"": Style(bold=True, color=""red""),
    ""inspect.equals"": Style(),
    ""inspect.help"": Style(color=""cyan""),
    ""inspect.doc"": Style(dim=True),
    ""inspect.value.border"": Style(color=""green""),
    ""live.ellipsis"": Style(bold=True, color=""red""),
    ""layout.tree.row"": Style(dim=False, color=""red""),
    ""layout.tree.column"": Style(dim=False, color=""blue""),
    ""logging.keyword"": Style(bold=True, color=""yellow""),
    ""logging.level.notset"": Style(dim=True),
    ""logging.level.debug"": Style(color=""green""),
    ""logging.level.info"": Style(color=""blue""),
    ""logging.level.warning"": Style(color=""yellow""),
    ""logging.level.error"": Style(color=""red"", bold=True),
    ""logging.level.critical"": Style(color=""red"", bold=True, reverse=True),
    ""log.level"": Style.null(),
    ""log.time"": Style(color=""cyan"", dim=True),
    ""log.message"": Style.null(),
    ""log.path"": Style(dim=True),
    ""repr.ellipsis"": Style(color=""yellow""),
    ""repr.indent"": Style(color=""green"", dim=True),
    ""repr.error"": Style(color=""red"", bold=True),
    ""repr.str"": Style(color=""green"", italic=False, bold=False),
    ""repr.brace"": Style(bold=True),
    ""repr.comma"": Style(bold=True),
    ""repr.ipv4"": Style(bold=True, color=""bright_green""),
    ""repr.ipv6"": Style(bold=True, color=""bright_green""),
    ""repr.eui48"": Style(bold=True, color=""bright_green""),
    ""repr.eui64"": Style(bold=True, color=""bright_green""),
    ""repr.tag_start"": Style(bold=True),
    ""repr.tag_name"": Style(color=""bright_magenta"", bold=True),
    ""repr.tag_contents"": Style(color=""default""),
    ""repr.tag_end"": Style(bold=True),
    ""repr.attrib_name"": Style(color=""yellow"", italic=False),
    ""repr.attrib_equal"": Style(bold=True),
    ""repr.attrib_value"": Style(color=""magenta"", italic=False),
    ""repr.number"": Style(color=""cyan"", bold=True, italic=False),
    ""repr.number_complex"": Style(color=""cyan"", bold=True, italic=False),  
    ""repr.bool_true"": Style(color=""bright_green"", italic=True),
    ""repr.bool_false"": Style(color=""bright_red"", italic=True),
    ""repr.none"": Style(color=""magenta"", italic=True),
    ""repr.url"": Style(underline=True, color=""bright_blue"", italic=False, bold=False),
    ""repr.uuid"": Style(color=""bright_yellow"", bold=False),
    ""repr.call"": Style(color=""magenta"", bold=True),
    ""repr.path"": Style(color=""magenta""),
    ""repr.filename"": Style(color=""bright_magenta""),
    ""rule.line"": Style(color=""bright_green""),
    ""rule.text"": Style.null(),
    ""json.brace"": Style(bold=True),
    ""json.bool_true"": Style(color=""bright_green"", italic=True),
    ""json.bool_false"": Style(color=""bright_red"", italic=True),
    ""json.null"": Style(color=""magenta"", italic=True),
    ""json.number"": Style(color=""cyan"", bold=True, italic=False),
    ""json.str"": Style(color=""green"", italic=False, bold=False),
    ""json.key"": Style(color=""blue"", bold=True),
    ""prompt"": Style.null(),
    ""prompt.choices"": Style(color=""magenta"", bold=True),
    ""prompt.default"": Style(color=""cyan"", bold=True),
    ""prompt.invalid"": Style(color=""red""),
    ""prompt.invalid.choice"": Style(color=""red""),
    ""pretty"": Style.null(),
    ""scope.border"": Style(color=""blue""),
    ""scope.key"": Style(color=""yellow"", italic=True),
    ""scope.key.special"": Style(color=""yellow"", italic=True, dim=True),
    ""scope.equals"": Style(color=""red""),
    ""table.header"": Style(bold=True),
    ""table.footer"": Style(bold=True),
    ""table.cell"": Style.null(),
    ""table.title"": Style(italic=True),
    ""table.caption"": Style(italic=True, dim=True),
    ""traceback.error"": Style(color=""red"", italic=True),
    ""traceback.border.syntax_error"": Style(color=""bright_red""),
    ""traceback.border"": Style(color=""red""),
    ""traceback.text"": Style.null(),
    ""traceback.title"": Style(color=""red"", bold=True),
    ""traceback.exc_type"": Style(color=""bright_red"", bold=True),
    ""traceback.exc_value"": Style.null(),
    ""traceback.offset"": Style(color=""bright_red"", bold=True),
    ""traceback.error_range"": Style(underline=True, bold=True),
    ""traceback.note"": Style(color=""green"", bold=True),
    ""traceback.group.border"": Style(color=""magenta""),
    ""bar.back"": Style(color=""grey23""),
    ""bar.complete"": Style(color=""rgb(249,38,114)""),
    ""bar.finished"": Style(color=""rgb(114,156,31)""),
    ""bar.pulse"": Style(color=""rgb(249,38,114)""),
    ""progress.description"": Style.null(),
    ""progress.filesize"": Style(color=""green""),
    ""progress.filesize.total"": Style(color=""green""),
    ""progress.download"": Style(color=""green""),
    ""progress.elapsed"": Style(color=""yellow""),
    ""progress.percentage"": Style(color=""magenta""),
    ""progress.remaining"": Style(color=""cyan""),
    ""progress.data.speed"": Style(color=""red""),
    ""progress.spinner"": Style(color=""green""),
    ""status.spinner"": Style(color=""green""),
    ""tree"": Style(),
    ""tree.line"": Style(),
    ""markdown.paragraph"": Style(),
    ""markdown.text"": Style(),
    ""markdown.em"": Style(italic=True),
    ""markdown.emph"": Style(italic=True),  
    ""markdown.strong"": Style(bold=True),
    ""markdown.code"": Style(bold=True, color=""cyan"", bgcolor=""black""),
    ""markdown.code_block"": Style(color=""cyan"", bgcolor=""black""),
    ""markdown.block_quote"": Style(color=""magenta""),
    ""markdown.list"": Style(color=""cyan""),
    ""markdown.item"": Style(),
    ""markdown.item.bullet"": Style(color=""yellow"", bold=True),
    ""markdown.item.number"": Style(color=""yellow"", bold=True),
    ""markdown.hr"": Style(color=""yellow""),
    ""markdown.h1.border"": Style(),
    ""markdown.h1"": Style(bold=True),
    ""markdown.h2"": Style(bold=True, underline=True),
    ""markdown.h3"": Style(bold=True),
    ""markdown.h4"": Style(bold=True, dim=True),
    ""markdown.h5"": Style(underline=True),
    ""markdown.h6"": Style(italic=True),
    ""markdown.h7"": Style(italic=True, dim=True),
    ""markdown.link"": Style(color=""bright_blue""),
    ""markdown.link_url"": Style(color=""blue"", underline=True),
    ""markdown.s"": Style(strike=True),
    ""iso8601.date"": Style(color=""blue""),
    ""iso8601.time"": Style(color=""magenta""),
    ""iso8601.timezone"": Style(color=""yellow""),
}


if __name__ == ""__main__"":  
    import argparse
    import io

    from pip._vendor.rich.console import Console
    from pip._vendor.rich.table import Table
    from pip._vendor.rich.text import Text

    parser = argparse.ArgumentParser()
    parser.add_argument(""--html"", action=""store_true"", help=""Export as HTML table"")
    args = parser.parse_args()
    html: bool = args.html
    console = Console(record=True, width=70, file=io.StringIO()) if html else Console()

    table = Table(""Name"", ""Styling"")

    for style_name, style in DEFAULT_STYLES.items():
        table.add_row(Text(style_name, style=style), str(style))

    console.print(table)
    if html:
        print(console.export_html(inline_styles=True))

import os
import platform

from pip._vendor.rich import inspect
from pip._vendor.rich.console import Console, get_windows_console_features
from pip._vendor.rich.panel import Panel
from pip._vendor.rich.pretty import Pretty


def report() -> None:  
    
    console = Console()
    inspect(console)
    features = get_windows_console_features()
    inspect(features)

    env_names = (
        ""CLICOLOR"",
        ""COLORTERM"",
        ""COLUMNS"",
        ""JPY_PARENT_PID"",
        ""JUPYTER_COLUMNS"",
        ""JUPYTER_LINES"",
        ""LINES"",
        ""NO_COLOR"",
        ""TERM_PROGRAM"",
        ""TERM"",
        ""TTY_COMPATIBLE"",
        ""TTY_INTERACTIVE"",
        ""VSCODE_VERBOSE_LOGGING"",
    )
    env = {name: os.getenv(name) for name in env_names}
    console.print(Panel.fit((Pretty(env)), title=""[b]Environment Variables""))

    console.print(f'platform=""{platform.system()}""')


if __name__ == ""__main__"":  
    report()

import sys
from typing import TYPE_CHECKING, Optional, Union, Literal

from .jupyter import JupyterMixin
from .segment import Segment
from .style import Style
from ._emoji_codes import EMOJI
from ._emoji_replace import _emoji_replace


if TYPE_CHECKING:
    from .console import Console, ConsoleOptions, RenderResult


EmojiVariant = Literal[""emoji"", ""text""]


class NoEmoji(Exception):
    


class Emoji(JupyterMixin):
    __slots__ = [""name"", ""style"", ""_char"", ""variant""]

    VARIANTS = {""text"": ""\uFE0E"", ""emoji"": ""\uFE0F""}

    def __init__(
        self,
        name: str,
        style: Union[str, Style] = ""none"",
        variant: Optional[EmojiVariant] = None,
    ) -> None:
        
        self.name = name
        self.style = style
        self.variant = variant
        try:
            self._char = EMOJI[name]
        except KeyError:
            raise NoEmoji(f""No emoji called {name!r}"")
        if variant is not None:
            self._char += self.VARIANTS.get(variant, """")

    @classmethod
    def replace(cls, text: str) -> str:
        
        return _emoji_replace(text)

    def __repr__(self) -> str:
        return f""<emoji {self.name!r}>""

    def __str__(self) -> str:
        return self._char

    def __rich_console__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> ""RenderResult"":
        yield Segment(self._char, console.get_style(self.style))


if __name__ == ""__main__"":  
    import sys

    from pip._vendor.rich.columns import Columns
    from pip._vendor.rich.console import Console

    console = Console(record=True)

    columns = Columns(
        (f"":{name}: {name}"" for name in sorted(EMOJI.keys()) if ""\u200D"" not in name),
        column_first=True,
    )

    console.print(columns)
    if len(sys.argv) > 1:
        console.save_html(sys.argv[1])

class ConsoleError(Exception):
    


class StyleError(Exception):
    


class StyleSyntaxError(ConsoleError):
    


class MissingStyle(StyleError):
    


class StyleStackError(ConsoleError):
    


class NotRenderableError(ConsoleError):
    


class MarkupError(ConsoleError):
    


class LiveError(ConsoleError):
    


class NoAltScreen(ConsoleError):
    



__all__ = [""decimal""]

from typing import Iterable, List, Optional, Tuple


def _to_str(
    size: int,
    suffixes: Iterable[str],
    base: int,
    *,
    precision: Optional[int] = 1,
    separator: Optional[str] = "" "",
) -> str:
    if size == 1:
        return ""1 byte""
    elif size < base:
        return f""{size:,} bytes""

    for i, suffix in enumerate(suffixes, 2):  
        unit = base**i
        if size < unit:
            break
    return ""{:,.{precision}f}{separator}{}"".format(
        (base * size / unit),
        suffix,
        precision=precision,
        separator=separator,
    )


def pick_unit_and_suffix(size: int, suffixes: List[str], base: int) -> Tuple[int, str]:
    
    for i, suffix in enumerate(suffixes):
        unit = base**i
        if size < unit * base:
            break
    return unit, suffix


def decimal(
    size: int,
    *,
    precision: Optional[int] = 1,
    separator: Optional[str] = "" "",
) -> str:
    
    return _to_str(
        size,
        (""kB"", ""MB"", ""GB"", ""TB"", ""PB"", ""EB"", ""ZB"", ""YB""),
        1000,
        precision=precision,
        separator=separator,
    )

import io
from typing import IO, TYPE_CHECKING, Any, List

from .ansi import AnsiDecoder
from .text import Text

if TYPE_CHECKING:
    from .console import Console


class FileProxy(io.TextIOBase):
    

    def __init__(self, console: ""Console"", file: IO[str]) -> None:
        self.__console = console
        self.__file = file
        self.__buffer: List[str] = []
        self.__ansi_decoder = AnsiDecoder()

    @property
    def rich_proxied_file(self) -> IO[str]:
        
        return self.__file

    def __getattr__(self, name: str) -> Any:
        return getattr(self.__file, name)

    def write(self, text: str) -> int:
        if not isinstance(text, str):
            raise TypeError(f""write() argument must be str, not {type(text).__name__}"")
        buffer = self.__buffer
        lines: List[str] = []
        while text:
            line, new_line, text = text.partition(""\n"")
            if new_line:
                lines.append("""".join(buffer) + line)
                buffer.clear()
            else:
                buffer.append(line)
                break
        if lines:
            console = self.__console
            with console:
                output = Text(""\n"").join(
                    self.__ansi_decoder.decode_line(line) for line in lines
                )
                console.print(output)
        return len(text)

    def flush(self) -> None:
        output = """".join(self.__buffer)
        if output:
            self.__console.print(output)
        del self.__buffer[:]

    def fileno(self) -> int:
        return self.__file.fileno()

import re
from abc import ABC, abstractmethod
from typing import List, Union

from .text import Span, Text


def _combine_regex(*regexes: str) -> str:
    
    return ""|"".join(regexes)


class Highlighter(ABC):
    

    def __call__(self, text: Union[str, Text]) -> Text:
        
        if isinstance(text, str):
            highlight_text = Text(text)
        elif isinstance(text, Text):
            highlight_text = text.copy()
        else:
            raise TypeError(f""str or Text instance required, not {text!r}"")
        self.highlight(highlight_text)
        return highlight_text

    @abstractmethod
    def highlight(self, text: Text) -> None:
        


class NullHighlighter(Highlighter):
    

    def highlight(self, text: Text) -> None:
        


class RegexHighlighter(Highlighter):
    

    highlights: List[str] = []
    base_style: str = """"

    def highlight(self, text: Text) -> None:
        

        highlight_regex = text.highlight_regex
        for re_highlight in self.highlights:
            highlight_regex(re_highlight, style_prefix=self.base_style)


class ReprHighlighter(RegexHighlighter):
    

    base_style = ""repr.""
    highlights = [
        r""(?P<tag_start><)(?P<tag_name>[-\w.:|]*)(?P<tag_contents>[\w\W]*)(?P<tag_end>>)"",
        r'(?P<attrib_name>[\w_]{1,50})=(?P<attrib_value>""?[\w_]+""?)?',
        r""(?P<brace>[][{}()])"",
        _combine_regex(
            r""(?P<ipv4>[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})"",
            r""(?P<ipv6>([A-Fa-f0-9]{1,4}::?){1,7}[A-Fa-f0-9]{1,4})"",
            r""(?P<eui64>(?:[0-9A-Fa-f]{1,2}-){7}[0-9A-Fa-f]{1,2}|(?:[0-9A-Fa-f]{1,2}:){7}[0-9A-Fa-f]{1,2}|(?:[0-9A-Fa-f]{4}\.){3}[0-9A-Fa-f]{4})"",
            r""(?P<eui48>(?:[0-9A-Fa-f]{1,2}-){5}[0-9A-Fa-f]{1,2}|(?:[0-9A-Fa-f]{1,2}:){5}[0-9A-Fa-f]{1,2}|(?:[0-9A-Fa-f]{4}\.){2}[0-9A-Fa-f]{4})"",
            r""(?P<uuid>[a-fA-F0-9]{8}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{12})"",
            r""(?P<call>[\w.]*?)\("",
            r""\b(?P<bool_true>True)\b|\b(?P<bool_false>False)\b|\b(?P<none>None)\b"",
            r""(?P<ellipsis>\.\.\.)"",
            r""(?P<number_complex>(?<!\w)(?:\-?[0-9]+\.?[0-9]*(?:e[-+]?\d+?)?)(?:[-+](?:[0-9]+\.?[0-9]*(?:e[-+]?\d+)?))?j)"",
            r""(?P<number>(?<!\w)\-?[0-9]+\.?[0-9]*(e[-+]?\d+?)?\b|0x[0-9a-fA-F]*)"",
            r""(?P<path>\B(/[-\w._+]+)*\/)(?P<filename>[-\w._+]*)?"",
            r""(?<![\\\w])(?P<str>b?|b?'.*?(?<!\\)'|b?\""\""\"".*?(?<!\\)\""\""\""|b?\"".*?(?<!\\)\"")"",
            r""(?P<url>(file|https|http|ws|wss)://[-0-9a-zA-Z$_+!`(),.?/;:&=%
        ),
    ]


class JSONHighlighter(RegexHighlighter):
    

    
    JSON_STR = r""(?<![\\\w])(?P<str>b?\"".*?(?<!\\)\"")""
    JSON_WHITESPACE = {"" "", ""\n"", ""\r"", ""\t""}

    base_style = ""json.""
    highlights = [
        _combine_regex(
            r""(?P<brace>[\{\[\(\)\]\}])"",
            r""\b(?P<bool_true>true)\b|\b(?P<bool_false>false)\b|\b(?P<null>null)\b"",
            r""(?P<number>(?<!\w)\-?[0-9]+\.?[0-9]*(e[\-\+]?\d+?)?\b|0x[0-9a-fA-F]*)"",
            JSON_STR,
        ),
    ]

    def highlight(self, text: Text) -> None:
        super().highlight(text)

        
        plain = text.plain
        append = text.spans.append
        whitespace = self.JSON_WHITESPACE
        for match in re.finditer(self.JSON_STR, plain):
            start, end = match.span()
            cursor = end
            while cursor < len(plain):
                char = plain[cursor]
                cursor += 1
                if char == "":"":
                    append(Span(start, end, ""json.key""))
                elif char in whitespace:
                    continue
                break


class ISO8601Highlighter(RegexHighlighter):
    

    base_style = ""iso8601.""
    highlights = [
        
        
        
        
        r""^(?P<year>[0-9]{4})-(?P<month>1[0-2]|0[1-9])$"",
        
        r""^(?P<date>(?P<year>[0-9]{4})(?P<month>1[0-2]|0[1-9])(?P<day>3[01]|0[1-9]|[12][0-9]))$"",
        
        r""^(?P<date>(?P<year>[0-9]{4})-?(?P<day>36[0-6]|3[0-5][0-9]|[12][0-9]{2}|0[1-9][0-9]|00[1-9]))$"",
        
        
        
        
        r""^(?P<date>(?P<year>[0-9]{4})-?W(?P<week>5[0-3]|[1-4][0-9]|0[1-9]))$"",
        
        r""^(?P<date>(?P<year>[0-9]{4})-?W(?P<week>5[0-3]|[1-4][0-9]|0[1-9])-?(?P<day>[1-7]))$"",
        
        
        
        
        r""^(?P<time>(?P<hour>2[0-3]|[01][0-9]):?(?P<minute>[0-5][0-9]))$"",
        
        r""^(?P<time>(?P<hour>2[0-3]|[01][0-9])(?P<minute>[0-5][0-9])(?P<second>[0-5][0-9]))$"",
        
        r""^(?P<timezone>(Z|[+-](?:2[0-3]|[01][0-9])(?::?(?:[0-5][0-9]))?))$"",
        
        
        r""^(?P<time>(?P<hour>2[0-3]|[01][0-9])(?P<minute>[0-5][0-9])(?P<second>[0-5][0-9]))(?P<timezone>Z|[+-](?:2[0-3]|[01][0-9])(?::?(?:[0-5][0-9]))?)$"",
        
        
        
        
        
        
        
        r""^(?P<date>(?P<year>[0-9]{4})(?P<hyphen>-)?(?P<month>1[0-2]|0[1-9])(?(hyphen)-)(?P<day>3[01]|0[1-9]|[12][0-9])) (?P<time>(?P<hour>2[0-3]|[01][0-9])(?(hyphen):)(?P<minute>[0-5][0-9])(?(hyphen):)(?P<second>[0-5][0-9]))$"",
        
        
        
        
        
        r""^(?P<date>(?P<year>-?(?:[1-9][0-9]*)?[0-9]{4})-(?P<month>1[0-2]|0[1-9])-(?P<day>3[01]|0[1-9]|[12][0-9]))(?P<timezone>Z|[+-](?:2[0-3]|[01][0-9]):[0-5][0-9])?$"",
        
        
        r""^(?P<time>(?P<hour>2[0-3]|[01][0-9]):(?P<minute>[0-5][0-9]):(?P<second>[0-5][0-9])(?P<frac>\.[0-9]+)?)(?P<timezone>Z|[+-](?:2[0-3]|[01][0-9]):[0-5][0-9])?$"",
        
        
        r""^(?P<date>(?P<year>-?(?:[1-9][0-9]*)?[0-9]{4})-(?P<month>1[0-2]|0[1-9])-(?P<day>3[01]|0[1-9]|[12][0-9]))T(?P<time>(?P<hour>2[0-3]|[01][0-9]):(?P<minute>[0-5][0-9]):(?P<second>[0-5][0-9])(?P<ms>\.[0-9]+)?)(?P<timezone>Z|[+-](?:2[0-3]|[01][0-9]):[0-5][0-9])?$"",
    ]


if __name__ == ""__main__"":  
    from .console import Console

    console = Console()
    console.print(""[bold green]hello world![/bold green]"")
    console.print(""'[bold green]hello world![/bold green]'"")

    console.print("" /foo"")
    console.print(""/foo/"")
    console.print(""/foo/bar"")
    console.print(""foo/bar/baz"")

    console.print(""/foo/bar/baz?foo=bar+egg&egg=baz"")
    console.print(""/foo/bar/baz/"")
    console.print(""/foo/bar/baz/egg"")
    console.print(""/foo/bar/baz/egg.py"")
    console.print(""/foo/bar/baz/egg.py word"")
    console.print("" /foo/bar/baz/egg.py word"")
    console.print(""foo /foo/bar/baz/egg.py word"")
    console.print(""foo /foo/bar/ba._++z/egg+.py word"")
    console.print(""https://example.org?foo=bar

    console.print(1234567.34)
    console.print(1 / 2)
    console.print(-1 / 123123123123)

    console.print(
        ""127.0.1.1 bar 192.168.1.4 2001:0db8:85a3:0000:0000:8a2e:0370:7334 foo""
    )
    import json

    console.print_json(json.dumps(obj={""name"": ""apple"", ""count"": 1}), indent=None)

from pathlib import Path
from json import loads, dumps
from typing import Any, Callable, Optional, Union

from .text import Text
from .highlighter import JSONHighlighter, NullHighlighter


class JSON:
    

    def __init__(
        self,
        json: str,
        indent: Union[None, int, str] = 2,
        highlight: bool = True,
        skip_keys: bool = False,
        ensure_ascii: bool = False,
        check_circular: bool = True,
        allow_nan: bool = True,
        default: Optional[Callable[[Any], Any]] = None,
        sort_keys: bool = False,
    ) -> None:
        data = loads(json)
        json = dumps(
            data,
            indent=indent,
            skipkeys=skip_keys,
            ensure_ascii=ensure_ascii,
            check_circular=check_circular,
            allow_nan=allow_nan,
            default=default,
            sort_keys=sort_keys,
        )
        highlighter = JSONHighlighter() if highlight else NullHighlighter()
        self.text = highlighter(json)
        self.text.no_wrap = True
        self.text.overflow = None

    @classmethod
    def from_data(
        cls,
        data: Any,
        indent: Union[None, int, str] = 2,
        highlight: bool = True,
        skip_keys: bool = False,
        ensure_ascii: bool = False,
        check_circular: bool = True,
        allow_nan: bool = True,
        default: Optional[Callable[[Any], Any]] = None,
        sort_keys: bool = False,
    ) -> ""JSON"":
        
        json_instance: ""JSON"" = cls.__new__(cls)
        json = dumps(
            data,
            indent=indent,
            skipkeys=skip_keys,
            ensure_ascii=ensure_ascii,
            check_circular=check_circular,
            allow_nan=allow_nan,
            default=default,
            sort_keys=sort_keys,
        )
        highlighter = JSONHighlighter() if highlight else NullHighlighter()
        json_instance.text = highlighter(json)
        json_instance.text.no_wrap = True
        json_instance.text.overflow = None
        return json_instance

    def __rich__(self) -> Text:
        return self.text


if __name__ == ""__main__"":
    import argparse
    import sys

    parser = argparse.ArgumentParser(description=""Pretty print json"")
    parser.add_argument(
        ""path"",
        metavar=""PATH"",
        help=""path to file, or - for stdin"",
    )
    parser.add_argument(
        ""-i"",
        ""--indent"",
        metavar=""SPACES"",
        type=int,
        help=""Number of spaces in an indent"",
        default=2,
    )
    args = parser.parse_args()

    from pip._vendor.rich.console import Console

    console = Console()
    error_console = Console(stderr=True)

    try:
        if args.path == ""-"":
            json_data = sys.stdin.read()
        else:
            json_data = Path(args.path).read_text()
    except Exception as error:
        error_console.print(f""Unable to read {args.path!r}; {error}"")
        sys.exit(-1)

    console.print(JSON(json_data, indent=args.indent), soft_wrap=True)

from typing import TYPE_CHECKING, Any, Dict, Iterable, List, Sequence

if TYPE_CHECKING:
    from pip._vendor.rich.console import ConsoleRenderable

from . import get_console
from .segment import Segment
from .terminal_theme import DEFAULT_TERMINAL_THEME

if TYPE_CHECKING:
    from pip._vendor.rich.console import ConsoleRenderable

JUPYTER_HTML_FORMAT = 


class JupyterRenderable:
    

    def __init__(self, html: str, text: str) -> None:
        self.html = html
        self.text = text

    def _repr_mimebundle_(
        self, include: Sequence[str], exclude: Sequence[str], **kwargs: Any
    ) -> Dict[str, str]:
        data = {""text/plain"": self.text, ""text/html"": self.html}
        if include:
            data = {k: v for (k, v) in data.items() if k in include}
        if exclude:
            data = {k: v for (k, v) in data.items() if k not in exclude}
        return data


class JupyterMixin:
    

    __slots__ = ()

    def _repr_mimebundle_(
        self: ""ConsoleRenderable"",
        include: Sequence[str],
        exclude: Sequence[str],
        **kwargs: Any,
    ) -> Dict[str, str]:
        console = get_console()
        segments = list(console.render(self, console.options))
        html = _render_segments(segments)
        text = console._render_buffer(segments)
        data = {""text/plain"": text, ""text/html"": html}
        if include:
            data = {k: v for (k, v) in data.items() if k in include}
        if exclude:
            data = {k: v for (k, v) in data.items() if k not in exclude}
        return data


def _render_segments(segments: Iterable[Segment]) -> str:
    def escape(text: str) -> str:
        
        return text.replace(""&"", ""&amp;"").replace(""<"", ""&lt;"").replace("">"", ""&gt;"")

    fragments: List[str] = []
    append_fragment = fragments.append
    theme = DEFAULT_TERMINAL_THEME
    for text, style, control in Segment.simplify(segments):
        if control:
            continue
        text = escape(text)
        if style:
            rule = style.get_html_style(theme)
            text = f'<span style=""{rule}"">{text}</span>' if rule else text
            if style.link:
                text = f'<a href=""{style.link}"" target=""_blank"">{text}</a>'
        append_fragment(text)

    code = """".join(fragments)
    html = JUPYTER_HTML_FORMAT.format(code=code)

    return html


def display(segments: Iterable[Segment], text: str) -> None:
    
    html = _render_segments(segments)
    jupyter_renderable = JupyterRenderable(html, text)
    try:
        from IPython.display import display as ipython_display

        ipython_display(jupyter_renderable)
    except ModuleNotFoundError:
        
        
        pass


def print(*args: Any, **kwargs: Any) -> None:
    
    console = get_console()
    return console.print(*args, **kwargs)

from abc import ABC, abstractmethod
from itertools import islice
from operator import itemgetter
from threading import RLock
from typing import (
    TYPE_CHECKING,
    Dict,
    Iterable,
    List,
    NamedTuple,
    Optional,
    Sequence,
    Tuple,
    Union,
)

from ._ratio import ratio_resolve
from .align import Align
from .console import Console, ConsoleOptions, RenderableType, RenderResult
from .highlighter import ReprHighlighter
from .panel import Panel
from .pretty import Pretty
from .region import Region
from .repr import Result, rich_repr
from .segment import Segment
from .style import StyleType

if TYPE_CHECKING:
    from pip._vendor.rich.tree import Tree


class LayoutRender(NamedTuple):
    

    region: Region
    render: List[List[Segment]]


RegionMap = Dict[""Layout"", Region]
RenderMap = Dict[""Layout"", LayoutRender]


class LayoutError(Exception):
    


class NoSplitter(LayoutError):
    


class _Placeholder:
    

    highlighter = ReprHighlighter()

    def __init__(self, layout: ""Layout"", style: StyleType = """") -> None:
        self.layout = layout
        self.style = style

    def __rich_console__(
        self, console: Console, options: ConsoleOptions
    ) -> RenderResult:
        width = options.max_width
        height = options.height or options.size.height
        layout = self.layout
        title = (
            f""{layout.name!r} ({width} x {height})""
            if layout.name
            else f""({width} x {height})""
        )
        yield Panel(
            Align.center(Pretty(layout), vertical=""middle""),
            style=self.style,
            title=self.highlighter(title),
            border_style=""blue"",
            height=height,
        )


class Splitter(ABC):
    

    name: str = """"

    @abstractmethod
    def get_tree_icon(self) -> str:
        

    @abstractmethod
    def divide(
        self, children: Sequence[""Layout""], region: Region
    ) -> Iterable[Tuple[""Layout"", Region]]:
        


class RowSplitter(Splitter):
    

    name = ""row""

    def get_tree_icon(self) -> str:
        return ""[layout.tree.row]⬌""

    def divide(
        self, children: Sequence[""Layout""], region: Region
    ) -> Iterable[Tuple[""Layout"", Region]]:
        x, y, width, height = region
        render_widths = ratio_resolve(width, children)
        offset = 0
        _Region = Region
        for child, child_width in zip(children, render_widths):
            yield child, _Region(x + offset, y, child_width, height)
            offset += child_width


class ColumnSplitter(Splitter):
    

    name = ""column""

    def get_tree_icon(self) -> str:
        return ""[layout.tree.column]⬍""

    def divide(
        self, children: Sequence[""Layout""], region: Region
    ) -> Iterable[Tuple[""Layout"", Region]]:
        x, y, width, height = region
        render_heights = ratio_resolve(height, children)
        offset = 0
        _Region = Region
        for child, child_height in zip(children, render_heights):
            yield child, _Region(x, y + offset, width, child_height)
            offset += child_height


@rich_repr
class Layout:
    

    splitters = {""row"": RowSplitter, ""column"": ColumnSplitter}

    def __init__(
        self,
        renderable: Optional[RenderableType] = None,
        *,
        name: Optional[str] = None,
        size: Optional[int] = None,
        minimum_size: int = 1,
        ratio: int = 1,
        visible: bool = True,
    ) -> None:
        self._renderable = renderable or _Placeholder(self)
        self.size = size
        self.minimum_size = minimum_size
        self.ratio = ratio
        self.name = name
        self.visible = visible
        self.splitter: Splitter = self.splitters[""column""]()
        self._children: List[Layout] = []
        self._render_map: RenderMap = {}
        self._lock = RLock()

    def __rich_repr__(self) -> Result:
        yield ""name"", self.name, None
        yield ""size"", self.size, None
        yield ""minimum_size"", self.minimum_size, 1
        yield ""ratio"", self.ratio, 1

    @property
    def renderable(self) -> RenderableType:
        
        return self if self._children else self._renderable

    @property
    def children(self) -> List[""Layout""]:
        
        return [child for child in self._children if child.visible]

    @property
    def map(self) -> RenderMap:
        
        return self._render_map

    def get(self, name: str) -> Optional[""Layout""]:
        
        if self.name == name:
            return self
        else:
            for child in self._children:
                named_layout = child.get(name)
                if named_layout is not None:
                    return named_layout
        return None

    def __getitem__(self, name: str) -> ""Layout"":
        layout = self.get(name)
        if layout is None:
            raise KeyError(f""No layout with name {name!r}"")
        return layout

    @property
    def tree(self) -> ""Tree"":
        
        from pip._vendor.rich.styled import Styled
        from pip._vendor.rich.table import Table
        from pip._vendor.rich.tree import Tree

        def summary(layout: ""Layout"") -> Table:
            icon = layout.splitter.get_tree_icon()

            table = Table.grid(padding=(0, 1, 0, 0))

            text: RenderableType = (
                Pretty(layout) if layout.visible else Styled(Pretty(layout), ""dim"")
            )
            table.add_row(icon, text)
            _summary = table
            return _summary

        layout = self
        tree = Tree(
            summary(layout),
            guide_style=f""layout.tree.{layout.splitter.name}"",
            highlight=True,
        )

        def recurse(tree: ""Tree"", layout: ""Layout"") -> None:
            for child in layout._children:
                recurse(
                    tree.add(
                        summary(child),
                        guide_style=f""layout.tree.{child.splitter.name}"",
                    ),
                    child,
                )

        recurse(tree, self)
        return tree

    def split(
        self,
        *layouts: Union[""Layout"", RenderableType],
        splitter: Union[Splitter, str] = ""column"",
    ) -> None:
        
        _layouts = [
            layout if isinstance(layout, Layout) else Layout(layout)
            for layout in layouts
        ]
        try:
            self.splitter = (
                splitter
                if isinstance(splitter, Splitter)
                else self.splitters[splitter]()
            )
        except KeyError:
            raise NoSplitter(f""No splitter called {splitter!r}"")
        self._children[:] = _layouts

    def add_split(self, *layouts: Union[""Layout"", RenderableType]) -> None:
        
        _layouts = (
            layout if isinstance(layout, Layout) else Layout(layout)
            for layout in layouts
        )
        self._children.extend(_layouts)

    def split_row(self, *layouts: Union[""Layout"", RenderableType]) -> None:
        
        self.split(*layouts, splitter=""row"")

    def split_column(self, *layouts: Union[""Layout"", RenderableType]) -> None:
        
        self.split(*layouts, splitter=""column"")

    def unsplit(self) -> None:
        
        del self._children[:]

    def update(self, renderable: RenderableType) -> None:
        
        with self._lock:
            self._renderable = renderable

    def refresh_screen(self, console: ""Console"", layout_name: str) -> None:
        
        with self._lock:
            layout = self[layout_name]
            region, _lines = self._render_map[layout]
            (x, y, width, height) = region
            lines = console.render_lines(
                layout, console.options.update_dimensions(width, height)
            )
            self._render_map[layout] = LayoutRender(region, lines)
            console.update_screen_lines(lines, x, y)

    def _make_region_map(self, width: int, height: int) -> RegionMap:
        
        stack: List[Tuple[Layout, Region]] = [(self, Region(0, 0, width, height))]
        push = stack.append
        pop = stack.pop
        layout_regions: List[Tuple[Layout, Region]] = []
        append_layout_region = layout_regions.append
        while stack:
            append_layout_region(pop())
            layout, region = layout_regions[-1]
            children = layout.children
            if children:
                for child_and_region in layout.splitter.divide(children, region):
                    push(child_and_region)

        region_map = {
            layout: region
            for layout, region in sorted(layout_regions, key=itemgetter(1))
        }
        return region_map

    def render(self, console: Console, options: ConsoleOptions) -> RenderMap:
        
        render_width = options.max_width
        render_height = options.height or console.height
        region_map = self._make_region_map(render_width, render_height)
        layout_regions = [
            (layout, region)
            for layout, region in region_map.items()
            if not layout.children
        ]
        render_map: Dict[""Layout"", ""LayoutRender""] = {}
        render_lines = console.render_lines
        update_dimensions = options.update_dimensions

        for layout, region in layout_regions:
            lines = render_lines(
                layout.renderable, update_dimensions(region.width, region.height)
            )
            render_map[layout] = LayoutRender(region, lines)
        return render_map

    def __rich_console__(
        self, console: Console, options: ConsoleOptions
    ) -> RenderResult:
        with self._lock:
            width = options.max_width or console.width
            height = options.height or console.height
            render_map = self.render(console, options.update_dimensions(width, height))
            self._render_map = render_map
            layout_lines: List[List[Segment]] = [[] for _ in range(height)]
            _islice = islice
            for region, lines in render_map.values():
                _x, y, _layout_width, layout_height = region
                for row, line in zip(
                    _islice(layout_lines, y, y + layout_height), lines
                ):
                    row.extend(line)

            new_line = Segment.line()
            for layout_row in layout_lines:
                yield from layout_row
                yield new_line


if __name__ == ""__main__"":
    from pip._vendor.rich.console import Console

    console = Console()
    layout = Layout()

    layout.split_column(
        Layout(name=""header"", size=3),
        Layout(ratio=1, name=""main""),
        Layout(size=10, name=""footer""),
    )

    layout[""main""].split_row(Layout(name=""side""), Layout(name=""body"", ratio=2))

    layout[""body""].split_row(Layout(name=""content"", ratio=2), Layout(name=""s2""))

    layout[""s2""].split_column(
        Layout(name=""top""), Layout(name=""middle""), Layout(name=""bottom"")
    )

    layout[""side""].split_column(Layout(layout.tree, name=""left1""), Layout(name=""left2""))

    layout[""content""].update(""foo"")

    console.print(layout)

from __future__ import annotations

import sys
from threading import Event, RLock, Thread
from types import TracebackType
from typing import IO, TYPE_CHECKING, Any, Callable, List, Optional, TextIO, Type, cast

from . import get_console
from .console import Console, ConsoleRenderable, Group, RenderableType, RenderHook
from .control import Control
from .file_proxy import FileProxy
from .jupyter import JupyterMixin
from .live_render import LiveRender, VerticalOverflowMethod
from .screen import Screen
from .text import Text

if TYPE_CHECKING:
    
    from typing_extensions import Self  


class _RefreshThread(Thread):
    

    def __init__(self, live: ""Live"", refresh_per_second: float) -> None:
        self.live = live
        self.refresh_per_second = refresh_per_second
        self.done = Event()
        super().__init__(daemon=True)

    def stop(self) -> None:
        self.done.set()

    def run(self) -> None:
        while not self.done.wait(1 / self.refresh_per_second):
            with self.live._lock:
                if not self.done.is_set():
                    self.live.refresh()


class Live(JupyterMixin, RenderHook):
    

    def __init__(
        self,
        renderable: Optional[RenderableType] = None,
        *,
        console: Optional[Console] = None,
        screen: bool = False,
        auto_refresh: bool = True,
        refresh_per_second: float = 4,
        transient: bool = False,
        redirect_stdout: bool = True,
        redirect_stderr: bool = True,
        vertical_overflow: VerticalOverflowMethod = ""ellipsis"",
        get_renderable: Optional[Callable[[], RenderableType]] = None,
    ) -> None:
        assert refresh_per_second > 0, ""refresh_per_second must be > 0""
        self._renderable = renderable
        self.console = console if console is not None else get_console()
        self._screen = screen
        self._alt_screen = False

        self._redirect_stdout = redirect_stdout
        self._redirect_stderr = redirect_stderr
        self._restore_stdout: Optional[IO[str]] = None
        self._restore_stderr: Optional[IO[str]] = None

        self._lock = RLock()
        self.ipy_widget: Optional[Any] = None
        self.auto_refresh = auto_refresh
        self._started: bool = False
        self.transient = True if screen else transient

        self._refresh_thread: Optional[_RefreshThread] = None
        self.refresh_per_second = refresh_per_second

        self.vertical_overflow = vertical_overflow
        self._get_renderable = get_renderable
        self._live_render = LiveRender(
            self.get_renderable(), vertical_overflow=vertical_overflow
        )
        self._nested = False

    @property
    def is_started(self) -> bool:
        
        return self._started

    def get_renderable(self) -> RenderableType:
        renderable = (
            self._get_renderable()
            if self._get_renderable is not None
            else self._renderable
        )
        return renderable or """"

    def start(self, refresh: bool = False) -> None:
        
        with self._lock:
            if self._started:
                return
            self._started = True

            if not self.console.set_live(self):
                self._nested = True
                return

            if self._screen:
                self._alt_screen = self.console.set_alt_screen(True)
            self.console.show_cursor(False)
            self._enable_redirect_io()
            self.console.push_render_hook(self)
            if refresh:
                try:
                    self.refresh()
                except Exception:
                    
                    
                    
                    
                    self.stop()
                    raise
            if self.auto_refresh:
                self._refresh_thread = _RefreshThread(self, self.refresh_per_second)
                self._refresh_thread.start()

    def stop(self) -> None:
        
        with self._lock:
            if not self._started:
                return
            self._started = False
            self.console.clear_live()
            if self._nested:
                if not self.transient:
                    self.console.print(self.renderable)
                return

            if self.auto_refresh and self._refresh_thread is not None:
                self._refresh_thread.stop()
                self._refresh_thread = None
            
            self.vertical_overflow = ""visible""
            with self.console:
                try:
                    if not self._alt_screen and not self.console.is_jupyter:
                        self.refresh()
                finally:
                    self._disable_redirect_io()
                    self.console.pop_render_hook()
                    if not self._alt_screen and self.console.is_terminal:
                        self.console.line()
                    self.console.show_cursor(True)
                    if self._alt_screen:
                        self.console.set_alt_screen(False)
                    if self.transient and not self._alt_screen:
                        self.console.control(self._live_render.restore_cursor())
                    if self.ipy_widget is not None and self.transient:
                        self.ipy_widget.close()  

    def __enter__(self) -> Self:
        self.start(refresh=self._renderable is not None)
        return self

    def __exit__(
        self,
        exc_type: Optional[Type[BaseException]],
        exc_val: Optional[BaseException],
        exc_tb: Optional[TracebackType],
    ) -> None:
        self.stop()

    def _enable_redirect_io(self) -> None:
        
        if self.console.is_terminal or self.console.is_jupyter:
            if self._redirect_stdout and not isinstance(sys.stdout, FileProxy):
                self._restore_stdout = sys.stdout
                sys.stdout = cast(""TextIO"", FileProxy(self.console, sys.stdout))
            if self._redirect_stderr and not isinstance(sys.stderr, FileProxy):
                self._restore_stderr = sys.stderr
                sys.stderr = cast(""TextIO"", FileProxy(self.console, sys.stderr))

    def _disable_redirect_io(self) -> None:
        
        if self._restore_stdout:
            sys.stdout = cast(""TextIO"", self._restore_stdout)
            self._restore_stdout = None
        if self._restore_stderr:
            sys.stderr = cast(""TextIO"", self._restore_stderr)
            self._restore_stderr = None

    @property
    def renderable(self) -> RenderableType:
        
        live_stack = self.console._live_stack
        renderable: RenderableType
        if live_stack and self is live_stack[0]:
            
            renderable = Group(*[live.get_renderable() for live in live_stack])
        else:
            renderable = self.get_renderable()
        return Screen(renderable) if self._alt_screen else renderable

    def update(self, renderable: RenderableType, *, refresh: bool = False) -> None:
        
        if isinstance(renderable, str):
            renderable = self.console.render_str(renderable)
        with self._lock:
            self._renderable = renderable
            if refresh:
                self.refresh()

    def refresh(self) -> None:
        
        with self._lock:
            self._live_render.set_renderable(self.renderable)
            if self._nested:
                if self.console._live_stack:
                    self.console._live_stack[0].refresh()
                return

            if self.console.is_jupyter:  
                try:
                    from IPython.display import display
                    from ipywidgets import Output
                except ImportError:
                    import warnings

                    warnings.warn('install ""ipywidgets"" for Jupyter support')
                else:
                    if self.ipy_widget is None:
                        self.ipy_widget = Output()
                        display(self.ipy_widget)

                    with self.ipy_widget:
                        self.ipy_widget.clear_output(wait=True)
                        self.console.print(self._live_render.renderable)
            elif self.console.is_terminal and not self.console.is_dumb_terminal:
                with self.console:
                    self.console.print(Control())
            elif (
                not self._started and not self.transient
            ):  
                with self.console:
                    self.console.print(Control())

    def process_renderables(
        self, renderables: List[ConsoleRenderable]
    ) -> List[ConsoleRenderable]:
        
        self._live_render.vertical_overflow = self.vertical_overflow
        if self.console.is_interactive:
            
            with self._lock:
                reset = (
                    Control.home()
                    if self._alt_screen
                    else self._live_render.position_cursor()
                )
                renderables = [reset, *renderables, self._live_render]
        elif (
            not self._started and not self.transient
        ):  
            renderables = [*renderables, self._live_render]

        return renderables


if __name__ == ""__main__"":  
    import random
    import time
    from itertools import cycle
    from typing import Dict, List, Tuple

    from .align import Align
    from .console import Console
    from .live import Live as Live
    from .panel import Panel
    from .rule import Rule
    from .syntax import Syntax
    from .table import Table

    console = Console()

    syntax = Syntax(
        ,
        ""python"",
        line_numbers=True,
    )

    table = Table(""foo"", ""bar"", ""baz"")
    table.add_row(""1"", ""2"", ""3"")

    progress_renderables = [
        ""You can make the terminal shorter and taller to see the live table hide""
        ""Text may be printed while the progress bars are rendering."",
        Panel(""In fact, [i]any[/i] renderable will work""),
        ""Such as [magenta]tables[/]..."",
        table,
        ""Pretty printed structures..."",
        {""type"": ""example"", ""text"": ""Pretty printed""},
        ""Syntax..."",
        syntax,
        Rule(""Give it a try!""),
    ]

    examples = cycle(progress_renderables)

    exchanges = [
        ""SGD"",
        ""MYR"",
        ""EUR"",
        ""USD"",
        ""AUD"",
        ""JPY"",
        ""CNH"",
        ""HKD"",
        ""CAD"",
        ""INR"",
        ""DKK"",
        ""GBP"",
        ""RUB"",
        ""NZD"",
        ""MXN"",
        ""IDR"",
        ""TWD"",
        ""THB"",
        ""VND"",
    ]
    with Live(console=console) as live_table:
        exchange_rate_dict: Dict[Tuple[str, str], float] = {}

        for index in range(100):
            select_exchange = exchanges[index % len(exchanges)]

            for exchange in exchanges:
                if exchange == select_exchange:
                    continue
                time.sleep(0.4)
                if random.randint(0, 10) < 1:
                    console.log(next(examples))
                exchange_rate_dict[(select_exchange, exchange)] = 200 / (
                    (random.random() * 320) + 1
                )
                if len(exchange_rate_dict) > len(exchanges) - 1:
                    exchange_rate_dict.pop(list(exchange_rate_dict.keys())[0])
                table = Table(title=""Exchange Rates"")

                table.add_column(""Source Currency"")
                table.add_column(""Destination Currency"")
                table.add_column(""Exchange Rate"")

                for (source, dest), exchange_rate in exchange_rate_dict.items():
                    table.add_row(
                        source,
                        dest,
                        Text(
                            f""{exchange_rate:.4f}"",
                            style=""red"" if exchange_rate < 1.0 else ""green"",
                        ),
                    )

                live_table.update(Align.center(table))

from typing import Optional, Tuple, Literal


from ._loop import loop_last
from .console import Console, ConsoleOptions, RenderableType, RenderResult
from .control import Control
from .segment import ControlType, Segment
from .style import StyleType
from .text import Text

VerticalOverflowMethod = Literal[""crop"", ""ellipsis"", ""visible""]


class LiveRender:
    

    def __init__(
        self,
        renderable: RenderableType,
        style: StyleType = """",
        vertical_overflow: VerticalOverflowMethod = ""ellipsis"",
    ) -> None:
        self.renderable = renderable
        self.style = style
        self.vertical_overflow = vertical_overflow
        self._shape: Optional[Tuple[int, int]] = None

    def set_renderable(self, renderable: RenderableType) -> None:
        
        self.renderable = renderable

    def position_cursor(self) -> Control:
        
        if self._shape is not None:
            _, height = self._shape
            return Control(
                ControlType.CARRIAGE_RETURN,
                (ControlType.ERASE_IN_LINE, 2),
                *(
                    (
                        (ControlType.CURSOR_UP, 1),
                        (ControlType.ERASE_IN_LINE, 2),
                    )
                    * (height - 1)
                )
            )
        return Control()

    def restore_cursor(self) -> Control:
        
        if self._shape is not None:
            _, height = self._shape
            return Control(
                ControlType.CARRIAGE_RETURN,
                *((ControlType.CURSOR_UP, 1), (ControlType.ERASE_IN_LINE, 2)) * height
            )
        return Control()

    def __rich_console__(
        self, console: Console, options: ConsoleOptions
    ) -> RenderResult:
        renderable = self.renderable
        style = console.get_style(self.style)
        lines = console.render_lines(renderable, options, style=style, pad=False)
        shape = Segment.get_shape(lines)

        _, height = shape
        if height > options.size.height:
            if self.vertical_overflow == ""crop"":
                lines = lines[: options.size.height]
                shape = Segment.get_shape(lines)
            elif self.vertical_overflow == ""ellipsis"":
                lines = lines[: (options.size.height - 1)]
                overflow_text = Text(
                    ""..."",
                    overflow=""crop"",
                    justify=""center"",
                    end="""",
                    style=""live.ellipsis"",
                )
                lines.append(list(console.render(overflow_text)))
                shape = Segment.get_shape(lines)
        self._shape = shape

        new_line = Segment.line()
        for last, line in loop_last(lines):
            yield from line
            if not last:
                yield new_line

import logging
from datetime import datetime
from logging import Handler, LogRecord
from pathlib import Path
from types import ModuleType
from typing import ClassVar, Iterable, List, Optional, Type, Union

from pip._vendor.rich._null_file import NullFile

from . import get_console
from ._log_render import FormatTimeCallable, LogRender
from .console import Console, ConsoleRenderable
from .highlighter import Highlighter, ReprHighlighter
from .text import Text
from .traceback import Traceback


class RichHandler(Handler):
    

    KEYWORDS: ClassVar[Optional[List[str]]] = [
        ""GET"",
        ""POST"",
        ""HEAD"",
        ""PUT"",
        ""DELETE"",
        ""OPTIONS"",
        ""TRACE"",
        ""PATCH"",
    ]
    HIGHLIGHTER_CLASS: ClassVar[Type[Highlighter]] = ReprHighlighter

    def __init__(
        self,
        level: Union[int, str] = logging.NOTSET,
        console: Optional[Console] = None,
        *,
        show_time: bool = True,
        omit_repeated_times: bool = True,
        show_level: bool = True,
        show_path: bool = True,
        enable_link_path: bool = True,
        highlighter: Optional[Highlighter] = None,
        markup: bool = False,
        rich_tracebacks: bool = False,
        tracebacks_width: Optional[int] = None,
        tracebacks_code_width: Optional[int] = 88,
        tracebacks_extra_lines: int = 3,
        tracebacks_theme: Optional[str] = None,
        tracebacks_word_wrap: bool = True,
        tracebacks_show_locals: bool = False,
        tracebacks_suppress: Iterable[Union[str, ModuleType]] = (),
        tracebacks_max_frames: int = 100,
        locals_max_length: int = 10,
        locals_max_string: int = 80,
        log_time_format: Union[str, FormatTimeCallable] = ""[%x %X]"",
        keywords: Optional[List[str]] = None,
    ) -> None:
        super().__init__(level=level)
        self.console = console or get_console()
        self.highlighter = highlighter or self.HIGHLIGHTER_CLASS()
        self._log_render = LogRender(
            show_time=show_time,
            show_level=show_level,
            show_path=show_path,
            time_format=log_time_format,
            omit_repeated_times=omit_repeated_times,
            level_width=None,
        )
        self.enable_link_path = enable_link_path
        self.markup = markup
        self.rich_tracebacks = rich_tracebacks
        self.tracebacks_width = tracebacks_width
        self.tracebacks_extra_lines = tracebacks_extra_lines
        self.tracebacks_theme = tracebacks_theme
        self.tracebacks_word_wrap = tracebacks_word_wrap
        self.tracebacks_show_locals = tracebacks_show_locals
        self.tracebacks_suppress = tracebacks_suppress
        self.tracebacks_max_frames = tracebacks_max_frames
        self.tracebacks_code_width = tracebacks_code_width
        self.locals_max_length = locals_max_length
        self.locals_max_string = locals_max_string
        self.keywords = keywords

    def get_level_text(self, record: LogRecord) -> Text:
        
        level_name = record.levelname
        level_text = Text.styled(
            level_name.ljust(8), f""logging.level.{level_name.lower()}""
        )
        return level_text

    def emit(self, record: LogRecord) -> None:
        
        message = self.format(record)
        traceback = None
        if (
            self.rich_tracebacks
            and record.exc_info
            and record.exc_info != (None, None, None)
        ):
            exc_type, exc_value, exc_traceback = record.exc_info
            assert exc_type is not None
            assert exc_value is not None
            traceback = Traceback.from_exception(
                exc_type,
                exc_value,
                exc_traceback,
                width=self.tracebacks_width,
                code_width=self.tracebacks_code_width,
                extra_lines=self.tracebacks_extra_lines,
                theme=self.tracebacks_theme,
                word_wrap=self.tracebacks_word_wrap,
                show_locals=self.tracebacks_show_locals,
                locals_max_length=self.locals_max_length,
                locals_max_string=self.locals_max_string,
                suppress=self.tracebacks_suppress,
                max_frames=self.tracebacks_max_frames,
            )
            message = record.getMessage()
            if self.formatter:
                record.message = record.getMessage()
                formatter = self.formatter
                if hasattr(formatter, ""usesTime"") and formatter.usesTime():
                    record.asctime = formatter.formatTime(record, formatter.datefmt)
                message = formatter.formatMessage(record)

        message_renderable = self.render_message(record, message)
        log_renderable = self.render(
            record=record, traceback=traceback, message_renderable=message_renderable
        )
        if isinstance(self.console.file, NullFile):
            
            
            
            self.handleError(record)
        else:
            try:
                self.console.print(log_renderable)
            except Exception:
                self.handleError(record)

    def render_message(self, record: LogRecord, message: str) -> ""ConsoleRenderable"":
        
        use_markup = getattr(record, ""markup"", self.markup)
        message_text = Text.from_markup(message) if use_markup else Text(message)

        highlighter = getattr(record, ""highlighter"", self.highlighter)
        if highlighter:
            message_text = highlighter(message_text)

        if self.keywords is None:
            self.keywords = self.KEYWORDS

        if self.keywords:
            message_text.highlight_words(self.keywords, ""logging.keyword"")

        return message_text

    def render(
        self,
        *,
        record: LogRecord,
        traceback: Optional[Traceback],
        message_renderable: ""ConsoleRenderable"",
    ) -> ""ConsoleRenderable"":
        
        path = Path(record.pathname).name
        level = self.get_level_text(record)
        time_format = None if self.formatter is None else self.formatter.datefmt
        log_time = datetime.fromtimestamp(record.created)

        log_renderable = self._log_render(
            self.console,
            [message_renderable] if not traceback else [message_renderable, traceback],
            log_time=log_time,
            time_format=time_format,
            level=level,
            path=path,
            line_no=record.lineno,
            link_path=record.pathname if self.enable_link_path else None,
        )
        return log_renderable


if __name__ == ""__main__"":  
    from time import sleep

    FORMAT = ""%(message)s""
    
    logging.basicConfig(
        level=""NOTSET"",
        format=FORMAT,
        datefmt=""[%X]"",
        handlers=[RichHandler(rich_tracebacks=True, tracebacks_show_locals=True)],
    )
    log = logging.getLogger(""rich"")

    log.info(""Server starting..."")
    log.info(""Listening on http://127.0.0.1:8080"")
    sleep(1)

    log.info(""GET /index.html 200 1298"")
    log.info(""GET /imgs/backgrounds/back1.jpg 200 54386"")
    log.info(""GET /css/styles.css 200 54386"")
    log.warning(""GET /favicon.ico 404 242"")
    sleep(1)

    log.debug(
        ""JSONRPC request\n--> %r\n<-- %r"",
        {
            ""version"": ""1.1"",
            ""method"": ""confirmFruitPurchase"",
            ""params"": [[""apple"", ""orange"", ""mangoes"", ""pomelo""], 1.123],
            ""id"": ""194521489"",
        },
        {""version"": ""1.1"", ""result"": True, ""error"": None, ""id"": ""194521489""},
    )
    log.debug(
        ""Loading configuration file /adasd/asdasd/qeqwe/qwrqwrqwr/sdgsdgsdg/werwerwer/dfgerert/ertertert/ertetert/werwerwer""
    )
    log.error(""Unable to find 'pomelo' in database!"")
    log.info(""POST /jsonrpc/ 200 65532"")
    log.info(""POST /admin/ 401 42234"")
    log.warning(""password was rejected for admin site."")

    def divide() -> None:
        number = 1
        divisor = 0
        foos = [""foo""] * 100
        log.debug(""in divide"")
        try:
            number / divisor
        except:
            log.exception(""An error of some kind occurred!"")

    divide()
    sleep(1)
    log.critical(""Out of memory!"")
    log.info(""Server exited with code=-1"")
    log.info(""[bold]EXITING...[/bold]"", extra=dict(markup=True))

import re
from ast import literal_eval
from operator import attrgetter
from typing import Callable, Iterable, List, Match, NamedTuple, Optional, Tuple, Union

from ._emoji_replace import _emoji_replace
from .emoji import EmojiVariant
from .errors import MarkupError
from .style import Style
from .text import Span, Text

RE_TAGS = re.compile(
    r,
    re.VERBOSE,
)

RE_HANDLER = re.compile(r""^([\w.]*?)(\(.*?\))?$"")


class Tag(NamedTuple):
    

    name: str
    
    parameters: Optional[str]
    

    def __str__(self) -> str:
        return (
            self.name if self.parameters is None else f""{self.name} {self.parameters}""
        )

    @property
    def markup(self) -> str:
        
        return (
            f""[{self.name}]""
            if self.parameters is None
            else f""[{self.name}={self.parameters}]""
        )


_ReStringMatch = Match[str]  
_ReSubCallable = Callable[[_ReStringMatch], str]  
_EscapeSubMethod = Callable[[_ReSubCallable, str], str]  


def escape(
    markup: str,
    _escape: _EscapeSubMethod = re.compile(r""(\\*)(\[[a-z
) -> str:
    

    def escape_backslashes(match: Match[str]) -> str:
        
        backslashes, text = match.groups()
        return f""{backslashes}{backslashes}\\{text}""

    markup = _escape(escape_backslashes, markup)
    if markup.endswith(""\\"") and not markup.endswith(""\\\\""):
        return markup + ""\\""

    return markup


def _parse(markup: str) -> Iterable[Tuple[int, Optional[str], Optional[Tag]]]:
    
    position = 0
    _divmod = divmod
    _Tag = Tag
    for match in RE_TAGS.finditer(markup):
        full_text, escapes, tag_text = match.groups()
        start, end = match.span()
        if start > position:
            yield start, markup[position:start], None
        if escapes:
            backslashes, escaped = _divmod(len(escapes), 2)
            if backslashes:
                
                yield start, ""\\"" * backslashes, None
                start += backslashes * 2
            if escaped:
                
                yield start, full_text[len(escapes) :], None
                position = end
                continue
        text, equals, parameters = tag_text.partition(""="")
        yield start, None, _Tag(text, parameters if equals else None)
        position = end
    if position < len(markup):
        yield position, markup[position:], None


def render(
    markup: str,
    style: Union[str, Style] = """",
    emoji: bool = True,
    emoji_variant: Optional[EmojiVariant] = None,
) -> Text:
    
    emoji_replace = _emoji_replace
    if ""["" not in markup:
        return Text(
            emoji_replace(markup, default_variant=emoji_variant) if emoji else markup,
            style=style,
        )
    text = Text(style=style)
    append = text.append
    normalize = Style.normalize

    style_stack: List[Tuple[int, Tag]] = []
    pop = style_stack.pop

    spans: List[Span] = []
    append_span = spans.append

    _Span = Span
    _Tag = Tag

    def pop_style(style_name: str) -> Tuple[int, Tag]:
        
        for index, (_, tag) in enumerate(reversed(style_stack), 1):
            if tag.name == style_name:
                return pop(-index)
        raise KeyError(style_name)

    for position, plain_text, tag in _parse(markup):
        if plain_text is not None:
            
            plain_text = plain_text.replace(""\\["", ""["")
            append(emoji_replace(plain_text) if emoji else plain_text)
        elif tag is not None:
            if tag.name.startswith(""/""):  
                style_name = tag.name[1:].strip()

                if style_name:  
                    style_name = normalize(style_name)
                    try:
                        start, open_tag = pop_style(style_name)
                    except KeyError:
                        raise MarkupError(
                            f""closing tag '{tag.markup}' at position {position} doesn't match any open tag""
                        ) from None
                else:  
                    try:
                        start, open_tag = pop()
                    except IndexError:
                        raise MarkupError(
                            f""closing tag '[/]' at position {position} has nothing to close""
                        ) from None

                if open_tag.name.startswith(""@""):
                    if open_tag.parameters:
                        handler_name = """"
                        parameters = open_tag.parameters.strip()
                        handler_match = RE_HANDLER.match(parameters)
                        if handler_match is not None:
                            handler_name, match_parameters = handler_match.groups()
                            parameters = (
                                ""()"" if match_parameters is None else match_parameters
                            )

                        try:
                            meta_params = literal_eval(parameters)
                        except SyntaxError as error:
                            raise MarkupError(
                                f""error parsing {parameters!r} in {open_tag.parameters!r}; {error.msg}""
                            )
                        except Exception as error:
                            raise MarkupError(
                                f""error parsing {open_tag.parameters!r}; {error}""
                            ) from None

                        if handler_name:
                            meta_params = (
                                handler_name,
                                meta_params
                                if isinstance(meta_params, tuple)
                                else (meta_params,),
                            )

                    else:
                        meta_params = ()

                    append_span(
                        _Span(
                            start, len(text), Style(meta={open_tag.name: meta_params})
                        )
                    )
                else:
                    append_span(_Span(start, len(text), str(open_tag)))

            else:  
                normalized_tag = _Tag(normalize(tag.name), tag.parameters)
                style_stack.append((len(text), normalized_tag))

    text_length = len(text)
    while style_stack:
        start, tag = style_stack.pop()
        style = str(tag)
        if style:
            append_span(_Span(start, text_length, style))

    text.spans = sorted(spans[::-1], key=attrgetter(""start""))
    return text


if __name__ == ""__main__"":  
    MARKUP = [
        ""[red]Hello World[/red]"",
        ""[magenta]Hello [b]World[/b]"",
        ""[bold]Bold[italic] bold and italic [/bold]italic[/italic]"",
        ""Click [link=https://www.willmcgugan.com]here[/link] to visit my Blog"",
        "":warning-emoji: [bold red blink] DANGER![/]"",
    ]

    from pip._vendor.rich import print
    from pip._vendor.rich.table import Table

    grid = Table(""Markup"", ""Result"", padding=(0, 1))

    for markup in MARKUP:
        grid.add_row(Text(markup), markup)

    print(grid)

from operator import itemgetter
from typing import TYPE_CHECKING, Callable, NamedTuple, Optional, Sequence

from . import errors
from .protocol import is_renderable, rich_cast

if TYPE_CHECKING:
    from .console import Console, ConsoleOptions, RenderableType


class Measurement(NamedTuple):
    

    minimum: int
    
    maximum: int
    

    @property
    def span(self) -> int:
        
        return self.maximum - self.minimum

    def normalize(self) -> ""Measurement"":
        
        minimum, maximum = self
        minimum = min(max(0, minimum), maximum)
        return Measurement(max(0, minimum), max(0, max(minimum, maximum)))

    def with_maximum(self, width: int) -> ""Measurement"":
        
        minimum, maximum = self
        return Measurement(min(minimum, width), min(maximum, width))

    def with_minimum(self, width: int) -> ""Measurement"":
        
        minimum, maximum = self
        width = max(0, width)
        return Measurement(max(minimum, width), max(maximum, width))

    def clamp(
        self, min_width: Optional[int] = None, max_width: Optional[int] = None
    ) -> ""Measurement"":
        
        measurement = self
        if min_width is not None:
            measurement = measurement.with_minimum(min_width)
        if max_width is not None:
            measurement = measurement.with_maximum(max_width)
        return measurement

    @classmethod
    def get(
        cls, console: ""Console"", options: ""ConsoleOptions"", renderable: ""RenderableType""
    ) -> ""Measurement"":
        
        _max_width = options.max_width
        if _max_width < 1:
            return Measurement(0, 0)
        if isinstance(renderable, str):
            renderable = console.render_str(
                renderable, markup=options.markup, highlight=False
            )
        renderable = rich_cast(renderable)
        if is_renderable(renderable):
            get_console_width: Optional[
                Callable[[""Console"", ""ConsoleOptions""], ""Measurement""]
            ] = getattr(renderable, ""__rich_measure__"", None)
            if get_console_width is not None:
                render_width = (
                    get_console_width(console, options)
                    .normalize()
                    .with_maximum(_max_width)
                )
                if render_width.maximum < 1:
                    return Measurement(0, 0)
                return render_width.normalize()
            else:
                return Measurement(0, _max_width)
        else:
            raise errors.NotRenderableError(
                f""Unable to get render width for {renderable!r}; ""
                ""a str, Segment, or object with __rich_console__ method is required""
            )


def measure_renderables(
    console: ""Console"",
    options: ""ConsoleOptions"",
    renderables: Sequence[""RenderableType""],
) -> ""Measurement"":
    
    if not renderables:
        return Measurement(0, 0)
    get_measurement = Measurement.get
    measurements = [
        get_measurement(console, options, renderable) for renderable in renderables
    ]
    measured_width = Measurement(
        max(measurements, key=itemgetter(0)).minimum,
        max(measurements, key=itemgetter(1)).maximum,
    )
    return measured_width

from typing import TYPE_CHECKING, List, Optional, Tuple, Union

if TYPE_CHECKING:
    from .console import (
        Console,
        ConsoleOptions,
        RenderableType,
        RenderResult,
    )

from .jupyter import JupyterMixin
from .measure import Measurement
from .segment import Segment
from .style import Style

PaddingDimensions = Union[int, Tuple[int], Tuple[int, int], Tuple[int, int, int, int]]


class Padding(JupyterMixin):
    

    def __init__(
        self,
        renderable: ""RenderableType"",
        pad: ""PaddingDimensions"" = (0, 0, 0, 0),
        *,
        style: Union[str, Style] = ""none"",
        expand: bool = True,
    ):
        self.renderable = renderable
        self.top, self.right, self.bottom, self.left = self.unpack(pad)
        self.style = style
        self.expand = expand

    @classmethod
    def indent(cls, renderable: ""RenderableType"", level: int) -> ""Padding"":
        

        return Padding(renderable, pad=(0, 0, 0, level), expand=False)

    @staticmethod
    def unpack(pad: ""PaddingDimensions"") -> Tuple[int, int, int, int]:
        
        if isinstance(pad, int):
            return (pad, pad, pad, pad)
        if len(pad) == 1:
            _pad = pad[0]
            return (_pad, _pad, _pad, _pad)
        if len(pad) == 2:
            pad_top, pad_right = pad
            return (pad_top, pad_right, pad_top, pad_right)
        if len(pad) == 4:
            top, right, bottom, left = pad
            return (top, right, bottom, left)
        raise ValueError(f""1, 2 or 4 integers required for padding; {len(pad)} given"")

    def __repr__(self) -> str:
        return f""Padding({self.renderable!r}, ({self.top},{self.right},{self.bottom},{self.left}))""

    def __rich_console__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> ""RenderResult"":
        style = console.get_style(self.style)
        if self.expand:
            width = options.max_width
        else:
            width = min(
                Measurement.get(console, options, self.renderable).maximum
                + self.left
                + self.right,
                options.max_width,
            )
        render_options = options.update_width(width - self.left - self.right)
        if render_options.height is not None:
            render_options = render_options.update_height(
                height=render_options.height - self.top - self.bottom
            )
        lines = console.render_lines(
            self.renderable, render_options, style=style, pad=True
        )
        _Segment = Segment

        left = _Segment("" "" * self.left, style) if self.left else None
        right = (
            [_Segment(f'{"" "" * self.right}', style), _Segment.line()]
            if self.right
            else [_Segment.line()]
        )
        blank_line: Optional[List[Segment]] = None
        if self.top:
            blank_line = [_Segment(f'{"" "" * width}\n', style)]
            yield from blank_line * self.top
        if left:
            for line in lines:
                yield left
                yield from line
                yield from right
        else:
            for line in lines:
                yield from line
                yield from right
        if self.bottom:
            blank_line = blank_line or [_Segment(f'{"" "" * width}\n', style)]
            yield from blank_line * self.bottom

    def __rich_measure__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> ""Measurement"":
        max_width = options.max_width
        extra_width = self.left + self.right
        if max_width - extra_width < 1:
            return Measurement(max_width, max_width)
        measure_min, measure_max = Measurement.get(console, options, self.renderable)
        measurement = Measurement(measure_min + extra_width, measure_max + extra_width)
        measurement = measurement.with_maximum(max_width)
        return measurement


if __name__ == ""__main__"":  
    from pip._vendor.rich import print

    print(Padding(""Hello, World"", (2, 4), style=""on blue""))

from abc import ABC, abstractmethod
from typing import Any


class Pager(ABC):
    

    @abstractmethod
    def show(self, content: str) -> None:
        


class SystemPager(Pager):
    

    def _pager(self, content: str) -> Any:  
        return __import__(""pydoc"").pager(content)

    def show(self, content: str) -> None:
        
        self._pager(content)


if __name__ == ""__main__"":  
    from .__main__ import make_test_card
    from .console import Console

    console = Console()
    with console.pager(styles=True):
        console.print(make_test_card())

from math import sqrt
from functools import lru_cache
from typing import Sequence, Tuple, TYPE_CHECKING

from .color_triplet import ColorTriplet

if TYPE_CHECKING:
    from pip._vendor.rich.table import Table


class Palette:
    

    def __init__(self, colors: Sequence[Tuple[int, int, int]]):
        self._colors = colors

    def __getitem__(self, number: int) -> ColorTriplet:
        return ColorTriplet(*self._colors[number])

    def __rich__(self) -> ""Table"":
        from pip._vendor.rich.color import Color
        from pip._vendor.rich.style import Style
        from pip._vendor.rich.text import Text
        from pip._vendor.rich.table import Table

        table = Table(
            ""index"",
            ""RGB"",
            ""Color"",
            title=""Palette"",
            caption=f""{len(self._colors)} colors"",
            highlight=True,
            caption_justify=""right"",
        )
        for index, color in enumerate(self._colors):
            table.add_row(
                str(index),
                repr(color),
                Text("" "" * 16, style=Style(bgcolor=Color.from_rgb(*color))),
            )
        return table

    
    @lru_cache(maxsize=1024)
    def match(self, color: Tuple[int, int, int]) -> int:
        
        red1, green1, blue1 = color
        _sqrt = sqrt
        get_color = self._colors.__getitem__

        def get_color_distance(index: int) -> float:
            
            red2, green2, blue2 = get_color(index)
            red_mean = (red1 + red2) // 2
            red = red1 - red2
            green = green1 - green2
            blue = blue1 - blue2
            return _sqrt(
                (((512 + red_mean) * red * red) >> 8)
                + 4 * green * green
                + (((767 - red_mean) * blue * blue) >> 8)
            )

        min_index = min(range(len(self._colors)), key=get_color_distance)
        return min_index


if __name__ == ""__main__"":  
    import colorsys
    from typing import Iterable
    from pip._vendor.rich.color import Color
    from pip._vendor.rich.console import Console, ConsoleOptions
    from pip._vendor.rich.segment import Segment
    from pip._vendor.rich.style import Style

    class ColorBox:
        def __rich_console__(
            self, console: Console, options: ConsoleOptions
        ) -> Iterable[Segment]:
            height = console.size.height - 3
            for y in range(0, height):
                for x in range(options.max_width):
                    h = x / options.max_width
                    l = y / (height + 1)
                    r1, g1, b1 = colorsys.hls_to_rgb(h, l, 1.0)
                    r2, g2, b2 = colorsys.hls_to_rgb(h, l + (1 / height / 2), 1.0)
                    bgcolor = Color.from_rgb(r1 * 255, g1 * 255, b1 * 255)
                    color = Color.from_rgb(r2 * 255, g2 * 255, b2 * 255)
                    yield Segment(""▄"", Style(color=color, bgcolor=bgcolor))
                yield Segment.line()

    console = Console()
    console.print(ColorBox())

from typing import TYPE_CHECKING, Optional

from .align import AlignMethod
from .box import ROUNDED, Box
from .cells import cell_len
from .jupyter import JupyterMixin
from .measure import Measurement, measure_renderables
from .padding import Padding, PaddingDimensions
from .segment import Segment
from .style import Style, StyleType
from .text import Text, TextType

if TYPE_CHECKING:
    from .console import Console, ConsoleOptions, RenderableType, RenderResult


class Panel(JupyterMixin):
    

    def __init__(
        self,
        renderable: ""RenderableType"",
        box: Box = ROUNDED,
        *,
        title: Optional[TextType] = None,
        title_align: AlignMethod = ""center"",
        subtitle: Optional[TextType] = None,
        subtitle_align: AlignMethod = ""center"",
        safe_box: Optional[bool] = None,
        expand: bool = True,
        style: StyleType = ""none"",
        border_style: StyleType = ""none"",
        width: Optional[int] = None,
        height: Optional[int] = None,
        padding: PaddingDimensions = (0, 1),
        highlight: bool = False,
    ) -> None:
        self.renderable = renderable
        self.box = box
        self.title = title
        self.title_align: AlignMethod = title_align
        self.subtitle = subtitle
        self.subtitle_align = subtitle_align
        self.safe_box = safe_box
        self.expand = expand
        self.style = style
        self.border_style = border_style
        self.width = width
        self.height = height
        self.padding = padding
        self.highlight = highlight

    @classmethod
    def fit(
        cls,
        renderable: ""RenderableType"",
        box: Box = ROUNDED,
        *,
        title: Optional[TextType] = None,
        title_align: AlignMethod = ""center"",
        subtitle: Optional[TextType] = None,
        subtitle_align: AlignMethod = ""center"",
        safe_box: Optional[bool] = None,
        style: StyleType = ""none"",
        border_style: StyleType = ""none"",
        width: Optional[int] = None,
        height: Optional[int] = None,
        padding: PaddingDimensions = (0, 1),
        highlight: bool = False,
    ) -> ""Panel"":
        
        return cls(
            renderable,
            box,
            title=title,
            title_align=title_align,
            subtitle=subtitle,
            subtitle_align=subtitle_align,
            safe_box=safe_box,
            style=style,
            border_style=border_style,
            width=width,
            height=height,
            padding=padding,
            highlight=highlight,
            expand=False,
        )

    @property
    def _title(self) -> Optional[Text]:
        if self.title:
            title_text = (
                Text.from_markup(self.title)
                if isinstance(self.title, str)
                else self.title.copy()
            )
            title_text.end = """"
            title_text.plain = title_text.plain.replace(""\n"", "" "")
            title_text.no_wrap = True
            title_text.expand_tabs()
            title_text.pad(1)
            return title_text
        return None

    @property
    def _subtitle(self) -> Optional[Text]:
        if self.subtitle:
            subtitle_text = (
                Text.from_markup(self.subtitle)
                if isinstance(self.subtitle, str)
                else self.subtitle.copy()
            )
            subtitle_text.end = """"
            subtitle_text.plain = subtitle_text.plain.replace(""\n"", "" "")
            subtitle_text.no_wrap = True
            subtitle_text.expand_tabs()
            subtitle_text.pad(1)
            return subtitle_text
        return None

    def __rich_console__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> ""RenderResult"":
        _padding = Padding.unpack(self.padding)
        renderable = (
            Padding(self.renderable, _padding) if any(_padding) else self.renderable
        )
        style = console.get_style(self.style)
        border_style = style + console.get_style(self.border_style)
        width = (
            options.max_width
            if self.width is None
            else min(options.max_width, self.width)
        )

        safe_box: bool = console.safe_box if self.safe_box is None else self.safe_box
        box = self.box.substitute(options, safe=safe_box)

        def align_text(
            text: Text, width: int, align: str, character: str, style: Style
        ) -> Text:
            
            text = text.copy()
            text.truncate(width)
            excess_space = width - cell_len(text.plain)
            if text.style:
                text.stylize(console.get_style(text.style))

            if excess_space:
                if align == ""left"":
                    return Text.assemble(
                        text,
                        (character * excess_space, style),
                        no_wrap=True,
                        end="""",
                    )
                elif align == ""center"":
                    left = excess_space // 2
                    return Text.assemble(
                        (character * left, style),
                        text,
                        (character * (excess_space - left), style),
                        no_wrap=True,
                        end="""",
                    )
                else:
                    return Text.assemble(
                        (character * excess_space, style),
                        text,
                        no_wrap=True,
                        end="""",
                    )
            return text

        title_text = self._title
        if title_text is not None:
            title_text.stylize_before(border_style)

        child_width = (
            width - 2
            if self.expand
            else console.measure(
                renderable, options=options.update_width(width - 2)
            ).maximum
        )
        child_height = self.height or options.height or None
        if child_height:
            child_height -= 2
        if title_text is not None:
            child_width = min(
                options.max_width - 2, max(child_width, title_text.cell_len + 2)
            )

        width = child_width + 2
        child_options = options.update(
            width=child_width, height=child_height, highlight=self.highlight
        )
        lines = console.render_lines(renderable, child_options, style=style)

        line_start = Segment(box.mid_left, border_style)
        line_end = Segment(f""{box.mid_right}"", border_style)
        new_line = Segment.line()
        if title_text is None or width <= 4:
            yield Segment(box.get_top([width - 2]), border_style)
        else:
            title_text = align_text(
                title_text,
                width - 4,
                self.title_align,
                box.top,
                border_style,
            )
            yield Segment(box.top_left + box.top, border_style)
            yield from console.render(title_text, child_options.update_width(width - 4))
            yield Segment(box.top + box.top_right, border_style)

        yield new_line
        for line in lines:
            yield line_start
            yield from line
            yield line_end
            yield new_line

        subtitle_text = self._subtitle
        if subtitle_text is not None:
            subtitle_text.stylize_before(border_style)

        if subtitle_text is None or width <= 4:
            yield Segment(box.get_bottom([width - 2]), border_style)
        else:
            subtitle_text = align_text(
                subtitle_text,
                width - 4,
                self.subtitle_align,
                box.bottom,
                border_style,
            )
            yield Segment(box.bottom_left + box.bottom, border_style)
            yield from console.render(
                subtitle_text, child_options.update_width(width - 4)
            )
            yield Segment(box.bottom + box.bottom_right, border_style)

        yield new_line

    def __rich_measure__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> ""Measurement"":
        _title = self._title
        _, right, _, left = Padding.unpack(self.padding)
        padding = left + right
        renderables = [self.renderable, _title] if _title else [self.renderable]

        if self.width is None:
            width = (
                measure_renderables(
                    console,
                    options.update_width(options.max_width - padding - 2),
                    renderables,
                ).maximum
                + padding
                + 2
            )
        else:
            width = self.width
        return Measurement(width, width)


if __name__ == ""__main__"":  
    from .console import Console

    c = Console()

    from .box import DOUBLE, ROUNDED
    from .padding import Padding

    p = Panel(
        ""Hello, World!"",
        title=""rich.Panel"",
        style=""white on blue"",
        box=DOUBLE,
        padding=1,
    )

    c.print()
    c.print(p)

import builtins
import collections
import dataclasses
import inspect
import os
import reprlib
import sys
from array import array
from collections import Counter, UserDict, UserList, defaultdict, deque
from dataclasses import dataclass, fields, is_dataclass
from inspect import isclass
from itertools import islice
from types import MappingProxyType
from typing import (
    TYPE_CHECKING,
    Any,
    Callable,
    DefaultDict,
    Deque,
    Dict,
    Iterable,
    List,
    Optional,
    Sequence,
    Set,
    Tuple,
    Union,
)

from pip._vendor.rich.repr import RichReprResult

try:
    import attr as _attr_module

    _has_attrs = hasattr(_attr_module, ""ib"")
except ImportError:  
    _has_attrs = False

from . import get_console
from ._loop import loop_last
from ._pick import pick_bool
from .abc import RichRenderable
from .cells import cell_len
from .highlighter import ReprHighlighter
from .jupyter import JupyterMixin, JupyterRenderable
from .measure import Measurement
from .text import Text

if TYPE_CHECKING:
    from .console import (
        Console,
        ConsoleOptions,
        HighlighterType,
        JustifyMethod,
        OverflowMethod,
        RenderResult,
    )


def _is_attr_object(obj: Any) -> bool:
    
    return _has_attrs and _attr_module.has(type(obj))


def _get_attr_fields(obj: Any) -> Sequence[""_attr_module.Attribute[Any]""]:
    
    return _attr_module.fields(type(obj)) if _has_attrs else []


def _is_dataclass_repr(obj: object) -> bool:
    
    
    
    try:
        return obj.__repr__.__code__.co_filename in (
            dataclasses.__file__,
            reprlib.__file__,
        )
    except Exception:  
        return False


_dummy_namedtuple = collections.namedtuple(""_dummy_namedtuple"", [])


def _has_default_namedtuple_repr(obj: object) -> bool:
    
    obj_file = None
    try:
        obj_file = inspect.getfile(obj.__repr__)
    except (OSError, TypeError):
        
        
        pass
    default_repr_file = inspect.getfile(_dummy_namedtuple.__repr__)
    return obj_file == default_repr_file


def _ipy_display_hook(
    value: Any,
    console: Optional[""Console""] = None,
    overflow: ""OverflowMethod"" = ""ignore"",
    crop: bool = False,
    indent_guides: bool = False,
    max_length: Optional[int] = None,
    max_string: Optional[int] = None,
    max_depth: Optional[int] = None,
    expand_all: bool = False,
) -> Union[str, None]:
    
    from .console import ConsoleRenderable

    
    if _safe_isinstance(value, JupyterRenderable) or value is None:
        return None

    console = console or get_console()

    with console.capture() as capture:
        
        if _safe_isinstance(value, ConsoleRenderable):
            console.line()
        console.print(
            (
                value
                if _safe_isinstance(value, RichRenderable)
                else Pretty(
                    value,
                    overflow=overflow,
                    indent_guides=indent_guides,
                    max_length=max_length,
                    max_string=max_string,
                    max_depth=max_depth,
                    expand_all=expand_all,
                    margin=12,
                )
            ),
            crop=crop,
            new_line_start=True,
            end="""",
        )
    
    
    return capture.get().rstrip(""\n"")


def _safe_isinstance(
    obj: object, class_or_tuple: Union[type, Tuple[type, ...]]
) -> bool:
    
    try:
        return isinstance(obj, class_or_tuple)
    except Exception:
        return False


def install(
    console: Optional[""Console""] = None,
    overflow: ""OverflowMethod"" = ""ignore"",
    crop: bool = False,
    indent_guides: bool = False,
    max_length: Optional[int] = None,
    max_string: Optional[int] = None,
    max_depth: Optional[int] = None,
    expand_all: bool = False,
) -> None:
    
    from pip._vendor.rich import get_console

    console = console or get_console()
    assert console is not None

    def display_hook(value: Any) -> None:
        
        if value is not None:
            assert console is not None
            builtins._ = None  
            console.print(
                (
                    value
                    if _safe_isinstance(value, RichRenderable)
                    else Pretty(
                        value,
                        overflow=overflow,
                        indent_guides=indent_guides,
                        max_length=max_length,
                        max_string=max_string,
                        max_depth=max_depth,
                        expand_all=expand_all,
                    )
                ),
                crop=crop,
            )
            builtins._ = value  

    try:
        ip = get_ipython()  
    except NameError:
        sys.displayhook = display_hook
    else:
        from IPython.core.formatters import BaseFormatter

        class RichFormatter(BaseFormatter):  
            pprint: bool = True

            def __call__(self, value: Any) -> Any:
                if self.pprint:
                    return _ipy_display_hook(
                        value,
                        console=get_console(),
                        overflow=overflow,
                        indent_guides=indent_guides,
                        max_length=max_length,
                        max_string=max_string,
                        max_depth=max_depth,
                        expand_all=expand_all,
                    )
                else:
                    return repr(value)

        
        rich_formatter = RichFormatter()
        ip.display_formatter.formatters[""text/plain""] = rich_formatter


class Pretty(JupyterMixin):
    

    def __init__(
        self,
        _object: Any,
        highlighter: Optional[""HighlighterType""] = None,
        *,
        indent_size: int = 4,
        justify: Optional[""JustifyMethod""] = None,
        overflow: Optional[""OverflowMethod""] = None,
        no_wrap: Optional[bool] = False,
        indent_guides: bool = False,
        max_length: Optional[int] = None,
        max_string: Optional[int] = None,
        max_depth: Optional[int] = None,
        expand_all: bool = False,
        margin: int = 0,
        insert_line: bool = False,
    ) -> None:
        self._object = _object
        self.highlighter = highlighter or ReprHighlighter()
        self.indent_size = indent_size
        self.justify: Optional[""JustifyMethod""] = justify
        self.overflow: Optional[""OverflowMethod""] = overflow
        self.no_wrap = no_wrap
        self.indent_guides = indent_guides
        self.max_length = max_length
        self.max_string = max_string
        self.max_depth = max_depth
        self.expand_all = expand_all
        self.margin = margin
        self.insert_line = insert_line

    def __rich_console__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> ""RenderResult"":
        pretty_str = pretty_repr(
            self._object,
            max_width=options.max_width - self.margin,
            indent_size=self.indent_size,
            max_length=self.max_length,
            max_string=self.max_string,
            max_depth=self.max_depth,
            expand_all=self.expand_all,
        )
        pretty_text = Text.from_ansi(
            pretty_str,
            justify=self.justify or options.justify,
            overflow=self.overflow or options.overflow,
            no_wrap=pick_bool(self.no_wrap, options.no_wrap),
            style=""pretty"",
        )
        pretty_text = (
            self.highlighter(pretty_text)
            if pretty_text
            else Text(
                f""{type(self._object)}.__repr__ returned empty string"",
                style=""dim italic"",
            )
        )
        if self.indent_guides and not options.ascii_only:
            pretty_text = pretty_text.with_indent_guides(
                self.indent_size, style=""repr.indent""
            )
        if self.insert_line and ""\n"" in pretty_text:
            yield """"
        yield pretty_text

    def __rich_measure__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> ""Measurement"":
        pretty_str = pretty_repr(
            self._object,
            max_width=options.max_width,
            indent_size=self.indent_size,
            max_length=self.max_length,
            max_string=self.max_string,
            max_depth=self.max_depth,
            expand_all=self.expand_all,
        )
        text_width = (
            max(cell_len(line) for line in pretty_str.splitlines()) if pretty_str else 0
        )
        return Measurement(text_width, text_width)


def _get_braces_for_defaultdict(_object: DefaultDict[Any, Any]) -> Tuple[str, str, str]:
    return (
        f""defaultdict({_object.default_factory!r}, {{"",
        ""})"",
        f""defaultdict({_object.default_factory!r}, {{}})"",
    )


def _get_braces_for_deque(_object: Deque[Any]) -> Tuple[str, str, str]:
    if _object.maxlen is None:
        return (""deque(["", ""])"", ""deque()"")
    return (
        ""deque(["",
        f""], maxlen={_object.maxlen})"",
        f""deque(maxlen={_object.maxlen})"",
    )


def _get_braces_for_array(_object: ""array[Any]"") -> Tuple[str, str, str]:
    return (f""array({_object.typecode!r}, ["", ""])"", f""array({_object.typecode!r})"")


_BRACES: Dict[type, Callable[[Any], Tuple[str, str, str]]] = {
    os._Environ: lambda _object: (""environ({"", ""})"", ""environ({})""),
    array: _get_braces_for_array,
    defaultdict: _get_braces_for_defaultdict,
    Counter: lambda _object: (""Counter({"", ""})"", ""Counter()""),
    deque: _get_braces_for_deque,
    dict: lambda _object: (""{"", ""}"", ""{}""),
    UserDict: lambda _object: (""{"", ""}"", ""{}""),
    frozenset: lambda _object: (""frozenset({"", ""})"", ""frozenset()""),
    list: lambda _object: (""["", ""]"", ""[]""),
    UserList: lambda _object: (""["", ""]"", ""[]""),
    set: lambda _object: (""{"", ""}"", ""set()""),
    tuple: lambda _object: (""("", "")"", ""()""),
    MappingProxyType: lambda _object: (""mappingproxy({"", ""})"", ""mappingproxy({})""),
}
_CONTAINERS = tuple(_BRACES.keys())
_MAPPING_CONTAINERS = (dict, os._Environ, MappingProxyType, UserDict)


def is_expandable(obj: Any) -> bool:
    
    return (
        _safe_isinstance(obj, _CONTAINERS)
        or (is_dataclass(obj))
        or (hasattr(obj, ""__rich_repr__""))
        or _is_attr_object(obj)
    ) and not isclass(obj)


@dataclass
class Node:
    

    key_repr: str = """"
    value_repr: str = """"
    open_brace: str = """"
    close_brace: str = """"
    empty: str = """"
    last: bool = False
    is_tuple: bool = False
    is_namedtuple: bool = False
    children: Optional[List[""Node""]] = None
    key_separator: str = "": ""
    separator: str = "", ""

    def iter_tokens(self) -> Iterable[str]:
        
        if self.key_repr:
            yield self.key_repr
            yield self.key_separator
        if self.value_repr:
            yield self.value_repr
        elif self.children is not None:
            if self.children:
                yield self.open_brace
                if self.is_tuple and not self.is_namedtuple and len(self.children) == 1:
                    yield from self.children[0].iter_tokens()
                    yield "",""
                else:
                    for child in self.children:
                        yield from child.iter_tokens()
                        if not child.last:
                            yield self.separator
                yield self.close_brace
            else:
                yield self.empty

    def check_length(self, start_length: int, max_length: int) -> bool:
        
        total_length = start_length
        for token in self.iter_tokens():
            total_length += cell_len(token)
            if total_length > max_length:
                return False
        return True

    def __str__(self) -> str:
        repr_text = """".join(self.iter_tokens())
        return repr_text

    def render(
        self, max_width: int = 80, indent_size: int = 4, expand_all: bool = False
    ) -> str:
        
        lines = [_Line(node=self, is_root=True)]
        line_no = 0
        while line_no < len(lines):
            line = lines[line_no]
            if line.expandable and not line.expanded:
                if expand_all or not line.check_length(max_width):
                    lines[line_no : line_no + 1] = line.expand(indent_size)
            line_no += 1

        repr_str = ""\n"".join(str(line) for line in lines)
        return repr_str


@dataclass
class _Line:
    

    parent: Optional[""_Line""] = None
    is_root: bool = False
    node: Optional[Node] = None
    text: str = """"
    suffix: str = """"
    whitespace: str = """"
    expanded: bool = False
    last: bool = False

    @property
    def expandable(self) -> bool:
        
        return bool(self.node is not None and self.node.children)

    def check_length(self, max_length: int) -> bool:
        
        start_length = (
            len(self.whitespace) + cell_len(self.text) + cell_len(self.suffix)
        )
        assert self.node is not None
        return self.node.check_length(start_length, max_length)

    def expand(self, indent_size: int) -> Iterable[""_Line""]:
        
        node = self.node
        assert node is not None
        whitespace = self.whitespace
        assert node.children
        if node.key_repr:
            new_line = yield _Line(
                text=f""{node.key_repr}{node.key_separator}{node.open_brace}"",
                whitespace=whitespace,
            )
        else:
            new_line = yield _Line(text=node.open_brace, whitespace=whitespace)
        child_whitespace = self.whitespace + "" "" * indent_size
        tuple_of_one = node.is_tuple and len(node.children) == 1
        for last, child in loop_last(node.children):
            separator = "","" if tuple_of_one else node.separator
            line = _Line(
                parent=new_line,
                node=child,
                whitespace=child_whitespace,
                suffix=separator,
                last=last and not tuple_of_one,
            )
            yield line

        yield _Line(
            text=node.close_brace,
            whitespace=whitespace,
            suffix=self.suffix,
            last=self.last,
        )

    def __str__(self) -> str:
        if self.last:
            return f""{self.whitespace}{self.text}{self.node or ''}""
        else:
            return (
                f""{self.whitespace}{self.text}{self.node or ''}{self.suffix.rstrip()}""
            )


def _is_namedtuple(obj: Any) -> bool:
    
    try:
        fields = getattr(obj, ""_fields"", None)
    except Exception:
        
        return False
    return isinstance(obj, tuple) and isinstance(fields, tuple)


def traverse(
    _object: Any,
    max_length: Optional[int] = None,
    max_string: Optional[int] = None,
    max_depth: Optional[int] = None,
) -> Node:
    

    def to_repr(obj: Any) -> str:
        
        if (
            max_string is not None
            and _safe_isinstance(obj, (bytes, str))
            and len(obj) > max_string
        ):
            truncated = len(obj) - max_string
            obj_repr = f""{obj[:max_string]!r}+{truncated}""
        else:
            try:
                obj_repr = repr(obj)
            except Exception as error:
                obj_repr = f""<repr-error {str(error)!r}>""
        return obj_repr

    visited_ids: Set[int] = set()
    push_visited = visited_ids.add
    pop_visited = visited_ids.remove

    def _traverse(obj: Any, root: bool = False, depth: int = 0) -> Node:
        

        obj_id = id(obj)
        if obj_id in visited_ids:
            
            return Node(value_repr=""..."")

        obj_type = type(obj)
        children: List[Node]
        reached_max_depth = max_depth is not None and depth >= max_depth

        def iter_rich_args(rich_args: Any) -> Iterable[Union[Any, Tuple[str, Any]]]:
            for arg in rich_args:
                if _safe_isinstance(arg, tuple):
                    if len(arg) == 3:
                        key, child, default = arg
                        if default == child:
                            continue
                        yield key, child
                    elif len(arg) == 2:
                        key, child = arg
                        yield key, child
                    elif len(arg) == 1:
                        yield arg[0]
                else:
                    yield arg

        try:
            fake_attributes = hasattr(
                obj, ""awehoi234_wdfjwljet234_234wdfoijsdfmmnxpi492""
            )
        except Exception:
            fake_attributes = False

        rich_repr_result: Optional[RichReprResult] = None
        if not fake_attributes:
            try:
                if hasattr(obj, ""__rich_repr__"") and not isclass(obj):
                    rich_repr_result = obj.__rich_repr__()
            except Exception:
                pass

        if rich_repr_result is not None:
            push_visited(obj_id)
            angular = getattr(obj.__rich_repr__, ""angular"", False)
            args = list(iter_rich_args(rich_repr_result))
            class_name = obj.__class__.__name__

            if args:
                children = []
                append = children.append

                if reached_max_depth:
                    if angular:
                        node = Node(value_repr=f""<{class_name}...>"")
                    else:
                        node = Node(value_repr=f""{class_name}(...)"")
                else:
                    if angular:
                        node = Node(
                            open_brace=f""<{class_name} "",
                            close_brace="">"",
                            children=children,
                            last=root,
                            separator="" "",
                        )
                    else:
                        node = Node(
                            open_brace=f""{class_name}("",
                            close_brace="")"",
                            children=children,
                            last=root,
                        )
                    for last, arg in loop_last(args):
                        if _safe_isinstance(arg, tuple):
                            key, child = arg
                            child_node = _traverse(child, depth=depth + 1)
                            child_node.last = last
                            child_node.key_repr = key
                            child_node.key_separator = ""=""
                            append(child_node)
                        else:
                            child_node = _traverse(arg, depth=depth + 1)
                            child_node.last = last
                            append(child_node)
            else:
                node = Node(
                    value_repr=f""<{class_name}>"" if angular else f""{class_name}()"",
                    children=[],
                    last=root,
                )
            pop_visited(obj_id)
        elif _is_attr_object(obj) and not fake_attributes:
            push_visited(obj_id)
            children = []
            append = children.append

            attr_fields = _get_attr_fields(obj)
            if attr_fields:
                if reached_max_depth:
                    node = Node(value_repr=f""{obj.__class__.__name__}(...)"")
                else:
                    node = Node(
                        open_brace=f""{obj.__class__.__name__}("",
                        close_brace="")"",
                        children=children,
                        last=root,
                    )

                    def iter_attrs() -> (
                        Iterable[Tuple[str, Any, Optional[Callable[[Any], str]]]]
                    ):
                        
                        for attr in attr_fields:
                            if attr.repr:
                                try:
                                    value = getattr(obj, attr.name)
                                except Exception as error:
                                    
                                    yield (attr.name, error, None)
                                else:
                                    yield (
                                        attr.name,
                                        value,
                                        attr.repr if callable(attr.repr) else None,
                                    )

                    for last, (name, value, repr_callable) in loop_last(iter_attrs()):
                        if repr_callable:
                            child_node = Node(value_repr=str(repr_callable(value)))
                        else:
                            child_node = _traverse(value, depth=depth + 1)
                        child_node.last = last
                        child_node.key_repr = name
                        child_node.key_separator = ""=""
                        append(child_node)
            else:
                node = Node(
                    value_repr=f""{obj.__class__.__name__}()"", children=[], last=root
                )
            pop_visited(obj_id)
        elif (
            is_dataclass(obj)
            and not _safe_isinstance(obj, type)
            and not fake_attributes
            and _is_dataclass_repr(obj)
        ):
            push_visited(obj_id)
            children = []
            append = children.append
            if reached_max_depth:
                node = Node(value_repr=f""{obj.__class__.__name__}(...)"")
            else:
                node = Node(
                    open_brace=f""{obj.__class__.__name__}("",
                    close_brace="")"",
                    children=children,
                    last=root,
                    empty=f""{obj.__class__.__name__}()"",
                )

                for last, field in loop_last(
                    field
                    for field in fields(obj)
                    if field.repr and hasattr(obj, field.name)
                ):
                    child_node = _traverse(getattr(obj, field.name), depth=depth + 1)
                    child_node.key_repr = field.name
                    child_node.last = last
                    child_node.key_separator = ""=""
                    append(child_node)

            pop_visited(obj_id)
        elif _is_namedtuple(obj) and _has_default_namedtuple_repr(obj):
            push_visited(obj_id)
            class_name = obj.__class__.__name__
            if reached_max_depth:
                
                node = Node(
                    value_repr=f""{class_name}(...)"",
                )
            else:
                children = []
                append = children.append
                node = Node(
                    open_brace=f""{class_name}("",
                    close_brace="")"",
                    children=children,
                    empty=f""{class_name}()"",
                )
                for last, (key, value) in loop_last(obj._asdict().items()):
                    child_node = _traverse(value, depth=depth + 1)
                    child_node.key_repr = key
                    child_node.last = last
                    child_node.key_separator = ""=""
                    append(child_node)
            pop_visited(obj_id)
        elif _safe_isinstance(obj, _CONTAINERS):
            for container_type in _CONTAINERS:
                if _safe_isinstance(obj, container_type):
                    obj_type = container_type
                    break

            push_visited(obj_id)

            open_brace, close_brace, empty = _BRACES[obj_type](obj)

            if reached_max_depth:
                node = Node(value_repr=f""{open_brace}...{close_brace}"")
            elif obj_type.__repr__ != type(obj).__repr__:
                node = Node(value_repr=to_repr(obj), last=root)
            elif obj:
                children = []
                node = Node(
                    open_brace=open_brace,
                    close_brace=close_brace,
                    children=children,
                    last=root,
                )
                append = children.append
                num_items = len(obj)
                last_item_index = num_items - 1

                if _safe_isinstance(obj, _MAPPING_CONTAINERS):
                    iter_items = iter(obj.items())
                    if max_length is not None:
                        iter_items = islice(iter_items, max_length)
                    for index, (key, child) in enumerate(iter_items):
                        child_node = _traverse(child, depth=depth + 1)
                        child_node.key_repr = to_repr(key)
                        child_node.last = index == last_item_index
                        append(child_node)
                else:
                    iter_values = iter(obj)
                    if max_length is not None:
                        iter_values = islice(iter_values, max_length)
                    for index, child in enumerate(iter_values):
                        child_node = _traverse(child, depth=depth + 1)
                        child_node.last = index == last_item_index
                        append(child_node)
                if max_length is not None and num_items > max_length:
                    append(Node(value_repr=f""... +{num_items - max_length}"", last=True))
            else:
                node = Node(empty=empty, children=[], last=root)

            pop_visited(obj_id)
        else:
            node = Node(value_repr=to_repr(obj), last=root)
        node.is_tuple = type(obj) == tuple
        node.is_namedtuple = _is_namedtuple(obj)
        return node

    node = _traverse(_object, root=True)
    return node


def pretty_repr(
    _object: Any,
    *,
    max_width: int = 80,
    indent_size: int = 4,
    max_length: Optional[int] = None,
    max_string: Optional[int] = None,
    max_depth: Optional[int] = None,
    expand_all: bool = False,
) -> str:
    

    if _safe_isinstance(_object, Node):
        node = _object
    else:
        node = traverse(
            _object, max_length=max_length, max_string=max_string, max_depth=max_depth
        )
    repr_str: str = node.render(
        max_width=max_width, indent_size=indent_size, expand_all=expand_all
    )
    return repr_str


def pprint(
    _object: Any,
    *,
    console: Optional[""Console""] = None,
    indent_guides: bool = True,
    max_length: Optional[int] = None,
    max_string: Optional[int] = None,
    max_depth: Optional[int] = None,
    expand_all: bool = False,
) -> None:
    
    _console = get_console() if console is None else console
    _console.print(
        Pretty(
            _object,
            max_length=max_length,
            max_string=max_string,
            max_depth=max_depth,
            indent_guides=indent_guides,
            expand_all=expand_all,
            overflow=""ignore"",
        ),
        soft_wrap=True,
    )


if __name__ == ""__main__"":  

    class BrokenRepr:
        def __repr__(self) -> str:
            1 / 0
            return ""this will fail""

    from typing import NamedTuple

    class StockKeepingUnit(NamedTuple):
        name: str
        description: str
        price: float
        category: str
        reviews: List[str]

    d = defaultdict(int)
    d[""foo""] = 5
    data = {
        ""foo"": [
            1,
            ""Hello World!"",
            100.123,
            323.232,
            432324.0,
            {5, 6, 7, (1, 2, 3, 4), 8},
        ],
        ""bar"": frozenset({1, 2, 3}),
        ""defaultdict"": defaultdict(
            list, {""crumble"": [""apple"", ""rhubarb"", ""butter"", ""sugar"", ""flour""]}
        ),
        ""counter"": Counter(
            [
                ""apple"",
                ""orange"",
                ""pear"",
                ""kumquat"",
                ""kumquat"",
                ""durian"" * 100,
            ]
        ),
        ""atomic"": (False, True, None),
        ""namedtuple"": StockKeepingUnit(
            ""Sparkling British Spring Water"",
            ""Carbonated spring water"",
            0.9,
            ""water"",
            [""its amazing!"", ""its terrible!""],
        ),
        ""Broken"": BrokenRepr(),
    }
    data[""foo""].append(data)  

    from pip._vendor.rich import print

    print(Pretty(data, indent_guides=True, max_string=20))

    class Thing:
        def __repr__(self) -> str:
            return ""Hello\x1b[38;5;239m World!""

    print(Pretty(Thing()))

from __future__ import annotations

import io
import typing
import warnings
from abc import ABC, abstractmethod
from collections import deque
from dataclasses import dataclass, field
from datetime import timedelta
from io import RawIOBase, UnsupportedOperation
from math import ceil
from mmap import mmap
from operator import length_hint
from os import PathLike, stat
from threading import Event, RLock, Thread
from types import TracebackType
from typing import (
    TYPE_CHECKING,
    Any,
    BinaryIO,
    Callable,
    ContextManager,
    Deque,
    Dict,
    Generic,
    Iterable,
    List,
    Literal,
    NamedTuple,
    NewType,
    Optional,
    TextIO,
    Tuple,
    Type,
    TypeVar,
    Union,
)

if TYPE_CHECKING:
    
    from typing_extensions import Self  

from . import filesize, get_console
from .console import Console, Group, JustifyMethod, RenderableType
from .highlighter import Highlighter
from .jupyter import JupyterMixin
from .live import Live
from .progress_bar import ProgressBar
from .spinner import Spinner
from .style import StyleType
from .table import Column, Table
from .text import Text, TextType

TaskID = NewType(""TaskID"", int)

ProgressType = TypeVar(""ProgressType"")

GetTimeCallable = Callable[[], float]


_I = typing.TypeVar(""_I"", TextIO, BinaryIO)


class _TrackThread(Thread):
    

    def __init__(self, progress: ""Progress"", task_id: ""TaskID"", update_period: float):
        self.progress = progress
        self.task_id = task_id
        self.update_period = update_period
        self.done = Event()

        self.completed = 0
        super().__init__(daemon=True)

    def run(self) -> None:
        task_id = self.task_id
        advance = self.progress.advance
        update_period = self.update_period
        last_completed = 0
        wait = self.done.wait
        while not wait(update_period) and self.progress.live.is_started:
            completed = self.completed
            if last_completed != completed:
                advance(task_id, completed - last_completed)
                last_completed = completed

        self.progress.update(self.task_id, completed=self.completed, refresh=True)

    def __enter__(self) -> ""_TrackThread"":
        self.start()
        return self

    def __exit__(
        self,
        exc_type: Optional[Type[BaseException]],
        exc_val: Optional[BaseException],
        exc_tb: Optional[TracebackType],
    ) -> None:
        self.done.set()
        self.join()


def track(
    sequence: Iterable[ProgressType],
    description: str = ""Working..."",
    total: Optional[float] = None,
    completed: int = 0,
    auto_refresh: bool = True,
    console: Optional[Console] = None,
    transient: bool = False,
    get_time: Optional[Callable[[], float]] = None,
    refresh_per_second: float = 10,
    style: StyleType = ""bar.back"",
    complete_style: StyleType = ""bar.complete"",
    finished_style: StyleType = ""bar.finished"",
    pulse_style: StyleType = ""bar.pulse"",
    update_period: float = 0.1,
    disable: bool = False,
    show_speed: bool = True,
) -> Iterable[ProgressType]:
    

    columns: List[""ProgressColumn""] = (
        [TextColumn(""[progress.description]{task.description}"")] if description else []
    )
    columns.extend(
        (
            BarColumn(
                style=style,
                complete_style=complete_style,
                finished_style=finished_style,
                pulse_style=pulse_style,
            ),
            TaskProgressColumn(show_speed=show_speed),
            TimeRemainingColumn(elapsed_when_finished=True),
        )
    )
    progress = Progress(
        *columns,
        auto_refresh=auto_refresh,
        console=console,
        transient=transient,
        get_time=get_time,
        refresh_per_second=refresh_per_second or 10,
        disable=disable,
    )

    with progress:
        yield from progress.track(
            sequence,
            total=total,
            completed=completed,
            description=description,
            update_period=update_period,
        )


class _Reader(RawIOBase, BinaryIO):
    

    def __init__(
        self,
        handle: BinaryIO,
        progress: ""Progress"",
        task: TaskID,
        close_handle: bool = True,
    ) -> None:
        self.handle = handle
        self.progress = progress
        self.task = task
        self.close_handle = close_handle
        self._closed = False

    def __enter__(self) -> ""_Reader"":
        self.handle.__enter__()
        return self

    def __exit__(
        self,
        exc_type: Optional[Type[BaseException]],
        exc_val: Optional[BaseException],
        exc_tb: Optional[TracebackType],
    ) -> None:
        self.close()

    def __iter__(self) -> BinaryIO:
        return self

    def __next__(self) -> bytes:
        line = next(self.handle)
        self.progress.advance(self.task, advance=len(line))
        return line

    @property
    def closed(self) -> bool:
        return self._closed

    def fileno(self) -> int:
        return self.handle.fileno()

    def isatty(self) -> bool:
        return self.handle.isatty()

    @property
    def mode(self) -> str:
        return self.handle.mode

    @property
    def name(self) -> str:
        return self.handle.name

    def readable(self) -> bool:
        return self.handle.readable()

    def seekable(self) -> bool:
        return self.handle.seekable()

    def writable(self) -> bool:
        return False

    def read(self, size: int = -1) -> bytes:
        block = self.handle.read(size)
        self.progress.advance(self.task, advance=len(block))
        return block

    def readinto(self, b: Union[bytearray, memoryview, mmap]):  
        n = self.handle.readinto(b)  
        self.progress.advance(self.task, advance=n)
        return n

    def readline(self, size: int = -1) -> bytes:  
        line = self.handle.readline(size)
        self.progress.advance(self.task, advance=len(line))
        return line

    def readlines(self, hint: int = -1) -> List[bytes]:
        lines = self.handle.readlines(hint)
        self.progress.advance(self.task, advance=sum(map(len, lines)))
        return lines

    def close(self) -> None:
        if self.close_handle:
            self.handle.close()
        self._closed = True

    def seek(self, offset: int, whence: int = 0) -> int:
        pos = self.handle.seek(offset, whence)
        self.progress.update(self.task, completed=pos)
        return pos

    def tell(self) -> int:
        return self.handle.tell()

    def write(self, s: Any) -> int:
        raise UnsupportedOperation(""write"")

    def writelines(self, lines: Iterable[Any]) -> None:
        raise UnsupportedOperation(""writelines"")


class _ReadContext(ContextManager[_I], Generic[_I]):
    

    def __init__(self, progress: ""Progress"", reader: _I) -> None:
        self.progress = progress
        self.reader: _I = reader

    def __enter__(self) -> _I:
        self.progress.start()
        return self.reader.__enter__()

    def __exit__(
        self,
        exc_type: Optional[Type[BaseException]],
        exc_val: Optional[BaseException],
        exc_tb: Optional[TracebackType],
    ) -> None:
        self.progress.stop()
        self.reader.__exit__(exc_type, exc_val, exc_tb)


def wrap_file(
    file: BinaryIO,
    total: int,
    *,
    description: str = ""Reading..."",
    auto_refresh: bool = True,
    console: Optional[Console] = None,
    transient: bool = False,
    get_time: Optional[Callable[[], float]] = None,
    refresh_per_second: float = 10,
    style: StyleType = ""bar.back"",
    complete_style: StyleType = ""bar.complete"",
    finished_style: StyleType = ""bar.finished"",
    pulse_style: StyleType = ""bar.pulse"",
    disable: bool = False,
) -> ContextManager[BinaryIO]:
    

    columns: List[""ProgressColumn""] = (
        [TextColumn(""[progress.description]{task.description}"")] if description else []
    )
    columns.extend(
        (
            BarColumn(
                style=style,
                complete_style=complete_style,
                finished_style=finished_style,
                pulse_style=pulse_style,
            ),
            DownloadColumn(),
            TimeRemainingColumn(),
        )
    )
    progress = Progress(
        *columns,
        auto_refresh=auto_refresh,
        console=console,
        transient=transient,
        get_time=get_time,
        refresh_per_second=refresh_per_second or 10,
        disable=disable,
    )

    reader = progress.wrap_file(file, total=total, description=description)
    return _ReadContext(progress, reader)


@typing.overload
def open(
    file: Union[str, ""PathLike[str]"", bytes],
    mode: Union[Literal[""rt""], Literal[""r""]],
    buffering: int = -1,
    encoding: Optional[str] = None,
    errors: Optional[str] = None,
    newline: Optional[str] = None,
    *,
    total: Optional[int] = None,
    description: str = ""Reading..."",
    auto_refresh: bool = True,
    console: Optional[Console] = None,
    transient: bool = False,
    get_time: Optional[Callable[[], float]] = None,
    refresh_per_second: float = 10,
    style: StyleType = ""bar.back"",
    complete_style: StyleType = ""bar.complete"",
    finished_style: StyleType = ""bar.finished"",
    pulse_style: StyleType = ""bar.pulse"",
    disable: bool = False,
) -> ContextManager[TextIO]:
    pass


@typing.overload
def open(
    file: Union[str, ""PathLike[str]"", bytes],
    mode: Literal[""rb""],
    buffering: int = -1,
    encoding: Optional[str] = None,
    errors: Optional[str] = None,
    newline: Optional[str] = None,
    *,
    total: Optional[int] = None,
    description: str = ""Reading..."",
    auto_refresh: bool = True,
    console: Optional[Console] = None,
    transient: bool = False,
    get_time: Optional[Callable[[], float]] = None,
    refresh_per_second: float = 10,
    style: StyleType = ""bar.back"",
    complete_style: StyleType = ""bar.complete"",
    finished_style: StyleType = ""bar.finished"",
    pulse_style: StyleType = ""bar.pulse"",
    disable: bool = False,
) -> ContextManager[BinaryIO]:
    pass


def open(
    file: Union[str, ""PathLike[str]"", bytes],
    mode: Union[Literal[""rb""], Literal[""rt""], Literal[""r""]] = ""r"",
    buffering: int = -1,
    encoding: Optional[str] = None,
    errors: Optional[str] = None,
    newline: Optional[str] = None,
    *,
    total: Optional[int] = None,
    description: str = ""Reading..."",
    auto_refresh: bool = True,
    console: Optional[Console] = None,
    transient: bool = False,
    get_time: Optional[Callable[[], float]] = None,
    refresh_per_second: float = 10,
    style: StyleType = ""bar.back"",
    complete_style: StyleType = ""bar.complete"",
    finished_style: StyleType = ""bar.finished"",
    pulse_style: StyleType = ""bar.pulse"",
    disable: bool = False,
) -> Union[ContextManager[BinaryIO], ContextManager[TextIO]]:
    

    columns: List[""ProgressColumn""] = (
        [TextColumn(""[progress.description]{task.description}"")] if description else []
    )
    columns.extend(
        (
            BarColumn(
                style=style,
                complete_style=complete_style,
                finished_style=finished_style,
                pulse_style=pulse_style,
            ),
            DownloadColumn(),
            TimeRemainingColumn(),
        )
    )
    progress = Progress(
        *columns,
        auto_refresh=auto_refresh,
        console=console,
        transient=transient,
        get_time=get_time,
        refresh_per_second=refresh_per_second or 10,
        disable=disable,
    )

    reader = progress.open(
        file,
        mode=mode,
        buffering=buffering,
        encoding=encoding,
        errors=errors,
        newline=newline,
        total=total,
        description=description,
    )
    return _ReadContext(progress, reader)  


class ProgressColumn(ABC):
    

    max_refresh: Optional[float] = None

    def __init__(self, table_column: Optional[Column] = None) -> None:
        self._table_column = table_column
        self._renderable_cache: Dict[TaskID, Tuple[float, RenderableType]] = {}
        self._update_time: Optional[float] = None

    def get_table_column(self) -> Column:
        
        return self._table_column or Column()

    def __call__(self, task: ""Task"") -> RenderableType:
        
        current_time = task.get_time()
        if self.max_refresh is not None and not task.completed:
            try:
                timestamp, renderable = self._renderable_cache[task.id]
            except KeyError:
                pass
            else:
                if timestamp + self.max_refresh > current_time:
                    return renderable

        renderable = self.render(task)
        self._renderable_cache[task.id] = (current_time, renderable)
        return renderable

    @abstractmethod
    def render(self, task: ""Task"") -> RenderableType:
        


class RenderableColumn(ProgressColumn):
    

    def __init__(
        self, renderable: RenderableType = """", *, table_column: Optional[Column] = None
    ):
        self.renderable = renderable
        super().__init__(table_column=table_column)

    def render(self, task: ""Task"") -> RenderableType:
        return self.renderable


class SpinnerColumn(ProgressColumn):
    

    def __init__(
        self,
        spinner_name: str = ""dots"",
        style: Optional[StyleType] = ""progress.spinner"",
        speed: float = 1.0,
        finished_text: TextType = "" "",
        table_column: Optional[Column] = None,
    ):
        self.spinner = Spinner(spinner_name, style=style, speed=speed)
        self.finished_text = (
            Text.from_markup(finished_text)
            if isinstance(finished_text, str)
            else finished_text
        )
        super().__init__(table_column=table_column)

    def set_spinner(
        self,
        spinner_name: str,
        spinner_style: Optional[StyleType] = ""progress.spinner"",
        speed: float = 1.0,
    ) -> None:
        
        self.spinner = Spinner(spinner_name, style=spinner_style, speed=speed)

    def render(self, task: ""Task"") -> RenderableType:
        text = (
            self.finished_text
            if task.finished
            else self.spinner.render(task.get_time())
        )
        return text


class TextColumn(ProgressColumn):
    

    def __init__(
        self,
        text_format: str,
        style: StyleType = ""none"",
        justify: JustifyMethod = ""left"",
        markup: bool = True,
        highlighter: Optional[Highlighter] = None,
        table_column: Optional[Column] = None,
    ) -> None:
        self.text_format = text_format
        self.justify: JustifyMethod = justify
        self.style = style
        self.markup = markup
        self.highlighter = highlighter
        super().__init__(table_column=table_column or Column(no_wrap=True))

    def render(self, task: ""Task"") -> Text:
        _text = self.text_format.format(task=task)
        if self.markup:
            text = Text.from_markup(_text, style=self.style, justify=self.justify)
        else:
            text = Text(_text, style=self.style, justify=self.justify)
        if self.highlighter:
            self.highlighter.highlight(text)
        return text


class BarColumn(ProgressColumn):
    

    def __init__(
        self,
        bar_width: Optional[int] = 40,
        style: StyleType = ""bar.back"",
        complete_style: StyleType = ""bar.complete"",
        finished_style: StyleType = ""bar.finished"",
        pulse_style: StyleType = ""bar.pulse"",
        table_column: Optional[Column] = None,
    ) -> None:
        self.bar_width = bar_width
        self.style = style
        self.complete_style = complete_style
        self.finished_style = finished_style
        self.pulse_style = pulse_style
        super().__init__(table_column=table_column)

    def render(self, task: ""Task"") -> ProgressBar:
        
        return ProgressBar(
            total=max(0, task.total) if task.total is not None else None,
            completed=max(0, task.completed),
            width=None if self.bar_width is None else max(1, self.bar_width),
            pulse=not task.started,
            animation_time=task.get_time(),
            style=self.style,
            complete_style=self.complete_style,
            finished_style=self.finished_style,
            pulse_style=self.pulse_style,
        )


class TimeElapsedColumn(ProgressColumn):
    

    def render(self, task: ""Task"") -> Text:
        
        elapsed = task.finished_time if task.finished else task.elapsed
        if elapsed is None:
            return Text(""-:--:--"", style=""progress.elapsed"")
        delta = timedelta(seconds=max(0, int(elapsed)))
        return Text(str(delta), style=""progress.elapsed"")


class TaskProgressColumn(TextColumn):
    

    def __init__(
        self,
        text_format: str = ""[progress.percentage]{task.percentage:>3.0f}%"",
        text_format_no_percentage: str = """",
        style: StyleType = ""none"",
        justify: JustifyMethod = ""left"",
        markup: bool = True,
        highlighter: Optional[Highlighter] = None,
        table_column: Optional[Column] = None,
        show_speed: bool = False,
    ) -> None:
        self.text_format_no_percentage = text_format_no_percentage
        self.show_speed = show_speed
        super().__init__(
            text_format=text_format,
            style=style,
            justify=justify,
            markup=markup,
            highlighter=highlighter,
            table_column=table_column,
        )

    @classmethod
    def render_speed(cls, speed: Optional[float]) -> Text:
        
        if speed is None:
            return Text("""", style=""progress.percentage"")
        unit, suffix = filesize.pick_unit_and_suffix(
            int(speed),
            ["""", ""×10³"", ""×10⁶"", ""×10⁹"", ""×10¹²""],
            1000,
        )
        data_speed = speed / unit
        return Text(f""{data_speed:.1f}{suffix} it/s"", style=""progress.percentage"")

    def render(self, task: ""Task"") -> Text:
        if task.total is None and self.show_speed:
            return self.render_speed(task.finished_speed or task.speed)
        text_format = (
            self.text_format_no_percentage if task.total is None else self.text_format
        )
        _text = text_format.format(task=task)
        if self.markup:
            text = Text.from_markup(_text, style=self.style, justify=self.justify)
        else:
            text = Text(_text, style=self.style, justify=self.justify)
        if self.highlighter:
            self.highlighter.highlight(text)
        return text


class TimeRemainingColumn(ProgressColumn):
    

    
    max_refresh = 0.5

    def __init__(
        self,
        compact: bool = False,
        elapsed_when_finished: bool = False,
        table_column: Optional[Column] = None,
    ):
        self.compact = compact
        self.elapsed_when_finished = elapsed_when_finished
        super().__init__(table_column=table_column)

    def render(self, task: ""Task"") -> Text:
        
        if self.elapsed_when_finished and task.finished:
            task_time = task.finished_time
            style = ""progress.elapsed""
        else:
            task_time = task.time_remaining
            style = ""progress.remaining""

        if task.total is None:
            return Text("""", style=style)

        if task_time is None:
            return Text(""--:--"" if self.compact else ""-:--:--"", style=style)

        
        minutes, seconds = divmod(int(task_time), 60)
        hours, minutes = divmod(minutes, 60)

        if self.compact and not hours:
            formatted = f""{minutes:02d}:{seconds:02d}""
        else:
            formatted = f""{hours:d}:{minutes:02d}:{seconds:02d}""

        return Text(formatted, style=style)


class FileSizeColumn(ProgressColumn):
    

    def render(self, task: ""Task"") -> Text:
        
        data_size = filesize.decimal(int(task.completed))
        return Text(data_size, style=""progress.filesize"")


class TotalFileSizeColumn(ProgressColumn):
    

    def render(self, task: ""Task"") -> Text:
        
        data_size = filesize.decimal(int(task.total)) if task.total is not None else """"
        return Text(data_size, style=""progress.filesize.total"")


class MofNCompleteColumn(ProgressColumn):
    

    def __init__(self, separator: str = ""/"", table_column: Optional[Column] = None):
        self.separator = separator
        super().__init__(table_column=table_column)

    def render(self, task: ""Task"") -> Text:
        
        completed = int(task.completed)
        total = int(task.total) if task.total is not None else ""?""
        total_width = len(str(total))
        return Text(
            f""{completed:{total_width}d}{self.separator}{total}"",
            style=""progress.download"",
        )


class DownloadColumn(ProgressColumn):
    

    def __init__(
        self, binary_units: bool = False, table_column: Optional[Column] = None
    ) -> None:
        self.binary_units = binary_units
        super().__init__(table_column=table_column)

    def render(self, task: ""Task"") -> Text:
        
        completed = int(task.completed)

        unit_and_suffix_calculation_base = (
            int(task.total) if task.total is not None else completed
        )
        if self.binary_units:
            unit, suffix = filesize.pick_unit_and_suffix(
                unit_and_suffix_calculation_base,
                [""bytes"", ""KiB"", ""MiB"", ""GiB"", ""TiB"", ""PiB"", ""EiB"", ""ZiB"", ""YiB""],
                1024,
            )
        else:
            unit, suffix = filesize.pick_unit_and_suffix(
                unit_and_suffix_calculation_base,
                [""bytes"", ""kB"", ""MB"", ""GB"", ""TB"", ""PB"", ""EB"", ""ZB"", ""YB""],
                1000,
            )
        precision = 0 if unit == 1 else 1

        completed_ratio = completed / unit
        completed_str = f""{completed_ratio:,.{precision}f}""

        if task.total is not None:
            total = int(task.total)
            total_ratio = total / unit
            total_str = f""{total_ratio:,.{precision}f}""
        else:
            total_str = ""?""

        download_status = f""{completed_str}/{total_str} {suffix}""
        download_text = Text(download_status, style=""progress.download"")
        return download_text


class TransferSpeedColumn(ProgressColumn):
    

    def render(self, task: ""Task"") -> Text:
        
        speed = task.finished_speed or task.speed
        if speed is None:
            return Text(""?"", style=""progress.data.speed"")
        data_speed = filesize.decimal(int(speed))
        return Text(f""{data_speed}/s"", style=""progress.data.speed"")


class ProgressSample(NamedTuple):
    

    timestamp: float
    
    completed: float
    


@dataclass
class Task:
    

    id: TaskID
    

    description: str
    

    total: Optional[float]
    

    completed: float
    

    _get_time: GetTimeCallable
    

    finished_time: Optional[float] = None
    

    visible: bool = True
    

    fields: Dict[str, Any] = field(default_factory=dict)
    

    start_time: Optional[float] = field(default=None, init=False, repr=False)
    

    stop_time: Optional[float] = field(default=None, init=False, repr=False)
    

    finished_speed: Optional[float] = None
    

    _progress: Deque[ProgressSample] = field(
        default_factory=lambda: deque(maxlen=1000), init=False, repr=False
    )

    _lock: RLock = field(repr=False, default_factory=RLock)
    

    def get_time(self) -> float:
        
        return self._get_time()

    @property
    def started(self) -> bool:
        
        return self.start_time is not None

    @property
    def remaining(self) -> Optional[float]:
        
        if self.total is None:
            return None
        return self.total - self.completed

    @property
    def elapsed(self) -> Optional[float]:
        
        if self.start_time is None:
            return None
        if self.stop_time is not None:
            return self.stop_time - self.start_time
        return self.get_time() - self.start_time

    @property
    def finished(self) -> bool:
        
        return self.finished_time is not None

    @property
    def percentage(self) -> float:
        
        if not self.total:
            return 0.0
        completed = (self.completed / self.total) * 100.0
        completed = min(100.0, max(0.0, completed))
        return completed

    @property
    def speed(self) -> Optional[float]:
        
        if self.start_time is None:
            return None
        with self._lock:
            progress = self._progress
            if not progress:
                return None
            total_time = progress[-1].timestamp - progress[0].timestamp
            if total_time == 0:
                return None
            iter_progress = iter(progress)
            next(iter_progress)
            total_completed = sum(sample.completed for sample in iter_progress)
            speed = total_completed / total_time
            return speed

    @property
    def time_remaining(self) -> Optional[float]:
        
        if self.finished:
            return 0.0
        speed = self.speed
        if not speed:
            return None
        remaining = self.remaining
        if remaining is None:
            return None
        estimate = ceil(remaining / speed)
        return estimate

    def _reset(self) -> None:
        
        self._progress.clear()
        self.finished_time = None
        self.finished_speed = None


class Progress(JupyterMixin):
    

    def __init__(
        self,
        *columns: Union[str, ProgressColumn],
        console: Optional[Console] = None,
        auto_refresh: bool = True,
        refresh_per_second: float = 10,
        speed_estimate_period: float = 30.0,
        transient: bool = False,
        redirect_stdout: bool = True,
        redirect_stderr: bool = True,
        get_time: Optional[GetTimeCallable] = None,
        disable: bool = False,
        expand: bool = False,
    ) -> None:
        assert refresh_per_second > 0, ""refresh_per_second must be > 0""
        self._lock = RLock()
        self.columns = columns or self.get_default_columns()
        self.speed_estimate_period = speed_estimate_period

        self.disable = disable
        self.expand = expand
        self._tasks: Dict[TaskID, Task] = {}
        self._task_index: TaskID = TaskID(0)
        self.live = Live(
            console=console or get_console(),
            auto_refresh=auto_refresh,
            refresh_per_second=refresh_per_second,
            transient=transient,
            redirect_stdout=redirect_stdout,
            redirect_stderr=redirect_stderr,
            get_renderable=self.get_renderable,
        )
        self.get_time = get_time or self.console.get_time
        self.print = self.console.print
        self.log = self.console.log

    @classmethod
    def get_default_columns(cls) -> Tuple[ProgressColumn, ...]:
        
        return (
            TextColumn(""[progress.description]{task.description}""),
            BarColumn(),
            TaskProgressColumn(),
            TimeRemainingColumn(),
        )

    @property
    def console(self) -> Console:
        return self.live.console

    @property
    def tasks(self) -> List[Task]:
        
        with self._lock:
            return list(self._tasks.values())

    @property
    def task_ids(self) -> List[TaskID]:
        
        with self._lock:
            return list(self._tasks.keys())

    @property
    def finished(self) -> bool:
        
        with self._lock:
            if not self._tasks:
                return True
            return all(task.finished for task in self._tasks.values())

    def start(self) -> None:
        
        if not self.disable:
            self.live.start(refresh=True)

    def stop(self) -> None:
        
        self.live.stop()
        if not self.console.is_interactive and not self.console.is_jupyter:
            self.console.print()

    def __enter__(self) -> Self:
        self.start()
        return self

    def __exit__(
        self,
        exc_type: Optional[Type[BaseException]],
        exc_val: Optional[BaseException],
        exc_tb: Optional[TracebackType],
    ) -> None:
        self.stop()

    def track(
        self,
        sequence: Iterable[ProgressType],
        total: Optional[float] = None,
        completed: int = 0,
        task_id: Optional[TaskID] = None,
        description: str = ""Working..."",
        update_period: float = 0.1,
    ) -> Iterable[ProgressType]:
        
        if total is None:
            total = float(length_hint(sequence)) or None

        if task_id is None:
            task_id = self.add_task(description, total=total, completed=completed)
        else:
            self.update(task_id, total=total, completed=completed)

        if self.live.auto_refresh:
            with _TrackThread(self, task_id, update_period) as track_thread:
                for value in sequence:
                    yield value
                    track_thread.completed += 1
        else:
            advance = self.advance
            refresh = self.refresh
            for value in sequence:
                yield value
                advance(task_id, 1)
                refresh()

    def wrap_file(
        self,
        file: BinaryIO,
        total: Optional[int] = None,
        *,
        task_id: Optional[TaskID] = None,
        description: str = ""Reading..."",
    ) -> BinaryIO:
        
        
        total_bytes: Optional[float] = None
        if total is not None:
            total_bytes = total
        elif task_id is not None:
            with self._lock:
                total_bytes = self._tasks[task_id].total
        if total_bytes is None:
            raise ValueError(
                f""unable to get the total number of bytes, please specify 'total'""
            )

        
        if task_id is None:
            task_id = self.add_task(description, total=total_bytes)
        else:
            self.update(task_id, total=total_bytes)

        return _Reader(file, self, task_id, close_handle=False)

    @typing.overload
    def open(
        self,
        file: Union[str, ""PathLike[str]"", bytes],
        mode: Literal[""rb""],
        buffering: int = -1,
        encoding: Optional[str] = None,
        errors: Optional[str] = None,
        newline: Optional[str] = None,
        *,
        total: Optional[int] = None,
        task_id: Optional[TaskID] = None,
        description: str = ""Reading..."",
    ) -> BinaryIO:
        pass

    @typing.overload
    def open(
        self,
        file: Union[str, ""PathLike[str]"", bytes],
        mode: Union[Literal[""r""], Literal[""rt""]],
        buffering: int = -1,
        encoding: Optional[str] = None,
        errors: Optional[str] = None,
        newline: Optional[str] = None,
        *,
        total: Optional[int] = None,
        task_id: Optional[TaskID] = None,
        description: str = ""Reading..."",
    ) -> TextIO:
        pass

    def open(
        self,
        file: Union[str, ""PathLike[str]"", bytes],
        mode: Union[Literal[""rb""], Literal[""rt""], Literal[""r""]] = ""r"",
        buffering: int = -1,
        encoding: Optional[str] = None,
        errors: Optional[str] = None,
        newline: Optional[str] = None,
        *,
        total: Optional[int] = None,
        task_id: Optional[TaskID] = None,
        description: str = ""Reading..."",
    ) -> Union[BinaryIO, TextIO]:
        
        
        _mode = """".join(sorted(mode, reverse=False))
        if _mode not in (""br"", ""rt"", ""r""):
            raise ValueError(f""invalid mode {mode!r}"")

        
        line_buffering = buffering == 1
        if _mode == ""br"" and buffering == 1:
            warnings.warn(
                ""line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used"",
                RuntimeWarning,
            )
            buffering = -1
        elif _mode in (""rt"", ""r""):
            if buffering == 0:
                raise ValueError(""can't have unbuffered text I/O"")
            elif buffering == 1:
                buffering = -1

        
        if total is None:
            total = stat(file).st_size

        
        if task_id is None:
            task_id = self.add_task(description, total=total)
        else:
            self.update(task_id, total=total)

        
        handle = io.open(file, ""rb"", buffering=buffering)
        reader = _Reader(handle, self, task_id, close_handle=True)

        
        if mode in (""r"", ""rt""):
            return io.TextIOWrapper(
                reader,
                encoding=encoding,
                errors=errors,
                newline=newline,
                line_buffering=line_buffering,
            )

        return reader

    def start_task(self, task_id: TaskID) -> None:
        
        with self._lock:
            task = self._tasks[task_id]
            if task.start_time is None:
                task.start_time = self.get_time()

    def stop_task(self, task_id: TaskID) -> None:
        
        with self._lock:
            task = self._tasks[task_id]
            current_time = self.get_time()
            if task.start_time is None:
                task.start_time = current_time
            task.stop_time = current_time

    def update(
        self,
        task_id: TaskID,
        *,
        total: Optional[float] = None,
        completed: Optional[float] = None,
        advance: Optional[float] = None,
        description: Optional[str] = None,
        visible: Optional[bool] = None,
        refresh: bool = False,
        **fields: Any,
    ) -> None:
        
        with self._lock:
            task = self._tasks[task_id]
            completed_start = task.completed

            if total is not None and total != task.total:
                task.total = total
                task._reset()
            if advance is not None:
                task.completed += advance
            if completed is not None:
                task.completed = completed
            if description is not None:
                task.description = description
            if visible is not None:
                task.visible = visible
            task.fields.update(fields)
            update_completed = task.completed - completed_start

            current_time = self.get_time()
            old_sample_time = current_time - self.speed_estimate_period
            _progress = task._progress

            popleft = _progress.popleft
            while _progress and _progress[0].timestamp < old_sample_time:
                popleft()
            if update_completed > 0:
                _progress.append(ProgressSample(current_time, update_completed))
            if (
                task.total is not None
                and task.completed >= task.total
                and task.finished_time is None
            ):
                task.finished_time = task.elapsed

        if refresh:
            self.refresh()

    def reset(
        self,
        task_id: TaskID,
        *,
        start: bool = True,
        total: Optional[float] = None,
        completed: int = 0,
        visible: Optional[bool] = None,
        description: Optional[str] = None,
        **fields: Any,
    ) -> None:
        
        current_time = self.get_time()
        with self._lock:
            task = self._tasks[task_id]
            task._reset()
            task.start_time = current_time if start else None
            if total is not None:
                task.total = total
            task.completed = completed
            if visible is not None:
                task.visible = visible
            if fields:
                task.fields = fields
            if description is not None:
                task.description = description
            task.finished_time = None
        self.refresh()

    def advance(self, task_id: TaskID, advance: float = 1) -> None:
        
        current_time = self.get_time()
        with self._lock:
            task = self._tasks[task_id]
            completed_start = task.completed
            task.completed += advance
            update_completed = task.completed - completed_start
            old_sample_time = current_time - self.speed_estimate_period
            _progress = task._progress

            popleft = _progress.popleft
            while _progress and _progress[0].timestamp < old_sample_time:
                popleft()
            while len(_progress) > 1000:
                popleft()
            _progress.append(ProgressSample(current_time, update_completed))
            if (
                task.total is not None
                and task.completed >= task.total
                and task.finished_time is None
            ):
                task.finished_time = task.elapsed
                task.finished_speed = task.speed

    def refresh(self) -> None:
        
        if not self.disable and self.live.is_started:
            self.live.refresh()

    def get_renderable(self) -> RenderableType:
        
        renderable = Group(*self.get_renderables())
        return renderable

    def get_renderables(self) -> Iterable[RenderableType]:
        
        table = self.make_tasks_table(self.tasks)
        yield table

    def make_tasks_table(self, tasks: Iterable[Task]) -> Table:
        
        table_columns = (
            (
                Column(no_wrap=True)
                if isinstance(_column, str)
                else _column.get_table_column().copy()
            )
            for _column in self.columns
        )
        table = Table.grid(*table_columns, padding=(0, 1), expand=self.expand)

        for task in tasks:
            if task.visible:
                table.add_row(
                    *(
                        (
                            column.format(task=task)
                            if isinstance(column, str)
                            else column(task)
                        )
                        for column in self.columns
                    )
                )
        return table

    def __rich__(self) -> RenderableType:
        
        with self._lock:
            return self.get_renderable()

    def add_task(
        self,
        description: str,
        start: bool = True,
        total: Optional[float] = 100.0,
        completed: int = 0,
        visible: bool = True,
        **fields: Any,
    ) -> TaskID:
        
        with self._lock:
            task = Task(
                self._task_index,
                description,
                total,
                completed,
                visible=visible,
                fields=fields,
                _get_time=self.get_time,
                _lock=self._lock,
            )
            self._tasks[self._task_index] = task
            if start:
                self.start_task(self._task_index)
            new_task_index = self._task_index
            self._task_index = TaskID(int(self._task_index) + 1)
        self.refresh()
        return new_task_index

    def remove_task(self, task_id: TaskID) -> None:
        
        with self._lock:
            del self._tasks[task_id]


if __name__ == ""__main__"":  
    import random
    import time

    from .panel import Panel
    from .rule import Rule
    from .syntax import Syntax
    from .table import Table

    syntax = Syntax(
        ,
        ""python"",
        line_numbers=True,
    )

    table = Table(""foo"", ""bar"", ""baz"")
    table.add_row(""1"", ""2"", ""3"")

    progress_renderables = [
        ""Text may be printed while the progress bars are rendering."",
        Panel(""In fact, [i]any[/i] renderable will work""),
        ""Such as [magenta]tables[/]..."",
        table,
        ""Pretty printed structures..."",
        {""type"": ""example"", ""text"": ""Pretty printed""},
        ""Syntax..."",
        syntax,
        Rule(""Give it a try!""),
    ]

    from itertools import cycle

    examples = cycle(progress_renderables)

    console = Console(record=True)

    with Progress(
        SpinnerColumn(),
        *Progress.get_default_columns(),
        TimeElapsedColumn(),
        console=console,
        transient=False,
    ) as progress:
        task1 = progress.add_task(""[red]Downloading"", total=1000)
        task2 = progress.add_task(""[green]Processing"", total=1000)
        task3 = progress.add_task(""[yellow]Thinking"", total=None)

        while not progress.finished:
            progress.update(task1, advance=0.5)
            progress.update(task2, advance=0.3)
            time.sleep(0.01)
            if random.randint(0, 100) < 1:
                progress.log(next(examples))

import math
from functools import lru_cache
from time import monotonic
from typing import Iterable, List, Optional

from .color import Color, blend_rgb
from .color_triplet import ColorTriplet
from .console import Console, ConsoleOptions, RenderResult
from .jupyter import JupyterMixin
from .measure import Measurement
from .segment import Segment
from .style import Style, StyleType


PULSE_SIZE = 20


class ProgressBar(JupyterMixin):
    

    def __init__(
        self,
        total: Optional[float] = 100.0,
        completed: float = 0,
        width: Optional[int] = None,
        pulse: bool = False,
        style: StyleType = ""bar.back"",
        complete_style: StyleType = ""bar.complete"",
        finished_style: StyleType = ""bar.finished"",
        pulse_style: StyleType = ""bar.pulse"",
        animation_time: Optional[float] = None,
    ):
        self.total = total
        self.completed = completed
        self.width = width
        self.pulse = pulse
        self.style = style
        self.complete_style = complete_style
        self.finished_style = finished_style
        self.pulse_style = pulse_style
        self.animation_time = animation_time

        self._pulse_segments: Optional[List[Segment]] = None

    def __repr__(self) -> str:
        return f""<Bar {self.completed!r} of {self.total!r}>""

    @property
    def percentage_completed(self) -> Optional[float]:
        
        if self.total is None:
            return None
        completed = (self.completed / self.total) * 100.0
        completed = min(100, max(0.0, completed))
        return completed

    @lru_cache(maxsize=16)
    def _get_pulse_segments(
        self,
        fore_style: Style,
        back_style: Style,
        color_system: str,
        no_color: bool,
        ascii: bool = False,
    ) -> List[Segment]:
        
        bar = ""-"" if ascii else ""━""
        segments: List[Segment] = []
        if color_system not in (""standard"", ""eight_bit"", ""truecolor"") or no_color:
            segments += [Segment(bar, fore_style)] * (PULSE_SIZE // 2)
            segments += [Segment("" "" if no_color else bar, back_style)] * (
                PULSE_SIZE - (PULSE_SIZE // 2)
            )
            return segments

        append = segments.append
        fore_color = (
            fore_style.color.get_truecolor()
            if fore_style.color
            else ColorTriplet(255, 0, 255)
        )
        back_color = (
            back_style.color.get_truecolor()
            if back_style.color
            else ColorTriplet(0, 0, 0)
        )
        cos = math.cos
        pi = math.pi
        _Segment = Segment
        _Style = Style
        from_triplet = Color.from_triplet

        for index in range(PULSE_SIZE):
            position = index / PULSE_SIZE
            fade = 0.5 + cos(position * pi * 2) / 2.0
            color = blend_rgb(fore_color, back_color, cross_fade=fade)
            append(_Segment(bar, _Style(color=from_triplet(color))))
        return segments

    def update(self, completed: float, total: Optional[float] = None) -> None:
        
        self.completed = completed
        self.total = total if total is not None else self.total

    def _render_pulse(
        self, console: Console, width: int, ascii: bool = False
    ) -> Iterable[Segment]:
        
        fore_style = console.get_style(self.pulse_style, default=""white"")
        back_style = console.get_style(self.style, default=""black"")

        pulse_segments = self._get_pulse_segments(
            fore_style, back_style, console.color_system, console.no_color, ascii=ascii
        )
        segment_count = len(pulse_segments)
        current_time = (
            monotonic() if self.animation_time is None else self.animation_time
        )
        segments = pulse_segments * (int(width / segment_count) + 2)
        offset = int(-current_time * 15) % segment_count
        segments = segments[offset : offset + width]
        yield from segments

    def __rich_console__(
        self, console: Console, options: ConsoleOptions
    ) -> RenderResult:
        width = min(self.width or options.max_width, options.max_width)
        ascii = options.legacy_windows or options.ascii_only
        should_pulse = self.pulse or self.total is None
        if should_pulse:
            yield from self._render_pulse(console, width, ascii=ascii)
            return

        completed: Optional[float] = (
            min(self.total, max(0, self.completed)) if self.total is not None else None
        )

        bar = ""-"" if ascii else ""━""
        half_bar_right = "" "" if ascii else ""╸""
        half_bar_left = "" "" if ascii else ""╺""
        complete_halves = (
            int(width * 2 * completed / self.total)
            if self.total and completed is not None
            else width * 2
        )
        bar_count = complete_halves // 2
        half_bar_count = complete_halves % 2
        style = console.get_style(self.style)
        is_finished = self.total is None or self.completed >= self.total
        complete_style = console.get_style(
            self.finished_style if is_finished else self.complete_style
        )
        _Segment = Segment
        if bar_count:
            yield _Segment(bar * bar_count, complete_style)
        if half_bar_count:
            yield _Segment(half_bar_right * half_bar_count, complete_style)

        if not console.no_color:
            remaining_bars = width - bar_count - half_bar_count
            if remaining_bars and console.color_system is not None:
                if not half_bar_count and bar_count:
                    yield _Segment(half_bar_left, style)
                    remaining_bars -= 1
                if remaining_bars:
                    yield _Segment(bar * remaining_bars, style)

    def __rich_measure__(
        self, console: Console, options: ConsoleOptions
    ) -> Measurement:
        return (
            Measurement(self.width, self.width)
            if self.width is not None
            else Measurement(4, options.max_width)
        )


if __name__ == ""__main__"":  
    console = Console()
    bar = ProgressBar(width=50, total=100)

    import time

    console.show_cursor(False)
    for n in range(0, 101, 1):
        bar.update(n)
        console.print(bar)
        console.file.write(""\r"")
        time.sleep(0.05)
    console.show_cursor(True)
    console.print()

from typing import Any, Generic, List, Optional, TextIO, TypeVar, Union, overload

from . import get_console
from .console import Console
from .text import Text, TextType

PromptType = TypeVar(""PromptType"")
DefaultType = TypeVar(""DefaultType"")


class PromptError(Exception):
    


class InvalidResponse(PromptError):
    

    def __init__(self, message: TextType) -> None:
        self.message = message

    def __rich__(self) -> TextType:
        return self.message


class PromptBase(Generic[PromptType]):
    

    response_type: type = str

    validate_error_message = ""[prompt.invalid]Please enter a valid value""
    illegal_choice_message = (
        ""[prompt.invalid.choice]Please select one of the available options""
    )
    prompt_suffix = "": ""

    choices: Optional[List[str]] = None

    def __init__(
        self,
        prompt: TextType = """",
        *,
        console: Optional[Console] = None,
        password: bool = False,
        choices: Optional[List[str]] = None,
        case_sensitive: bool = True,
        show_default: bool = True,
        show_choices: bool = True,
    ) -> None:
        self.console = console or get_console()
        self.prompt = (
            Text.from_markup(prompt, style=""prompt"")
            if isinstance(prompt, str)
            else prompt
        )
        self.password = password
        if choices is not None:
            self.choices = choices
        self.case_sensitive = case_sensitive
        self.show_default = show_default
        self.show_choices = show_choices

    @classmethod
    @overload
    def ask(
        cls,
        prompt: TextType = """",
        *,
        console: Optional[Console] = None,
        password: bool = False,
        choices: Optional[List[str]] = None,
        case_sensitive: bool = True,
        show_default: bool = True,
        show_choices: bool = True,
        default: DefaultType,
        stream: Optional[TextIO] = None,
    ) -> Union[DefaultType, PromptType]:
        ...

    @classmethod
    @overload
    def ask(
        cls,
        prompt: TextType = """",
        *,
        console: Optional[Console] = None,
        password: bool = False,
        choices: Optional[List[str]] = None,
        case_sensitive: bool = True,
        show_default: bool = True,
        show_choices: bool = True,
        stream: Optional[TextIO] = None,
    ) -> PromptType:
        ...

    @classmethod
    def ask(
        cls,
        prompt: TextType = """",
        *,
        console: Optional[Console] = None,
        password: bool = False,
        choices: Optional[List[str]] = None,
        case_sensitive: bool = True,
        show_default: bool = True,
        show_choices: bool = True,
        default: Any = ...,
        stream: Optional[TextIO] = None,
    ) -> Any:
        
        _prompt = cls(
            prompt,
            console=console,
            password=password,
            choices=choices,
            case_sensitive=case_sensitive,
            show_default=show_default,
            show_choices=show_choices,
        )
        return _prompt(default=default, stream=stream)

    def render_default(self, default: DefaultType) -> Text:
        
        return Text(f""({default})"", ""prompt.default"")

    def make_prompt(self, default: DefaultType) -> Text:
        
        prompt = self.prompt.copy()
        prompt.end = """"

        if self.show_choices and self.choices:
            _choices = ""/"".join(self.choices)
            choices = f""[{_choices}]""
            prompt.append("" "")
            prompt.append(choices, ""prompt.choices"")

        if (
            default != ...
            and self.show_default
            and isinstance(default, (str, self.response_type))
        ):
            prompt.append("" "")
            _default = self.render_default(default)
            prompt.append(_default)

        prompt.append(self.prompt_suffix)

        return prompt

    @classmethod
    def get_input(
        cls,
        console: Console,
        prompt: TextType,
        password: bool,
        stream: Optional[TextIO] = None,
    ) -> str:
        
        return console.input(prompt, password=password, stream=stream)

    def check_choice(self, value: str) -> bool:
        
        assert self.choices is not None
        if self.case_sensitive:
            return value.strip() in self.choices
        return value.strip().lower() in [choice.lower() for choice in self.choices]

    def process_response(self, value: str) -> PromptType:
        
        value = value.strip()
        try:
            return_value: PromptType = self.response_type(value)
        except ValueError:
            raise InvalidResponse(self.validate_error_message)

        if self.choices is not None:
            if not self.check_choice(value):
                raise InvalidResponse(self.illegal_choice_message)

            if not self.case_sensitive:
                
                return_value = self.response_type(
                    self.choices[
                        [choice.lower() for choice in self.choices].index(value.lower())
                    ]
                )
        return return_value

    def on_validate_error(self, value: str, error: InvalidResponse) -> None:
        
        self.console.print(error)

    def pre_prompt(self) -> None:
        

    @overload
    def __call__(self, *, stream: Optional[TextIO] = None) -> PromptType:
        ...

    @overload
    def __call__(
        self, *, default: DefaultType, stream: Optional[TextIO] = None
    ) -> Union[PromptType, DefaultType]:
        ...

    def __call__(self, *, default: Any = ..., stream: Optional[TextIO] = None) -> Any:
        
        while True:
            self.pre_prompt()
            prompt = self.make_prompt(default)
            value = self.get_input(self.console, prompt, self.password, stream=stream)
            if value == """" and default != ...:
                return default
            try:
                return_value = self.process_response(value)
            except InvalidResponse as error:
                self.on_validate_error(value, error)
                continue
            else:
                return return_value


class Prompt(PromptBase[str]):
    

    response_type = str


class IntPrompt(PromptBase[int]):
    

    response_type = int
    validate_error_message = ""[prompt.invalid]Please enter a valid integer number""


class FloatPrompt(PromptBase[float]):
    

    response_type = float
    validate_error_message = ""[prompt.invalid]Please enter a number""


class Confirm(PromptBase[bool]):
    

    response_type = bool
    validate_error_message = ""[prompt.invalid]Please enter Y or N""
    choices: List[str] = [""y"", ""n""]

    def render_default(self, default: DefaultType) -> Text:
        
        yes, no = self.choices
        return Text(f""({yes})"" if default else f""({no})"", style=""prompt.default"")

    def process_response(self, value: str) -> bool:
        
        value = value.strip().lower()
        if value not in self.choices:
            raise InvalidResponse(self.validate_error_message)
        return value == self.choices[0]


if __name__ == ""__main__"":  
    from pip._vendor.rich import print

    if Confirm.ask(""Run [i]prompt[/i] tests?"", default=True):
        while True:
            result = IntPrompt.ask(
                "":rocket: Enter a number between [b]1[/b] and [b]10[/b]"", default=5
            )
            if result >= 1 and result <= 10:
                break
            print("":pile_of_poo: [prompt.invalid]Number must be between 1 and 10"")
        print(f""number={result}"")

        while True:
            password = Prompt.ask(
                ""Please enter a password [cyan](must be at least 5 characters)"",
                password=True,
            )
            if len(password) >= 5:
                break
            print(""[prompt.invalid]password too short"")
        print(f""password={password!r}"")

        fruit = Prompt.ask(""Enter a fruit"", choices=[""apple"", ""orange"", ""pear""])
        print(f""fruit={fruit!r}"")

        doggie = Prompt.ask(
            ""What's the best Dog? (Case INSENSITIVE)"",
            choices=[""Border Terrier"", ""Collie"", ""Labradoodle""],
            case_sensitive=False,
        )
        print(f""doggie={doggie!r}"")

    else:
        print(""[b]OK :loudly_crying_face:"")

from typing import Any, cast, Set, TYPE_CHECKING
from inspect import isclass

if TYPE_CHECKING:
    from pip._vendor.rich.console import RenderableType

_GIBBERISH = 


def is_renderable(check_object: Any) -> bool:
    
    return (
        isinstance(check_object, str)
        or hasattr(check_object, ""__rich__"")
        or hasattr(check_object, ""__rich_console__"")
    )


def rich_cast(renderable: object) -> ""RenderableType"":
    
    from pip._vendor.rich.console import RenderableType

    rich_visited_set: Set[type] = set()  
    while hasattr(renderable, ""__rich__"") and not isclass(renderable):
        
        if hasattr(renderable, _GIBBERISH):
            return repr(renderable)
        cast_method = getattr(renderable, ""__rich__"")
        renderable = cast_method()
        renderable_type = type(renderable)
        if renderable_type in rich_visited_set:
            break
        rich_visited_set.add(renderable_type)

    return cast(RenderableType, renderable)

from typing import NamedTuple


class Region(NamedTuple):
    

    x: int
    y: int
    width: int
    height: int

import inspect
from functools import partial
from typing import (
    Any,
    Callable,
    Iterable,
    List,
    Optional,
    Tuple,
    Type,
    TypeVar,
    Union,
    overload,
)

T = TypeVar(""T"")


Result = Iterable[Union[Any, Tuple[Any], Tuple[str, Any], Tuple[str, Any, Any]]]
RichReprResult = Result


class ReprError(Exception):
    


@overload
def auto(cls: Optional[Type[T]]) -> Type[T]:
    ...


@overload
def auto(*, angular: bool = False) -> Callable[[Type[T]], Type[T]]:
    ...


def auto(
    cls: Optional[Type[T]] = None, *, angular: Optional[bool] = None
) -> Union[Type[T], Callable[[Type[T]], Type[T]]]:
    

    def do_replace(cls: Type[T], angular: Optional[bool] = None) -> Type[T]:
        def auto_repr(self: T) -> str:
            
            repr_str: List[str] = []
            append = repr_str.append

            angular: bool = getattr(self.__rich_repr__, ""angular"", False)  
            for arg in self.__rich_repr__():  
                if isinstance(arg, tuple):
                    if len(arg) == 1:
                        append(repr(arg[0]))
                    else:
                        key, value, *default = arg
                        if key is None:
                            append(repr(value))
                        else:
                            if default and default[0] == value:
                                continue
                            append(f""{key}={value!r}"")
                else:
                    append(repr(arg))
            if angular:
                return f""<{self.__class__.__name__} {' '.join(repr_str)}>""
            else:
                return f""{self.__class__.__name__}({', '.join(repr_str)})""

        def auto_rich_repr(self: Type[T]) -> Result:
            
            try:
                signature = inspect.signature(self.__init__)
                for name, param in signature.parameters.items():
                    if param.kind == param.POSITIONAL_ONLY:
                        yield getattr(self, name)
                    elif param.kind in (
                        param.POSITIONAL_OR_KEYWORD,
                        param.KEYWORD_ONLY,
                    ):
                        if param.default is param.empty:
                            yield getattr(self, param.name)
                        else:
                            yield param.name, getattr(self, param.name), param.default
            except Exception as error:
                raise ReprError(
                    f""Failed to auto generate __rich_repr__; {error}""
                ) from None

        if not hasattr(cls, ""__rich_repr__""):
            auto_rich_repr.__doc__ = ""Build a rich repr""
            cls.__rich_repr__ = auto_rich_repr  

        auto_repr.__doc__ = ""Return repr(self)""
        cls.__repr__ = auto_repr  
        if angular is not None:
            cls.__rich_repr__.angular = angular  
        return cls

    if cls is None:
        return partial(do_replace, angular=angular)
    else:
        return do_replace(cls, angular=angular)


@overload
def rich_repr(cls: Optional[Type[T]]) -> Type[T]:
    ...


@overload
def rich_repr(*, angular: bool = False) -> Callable[[Type[T]], Type[T]]:
    ...


def rich_repr(
    cls: Optional[Type[T]] = None, *, angular: bool = False
) -> Union[Type[T], Callable[[Type[T]], Type[T]]]:
    if cls is None:
        return auto(angular=angular)
    else:
        return auto(cls)


if __name__ == ""__main__"":

    @auto
    class Foo:
        def __rich_repr__(self) -> Result:
            yield ""foo""
            yield ""bar"", {""shopping"": [""eggs"", ""ham"", ""pineapple""]}
            yield ""buy"", ""hand sanitizer""

    foo = Foo()
    from pip._vendor.rich.console import Console

    console = Console()

    console.rule(""Standard repr"")
    console.print(foo)

    console.print(foo, width=60)
    console.print(foo, width=30)

    console.rule(""Angular repr"")
    Foo.__rich_repr__.angular = True  

    console.print(foo)

    console.print(foo, width=60)
    console.print(foo, width=30)

from typing import Union

from .align import AlignMethod
from .cells import cell_len, set_cell_size
from .console import Console, ConsoleOptions, RenderResult
from .jupyter import JupyterMixin
from .measure import Measurement
from .style import Style
from .text import Text


class Rule(JupyterMixin):
    

    def __init__(
        self,
        title: Union[str, Text] = """",
        *,
        characters: str = ""─"",
        style: Union[str, Style] = ""rule.line"",
        end: str = ""\n"",
        align: AlignMethod = ""center"",
    ) -> None:
        if cell_len(characters) < 1:
            raise ValueError(
                ""'characters' argument must have a cell width of at least 1""
            )
        if align not in (""left"", ""center"", ""right""):
            raise ValueError(
                f'invalid value for align, expected ""left"", ""center"", ""right"" (not {align!r})'
            )
        self.title = title
        self.characters = characters
        self.style = style
        self.end = end
        self.align = align

    def __repr__(self) -> str:
        return f""Rule({self.title!r}, {self.characters!r})""

    def __rich_console__(
        self, console: Console, options: ConsoleOptions
    ) -> RenderResult:
        width = options.max_width

        characters = (
            ""-""
            if (options.ascii_only and not self.characters.isascii())
            else self.characters
        )

        chars_len = cell_len(characters)
        if not self.title:
            yield self._rule_line(chars_len, width)
            return

        if isinstance(self.title, Text):
            title_text = self.title
        else:
            title_text = console.render_str(self.title, style=""rule.text"")

        title_text.plain = title_text.plain.replace(""\n"", "" "")
        title_text.expand_tabs()

        required_space = 4 if self.align == ""center"" else 2
        truncate_width = max(0, width - required_space)
        if not truncate_width:
            yield self._rule_line(chars_len, width)
            return

        rule_text = Text(end=self.end)
        if self.align == ""center"":
            title_text.truncate(truncate_width, overflow=""ellipsis"")
            side_width = (width - cell_len(title_text.plain)) // 2
            left = Text(characters * (side_width // chars_len + 1))
            left.truncate(side_width - 1)
            right_length = width - cell_len(left.plain) - cell_len(title_text.plain)
            right = Text(characters * (side_width // chars_len + 1))
            right.truncate(right_length)
            rule_text.append(left.plain + "" "", self.style)
            rule_text.append(title_text)
            rule_text.append("" "" + right.plain, self.style)
        elif self.align == ""left"":
            title_text.truncate(truncate_width, overflow=""ellipsis"")
            rule_text.append(title_text)
            rule_text.append("" "")
            rule_text.append(characters * (width - rule_text.cell_len), self.style)
        elif self.align == ""right"":
            title_text.truncate(truncate_width, overflow=""ellipsis"")
            rule_text.append(characters * (width - title_text.cell_len - 1), self.style)
            rule_text.append("" "")
            rule_text.append(title_text)

        rule_text.plain = set_cell_size(rule_text.plain, width)
        yield rule_text

    def _rule_line(self, chars_len: int, width: int) -> Text:
        rule_text = Text(self.characters * ((width // chars_len) + 1), self.style)
        rule_text.truncate(width)
        rule_text.plain = set_cell_size(rule_text.plain, width)
        return rule_text

    def __rich_measure__(
        self, console: Console, options: ConsoleOptions
    ) -> Measurement:
        return Measurement(1, 1)


if __name__ == ""__main__"":  
    import sys

    from pip._vendor.rich.console import Console

    try:
        text = sys.argv[1]
    except IndexError:
        text = ""Hello, World""
    console = Console()
    console.print(Rule(title=text))

    console = Console()
    console.print(Rule(""foo""), width=4)

from collections.abc import Mapping
from typing import TYPE_CHECKING, Any, Optional, Tuple

from .highlighter import ReprHighlighter
from .panel import Panel
from .pretty import Pretty
from .table import Table
from .text import Text, TextType

if TYPE_CHECKING:
    from .console import ConsoleRenderable


def render_scope(
    scope: ""Mapping[str, Any]"",
    *,
    title: Optional[TextType] = None,
    sort_keys: bool = True,
    indent_guides: bool = False,
    max_length: Optional[int] = None,
    max_string: Optional[int] = None,
) -> ""ConsoleRenderable"":
    
    highlighter = ReprHighlighter()
    items_table = Table.grid(padding=(0, 1), expand=False)
    items_table.add_column(justify=""right"")

    def sort_items(item: Tuple[str, Any]) -> Tuple[bool, str]:
        
        key, _ = item
        return (not key.startswith(""__""), key.lower())

    items = sorted(scope.items(), key=sort_items) if sort_keys else scope.items()
    for key, value in items:
        key_text = Text.assemble(
            (key, ""scope.key.special"" if key.startswith(""__"") else ""scope.key""),
            ("" ="", ""scope.equals""),
        )
        items_table.add_row(
            key_text,
            Pretty(
                value,
                highlighter=highlighter,
                indent_guides=indent_guides,
                max_length=max_length,
                max_string=max_string,
            ),
        )
    return Panel.fit(
        items_table,
        title=title,
        border_style=""scope.border"",
        padding=(0, 1),
    )


if __name__ == ""__main__"":  
    from pip._vendor.rich import print

    print()

    def test(foo: float, bar: float) -> None:
        list_of_things = [1, 2, 3, None, 4, True, False, ""Hello World""]
        dict_of_things = {
            ""version"": ""1.1"",
            ""method"": ""confirmFruitPurchase"",
            ""params"": [[""apple"", ""orange"", ""mangoes"", ""pomelo""], 1.123],
            ""id"": ""194521489"",
        }
        print(render_scope(locals(), title=""[i]locals"", sort_keys=False))

    test(20.3423, 3.1427)
    print()

from typing import Optional, TYPE_CHECKING

from .segment import Segment
from .style import StyleType
from ._loop import loop_last


if TYPE_CHECKING:
    from .console import (
        Console,
        ConsoleOptions,
        RenderResult,
        RenderableType,
        Group,
    )


class Screen:
    

    renderable: ""RenderableType""

    def __init__(
        self,
        *renderables: ""RenderableType"",
        style: Optional[StyleType] = None,
        application_mode: bool = False,
    ) -> None:
        from pip._vendor.rich.console import Group

        self.renderable = Group(*renderables)
        self.style = style
        self.application_mode = application_mode

    def __rich_console__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> ""RenderResult"":
        width, height = options.size
        style = console.get_style(self.style) if self.style else None
        render_options = options.update(width=width, height=height)
        lines = console.render_lines(
            self.renderable or """", render_options, style=style, pad=True
        )
        lines = Segment.set_shape(lines, width, height, style=style)
        new_line = Segment(""\n\r"") if self.application_mode else Segment.line()
        for last, line in loop_last(lines):
            yield from line
            if not last:
                yield new_line

from enum import IntEnum
from functools import lru_cache
from itertools import filterfalse
from logging import getLogger
from operator import attrgetter
from typing import (
    TYPE_CHECKING,
    Dict,
    Iterable,
    List,
    NamedTuple,
    Optional,
    Sequence,
    Tuple,
    Type,
    Union,
)

from .cells import (
    _is_single_cell_widths,
    cached_cell_len,
    cell_len,
    get_character_cell_size,
    set_cell_size,
)
from .repr import Result, rich_repr
from .style import Style

if TYPE_CHECKING:
    from .console import Console, ConsoleOptions, RenderResult

log = getLogger(""rich"")


class ControlType(IntEnum):
    

    BELL = 1
    CARRIAGE_RETURN = 2
    HOME = 3
    CLEAR = 4
    SHOW_CURSOR = 5
    HIDE_CURSOR = 6
    ENABLE_ALT_SCREEN = 7
    DISABLE_ALT_SCREEN = 8
    CURSOR_UP = 9
    CURSOR_DOWN = 10
    CURSOR_FORWARD = 11
    CURSOR_BACKWARD = 12
    CURSOR_MOVE_TO_COLUMN = 13
    CURSOR_MOVE_TO = 14
    ERASE_IN_LINE = 15
    SET_WINDOW_TITLE = 16


ControlCode = Union[
    Tuple[ControlType],
    Tuple[ControlType, Union[int, str]],
    Tuple[ControlType, int, int],
]


@rich_repr()
class Segment(NamedTuple):
    

    text: str
    style: Optional[Style] = None
    control: Optional[Sequence[ControlCode]] = None

    @property
    def cell_length(self) -> int:
        
        text, _style, control = self
        return 0 if control else cell_len(text)

    def __rich_repr__(self) -> Result:
        yield self.text
        if self.control is None:
            if self.style is not None:
                yield self.style
        else:
            yield self.style
            yield self.control

    def __bool__(self) -> bool:
        
        return bool(self.text)

    @property
    def is_control(self) -> bool:
        
        return self.control is not None

    @classmethod
    @lru_cache(1024 * 16)
    def _split_cells(cls, segment: ""Segment"", cut: int) -> Tuple[""Segment"", ""Segment""]:
        
        text, style, control = segment
        _Segment = Segment
        cell_length = segment.cell_length
        if cut >= cell_length:
            return segment, _Segment("""", style, control)

        cell_size = get_character_cell_size

        pos = int((cut / cell_length) * len(text))

        while True:
            before = text[:pos]
            cell_pos = cell_len(before)
            out_by = cell_pos - cut
            if not out_by:
                return (
                    _Segment(before, style, control),
                    _Segment(text[pos:], style, control),
                )
            if out_by == -1 and cell_size(text[pos]) == 2:
                return (
                    _Segment(text[:pos] + "" "", style, control),
                    _Segment("" "" + text[pos + 1 :], style, control),
                )
            if out_by == +1 and cell_size(text[pos - 1]) == 2:
                return (
                    _Segment(text[: pos - 1] + "" "", style, control),
                    _Segment("" "" + text[pos:], style, control),
                )
            if cell_pos < cut:
                pos += 1
            else:
                pos -= 1

    def split_cells(self, cut: int) -> Tuple[""Segment"", ""Segment""]:
        
        text, style, control = self
        assert cut >= 0

        if _is_single_cell_widths(text):
            
            if cut >= len(text):
                return self, Segment("""", style, control)
            return (
                Segment(text[:cut], style, control),
                Segment(text[cut:], style, control),
            )

        return self._split_cells(self, cut)

    @classmethod
    def line(cls) -> ""Segment"":
        
        return cls(""\n"")

    @classmethod
    def apply_style(
        cls,
        segments: Iterable[""Segment""],
        style: Optional[Style] = None,
        post_style: Optional[Style] = None,
    ) -> Iterable[""Segment""]:
        
        result_segments = segments
        if style:
            apply = style.__add__
            result_segments = (
                cls(text, None if control else apply(_style), control)
                for text, _style, control in result_segments
            )
        if post_style:
            result_segments = (
                cls(
                    text,
                    (
                        None
                        if control
                        else (_style + post_style if _style else post_style)
                    ),
                    control,
                )
                for text, _style, control in result_segments
            )
        return result_segments

    @classmethod
    def filter_control(
        cls, segments: Iterable[""Segment""], is_control: bool = False
    ) -> Iterable[""Segment""]:
        
        if is_control:
            return filter(attrgetter(""control""), segments)
        else:
            return filterfalse(attrgetter(""control""), segments)

    @classmethod
    def split_lines(cls, segments: Iterable[""Segment""]) -> Iterable[List[""Segment""]]:
        
        line: List[Segment] = []
        append = line.append

        for segment in segments:
            if ""\n"" in segment.text and not segment.control:
                text, style, _ = segment
                while text:
                    _text, new_line, text = text.partition(""\n"")
                    if _text:
                        append(cls(_text, style))
                    if new_line:
                        yield line
                        line = []
                        append = line.append
            else:
                append(segment)
        if line:
            yield line

    @classmethod
    def split_and_crop_lines(
        cls,
        segments: Iterable[""Segment""],
        length: int,
        style: Optional[Style] = None,
        pad: bool = True,
        include_new_lines: bool = True,
    ) -> Iterable[List[""Segment""]]:
        
        line: List[Segment] = []
        append = line.append

        adjust_line_length = cls.adjust_line_length
        new_line_segment = cls(""\n"")

        for segment in segments:
            if ""\n"" in segment.text and not segment.control:
                text, segment_style, _ = segment
                while text:
                    _text, new_line, text = text.partition(""\n"")
                    if _text:
                        append(cls(_text, segment_style))
                    if new_line:
                        cropped_line = adjust_line_length(
                            line, length, style=style, pad=pad
                        )
                        if include_new_lines:
                            cropped_line.append(new_line_segment)
                        yield cropped_line
                        line.clear()
            else:
                append(segment)
        if line:
            yield adjust_line_length(line, length, style=style, pad=pad)

    @classmethod
    def adjust_line_length(
        cls,
        line: List[""Segment""],
        length: int,
        style: Optional[Style] = None,
        pad: bool = True,
    ) -> List[""Segment""]:
        
        line_length = sum(segment.cell_length for segment in line)
        new_line: List[Segment]

        if line_length < length:
            if pad:
                new_line = line + [cls("" "" * (length - line_length), style)]
            else:
                new_line = line[:]
        elif line_length > length:
            new_line = []
            append = new_line.append
            line_length = 0
            for segment in line:
                segment_length = segment.cell_length
                if line_length + segment_length < length or segment.control:
                    append(segment)
                    line_length += segment_length
                else:
                    text, segment_style, _ = segment
                    text = set_cell_size(text, length - line_length)
                    append(cls(text, segment_style))
                    break
        else:
            new_line = line[:]
        return new_line

    @classmethod
    def get_line_length(cls, line: List[""Segment""]) -> int:
        
        _cell_len = cell_len
        return sum(_cell_len(text) for text, style, control in line if not control)

    @classmethod
    def get_shape(cls, lines: List[List[""Segment""]]) -> Tuple[int, int]:
        
        get_line_length = cls.get_line_length
        max_width = max(get_line_length(line) for line in lines) if lines else 0
        return (max_width, len(lines))

    @classmethod
    def set_shape(
        cls,
        lines: List[List[""Segment""]],
        width: int,
        height: Optional[int] = None,
        style: Optional[Style] = None,
        new_lines: bool = False,
    ) -> List[List[""Segment""]]:
        
        _height = height or len(lines)

        blank = (
            [cls("" "" * width + ""\n"", style)] if new_lines else [cls("" "" * width, style)]
        )

        adjust_line_length = cls.adjust_line_length
        shaped_lines = lines[:_height]
        shaped_lines[:] = [
            adjust_line_length(line, width, style=style) for line in lines
        ]
        if len(shaped_lines) < _height:
            shaped_lines.extend([blank] * (_height - len(shaped_lines)))
        return shaped_lines

    @classmethod
    def align_top(
        cls: Type[""Segment""],
        lines: List[List[""Segment""]],
        width: int,
        height: int,
        style: Style,
        new_lines: bool = False,
    ) -> List[List[""Segment""]]:
        
        extra_lines = height - len(lines)
        if not extra_lines:
            return lines[:]
        lines = lines[:height]
        blank = cls("" "" * width + ""\n"", style) if new_lines else cls("" "" * width, style)
        lines = lines + [[blank]] * extra_lines
        return lines

    @classmethod
    def align_bottom(
        cls: Type[""Segment""],
        lines: List[List[""Segment""]],
        width: int,
        height: int,
        style: Style,
        new_lines: bool = False,
    ) -> List[List[""Segment""]]:
        
        extra_lines = height - len(lines)
        if not extra_lines:
            return lines[:]
        lines = lines[:height]
        blank = cls("" "" * width + ""\n"", style) if new_lines else cls("" "" * width, style)
        lines = [[blank]] * extra_lines + lines
        return lines

    @classmethod
    def align_middle(
        cls: Type[""Segment""],
        lines: List[List[""Segment""]],
        width: int,
        height: int,
        style: Style,
        new_lines: bool = False,
    ) -> List[List[""Segment""]]:
        
        extra_lines = height - len(lines)
        if not extra_lines:
            return lines[:]
        lines = lines[:height]
        blank = cls("" "" * width + ""\n"", style) if new_lines else cls("" "" * width, style)
        top_lines = extra_lines // 2
        bottom_lines = extra_lines - top_lines
        lines = [[blank]] * top_lines + lines + [[blank]] * bottom_lines
        return lines

    @classmethod
    def simplify(cls, segments: Iterable[""Segment""]) -> Iterable[""Segment""]:
        
        iter_segments = iter(segments)
        try:
            last_segment = next(iter_segments)
        except StopIteration:
            return

        _Segment = Segment
        for segment in iter_segments:
            if last_segment.style == segment.style and not segment.control:
                last_segment = _Segment(
                    last_segment.text + segment.text, last_segment.style
                )
            else:
                yield last_segment
                last_segment = segment
        yield last_segment

    @classmethod
    def strip_links(cls, segments: Iterable[""Segment""]) -> Iterable[""Segment""]:
        
        for segment in segments:
            if segment.control or segment.style is None:
                yield segment
            else:
                text, style, _control = segment
                yield cls(text, style.update_link(None) if style else None)

    @classmethod
    def strip_styles(cls, segments: Iterable[""Segment""]) -> Iterable[""Segment""]:
        
        for text, _style, control in segments:
            yield cls(text, None, control)

    @classmethod
    def remove_color(cls, segments: Iterable[""Segment""]) -> Iterable[""Segment""]:
        

        cache: Dict[Style, Style] = {}
        for text, style, control in segments:
            if style:
                colorless_style = cache.get(style)
                if colorless_style is None:
                    colorless_style = style.without_color
                    cache[style] = colorless_style
                yield cls(text, colorless_style, control)
            else:
                yield cls(text, None, control)

    @classmethod
    def divide(
        cls, segments: Iterable[""Segment""], cuts: Iterable[int]
    ) -> Iterable[List[""Segment""]]:
        
        split_segments: List[""Segment""] = []
        add_segment = split_segments.append

        iter_cuts = iter(cuts)

        while True:
            cut = next(iter_cuts, -1)
            if cut == -1:
                return
            if cut != 0:
                break
            yield []
        pos = 0

        segments_clear = split_segments.clear
        segments_copy = split_segments.copy

        _cell_len = cached_cell_len
        for segment in segments:
            text, _style, control = segment
            while text:
                end_pos = pos if control else pos + _cell_len(text)
                if end_pos < cut:
                    add_segment(segment)
                    pos = end_pos
                    break

                if end_pos == cut:
                    add_segment(segment)
                    yield segments_copy()
                    segments_clear()
                    pos = end_pos

                    cut = next(iter_cuts, -1)
                    if cut == -1:
                        if split_segments:
                            yield segments_copy()
                        return

                    break

                else:
                    before, segment = segment.split_cells(cut - pos)
                    text, _style, control = segment
                    add_segment(before)
                    yield segments_copy()
                    segments_clear()
                    pos = cut

                cut = next(iter_cuts, -1)
                if cut == -1:
                    if split_segments:
                        yield segments_copy()
                    return

        yield segments_copy()


class Segments:
    

    def __init__(self, segments: Iterable[Segment], new_lines: bool = False) -> None:
        self.segments = list(segments)
        self.new_lines = new_lines

    def __rich_console__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> ""RenderResult"":
        if self.new_lines:
            line = Segment.line()
            for segment in self.segments:
                yield segment
                yield line
        else:
            yield from self.segments


class SegmentLines:
    def __init__(self, lines: Iterable[List[Segment]], new_lines: bool = False) -> None:
        
        self.lines = list(lines)
        self.new_lines = new_lines

    def __rich_console__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> ""RenderResult"":
        if self.new_lines:
            new_line = Segment.line()
            for line in self.lines:
                yield from line
                yield new_line
        else:
            for line in self.lines:
                yield from line


if __name__ == ""__main__"":  
    from pip._vendor.rich.console import Console
    from pip._vendor.rich.syntax import Syntax
    from pip._vendor.rich.text import Text

    code = 

    text = Text.from_markup(""Hello, [bold magenta]World[/]!"")

    console = Console()

    console.rule(""rich.Segment"")
    console.print(
        ""A Segment is the last step in the Rich render process before generating text with ANSI codes.""
    )
    console.print(""\nConsider the following code:\n"")
    console.print(Syntax(code, ""python"", line_numbers=True))
    console.print()
    console.print(
        ""When you call [b]print()[/b], Rich [i]renders[/i] the object in to the following:\n""
    )
    fragments = list(console.render(text))
    console.print(fragments)
    console.print()
    console.print(""The Segments are then processed to produce the following output:\n"")
    console.print(text)
    console.print(
        ""\nYou will only need to know this if you are implementing your own Rich renderables.""
    )

from typing import TYPE_CHECKING, List, Optional, Union, cast

from ._spinners import SPINNERS
from .measure import Measurement
from .table import Table
from .text import Text

if TYPE_CHECKING:
    from .console import Console, ConsoleOptions, RenderableType, RenderResult
    from .style import StyleType


class Spinner:
    

    def __init__(
        self,
        name: str,
        text: ""RenderableType"" = """",
        *,
        style: Optional[""StyleType""] = None,
        speed: float = 1.0,
    ) -> None:
        try:
            spinner = SPINNERS[name]
        except KeyError:
            raise KeyError(f""no spinner called {name!r}"")
        self.text: ""Union[RenderableType, Text]"" = (
            Text.from_markup(text) if isinstance(text, str) else text
        )
        self.name = name
        self.frames = cast(List[str], spinner[""frames""])[:]
        self.interval = cast(float, spinner[""interval""])
        self.start_time: Optional[float] = None
        self.style = style
        self.speed = speed
        self.frame_no_offset: float = 0.0
        self._update_speed = 0.0

    def __rich_console__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> ""RenderResult"":
        yield self.render(console.get_time())

    def __rich_measure__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> Measurement:
        text = self.render(0)
        return Measurement.get(console, options, text)

    def render(self, time: float) -> ""RenderableType"":
        
        if self.start_time is None:
            self.start_time = time

        frame_no = ((time - self.start_time) * self.speed) / (
            self.interval / 1000.0
        ) + self.frame_no_offset
        frame = Text(
            self.frames[int(frame_no) % len(self.frames)], style=self.style or """"
        )

        if self._update_speed:
            self.frame_no_offset = frame_no
            self.start_time = time
            self.speed = self._update_speed
            self._update_speed = 0.0

        if not self.text:
            return frame
        elif isinstance(self.text, (str, Text)):
            return Text.assemble(frame, "" "", self.text)
        else:
            table = Table.grid(padding=1)
            table.add_row(frame, self.text)
            return table

    def update(
        self,
        *,
        text: ""RenderableType"" = """",
        style: Optional[""StyleType""] = None,
        speed: Optional[float] = None,
    ) -> None:
        
        if text:
            self.text = Text.from_markup(text) if isinstance(text, str) else text
        if style:
            self.style = style
        if speed:
            self._update_speed = speed


if __name__ == ""__main__"":  
    from time import sleep

    from .console import Group
    from .live import Live

    all_spinners = Group(
        *[
            Spinner(spinner_name, text=Text(repr(spinner_name), style=""green""))
            for spinner_name in sorted(SPINNERS.keys())
        ]
    )

    with Live(all_spinners, refresh_per_second=20) as live:
        while True:
            sleep(0.1)

from types import TracebackType
from typing import Optional, Type

from .console import Console, RenderableType
from .jupyter import JupyterMixin
from .live import Live
from .spinner import Spinner
from .style import StyleType


class Status(JupyterMixin):
    

    def __init__(
        self,
        status: RenderableType,
        *,
        console: Optional[Console] = None,
        spinner: str = ""dots"",
        spinner_style: StyleType = ""status.spinner"",
        speed: float = 1.0,
        refresh_per_second: float = 12.5,
    ):
        self.status = status
        self.spinner_style = spinner_style
        self.speed = speed
        self._spinner = Spinner(spinner, text=status, style=spinner_style, speed=speed)
        self._live = Live(
            self.renderable,
            console=console,
            refresh_per_second=refresh_per_second,
            transient=True,
        )

    @property
    def renderable(self) -> Spinner:
        return self._spinner

    @property
    def console(self) -> ""Console"":
        
        return self._live.console

    def update(
        self,
        status: Optional[RenderableType] = None,
        *,
        spinner: Optional[str] = None,
        spinner_style: Optional[StyleType] = None,
        speed: Optional[float] = None,
    ) -> None:
        
        if status is not None:
            self.status = status
        if spinner_style is not None:
            self.spinner_style = spinner_style
        if speed is not None:
            self.speed = speed
        if spinner is not None:
            self._spinner = Spinner(
                spinner, text=self.status, style=self.spinner_style, speed=self.speed
            )
            self._live.update(self.renderable, refresh=True)
        else:
            self._spinner.update(
                text=self.status, style=self.spinner_style, speed=self.speed
            )

    def start(self) -> None:
        
        self._live.start()

    def stop(self) -> None:
        
        self._live.stop()

    def __rich__(self) -> RenderableType:
        return self.renderable

    def __enter__(self) -> ""Status"":
        self.start()
        return self

    def __exit__(
        self,
        exc_type: Optional[Type[BaseException]],
        exc_val: Optional[BaseException],
        exc_tb: Optional[TracebackType],
    ) -> None:
        self.stop()


if __name__ == ""__main__"":  
    from time import sleep

    from .console import Console

    console = Console()
    with console.status(""[magenta]Covid detector booting up"") as status:
        sleep(3)
        console.log(""Importing advanced AI"")
        sleep(3)
        console.log(""Advanced Covid AI Ready"")
        sleep(3)
        status.update(status=""[bold blue] Scanning for Covid"", spinner=""earth"")
        sleep(3)
        console.log(""Found 10,000,000,000 copies of Covid32.exe"")
        sleep(3)
        status.update(
            status=""[bold red]Moving Covid32.exe to Trash"",
            spinner=""bouncingBall"",
            spinner_style=""yellow"",
        )
        sleep(5)
    console.print(""[bold green]Covid deleted successfully"")

import sys
from functools import lru_cache
from marshal import dumps, loads
from random import randint
from typing import Any, Dict, Iterable, List, Optional, Type, Union, cast

from . import errors
from .color import Color, ColorParseError, ColorSystem, blend_rgb
from .repr import Result, rich_repr
from .terminal_theme import DEFAULT_TERMINAL_THEME, TerminalTheme


StyleType = Union[str, ""Style""]


class _Bit:
    

    __slots__ = [""bit""]

    def __init__(self, bit_no: int) -> None:
        self.bit = 1 << bit_no

    def __get__(self, obj: ""Style"", objtype: Type[""Style""]) -> Optional[bool]:
        if obj._set_attributes & self.bit:
            return obj._attributes & self.bit != 0
        return None


@rich_repr
class Style:
    

    _color: Optional[Color]
    _bgcolor: Optional[Color]
    _attributes: int
    _set_attributes: int
    _hash: Optional[int]
    _null: bool
    _meta: Optional[bytes]

    __slots__ = [
        ""_color"",
        ""_bgcolor"",
        ""_attributes"",
        ""_set_attributes"",
        ""_link"",
        ""_link_id"",
        ""_ansi"",
        ""_style_definition"",
        ""_hash"",
        ""_null"",
        ""_meta"",
    ]

    
    _style_map = {
        0: ""1"",
        1: ""2"",
        2: ""3"",
        3: ""4"",
        4: ""5"",
        5: ""6"",
        6: ""7"",
        7: ""8"",
        8: ""9"",
        9: ""21"",
        10: ""51"",
        11: ""52"",
        12: ""53"",
    }

    STYLE_ATTRIBUTES = {
        ""dim"": ""dim"",
        ""d"": ""dim"",
        ""bold"": ""bold"",
        ""b"": ""bold"",
        ""italic"": ""italic"",
        ""i"": ""italic"",
        ""underline"": ""underline"",
        ""u"": ""underline"",
        ""blink"": ""blink"",
        ""blink2"": ""blink2"",
        ""reverse"": ""reverse"",
        ""r"": ""reverse"",
        ""conceal"": ""conceal"",
        ""c"": ""conceal"",
        ""strike"": ""strike"",
        ""s"": ""strike"",
        ""underline2"": ""underline2"",
        ""uu"": ""underline2"",
        ""frame"": ""frame"",
        ""encircle"": ""encircle"",
        ""overline"": ""overline"",
        ""o"": ""overline"",
    }

    def __init__(
        self,
        *,
        color: Optional[Union[Color, str]] = None,
        bgcolor: Optional[Union[Color, str]] = None,
        bold: Optional[bool] = None,
        dim: Optional[bool] = None,
        italic: Optional[bool] = None,
        underline: Optional[bool] = None,
        blink: Optional[bool] = None,
        blink2: Optional[bool] = None,
        reverse: Optional[bool] = None,
        conceal: Optional[bool] = None,
        strike: Optional[bool] = None,
        underline2: Optional[bool] = None,
        frame: Optional[bool] = None,
        encircle: Optional[bool] = None,
        overline: Optional[bool] = None,
        link: Optional[str] = None,
        meta: Optional[Dict[str, Any]] = None,
    ):
        self._ansi: Optional[str] = None
        self._style_definition: Optional[str] = None

        def _make_color(color: Union[Color, str]) -> Color:
            return color if isinstance(color, Color) else Color.parse(color)

        self._color = None if color is None else _make_color(color)
        self._bgcolor = None if bgcolor is None else _make_color(bgcolor)
        self._set_attributes = sum(
            (
                bold is not None,
                dim is not None and 2,
                italic is not None and 4,
                underline is not None and 8,
                blink is not None and 16,
                blink2 is not None and 32,
                reverse is not None and 64,
                conceal is not None and 128,
                strike is not None and 256,
                underline2 is not None and 512,
                frame is not None and 1024,
                encircle is not None and 2048,
                overline is not None and 4096,
            )
        )
        self._attributes = (
            sum(
                (
                    bold and 1 or 0,
                    dim and 2 or 0,
                    italic and 4 or 0,
                    underline and 8 or 0,
                    blink and 16 or 0,
                    blink2 and 32 or 0,
                    reverse and 64 or 0,
                    conceal and 128 or 0,
                    strike and 256 or 0,
                    underline2 and 512 or 0,
                    frame and 1024 or 0,
                    encircle and 2048 or 0,
                    overline and 4096 or 0,
                )
            )
            if self._set_attributes
            else 0
        )

        self._link = link
        self._meta = None if meta is None else dumps(meta)
        self._link_id = (
            f""{randint(0, 999999)}{hash(self._meta)}"" if (link or meta) else """"
        )
        self._hash: Optional[int] = None
        self._null = not (self._set_attributes or color or bgcolor or link or meta)

    @classmethod
    def null(cls) -> ""Style"":
        
        return NULL_STYLE

    @classmethod
    def from_color(
        cls, color: Optional[Color] = None, bgcolor: Optional[Color] = None
    ) -> ""Style"":
        
        style: Style = cls.__new__(Style)
        style._ansi = None
        style._style_definition = None
        style._color = color
        style._bgcolor = bgcolor
        style._set_attributes = 0
        style._attributes = 0
        style._link = None
        style._link_id = """"
        style._meta = None
        style._null = not (color or bgcolor)
        style._hash = None
        return style

    @classmethod
    def from_meta(cls, meta: Optional[Dict[str, Any]]) -> ""Style"":
        
        style: Style = cls.__new__(Style)
        style._ansi = None
        style._style_definition = None
        style._color = None
        style._bgcolor = None
        style._set_attributes = 0
        style._attributes = 0
        style._link = None
        style._meta = dumps(meta)
        style._link_id = f""{randint(0, 999999)}{hash(style._meta)}""
        style._hash = None
        style._null = not (meta)
        return style

    @classmethod
    def on(cls, meta: Optional[Dict[str, Any]] = None, **handlers: Any) -> ""Style"":
        
        meta = {} if meta is None else meta
        meta.update({f""@{key}"": value for key, value in handlers.items()})
        return cls.from_meta(meta)

    bold = _Bit(0)
    dim = _Bit(1)
    italic = _Bit(2)
    underline = _Bit(3)
    blink = _Bit(4)
    blink2 = _Bit(5)
    reverse = _Bit(6)
    conceal = _Bit(7)
    strike = _Bit(8)
    underline2 = _Bit(9)
    frame = _Bit(10)
    encircle = _Bit(11)
    overline = _Bit(12)

    @property
    def link_id(self) -> str:
        
        return self._link_id

    def __str__(self) -> str:
        
        if self._style_definition is None:
            attributes: List[str] = []
            append = attributes.append
            bits = self._set_attributes
            if bits & 0b0000000001111:
                if bits & 1:
                    append(""bold"" if self.bold else ""not bold"")
                if bits & (1 << 1):
                    append(""dim"" if self.dim else ""not dim"")
                if bits & (1 << 2):
                    append(""italic"" if self.italic else ""not italic"")
                if bits & (1 << 3):
                    append(""underline"" if self.underline else ""not underline"")
            if bits & 0b0000111110000:
                if bits & (1 << 4):
                    append(""blink"" if self.blink else ""not blink"")
                if bits & (1 << 5):
                    append(""blink2"" if self.blink2 else ""not blink2"")
                if bits & (1 << 6):
                    append(""reverse"" if self.reverse else ""not reverse"")
                if bits & (1 << 7):
                    append(""conceal"" if self.conceal else ""not conceal"")
                if bits & (1 << 8):
                    append(""strike"" if self.strike else ""not strike"")
            if bits & 0b1111000000000:
                if bits & (1 << 9):
                    append(""underline2"" if self.underline2 else ""not underline2"")
                if bits & (1 << 10):
                    append(""frame"" if self.frame else ""not frame"")
                if bits & (1 << 11):
                    append(""encircle"" if self.encircle else ""not encircle"")
                if bits & (1 << 12):
                    append(""overline"" if self.overline else ""not overline"")
            if self._color is not None:
                append(self._color.name)
            if self._bgcolor is not None:
                append(""on"")
                append(self._bgcolor.name)
            if self._link:
                append(""link"")
                append(self._link)
            self._style_definition = "" "".join(attributes) or ""none""
        return self._style_definition

    def __bool__(self) -> bool:
        
        return not self._null

    def _make_ansi_codes(self, color_system: ColorSystem) -> str:
        

        if self._ansi is None:
            sgr: List[str] = []
            append = sgr.append
            _style_map = self._style_map
            attributes = self._attributes & self._set_attributes
            if attributes:
                if attributes & 1:
                    append(_style_map[0])
                if attributes & 2:
                    append(_style_map[1])
                if attributes & 4:
                    append(_style_map[2])
                if attributes & 8:
                    append(_style_map[3])
                if attributes & 0b0000111110000:
                    for bit in range(4, 9):
                        if attributes & (1 << bit):
                            append(_style_map[bit])
                if attributes & 0b1111000000000:
                    for bit in range(9, 13):
                        if attributes & (1 << bit):
                            append(_style_map[bit])
            if self._color is not None:
                sgr.extend(self._color.downgrade(color_system).get_ansi_codes())
            if self._bgcolor is not None:
                sgr.extend(
                    self._bgcolor.downgrade(color_system).get_ansi_codes(
                        foreground=False
                    )
                )
            self._ansi = "";"".join(sgr)
        return self._ansi

    @classmethod
    @lru_cache(maxsize=1024)
    def normalize(cls, style: str) -> str:
        
        try:
            return str(cls.parse(style))
        except errors.StyleSyntaxError:
            return style.strip().lower()

    @classmethod
    def pick_first(cls, *values: Optional[StyleType]) -> StyleType:
        
        for value in values:
            if value is not None:
                return value
        raise ValueError(""expected at least one non-None style"")

    def __rich_repr__(self) -> Result:
        yield ""color"", self.color, None
        yield ""bgcolor"", self.bgcolor, None
        yield ""bold"", self.bold, None,
        yield ""dim"", self.dim, None,
        yield ""italic"", self.italic, None
        yield ""underline"", self.underline, None,
        yield ""blink"", self.blink, None
        yield ""blink2"", self.blink2, None
        yield ""reverse"", self.reverse, None
        yield ""conceal"", self.conceal, None
        yield ""strike"", self.strike, None
        yield ""underline2"", self.underline2, None
        yield ""frame"", self.frame, None
        yield ""encircle"", self.encircle, None
        yield ""link"", self.link, None
        if self._meta:
            yield ""meta"", self.meta

    def __eq__(self, other: Any) -> bool:
        if not isinstance(other, Style):
            return NotImplemented
        return self.__hash__() == other.__hash__()

    def __ne__(self, other: Any) -> bool:
        if not isinstance(other, Style):
            return NotImplemented
        return self.__hash__() != other.__hash__()

    def __hash__(self) -> int:
        if self._hash is not None:
            return self._hash
        self._hash = hash(
            (
                self._color,
                self._bgcolor,
                self._attributes,
                self._set_attributes,
                self._link,
                self._meta,
            )
        )
        return self._hash

    @property
    def color(self) -> Optional[Color]:
        
        return self._color

    @property
    def bgcolor(self) -> Optional[Color]:
        
        return self._bgcolor

    @property
    def link(self) -> Optional[str]:
        
        return self._link

    @property
    def transparent_background(self) -> bool:
        
        return self.bgcolor is None or self.bgcolor.is_default

    @property
    def background_style(self) -> ""Style"":
        
        return Style(bgcolor=self.bgcolor)

    @property
    def meta(self) -> Dict[str, Any]:
        
        return {} if self._meta is None else cast(Dict[str, Any], loads(self._meta))

    @property
    def without_color(self) -> ""Style"":
        
        if self._null:
            return NULL_STYLE
        style: Style = self.__new__(Style)
        style._ansi = None
        style._style_definition = None
        style._color = None
        style._bgcolor = None
        style._attributes = self._attributes
        style._set_attributes = self._set_attributes
        style._link = self._link
        style._link_id = f""{randint(0, 999999)}"" if self._link else """"
        style._null = False
        style._meta = None
        style._hash = None
        return style

    @classmethod
    @lru_cache(maxsize=4096)
    def parse(cls, style_definition: str) -> ""Style"":
        
        if style_definition.strip() == ""none"" or not style_definition:
            return cls.null()

        STYLE_ATTRIBUTES = cls.STYLE_ATTRIBUTES
        color: Optional[str] = None
        bgcolor: Optional[str] = None
        attributes: Dict[str, Optional[Any]] = {}
        link: Optional[str] = None

        words = iter(style_definition.split())
        for original_word in words:
            word = original_word.lower()
            if word == ""on"":
                word = next(words, """")
                if not word:
                    raise errors.StyleSyntaxError(""color expected after 'on'"")
                try:
                    Color.parse(word)
                except ColorParseError as error:
                    raise errors.StyleSyntaxError(
                        f""unable to parse {word!r} as background color; {error}""
                    ) from None
                bgcolor = word

            elif word == ""not"":
                word = next(words, """")
                attribute = STYLE_ATTRIBUTES.get(word)
                if attribute is None:
                    raise errors.StyleSyntaxError(
                        f""expected style attribute after 'not', found {word!r}""
                    )
                attributes[attribute] = False

            elif word == ""link"":
                word = next(words, """")
                if not word:
                    raise errors.StyleSyntaxError(""URL expected after 'link'"")
                link = word

            elif word in STYLE_ATTRIBUTES:
                attributes[STYLE_ATTRIBUTES[word]] = True

            else:
                try:
                    Color.parse(word)
                except ColorParseError as error:
                    raise errors.StyleSyntaxError(
                        f""unable to parse {word!r} as color; {error}""
                    ) from None
                color = word
        style = Style(color=color, bgcolor=bgcolor, link=link, **attributes)
        return style

    @lru_cache(maxsize=1024)
    def get_html_style(self, theme: Optional[TerminalTheme] = None) -> str:
        
        theme = theme or DEFAULT_TERMINAL_THEME
        css: List[str] = []
        append = css.append

        color = self.color
        bgcolor = self.bgcolor
        if self.reverse:
            color, bgcolor = bgcolor, color
        if self.dim:
            foreground_color = (
                theme.foreground_color if color is None else color.get_truecolor(theme)
            )
            color = Color.from_triplet(
                blend_rgb(foreground_color, theme.background_color, 0.5)
            )
        if color is not None:
            theme_color = color.get_truecolor(theme)
            append(f""color: {theme_color.hex}"")
            append(f""text-decoration-color: {theme_color.hex}"")
        if bgcolor is not None:
            theme_color = bgcolor.get_truecolor(theme, foreground=False)
            append(f""background-color: {theme_color.hex}"")
        if self.bold:
            append(""font-weight: bold"")
        if self.italic:
            append(""font-style: italic"")
        if self.underline:
            append(""text-decoration: underline"")
        if self.strike:
            append(""text-decoration: line-through"")
        if self.overline:
            append(""text-decoration: overline"")
        return ""; "".join(css)

    @classmethod
    def combine(cls, styles: Iterable[""Style""]) -> ""Style"":
        
        iter_styles = iter(styles)
        return sum(iter_styles, next(iter_styles))

    @classmethod
    def chain(cls, *styles: ""Style"") -> ""Style"":
        
        iter_styles = iter(styles)
        return sum(iter_styles, next(iter_styles))

    def copy(self) -> ""Style"":
        
        if self._null:
            return NULL_STYLE
        style: Style = self.__new__(Style)
        style._ansi = self._ansi
        style._style_definition = self._style_definition
        style._color = self._color
        style._bgcolor = self._bgcolor
        style._attributes = self._attributes
        style._set_attributes = self._set_attributes
        style._link = self._link
        style._link_id = f""{randint(0, 999999)}"" if self._link else """"
        style._hash = self._hash
        style._null = False
        style._meta = self._meta
        return style

    @lru_cache(maxsize=128)
    def clear_meta_and_links(self) -> ""Style"":
        
        if self._null:
            return NULL_STYLE
        style: Style = self.__new__(Style)
        style._ansi = self._ansi
        style._style_definition = self._style_definition
        style._color = self._color
        style._bgcolor = self._bgcolor
        style._attributes = self._attributes
        style._set_attributes = self._set_attributes
        style._link = None
        style._link_id = """"
        style._hash = None
        style._null = False
        style._meta = None
        return style

    def update_link(self, link: Optional[str] = None) -> ""Style"":
        
        style: Style = self.__new__(Style)
        style._ansi = self._ansi
        style._style_definition = self._style_definition
        style._color = self._color
        style._bgcolor = self._bgcolor
        style._attributes = self._attributes
        style._set_attributes = self._set_attributes
        style._link = link
        style._link_id = f""{randint(0, 999999)}"" if link else """"
        style._hash = None
        style._null = False
        style._meta = self._meta
        return style

    def render(
        self,
        text: str = """",
        *,
        color_system: Optional[ColorSystem] = ColorSystem.TRUECOLOR,
        legacy_windows: bool = False,
    ) -> str:
        
        if not text or color_system is None:
            return text
        attrs = self._ansi or self._make_ansi_codes(color_system)
        rendered = f""\x1b[{attrs}m{text}\x1b[0m"" if attrs else text
        if self._link and not legacy_windows:
            rendered = (
                f""\x1b]8;id={self._link_id};{self._link}\x1b\\{rendered}\x1b]8;;\x1b\\""
            )
        return rendered

    def test(self, text: Optional[str] = None) -> None:
        
        text = text or str(self)
        sys.stdout.write(f""{self.render(text)}\n"")

    @lru_cache(maxsize=1024)
    def _add(self, style: Optional[""Style""]) -> ""Style"":
        if style is None or style._null:
            return self
        if self._null:
            return style
        new_style: Style = self.__new__(Style)
        new_style._ansi = None
        new_style._style_definition = None
        new_style._color = style._color or self._color
        new_style._bgcolor = style._bgcolor or self._bgcolor
        new_style._attributes = (self._attributes & ~style._set_attributes) | (
            style._attributes & style._set_attributes
        )
        new_style._set_attributes = self._set_attributes | style._set_attributes
        new_style._link = style._link or self._link
        new_style._link_id = style._link_id or self._link_id
        new_style._null = style._null
        if self._meta and style._meta:
            new_style._meta = dumps({**self.meta, **style.meta})
        else:
            new_style._meta = self._meta or style._meta
        new_style._hash = None
        return new_style

    def __add__(self, style: Optional[""Style""]) -> ""Style"":
        combined_style = self._add(style)
        return combined_style.copy() if combined_style.link else combined_style


NULL_STYLE = Style()


class StyleStack:
    

    __slots__ = [""_stack""]

    def __init__(self, default_style: ""Style"") -> None:
        self._stack: List[Style] = [default_style]

    def __repr__(self) -> str:
        return f""<stylestack {self._stack!r}>""

    @property
    def current(self) -> Style:
        
        return self._stack[-1]

    def push(self, style: Style) -> None:
        
        self._stack.append(self._stack[-1] + style)

    def pop(self) -> Style:
        
        self._stack.pop()
        return self._stack[-1]

from typing import TYPE_CHECKING

from .measure import Measurement
from .segment import Segment
from .style import StyleType

if TYPE_CHECKING:
    from .console import Console, ConsoleOptions, RenderResult, RenderableType


class Styled:
    

    def __init__(self, renderable: ""RenderableType"", style: ""StyleType"") -> None:
        self.renderable = renderable
        self.style = style

    def __rich_console__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> ""RenderResult"":
        style = console.get_style(self.style)
        rendered_segments = console.render(self.renderable, options)
        segments = Segment.apply_style(rendered_segments, style)
        return segments

    def __rich_measure__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> Measurement:
        return Measurement.get(console, options, self.renderable)


if __name__ == ""__main__"":  
    from pip._vendor.rich import print
    from pip._vendor.rich.panel import Panel

    panel = Styled(Panel(""hello""), ""on blue"")
    print(panel)

from __future__ import annotations

import os.path
import re
import sys
import textwrap
from abc import ABC, abstractmethod
from pathlib import Path
from typing import (
    Any,
    Dict,
    Iterable,
    List,
    NamedTuple,
    Optional,
    Sequence,
    Set,
    Tuple,
    Type,
    Union,
)

from pip._vendor.pygments.lexer import Lexer
from pip._vendor.pygments.lexers import get_lexer_by_name, guess_lexer_for_filename
from pip._vendor.pygments.style import Style as PygmentsStyle
from pip._vendor.pygments.styles import get_style_by_name
from pip._vendor.pygments.token import (
    Comment,
    Error,
    Generic,
    Keyword,
    Name,
    Number,
    Operator,
    String,
    Token,
    Whitespace,
)
from pip._vendor.pygments.util import ClassNotFound

from pip._vendor.rich.containers import Lines
from pip._vendor.rich.padding import Padding, PaddingDimensions

from ._loop import loop_first
from .cells import cell_len
from .color import Color, blend_rgb
from .console import Console, ConsoleOptions, JustifyMethod, RenderResult
from .jupyter import JupyterMixin
from .measure import Measurement
from .segment import Segment, Segments
from .style import Style, StyleType
from .text import Text

TokenType = Tuple[str, ...]

WINDOWS = sys.platform == ""win32""
DEFAULT_THEME = ""monokai""




ANSI_LIGHT: Dict[TokenType, Style] = {
    Token: Style(),
    Whitespace: Style(color=""white""),
    Comment: Style(dim=True),
    Comment.Preproc: Style(color=""cyan""),
    Keyword: Style(color=""blue""),
    Keyword.Type: Style(color=""cyan""),
    Operator.Word: Style(color=""magenta""),
    Name.Builtin: Style(color=""cyan""),
    Name.Function: Style(color=""green""),
    Name.Namespace: Style(color=""cyan"", underline=True),
    Name.Class: Style(color=""green"", underline=True),
    Name.Exception: Style(color=""cyan""),
    Name.Decorator: Style(color=""magenta"", bold=True),
    Name.Variable: Style(color=""red""),
    Name.Constant: Style(color=""red""),
    Name.Attribute: Style(color=""cyan""),
    Name.Tag: Style(color=""bright_blue""),
    String: Style(color=""yellow""),
    Number: Style(color=""blue""),
    Generic.Deleted: Style(color=""bright_red""),
    Generic.Inserted: Style(color=""green""),
    Generic.Heading: Style(bold=True),
    Generic.Subheading: Style(color=""magenta"", bold=True),
    Generic.Prompt: Style(bold=True),
    Generic.Error: Style(color=""bright_red""),
    Error: Style(color=""red"", underline=True),
}

ANSI_DARK: Dict[TokenType, Style] = {
    Token: Style(),
    Whitespace: Style(color=""bright_black""),
    Comment: Style(dim=True),
    Comment.Preproc: Style(color=""bright_cyan""),
    Keyword: Style(color=""bright_blue""),
    Keyword.Type: Style(color=""bright_cyan""),
    Operator.Word: Style(color=""bright_magenta""),
    Name.Builtin: Style(color=""bright_cyan""),
    Name.Function: Style(color=""bright_green""),
    Name.Namespace: Style(color=""bright_cyan"", underline=True),
    Name.Class: Style(color=""bright_green"", underline=True),
    Name.Exception: Style(color=""bright_cyan""),
    Name.Decorator: Style(color=""bright_magenta"", bold=True),
    Name.Variable: Style(color=""bright_red""),
    Name.Constant: Style(color=""bright_red""),
    Name.Attribute: Style(color=""bright_cyan""),
    Name.Tag: Style(color=""bright_blue""),
    String: Style(color=""yellow""),
    Number: Style(color=""bright_blue""),
    Generic.Deleted: Style(color=""bright_red""),
    Generic.Inserted: Style(color=""bright_green""),
    Generic.Heading: Style(bold=True),
    Generic.Subheading: Style(color=""bright_magenta"", bold=True),
    Generic.Prompt: Style(bold=True),
    Generic.Error: Style(color=""bright_red""),
    Error: Style(color=""red"", underline=True),
}

RICH_SYNTAX_THEMES = {""ansi_light"": ANSI_LIGHT, ""ansi_dark"": ANSI_DARK}
NUMBERS_COLUMN_DEFAULT_PADDING = 2


class SyntaxTheme(ABC):
    

    @abstractmethod
    def get_style_for_token(self, token_type: TokenType) -> Style:
        
        raise NotImplementedError  

    @abstractmethod
    def get_background_style(self) -> Style:
        
        raise NotImplementedError  


class PygmentsSyntaxTheme(SyntaxTheme):
    

    def __init__(self, theme: Union[str, Type[PygmentsStyle]]) -> None:
        self._style_cache: Dict[TokenType, Style] = {}
        if isinstance(theme, str):
            try:
                self._pygments_style_class = get_style_by_name(theme)
            except ClassNotFound:
                self._pygments_style_class = get_style_by_name(""default"")
        else:
            self._pygments_style_class = theme

        self._background_color = self._pygments_style_class.background_color
        self._background_style = Style(bgcolor=self._background_color)

    def get_style_for_token(self, token_type: TokenType) -> Style:
        
        try:
            return self._style_cache[token_type]
        except KeyError:
            try:
                pygments_style = self._pygments_style_class.style_for_token(token_type)
            except KeyError:
                style = Style.null()
            else:
                color = pygments_style[""color""]
                bgcolor = pygments_style[""bgcolor""]
                style = Style(
                    color=""
                    bgcolor=""
                    bold=pygments_style[""bold""],
                    italic=pygments_style[""italic""],
                    underline=pygments_style[""underline""],
                )
            self._style_cache[token_type] = style
        return style

    def get_background_style(self) -> Style:
        return self._background_style


class ANSISyntaxTheme(SyntaxTheme):
    

    def __init__(self, style_map: Dict[TokenType, Style]) -> None:
        self.style_map = style_map
        self._missing_style = Style.null()
        self._background_style = Style.null()
        self._style_cache: Dict[TokenType, Style] = {}

    def get_style_for_token(self, token_type: TokenType) -> Style:
        
        try:
            return self._style_cache[token_type]
        except KeyError:
            
            
            
            get_style = self.style_map.get
            token = tuple(token_type)
            style = self._missing_style
            while token:
                _style = get_style(token)
                if _style is not None:
                    style = _style
                    break
                token = token[:-1]
            self._style_cache[token_type] = style
            return style

    def get_background_style(self) -> Style:
        return self._background_style


SyntaxPosition = Tuple[int, int]


class _SyntaxHighlightRange(NamedTuple):
    

    style: StyleType
    start: SyntaxPosition
    end: SyntaxPosition
    style_before: bool = False


class PaddingProperty:
    

    def __get__(self, obj: Syntax, objtype: Type[Syntax]) -> Tuple[int, int, int, int]:
        
        return obj._padding

    def __set__(self, obj: Syntax, padding: PaddingDimensions) -> None:
        obj._padding = Padding.unpack(padding)


class Syntax(JupyterMixin):
    

    _pygments_style_class: Type[PygmentsStyle]
    _theme: SyntaxTheme

    @classmethod
    def get_theme(cls, name: Union[str, SyntaxTheme]) -> SyntaxTheme:
        
        if isinstance(name, SyntaxTheme):
            return name
        theme: SyntaxTheme
        if name in RICH_SYNTAX_THEMES:
            theme = ANSISyntaxTheme(RICH_SYNTAX_THEMES[name])
        else:
            theme = PygmentsSyntaxTheme(name)
        return theme

    def __init__(
        self,
        code: str,
        lexer: Union[Lexer, str],
        *,
        theme: Union[str, SyntaxTheme] = DEFAULT_THEME,
        dedent: bool = False,
        line_numbers: bool = False,
        start_line: int = 1,
        line_range: Optional[Tuple[Optional[int], Optional[int]]] = None,
        highlight_lines: Optional[Set[int]] = None,
        code_width: Optional[int] = None,
        tab_size: int = 4,
        word_wrap: bool = False,
        background_color: Optional[str] = None,
        indent_guides: bool = False,
        padding: PaddingDimensions = 0,
    ) -> None:
        self.code = code
        self._lexer = lexer
        self.dedent = dedent
        self.line_numbers = line_numbers
        self.start_line = start_line
        self.line_range = line_range
        self.highlight_lines = highlight_lines or set()
        self.code_width = code_width
        self.tab_size = tab_size
        self.word_wrap = word_wrap
        self.background_color = background_color
        self.background_style = (
            Style(bgcolor=background_color) if background_color else Style()
        )
        self.indent_guides = indent_guides
        self._padding = Padding.unpack(padding)

        self._theme = self.get_theme(theme)
        self._stylized_ranges: List[_SyntaxHighlightRange] = []

    padding = PaddingProperty()

    @classmethod
    def from_path(
        cls,
        path: str,
        encoding: str = ""utf-8"",
        lexer: Optional[Union[Lexer, str]] = None,
        theme: Union[str, SyntaxTheme] = DEFAULT_THEME,
        dedent: bool = False,
        line_numbers: bool = False,
        line_range: Optional[Tuple[int, int]] = None,
        start_line: int = 1,
        highlight_lines: Optional[Set[int]] = None,
        code_width: Optional[int] = None,
        tab_size: int = 4,
        word_wrap: bool = False,
        background_color: Optional[str] = None,
        indent_guides: bool = False,
        padding: PaddingDimensions = 0,
    ) -> ""Syntax"":
        
        code = Path(path).read_text(encoding=encoding)

        if not lexer:
            lexer = cls.guess_lexer(path, code=code)

        return cls(
            code,
            lexer,
            theme=theme,
            dedent=dedent,
            line_numbers=line_numbers,
            line_range=line_range,
            start_line=start_line,
            highlight_lines=highlight_lines,
            code_width=code_width,
            tab_size=tab_size,
            word_wrap=word_wrap,
            background_color=background_color,
            indent_guides=indent_guides,
            padding=padding,
        )

    @classmethod
    def guess_lexer(cls, path: str, code: Optional[str] = None) -> str:
        
        lexer: Optional[Lexer] = None
        lexer_name = ""default""
        if code:
            try:
                lexer = guess_lexer_for_filename(path, code)
            except ClassNotFound:
                pass

        if not lexer:
            try:
                _, ext = os.path.splitext(path)
                if ext:
                    extension = ext.lstrip(""."").lower()
                    lexer = get_lexer_by_name(extension)
            except ClassNotFound:
                pass

        if lexer:
            if lexer.aliases:
                lexer_name = lexer.aliases[0]
            else:
                lexer_name = lexer.name

        return lexer_name

    def _get_base_style(self) -> Style:
        
        default_style = self._theme.get_background_style() + self.background_style
        return default_style

    def _get_token_color(self, token_type: TokenType) -> Optional[Color]:
        
        style = self._theme.get_style_for_token(token_type)
        return style.color

    @property
    def lexer(self) -> Optional[Lexer]:
        

        if isinstance(self._lexer, Lexer):
            return self._lexer
        try:
            return get_lexer_by_name(
                self._lexer,
                stripnl=False,
                ensurenl=True,
                tabsize=self.tab_size,
            )
        except ClassNotFound:
            return None

    @property
    def default_lexer(self) -> Lexer:
        
        return get_lexer_by_name(
            ""text"",
            stripnl=False,
            ensurenl=True,
            tabsize=self.tab_size,
        )

    def highlight(
        self,
        code: str,
        line_range: Optional[Tuple[Optional[int], Optional[int]]] = None,
    ) -> Text:
        

        base_style = self._get_base_style()
        justify: JustifyMethod = (
            ""default"" if base_style.transparent_background else ""left""
        )

        text = Text(
            justify=justify,
            style=base_style,
            tab_size=self.tab_size,
            no_wrap=not self.word_wrap,
        )
        _get_theme_style = self._theme.get_style_for_token

        lexer = self.lexer or self.default_lexer

        if lexer is None:
            text.append(code)
        else:
            if line_range:
                
                
                line_start, line_end = line_range

                def line_tokenize() -> Iterable[Tuple[Any, str]]:
                    
                    assert lexer  

                    for token_type, token in lexer.get_tokens(code):
                        while token:
                            line_token, new_line, token = token.partition(""\n"")
                            yield token_type, line_token + new_line

                def tokens_to_spans() -> Iterable[Tuple[str, Optional[Style]]]:
                    
                    tokens = iter(line_tokenize())
                    line_no = 0
                    _line_start = line_start - 1 if line_start else 0

                    
                    while line_no < _line_start:
                        try:
                            _token_type, token = next(tokens)
                        except StopIteration:
                            break
                        yield (token, None)
                        if token.endswith(""\n""):
                            line_no += 1
                    
                    for token_type, token in tokens:
                        yield (token, _get_theme_style(token_type))
                        if token.endswith(""\n""):
                            line_no += 1
                            if line_end and line_no >= line_end:
                                break

                text.append_tokens(tokens_to_spans())

            else:
                text.append_tokens(
                    (token, _get_theme_style(token_type))
                    for token_type, token in lexer.get_tokens(code)
                )
            if self.background_color is not None:
                text.stylize(f""on {self.background_color}"")

        if self._stylized_ranges:
            self._apply_stylized_ranges(text)

        return text

    def stylize_range(
        self,
        style: StyleType,
        start: SyntaxPosition,
        end: SyntaxPosition,
        style_before: bool = False,
    ) -> None:
        
        self._stylized_ranges.append(
            _SyntaxHighlightRange(style, start, end, style_before)
        )

    def _get_line_numbers_color(self, blend: float = 0.3) -> Color:
        background_style = self._theme.get_background_style() + self.background_style
        background_color = background_style.bgcolor
        if background_color is None or background_color.is_system_defined:
            return Color.default()
        foreground_color = self._get_token_color(Token.Text)
        if foreground_color is None or foreground_color.is_system_defined:
            return foreground_color or Color.default()
        new_color = blend_rgb(
            background_color.get_truecolor(),
            foreground_color.get_truecolor(),
            cross_fade=blend,
        )
        return Color.from_triplet(new_color)

    @property
    def _numbers_column_width(self) -> int:
        
        column_width = 0
        if self.line_numbers:
            column_width = (
                len(str(self.start_line + self.code.count(""\n"")))
                + NUMBERS_COLUMN_DEFAULT_PADDING
            )
        return column_width

    def _get_number_styles(self, console: Console) -> Tuple[Style, Style, Style]:
        
        background_style = self._get_base_style()
        if background_style.transparent_background:
            return Style.null(), Style(dim=True), Style.null()
        if console.color_system in (""256"", ""truecolor""):
            number_style = Style.chain(
                background_style,
                self._theme.get_style_for_token(Token.Text),
                Style(color=self._get_line_numbers_color()),
                self.background_style,
            )
            highlight_number_style = Style.chain(
                background_style,
                self._theme.get_style_for_token(Token.Text),
                Style(bold=True, color=self._get_line_numbers_color(0.9)),
                self.background_style,
            )
        else:
            number_style = background_style + Style(dim=True)
            highlight_number_style = background_style + Style(dim=False)
        return background_style, number_style, highlight_number_style

    def __rich_measure__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> ""Measurement"":
        _, right, _, left = self.padding
        padding = left + right
        if self.code_width is not None:
            width = self.code_width + self._numbers_column_width + padding + 1
            return Measurement(self._numbers_column_width, width)
        lines = self.code.splitlines()
        width = (
            self._numbers_column_width
            + padding
            + (max(cell_len(line) for line in lines) if lines else 0)
        )
        if self.line_numbers:
            width += 1
        return Measurement(self._numbers_column_width, width)

    def __rich_console__(
        self, console: Console, options: ConsoleOptions
    ) -> RenderResult:
        segments = Segments(self._get_syntax(console, options))
        if any(self.padding):
            yield Padding(segments, style=self._get_base_style(), pad=self.padding)
        else:
            yield segments

    def _get_syntax(
        self,
        console: Console,
        options: ConsoleOptions,
    ) -> Iterable[Segment]:
        
        transparent_background = self._get_base_style().transparent_background
        _pad_top, pad_right, _pad_bottom, pad_left = self.padding
        horizontal_padding = pad_left + pad_right
        code_width = (
            (
                (options.max_width - self._numbers_column_width - 1)
                if self.line_numbers
                else options.max_width
            )
            - horizontal_padding
            if self.code_width is None
            else self.code_width
        )
        code_width = max(0, code_width)

        ends_on_nl, processed_code = self._process_code(self.code)
        text = self.highlight(processed_code, self.line_range)

        if not self.line_numbers and not self.word_wrap and not self.line_range:
            if not ends_on_nl:
                text.remove_suffix(""\n"")
            
            style = (
                self._get_base_style()
                + self._theme.get_style_for_token(Comment)
                + Style(dim=True)
                + self.background_style
            )
            if self.indent_guides and not options.ascii_only:
                text = text.with_indent_guides(self.tab_size, style=style)
                text.overflow = ""crop""
            if style.transparent_background:
                yield from console.render(
                    text, options=options.update(width=code_width)
                )
            else:
                syntax_lines = console.render_lines(
                    text,
                    options.update(width=code_width, height=None, justify=""left""),
                    style=self.background_style,
                    pad=True,
                    new_lines=True,
                )
                for syntax_line in syntax_lines:
                    yield from syntax_line
            return

        start_line, end_line = self.line_range or (None, None)
        line_offset = 0
        if start_line:
            line_offset = max(0, start_line - 1)
        lines: Union[List[Text], Lines] = text.split(""\n"", allow_blank=ends_on_nl)
        if self.line_range:
            if line_offset > len(lines):
                return
            lines = lines[line_offset:end_line]

        if self.indent_guides and not options.ascii_only:
            style = (
                self._get_base_style()
                + self._theme.get_style_for_token(Comment)
                + Style(dim=True)
                + self.background_style
            )
            lines = (
                Text(""\n"")
                .join(lines)
                .with_indent_guides(self.tab_size, style=style + Style(italic=False))
                .split(""\n"", allow_blank=True)
            )

        numbers_column_width = self._numbers_column_width
        render_options = options.update(width=code_width)

        highlight_line = self.highlight_lines.__contains__
        _Segment = Segment
        new_line = _Segment(""\n"")

        line_pointer = ""> "" if options.legacy_windows else ""❱ ""

        (
            background_style,
            number_style,
            highlight_number_style,
        ) = self._get_number_styles(console)

        for line_no, line in enumerate(lines, self.start_line + line_offset):
            if self.word_wrap:
                wrapped_lines = console.render_lines(
                    line,
                    render_options.update(height=None, justify=""left""),
                    style=background_style,
                    pad=not transparent_background,
                )
            else:
                segments = list(line.render(console, end=""""))
                if options.no_wrap:
                    wrapped_lines = [segments]
                else:
                    wrapped_lines = [
                        _Segment.adjust_line_length(
                            segments,
                            render_options.max_width,
                            style=background_style,
                            pad=not transparent_background,
                        )
                    ]

            if self.line_numbers:
                wrapped_line_left_pad = _Segment(
                    "" "" * numbers_column_width + "" "", background_style
                )
                for first, wrapped_line in loop_first(wrapped_lines):
                    if first:
                        line_column = str(line_no).rjust(numbers_column_width - 2) + "" ""
                        if highlight_line(line_no):
                            yield _Segment(line_pointer, Style(color=""red""))
                            yield _Segment(line_column, highlight_number_style)
                        else:
                            yield _Segment(""  "", highlight_number_style)
                            yield _Segment(line_column, number_style)
                    else:
                        yield wrapped_line_left_pad
                    yield from wrapped_line
                    yield new_line
            else:
                for wrapped_line in wrapped_lines:
                    yield from wrapped_line
                    yield new_line

    def _apply_stylized_ranges(self, text: Text) -> None:
        
        code = text.plain
        newlines_offsets = [
            
            0,
            
            *[
                match.start() + 1
                for match in re.finditer(""\n"", code, flags=re.MULTILINE)
            ],
            len(code) + 1,
        ]

        for stylized_range in self._stylized_ranges:
            start = _get_code_index_for_syntax_position(
                newlines_offsets, stylized_range.start
            )
            end = _get_code_index_for_syntax_position(
                newlines_offsets, stylized_range.end
            )
            if start is not None and end is not None:
                if stylized_range.style_before:
                    text.stylize_before(stylized_range.style, start, end)
                else:
                    text.stylize(stylized_range.style, start, end)

    def _process_code(self, code: str) -> Tuple[bool, str]:
        
        ends_on_nl = code.endswith(""\n"")
        processed_code = code if ends_on_nl else code + ""\n""
        processed_code = (
            textwrap.dedent(processed_code) if self.dedent else processed_code
        )
        processed_code = processed_code.expandtabs(self.tab_size)
        return ends_on_nl, processed_code


def _get_code_index_for_syntax_position(
    newlines_offsets: Sequence[int], position: SyntaxPosition
) -> Optional[int]:
    
    lines_count = len(newlines_offsets)

    line_number, column_index = position
    if line_number > lines_count or len(newlines_offsets) < (line_number + 1):
        return None  
    line_index = line_number - 1
    line_length = newlines_offsets[line_index + 1] - newlines_offsets[line_index] - 1
    
    column_index = min(line_length, column_index)
    return newlines_offsets[line_index] + column_index


if __name__ == ""__main__"":  
    import argparse
    import sys

    parser = argparse.ArgumentParser(
        description=""Render syntax to the console with Rich""
    )
    parser.add_argument(
        ""path"",
        metavar=""PATH"",
        help=""path to file, or - for stdin"",
    )
    parser.add_argument(
        ""-c"",
        ""--force-color"",
        dest=""force_color"",
        action=""store_true"",
        default=None,
        help=""force color for non-terminals"",
    )
    parser.add_argument(
        ""-i"",
        ""--indent-guides"",
        dest=""indent_guides"",
        action=""store_true"",
        default=False,
        help=""display indent guides"",
    )
    parser.add_argument(
        ""-l"",
        ""--line-numbers"",
        dest=""line_numbers"",
        action=""store_true"",
        help=""render line numbers"",
    )
    parser.add_argument(
        ""-w"",
        ""--width"",
        type=int,
        dest=""width"",
        default=None,
        help=""width of output (default will auto-detect)"",
    )
    parser.add_argument(
        ""-r"",
        ""--wrap"",
        dest=""word_wrap"",
        action=""store_true"",
        default=False,
        help=""word wrap long lines"",
    )
    parser.add_argument(
        ""-s"",
        ""--soft-wrap"",
        action=""store_true"",
        dest=""soft_wrap"",
        default=False,
        help=""enable soft wrapping mode"",
    )
    parser.add_argument(
        ""-t"", ""--theme"", dest=""theme"", default=""monokai"", help=""pygments theme""
    )
    parser.add_argument(
        ""-b"",
        ""--background-color"",
        dest=""background_color"",
        default=None,
        help=""Override background color"",
    )
    parser.add_argument(
        ""-x"",
        ""--lexer"",
        default=None,
        dest=""lexer_name"",
        help=""Lexer name"",
    )
    parser.add_argument(
        ""-p"", ""--padding"", type=int, default=0, dest=""padding"", help=""Padding""
    )
    parser.add_argument(
        ""--highlight-line"",
        type=int,
        default=None,
        dest=""highlight_line"",
        help=""The line number (not index!) to highlight"",
    )
    args = parser.parse_args()

    from pip._vendor.rich.console import Console

    console = Console(force_terminal=args.force_color, width=args.width)

    if args.path == ""-"":
        code = sys.stdin.read()
        syntax = Syntax(
            code=code,
            lexer=args.lexer_name,
            line_numbers=args.line_numbers,
            word_wrap=args.word_wrap,
            theme=args.theme,
            background_color=args.background_color,
            indent_guides=args.indent_guides,
            padding=args.padding,
            highlight_lines={args.highlight_line},
        )
    else:
        syntax = Syntax.from_path(
            args.path,
            lexer=args.lexer_name,
            line_numbers=args.line_numbers,
            word_wrap=args.word_wrap,
            theme=args.theme,
            background_color=args.background_color,
            indent_guides=args.indent_guides,
            padding=args.padding,
            highlight_lines={args.highlight_line},
        )
    console.print(syntax, soft_wrap=args.soft_wrap)

from dataclasses import dataclass, field, replace
from typing import (
    TYPE_CHECKING,
    Dict,
    Iterable,
    List,
    NamedTuple,
    Optional,
    Sequence,
    Tuple,
    Union,
)

from . import box, errors
from ._loop import loop_first_last, loop_last
from ._pick import pick_bool
from ._ratio import ratio_distribute, ratio_reduce
from .align import VerticalAlignMethod
from .jupyter import JupyterMixin
from .measure import Measurement
from .padding import Padding, PaddingDimensions
from .protocol import is_renderable
from .segment import Segment
from .style import Style, StyleType
from .text import Text, TextType

if TYPE_CHECKING:
    from .console import (
        Console,
        ConsoleOptions,
        JustifyMethod,
        OverflowMethod,
        RenderableType,
        RenderResult,
    )


@dataclass
class Column:
    

    header: ""RenderableType"" = """"
    

    footer: ""RenderableType"" = """"
    

    header_style: StyleType = """"
    

    footer_style: StyleType = """"
    

    style: StyleType = """"
    

    justify: ""JustifyMethod"" = ""left""
    

    vertical: ""VerticalAlignMethod"" = ""top""
    

    overflow: ""OverflowMethod"" = ""ellipsis""
    

    width: Optional[int] = None
    

    min_width: Optional[int] = None
    

    max_width: Optional[int] = None
    

    ratio: Optional[int] = None
    

    no_wrap: bool = False
    

    highlight: bool = False
    

    _index: int = 0
    

    _cells: List[""RenderableType""] = field(default_factory=list)

    def copy(self) -> ""Column"":
        
        return replace(self, _cells=[])

    @property
    def cells(self) -> Iterable[""RenderableType""]:
        
        yield from self._cells

    @property
    def flexible(self) -> bool:
        
        return self.ratio is not None


@dataclass
class Row:
    

    style: Optional[StyleType] = None
    

    end_section: bool = False
    


class _Cell(NamedTuple):
    

    style: StyleType
    
    renderable: ""RenderableType""
    
    vertical: VerticalAlignMethod
    


class Table(JupyterMixin):
    

    columns: List[Column]
    rows: List[Row]

    def __init__(
        self,
        *headers: Union[Column, str],
        title: Optional[TextType] = None,
        caption: Optional[TextType] = None,
        width: Optional[int] = None,
        min_width: Optional[int] = None,
        box: Optional[box.Box] = box.HEAVY_HEAD,
        safe_box: Optional[bool] = None,
        padding: PaddingDimensions = (0, 1),
        collapse_padding: bool = False,
        pad_edge: bool = True,
        expand: bool = False,
        show_header: bool = True,
        show_footer: bool = False,
        show_edge: bool = True,
        show_lines: bool = False,
        leading: int = 0,
        style: StyleType = ""none"",
        row_styles: Optional[Iterable[StyleType]] = None,
        header_style: Optional[StyleType] = ""table.header"",
        footer_style: Optional[StyleType] = ""table.footer"",
        border_style: Optional[StyleType] = None,
        title_style: Optional[StyleType] = None,
        caption_style: Optional[StyleType] = None,
        title_justify: ""JustifyMethod"" = ""center"",
        caption_justify: ""JustifyMethod"" = ""center"",
        highlight: bool = False,
    ) -> None:
        self.columns: List[Column] = []
        self.rows: List[Row] = []
        self.title = title
        self.caption = caption
        self.width = width
        self.min_width = min_width
        self.box = box
        self.safe_box = safe_box
        self._padding = Padding.unpack(padding)
        self.pad_edge = pad_edge
        self._expand = expand
        self.show_header = show_header
        self.show_footer = show_footer
        self.show_edge = show_edge
        self.show_lines = show_lines
        self.leading = leading
        self.collapse_padding = collapse_padding
        self.style = style
        self.header_style = header_style or """"
        self.footer_style = footer_style or """"
        self.border_style = border_style
        self.title_style = title_style
        self.caption_style = caption_style
        self.title_justify: ""JustifyMethod"" = title_justify
        self.caption_justify: ""JustifyMethod"" = caption_justify
        self.highlight = highlight
        self.row_styles: Sequence[StyleType] = list(row_styles or [])
        append_column = self.columns.append
        for header in headers:
            if isinstance(header, str):
                self.add_column(header=header)
            else:
                header._index = len(self.columns)
                append_column(header)

    @classmethod
    def grid(
        cls,
        *headers: Union[Column, str],
        padding: PaddingDimensions = 0,
        collapse_padding: bool = True,
        pad_edge: bool = False,
        expand: bool = False,
    ) -> ""Table"":
        
        return cls(
            *headers,
            box=None,
            padding=padding,
            collapse_padding=collapse_padding,
            show_header=False,
            show_footer=False,
            show_edge=False,
            pad_edge=pad_edge,
            expand=expand,
        )

    @property
    def expand(self) -> bool:
        
        return self._expand or self.width is not None

    @expand.setter
    def expand(self, expand: bool) -> None:
        
        self._expand = expand

    @property
    def _extra_width(self) -> int:
        
        width = 0
        if self.box and self.show_edge:
            width += 2
        if self.box:
            width += len(self.columns) - 1
        return width

    @property
    def row_count(self) -> int:
        
        return len(self.rows)

    def get_row_style(self, console: ""Console"", index: int) -> StyleType:
        
        style = Style.null()
        if self.row_styles:
            style += console.get_style(self.row_styles[index % len(self.row_styles)])
        row_style = self.rows[index].style
        if row_style is not None:
            style += console.get_style(row_style)
        return style

    def __rich_measure__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> Measurement:
        max_width = options.max_width
        if self.width is not None:
            max_width = self.width
        if max_width < 0:
            return Measurement(0, 0)

        extra_width = self._extra_width
        max_width = sum(
            self._calculate_column_widths(
                console, options.update_width(max_width - extra_width)
            )
        )
        _measure_column = self._measure_column

        measurements = [
            _measure_column(console, options.update_width(max_width), column)
            for column in self.columns
        ]
        minimum_width = (
            sum(measurement.minimum for measurement in measurements) + extra_width
        )
        maximum_width = (
            sum(measurement.maximum for measurement in measurements) + extra_width
            if (self.width is None)
            else self.width
        )
        measurement = Measurement(minimum_width, maximum_width)
        measurement = measurement.clamp(self.min_width)
        return measurement

    @property
    def padding(self) -> Tuple[int, int, int, int]:
        
        return self._padding

    @padding.setter
    def padding(self, padding: PaddingDimensions) -> ""Table"":
        
        self._padding = Padding.unpack(padding)
        return self

    def add_column(
        self,
        header: ""RenderableType"" = """",
        footer: ""RenderableType"" = """",
        *,
        header_style: Optional[StyleType] = None,
        highlight: Optional[bool] = None,
        footer_style: Optional[StyleType] = None,
        style: Optional[StyleType] = None,
        justify: ""JustifyMethod"" = ""left"",
        vertical: ""VerticalAlignMethod"" = ""top"",
        overflow: ""OverflowMethod"" = ""ellipsis"",
        width: Optional[int] = None,
        min_width: Optional[int] = None,
        max_width: Optional[int] = None,
        ratio: Optional[int] = None,
        no_wrap: bool = False,
    ) -> None:
        

        column = Column(
            _index=len(self.columns),
            header=header,
            footer=footer,
            header_style=header_style or """",
            highlight=highlight if highlight is not None else self.highlight,
            footer_style=footer_style or """",
            style=style or """",
            justify=justify,
            vertical=vertical,
            overflow=overflow,
            width=width,
            min_width=min_width,
            max_width=max_width,
            ratio=ratio,
            no_wrap=no_wrap,
        )
        self.columns.append(column)

    def add_row(
        self,
        *renderables: Optional[""RenderableType""],
        style: Optional[StyleType] = None,
        end_section: bool = False,
    ) -> None:
        

        def add_cell(column: Column, renderable: ""RenderableType"") -> None:
            column._cells.append(renderable)

        cell_renderables: List[Optional[""RenderableType""]] = list(renderables)

        columns = self.columns
        if len(cell_renderables) < len(columns):
            cell_renderables = [
                *cell_renderables,
                *[None] * (len(columns) - len(cell_renderables)),
            ]
        for index, renderable in enumerate(cell_renderables):
            if index == len(columns):
                column = Column(_index=index, highlight=self.highlight)
                for _ in self.rows:
                    add_cell(column, Text(""""))
                self.columns.append(column)
            else:
                column = columns[index]
            if renderable is None:
                add_cell(column, """")
            elif is_renderable(renderable):
                add_cell(column, renderable)
            else:
                raise errors.NotRenderableError(
                    f""unable to render {type(renderable).__name__}; a string or other renderable object is required""
                )
        self.rows.append(Row(style=style, end_section=end_section))

    def add_section(self) -> None:
        

        if self.rows:
            self.rows[-1].end_section = True

    def __rich_console__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> ""RenderResult"":
        if not self.columns:
            yield Segment(""\n"")
            return

        max_width = options.max_width
        if self.width is not None:
            max_width = self.width

        extra_width = self._extra_width
        widths = self._calculate_column_widths(
            console, options.update_width(max_width - extra_width)
        )
        table_width = sum(widths) + extra_width

        render_options = options.update(
            width=table_width, highlight=self.highlight, height=None
        )

        def render_annotation(
            text: TextType, style: StyleType, justify: ""JustifyMethod"" = ""center""
        ) -> ""RenderResult"":
            render_text = (
                console.render_str(text, style=style, highlight=False)
                if isinstance(text, str)
                else text
            )
            return console.render(
                render_text, options=render_options.update(justify=justify)
            )

        if self.title:
            yield from render_annotation(
                self.title,
                style=Style.pick_first(self.title_style, ""table.title""),
                justify=self.title_justify,
            )
        yield from self._render(console, render_options, widths)
        if self.caption:
            yield from render_annotation(
                self.caption,
                style=Style.pick_first(self.caption_style, ""table.caption""),
                justify=self.caption_justify,
            )

    def _calculate_column_widths(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> List[int]:
        
        max_width = options.max_width
        columns = self.columns
        width_ranges = [
            self._measure_column(console, options, column) for column in columns
        ]
        widths = [_range.maximum or 1 for _range in width_ranges]
        get_padding_width = self._get_padding_width
        extra_width = self._extra_width
        if self.expand:
            ratios = [col.ratio or 0 for col in columns if col.flexible]
            if any(ratios):
                fixed_widths = [
                    0 if column.flexible else _range.maximum
                    for _range, column in zip(width_ranges, columns)
                ]
                flex_minimum = [
                    (column.width or 1) + get_padding_width(column._index)
                    for column in columns
                    if column.flexible
                ]
                flexible_width = max_width - sum(fixed_widths)
                flex_widths = ratio_distribute(flexible_width, ratios, flex_minimum)
                iter_flex_widths = iter(flex_widths)
                for index, column in enumerate(columns):
                    if column.flexible:
                        widths[index] = fixed_widths[index] + next(iter_flex_widths)
        table_width = sum(widths)

        if table_width > max_width:
            widths = self._collapse_widths(
                widths,
                [(column.width is None and not column.no_wrap) for column in columns],
                max_width,
            )
            table_width = sum(widths)
            
            if table_width > max_width:
                excess_width = table_width - max_width
                widths = ratio_reduce(excess_width, [1] * len(widths), widths, widths)
                table_width = sum(widths)

            width_ranges = [
                self._measure_column(console, options.update_width(width), column)
                for width, column in zip(widths, columns)
            ]
            widths = [_range.maximum or 0 for _range in width_ranges]

        if (table_width < max_width and self.expand) or (
            self.min_width is not None and table_width < (self.min_width - extra_width)
        ):
            _max_width = (
                max_width
                if self.min_width is None
                else min(self.min_width - extra_width, max_width)
            )
            pad_widths = ratio_distribute(_max_width - table_width, widths)
            widths = [_width + pad for _width, pad in zip(widths, pad_widths)]

        return widths

    @classmethod
    def _collapse_widths(
        cls, widths: List[int], wrapable: List[bool], max_width: int
    ) -> List[int]:
        
        total_width = sum(widths)
        excess_width = total_width - max_width
        if any(wrapable):
            while total_width and excess_width > 0:
                max_column = max(
                    width for width, allow_wrap in zip(widths, wrapable) if allow_wrap
                )
                second_max_column = max(
                    width if allow_wrap and width != max_column else 0
                    for width, allow_wrap in zip(widths, wrapable)
                )
                column_difference = max_column - second_max_column
                ratios = [
                    (1 if (width == max_column and allow_wrap) else 0)
                    for width, allow_wrap in zip(widths, wrapable)
                ]
                if not any(ratios) or not column_difference:
                    break
                max_reduce = [min(excess_width, column_difference)] * len(widths)
                widths = ratio_reduce(excess_width, ratios, max_reduce, widths)

                total_width = sum(widths)
                excess_width = total_width - max_width
        return widths

    def _get_cells(
        self, console: ""Console"", column_index: int, column: Column
    ) -> Iterable[_Cell]:
        

        collapse_padding = self.collapse_padding
        pad_edge = self.pad_edge
        padding = self.padding
        any_padding = any(padding)

        first_column = column_index == 0
        last_column = column_index == len(self.columns) - 1

        _padding_cache: Dict[Tuple[bool, bool], Tuple[int, int, int, int]] = {}

        def get_padding(first_row: bool, last_row: bool) -> Tuple[int, int, int, int]:
            cached = _padding_cache.get((first_row, last_row))
            if cached:
                return cached
            top, right, bottom, left = padding

            if collapse_padding:
                if not first_column:
                    left = max(0, left - right)
                if not last_row:
                    bottom = max(0, top - bottom)

            if not pad_edge:
                if first_column:
                    left = 0
                if last_column:
                    right = 0
                if first_row:
                    top = 0
                if last_row:
                    bottom = 0
            _padding = (top, right, bottom, left)
            _padding_cache[(first_row, last_row)] = _padding
            return _padding

        raw_cells: List[Tuple[StyleType, ""RenderableType""]] = []
        _append = raw_cells.append
        get_style = console.get_style
        if self.show_header:
            header_style = get_style(self.header_style or """") + get_style(
                column.header_style
            )
            _append((header_style, column.header))
        cell_style = get_style(column.style or """")
        for cell in column.cells:
            _append((cell_style, cell))
        if self.show_footer:
            footer_style = get_style(self.footer_style or """") + get_style(
                column.footer_style
            )
            _append((footer_style, column.footer))

        if any_padding:
            _Padding = Padding
            for first, last, (style, renderable) in loop_first_last(raw_cells):
                yield _Cell(
                    style,
                    _Padding(renderable, get_padding(first, last)),
                    getattr(renderable, ""vertical"", None) or column.vertical,
                )
        else:
            for style, renderable in raw_cells:
                yield _Cell(
                    style,
                    renderable,
                    getattr(renderable, ""vertical"", None) or column.vertical,
                )

    def _get_padding_width(self, column_index: int) -> int:
        
        _, pad_right, _, pad_left = self.padding
        if self.collapse_padding:
            if column_index > 0:
                pad_left = max(0, pad_left - pad_right)
        return pad_left + pad_right

    def _measure_column(
        self,
        console: ""Console"",
        options: ""ConsoleOptions"",
        column: Column,
    ) -> Measurement:
        

        max_width = options.max_width
        if max_width < 1:
            return Measurement(0, 0)

        padding_width = self._get_padding_width(column._index)

        if column.width is not None:
            
            return Measurement(
                column.width + padding_width, column.width + padding_width
            ).with_maximum(max_width)
        
        min_widths: List[int] = []
        max_widths: List[int] = []
        append_min = min_widths.append
        append_max = max_widths.append
        get_render_width = Measurement.get
        for cell in self._get_cells(console, column._index, column):
            _min, _max = get_render_width(console, options, cell.renderable)
            append_min(_min)
            append_max(_max)

        measurement = Measurement(
            max(min_widths) if min_widths else 1,
            max(max_widths) if max_widths else max_width,
        ).with_maximum(max_width)
        measurement = measurement.clamp(
            None if column.min_width is None else column.min_width + padding_width,
            None if column.max_width is None else column.max_width + padding_width,
        )
        return measurement

    def _render(
        self, console: ""Console"", options: ""ConsoleOptions"", widths: List[int]
    ) -> ""RenderResult"":
        table_style = console.get_style(self.style or """")

        border_style = table_style + console.get_style(self.border_style or """")
        _column_cells = (
            self._get_cells(console, column_index, column)
            for column_index, column in enumerate(self.columns)
        )
        row_cells: List[Tuple[_Cell, ...]] = list(zip(*_column_cells))
        _box = (
            self.box.substitute(
                options, safe=pick_bool(self.safe_box, console.safe_box)
            )
            if self.box
            else None
        )
        _box = _box.get_plain_headed_box() if _box and not self.show_header else _box

        new_line = Segment.line()

        columns = self.columns
        show_header = self.show_header
        show_footer = self.show_footer
        show_edge = self.show_edge
        show_lines = self.show_lines
        leading = self.leading

        _Segment = Segment
        if _box:
            box_segments = [
                (
                    _Segment(_box.head_left, border_style),
                    _Segment(_box.head_right, border_style),
                    _Segment(_box.head_vertical, border_style),
                ),
                (
                    _Segment(_box.mid_left, border_style),
                    _Segment(_box.mid_right, border_style),
                    _Segment(_box.mid_vertical, border_style),
                ),
                (
                    _Segment(_box.foot_left, border_style),
                    _Segment(_box.foot_right, border_style),
                    _Segment(_box.foot_vertical, border_style),
                ),
            ]
            if show_edge:
                yield _Segment(_box.get_top(widths), border_style)
                yield new_line
        else:
            box_segments = []

        get_row_style = self.get_row_style
        get_style = console.get_style

        for index, (first, last, row_cell) in enumerate(loop_first_last(row_cells)):
            header_row = first and show_header
            footer_row = last and show_footer
            row = (
                self.rows[index - show_header]
                if (not header_row and not footer_row)
                else None
            )
            max_height = 1
            cells: List[List[List[Segment]]] = []
            if header_row or footer_row:
                row_style = Style.null()
            else:
                row_style = get_style(
                    get_row_style(console, index - 1 if show_header else index)
                )
            for width, cell, column in zip(widths, row_cell, columns):
                render_options = options.update(
                    width=width,
                    justify=column.justify,
                    no_wrap=column.no_wrap,
                    overflow=column.overflow,
                    height=None,
                    highlight=column.highlight,
                )
                lines = console.render_lines(
                    cell.renderable,
                    render_options,
                    style=get_style(cell.style) + row_style,
                )
                max_height = max(max_height, len(lines))
                cells.append(lines)

            row_height = max(len(cell) for cell in cells)

            def align_cell(
                cell: List[List[Segment]],
                vertical: ""VerticalAlignMethod"",
                width: int,
                style: Style,
            ) -> List[List[Segment]]:
                if header_row:
                    vertical = ""bottom""
                elif footer_row:
                    vertical = ""top""

                if vertical == ""top"":
                    return _Segment.align_top(cell, width, row_height, style)
                elif vertical == ""middle"":
                    return _Segment.align_middle(cell, width, row_height, style)
                return _Segment.align_bottom(cell, width, row_height, style)

            cells[:] = [
                _Segment.set_shape(
                    align_cell(
                        cell,
                        _cell.vertical,
                        width,
                        get_style(_cell.style) + row_style,
                    ),
                    width,
                    max_height,
                )
                for width, _cell, cell, column in zip(widths, row_cell, cells, columns)
            ]

            if _box:
                if last and show_footer:
                    yield _Segment(
                        _box.get_row(widths, ""foot"", edge=show_edge), border_style
                    )
                    yield new_line
                left, right, _divider = box_segments[0 if first else (2 if last else 1)]

                
                divider = (
                    _divider
                    if _divider.text.strip()
                    else _Segment(
                        _divider.text, row_style.background_style + _divider.style
                    )
                )
                for line_no in range(max_height):
                    if show_edge:
                        yield left
                    for last_cell, rendered_cell in loop_last(cells):
                        yield from rendered_cell[line_no]
                        if not last_cell:
                            yield divider
                    if show_edge:
                        yield right
                    yield new_line
            else:
                for line_no in range(max_height):
                    for rendered_cell in cells:
                        yield from rendered_cell[line_no]
                    yield new_line
            if _box and first and show_header:
                yield _Segment(
                    _box.get_row(widths, ""head"", edge=show_edge), border_style
                )
                yield new_line
            end_section = row and row.end_section
            if _box and (show_lines or leading or end_section):
                if (
                    not last
                    and not (show_footer and index >= len(row_cells) - 2)
                    and not (show_header and header_row)
                ):
                    if leading:
                        yield _Segment(
                            _box.get_row(widths, ""mid"", edge=show_edge) * leading,
                            border_style,
                        )
                    else:
                        yield _Segment(
                            _box.get_row(widths, ""row"", edge=show_edge), border_style
                        )
                    yield new_line

        if _box and show_edge:
            yield _Segment(_box.get_bottom(widths), border_style)
            yield new_line


if __name__ == ""__main__"":  
    from pip._vendor.rich.console import Console
    from pip._vendor.rich.highlighter import ReprHighlighter

    from ._timer import timer

    with timer(""Table render""):
        table = Table(
            title=""Star Wars Movies"",
            caption=""Rich example table"",
            caption_justify=""right"",
        )

        table.add_column(
            ""Released"", header_style=""bright_cyan"", style=""cyan"", no_wrap=True
        )
        table.add_column(""Title"", style=""magenta"")
        table.add_column(""Box Office"", justify=""right"", style=""green"")

        table.add_row(
            ""Dec 20, 2019"",
            ""Star Wars: The Rise of Skywalker"",
            ""$952,110,690"",
        )
        table.add_row(""May 25, 2018"", ""Solo: A Star Wars Story"", ""$393,151,347"")
        table.add_row(
            ""Dec 15, 2017"",
            ""Star Wars Ep. V111: The Last Jedi"",
            ""$1,332,539,889"",
            style=""on black"",
            end_section=True,
        )
        table.add_row(
            ""Dec 16, 2016"",
            ""Rogue One: A Star Wars Story"",
            ""$1,332,439,889"",
        )

        def header(text: str) -> None:
            console.print()
            console.rule(highlight(text))
            console.print()

        console = Console()
        highlight = ReprHighlighter()
        header(""Example Table"")
        console.print(table, justify=""center"")

        table.expand = True
        header(""expand=True"")
        console.print(table)

        table.width = 50
        header(""width=50"")

        console.print(table, justify=""center"")

        table.width = None
        table.expand = False
        table.row_styles = [""dim"", ""none""]
        header(""row_styles=['dim', 'none']"")

        console.print(table, justify=""center"")

        table.width = None
        table.expand = False
        table.row_styles = [""dim"", ""none""]
        table.leading = 1
        header(""leading=1, row_styles=['dim', 'none']"")
        console.print(table, justify=""center"")

        table.width = None
        table.expand = False
        table.row_styles = [""dim"", ""none""]
        table.show_lines = True
        table.leading = 0
        header(""show_lines=True, row_styles=['dim', 'none']"")
        console.print(table, justify=""center"")

from typing import List, Optional, Tuple

from .color_triplet import ColorTriplet
from .palette import Palette

_ColorTuple = Tuple[int, int, int]


class TerminalTheme:
    

    def __init__(
        self,
        background: _ColorTuple,
        foreground: _ColorTuple,
        normal: List[_ColorTuple],
        bright: Optional[List[_ColorTuple]] = None,
    ) -> None:
        self.background_color = ColorTriplet(*background)
        self.foreground_color = ColorTriplet(*foreground)
        self.ansi_colors = Palette(normal + (bright or normal))


DEFAULT_TERMINAL_THEME = TerminalTheme(
    (255, 255, 255),
    (0, 0, 0),
    [
        (0, 0, 0),
        (128, 0, 0),
        (0, 128, 0),
        (128, 128, 0),
        (0, 0, 128),
        (128, 0, 128),
        (0, 128, 128),
        (192, 192, 192),
    ],
    [
        (128, 128, 128),
        (255, 0, 0),
        (0, 255, 0),
        (255, 255, 0),
        (0, 0, 255),
        (255, 0, 255),
        (0, 255, 255),
        (255, 255, 255),
    ],
)

MONOKAI = TerminalTheme(
    (12, 12, 12),
    (217, 217, 217),
    [
        (26, 26, 26),
        (244, 0, 95),
        (152, 224, 36),
        (253, 151, 31),
        (157, 101, 255),
        (244, 0, 95),
        (88, 209, 235),
        (196, 197, 181),
        (98, 94, 76),
    ],
    [
        (244, 0, 95),
        (152, 224, 36),
        (224, 213, 97),
        (157, 101, 255),
        (244, 0, 95),
        (88, 209, 235),
        (246, 246, 239),
    ],
)
DIMMED_MONOKAI = TerminalTheme(
    (25, 25, 25),
    (185, 188, 186),
    [
        (58, 61, 67),
        (190, 63, 72),
        (135, 154, 59),
        (197, 166, 53),
        (79, 118, 161),
        (133, 92, 141),
        (87, 143, 164),
        (185, 188, 186),
        (136, 137, 135),
    ],
    [
        (251, 0, 31),
        (15, 114, 47),
        (196, 112, 51),
        (24, 109, 227),
        (251, 0, 103),
        (46, 112, 109),
        (253, 255, 185),
    ],
)
NIGHT_OWLISH = TerminalTheme(
    (255, 255, 255),
    (64, 63, 83),
    [
        (1, 22, 39),
        (211, 66, 62),
        (42, 162, 152),
        (218, 170, 1),
        (72, 118, 214),
        (64, 63, 83),
        (8, 145, 106),
        (122, 129, 129),
        (122, 129, 129),
    ],
    [
        (247, 110, 110),
        (73, 208, 197),
        (218, 194, 107),
        (92, 167, 228),
        (105, 112, 152),
        (0, 201, 144),
        (152, 159, 177),
    ],
)

SVG_EXPORT_THEME = TerminalTheme(
    (41, 41, 41),
    (197, 200, 198),
    [
        (75, 78, 85),
        (204, 85, 90),
        (152, 168, 75),
        (208, 179, 68),
        (96, 138, 177),
        (152, 114, 159),
        (104, 160, 179),
        (197, 200, 198),
        (154, 155, 153),
    ],
    [
        (255, 38, 39),
        (0, 130, 61),
        (208, 132, 66),
        (25, 132, 233),
        (255, 44, 122),
        (57, 130, 128),
        (253, 253, 197),
    ],
)

import re
from functools import partial, reduce
from math import gcd
from operator import itemgetter
from typing import (
    TYPE_CHECKING,
    Any,
    Callable,
    Dict,
    Iterable,
    List,
    NamedTuple,
    Optional,
    Pattern,
    Tuple,
    Union,
)

from ._loop import loop_last
from ._pick import pick_bool
from ._wrap import divide_line
from .align import AlignMethod
from .cells import cell_len, set_cell_size
from .containers import Lines
from .control import strip_control_codes
from .emoji import EmojiVariant
from .jupyter import JupyterMixin
from .measure import Measurement
from .segment import Segment
from .style import Style, StyleType

if TYPE_CHECKING:  
    from .console import Console, ConsoleOptions, JustifyMethod, OverflowMethod

DEFAULT_JUSTIFY: ""JustifyMethod"" = ""default""
DEFAULT_OVERFLOW: ""OverflowMethod"" = ""fold""


_re_whitespace = re.compile(r""\s+$"")

TextType = Union[str, ""Text""]


GetStyleCallable = Callable[[str], Optional[StyleType]]


class Span(NamedTuple):
    

    start: int
    
    end: int
    
    style: Union[str, Style]
    

    def __repr__(self) -> str:
        return f""Span({self.start}, {self.end}, {self.style!r})""

    def __bool__(self) -> bool:
        return self.end > self.start

    def split(self, offset: int) -> Tuple[""Span"", Optional[""Span""]]:
        

        if offset < self.start:
            return self, None
        if offset >= self.end:
            return self, None

        start, end, style = self
        span1 = Span(start, min(end, offset), style)
        span2 = Span(span1.end, end, style)
        return span1, span2

    def move(self, offset: int) -> ""Span"":
        
        start, end, style = self
        return Span(start + offset, end + offset, style)

    def right_crop(self, offset: int) -> ""Span"":
        
        start, end, style = self
        if offset >= end:
            return self
        return Span(start, min(offset, end), style)

    def extend(self, cells: int) -> ""Span"":
        
        if cells:
            start, end, style = self
            return Span(start, end + cells, style)
        else:
            return self


class Text(JupyterMixin):
    

    __slots__ = [
        ""_text"",
        ""style"",
        ""justify"",
        ""overflow"",
        ""no_wrap"",
        ""end"",
        ""tab_size"",
        ""_spans"",
        ""_length"",
    ]

    def __init__(
        self,
        text: str = """",
        style: Union[str, Style] = """",
        *,
        justify: Optional[""JustifyMethod""] = None,
        overflow: Optional[""OverflowMethod""] = None,
        no_wrap: Optional[bool] = None,
        end: str = ""\n"",
        tab_size: Optional[int] = None,
        spans: Optional[List[Span]] = None,
    ) -> None:
        sanitized_text = strip_control_codes(text)
        self._text = [sanitized_text]
        self.style = style
        self.justify: Optional[""JustifyMethod""] = justify
        self.overflow: Optional[""OverflowMethod""] = overflow
        self.no_wrap = no_wrap
        self.end = end
        self.tab_size = tab_size
        self._spans: List[Span] = spans or []
        self._length: int = len(sanitized_text)

    def __len__(self) -> int:
        return self._length

    def __bool__(self) -> bool:
        return bool(self._length)

    def __str__(self) -> str:
        return self.plain

    def __repr__(self) -> str:
        return f""<text {self.plain!r} {self._spans!r} {self.style!r}>""

    def __add__(self, other: Any) -> ""Text"":
        if isinstance(other, (str, Text)):
            result = self.copy()
            result.append(other)
            return result
        return NotImplemented

    def __eq__(self, other: object) -> bool:
        if not isinstance(other, Text):
            return NotImplemented
        return self.plain == other.plain and self._spans == other._spans

    def __contains__(self, other: object) -> bool:
        if isinstance(other, str):
            return other in self.plain
        elif isinstance(other, Text):
            return other.plain in self.plain
        return False

    def __getitem__(self, slice: Union[int, slice]) -> ""Text"":
        def get_text_at(offset: int) -> ""Text"":
            _Span = Span
            text = Text(
                self.plain[offset],
                spans=[
                    _Span(0, 1, style)
                    for start, end, style in self._spans
                    if end > offset >= start
                ],
                end="""",
            )
            return text

        if isinstance(slice, int):
            return get_text_at(slice)
        else:
            start, stop, step = slice.indices(len(self.plain))
            if step == 1:
                lines = self.divide([start, stop])
                return lines[1]
            else:
                
                
                raise TypeError(""slices with step!=1 are not supported"")

    @property
    def cell_len(self) -> int:
        
        return cell_len(self.plain)

    @property
    def markup(self) -> str:
        
        from .markup import escape

        output: List[str] = []

        plain = self.plain
        markup_spans = [
            (0, False, self.style),
            *((span.start, False, span.style) for span in self._spans),
            *((span.end, True, span.style) for span in self._spans),
            (len(plain), True, self.style),
        ]
        markup_spans.sort(key=itemgetter(0, 1))
        position = 0
        append = output.append
        for offset, closing, style in markup_spans:
            if offset > position:
                append(escape(plain[position:offset]))
                position = offset
            if style:
                append(f""[/{style}]"" if closing else f""[{style}]"")
        markup = """".join(output)
        return markup

    @classmethod
    def from_markup(
        cls,
        text: str,
        *,
        style: Union[str, Style] = """",
        emoji: bool = True,
        emoji_variant: Optional[EmojiVariant] = None,
        justify: Optional[""JustifyMethod""] = None,
        overflow: Optional[""OverflowMethod""] = None,
        end: str = ""\n"",
    ) -> ""Text"":
        
        from .markup import render

        rendered_text = render(text, style, emoji=emoji, emoji_variant=emoji_variant)
        rendered_text.justify = justify
        rendered_text.overflow = overflow
        rendered_text.end = end
        return rendered_text

    @classmethod
    def from_ansi(
        cls,
        text: str,
        *,
        style: Union[str, Style] = """",
        justify: Optional[""JustifyMethod""] = None,
        overflow: Optional[""OverflowMethod""] = None,
        no_wrap: Optional[bool] = None,
        end: str = ""\n"",
        tab_size: Optional[int] = 8,
    ) -> ""Text"":
        
        from .ansi import AnsiDecoder

        joiner = Text(
            ""\n"",
            justify=justify,
            overflow=overflow,
            no_wrap=no_wrap,
            end=end,
            tab_size=tab_size,
            style=style,
        )
        decoder = AnsiDecoder()
        result = joiner.join(line for line in decoder.decode(text))
        return result

    @classmethod
    def styled(
        cls,
        text: str,
        style: StyleType = """",
        *,
        justify: Optional[""JustifyMethod""] = None,
        overflow: Optional[""OverflowMethod""] = None,
    ) -> ""Text"":
        
        styled_text = cls(text, justify=justify, overflow=overflow)
        styled_text.stylize(style)
        return styled_text

    @classmethod
    def assemble(
        cls,
        *parts: Union[str, ""Text"", Tuple[str, StyleType]],
        style: Union[str, Style] = """",
        justify: Optional[""JustifyMethod""] = None,
        overflow: Optional[""OverflowMethod""] = None,
        no_wrap: Optional[bool] = None,
        end: str = ""\n"",
        tab_size: int = 8,
        meta: Optional[Dict[str, Any]] = None,
    ) -> ""Text"":
        
        text = cls(
            style=style,
            justify=justify,
            overflow=overflow,
            no_wrap=no_wrap,
            end=end,
            tab_size=tab_size,
        )
        append = text.append
        _Text = Text
        for part in parts:
            if isinstance(part, (_Text, str)):
                append(part)
            else:
                append(*part)
        if meta:
            text.apply_meta(meta)
        return text

    @property
    def plain(self) -> str:
        
        if len(self._text) != 1:
            self._text[:] = ["""".join(self._text)]
        return self._text[0]

    @plain.setter
    def plain(self, new_text: str) -> None:
        
        if new_text != self.plain:
            sanitized_text = strip_control_codes(new_text)
            self._text[:] = [sanitized_text]
            old_length = self._length
            self._length = len(sanitized_text)
            if old_length > self._length:
                self._trim_spans()

    @property
    def spans(self) -> List[Span]:
        
        return self._spans

    @spans.setter
    def spans(self, spans: List[Span]) -> None:
        
        self._spans = spans[:]

    def blank_copy(self, plain: str = """") -> ""Text"":
        
        copy_self = Text(
            plain,
            style=self.style,
            justify=self.justify,
            overflow=self.overflow,
            no_wrap=self.no_wrap,
            end=self.end,
            tab_size=self.tab_size,
        )
        return copy_self

    def copy(self) -> ""Text"":
        
        copy_self = Text(
            self.plain,
            style=self.style,
            justify=self.justify,
            overflow=self.overflow,
            no_wrap=self.no_wrap,
            end=self.end,
            tab_size=self.tab_size,
        )
        copy_self._spans[:] = self._spans
        return copy_self

    def stylize(
        self,
        style: Union[str, Style],
        start: int = 0,
        end: Optional[int] = None,
    ) -> None:
        
        if style:
            length = len(self)
            if start < 0:
                start = length + start
            if end is None:
                end = length
            if end < 0:
                end = length + end
            if start >= length or end <= start:
                
                return
            self._spans.append(Span(start, min(length, end), style))

    def stylize_before(
        self,
        style: Union[str, Style],
        start: int = 0,
        end: Optional[int] = None,
    ) -> None:
        
        if style:
            length = len(self)
            if start < 0:
                start = length + start
            if end is None:
                end = length
            if end < 0:
                end = length + end
            if start >= length or end <= start:
                
                return
            self._spans.insert(0, Span(start, min(length, end), style))

    def apply_meta(
        self, meta: Dict[str, Any], start: int = 0, end: Optional[int] = None
    ) -> None:
        
        style = Style.from_meta(meta)
        self.stylize(style, start=start, end=end)

    def on(self, meta: Optional[Dict[str, Any]] = None, **handlers: Any) -> ""Text"":
        
        meta = {} if meta is None else meta
        meta.update({f""@{key}"": value for key, value in handlers.items()})
        self.stylize(Style.from_meta(meta))
        return self

    def remove_suffix(self, suffix: str) -> None:
        
        if self.plain.endswith(suffix):
            self.right_crop(len(suffix))

    def get_style_at_offset(self, console: ""Console"", offset: int) -> Style:
        
        
        if offset < 0:
            offset = len(self) + offset
        get_style = console.get_style
        style = get_style(self.style).copy()
        for start, end, span_style in self._spans:
            if end > offset >= start:
                style += get_style(span_style, default="""")
        return style

    def extend_style(self, spaces: int) -> None:
        
        if spaces <= 0:
            return
        spans = self.spans
        new_spaces = "" "" * spaces
        if spans:
            end_offset = len(self)
            self._spans[:] = [
                span.extend(spaces) if span.end >= end_offset else span
                for span in spans
            ]
            self._text.append(new_spaces)
            self._length += spaces
        else:
            self.plain += new_spaces

    def highlight_regex(
        self,
        re_highlight: Union[Pattern[str], str],
        style: Optional[Union[GetStyleCallable, StyleType]] = None,
        *,
        style_prefix: str = """",
    ) -> int:
        
        count = 0
        append_span = self._spans.append
        _Span = Span
        plain = self.plain
        if isinstance(re_highlight, str):
            re_highlight = re.compile(re_highlight)
        for match in re_highlight.finditer(plain):
            get_span = match.span
            if style:
                start, end = get_span()
                match_style = style(plain[start:end]) if callable(style) else style
                if match_style is not None and end > start:
                    append_span(_Span(start, end, match_style))

            count += 1
            for name in match.groupdict().keys():
                start, end = get_span(name)
                if start != -1 and end > start:
                    append_span(_Span(start, end, f""{style_prefix}{name}""))
        return count

    def highlight_words(
        self,
        words: Iterable[str],
        style: Union[str, Style],
        *,
        case_sensitive: bool = True,
    ) -> int:
        
        re_words = ""|"".join(re.escape(word) for word in words)
        add_span = self._spans.append
        count = 0
        _Span = Span
        for match in re.finditer(
            re_words, self.plain, flags=0 if case_sensitive else re.IGNORECASE
        ):
            start, end = match.span(0)
            add_span(_Span(start, end, style))
            count += 1
        return count

    def rstrip(self) -> None:
        
        self.plain = self.plain.rstrip()

    def rstrip_end(self, size: int) -> None:
        
        text_length = len(self)
        if text_length > size:
            excess = text_length - size
            whitespace_match = _re_whitespace.search(self.plain)
            if whitespace_match is not None:
                whitespace_count = len(whitespace_match.group(0))
                self.right_crop(min(whitespace_count, excess))

    def set_length(self, new_length: int) -> None:
        
        length = len(self)
        if length != new_length:
            if length < new_length:
                self.pad_right(new_length - length)
            else:
                self.right_crop(length - new_length)

    def __rich_console__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> Iterable[Segment]:
        tab_size: int = console.tab_size if self.tab_size is None else self.tab_size
        justify = self.justify or options.justify or DEFAULT_JUSTIFY

        overflow = self.overflow or options.overflow or DEFAULT_OVERFLOW

        lines = self.wrap(
            console,
            options.max_width,
            justify=justify,
            overflow=overflow,
            tab_size=tab_size or 8,
            no_wrap=pick_bool(self.no_wrap, options.no_wrap, False),
        )
        all_lines = Text(""\n"").join(lines)
        yield from all_lines.render(console, end=self.end)

    def __rich_measure__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> Measurement:
        text = self.plain
        lines = text.splitlines()
        max_text_width = max(cell_len(line) for line in lines) if lines else 0
        words = text.split()
        min_text_width = (
            max(cell_len(word) for word in words) if words else max_text_width
        )
        return Measurement(min_text_width, max_text_width)

    def render(self, console: ""Console"", end: str = """") -> Iterable[""Segment""]:
        
        _Segment = Segment
        text = self.plain
        if not self._spans:
            yield Segment(text)
            if end:
                yield _Segment(end)
            return
        get_style = partial(console.get_style, default=Style.null())

        enumerated_spans = list(enumerate(self._spans, 1))
        style_map = {index: get_style(span.style) for index, span in enumerated_spans}
        style_map[0] = get_style(self.style)

        spans = [
            (0, False, 0),
            *((span.start, False, index) for index, span in enumerated_spans),
            *((span.end, True, index) for index, span in enumerated_spans),
            (len(text), True, 0),
        ]
        spans.sort(key=itemgetter(0, 1))

        stack: List[int] = []
        stack_append = stack.append
        stack_pop = stack.remove

        style_cache: Dict[Tuple[Style, ...], Style] = {}
        style_cache_get = style_cache.get
        combine = Style.combine

        def get_current_style() -> Style:
            
            styles = tuple(style_map[_style_id] for _style_id in sorted(stack))
            cached_style = style_cache_get(styles)
            if cached_style is not None:
                return cached_style
            current_style = combine(styles)
            style_cache[styles] = current_style
            return current_style

        for (offset, leaving, style_id), (next_offset, _, _) in zip(spans, spans[1:]):
            if leaving:
                stack_pop(style_id)
            else:
                stack_append(style_id)
            if next_offset > offset:
                yield _Segment(text[offset:next_offset], get_current_style())
        if end:
            yield _Segment(end)

    def join(self, lines: Iterable[""Text""]) -> ""Text"":
        

        new_text = self.blank_copy()

        def iter_text() -> Iterable[""Text""]:
            if self.plain:
                for last, line in loop_last(lines):
                    yield line
                    if not last:
                        yield self
            else:
                yield from lines

        extend_text = new_text._text.extend
        append_span = new_text._spans.append
        extend_spans = new_text._spans.extend
        offset = 0
        _Span = Span

        for text in iter_text():
            extend_text(text._text)
            if text.style:
                append_span(_Span(offset, offset + len(text), text.style))
            extend_spans(
                _Span(offset + start, offset + end, style)
                for start, end, style in text._spans
            )
            offset += len(text)
        new_text._length = offset
        return new_text

    def expand_tabs(self, tab_size: Optional[int] = None) -> None:
        
        if ""\t"" not in self.plain:
            return
        if tab_size is None:
            tab_size = self.tab_size
        if tab_size is None:
            tab_size = 8

        new_text: List[Text] = []
        append = new_text.append

        for line in self.split(""\n"", include_separator=True):
            if ""\t"" not in line.plain:
                append(line)
            else:
                cell_position = 0
                parts = line.split(""\t"", include_separator=True)
                for part in parts:
                    if part.plain.endswith(""\t""):
                        part._text[-1] = part._text[-1][:-1] + "" ""
                        cell_position += part.cell_len
                        tab_remainder = cell_position % tab_size
                        if tab_remainder:
                            spaces = tab_size - tab_remainder
                            part.extend_style(spaces)
                            cell_position += spaces
                    else:
                        cell_position += part.cell_len
                    append(part)

        result = Text("""").join(new_text)

        self._text = [result.plain]
        self._length = len(self.plain)
        self._spans[:] = result._spans

    def truncate(
        self,
        max_width: int,
        *,
        overflow: Optional[""OverflowMethod""] = None,
        pad: bool = False,
    ) -> None:
        
        _overflow = overflow or self.overflow or DEFAULT_OVERFLOW
        if _overflow != ""ignore"":
            length = cell_len(self.plain)
            if length > max_width:
                if _overflow == ""ellipsis"":
                    self.plain = set_cell_size(self.plain, max_width - 1) + ""…""
                else:
                    self.plain = set_cell_size(self.plain, max_width)
            if pad and length < max_width:
                spaces = max_width - length
                self._text = [f""{self.plain}{' ' * spaces}""]
                self._length = len(self.plain)

    def _trim_spans(self) -> None:
        
        max_offset = len(self.plain)
        _Span = Span
        self._spans[:] = [
            (
                span
                if span.end < max_offset
                else _Span(span.start, min(max_offset, span.end), span.style)
            )
            for span in self._spans
            if span.start < max_offset
        ]

    def pad(self, count: int, character: str = "" "") -> None:
        
        assert len(character) == 1, ""Character must be a string of length 1""
        if count:
            pad_characters = character * count
            self.plain = f""{pad_characters}{self.plain}{pad_characters}""
            _Span = Span
            self._spans[:] = [
                _Span(start + count, end + count, style)
                for start, end, style in self._spans
            ]

    def pad_left(self, count: int, character: str = "" "") -> None:
        
        assert len(character) == 1, ""Character must be a string of length 1""
        if count:
            self.plain = f""{character * count}{self.plain}""
            _Span = Span
            self._spans[:] = [
                _Span(start + count, end + count, style)
                for start, end, style in self._spans
            ]

    def pad_right(self, count: int, character: str = "" "") -> None:
        
        assert len(character) == 1, ""Character must be a string of length 1""
        if count:
            self.plain = f""{self.plain}{character * count}""

    def align(self, align: AlignMethod, width: int, character: str = "" "") -> None:
        
        self.truncate(width)
        excess_space = width - cell_len(self.plain)
        if excess_space:
            if align == ""left"":
                self.pad_right(excess_space, character)
            elif align == ""center"":
                left = excess_space // 2
                self.pad_left(left, character)
                self.pad_right(excess_space - left, character)
            else:
                self.pad_left(excess_space, character)

    def append(
        self, text: Union[""Text"", str], style: Optional[Union[str, ""Style""]] = None
    ) -> ""Text"":
        

        if not isinstance(text, (str, Text)):
            raise TypeError(""Only str or Text can be appended to Text"")

        if len(text):
            if isinstance(text, str):
                sanitized_text = strip_control_codes(text)
                self._text.append(sanitized_text)
                offset = len(self)
                text_length = len(sanitized_text)
                if style:
                    self._spans.append(Span(offset, offset + text_length, style))
                self._length += text_length
            elif isinstance(text, Text):
                _Span = Span
                if style is not None:
                    raise ValueError(
                        ""style must not be set when appending Text instance""
                    )
                text_length = self._length
                if text.style:
                    self._spans.append(
                        _Span(text_length, text_length + len(text), text.style)
                    )
                self._text.append(text.plain)
                self._spans.extend(
                    _Span(start + text_length, end + text_length, style)
                    for start, end, style in text._spans.copy()
                )
                self._length += len(text)
        return self

    def append_text(self, text: ""Text"") -> ""Text"":
        
        _Span = Span
        text_length = self._length
        if text.style:
            self._spans.append(_Span(text_length, text_length + len(text), text.style))
        self._text.append(text.plain)
        self._spans.extend(
            _Span(start + text_length, end + text_length, style)
            for start, end, style in text._spans.copy()
        )
        self._length += len(text)
        return self

    def append_tokens(
        self, tokens: Iterable[Tuple[str, Optional[StyleType]]]
    ) -> ""Text"":
        
        append_text = self._text.append
        append_span = self._spans.append
        _Span = Span
        offset = len(self)
        for content, style in tokens:
            content = strip_control_codes(content)
            append_text(content)
            if style:
                append_span(_Span(offset, offset + len(content), style))
            offset += len(content)
        self._length = offset
        return self

    def copy_styles(self, text: ""Text"") -> None:
        
        self._spans.extend(text._spans)

    def split(
        self,
        separator: str = ""\n"",
        *,
        include_separator: bool = False,
        allow_blank: bool = False,
    ) -> Lines:
        
        assert separator, ""separator must not be empty""

        text = self.plain
        if separator not in text:
            return Lines([self.copy()])

        if include_separator:
            lines = self.divide(
                match.end() for match in re.finditer(re.escape(separator), text)
            )
        else:

            def flatten_spans() -> Iterable[int]:
                for match in re.finditer(re.escape(separator), text):
                    start, end = match.span()
                    yield start
                    yield end

            lines = Lines(
                line for line in self.divide(flatten_spans()) if line.plain != separator
            )

        if not allow_blank and text.endswith(separator):
            lines.pop()

        return lines

    def divide(self, offsets: Iterable[int]) -> Lines:
        
        _offsets = list(offsets)

        if not _offsets:
            return Lines([self.copy()])

        text = self.plain
        text_length = len(text)
        divide_offsets = [0, *_offsets, text_length]
        line_ranges = list(zip(divide_offsets, divide_offsets[1:]))

        style = self.style
        justify = self.justify
        overflow = self.overflow
        _Text = Text
        new_lines = Lines(
            _Text(
                text[start:end],
                style=style,
                justify=justify,
                overflow=overflow,
            )
            for start, end in line_ranges
        )
        if not self._spans:
            return new_lines

        _line_appends = [line._spans.append for line in new_lines._lines]
        line_count = len(line_ranges)
        _Span = Span

        for span_start, span_end, style in self._spans:
            lower_bound = 0
            upper_bound = line_count
            start_line_no = (lower_bound + upper_bound) // 2

            while True:
                line_start, line_end = line_ranges[start_line_no]
                if span_start < line_start:
                    upper_bound = start_line_no - 1
                elif span_start > line_end:
                    lower_bound = start_line_no + 1
                else:
                    break
                start_line_no = (lower_bound + upper_bound) // 2

            if span_end < line_end:
                end_line_no = start_line_no
            else:
                end_line_no = lower_bound = start_line_no
                upper_bound = line_count

                while True:
                    line_start, line_end = line_ranges[end_line_no]
                    if span_end < line_start:
                        upper_bound = end_line_no - 1
                    elif span_end > line_end:
                        lower_bound = end_line_no + 1
                    else:
                        break
                    end_line_no = (lower_bound + upper_bound) // 2

            for line_no in range(start_line_no, end_line_no + 1):
                line_start, line_end = line_ranges[line_no]
                new_start = max(0, span_start - line_start)
                new_end = min(span_end - line_start, line_end - line_start)
                if new_end > new_start:
                    _line_appends[line_no](_Span(new_start, new_end, style))

        return new_lines

    def right_crop(self, amount: int = 1) -> None:
        
        max_offset = len(self.plain) - amount
        _Span = Span
        self._spans[:] = [
            (
                span
                if span.end < max_offset
                else _Span(span.start, min(max_offset, span.end), span.style)
            )
            for span in self._spans
            if span.start < max_offset
        ]
        self._text = [self.plain[:-amount]]
        self._length -= amount

    def wrap(
        self,
        console: ""Console"",
        width: int,
        *,
        justify: Optional[""JustifyMethod""] = None,
        overflow: Optional[""OverflowMethod""] = None,
        tab_size: int = 8,
        no_wrap: Optional[bool] = None,
    ) -> Lines:
        
        wrap_justify = justify or self.justify or DEFAULT_JUSTIFY
        wrap_overflow = overflow or self.overflow or DEFAULT_OVERFLOW

        no_wrap = pick_bool(no_wrap, self.no_wrap, False) or overflow == ""ignore""

        lines = Lines()
        for line in self.split(allow_blank=True):
            if ""\t"" in line:
                line.expand_tabs(tab_size)
            if no_wrap:
                new_lines = Lines([line])
            else:
                offsets = divide_line(str(line), width, fold=wrap_overflow == ""fold"")
                new_lines = line.divide(offsets)
            for line in new_lines:
                line.rstrip_end(width)
            if wrap_justify:
                new_lines.justify(
                    console, width, justify=wrap_justify, overflow=wrap_overflow
                )
            for line in new_lines:
                line.truncate(width, overflow=wrap_overflow)
            lines.extend(new_lines)
        return lines

    def fit(self, width: int) -> Lines:
        
        lines: Lines = Lines()
        append = lines.append
        for line in self.split():
            line.set_length(width)
            append(line)
        return lines

    def detect_indentation(self) -> int:
        

        _indentations = {
            len(match.group(1))
            for match in re.finditer(r""^( *)(.*)$"", self.plain, flags=re.MULTILINE)
        }

        try:
            indentation = (
                reduce(gcd, [indent for indent in _indentations if not indent % 2]) or 1
            )
        except TypeError:
            indentation = 1

        return indentation

    def with_indent_guides(
        self,
        indent_size: Optional[int] = None,
        *,
        character: str = ""│"",
        style: StyleType = ""dim green"",
    ) -> ""Text"":
        

        _indent_size = self.detect_indentation() if indent_size is None else indent_size

        text = self.copy()
        text.expand_tabs()
        indent_line = f""{character}{' ' * (_indent_size - 1)}""

        re_indent = re.compile(r""^( *)(.*)$"")
        new_lines: List[Text] = []
        add_line = new_lines.append
        blank_lines = 0
        for line in text.split(allow_blank=True):
            match = re_indent.match(line.plain)
            if not match or not match.group(2):
                blank_lines += 1
                continue
            indent = match.group(1)
            full_indents, remaining_space = divmod(len(indent), _indent_size)
            new_indent = f""{indent_line * full_indents}{' ' * remaining_space}""
            line.plain = new_indent + line.plain[len(new_indent) :]
            line.stylize(style, 0, len(new_indent))
            if blank_lines:
                new_lines.extend([Text(new_indent, style=style)] * blank_lines)
                blank_lines = 0
            add_line(line)
        if blank_lines:
            new_lines.extend([Text("""", style=style)] * blank_lines)

        new_text = text.blank_copy(""\n"").join(new_lines)
        return new_text


if __name__ == ""__main__"":  
    from pip._vendor.rich.console import Console

    text = Text(
        
    )
    text.highlight_words([""Lorem""], ""bold"")
    text.highlight_words([""ipsum""], ""italic"")

    console = Console()

    console.rule(""justify='left'"")
    console.print(text, style=""red"")
    console.print()

    console.rule(""justify='center'"")
    console.print(text, style=""green"", justify=""center"")
    console.print()

    console.rule(""justify='right'"")
    console.print(text, style=""blue"", justify=""right"")
    console.print()

    console.rule(""justify='full'"")
    console.print(text, style=""magenta"", justify=""full"")
    console.print()

import configparser
from typing import IO, Dict, List, Mapping, Optional

from .default_styles import DEFAULT_STYLES
from .style import Style, StyleType


class Theme:
    

    styles: Dict[str, Style]

    def __init__(
        self, styles: Optional[Mapping[str, StyleType]] = None, inherit: bool = True
    ):
        self.styles = DEFAULT_STYLES.copy() if inherit else {}
        if styles is not None:
            self.styles.update(
                {
                    name: style if isinstance(style, Style) else Style.parse(style)
                    for name, style in styles.items()
                }
            )

    @property
    def config(self) -> str:
        
        config = ""[styles]\n"" + ""\n"".join(
            f""{name} = {style}"" for name, style in sorted(self.styles.items())
        )
        return config

    @classmethod
    def from_file(
        cls, config_file: IO[str], source: Optional[str] = None, inherit: bool = True
    ) -> ""Theme"":
        
        config = configparser.ConfigParser()
        config.read_file(config_file, source=source)
        styles = {name: Style.parse(value) for name, value in config.items(""styles"")}
        theme = Theme(styles, inherit=inherit)
        return theme

    @classmethod
    def read(
        cls, path: str, inherit: bool = True, encoding: Optional[str] = None
    ) -> ""Theme"":
        
        with open(path, encoding=encoding) as config_file:
            return cls.from_file(config_file, source=path, inherit=inherit)


class ThemeStackError(Exception):
    


class ThemeStack:
    

    def __init__(self, theme: Theme) -> None:
        self._entries: List[Dict[str, Style]] = [theme.styles]
        self.get = self._entries[-1].get

    def push_theme(self, theme: Theme, inherit: bool = True) -> None:
        
        styles: Dict[str, Style]
        styles = (
            {**self._entries[-1], **theme.styles} if inherit else theme.styles.copy()
        )
        self._entries.append(styles)
        self.get = self._entries[-1].get

    def pop_theme(self) -> None:
        
        if len(self._entries) == 1:
            raise ThemeStackError(""Unable to pop base theme"")
        self._entries.pop()
        self.get = self._entries[-1].get


if __name__ == ""__main__"":  
    theme = Theme()
    print(theme.config)

from .default_styles import DEFAULT_STYLES
from .theme import Theme


DEFAULT = Theme(DEFAULT_STYLES)

import inspect
import linecache
import os
import sys
from dataclasses import dataclass, field
from itertools import islice
from traceback import walk_tb
from types import ModuleType, TracebackType
from typing import (
    Any,
    Callable,
    Dict,
    Iterable,
    List,
    Optional,
    Sequence,
    Set,
    Tuple,
    Type,
    Union,
)

from pip._vendor.pygments.lexers import guess_lexer_for_filename
from pip._vendor.pygments.token import Comment, Keyword, Name, Number, Operator, String
from pip._vendor.pygments.token import Text as TextToken
from pip._vendor.pygments.token import Token
from pip._vendor.pygments.util import ClassNotFound

from . import pretty
from ._loop import loop_first_last, loop_last
from .columns import Columns
from .console import (
    Console,
    ConsoleOptions,
    ConsoleRenderable,
    Group,
    RenderResult,
    group,
)
from .constrain import Constrain
from .highlighter import RegexHighlighter, ReprHighlighter
from .panel import Panel
from .scope import render_scope
from .style import Style
from .syntax import Syntax, SyntaxPosition
from .text import Text
from .theme import Theme

WINDOWS = sys.platform == ""win32""

LOCALS_MAX_LENGTH = 10
LOCALS_MAX_STRING = 80


def _iter_syntax_lines(
    start: SyntaxPosition, end: SyntaxPosition
) -> Iterable[Tuple[int, int, int]]:
    

    line1, column1 = start
    line2, column2 = end

    if line1 == line2:
        yield line1, column1, column2
    else:
        for first, last, line_no in loop_first_last(range(line1, line2 + 1)):
            if first:
                yield line_no, column1, -1
            elif last:
                yield line_no, 0, column2
            else:
                yield line_no, 0, -1


def install(
    *,
    console: Optional[Console] = None,
    width: Optional[int] = 100,
    code_width: Optional[int] = 88,
    extra_lines: int = 3,
    theme: Optional[str] = None,
    word_wrap: bool = False,
    show_locals: bool = False,
    locals_max_length: int = LOCALS_MAX_LENGTH,
    locals_max_string: int = LOCALS_MAX_STRING,
    locals_hide_dunder: bool = True,
    locals_hide_sunder: Optional[bool] = None,
    indent_guides: bool = True,
    suppress: Iterable[Union[str, ModuleType]] = (),
    max_frames: int = 100,
) -> Callable[[Type[BaseException], BaseException, Optional[TracebackType]], Any]:
    
    traceback_console = Console(stderr=True) if console is None else console

    locals_hide_sunder = (
        True
        if (traceback_console.is_jupyter and locals_hide_sunder is None)
        else locals_hide_sunder
    )

    def excepthook(
        type_: Type[BaseException],
        value: BaseException,
        traceback: Optional[TracebackType],
    ) -> None:
        exception_traceback = Traceback.from_exception(
            type_,
            value,
            traceback,
            width=width,
            code_width=code_width,
            extra_lines=extra_lines,
            theme=theme,
            word_wrap=word_wrap,
            show_locals=show_locals,
            locals_max_length=locals_max_length,
            locals_max_string=locals_max_string,
            locals_hide_dunder=locals_hide_dunder,
            locals_hide_sunder=bool(locals_hide_sunder),
            indent_guides=indent_guides,
            suppress=suppress,
            max_frames=max_frames,
        )
        traceback_console.print(exception_traceback)

    def ipy_excepthook_closure(ip: Any) -> None:  
        tb_data = {}  
        default_showtraceback = ip.showtraceback  

        def ipy_show_traceback(*args: Any, **kwargs: Any) -> None:
            
            nonlocal tb_data
            tb_data = kwargs
            default_showtraceback(*args, **kwargs)

        def ipy_display_traceback(
            *args: Any, is_syntax: bool = False, **kwargs: Any
        ) -> None:
            
            nonlocal tb_data
            exc_tuple = ip._get_exc_info()

            
            tb: Optional[TracebackType] = None if is_syntax else exc_tuple[2]

            
            compiled = tb_data.get(""running_compiled_code"", False)
            tb_offset = tb_data.get(""tb_offset"")
            if tb_offset is None:
                tb_offset = 1 if compiled else 0
            
            for _ in range(tb_offset):
                if tb is None:
                    break
                tb = tb.tb_next

            excepthook(exc_tuple[0], exc_tuple[1], tb)
            tb_data = {}  

        
        
        ip._showtraceback = ipy_display_traceback
        
        ip.showtraceback = ipy_show_traceback
        ip.showsyntaxerror = lambda *args, **kwargs: ipy_display_traceback(
            *args, is_syntax=True, **kwargs
        )

    try:  
        
        ip = get_ipython()  
        ipy_excepthook_closure(ip)
        return sys.excepthook
    except Exception:
        
        old_excepthook = sys.excepthook
        sys.excepthook = excepthook
        return old_excepthook


@dataclass
class Frame:
    filename: str
    lineno: int
    name: str
    line: str = """"
    locals: Optional[Dict[str, pretty.Node]] = None
    last_instruction: Optional[Tuple[Tuple[int, int], Tuple[int, int]]] = None


@dataclass
class _SyntaxError:
    offset: int
    filename: str
    line: str
    lineno: int
    msg: str
    notes: List[str] = field(default_factory=list)


@dataclass
class Stack:
    exc_type: str
    exc_value: str
    syntax_error: Optional[_SyntaxError] = None
    is_cause: bool = False
    frames: List[Frame] = field(default_factory=list)
    notes: List[str] = field(default_factory=list)
    is_group: bool = False
    exceptions: List[""Trace""] = field(default_factory=list)


@dataclass
class Trace:
    stacks: List[Stack]


class PathHighlighter(RegexHighlighter):
    highlights = [r""(?P<dim>.*/)(?P<bold>.+)""]


class Traceback:
    

    LEXERS = {
        """": ""text"",
        "".py"": ""python"",
        "".pxd"": ""cython"",
        "".pyx"": ""cython"",
        "".pxi"": ""pyrex"",
    }

    def __init__(
        self,
        trace: Optional[Trace] = None,
        *,
        width: Optional[int] = 100,
        code_width: Optional[int] = 88,
        extra_lines: int = 3,
        theme: Optional[str] = None,
        word_wrap: bool = False,
        show_locals: bool = False,
        locals_max_length: int = LOCALS_MAX_LENGTH,
        locals_max_string: int = LOCALS_MAX_STRING,
        locals_hide_dunder: bool = True,
        locals_hide_sunder: bool = False,
        indent_guides: bool = True,
        suppress: Iterable[Union[str, ModuleType]] = (),
        max_frames: int = 100,
    ):
        if trace is None:
            exc_type, exc_value, traceback = sys.exc_info()
            if exc_type is None or exc_value is None or traceback is None:
                raise ValueError(
                    ""Value for 'trace' required if not called in except: block""
                )
            trace = self.extract(
                exc_type, exc_value, traceback, show_locals=show_locals
            )
        self.trace = trace
        self.width = width
        self.code_width = code_width
        self.extra_lines = extra_lines
        self.theme = Syntax.get_theme(theme or ""ansi_dark"")
        self.word_wrap = word_wrap
        self.show_locals = show_locals
        self.indent_guides = indent_guides
        self.locals_max_length = locals_max_length
        self.locals_max_string = locals_max_string
        self.locals_hide_dunder = locals_hide_dunder
        self.locals_hide_sunder = locals_hide_sunder

        self.suppress: Sequence[str] = []
        for suppress_entity in suppress:
            if not isinstance(suppress_entity, str):
                assert (
                    suppress_entity.__file__ is not None
                ), f""{suppress_entity!r} must be a module with '__file__' attribute""
                path = os.path.dirname(suppress_entity.__file__)
            else:
                path = suppress_entity
            path = os.path.normpath(os.path.abspath(path))
            self.suppress.append(path)
        self.max_frames = max(4, max_frames) if max_frames > 0 else 0

    @classmethod
    def from_exception(
        cls,
        exc_type: Type[Any],
        exc_value: BaseException,
        traceback: Optional[TracebackType],
        *,
        width: Optional[int] = 100,
        code_width: Optional[int] = 88,
        extra_lines: int = 3,
        theme: Optional[str] = None,
        word_wrap: bool = False,
        show_locals: bool = False,
        locals_max_length: int = LOCALS_MAX_LENGTH,
        locals_max_string: int = LOCALS_MAX_STRING,
        locals_hide_dunder: bool = True,
        locals_hide_sunder: bool = False,
        indent_guides: bool = True,
        suppress: Iterable[Union[str, ModuleType]] = (),
        max_frames: int = 100,
    ) -> ""Traceback"":
        
        rich_traceback = cls.extract(
            exc_type,
            exc_value,
            traceback,
            show_locals=show_locals,
            locals_max_length=locals_max_length,
            locals_max_string=locals_max_string,
            locals_hide_dunder=locals_hide_dunder,
            locals_hide_sunder=locals_hide_sunder,
        )

        return cls(
            rich_traceback,
            width=width,
            code_width=code_width,
            extra_lines=extra_lines,
            theme=theme,
            word_wrap=word_wrap,
            show_locals=show_locals,
            indent_guides=indent_guides,
            locals_max_length=locals_max_length,
            locals_max_string=locals_max_string,
            locals_hide_dunder=locals_hide_dunder,
            locals_hide_sunder=locals_hide_sunder,
            suppress=suppress,
            max_frames=max_frames,
        )

    @classmethod
    def extract(
        cls,
        exc_type: Type[BaseException],
        exc_value: BaseException,
        traceback: Optional[TracebackType],
        *,
        show_locals: bool = False,
        locals_max_length: int = LOCALS_MAX_LENGTH,
        locals_max_string: int = LOCALS_MAX_STRING,
        locals_hide_dunder: bool = True,
        locals_hide_sunder: bool = False,
        _visited_exceptions: Optional[Set[BaseException]] = None,
    ) -> Trace:
        

        stacks: List[Stack] = []
        is_cause = False

        from pip._vendor.rich import _IMPORT_CWD

        notes: List[str] = getattr(exc_value, ""__notes__"", None) or []

        grouped_exceptions: Set[BaseException] = (
            set() if _visited_exceptions is None else _visited_exceptions
        )

        def safe_str(_object: Any) -> str:
            
            try:
                return str(_object)
            except Exception:
                return ""<exception str() failed>""

        while True:
            stack = Stack(
                exc_type=safe_str(exc_type.__name__),
                exc_value=safe_str(exc_value),
                is_cause=is_cause,
                notes=notes,
            )

            if sys.version_info >= (3, 11):
                if isinstance(exc_value, (BaseExceptionGroup, ExceptionGroup)):
                    stack.is_group = True
                    for exception in exc_value.exceptions:
                        if exception in grouped_exceptions:
                            continue
                        grouped_exceptions.add(exception)
                        stack.exceptions.append(
                            Traceback.extract(
                                type(exception),
                                exception,
                                exception.__traceback__,
                                show_locals=show_locals,
                                locals_max_length=locals_max_length,
                                locals_hide_dunder=locals_hide_dunder,
                                locals_hide_sunder=locals_hide_sunder,
                                _visited_exceptions=grouped_exceptions,
                            )
                        )

            if isinstance(exc_value, SyntaxError):
                stack.syntax_error = _SyntaxError(
                    offset=exc_value.offset or 0,
                    filename=exc_value.filename or ""?"",
                    lineno=exc_value.lineno or 0,
                    line=exc_value.text or """",
                    msg=exc_value.msg,
                    notes=notes,
                )

            stacks.append(stack)
            append = stack.frames.append

            def get_locals(
                iter_locals: Iterable[Tuple[str, object]],
            ) -> Iterable[Tuple[str, object]]:
                
                if not (locals_hide_dunder or locals_hide_sunder):
                    yield from iter_locals
                    return
                for key, value in iter_locals:
                    if locals_hide_dunder and key.startswith(""__""):
                        continue
                    if locals_hide_sunder and key.startswith(""_""):
                        continue
                    yield key, value

            for frame_summary, line_no in walk_tb(traceback):
                filename = frame_summary.f_code.co_filename

                last_instruction: Optional[Tuple[Tuple[int, int], Tuple[int, int]]]
                last_instruction = None
                if sys.version_info >= (3, 11):
                    instruction_index = frame_summary.f_lasti // 2
                    instruction_position = next(
                        islice(
                            frame_summary.f_code.co_positions(),
                            instruction_index,
                            instruction_index + 1,
                        )
                    )
                    (
                        start_line,
                        end_line,
                        start_column,
                        end_column,
                    ) = instruction_position
                    if (
                        start_line is not None
                        and end_line is not None
                        and start_column is not None
                        and end_column is not None
                    ):
                        last_instruction = (
                            (start_line, start_column),
                            (end_line, end_column),
                        )

                if filename and not filename.startswith(""<""):
                    if not os.path.isabs(filename):
                        filename = os.path.join(_IMPORT_CWD, filename)
                if frame_summary.f_locals.get(""_rich_traceback_omit"", False):
                    continue

                frame = Frame(
                    filename=filename or ""?"",
                    lineno=line_no,
                    name=frame_summary.f_code.co_name,
                    locals=(
                        {
                            key: pretty.traverse(
                                value,
                                max_length=locals_max_length,
                                max_string=locals_max_string,
                            )
                            for key, value in get_locals(frame_summary.f_locals.items())
                            if not (inspect.isfunction(value) or inspect.isclass(value))
                        }
                        if show_locals
                        else None
                    ),
                    last_instruction=last_instruction,
                )
                append(frame)
                if frame_summary.f_locals.get(""_rich_traceback_guard"", False):
                    del stack.frames[:]

            if not grouped_exceptions:
                cause = getattr(exc_value, ""__cause__"", None)
                if cause is not None and cause is not exc_value:
                    exc_type = cause.__class__
                    exc_value = cause
                    
                    
                    traceback = cause.__traceback__
                    is_cause = True
                    continue

                cause = exc_value.__context__
                if cause is not None and not getattr(
                    exc_value, ""__suppress_context__"", False
                ):
                    exc_type = cause.__class__
                    exc_value = cause
                    traceback = cause.__traceback__
                    is_cause = False
                    continue
            
            break  

        trace = Trace(stacks=stacks)

        return trace

    def __rich_console__(
        self, console: Console, options: ConsoleOptions
    ) -> RenderResult:
        theme = self.theme
        background_style = theme.get_background_style()
        token_style = theme.get_style_for_token

        traceback_theme = Theme(
            {
                ""pretty"": token_style(TextToken),
                ""pygments.text"": token_style(Token),
                ""pygments.string"": token_style(String),
                ""pygments.function"": token_style(Name.Function),
                ""pygments.number"": token_style(Number),
                ""repr.indent"": token_style(Comment) + Style(dim=True),
                ""repr.str"": token_style(String),
                ""repr.brace"": token_style(TextToken) + Style(bold=True),
                ""repr.number"": token_style(Number),
                ""repr.bool_true"": token_style(Keyword.Constant),
                ""repr.bool_false"": token_style(Keyword.Constant),
                ""repr.none"": token_style(Keyword.Constant),
                ""scope.border"": token_style(String.Delimiter),
                ""scope.equals"": token_style(Operator),
                ""scope.key"": token_style(Name),
                ""scope.key.special"": token_style(Name.Constant) + Style(dim=True),
            },
            inherit=False,
        )

        highlighter = ReprHighlighter()

        @group()
        def render_stack(stack: Stack, last: bool) -> RenderResult:
            if stack.frames:
                stack_renderable: ConsoleRenderable = Panel(
                    self._render_stack(stack),
                    title=""[traceback.title]Traceback [dim](most recent call last)"",
                    style=background_style,
                    border_style=""traceback.border"",
                    expand=True,
                    padding=(0, 1),
                )
                stack_renderable = Constrain(stack_renderable, self.width)
                with console.use_theme(traceback_theme):
                    yield stack_renderable

            if stack.syntax_error is not None:
                with console.use_theme(traceback_theme):
                    yield Constrain(
                        Panel(
                            self._render_syntax_error(stack.syntax_error),
                            style=background_style,
                            border_style=""traceback.border.syntax_error"",
                            expand=True,
                            padding=(0, 1),
                            width=self.width,
                        ),
                        self.width,
                    )
                yield Text.assemble(
                    (f""{stack.exc_type}: "", ""traceback.exc_type""),
                    highlighter(stack.syntax_error.msg),
                )
            elif stack.exc_value:
                yield Text.assemble(
                    (f""{stack.exc_type}: "", ""traceback.exc_type""),
                    highlighter(stack.exc_value),
                )
            else:
                yield Text.assemble((f""{stack.exc_type}"", ""traceback.exc_type""))

            for note in stack.notes:
                yield Text.assemble((""[NOTE] "", ""traceback.note""), highlighter(note))

            if stack.is_group:
                for group_no, group_exception in enumerate(stack.exceptions, 1):
                    grouped_exceptions: List[Group] = []
                    for group_last, group_stack in loop_last(group_exception.stacks):
                        grouped_exceptions.append(render_stack(group_stack, group_last))
                    yield """"
                    yield Constrain(
                        Panel(
                            Group(*grouped_exceptions),
                            title=f""Sub-exception 
                            border_style=""traceback.group.border"",
                        ),
                        self.width,
                    )

            if not last:
                if stack.is_cause:
                    yield Text.from_markup(
                        ""\n[i]The above exception was the direct cause of the following exception:\n"",
                    )
                else:
                    yield Text.from_markup(
                        ""\n[i]During handling of the above exception, another exception occurred:\n"",
                    )

        for last, stack in loop_last(reversed(self.trace.stacks)):
            yield render_stack(stack, last)

    @group()
    def _render_syntax_error(self, syntax_error: _SyntaxError) -> RenderResult:
        highlighter = ReprHighlighter()
        path_highlighter = PathHighlighter()
        if syntax_error.filename != ""<stdin>"":
            if os.path.exists(syntax_error.filename):
                text = Text.assemble(
                    (f"" {syntax_error.filename}"", ""pygments.string""),
                    ("":"", ""pygments.text""),
                    (str(syntax_error.lineno), ""pygments.number""),
                    style=""pygments.text"",
                )
                yield path_highlighter(text)
        syntax_error_text = highlighter(syntax_error.line.rstrip())
        syntax_error_text.no_wrap = True
        offset = min(syntax_error.offset - 1, len(syntax_error_text))
        syntax_error_text.stylize(""bold underline"", offset, offset)
        syntax_error_text += Text.from_markup(
            ""\n"" + "" "" * offset + ""[traceback.offset]▲[/]"",
            style=""pygments.text"",
        )
        yield syntax_error_text

    @classmethod
    def _guess_lexer(cls, filename: str, code: str) -> str:
        ext = os.path.splitext(filename)[-1]
        if not ext:
            
            
            
            new_line_index = code.index(""\n"")
            first_line = code[:new_line_index] if new_line_index != -1 else code
            if first_line.startswith(""
                return ""python""
        try:
            return cls.LEXERS.get(ext) or guess_lexer_for_filename(filename, code).name
        except ClassNotFound:
            return ""text""

    @group()
    def _render_stack(self, stack: Stack) -> RenderResult:
        path_highlighter = PathHighlighter()
        theme = self.theme

        def render_locals(frame: Frame) -> Iterable[ConsoleRenderable]:
            if frame.locals:
                yield render_scope(
                    frame.locals,
                    title=""locals"",
                    indent_guides=self.indent_guides,
                    max_length=self.locals_max_length,
                    max_string=self.locals_max_string,
                )

        exclude_frames: Optional[range] = None
        if self.max_frames != 0:
            exclude_frames = range(
                self.max_frames // 2,
                len(stack.frames) - self.max_frames // 2,
            )

        excluded = False
        for frame_index, frame in enumerate(stack.frames):
            if exclude_frames and frame_index in exclude_frames:
                excluded = True
                continue

            if excluded:
                assert exclude_frames is not None
                yield Text(
                    f""\n... {len(exclude_frames)} frames hidden ..."",
                    justify=""center"",
                    style=""traceback.error"",
                )
                excluded = False

            first = frame_index == 0
            frame_filename = frame.filename
            suppressed = any(frame_filename.startswith(path) for path in self.suppress)

            if os.path.exists(frame.filename):
                text = Text.assemble(
                    path_highlighter(Text(frame.filename, style=""pygments.string"")),
                    ("":"", ""pygments.text""),
                    (str(frame.lineno), ""pygments.number""),
                    "" in "",
                    (frame.name, ""pygments.function""),
                    style=""pygments.text"",
                )
            else:
                text = Text.assemble(
                    ""in "",
                    (frame.name, ""pygments.function""),
                    ("":"", ""pygments.text""),
                    (str(frame.lineno), ""pygments.number""),
                    style=""pygments.text"",
                )
            if not frame.filename.startswith(""<"") and not first:
                yield """"
            yield text
            if frame.filename.startswith(""<""):
                yield from render_locals(frame)
                continue
            if not suppressed:
                try:
                    code_lines = linecache.getlines(frame.filename)
                    code = """".join(code_lines)
                    if not code:
                        
                        
                        continue
                    lexer_name = self._guess_lexer(frame.filename, code)
                    syntax = Syntax(
                        code,
                        lexer_name,
                        theme=theme,
                        line_numbers=True,
                        line_range=(
                            frame.lineno - self.extra_lines,
                            frame.lineno + self.extra_lines,
                        ),
                        highlight_lines={frame.lineno},
                        word_wrap=self.word_wrap,
                        code_width=self.code_width,
                        indent_guides=self.indent_guides,
                        dedent=False,
                    )
                    yield """"
                except Exception as error:
                    yield Text.assemble(
                        (f""\n{error}"", ""traceback.error""),
                    )
                else:
                    if frame.last_instruction is not None:
                        start, end = frame.last_instruction

                        
                        
                        for line1, column1, column2 in _iter_syntax_lines(start, end):
                            try:
                                if column1 == 0:
                                    line = code_lines[line1 - 1]
                                    column1 = len(line) - len(line.lstrip())
                                if column2 == -1:
                                    column2 = len(code_lines[line1 - 1])
                            except IndexError:
                                
                                
                                continue

                            syntax.stylize_range(
                                style=""traceback.error_range"",
                                start=(line1, column1),
                                end=(line1, column2),
                            )
                    yield (
                        Columns(
                            [
                                syntax,
                                *render_locals(frame),
                            ],
                            padding=1,
                        )
                        if frame.locals
                        else syntax
                    )


if __name__ == ""__main__"":  
    install(show_locals=True)
    import sys

    def bar(
        a: Any,
    ) -> None:  
        one = 1
        print(one / a)

    def foo(a: Any) -> None:
        _rich_traceback_guard = True
        zed = {
            ""characters"": {
                ""Paul Atreides"",
                ""Vladimir Harkonnen"",
                ""Thufir Hawat"",
                ""Duncan Idaho"",
            },
            ""atomic_types"": (None, False, True),
        }
        bar(a)

    def error() -> None:
        foo(0)

    error()

from typing import Iterator, List, Optional, Tuple

from ._loop import loop_first, loop_last
from .console import Console, ConsoleOptions, RenderableType, RenderResult
from .jupyter import JupyterMixin
from .measure import Measurement
from .segment import Segment
from .style import Style, StyleStack, StyleType
from .styled import Styled

GuideType = Tuple[str, str, str, str]


class Tree(JupyterMixin):
    

    ASCII_GUIDES = (""    "", ""|   "", ""+-- "", ""`-- "")
    TREE_GUIDES = [
        (""    "", ""│   "", ""├── "", ""└── ""),
        (""    "", ""┃   "", ""┣━━ "", ""┗━━ ""),
        (""    "", ""║   "", ""╠══ "", ""╚══ ""),
    ]

    def __init__(
        self,
        label: RenderableType,
        *,
        style: StyleType = ""tree"",
        guide_style: StyleType = ""tree.line"",
        expanded: bool = True,
        highlight: bool = False,
        hide_root: bool = False,
    ) -> None:
        self.label = label
        self.style = style
        self.guide_style = guide_style
        self.children: List[Tree] = []
        self.expanded = expanded
        self.highlight = highlight
        self.hide_root = hide_root

    def add(
        self,
        label: RenderableType,
        *,
        style: Optional[StyleType] = None,
        guide_style: Optional[StyleType] = None,
        expanded: bool = True,
        highlight: Optional[bool] = False,
    ) -> ""Tree"":
        
        node = Tree(
            label,
            style=self.style if style is None else style,
            guide_style=self.guide_style if guide_style is None else guide_style,
            expanded=expanded,
            highlight=self.highlight if highlight is None else highlight,
        )
        self.children.append(node)
        return node

    def __rich_console__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> ""RenderResult"":
        stack: List[Iterator[Tuple[bool, Tree]]] = []
        pop = stack.pop
        push = stack.append
        new_line = Segment.line()

        get_style = console.get_style
        null_style = Style.null()
        guide_style = get_style(self.guide_style, default="""") or null_style
        SPACE, CONTINUE, FORK, END = range(4)

        _Segment = Segment

        def make_guide(index: int, style: Style) -> Segment:
            
            if options.ascii_only:
                line = self.ASCII_GUIDES[index]
            else:
                guide = 1 if style.bold else (2 if style.underline2 else 0)
                line = self.TREE_GUIDES[0 if options.legacy_windows else guide][index]
            return _Segment(line, style)

        levels: List[Segment] = [make_guide(CONTINUE, guide_style)]
        push(iter(loop_last([self])))

        guide_style_stack = StyleStack(get_style(self.guide_style))
        style_stack = StyleStack(get_style(self.style))
        remove_guide_styles = Style(bold=False, underline2=False)

        depth = 0

        while stack:
            stack_node = pop()
            try:
                last, node = next(stack_node)
            except StopIteration:
                levels.pop()
                if levels:
                    guide_style = levels[-1].style or null_style
                    levels[-1] = make_guide(FORK, guide_style)
                    guide_style_stack.pop()
                    style_stack.pop()
                continue
            push(stack_node)
            if last:
                levels[-1] = make_guide(END, levels[-1].style or null_style)

            guide_style = guide_style_stack.current + get_style(node.guide_style)
            style = style_stack.current + get_style(node.style)
            prefix = levels[(2 if self.hide_root else 1) :]
            renderable_lines = console.render_lines(
                Styled(node.label, style),
                options.update(
                    width=options.max_width
                    - sum(level.cell_length for level in prefix),
                    highlight=self.highlight,
                    height=None,
                ),
                pad=options.justify is not None,
            )

            if not (depth == 0 and self.hide_root):
                for first, line in loop_first(renderable_lines):
                    if prefix:
                        yield from _Segment.apply_style(
                            prefix,
                            style.background_style,
                            post_style=remove_guide_styles,
                        )
                    yield from line
                    yield new_line
                    if first and prefix:
                        prefix[-1] = make_guide(
                            SPACE if last else CONTINUE, prefix[-1].style or null_style
                        )

            if node.expanded and node.children:
                levels[-1] = make_guide(
                    SPACE if last else CONTINUE, levels[-1].style or null_style
                )
                levels.append(
                    make_guide(END if len(node.children) == 1 else FORK, guide_style)
                )
                style_stack.push(get_style(node.style))
                guide_style_stack.push(get_style(node.guide_style))
                push(iter(loop_last(node.children)))
                depth += 1

    def __rich_measure__(
        self, console: ""Console"", options: ""ConsoleOptions""
    ) -> ""Measurement"":
        stack: List[Iterator[Tree]] = [iter([self])]
        pop = stack.pop
        push = stack.append
        minimum = 0
        maximum = 0
        measure = Measurement.get
        level = 0
        while stack:
            iter_tree = pop()
            try:
                tree = next(iter_tree)
            except StopIteration:
                level -= 1
                continue
            push(iter_tree)
            min_measure, max_measure = measure(console, options, tree.label)
            indent = level * 4
            minimum = max(min_measure + indent, minimum)
            maximum = max(max_measure + indent, maximum)
            if tree.expanded and tree.children:
                push(iter(tree.children))
                level += 1
        return Measurement(minimum, maximum)


if __name__ == ""__main__"":  
    from pip._vendor.rich.console import Group
    from pip._vendor.rich.markdown import Markdown
    from pip._vendor.rich.panel import Panel
    from pip._vendor.rich.syntax import Syntax
    from pip._vendor.rich.table import Table

    table = Table(row_styles=["""", ""dim""])

    table.add_column(""Released"", style=""cyan"", no_wrap=True)
    table.add_column(""Title"", style=""magenta"")
    table.add_column(""Box Office"", justify=""right"", style=""green"")

    table.add_row(""Dec 20, 2019"", ""Star Wars: The Rise of Skywalker"", ""$952,110,690"")
    table.add_row(""May 25, 2018"", ""Solo: A Star Wars Story"", ""$393,151,347"")
    table.add_row(""Dec 15, 2017"", ""Star Wars Ep. V111: The Last Jedi"", ""$1,332,539,889"")
    table.add_row(""Dec 16, 2016"", ""Rogue One: A Star Wars Story"", ""$1,332,439,889"")

    code = 
    syntax = Syntax(code, ""python"", theme=""monokai"", line_numbers=True)

    markdown = Markdown(
        
    )

    root = Tree(""🌲 [b green]Rich Tree"", highlight=True, hide_root=True)

    node = root.add("":file_folder: Renderables"", guide_style=""red"")
    simple_node = node.add("":file_folder: [bold yellow]Atomic"", guide_style=""uu green"")
    simple_node.add(Group(""📄 Syntax"", syntax))
    simple_node.add(Group(""📄 Markdown"", Panel(markdown, border_style=""green"")))

    containers_node = node.add(
        "":file_folder: [bold magenta]Containers"", guide_style=""bold magenta""
    )
    containers_node.expanded = True
    panel = Panel.fit(""Just a panel"", border_style=""red"")
    containers_node.add(Group(""📄 Panels"", panel))

    containers_node.add(Group(""📄 [b magenta]Table"", table))

    console = Console()

    console.print(root)



CELL_WIDTHS = [
    (0, 0, 0),
    (1, 31, -1),
    (127, 159, -1),
    (173, 173, 0),
    (768, 879, 0),
    (1155, 1161, 0),
    (1425, 1469, 0),
    (1471, 1471, 0),
    (1473, 1474, 0),
    (1476, 1477, 0),
    (1479, 1479, 0),
    (1536, 1541, 0),
    (1552, 1562, 0),
    (1564, 1564, 0),
    (1611, 1631, 0),
    (1648, 1648, 0),
    (1750, 1757, 0),
    (1759, 1764, 0),
    (1767, 1768, 0),
    (1770, 1773, 0),
    (1807, 1807, 0),
    (1809, 1809, 0),
    (1840, 1866, 0),
    (1958, 1968, 0),
    (2027, 2035, 0),
    (2045, 2045, 0),
    (2070, 2073, 0),
    (2075, 2083, 0),
    (2085, 2087, 0),
    (2089, 2093, 0),
    (2137, 2139, 0),
    (2192, 2193, 0),
    (2200, 2207, 0),
    (2250, 2307, 0),
    (2362, 2364, 0),
    (2366, 2383, 0),
    (2385, 2391, 0),
    (2402, 2403, 0),
    (2433, 2435, 0),
    (2492, 2492, 0),
    (2494, 2500, 0),
    (2503, 2504, 0),
    (2507, 2509, 0),
    (2519, 2519, 0),
    (2530, 2531, 0),
    (2558, 2558, 0),
    (2561, 2563, 0),
    (2620, 2620, 0),
    (2622, 2626, 0),
    (2631, 2632, 0),
    (2635, 2637, 0),
    (2641, 2641, 0),
    (2672, 2673, 0),
    (2677, 2677, 0),
    (2689, 2691, 0),
    (2748, 2748, 0),
    (2750, 2757, 0),
    (2759, 2761, 0),
    (2763, 2765, 0),
    (2786, 2787, 0),
    (2810, 2815, 0),
    (2817, 2819, 0),
    (2876, 2876, 0),
    (2878, 2884, 0),
    (2887, 2888, 0),
    (2891, 2893, 0),
    (2901, 2903, 0),
    (2914, 2915, 0),
    (2946, 2946, 0),
    (3006, 3010, 0),
    (3014, 3016, 0),
    (3018, 3021, 0),
    (3031, 3031, 0),
    (3072, 3076, 0),
    (3132, 3132, 0),
    (3134, 3140, 0),
    (3142, 3144, 0),
    (3146, 3149, 0),
    (3157, 3158, 0),
    (3170, 3171, 0),
    (3201, 3203, 0),
    (3260, 3260, 0),
    (3262, 3268, 0),
    (3270, 3272, 0),
    (3274, 3277, 0),
    (3285, 3286, 0),
    (3298, 3299, 0),
    (3315, 3315, 0),
    (3328, 3331, 0),
    (3387, 3388, 0),
    (3390, 3396, 0),
    (3398, 3400, 0),
    (3402, 3405, 0),
    (3415, 3415, 0),
    (3426, 3427, 0),
    (3457, 3459, 0),
    (3530, 3530, 0),
    (3535, 3540, 0),
    (3542, 3542, 0),
    (3544, 3551, 0),
    (3570, 3571, 0),
    (3633, 3633, 0),
    (3636, 3642, 0),
    (3655, 3662, 0),
    (3761, 3761, 0),
    (3764, 3772, 0),
    (3784, 3790, 0),
    (3864, 3865, 0),
    (3893, 3893, 0),
    (3895, 3895, 0),
    (3897, 3897, 0),
    (3902, 3903, 0),
    (3953, 3972, 0),
    (3974, 3975, 0),
    (3981, 3991, 0),
    (3993, 4028, 0),
    (4038, 4038, 0),
    (4139, 4158, 0),
    (4182, 4185, 0),
    (4190, 4192, 0),
    (4194, 4196, 0),
    (4199, 4205, 0),
    (4209, 4212, 0),
    (4226, 4237, 0),
    (4239, 4239, 0),
    (4250, 4253, 0),
    (4352, 4447, 2),
    (4448, 4607, 0),
    (4957, 4959, 0),
    (5906, 5909, 0),
    (5938, 5940, 0),
    (5970, 5971, 0),
    (6002, 6003, 0),
    (6068, 6099, 0),
    (6109, 6109, 0),
    (6155, 6159, 0),
    (6277, 6278, 0),
    (6313, 6313, 0),
    (6432, 6443, 0),
    (6448, 6459, 0),
    (6679, 6683, 0),
    (6741, 6750, 0),
    (6752, 6780, 0),
    (6783, 6783, 0),
    (6832, 6862, 0),
    (6912, 6916, 0),
    (6964, 6980, 0),
    (7019, 7027, 0),
    (7040, 7042, 0),
    (7073, 7085, 0),
    (7142, 7155, 0),
    (7204, 7223, 0),
    (7376, 7378, 0),
    (7380, 7400, 0),
    (7405, 7405, 0),
    (7412, 7412, 0),
    (7415, 7417, 0),
    (7616, 7679, 0),
    (8203, 8207, 0),
    (8232, 8238, 0),
    (8288, 8292, 0),
    (8294, 8303, 0),
    (8400, 8432, 0),
    (8986, 8987, 2),
    (9001, 9002, 2),
    (9193, 9196, 2),
    (9200, 9200, 2),
    (9203, 9203, 2),
    (9725, 9726, 2),
    (9748, 9749, 2),
    (9800, 9811, 2),
    (9855, 9855, 2),
    (9875, 9875, 2),
    (9889, 9889, 2),
    (9898, 9899, 2),
    (9917, 9918, 2),
    (9924, 9925, 2),
    (9934, 9934, 2),
    (9940, 9940, 2),
    (9962, 9962, 2),
    (9970, 9971, 2),
    (9973, 9973, 2),
    (9978, 9978, 2),
    (9981, 9981, 2),
    (9989, 9989, 2),
    (9994, 9995, 2),
    (10024, 10024, 2),
    (10060, 10060, 2),
    (10062, 10062, 2),
    (10067, 10069, 2),
    (10071, 10071, 2),
    (10133, 10135, 2),
    (10160, 10160, 2),
    (10175, 10175, 2),
    (11035, 11036, 2),
    (11088, 11088, 2),
    (11093, 11093, 2),
    (11503, 11505, 0),
    (11647, 11647, 0),
    (11744, 11775, 0),
    (11904, 11929, 2),
    (11931, 12019, 2),
    (12032, 12245, 2),
    (12272, 12329, 2),
    (12330, 12335, 0),
    (12336, 12350, 2),
    (12353, 12438, 2),
    (12441, 12442, 0),
    (12443, 12543, 2),
    (12549, 12591, 2),
    (12593, 12686, 2),
    (12688, 12771, 2),
    (12783, 12830, 2),
    (12832, 12871, 2),
    (12880, 19903, 2),
    (19968, 42124, 2),
    (42128, 42182, 2),
    (42607, 42610, 0),
    (42612, 42621, 0),
    (42654, 42655, 0),
    (42736, 42737, 0),
    (43010, 43010, 0),
    (43014, 43014, 0),
    (43019, 43019, 0),
    (43043, 43047, 0),
    (43052, 43052, 0),
    (43136, 43137, 0),
    (43188, 43205, 0),
    (43232, 43249, 0),
    (43263, 43263, 0),
    (43302, 43309, 0),
    (43335, 43347, 0),
    (43360, 43388, 2),
    (43392, 43395, 0),
    (43443, 43456, 0),
    (43493, 43493, 0),
    (43561, 43574, 0),
    (43587, 43587, 0),
    (43596, 43597, 0),
    (43643, 43645, 0),
    (43696, 43696, 0),
    (43698, 43700, 0),
    (43703, 43704, 0),
    (43710, 43711, 0),
    (43713, 43713, 0),
    (43755, 43759, 0),
    (43765, 43766, 0),
    (44003, 44010, 0),
    (44012, 44013, 0),
    (44032, 55203, 2),
    (55216, 55295, 0),
    (63744, 64255, 2),
    (64286, 64286, 0),
    (65024, 65039, 0),
    (65040, 65049, 2),
    (65056, 65071, 0),
    (65072, 65106, 2),
    (65108, 65126, 2),
    (65128, 65131, 2),
    (65279, 65279, 0),
    (65281, 65376, 2),
    (65504, 65510, 2),
    (65529, 65531, 0),
    (66045, 66045, 0),
    (66272, 66272, 0),
    (66422, 66426, 0),
    (68097, 68099, 0),
    (68101, 68102, 0),
    (68108, 68111, 0),
    (68152, 68154, 0),
    (68159, 68159, 0),
    (68325, 68326, 0),
    (68900, 68903, 0),
    (69291, 69292, 0),
    (69373, 69375, 0),
    (69446, 69456, 0),
    (69506, 69509, 0),
    (69632, 69634, 0),
    (69688, 69702, 0),
    (69744, 69744, 0),
    (69747, 69748, 0),
    (69759, 69762, 0),
    (69808, 69818, 0),
    (69821, 69821, 0),
    (69826, 69826, 0),
    (69837, 69837, 0),
    (69888, 69890, 0),
    (69927, 69940, 0),
    (69957, 69958, 0),
    (70003, 70003, 0),
    (70016, 70018, 0),
    (70067, 70080, 0),
    (70089, 70092, 0),
    (70094, 70095, 0),
    (70188, 70199, 0),
    (70206, 70206, 0),
    (70209, 70209, 0),
    (70367, 70378, 0),
    (70400, 70403, 0),
    (70459, 70460, 0),
    (70462, 70468, 0),
    (70471, 70472, 0),
    (70475, 70477, 0),
    (70487, 70487, 0),
    (70498, 70499, 0),
    (70502, 70508, 0),
    (70512, 70516, 0),
    (70709, 70726, 0),
    (70750, 70750, 0),
    (70832, 70851, 0),
    (71087, 71093, 0),
    (71096, 71104, 0),
    (71132, 71133, 0),
    (71216, 71232, 0),
    (71339, 71351, 0),
    (71453, 71467, 0),
    (71724, 71738, 0),
    (71984, 71989, 0),
    (71991, 71992, 0),
    (71995, 71998, 0),
    (72000, 72000, 0),
    (72002, 72003, 0),
    (72145, 72151, 0),
    (72154, 72160, 0),
    (72164, 72164, 0),
    (72193, 72202, 0),
    (72243, 72249, 0),
    (72251, 72254, 0),
    (72263, 72263, 0),
    (72273, 72283, 0),
    (72330, 72345, 0),
    (72751, 72758, 0),
    (72760, 72767, 0),
    (72850, 72871, 0),
    (72873, 72886, 0),
    (73009, 73014, 0),
    (73018, 73018, 0),
    (73020, 73021, 0),
    (73023, 73029, 0),
    (73031, 73031, 0),
    (73098, 73102, 0),
    (73104, 73105, 0),
    (73107, 73111, 0),
    (73459, 73462, 0),
    (73472, 73473, 0),
    (73475, 73475, 0),
    (73524, 73530, 0),
    (73534, 73538, 0),
    (78896, 78912, 0),
    (78919, 78933, 0),
    (92912, 92916, 0),
    (92976, 92982, 0),
    (94031, 94031, 0),
    (94033, 94087, 0),
    (94095, 94098, 0),
    (94176, 94179, 2),
    (94180, 94180, 0),
    (94192, 94193, 0),
    (94208, 100343, 2),
    (100352, 101589, 2),
    (101632, 101640, 2),
    (110576, 110579, 2),
    (110581, 110587, 2),
    (110589, 110590, 2),
    (110592, 110882, 2),
    (110898, 110898, 2),
    (110928, 110930, 2),
    (110933, 110933, 2),
    (110948, 110951, 2),
    (110960, 111355, 2),
    (113821, 113822, 0),
    (113824, 113827, 0),
    (118528, 118573, 0),
    (118576, 118598, 0),
    (119141, 119145, 0),
    (119149, 119170, 0),
    (119173, 119179, 0),
    (119210, 119213, 0),
    (119362, 119364, 0),
    (121344, 121398, 0),
    (121403, 121452, 0),
    (121461, 121461, 0),
    (121476, 121476, 0),
    (121499, 121503, 0),
    (121505, 121519, 0),
    (122880, 122886, 0),
    (122888, 122904, 0),
    (122907, 122913, 0),
    (122915, 122916, 0),
    (122918, 122922, 0),
    (123023, 123023, 0),
    (123184, 123190, 0),
    (123566, 123566, 0),
    (123628, 123631, 0),
    (124140, 124143, 0),
    (125136, 125142, 0),
    (125252, 125258, 0),
    (126980, 126980, 2),
    (127183, 127183, 2),
    (127374, 127374, 2),
    (127377, 127386, 2),
    (127488, 127490, 2),
    (127504, 127547, 2),
    (127552, 127560, 2),
    (127568, 127569, 2),
    (127584, 127589, 2),
    (127744, 127776, 2),
    (127789, 127797, 2),
    (127799, 127868, 2),
    (127870, 127891, 2),
    (127904, 127946, 2),
    (127951, 127955, 2),
    (127968, 127984, 2),
    (127988, 127988, 2),
    (127992, 127994, 2),
    (127995, 127999, 0),
    (128000, 128062, 2),
    (128064, 128064, 2),
    (128066, 128252, 2),
    (128255, 128317, 2),
    (128331, 128334, 2),
    (128336, 128359, 2),
    (128378, 128378, 2),
    (128405, 128406, 2),
    (128420, 128420, 2),
    (128507, 128591, 2),
    (128640, 128709, 2),
    (128716, 128716, 2),
    (128720, 128722, 2),
    (128725, 128727, 2),
    (128732, 128735, 2),
    (128747, 128748, 2),
    (128756, 128764, 2),
    (128992, 129003, 2),
    (129008, 129008, 2),
    (129292, 129338, 2),
    (129340, 129349, 2),
    (129351, 129535, 2),
    (129648, 129660, 2),
    (129664, 129672, 2),
    (129680, 129725, 2),
    (129727, 129733, 2),
    (129742, 129755, 2),
    (129760, 129768, 2),
    (129776, 129784, 2),
    (131072, 196605, 2),
    (196608, 262141, 2),
    (917505, 917505, 0),
    (917536, 917631, 0),
    (917760, 917999, 0),
]

EMOJI = {
    ""1st_place_medal"": ""🥇"",
    ""2nd_place_medal"": ""🥈"",
    ""3rd_place_medal"": ""🥉"",
    ""ab_button_(blood_type)"": ""🆎"",
    ""atm_sign"": ""🏧"",
    ""a_button_(blood_type)"": ""🅰"",
    ""afghanistan"": ""🇦🇫"",
    ""albania"": ""🇦🇱"",
    ""algeria"": ""🇩🇿"",
    ""american_samoa"": ""🇦🇸"",
    ""andorra"": ""🇦🇩"",
    ""angola"": ""🇦🇴"",
    ""anguilla"": ""🇦🇮"",
    ""antarctica"": ""🇦🇶"",
    ""antigua_&_barbuda"": ""🇦🇬"",
    ""aquarius"": ""♒"",
    ""argentina"": ""🇦🇷"",
    ""aries"": ""♈"",
    ""armenia"": ""🇦🇲"",
    ""aruba"": ""🇦🇼"",
    ""ascension_island"": ""🇦🇨"",
    ""australia"": ""🇦🇺"",
    ""austria"": ""🇦🇹"",
    ""azerbaijan"": ""🇦🇿"",
    ""back_arrow"": ""🔙"",
    ""b_button_(blood_type)"": ""🅱"",
    ""bahamas"": ""🇧🇸"",
    ""bahrain"": ""🇧🇭"",
    ""bangladesh"": ""🇧🇩"",
    ""barbados"": ""🇧🇧"",
    ""belarus"": ""🇧🇾"",
    ""belgium"": ""🇧🇪"",
    ""belize"": ""🇧🇿"",
    ""benin"": ""🇧🇯"",
    ""bermuda"": ""🇧🇲"",
    ""bhutan"": ""🇧🇹"",
    ""bolivia"": ""🇧🇴"",
    ""bosnia_&_herzegovina"": ""🇧🇦"",
    ""botswana"": ""🇧🇼"",
    ""bouvet_island"": ""🇧🇻"",
    ""brazil"": ""🇧🇷"",
    ""british_indian_ocean_territory"": ""🇮🇴"",
    ""british_virgin_islands"": ""🇻🇬"",
    ""brunei"": ""🇧🇳"",
    ""bulgaria"": ""🇧🇬"",
    ""burkina_faso"": ""🇧🇫"",
    ""burundi"": ""🇧🇮"",
    ""cl_button"": ""🆑"",
    ""cool_button"": ""🆒"",
    ""cambodia"": ""🇰🇭"",
    ""cameroon"": ""🇨🇲"",
    ""canada"": ""🇨🇦"",
    ""canary_islands"": ""🇮🇨"",
    ""cancer"": ""♋"",
    ""cape_verde"": ""🇨🇻"",
    ""capricorn"": ""♑"",
    ""caribbean_netherlands"": ""🇧🇶"",
    ""cayman_islands"": ""🇰🇾"",
    ""central_african_republic"": ""🇨🇫"",
    ""ceuta_&_melilla"": ""🇪🇦"",
    ""chad"": ""🇹🇩"",
    ""chile"": ""🇨🇱"",
    ""china"": ""🇨🇳"",
    ""christmas_island"": ""🇨🇽"",
    ""christmas_tree"": ""🎄"",
    ""clipperton_island"": ""🇨🇵"",
    ""cocos_(keeling)_islands"": ""🇨🇨"",
    ""colombia"": ""🇨🇴"",
    ""comoros"": ""🇰🇲"",
    ""congo_-_brazzaville"": ""🇨🇬"",
    ""congo_-_kinshasa"": ""🇨🇩"",
    ""cook_islands"": ""🇨🇰"",
    ""costa_rica"": ""🇨🇷"",
    ""croatia"": ""🇭🇷"",
    ""cuba"": ""🇨🇺"",
    ""curaçao"": ""🇨🇼"",
    ""cyprus"": ""🇨🇾"",
    ""czechia"": ""🇨🇿"",
    ""côte_d’ivoire"": ""🇨🇮"",
    ""denmark"": ""🇩🇰"",
    ""diego_garcia"": ""🇩🇬"",
    ""djibouti"": ""🇩🇯"",
    ""dominica"": ""🇩🇲"",
    ""dominican_republic"": ""🇩🇴"",
    ""end_arrow"": ""🔚"",
    ""ecuador"": ""🇪🇨"",
    ""egypt"": ""🇪🇬"",
    ""el_salvador"": ""🇸🇻"",
    ""england"": ""🏴\U000e0067\U000e0062\U000e0065\U000e006e\U000e0067\U000e007f"",
    ""equatorial_guinea"": ""🇬🇶"",
    ""eritrea"": ""🇪🇷"",
    ""estonia"": ""🇪🇪"",
    ""ethiopia"": ""🇪🇹"",
    ""european_union"": ""🇪🇺"",
    ""free_button"": ""🆓"",
    ""falkland_islands"": ""🇫🇰"",
    ""faroe_islands"": ""🇫🇴"",
    ""fiji"": ""🇫🇯"",
    ""finland"": ""🇫🇮"",
    ""france"": ""🇫🇷"",
    ""french_guiana"": ""🇬🇫"",
    ""french_polynesia"": ""🇵🇫"",
    ""french_southern_territories"": ""🇹🇫"",
    ""gabon"": ""🇬🇦"",
    ""gambia"": ""🇬🇲"",
    ""gemini"": ""♊"",
    ""georgia"": ""🇬🇪"",
    ""germany"": ""🇩🇪"",
    ""ghana"": ""🇬🇭"",
    ""gibraltar"": ""🇬🇮"",
    ""greece"": ""🇬🇷"",
    ""greenland"": ""🇬🇱"",
    ""grenada"": ""🇬🇩"",
    ""guadeloupe"": ""🇬🇵"",
    ""guam"": ""🇬🇺"",
    ""guatemala"": ""🇬🇹"",
    ""guernsey"": ""🇬🇬"",
    ""guinea"": ""🇬🇳"",
    ""guinea-bissau"": ""🇬🇼"",
    ""guyana"": ""🇬🇾"",
    ""haiti"": ""🇭🇹"",
    ""heard_&_mcdonald_islands"": ""🇭🇲"",
    ""honduras"": ""🇭🇳"",
    ""hong_kong_sar_china"": ""🇭🇰"",
    ""hungary"": ""🇭🇺"",
    ""id_button"": ""🆔"",
    ""iceland"": ""🇮🇸"",
    ""india"": ""🇮🇳"",
    ""indonesia"": ""🇮🇩"",
    ""iran"": ""🇮🇷"",
    ""iraq"": ""🇮🇶"",
    ""ireland"": ""🇮🇪"",
    ""isle_of_man"": ""🇮🇲"",
    ""israel"": ""🇮🇱"",
    ""italy"": ""🇮🇹"",
    ""jamaica"": ""🇯🇲"",
    ""japan"": ""🗾"",
    ""japanese_acceptable_button"": ""🉑"",
    ""japanese_application_button"": ""🈸"",
    ""japanese_bargain_button"": ""🉐"",
    ""japanese_castle"": ""🏯"",
    ""japanese_congratulations_button"": ""㊗"",
    ""japanese_discount_button"": ""🈹"",
    ""japanese_dolls"": ""🎎"",
    ""japanese_free_of_charge_button"": ""🈚"",
    ""japanese_here_button"": ""🈁"",
    ""japanese_monthly_amount_button"": ""🈷"",
    ""japanese_no_vacancy_button"": ""🈵"",
    ""japanese_not_free_of_charge_button"": ""🈶"",
    ""japanese_open_for_business_button"": ""🈺"",
    ""japanese_passing_grade_button"": ""🈴"",
    ""japanese_post_office"": ""🏣"",
    ""japanese_prohibited_button"": ""🈲"",
    ""japanese_reserved_button"": ""🈯"",
    ""japanese_secret_button"": ""㊙"",
    ""japanese_service_charge_button"": ""🈂"",
    ""japanese_symbol_for_beginner"": ""🔰"",
    ""japanese_vacancy_button"": ""🈳"",
    ""jersey"": ""🇯🇪"",
    ""jordan"": ""🇯🇴"",
    ""kazakhstan"": ""🇰🇿"",
    ""kenya"": ""🇰🇪"",
    ""kiribati"": ""🇰🇮"",
    ""kosovo"": ""🇽🇰"",
    ""kuwait"": ""🇰🇼"",
    ""kyrgyzstan"": ""🇰🇬"",
    ""laos"": ""🇱🇦"",
    ""latvia"": ""🇱🇻"",
    ""lebanon"": ""🇱🇧"",
    ""leo"": ""♌"",
    ""lesotho"": ""🇱🇸"",
    ""liberia"": ""🇱🇷"",
    ""libra"": ""♎"",
    ""libya"": ""🇱🇾"",
    ""liechtenstein"": ""🇱🇮"",
    ""lithuania"": ""🇱🇹"",
    ""luxembourg"": ""🇱🇺"",
    ""macau_sar_china"": ""🇲🇴"",
    ""macedonia"": ""🇲🇰"",
    ""madagascar"": ""🇲🇬"",
    ""malawi"": ""🇲🇼"",
    ""malaysia"": ""🇲🇾"",
    ""maldives"": ""🇲🇻"",
    ""mali"": ""🇲🇱"",
    ""malta"": ""🇲🇹"",
    ""marshall_islands"": ""🇲🇭"",
    ""martinique"": ""🇲🇶"",
    ""mauritania"": ""🇲🇷"",
    ""mauritius"": ""🇲🇺"",
    ""mayotte"": ""🇾🇹"",
    ""mexico"": ""🇲🇽"",
    ""micronesia"": ""🇫🇲"",
    ""moldova"": ""🇲🇩"",
    ""monaco"": ""🇲🇨"",
    ""mongolia"": ""🇲🇳"",
    ""montenegro"": ""🇲🇪"",
    ""montserrat"": ""🇲🇸"",
    ""morocco"": ""🇲🇦"",
    ""mozambique"": ""🇲🇿"",
    ""mrs._claus"": ""🤶"",
    ""mrs._claus_dark_skin_tone"": ""🤶🏿"",
    ""mrs._claus_light_skin_tone"": ""🤶🏻"",
    ""mrs._claus_medium-dark_skin_tone"": ""🤶🏾"",
    ""mrs._claus_medium-light_skin_tone"": ""🤶🏼"",
    ""mrs._claus_medium_skin_tone"": ""🤶🏽"",
    ""myanmar_(burma)"": ""🇲🇲"",
    ""new_button"": ""🆕"",
    ""ng_button"": ""🆖"",
    ""namibia"": ""🇳🇦"",
    ""nauru"": ""🇳🇷"",
    ""nepal"": ""🇳🇵"",
    ""netherlands"": ""🇳🇱"",
    ""new_caledonia"": ""🇳🇨"",
    ""new_zealand"": ""🇳🇿"",
    ""nicaragua"": ""🇳🇮"",
    ""niger"": ""🇳🇪"",
    ""nigeria"": ""🇳🇬"",
    ""niue"": ""🇳🇺"",
    ""norfolk_island"": ""🇳🇫"",
    ""north_korea"": ""🇰🇵"",
    ""northern_mariana_islands"": ""🇲🇵"",
    ""norway"": ""🇳🇴"",
    ""ok_button"": ""🆗"",
    ""ok_hand"": ""👌"",
    ""ok_hand_dark_skin_tone"": ""👌🏿"",
    ""ok_hand_light_skin_tone"": ""👌🏻"",
    ""ok_hand_medium-dark_skin_tone"": ""👌🏾"",
    ""ok_hand_medium-light_skin_tone"": ""👌🏼"",
    ""ok_hand_medium_skin_tone"": ""👌🏽"",
    ""on!_arrow"": ""🔛"",
    ""o_button_(blood_type)"": ""🅾"",
    ""oman"": ""🇴🇲"",
    ""ophiuchus"": ""⛎"",
    ""p_button"": ""🅿"",
    ""pakistan"": ""🇵🇰"",
    ""palau"": ""🇵🇼"",
    ""palestinian_territories"": ""🇵🇸"",
    ""panama"": ""🇵🇦"",
    ""papua_new_guinea"": ""🇵🇬"",
    ""paraguay"": ""🇵🇾"",
    ""peru"": ""🇵🇪"",
    ""philippines"": ""🇵🇭"",
    ""pisces"": ""♓"",
    ""pitcairn_islands"": ""🇵🇳"",
    ""poland"": ""🇵🇱"",
    ""portugal"": ""🇵🇹"",
    ""puerto_rico"": ""🇵🇷"",
    ""qatar"": ""🇶🇦"",
    ""romania"": ""🇷🇴"",
    ""russia"": ""🇷🇺"",
    ""rwanda"": ""🇷🇼"",
    ""réunion"": ""🇷🇪"",
    ""soon_arrow"": ""🔜"",
    ""sos_button"": ""🆘"",
    ""sagittarius"": ""♐"",
    ""samoa"": ""🇼🇸"",
    ""san_marino"": ""🇸🇲"",
    ""santa_claus"": ""🎅"",
    ""santa_claus_dark_skin_tone"": ""🎅🏿"",
    ""santa_claus_light_skin_tone"": ""🎅🏻"",
    ""santa_claus_medium-dark_skin_tone"": ""🎅🏾"",
    ""santa_claus_medium-light_skin_tone"": ""🎅🏼"",
    ""santa_claus_medium_skin_tone"": ""🎅🏽"",
    ""saudi_arabia"": ""🇸🇦"",
    ""scorpio"": ""♏"",
    ""scotland"": ""🏴\U000e0067\U000e0062\U000e0073\U000e0063\U000e0074\U000e007f"",
    ""senegal"": ""🇸🇳"",
    ""serbia"": ""🇷🇸"",
    ""seychelles"": ""🇸🇨"",
    ""sierra_leone"": ""🇸🇱"",
    ""singapore"": ""🇸🇬"",
    ""sint_maarten"": ""🇸🇽"",
    ""slovakia"": ""🇸🇰"",
    ""slovenia"": ""🇸🇮"",
    ""solomon_islands"": ""🇸🇧"",
    ""somalia"": ""🇸🇴"",
    ""south_africa"": ""🇿🇦"",
    ""south_georgia_&_south_sandwich_islands"": ""🇬🇸"",
    ""south_korea"": ""🇰🇷"",
    ""south_sudan"": ""🇸🇸"",
    ""spain"": ""🇪🇸"",
    ""sri_lanka"": ""🇱🇰"",
    ""st._barthélemy"": ""🇧🇱"",
    ""st._helena"": ""🇸🇭"",
    ""st._kitts_&_nevis"": ""🇰🇳"",
    ""st._lucia"": ""🇱🇨"",
    ""st._martin"": ""🇲🇫"",
    ""st._pierre_&_miquelon"": ""🇵🇲"",
    ""st._vincent_&_grenadines"": ""🇻🇨"",
    ""statue_of_liberty"": ""🗽"",
    ""sudan"": ""🇸🇩"",
    ""suriname"": ""🇸🇷"",
    ""svalbard_&_jan_mayen"": ""🇸🇯"",
    ""swaziland"": ""🇸🇿"",
    ""sweden"": ""🇸🇪"",
    ""switzerland"": ""🇨🇭"",
    ""syria"": ""🇸🇾"",
    ""são_tomé_&_príncipe"": ""🇸🇹"",
    ""t-rex"": ""🦖"",
    ""top_arrow"": ""🔝"",
    ""taiwan"": ""🇹🇼"",
    ""tajikistan"": ""🇹🇯"",
    ""tanzania"": ""🇹🇿"",
    ""taurus"": ""♉"",
    ""thailand"": ""🇹🇭"",
    ""timor-leste"": ""🇹🇱"",
    ""togo"": ""🇹🇬"",
    ""tokelau"": ""🇹🇰"",
    ""tokyo_tower"": ""🗼"",
    ""tonga"": ""🇹🇴"",
    ""trinidad_&_tobago"": ""🇹🇹"",
    ""tristan_da_cunha"": ""🇹🇦"",
    ""tunisia"": ""🇹🇳"",
    ""turkey"": ""🦃"",
    ""turkmenistan"": ""🇹🇲"",
    ""turks_&_caicos_islands"": ""🇹🇨"",
    ""tuvalu"": ""🇹🇻"",
    ""u.s._outlying_islands"": ""🇺🇲"",
    ""u.s._virgin_islands"": ""🇻🇮"",
    ""up!_button"": ""🆙"",
    ""uganda"": ""🇺🇬"",
    ""ukraine"": ""🇺🇦"",
    ""united_arab_emirates"": ""🇦🇪"",
    ""united_kingdom"": ""🇬🇧"",
    ""united_nations"": ""🇺🇳"",
    ""united_states"": ""🇺🇸"",
    ""uruguay"": ""🇺🇾"",
    ""uzbekistan"": ""🇺🇿"",
    ""vs_button"": ""🆚"",
    ""vanuatu"": ""🇻🇺"",
    ""vatican_city"": ""🇻🇦"",
    ""venezuela"": ""🇻🇪"",
    ""vietnam"": ""🇻🇳"",
    ""virgo"": ""♍"",
    ""wales"": ""🏴\U000e0067\U000e0062\U000e0077\U000e006c\U000e0073\U000e007f"",
    ""wallis_&_futuna"": ""🇼🇫"",
    ""western_sahara"": ""🇪🇭"",
    ""yemen"": ""🇾🇪"",
    ""zambia"": ""🇿🇲"",
    ""zimbabwe"": ""🇿🇼"",
    ""abacus"": ""🧮"",
    ""adhesive_bandage"": ""🩹"",
    ""admission_tickets"": ""🎟"",
    ""adult"": ""🧑"",
    ""adult_dark_skin_tone"": ""🧑🏿"",
    ""adult_light_skin_tone"": ""🧑🏻"",
    ""adult_medium-dark_skin_tone"": ""🧑🏾"",
    ""adult_medium-light_skin_tone"": ""🧑🏼"",
    ""adult_medium_skin_tone"": ""🧑🏽"",
    ""aerial_tramway"": ""🚡"",
    ""airplane"": ""✈"",
    ""airplane_arrival"": ""🛬"",
    ""airplane_departure"": ""🛫"",
    ""alarm_clock"": ""⏰"",
    ""alembic"": ""⚗"",
    ""alien"": ""👽"",
    ""alien_monster"": ""👾"",
    ""ambulance"": ""🚑"",
    ""american_football"": ""🏈"",
    ""amphora"": ""🏺"",
    ""anchor"": ""⚓"",
    ""anger_symbol"": ""💢"",
    ""angry_face"": ""😠"",
    ""angry_face_with_horns"": ""👿"",
    ""anguished_face"": ""😧"",
    ""ant"": ""🐜"",
    ""antenna_bars"": ""📶"",
    ""anxious_face_with_sweat"": ""😰"",
    ""articulated_lorry"": ""🚛"",
    ""artist_palette"": ""🎨"",
    ""astonished_face"": ""😲"",
    ""atom_symbol"": ""⚛"",
    ""auto_rickshaw"": ""🛺"",
    ""automobile"": ""🚗"",
    ""avocado"": ""🥑"",
    ""axe"": ""🪓"",
    ""baby"": ""👶"",
    ""baby_angel"": ""👼"",
    ""baby_angel_dark_skin_tone"": ""👼🏿"",
    ""baby_angel_light_skin_tone"": ""👼🏻"",
    ""baby_angel_medium-dark_skin_tone"": ""👼🏾"",
    ""baby_angel_medium-light_skin_tone"": ""👼🏼"",
    ""baby_angel_medium_skin_tone"": ""👼🏽"",
    ""baby_bottle"": ""🍼"",
    ""baby_chick"": ""🐤"",
    ""baby_dark_skin_tone"": ""👶🏿"",
    ""baby_light_skin_tone"": ""👶🏻"",
    ""baby_medium-dark_skin_tone"": ""👶🏾"",
    ""baby_medium-light_skin_tone"": ""👶🏼"",
    ""baby_medium_skin_tone"": ""👶🏽"",
    ""baby_symbol"": ""🚼"",
    ""backhand_index_pointing_down"": ""👇"",
    ""backhand_index_pointing_down_dark_skin_tone"": ""👇🏿"",
    ""backhand_index_pointing_down_light_skin_tone"": ""👇🏻"",
    ""backhand_index_pointing_down_medium-dark_skin_tone"": ""👇🏾"",
    ""backhand_index_pointing_down_medium-light_skin_tone"": ""👇🏼"",
    ""backhand_index_pointing_down_medium_skin_tone"": ""👇🏽"",
    ""backhand_index_pointing_left"": ""👈"",
    ""backhand_index_pointing_left_dark_skin_tone"": ""👈🏿"",
    ""backhand_index_pointing_left_light_skin_tone"": ""👈🏻"",
    ""backhand_index_pointing_left_medium-dark_skin_tone"": ""👈🏾"",
    ""backhand_index_pointing_left_medium-light_skin_tone"": ""👈🏼"",
    ""backhand_index_pointing_left_medium_skin_tone"": ""👈🏽"",
    ""backhand_index_pointing_right"": ""👉"",
    ""backhand_index_pointing_right_dark_skin_tone"": ""👉🏿"",
    ""backhand_index_pointing_right_light_skin_tone"": ""👉🏻"",
    ""backhand_index_pointing_right_medium-dark_skin_tone"": ""👉🏾"",
    ""backhand_index_pointing_right_medium-light_skin_tone"": ""👉🏼"",
    ""backhand_index_pointing_right_medium_skin_tone"": ""👉🏽"",
    ""backhand_index_pointing_up"": ""👆"",
    ""backhand_index_pointing_up_dark_skin_tone"": ""👆🏿"",
    ""backhand_index_pointing_up_light_skin_tone"": ""👆🏻"",
    ""backhand_index_pointing_up_medium-dark_skin_tone"": ""👆🏾"",
    ""backhand_index_pointing_up_medium-light_skin_tone"": ""👆🏼"",
    ""backhand_index_pointing_up_medium_skin_tone"": ""👆🏽"",
    ""bacon"": ""🥓"",
    ""badger"": ""🦡"",
    ""badminton"": ""🏸"",
    ""bagel"": ""🥯"",
    ""baggage_claim"": ""🛄"",
    ""baguette_bread"": ""🥖"",
    ""balance_scale"": ""⚖"",
    ""bald"": ""🦲"",
    ""bald_man"": ""👨\u200d🦲"",
    ""bald_woman"": ""👩\u200d🦲"",
    ""ballet_shoes"": ""🩰"",
    ""balloon"": ""🎈"",
    ""ballot_box_with_ballot"": ""🗳"",
    ""ballot_box_with_check"": ""☑"",
    ""banana"": ""🍌"",
    ""banjo"": ""🪕"",
    ""bank"": ""🏦"",
    ""bar_chart"": ""📊"",
    ""barber_pole"": ""💈"",
    ""baseball"": ""⚾"",
    ""basket"": ""🧺"",
    ""basketball"": ""🏀"",
    ""bat"": ""🦇"",
    ""bathtub"": ""🛁"",
    ""battery"": ""🔋"",
    ""beach_with_umbrella"": ""🏖"",
    ""beaming_face_with_smiling_eyes"": ""😁"",
    ""bear_face"": ""🐻"",
    ""bearded_person"": ""🧔"",
    ""bearded_person_dark_skin_tone"": ""🧔🏿"",
    ""bearded_person_light_skin_tone"": ""🧔🏻"",
    ""bearded_person_medium-dark_skin_tone"": ""🧔🏾"",
    ""bearded_person_medium-light_skin_tone"": ""🧔🏼"",
    ""bearded_person_medium_skin_tone"": ""🧔🏽"",
    ""beating_heart"": ""💓"",
    ""bed"": ""🛏"",
    ""beer_mug"": ""🍺"",
    ""bell"": ""🔔"",
    ""bell_with_slash"": ""🔕"",
    ""bellhop_bell"": ""🛎"",
    ""bento_box"": ""🍱"",
    ""beverage_box"": ""🧃"",
    ""bicycle"": ""🚲"",
    ""bikini"": ""👙"",
    ""billed_cap"": ""🧢"",
    ""biohazard"": ""☣"",
    ""bird"": ""🐦"",
    ""birthday_cake"": ""🎂"",
    ""black_circle"": ""⚫"",
    ""black_flag"": ""🏴"",
    ""black_heart"": ""🖤"",
    ""black_large_square"": ""⬛"",
    ""black_medium-small_square"": ""◾"",
    ""black_medium_square"": ""◼"",
    ""black_nib"": ""✒"",
    ""black_small_square"": ""▪"",
    ""black_square_button"": ""🔲"",
    ""blond-haired_man"": ""👱\u200d♂️"",
    ""blond-haired_man_dark_skin_tone"": ""👱🏿\u200d♂️"",
    ""blond-haired_man_light_skin_tone"": ""👱🏻\u200d♂️"",
    ""blond-haired_man_medium-dark_skin_tone"": ""👱🏾\u200d♂️"",
    ""blond-haired_man_medium-light_skin_tone"": ""👱🏼\u200d♂️"",
    ""blond-haired_man_medium_skin_tone"": ""👱🏽\u200d♂️"",
    ""blond-haired_person"": ""👱"",
    ""blond-haired_person_dark_skin_tone"": ""👱🏿"",
    ""blond-haired_person_light_skin_tone"": ""👱🏻"",
    ""blond-haired_person_medium-dark_skin_tone"": ""👱🏾"",
    ""blond-haired_person_medium-light_skin_tone"": ""👱🏼"",
    ""blond-haired_person_medium_skin_tone"": ""👱🏽"",
    ""blond-haired_woman"": ""👱\u200d♀️"",
    ""blond-haired_woman_dark_skin_tone"": ""👱🏿\u200d♀️"",
    ""blond-haired_woman_light_skin_tone"": ""👱🏻\u200d♀️"",
    ""blond-haired_woman_medium-dark_skin_tone"": ""👱🏾\u200d♀️"",
    ""blond-haired_woman_medium-light_skin_tone"": ""👱🏼\u200d♀️"",
    ""blond-haired_woman_medium_skin_tone"": ""👱🏽\u200d♀️"",
    ""blossom"": ""🌼"",
    ""blowfish"": ""🐡"",
    ""blue_book"": ""📘"",
    ""blue_circle"": ""🔵"",
    ""blue_heart"": ""💙"",
    ""blue_square"": ""🟦"",
    ""boar"": ""🐗"",
    ""bomb"": ""💣"",
    ""bone"": ""🦴"",
    ""bookmark"": ""🔖"",
    ""bookmark_tabs"": ""📑"",
    ""books"": ""📚"",
    ""bottle_with_popping_cork"": ""🍾"",
    ""bouquet"": ""💐"",
    ""bow_and_arrow"": ""🏹"",
    ""bowl_with_spoon"": ""🥣"",
    ""bowling"": ""🎳"",
    ""boxing_glove"": ""🥊"",
    ""boy"": ""👦"",
    ""boy_dark_skin_tone"": ""👦🏿"",
    ""boy_light_skin_tone"": ""👦🏻"",
    ""boy_medium-dark_skin_tone"": ""👦🏾"",
    ""boy_medium-light_skin_tone"": ""👦🏼"",
    ""boy_medium_skin_tone"": ""👦🏽"",
    ""brain"": ""🧠"",
    ""bread"": ""🍞"",
    ""breast-feeding"": ""🤱"",
    ""breast-feeding_dark_skin_tone"": ""🤱🏿"",
    ""breast-feeding_light_skin_tone"": ""🤱🏻"",
    ""breast-feeding_medium-dark_skin_tone"": ""🤱🏾"",
    ""breast-feeding_medium-light_skin_tone"": ""🤱🏼"",
    ""breast-feeding_medium_skin_tone"": ""🤱🏽"",
    ""brick"": ""🧱"",
    ""bride_with_veil"": ""👰"",
    ""bride_with_veil_dark_skin_tone"": ""👰🏿"",
    ""bride_with_veil_light_skin_tone"": ""👰🏻"",
    ""bride_with_veil_medium-dark_skin_tone"": ""👰🏾"",
    ""bride_with_veil_medium-light_skin_tone"": ""👰🏼"",
    ""bride_with_veil_medium_skin_tone"": ""👰🏽"",
    ""bridge_at_night"": ""🌉"",
    ""briefcase"": ""💼"",
    ""briefs"": ""🩲"",
    ""bright_button"": ""🔆"",
    ""broccoli"": ""🥦"",
    ""broken_heart"": ""💔"",
    ""broom"": ""🧹"",
    ""brown_circle"": ""🟤"",
    ""brown_heart"": ""🤎"",
    ""brown_square"": ""🟫"",
    ""bug"": ""🐛"",
    ""building_construction"": ""🏗"",
    ""bullet_train"": ""🚅"",
    ""burrito"": ""🌯"",
    ""bus"": ""🚌"",
    ""bus_stop"": ""🚏"",
    ""bust_in_silhouette"": ""👤"",
    ""busts_in_silhouette"": ""👥"",
    ""butter"": ""🧈"",
    ""butterfly"": ""🦋"",
    ""cactus"": ""🌵"",
    ""calendar"": ""📆"",
    ""call_me_hand"": ""🤙"",
    ""call_me_hand_dark_skin_tone"": ""🤙🏿"",
    ""call_me_hand_light_skin_tone"": ""🤙🏻"",
    ""call_me_hand_medium-dark_skin_tone"": ""🤙🏾"",
    ""call_me_hand_medium-light_skin_tone"": ""🤙🏼"",
    ""call_me_hand_medium_skin_tone"": ""🤙🏽"",
    ""camel"": ""🐫"",
    ""camera"": ""📷"",
    ""camera_with_flash"": ""📸"",
    ""camping"": ""🏕"",
    ""candle"": ""🕯"",
    ""candy"": ""🍬"",
    ""canned_food"": ""🥫"",
    ""canoe"": ""🛶"",
    ""card_file_box"": ""🗃"",
    ""card_index"": ""📇"",
    ""card_index_dividers"": ""🗂"",
    ""carousel_horse"": ""🎠"",
    ""carp_streamer"": ""🎏"",
    ""carrot"": ""🥕"",
    ""castle"": ""🏰"",
    ""cat"": ""🐱"",
    ""cat_face"": ""🐱"",
    ""cat_face_with_tears_of_joy"": ""😹"",
    ""cat_face_with_wry_smile"": ""😼"",
    ""chains"": ""⛓"",
    ""chair"": ""🪑"",
    ""chart_decreasing"": ""📉"",
    ""chart_increasing"": ""📈"",
    ""chart_increasing_with_yen"": ""💹"",
    ""cheese_wedge"": ""🧀"",
    ""chequered_flag"": ""🏁"",
    ""cherries"": ""🍒"",
    ""cherry_blossom"": ""🌸"",
    ""chess_pawn"": ""♟"",
    ""chestnut"": ""🌰"",
    ""chicken"": ""🐔"",
    ""child"": ""🧒"",
    ""child_dark_skin_tone"": ""🧒🏿"",
    ""child_light_skin_tone"": ""🧒🏻"",
    ""child_medium-dark_skin_tone"": ""🧒🏾"",
    ""child_medium-light_skin_tone"": ""🧒🏼"",
    ""child_medium_skin_tone"": ""🧒🏽"",
    ""children_crossing"": ""🚸"",
    ""chipmunk"": ""🐿"",
    ""chocolate_bar"": ""🍫"",
    ""chopsticks"": ""🥢"",
    ""church"": ""⛪"",
    ""cigarette"": ""🚬"",
    ""cinema"": ""🎦"",
    ""circled_m"": ""Ⓜ"",
    ""circus_tent"": ""🎪"",
    ""cityscape"": ""🏙"",
    ""cityscape_at_dusk"": ""🌆"",
    ""clamp"": ""🗜"",
    ""clapper_board"": ""🎬"",
    ""clapping_hands"": ""👏"",
    ""clapping_hands_dark_skin_tone"": ""👏🏿"",
    ""clapping_hands_light_skin_tone"": ""👏🏻"",
    ""clapping_hands_medium-dark_skin_tone"": ""👏🏾"",
    ""clapping_hands_medium-light_skin_tone"": ""👏🏼"",
    ""clapping_hands_medium_skin_tone"": ""👏🏽"",
    ""classical_building"": ""🏛"",
    ""clinking_beer_mugs"": ""🍻"",
    ""clinking_glasses"": ""🥂"",
    ""clipboard"": ""📋"",
    ""clockwise_vertical_arrows"": ""🔃"",
    ""closed_book"": ""📕"",
    ""closed_mailbox_with_lowered_flag"": ""📪"",
    ""closed_mailbox_with_raised_flag"": ""📫"",
    ""closed_umbrella"": ""🌂"",
    ""cloud"": ""☁"",
    ""cloud_with_lightning"": ""🌩"",
    ""cloud_with_lightning_and_rain"": ""⛈"",
    ""cloud_with_rain"": ""🌧"",
    ""cloud_with_snow"": ""🌨"",
    ""clown_face"": ""🤡"",
    ""club_suit"": ""♣"",
    ""clutch_bag"": ""👝"",
    ""coat"": ""🧥"",
    ""cocktail_glass"": ""🍸"",
    ""coconut"": ""🥥"",
    ""coffin"": ""⚰"",
    ""cold_face"": ""🥶"",
    ""collision"": ""💥"",
    ""comet"": ""☄"",
    ""compass"": ""🧭"",
    ""computer_disk"": ""💽"",
    ""computer_mouse"": ""🖱"",
    ""confetti_ball"": ""🎊"",
    ""confounded_face"": ""😖"",
    ""confused_face"": ""😕"",
    ""construction"": ""🚧"",
    ""construction_worker"": ""👷"",
    ""construction_worker_dark_skin_tone"": ""👷🏿"",
    ""construction_worker_light_skin_tone"": ""👷🏻"",
    ""construction_worker_medium-dark_skin_tone"": ""👷🏾"",
    ""construction_worker_medium-light_skin_tone"": ""👷🏼"",
    ""construction_worker_medium_skin_tone"": ""👷🏽"",
    ""control_knobs"": ""🎛"",
    ""convenience_store"": ""🏪"",
    ""cooked_rice"": ""🍚"",
    ""cookie"": ""🍪"",
    ""cooking"": ""🍳"",
    ""copyright"": ""©"",
    ""couch_and_lamp"": ""🛋"",
    ""counterclockwise_arrows_button"": ""🔄"",
    ""couple_with_heart"": ""💑"",
    ""couple_with_heart_man_man"": ""👨\u200d❤️\u200d👨"",
    ""couple_with_heart_woman_man"": ""👩\u200d❤️\u200d👨"",
    ""couple_with_heart_woman_woman"": ""👩\u200d❤️\u200d👩"",
    ""cow"": ""🐮"",
    ""cow_face"": ""🐮"",
    ""cowboy_hat_face"": ""🤠"",
    ""crab"": ""🦀"",
    ""crayon"": ""🖍"",
    ""credit_card"": ""💳"",
    ""crescent_moon"": ""🌙"",
    ""cricket"": ""🦗"",
    ""cricket_game"": ""🏏"",
    ""crocodile"": ""🐊"",
    ""croissant"": ""🥐"",
    ""cross_mark"": ""❌"",
    ""cross_mark_button"": ""❎"",
    ""crossed_fingers"": ""🤞"",
    ""crossed_fingers_dark_skin_tone"": ""🤞🏿"",
    ""crossed_fingers_light_skin_tone"": ""🤞🏻"",
    ""crossed_fingers_medium-dark_skin_tone"": ""🤞🏾"",
    ""crossed_fingers_medium-light_skin_tone"": ""🤞🏼"",
    ""crossed_fingers_medium_skin_tone"": ""🤞🏽"",
    ""crossed_flags"": ""🎌"",
    ""crossed_swords"": ""⚔"",
    ""crown"": ""👑"",
    ""crying_cat_face"": ""😿"",
    ""crying_face"": ""😢"",
    ""crystal_ball"": ""🔮"",
    ""cucumber"": ""🥒"",
    ""cupcake"": ""🧁"",
    ""cup_with_straw"": ""🥤"",
    ""curling_stone"": ""🥌"",
    ""curly_hair"": ""🦱"",
    ""curly-haired_man"": ""👨\u200d🦱"",
    ""curly-haired_woman"": ""👩\u200d🦱"",
    ""curly_loop"": ""➰"",
    ""currency_exchange"": ""💱"",
    ""curry_rice"": ""🍛"",
    ""custard"": ""🍮"",
    ""customs"": ""🛃"",
    ""cut_of_meat"": ""🥩"",
    ""cyclone"": ""🌀"",
    ""dagger"": ""🗡"",
    ""dango"": ""🍡"",
    ""dashing_away"": ""💨"",
    ""deaf_person"": ""🧏"",
    ""deciduous_tree"": ""🌳"",
    ""deer"": ""🦌"",
    ""delivery_truck"": ""🚚"",
    ""department_store"": ""🏬"",
    ""derelict_house"": ""🏚"",
    ""desert"": ""🏜"",
    ""desert_island"": ""🏝"",
    ""desktop_computer"": ""🖥"",
    ""detective"": ""🕵"",
    ""detective_dark_skin_tone"": ""🕵🏿"",
    ""detective_light_skin_tone"": ""🕵🏻"",
    ""detective_medium-dark_skin_tone"": ""🕵🏾"",
    ""detective_medium-light_skin_tone"": ""🕵🏼"",
    ""detective_medium_skin_tone"": ""🕵🏽"",
    ""diamond_suit"": ""♦"",
    ""diamond_with_a_dot"": ""💠"",
    ""dim_button"": ""🔅"",
    ""direct_hit"": ""🎯"",
    ""disappointed_face"": ""😞"",
    ""diving_mask"": ""🤿"",
    ""diya_lamp"": ""🪔"",
    ""dizzy"": ""💫"",
    ""dizzy_face"": ""😵"",
    ""dna"": ""🧬"",
    ""dog"": ""🐶"",
    ""dog_face"": ""🐶"",
    ""dollar_banknote"": ""💵"",
    ""dolphin"": ""🐬"",
    ""door"": ""🚪"",
    ""dotted_six-pointed_star"": ""🔯"",
    ""double_curly_loop"": ""➿"",
    ""double_exclamation_mark"": ""‼"",
    ""doughnut"": ""🍩"",
    ""dove"": ""🕊"",
    ""down-left_arrow"": ""↙"",
    ""down-right_arrow"": ""↘"",
    ""down_arrow"": ""⬇"",
    ""downcast_face_with_sweat"": ""😓"",
    ""downwards_button"": ""🔽"",
    ""dragon"": ""🐉"",
    ""dragon_face"": ""🐲"",
    ""dress"": ""👗"",
    ""drooling_face"": ""🤤"",
    ""drop_of_blood"": ""🩸"",
    ""droplet"": ""💧"",
    ""drum"": ""🥁"",
    ""duck"": ""🦆"",
    ""dumpling"": ""🥟"",
    ""dvd"": ""📀"",
    ""e-mail"": ""📧"",
    ""eagle"": ""🦅"",
    ""ear"": ""👂"",
    ""ear_dark_skin_tone"": ""👂🏿"",
    ""ear_light_skin_tone"": ""👂🏻"",
    ""ear_medium-dark_skin_tone"": ""👂🏾"",
    ""ear_medium-light_skin_tone"": ""👂🏼"",
    ""ear_medium_skin_tone"": ""👂🏽"",
    ""ear_of_corn"": ""🌽"",
    ""ear_with_hearing_aid"": ""🦻"",
    ""egg"": ""🍳"",
    ""eggplant"": ""🍆"",
    ""eight-pointed_star"": ""✴"",
    ""eight-spoked_asterisk"": ""✳"",
    ""eight-thirty"": ""🕣"",
    ""eight_o’clock"": ""🕗"",
    ""eject_button"": ""⏏"",
    ""electric_plug"": ""🔌"",
    ""elephant"": ""🐘"",
    ""eleven-thirty"": ""🕦"",
    ""eleven_o’clock"": ""🕚"",
    ""elf"": ""🧝"",
    ""elf_dark_skin_tone"": ""🧝🏿"",
    ""elf_light_skin_tone"": ""🧝🏻"",
    ""elf_medium-dark_skin_tone"": ""🧝🏾"",
    ""elf_medium-light_skin_tone"": ""🧝🏼"",
    ""elf_medium_skin_tone"": ""🧝🏽"",
    ""envelope"": ""✉"",
    ""envelope_with_arrow"": ""📩"",
    ""euro_banknote"": ""💶"",
    ""evergreen_tree"": ""🌲"",
    ""ewe"": ""🐑"",
    ""exclamation_mark"": ""❗"",
    ""exclamation_question_mark"": ""⁉"",
    ""exploding_head"": ""🤯"",
    ""expressionless_face"": ""😑"",
    ""eye"": ""👁"",
    ""eye_in_speech_bubble"": ""👁️\u200d🗨️"",
    ""eyes"": ""👀"",
    ""face_blowing_a_kiss"": ""😘"",
    ""face_savoring_food"": ""😋"",
    ""face_screaming_in_fear"": ""😱"",
    ""face_vomiting"": ""🤮"",
    ""face_with_hand_over_mouth"": ""🤭"",
    ""face_with_head-bandage"": ""🤕"",
    ""face_with_medical_mask"": ""😷"",
    ""face_with_monocle"": ""🧐"",
    ""face_with_open_mouth"": ""😮"",
    ""face_with_raised_eyebrow"": ""🤨"",
    ""face_with_rolling_eyes"": ""🙄"",
    ""face_with_steam_from_nose"": ""😤"",
    ""face_with_symbols_on_mouth"": ""🤬"",
    ""face_with_tears_of_joy"": ""😂"",
    ""face_with_thermometer"": ""🤒"",
    ""face_with_tongue"": ""😛"",
    ""face_without_mouth"": ""😶"",
    ""factory"": ""🏭"",
    ""fairy"": ""🧚"",
    ""fairy_dark_skin_tone"": ""🧚🏿"",
    ""fairy_light_skin_tone"": ""🧚🏻"",
    ""fairy_medium-dark_skin_tone"": ""🧚🏾"",
    ""fairy_medium-light_skin_tone"": ""🧚🏼"",
    ""fairy_medium_skin_tone"": ""🧚🏽"",
    ""falafel"": ""🧆"",
    ""fallen_leaf"": ""🍂"",
    ""family"": ""👪"",
    ""family_man_boy"": ""👨\u200d👦"",
    ""family_man_boy_boy"": ""👨\u200d👦\u200d👦"",
    ""family_man_girl"": ""👨\u200d👧"",
    ""family_man_girl_boy"": ""👨\u200d👧\u200d👦"",
    ""family_man_girl_girl"": ""👨\u200d👧\u200d👧"",
    ""family_man_man_boy"": ""👨\u200d👨\u200d👦"",
    ""family_man_man_boy_boy"": ""👨\u200d👨\u200d👦\u200d👦"",
    ""family_man_man_girl"": ""👨\u200d👨\u200d👧"",
    ""family_man_man_girl_boy"": ""👨\u200d👨\u200d👧\u200d👦"",
    ""family_man_man_girl_girl"": ""👨\u200d👨\u200d👧\u200d👧"",
    ""family_man_woman_boy"": ""👨\u200d👩\u200d👦"",
    ""family_man_woman_boy_boy"": ""👨\u200d👩\u200d👦\u200d👦"",
    ""family_man_woman_girl"": ""👨\u200d👩\u200d👧"",
    ""family_man_woman_girl_boy"": ""👨\u200d👩\u200d👧\u200d👦"",
    ""family_man_woman_girl_girl"": ""👨\u200d👩\u200d👧\u200d👧"",
    ""family_woman_boy"": ""👩\u200d👦"",
    ""family_woman_boy_boy"": ""👩\u200d👦\u200d👦"",
    ""family_woman_girl"": ""👩\u200d👧"",
    ""family_woman_girl_boy"": ""👩\u200d👧\u200d👦"",
    ""family_woman_girl_girl"": ""👩\u200d👧\u200d👧"",
    ""family_woman_woman_boy"": ""👩\u200d👩\u200d👦"",
    ""family_woman_woman_boy_boy"": ""👩\u200d👩\u200d👦\u200d👦"",
    ""family_woman_woman_girl"": ""👩\u200d👩\u200d👧"",
    ""family_woman_woman_girl_boy"": ""👩\u200d👩\u200d👧\u200d👦"",
    ""family_woman_woman_girl_girl"": ""👩\u200d👩\u200d👧\u200d👧"",
    ""fast-forward_button"": ""⏩"",
    ""fast_down_button"": ""⏬"",
    ""fast_reverse_button"": ""⏪"",
    ""fast_up_button"": ""⏫"",
    ""fax_machine"": ""📠"",
    ""fearful_face"": ""😨"",
    ""female_sign"": ""♀"",
    ""ferris_wheel"": ""🎡"",
    ""ferry"": ""⛴"",
    ""field_hockey"": ""🏑"",
    ""file_cabinet"": ""🗄"",
    ""file_folder"": ""📁"",
    ""film_frames"": ""🎞"",
    ""film_projector"": ""📽"",
    ""fire"": ""🔥"",
    ""fire_extinguisher"": ""🧯"",
    ""firecracker"": ""🧨"",
    ""fire_engine"": ""🚒"",
    ""fireworks"": ""🎆"",
    ""first_quarter_moon"": ""🌓"",
    ""first_quarter_moon_face"": ""🌛"",
    ""fish"": ""🐟"",
    ""fish_cake_with_swirl"": ""🍥"",
    ""fishing_pole"": ""🎣"",
    ""five-thirty"": ""🕠"",
    ""five_o’clock"": ""🕔"",
    ""flag_in_hole"": ""⛳"",
    ""flamingo"": ""🦩"",
    ""flashlight"": ""🔦"",
    ""flat_shoe"": ""🥿"",
    ""fleur-de-lis"": ""⚜"",
    ""flexed_biceps"": ""💪"",
    ""flexed_biceps_dark_skin_tone"": ""💪🏿"",
    ""flexed_biceps_light_skin_tone"": ""💪🏻"",
    ""flexed_biceps_medium-dark_skin_tone"": ""💪🏾"",
    ""flexed_biceps_medium-light_skin_tone"": ""💪🏼"",
    ""flexed_biceps_medium_skin_tone"": ""💪🏽"",
    ""floppy_disk"": ""💾"",
    ""flower_playing_cards"": ""🎴"",
    ""flushed_face"": ""😳"",
    ""flying_disc"": ""🥏"",
    ""flying_saucer"": ""🛸"",
    ""fog"": ""🌫"",
    ""foggy"": ""🌁"",
    ""folded_hands"": ""🙏"",
    ""folded_hands_dark_skin_tone"": ""🙏🏿"",
    ""folded_hands_light_skin_tone"": ""🙏🏻"",
    ""folded_hands_medium-dark_skin_tone"": ""🙏🏾"",
    ""folded_hands_medium-light_skin_tone"": ""🙏🏼"",
    ""folded_hands_medium_skin_tone"": ""🙏🏽"",
    ""foot"": ""🦶"",
    ""footprints"": ""👣"",
    ""fork_and_knife"": ""🍴"",
    ""fork_and_knife_with_plate"": ""🍽"",
    ""fortune_cookie"": ""🥠"",
    ""fountain"": ""⛲"",
    ""fountain_pen"": ""🖋"",
    ""four-thirty"": ""🕟"",
    ""four_leaf_clover"": ""🍀"",
    ""four_o’clock"": ""🕓"",
    ""fox_face"": ""🦊"",
    ""framed_picture"": ""🖼"",
    ""french_fries"": ""🍟"",
    ""fried_shrimp"": ""🍤"",
    ""frog_face"": ""🐸"",
    ""front-facing_baby_chick"": ""🐥"",
    ""frowning_face"": ""☹"",
    ""frowning_face_with_open_mouth"": ""😦"",
    ""fuel_pump"": ""⛽"",
    ""full_moon"": ""🌕"",
    ""full_moon_face"": ""🌝"",
    ""funeral_urn"": ""⚱"",
    ""game_die"": ""🎲"",
    ""garlic"": ""🧄"",
    ""gear"": ""⚙"",
    ""gem_stone"": ""💎"",
    ""genie"": ""🧞"",
    ""ghost"": ""👻"",
    ""giraffe"": ""🦒"",
    ""girl"": ""👧"",
    ""girl_dark_skin_tone"": ""👧🏿"",
    ""girl_light_skin_tone"": ""👧🏻"",
    ""girl_medium-dark_skin_tone"": ""👧🏾"",
    ""girl_medium-light_skin_tone"": ""👧🏼"",
    ""girl_medium_skin_tone"": ""👧🏽"",
    ""glass_of_milk"": ""🥛"",
    ""glasses"": ""👓"",
    ""globe_showing_americas"": ""🌎"",
    ""globe_showing_asia-australia"": ""🌏"",
    ""globe_showing_europe-africa"": ""🌍"",
    ""globe_with_meridians"": ""🌐"",
    ""gloves"": ""🧤"",
    ""glowing_star"": ""🌟"",
    ""goal_net"": ""🥅"",
    ""goat"": ""🐐"",
    ""goblin"": ""👺"",
    ""goggles"": ""🥽"",
    ""gorilla"": ""🦍"",
    ""graduation_cap"": ""🎓"",
    ""grapes"": ""🍇"",
    ""green_apple"": ""🍏"",
    ""green_book"": ""📗"",
    ""green_circle"": ""🟢"",
    ""green_heart"": ""💚"",
    ""green_salad"": ""🥗"",
    ""green_square"": ""🟩"",
    ""grimacing_face"": ""😬"",
    ""grinning_cat_face"": ""😺"",
    ""grinning_cat_face_with_smiling_eyes"": ""😸"",
    ""grinning_face"": ""😀"",
    ""grinning_face_with_big_eyes"": ""😃"",
    ""grinning_face_with_smiling_eyes"": ""😄"",
    ""grinning_face_with_sweat"": ""😅"",
    ""grinning_squinting_face"": ""😆"",
    ""growing_heart"": ""💗"",
    ""guard"": ""💂"",
    ""guard_dark_skin_tone"": ""💂🏿"",
    ""guard_light_skin_tone"": ""💂🏻"",
    ""guard_medium-dark_skin_tone"": ""💂🏾"",
    ""guard_medium-light_skin_tone"": ""💂🏼"",
    ""guard_medium_skin_tone"": ""💂🏽"",
    ""guide_dog"": ""🦮"",
    ""guitar"": ""🎸"",
    ""hamburger"": ""🍔"",
    ""hammer"": ""🔨"",
    ""hammer_and_pick"": ""⚒"",
    ""hammer_and_wrench"": ""🛠"",
    ""hamster_face"": ""🐹"",
    ""hand_with_fingers_splayed"": ""🖐"",
    ""hand_with_fingers_splayed_dark_skin_tone"": ""🖐🏿"",
    ""hand_with_fingers_splayed_light_skin_tone"": ""🖐🏻"",
    ""hand_with_fingers_splayed_medium-dark_skin_tone"": ""🖐🏾"",
    ""hand_with_fingers_splayed_medium-light_skin_tone"": ""🖐🏼"",
    ""hand_with_fingers_splayed_medium_skin_tone"": ""🖐🏽"",
    ""handbag"": ""👜"",
    ""handshake"": ""🤝"",
    ""hatching_chick"": ""🐣"",
    ""headphone"": ""🎧"",
    ""hear-no-evil_monkey"": ""🙉"",
    ""heart_decoration"": ""💟"",
    ""heart_suit"": ""♥"",
    ""heart_with_arrow"": ""💘"",
    ""heart_with_ribbon"": ""💝"",
    ""heavy_check_mark"": ""✔"",
    ""heavy_division_sign"": ""➗"",
    ""heavy_dollar_sign"": ""💲"",
    ""heavy_heart_exclamation"": ""❣"",
    ""heavy_large_circle"": ""⭕"",
    ""heavy_minus_sign"": ""➖"",
    ""heavy_multiplication_x"": ""✖"",
    ""heavy_plus_sign"": ""➕"",
    ""hedgehog"": ""🦔"",
    ""helicopter"": ""🚁"",
    ""herb"": ""🌿"",
    ""hibiscus"": ""🌺"",
    ""high-heeled_shoe"": ""👠"",
    ""high-speed_train"": ""🚄"",
    ""high_voltage"": ""⚡"",
    ""hiking_boot"": ""🥾"",
    ""hindu_temple"": ""🛕"",
    ""hippopotamus"": ""🦛"",
    ""hole"": ""🕳"",
    ""honey_pot"": ""🍯"",
    ""honeybee"": ""🐝"",
    ""horizontal_traffic_light"": ""🚥"",
    ""horse"": ""🐴"",
    ""horse_face"": ""🐴"",
    ""horse_racing"": ""🏇"",
    ""horse_racing_dark_skin_tone"": ""🏇🏿"",
    ""horse_racing_light_skin_tone"": ""🏇🏻"",
    ""horse_racing_medium-dark_skin_tone"": ""🏇🏾"",
    ""horse_racing_medium-light_skin_tone"": ""🏇🏼"",
    ""horse_racing_medium_skin_tone"": ""🏇🏽"",
    ""hospital"": ""🏥"",
    ""hot_beverage"": ""☕"",
    ""hot_dog"": ""🌭"",
    ""hot_face"": ""🥵"",
    ""hot_pepper"": ""🌶"",
    ""hot_springs"": ""♨"",
    ""hotel"": ""🏨"",
    ""hourglass_done"": ""⌛"",
    ""hourglass_not_done"": ""⏳"",
    ""house"": ""🏠"",
    ""house_with_garden"": ""🏡"",
    ""houses"": ""🏘"",
    ""hugging_face"": ""🤗"",
    ""hundred_points"": ""💯"",
    ""hushed_face"": ""😯"",
    ""ice"": ""🧊"",
    ""ice_cream"": ""🍨"",
    ""ice_hockey"": ""🏒"",
    ""ice_skate"": ""⛸"",
    ""inbox_tray"": ""📥"",
    ""incoming_envelope"": ""📨"",
    ""index_pointing_up"": ""☝"",
    ""index_pointing_up_dark_skin_tone"": ""☝🏿"",
    ""index_pointing_up_light_skin_tone"": ""☝🏻"",
    ""index_pointing_up_medium-dark_skin_tone"": ""☝🏾"",
    ""index_pointing_up_medium-light_skin_tone"": ""☝🏼"",
    ""index_pointing_up_medium_skin_tone"": ""☝🏽"",
    ""infinity"": ""♾"",
    ""information"": ""ℹ"",
    ""input_latin_letters"": ""🔤"",
    ""input_latin_lowercase"": ""🔡"",
    ""input_latin_uppercase"": ""🔠"",
    ""input_numbers"": ""🔢"",
    ""input_symbols"": ""🔣"",
    ""jack-o-lantern"": ""🎃"",
    ""jeans"": ""👖"",
    ""jigsaw"": ""🧩"",
    ""joker"": ""🃏"",
    ""joystick"": ""🕹"",
    ""kaaba"": ""🕋"",
    ""kangaroo"": ""🦘"",
    ""key"": ""🔑"",
    ""keyboard"": ""⌨"",
    ""keycap_
    ""keycap_*"": ""*️⃣"",
    ""keycap_0"": ""0️⃣"",
    ""keycap_1"": ""1️⃣"",
    ""keycap_10"": ""🔟"",
    ""keycap_2"": ""2️⃣"",
    ""keycap_3"": ""3️⃣"",
    ""keycap_4"": ""4️⃣"",
    ""keycap_5"": ""5️⃣"",
    ""keycap_6"": ""6️⃣"",
    ""keycap_7"": ""7️⃣"",
    ""keycap_8"": ""8️⃣"",
    ""keycap_9"": ""9️⃣"",
    ""kick_scooter"": ""🛴"",
    ""kimono"": ""👘"",
    ""kiss"": ""💋"",
    ""kiss_man_man"": ""👨\u200d❤️\u200d💋\u200d👨"",
    ""kiss_mark"": ""💋"",
    ""kiss_woman_man"": ""👩\u200d❤️\u200d💋\u200d👨"",
    ""kiss_woman_woman"": ""👩\u200d❤️\u200d💋\u200d👩"",
    ""kissing_cat_face"": ""😽"",
    ""kissing_face"": ""😗"",
    ""kissing_face_with_closed_eyes"": ""😚"",
    ""kissing_face_with_smiling_eyes"": ""😙"",
    ""kitchen_knife"": ""🔪"",
    ""kite"": ""🪁"",
    ""kiwi_fruit"": ""🥝"",
    ""koala"": ""🐨"",
    ""lab_coat"": ""🥼"",
    ""label"": ""🏷"",
    ""lacrosse"": ""🥍"",
    ""lady_beetle"": ""🐞"",
    ""laptop_computer"": ""💻"",
    ""large_blue_diamond"": ""🔷"",
    ""large_orange_diamond"": ""🔶"",
    ""last_quarter_moon"": ""🌗"",
    ""last_quarter_moon_face"": ""🌜"",
    ""last_track_button"": ""⏮"",
    ""latin_cross"": ""✝"",
    ""leaf_fluttering_in_wind"": ""🍃"",
    ""leafy_green"": ""🥬"",
    ""ledger"": ""📒"",
    ""left-facing_fist"": ""🤛"",
    ""left-facing_fist_dark_skin_tone"": ""🤛🏿"",
    ""left-facing_fist_light_skin_tone"": ""🤛🏻"",
    ""left-facing_fist_medium-dark_skin_tone"": ""🤛🏾"",
    ""left-facing_fist_medium-light_skin_tone"": ""🤛🏼"",
    ""left-facing_fist_medium_skin_tone"": ""🤛🏽"",
    ""left-right_arrow"": ""↔"",
    ""left_arrow"": ""⬅"",
    ""left_arrow_curving_right"": ""↪"",
    ""left_luggage"": ""🛅"",
    ""left_speech_bubble"": ""🗨"",
    ""leg"": ""🦵"",
    ""lemon"": ""🍋"",
    ""leopard"": ""🐆"",
    ""level_slider"": ""🎚"",
    ""light_bulb"": ""💡"",
    ""light_rail"": ""🚈"",
    ""link"": ""🔗"",
    ""linked_paperclips"": ""🖇"",
    ""lion_face"": ""🦁"",
    ""lipstick"": ""💄"",
    ""litter_in_bin_sign"": ""🚮"",
    ""lizard"": ""🦎"",
    ""llama"": ""🦙"",
    ""lobster"": ""🦞"",
    ""locked"": ""🔒"",
    ""locked_with_key"": ""🔐"",
    ""locked_with_pen"": ""🔏"",
    ""locomotive"": ""🚂"",
    ""lollipop"": ""🍭"",
    ""lotion_bottle"": ""🧴"",
    ""loudly_crying_face"": ""😭"",
    ""loudspeaker"": ""📢"",
    ""love-you_gesture"": ""🤟"",
    ""love-you_gesture_dark_skin_tone"": ""🤟🏿"",
    ""love-you_gesture_light_skin_tone"": ""🤟🏻"",
    ""love-you_gesture_medium-dark_skin_tone"": ""🤟🏾"",
    ""love-you_gesture_medium-light_skin_tone"": ""🤟🏼"",
    ""love-you_gesture_medium_skin_tone"": ""🤟🏽"",
    ""love_hotel"": ""🏩"",
    ""love_letter"": ""💌"",
    ""luggage"": ""🧳"",
    ""lying_face"": ""🤥"",
    ""mage"": ""🧙"",
    ""mage_dark_skin_tone"": ""🧙🏿"",
    ""mage_light_skin_tone"": ""🧙🏻"",
    ""mage_medium-dark_skin_tone"": ""🧙🏾"",
    ""mage_medium-light_skin_tone"": ""🧙🏼"",
    ""mage_medium_skin_tone"": ""🧙🏽"",
    ""magnet"": ""🧲"",
    ""magnifying_glass_tilted_left"": ""🔍"",
    ""magnifying_glass_tilted_right"": ""🔎"",
    ""mahjong_red_dragon"": ""🀄"",
    ""male_sign"": ""♂"",
    ""man"": ""👨"",
    ""man_and_woman_holding_hands"": ""👫"",
    ""man_artist"": ""👨\u200d🎨"",
    ""man_artist_dark_skin_tone"": ""👨🏿\u200d🎨"",
    ""man_artist_light_skin_tone"": ""👨🏻\u200d🎨"",
    ""man_artist_medium-dark_skin_tone"": ""👨🏾\u200d🎨"",
    ""man_artist_medium-light_skin_tone"": ""👨🏼\u200d🎨"",
    ""man_artist_medium_skin_tone"": ""👨🏽\u200d🎨"",
    ""man_astronaut"": ""👨\u200d🚀"",
    ""man_astronaut_dark_skin_tone"": ""👨🏿\u200d🚀"",
    ""man_astronaut_light_skin_tone"": ""👨🏻\u200d🚀"",
    ""man_astronaut_medium-dark_skin_tone"": ""👨🏾\u200d🚀"",
    ""man_astronaut_medium-light_skin_tone"": ""👨🏼\u200d🚀"",
    ""man_astronaut_medium_skin_tone"": ""👨🏽\u200d🚀"",
    ""man_biking"": ""🚴\u200d♂️"",
    ""man_biking_dark_skin_tone"": ""🚴🏿\u200d♂️"",
    ""man_biking_light_skin_tone"": ""🚴🏻\u200d♂️"",
    ""man_biking_medium-dark_skin_tone"": ""🚴🏾\u200d♂️"",
    ""man_biking_medium-light_skin_tone"": ""🚴🏼\u200d♂️"",
    ""man_biking_medium_skin_tone"": ""🚴🏽\u200d♂️"",
    ""man_bouncing_ball"": ""⛹️\u200d♂️"",
    ""man_bouncing_ball_dark_skin_tone"": ""⛹🏿\u200d♂️"",
    ""man_bouncing_ball_light_skin_tone"": ""⛹🏻\u200d♂️"",
    ""man_bouncing_ball_medium-dark_skin_tone"": ""⛹🏾\u200d♂️"",
    ""man_bouncing_ball_medium-light_skin_tone"": ""⛹🏼\u200d♂️"",
    ""man_bouncing_ball_medium_skin_tone"": ""⛹🏽\u200d♂️"",
    ""man_bowing"": ""🙇\u200d♂️"",
    ""man_bowing_dark_skin_tone"": ""🙇🏿\u200d♂️"",
    ""man_bowing_light_skin_tone"": ""🙇🏻\u200d♂️"",
    ""man_bowing_medium-dark_skin_tone"": ""🙇🏾\u200d♂️"",
    ""man_bowing_medium-light_skin_tone"": ""🙇🏼\u200d♂️"",
    ""man_bowing_medium_skin_tone"": ""🙇🏽\u200d♂️"",
    ""man_cartwheeling"": ""🤸\u200d♂️"",
    ""man_cartwheeling_dark_skin_tone"": ""🤸🏿\u200d♂️"",
    ""man_cartwheeling_light_skin_tone"": ""🤸🏻\u200d♂️"",
    ""man_cartwheeling_medium-dark_skin_tone"": ""🤸🏾\u200d♂️"",
    ""man_cartwheeling_medium-light_skin_tone"": ""🤸🏼\u200d♂️"",
    ""man_cartwheeling_medium_skin_tone"": ""🤸🏽\u200d♂️"",
    ""man_climbing"": ""🧗\u200d♂️"",
    ""man_climbing_dark_skin_tone"": ""🧗🏿\u200d♂️"",
    ""man_climbing_light_skin_tone"": ""🧗🏻\u200d♂️"",
    ""man_climbing_medium-dark_skin_tone"": ""🧗🏾\u200d♂️"",
    ""man_climbing_medium-light_skin_tone"": ""🧗🏼\u200d♂️"",
    ""man_climbing_medium_skin_tone"": ""🧗🏽\u200d♂️"",
    ""man_construction_worker"": ""👷\u200d♂️"",
    ""man_construction_worker_dark_skin_tone"": ""👷🏿\u200d♂️"",
    ""man_construction_worker_light_skin_tone"": ""👷🏻\u200d♂️"",
    ""man_construction_worker_medium-dark_skin_tone"": ""👷🏾\u200d♂️"",
    ""man_construction_worker_medium-light_skin_tone"": ""👷🏼\u200d♂️"",
    ""man_construction_worker_medium_skin_tone"": ""👷🏽\u200d♂️"",
    ""man_cook"": ""👨\u200d🍳"",
    ""man_cook_dark_skin_tone"": ""👨🏿\u200d🍳"",
    ""man_cook_light_skin_tone"": ""👨🏻\u200d🍳"",
    ""man_cook_medium-dark_skin_tone"": ""👨🏾\u200d🍳"",
    ""man_cook_medium-light_skin_tone"": ""👨🏼\u200d🍳"",
    ""man_cook_medium_skin_tone"": ""👨🏽\u200d🍳"",
    ""man_dancing"": ""🕺"",
    ""man_dancing_dark_skin_tone"": ""🕺🏿"",
    ""man_dancing_light_skin_tone"": ""🕺🏻"",
    ""man_dancing_medium-dark_skin_tone"": ""🕺🏾"",
    ""man_dancing_medium-light_skin_tone"": ""🕺🏼"",
    ""man_dancing_medium_skin_tone"": ""🕺🏽"",
    ""man_dark_skin_tone"": ""👨🏿"",
    ""man_detective"": ""🕵️\u200d♂️"",
    ""man_detective_dark_skin_tone"": ""🕵🏿\u200d♂️"",
    ""man_detective_light_skin_tone"": ""🕵🏻\u200d♂️"",
    ""man_detective_medium-dark_skin_tone"": ""🕵🏾\u200d♂️"",
    ""man_detective_medium-light_skin_tone"": ""🕵🏼\u200d♂️"",
    ""man_detective_medium_skin_tone"": ""🕵🏽\u200d♂️"",
    ""man_elf"": ""🧝\u200d♂️"",
    ""man_elf_dark_skin_tone"": ""🧝🏿\u200d♂️"",
    ""man_elf_light_skin_tone"": ""🧝🏻\u200d♂️"",
    ""man_elf_medium-dark_skin_tone"": ""🧝🏾\u200d♂️"",
    ""man_elf_medium-light_skin_tone"": ""🧝🏼\u200d♂️"",
    ""man_elf_medium_skin_tone"": ""🧝🏽\u200d♂️"",
    ""man_facepalming"": ""🤦\u200d♂️"",
    ""man_facepalming_dark_skin_tone"": ""🤦🏿\u200d♂️"",
    ""man_facepalming_light_skin_tone"": ""🤦🏻\u200d♂️"",
    ""man_facepalming_medium-dark_skin_tone"": ""🤦🏾\u200d♂️"",
    ""man_facepalming_medium-light_skin_tone"": ""🤦🏼\u200d♂️"",
    ""man_facepalming_medium_skin_tone"": ""🤦🏽\u200d♂️"",
    ""man_factory_worker"": ""👨\u200d🏭"",
    ""man_factory_worker_dark_skin_tone"": ""👨🏿\u200d🏭"",
    ""man_factory_worker_light_skin_tone"": ""👨🏻\u200d🏭"",
    ""man_factory_worker_medium-dark_skin_tone"": ""👨🏾\u200d🏭"",
    ""man_factory_worker_medium-light_skin_tone"": ""👨🏼\u200d🏭"",
    ""man_factory_worker_medium_skin_tone"": ""👨🏽\u200d🏭"",
    ""man_fairy"": ""🧚\u200d♂️"",
    ""man_fairy_dark_skin_tone"": ""🧚🏿\u200d♂️"",
    ""man_fairy_light_skin_tone"": ""🧚🏻\u200d♂️"",
    ""man_fairy_medium-dark_skin_tone"": ""🧚🏾\u200d♂️"",
    ""man_fairy_medium-light_skin_tone"": ""🧚🏼\u200d♂️"",
    ""man_fairy_medium_skin_tone"": ""🧚🏽\u200d♂️"",
    ""man_farmer"": ""👨\u200d🌾"",
    ""man_farmer_dark_skin_tone"": ""👨🏿\u200d🌾"",
    ""man_farmer_light_skin_tone"": ""👨🏻\u200d🌾"",
    ""man_farmer_medium-dark_skin_tone"": ""👨🏾\u200d🌾"",
    ""man_farmer_medium-light_skin_tone"": ""👨🏼\u200d🌾"",
    ""man_farmer_medium_skin_tone"": ""👨🏽\u200d🌾"",
    ""man_firefighter"": ""👨\u200d🚒"",
    ""man_firefighter_dark_skin_tone"": ""👨🏿\u200d🚒"",
    ""man_firefighter_light_skin_tone"": ""👨🏻\u200d🚒"",
    ""man_firefighter_medium-dark_skin_tone"": ""👨🏾\u200d🚒"",
    ""man_firefighter_medium-light_skin_tone"": ""👨🏼\u200d🚒"",
    ""man_firefighter_medium_skin_tone"": ""👨🏽\u200d🚒"",
    ""man_frowning"": ""🙍\u200d♂️"",
    ""man_frowning_dark_skin_tone"": ""🙍🏿\u200d♂️"",
    ""man_frowning_light_skin_tone"": ""🙍🏻\u200d♂️"",
    ""man_frowning_medium-dark_skin_tone"": ""🙍🏾\u200d♂️"",
    ""man_frowning_medium-light_skin_tone"": ""🙍🏼\u200d♂️"",
    ""man_frowning_medium_skin_tone"": ""🙍🏽\u200d♂️"",
    ""man_genie"": ""🧞\u200d♂️"",
    ""man_gesturing_no"": ""🙅\u200d♂️"",
    ""man_gesturing_no_dark_skin_tone"": ""🙅🏿\u200d♂️"",
    ""man_gesturing_no_light_skin_tone"": ""🙅🏻\u200d♂️"",
    ""man_gesturing_no_medium-dark_skin_tone"": ""🙅🏾\u200d♂️"",
    ""man_gesturing_no_medium-light_skin_tone"": ""🙅🏼\u200d♂️"",
    ""man_gesturing_no_medium_skin_tone"": ""🙅🏽\u200d♂️"",
    ""man_gesturing_ok"": ""🙆\u200d♂️"",
    ""man_gesturing_ok_dark_skin_tone"": ""🙆🏿\u200d♂️"",
    ""man_gesturing_ok_light_skin_tone"": ""🙆🏻\u200d♂️"",
    ""man_gesturing_ok_medium-dark_skin_tone"": ""🙆🏾\u200d♂️"",
    ""man_gesturing_ok_medium-light_skin_tone"": ""🙆🏼\u200d♂️"",
    ""man_gesturing_ok_medium_skin_tone"": ""🙆🏽\u200d♂️"",
    ""man_getting_haircut"": ""💇\u200d♂️"",
    ""man_getting_haircut_dark_skin_tone"": ""💇🏿\u200d♂️"",
    ""man_getting_haircut_light_skin_tone"": ""💇🏻\u200d♂️"",
    ""man_getting_haircut_medium-dark_skin_tone"": ""💇🏾\u200d♂️"",
    ""man_getting_haircut_medium-light_skin_tone"": ""💇🏼\u200d♂️"",
    ""man_getting_haircut_medium_skin_tone"": ""💇🏽\u200d♂️"",
    ""man_getting_massage"": ""💆\u200d♂️"",
    ""man_getting_massage_dark_skin_tone"": ""💆🏿\u200d♂️"",
    ""man_getting_massage_light_skin_tone"": ""💆🏻\u200d♂️"",
    ""man_getting_massage_medium-dark_skin_tone"": ""💆🏾\u200d♂️"",
    ""man_getting_massage_medium-light_skin_tone"": ""💆🏼\u200d♂️"",
    ""man_getting_massage_medium_skin_tone"": ""💆🏽\u200d♂️"",
    ""man_golfing"": ""🏌️\u200d♂️"",
    ""man_golfing_dark_skin_tone"": ""🏌🏿\u200d♂️"",
    ""man_golfing_light_skin_tone"": ""🏌🏻\u200d♂️"",
    ""man_golfing_medium-dark_skin_tone"": ""🏌🏾\u200d♂️"",
    ""man_golfing_medium-light_skin_tone"": ""🏌🏼\u200d♂️"",
    ""man_golfing_medium_skin_tone"": ""🏌🏽\u200d♂️"",
    ""man_guard"": ""💂\u200d♂️"",
    ""man_guard_dark_skin_tone"": ""💂🏿\u200d♂️"",
    ""man_guard_light_skin_tone"": ""💂🏻\u200d♂️"",
    ""man_guard_medium-dark_skin_tone"": ""💂🏾\u200d♂️"",
    ""man_guard_medium-light_skin_tone"": ""💂🏼\u200d♂️"",
    ""man_guard_medium_skin_tone"": ""💂🏽\u200d♂️"",
    ""man_health_worker"": ""👨\u200d⚕️"",
    ""man_health_worker_dark_skin_tone"": ""👨🏿\u200d⚕️"",
    ""man_health_worker_light_skin_tone"": ""👨🏻\u200d⚕️"",
    ""man_health_worker_medium-dark_skin_tone"": ""👨🏾\u200d⚕️"",
    ""man_health_worker_medium-light_skin_tone"": ""👨🏼\u200d⚕️"",
    ""man_health_worker_medium_skin_tone"": ""👨🏽\u200d⚕️"",
    ""man_in_lotus_position"": ""🧘\u200d♂️"",
    ""man_in_lotus_position_dark_skin_tone"": ""🧘🏿\u200d♂️"",
    ""man_in_lotus_position_light_skin_tone"": ""🧘🏻\u200d♂️"",
    ""man_in_lotus_position_medium-dark_skin_tone"": ""🧘🏾\u200d♂️"",
    ""man_in_lotus_position_medium-light_skin_tone"": ""🧘🏼\u200d♂️"",
    ""man_in_lotus_position_medium_skin_tone"": ""🧘🏽\u200d♂️"",
    ""man_in_manual_wheelchair"": ""👨\u200d🦽"",
    ""man_in_motorized_wheelchair"": ""👨\u200d🦼"",
    ""man_in_steamy_room"": ""🧖\u200d♂️"",
    ""man_in_steamy_room_dark_skin_tone"": ""🧖🏿\u200d♂️"",
    ""man_in_steamy_room_light_skin_tone"": ""🧖🏻\u200d♂️"",
    ""man_in_steamy_room_medium-dark_skin_tone"": ""🧖🏾\u200d♂️"",
    ""man_in_steamy_room_medium-light_skin_tone"": ""🧖🏼\u200d♂️"",
    ""man_in_steamy_room_medium_skin_tone"": ""🧖🏽\u200d♂️"",
    ""man_in_suit_levitating"": ""🕴"",
    ""man_in_suit_levitating_dark_skin_tone"": ""🕴🏿"",
    ""man_in_suit_levitating_light_skin_tone"": ""🕴🏻"",
    ""man_in_suit_levitating_medium-dark_skin_tone"": ""🕴🏾"",
    ""man_in_suit_levitating_medium-light_skin_tone"": ""🕴🏼"",
    ""man_in_suit_levitating_medium_skin_tone"": ""🕴🏽"",
    ""man_in_tuxedo"": ""🤵"",
    ""man_in_tuxedo_dark_skin_tone"": ""🤵🏿"",
    ""man_in_tuxedo_light_skin_tone"": ""🤵🏻"",
    ""man_in_tuxedo_medium-dark_skin_tone"": ""🤵🏾"",
    ""man_in_tuxedo_medium-light_skin_tone"": ""🤵🏼"",
    ""man_in_tuxedo_medium_skin_tone"": ""🤵🏽"",
    ""man_judge"": ""👨\u200d⚖️"",
    ""man_judge_dark_skin_tone"": ""👨🏿\u200d⚖️"",
    ""man_judge_light_skin_tone"": ""👨🏻\u200d⚖️"",
    ""man_judge_medium-dark_skin_tone"": ""👨🏾\u200d⚖️"",
    ""man_judge_medium-light_skin_tone"": ""👨🏼\u200d⚖️"",
    ""man_judge_medium_skin_tone"": ""👨🏽\u200d⚖️"",
    ""man_juggling"": ""🤹\u200d♂️"",
    ""man_juggling_dark_skin_tone"": ""🤹🏿\u200d♂️"",
    ""man_juggling_light_skin_tone"": ""🤹🏻\u200d♂️"",
    ""man_juggling_medium-dark_skin_tone"": ""🤹🏾\u200d♂️"",
    ""man_juggling_medium-light_skin_tone"": ""🤹🏼\u200d♂️"",
    ""man_juggling_medium_skin_tone"": ""🤹🏽\u200d♂️"",
    ""man_lifting_weights"": ""🏋️\u200d♂️"",
    ""man_lifting_weights_dark_skin_tone"": ""🏋🏿\u200d♂️"",
    ""man_lifting_weights_light_skin_tone"": ""🏋🏻\u200d♂️"",
    ""man_lifting_weights_medium-dark_skin_tone"": ""🏋🏾\u200d♂️"",
    ""man_lifting_weights_medium-light_skin_tone"": ""🏋🏼\u200d♂️"",
    ""man_lifting_weights_medium_skin_tone"": ""🏋🏽\u200d♂️"",
    ""man_light_skin_tone"": ""👨🏻"",
    ""man_mage"": ""🧙\u200d♂️"",
    ""man_mage_dark_skin_tone"": ""🧙🏿\u200d♂️"",
    ""man_mage_light_skin_tone"": ""🧙🏻\u200d♂️"",
    ""man_mage_medium-dark_skin_tone"": ""🧙🏾\u200d♂️"",
    ""man_mage_medium-light_skin_tone"": ""🧙🏼\u200d♂️"",
    ""man_mage_medium_skin_tone"": ""🧙🏽\u200d♂️"",
    ""man_mechanic"": ""👨\u200d🔧"",
    ""man_mechanic_dark_skin_tone"": ""👨🏿\u200d🔧"",
    ""man_mechanic_light_skin_tone"": ""👨🏻\u200d🔧"",
    ""man_mechanic_medium-dark_skin_tone"": ""👨🏾\u200d🔧"",
    ""man_mechanic_medium-light_skin_tone"": ""👨🏼\u200d🔧"",
    ""man_mechanic_medium_skin_tone"": ""👨🏽\u200d🔧"",
    ""man_medium-dark_skin_tone"": ""👨🏾"",
    ""man_medium-light_skin_tone"": ""👨🏼"",
    ""man_medium_skin_tone"": ""👨🏽"",
    ""man_mountain_biking"": ""🚵\u200d♂️"",
    ""man_mountain_biking_dark_skin_tone"": ""🚵🏿\u200d♂️"",
    ""man_mountain_biking_light_skin_tone"": ""🚵🏻\u200d♂️"",
    ""man_mountain_biking_medium-dark_skin_tone"": ""🚵🏾\u200d♂️"",
    ""man_mountain_biking_medium-light_skin_tone"": ""🚵🏼\u200d♂️"",
    ""man_mountain_biking_medium_skin_tone"": ""🚵🏽\u200d♂️"",
    ""man_office_worker"": ""👨\u200d💼"",
    ""man_office_worker_dark_skin_tone"": ""👨🏿\u200d💼"",
    ""man_office_worker_light_skin_tone"": ""👨🏻\u200d💼"",
    ""man_office_worker_medium-dark_skin_tone"": ""👨🏾\u200d💼"",
    ""man_office_worker_medium-light_skin_tone"": ""👨🏼\u200d💼"",
    ""man_office_worker_medium_skin_tone"": ""👨🏽\u200d💼"",
    ""man_pilot"": ""👨\u200d✈️"",
    ""man_pilot_dark_skin_tone"": ""👨🏿\u200d✈️"",
    ""man_pilot_light_skin_tone"": ""👨🏻\u200d✈️"",
    ""man_pilot_medium-dark_skin_tone"": ""👨🏾\u200d✈️"",
    ""man_pilot_medium-light_skin_tone"": ""👨🏼\u200d✈️"",
    ""man_pilot_medium_skin_tone"": ""👨🏽\u200d✈️"",
    ""man_playing_handball"": ""🤾\u200d♂️"",
    ""man_playing_handball_dark_skin_tone"": ""🤾🏿\u200d♂️"",
    ""man_playing_handball_light_skin_tone"": ""🤾🏻\u200d♂️"",
    ""man_playing_handball_medium-dark_skin_tone"": ""🤾🏾\u200d♂️"",
    ""man_playing_handball_medium-light_skin_tone"": ""🤾🏼\u200d♂️"",
    ""man_playing_handball_medium_skin_tone"": ""🤾🏽\u200d♂️"",
    ""man_playing_water_polo"": ""🤽\u200d♂️"",
    ""man_playing_water_polo_dark_skin_tone"": ""🤽🏿\u200d♂️"",
    ""man_playing_water_polo_light_skin_tone"": ""🤽🏻\u200d♂️"",
    ""man_playing_water_polo_medium-dark_skin_tone"": ""🤽🏾\u200d♂️"",
    ""man_playing_water_polo_medium-light_skin_tone"": ""🤽🏼\u200d♂️"",
    ""man_playing_water_polo_medium_skin_tone"": ""🤽🏽\u200d♂️"",
    ""man_police_officer"": ""👮\u200d♂️"",
    ""man_police_officer_dark_skin_tone"": ""👮🏿\u200d♂️"",
    ""man_police_officer_light_skin_tone"": ""👮🏻\u200d♂️"",
    ""man_police_officer_medium-dark_skin_tone"": ""👮🏾\u200d♂️"",
    ""man_police_officer_medium-light_skin_tone"": ""👮🏼\u200d♂️"",
    ""man_police_officer_medium_skin_tone"": ""👮🏽\u200d♂️"",
    ""man_pouting"": ""🙎\u200d♂️"",
    ""man_pouting_dark_skin_tone"": ""🙎🏿\u200d♂️"",
    ""man_pouting_light_skin_tone"": ""🙎🏻\u200d♂️"",
    ""man_pouting_medium-dark_skin_tone"": ""🙎🏾\u200d♂️"",
    ""man_pouting_medium-light_skin_tone"": ""🙎🏼\u200d♂️"",
    ""man_pouting_medium_skin_tone"": ""🙎🏽\u200d♂️"",
    ""man_raising_hand"": ""🙋\u200d♂️"",
    ""man_raising_hand_dark_skin_tone"": ""🙋🏿\u200d♂️"",
    ""man_raising_hand_light_skin_tone"": ""🙋🏻\u200d♂️"",
    ""man_raising_hand_medium-dark_skin_tone"": ""🙋🏾\u200d♂️"",
    ""man_raising_hand_medium-light_skin_tone"": ""🙋🏼\u200d♂️"",
    ""man_raising_hand_medium_skin_tone"": ""🙋🏽\u200d♂️"",
    ""man_rowing_boat"": ""🚣\u200d♂️"",
    ""man_rowing_boat_dark_skin_tone"": ""🚣🏿\u200d♂️"",
    ""man_rowing_boat_light_skin_tone"": ""🚣🏻\u200d♂️"",
    ""man_rowing_boat_medium-dark_skin_tone"": ""🚣🏾\u200d♂️"",
    ""man_rowing_boat_medium-light_skin_tone"": ""🚣🏼\u200d♂️"",
    ""man_rowing_boat_medium_skin_tone"": ""🚣🏽\u200d♂️"",
    ""man_running"": ""🏃\u200d♂️"",
    ""man_running_dark_skin_tone"": ""🏃🏿\u200d♂️"",
    ""man_running_light_skin_tone"": ""🏃🏻\u200d♂️"",
    ""man_running_medium-dark_skin_tone"": ""🏃🏾\u200d♂️"",
    ""man_running_medium-light_skin_tone"": ""🏃🏼\u200d♂️"",
    ""man_running_medium_skin_tone"": ""🏃🏽\u200d♂️"",
    ""man_scientist"": ""👨\u200d🔬"",
    ""man_scientist_dark_skin_tone"": ""👨🏿\u200d🔬"",
    ""man_scientist_light_skin_tone"": ""👨🏻\u200d🔬"",
    ""man_scientist_medium-dark_skin_tone"": ""👨🏾\u200d🔬"",
    ""man_scientist_medium-light_skin_tone"": ""👨🏼\u200d🔬"",
    ""man_scientist_medium_skin_tone"": ""👨🏽\u200d🔬"",
    ""man_shrugging"": ""🤷\u200d♂️"",
    ""man_shrugging_dark_skin_tone"": ""🤷🏿\u200d♂️"",
    ""man_shrugging_light_skin_tone"": ""🤷🏻\u200d♂️"",
    ""man_shrugging_medium-dark_skin_tone"": ""🤷🏾\u200d♂️"",
    ""man_shrugging_medium-light_skin_tone"": ""🤷🏼\u200d♂️"",
    ""man_shrugging_medium_skin_tone"": ""🤷🏽\u200d♂️"",
    ""man_singer"": ""👨\u200d🎤"",
    ""man_singer_dark_skin_tone"": ""👨🏿\u200d🎤"",
    ""man_singer_light_skin_tone"": ""👨🏻\u200d🎤"",
    ""man_singer_medium-dark_skin_tone"": ""👨🏾\u200d🎤"",
    ""man_singer_medium-light_skin_tone"": ""👨🏼\u200d🎤"",
    ""man_singer_medium_skin_tone"": ""👨🏽\u200d🎤"",
    ""man_student"": ""👨\u200d🎓"",
    ""man_student_dark_skin_tone"": ""👨🏿\u200d🎓"",
    ""man_student_light_skin_tone"": ""👨🏻\u200d🎓"",
    ""man_student_medium-dark_skin_tone"": ""👨🏾\u200d🎓"",
    ""man_student_medium-light_skin_tone"": ""👨🏼\u200d🎓"",
    ""man_student_medium_skin_tone"": ""👨🏽\u200d🎓"",
    ""man_surfing"": ""🏄\u200d♂️"",
    ""man_surfing_dark_skin_tone"": ""🏄🏿\u200d♂️"",
    ""man_surfing_light_skin_tone"": ""🏄🏻\u200d♂️"",
    ""man_surfing_medium-dark_skin_tone"": ""🏄🏾\u200d♂️"",
    ""man_surfing_medium-light_skin_tone"": ""🏄🏼\u200d♂️"",
    ""man_surfing_medium_skin_tone"": ""🏄🏽\u200d♂️"",
    ""man_swimming"": ""🏊\u200d♂️"",
    ""man_swimming_dark_skin_tone"": ""🏊🏿\u200d♂️"",
    ""man_swimming_light_skin_tone"": ""🏊🏻\u200d♂️"",
    ""man_swimming_medium-dark_skin_tone"": ""🏊🏾\u200d♂️"",
    ""man_swimming_medium-light_skin_tone"": ""🏊🏼\u200d♂️"",
    ""man_swimming_medium_skin_tone"": ""🏊🏽\u200d♂️"",
    ""man_teacher"": ""👨\u200d🏫"",
    ""man_teacher_dark_skin_tone"": ""👨🏿\u200d🏫"",
    ""man_teacher_light_skin_tone"": ""👨🏻\u200d🏫"",
    ""man_teacher_medium-dark_skin_tone"": ""👨🏾\u200d🏫"",
    ""man_teacher_medium-light_skin_tone"": ""👨🏼\u200d🏫"",
    ""man_teacher_medium_skin_tone"": ""👨🏽\u200d🏫"",
    ""man_technologist"": ""👨\u200d💻"",
    ""man_technologist_dark_skin_tone"": ""👨🏿\u200d💻"",
    ""man_technologist_light_skin_tone"": ""👨🏻\u200d💻"",
    ""man_technologist_medium-dark_skin_tone"": ""👨🏾\u200d💻"",
    ""man_technologist_medium-light_skin_tone"": ""👨🏼\u200d💻"",
    ""man_technologist_medium_skin_tone"": ""👨🏽\u200d💻"",
    ""man_tipping_hand"": ""💁\u200d♂️"",
    ""man_tipping_hand_dark_skin_tone"": ""💁🏿\u200d♂️"",
    ""man_tipping_hand_light_skin_tone"": ""💁🏻\u200d♂️"",
    ""man_tipping_hand_medium-dark_skin_tone"": ""💁🏾\u200d♂️"",
    ""man_tipping_hand_medium-light_skin_tone"": ""💁🏼\u200d♂️"",
    ""man_tipping_hand_medium_skin_tone"": ""💁🏽\u200d♂️"",
    ""man_vampire"": ""🧛\u200d♂️"",
    ""man_vampire_dark_skin_tone"": ""🧛🏿\u200d♂️"",
    ""man_vampire_light_skin_tone"": ""🧛🏻\u200d♂️"",
    ""man_vampire_medium-dark_skin_tone"": ""🧛🏾\u200d♂️"",
    ""man_vampire_medium-light_skin_tone"": ""🧛🏼\u200d♂️"",
    ""man_vampire_medium_skin_tone"": ""🧛🏽\u200d♂️"",
    ""man_walking"": ""🚶\u200d♂️"",
    ""man_walking_dark_skin_tone"": ""🚶🏿\u200d♂️"",
    ""man_walking_light_skin_tone"": ""🚶🏻\u200d♂️"",
    ""man_walking_medium-dark_skin_tone"": ""🚶🏾\u200d♂️"",
    ""man_walking_medium-light_skin_tone"": ""🚶🏼\u200d♂️"",
    ""man_walking_medium_skin_tone"": ""🚶🏽\u200d♂️"",
    ""man_wearing_turban"": ""👳\u200d♂️"",
    ""man_wearing_turban_dark_skin_tone"": ""👳🏿\u200d♂️"",
    ""man_wearing_turban_light_skin_tone"": ""👳🏻\u200d♂️"",
    ""man_wearing_turban_medium-dark_skin_tone"": ""👳🏾\u200d♂️"",
    ""man_wearing_turban_medium-light_skin_tone"": ""👳🏼\u200d♂️"",
    ""man_wearing_turban_medium_skin_tone"": ""👳🏽\u200d♂️"",
    ""man_with_probing_cane"": ""👨\u200d🦯"",
    ""man_with_chinese_cap"": ""👲"",
    ""man_with_chinese_cap_dark_skin_tone"": ""👲🏿"",
    ""man_with_chinese_cap_light_skin_tone"": ""👲🏻"",
    ""man_with_chinese_cap_medium-dark_skin_tone"": ""👲🏾"",
    ""man_with_chinese_cap_medium-light_skin_tone"": ""👲🏼"",
    ""man_with_chinese_cap_medium_skin_tone"": ""👲🏽"",
    ""man_zombie"": ""🧟\u200d♂️"",
    ""mango"": ""🥭"",
    ""mantelpiece_clock"": ""🕰"",
    ""manual_wheelchair"": ""🦽"",
    ""man’s_shoe"": ""👞"",
    ""map_of_japan"": ""🗾"",
    ""maple_leaf"": ""🍁"",
    ""martial_arts_uniform"": ""🥋"",
    ""mate"": ""🧉"",
    ""meat_on_bone"": ""🍖"",
    ""mechanical_arm"": ""🦾"",
    ""mechanical_leg"": ""🦿"",
    ""medical_symbol"": ""⚕"",
    ""megaphone"": ""📣"",
    ""melon"": ""🍈"",
    ""memo"": ""📝"",
    ""men_with_bunny_ears"": ""👯\u200d♂️"",
    ""men_wrestling"": ""🤼\u200d♂️"",
    ""menorah"": ""🕎"",
    ""men’s_room"": ""🚹"",
    ""mermaid"": ""🧜\u200d♀️"",
    ""mermaid_dark_skin_tone"": ""🧜🏿\u200d♀️"",
    ""mermaid_light_skin_tone"": ""🧜🏻\u200d♀️"",
    ""mermaid_medium-dark_skin_tone"": ""🧜🏾\u200d♀️"",
    ""mermaid_medium-light_skin_tone"": ""🧜🏼\u200d♀️"",
    ""mermaid_medium_skin_tone"": ""🧜🏽\u200d♀️"",
    ""merman"": ""🧜\u200d♂️"",
    ""merman_dark_skin_tone"": ""🧜🏿\u200d♂️"",
    ""merman_light_skin_tone"": ""🧜🏻\u200d♂️"",
    ""merman_medium-dark_skin_tone"": ""🧜🏾\u200d♂️"",
    ""merman_medium-light_skin_tone"": ""🧜🏼\u200d♂️"",
    ""merman_medium_skin_tone"": ""🧜🏽\u200d♂️"",
    ""merperson"": ""🧜"",
    ""merperson_dark_skin_tone"": ""🧜🏿"",
    ""merperson_light_skin_tone"": ""🧜🏻"",
    ""merperson_medium-dark_skin_tone"": ""🧜🏾"",
    ""merperson_medium-light_skin_tone"": ""🧜🏼"",
    ""merperson_medium_skin_tone"": ""🧜🏽"",
    ""metro"": ""🚇"",
    ""microbe"": ""🦠"",
    ""microphone"": ""🎤"",
    ""microscope"": ""🔬"",
    ""middle_finger"": ""🖕"",
    ""middle_finger_dark_skin_tone"": ""🖕🏿"",
    ""middle_finger_light_skin_tone"": ""🖕🏻"",
    ""middle_finger_medium-dark_skin_tone"": ""🖕🏾"",
    ""middle_finger_medium-light_skin_tone"": ""🖕🏼"",
    ""middle_finger_medium_skin_tone"": ""🖕🏽"",
    ""military_medal"": ""🎖"",
    ""milky_way"": ""🌌"",
    ""minibus"": ""🚐"",
    ""moai"": ""🗿"",
    ""mobile_phone"": ""📱"",
    ""mobile_phone_off"": ""📴"",
    ""mobile_phone_with_arrow"": ""📲"",
    ""money-mouth_face"": ""🤑"",
    ""money_bag"": ""💰"",
    ""money_with_wings"": ""💸"",
    ""monkey"": ""🐒"",
    ""monkey_face"": ""🐵"",
    ""monorail"": ""🚝"",
    ""moon_cake"": ""🥮"",
    ""moon_viewing_ceremony"": ""🎑"",
    ""mosque"": ""🕌"",
    ""mosquito"": ""🦟"",
    ""motor_boat"": ""🛥"",
    ""motor_scooter"": ""🛵"",
    ""motorcycle"": ""🏍"",
    ""motorized_wheelchair"": ""🦼"",
    ""motorway"": ""🛣"",
    ""mount_fuji"": ""🗻"",
    ""mountain"": ""⛰"",
    ""mountain_cableway"": ""🚠"",
    ""mountain_railway"": ""🚞"",
    ""mouse"": ""🐭"",
    ""mouse_face"": ""🐭"",
    ""mouth"": ""👄"",
    ""movie_camera"": ""🎥"",
    ""mushroom"": ""🍄"",
    ""musical_keyboard"": ""🎹"",
    ""musical_note"": ""🎵"",
    ""musical_notes"": ""🎶"",
    ""musical_score"": ""🎼"",
    ""muted_speaker"": ""🔇"",
    ""nail_polish"": ""💅"",
    ""nail_polish_dark_skin_tone"": ""💅🏿"",
    ""nail_polish_light_skin_tone"": ""💅🏻"",
    ""nail_polish_medium-dark_skin_tone"": ""💅🏾"",
    ""nail_polish_medium-light_skin_tone"": ""💅🏼"",
    ""nail_polish_medium_skin_tone"": ""💅🏽"",
    ""name_badge"": ""📛"",
    ""national_park"": ""🏞"",
    ""nauseated_face"": ""🤢"",
    ""nazar_amulet"": ""🧿"",
    ""necktie"": ""👔"",
    ""nerd_face"": ""🤓"",
    ""neutral_face"": ""😐"",
    ""new_moon"": ""🌑"",
    ""new_moon_face"": ""🌚"",
    ""newspaper"": ""📰"",
    ""next_track_button"": ""⏭"",
    ""night_with_stars"": ""🌃"",
    ""nine-thirty"": ""🕤"",
    ""nine_o’clock"": ""🕘"",
    ""no_bicycles"": ""🚳"",
    ""no_entry"": ""⛔"",
    ""no_littering"": ""🚯"",
    ""no_mobile_phones"": ""📵"",
    ""no_one_under_eighteen"": ""🔞"",
    ""no_pedestrians"": ""🚷"",
    ""no_smoking"": ""🚭"",
    ""non-potable_water"": ""🚱"",
    ""nose"": ""👃"",
    ""nose_dark_skin_tone"": ""👃🏿"",
    ""nose_light_skin_tone"": ""👃🏻"",
    ""nose_medium-dark_skin_tone"": ""👃🏾"",
    ""nose_medium-light_skin_tone"": ""👃🏼"",
    ""nose_medium_skin_tone"": ""👃🏽"",
    ""notebook"": ""📓"",
    ""notebook_with_decorative_cover"": ""📔"",
    ""nut_and_bolt"": ""🔩"",
    ""octopus"": ""🐙"",
    ""oden"": ""🍢"",
    ""office_building"": ""🏢"",
    ""ogre"": ""👹"",
    ""oil_drum"": ""🛢"",
    ""old_key"": ""🗝"",
    ""old_man"": ""👴"",
    ""old_man_dark_skin_tone"": ""👴🏿"",
    ""old_man_light_skin_tone"": ""👴🏻"",
    ""old_man_medium-dark_skin_tone"": ""👴🏾"",
    ""old_man_medium-light_skin_tone"": ""👴🏼"",
    ""old_man_medium_skin_tone"": ""👴🏽"",
    ""old_woman"": ""👵"",
    ""old_woman_dark_skin_tone"": ""👵🏿"",
    ""old_woman_light_skin_tone"": ""👵🏻"",
    ""old_woman_medium-dark_skin_tone"": ""👵🏾"",
    ""old_woman_medium-light_skin_tone"": ""👵🏼"",
    ""old_woman_medium_skin_tone"": ""👵🏽"",
    ""older_adult"": ""🧓"",
    ""older_adult_dark_skin_tone"": ""🧓🏿"",
    ""older_adult_light_skin_tone"": ""🧓🏻"",
    ""older_adult_medium-dark_skin_tone"": ""🧓🏾"",
    ""older_adult_medium-light_skin_tone"": ""🧓🏼"",
    ""older_adult_medium_skin_tone"": ""🧓🏽"",
    ""om"": ""🕉"",
    ""oncoming_automobile"": ""🚘"",
    ""oncoming_bus"": ""🚍"",
    ""oncoming_fist"": ""👊"",
    ""oncoming_fist_dark_skin_tone"": ""👊🏿"",
    ""oncoming_fist_light_skin_tone"": ""👊🏻"",
    ""oncoming_fist_medium-dark_skin_tone"": ""👊🏾"",
    ""oncoming_fist_medium-light_skin_tone"": ""👊🏼"",
    ""oncoming_fist_medium_skin_tone"": ""👊🏽"",
    ""oncoming_police_car"": ""🚔"",
    ""oncoming_taxi"": ""🚖"",
    ""one-piece_swimsuit"": ""🩱"",
    ""one-thirty"": ""🕜"",
    ""one_o’clock"": ""🕐"",
    ""onion"": ""🧅"",
    ""open_book"": ""📖"",
    ""open_file_folder"": ""📂"",
    ""open_hands"": ""👐"",
    ""open_hands_dark_skin_tone"": ""👐🏿"",
    ""open_hands_light_skin_tone"": ""👐🏻"",
    ""open_hands_medium-dark_skin_tone"": ""👐🏾"",
    ""open_hands_medium-light_skin_tone"": ""👐🏼"",
    ""open_hands_medium_skin_tone"": ""👐🏽"",
    ""open_mailbox_with_lowered_flag"": ""📭"",
    ""open_mailbox_with_raised_flag"": ""📬"",
    ""optical_disk"": ""💿"",
    ""orange_book"": ""📙"",
    ""orange_circle"": ""🟠"",
    ""orange_heart"": ""🧡"",
    ""orange_square"": ""🟧"",
    ""orangutan"": ""🦧"",
    ""orthodox_cross"": ""☦"",
    ""otter"": ""🦦"",
    ""outbox_tray"": ""📤"",
    ""owl"": ""🦉"",
    ""ox"": ""🐂"",
    ""oyster"": ""🦪"",
    ""package"": ""📦"",
    ""page_facing_up"": ""📄"",
    ""page_with_curl"": ""📃"",
    ""pager"": ""📟"",
    ""paintbrush"": ""🖌"",
    ""palm_tree"": ""🌴"",
    ""palms_up_together"": ""🤲"",
    ""palms_up_together_dark_skin_tone"": ""🤲🏿"",
    ""palms_up_together_light_skin_tone"": ""🤲🏻"",
    ""palms_up_together_medium-dark_skin_tone"": ""🤲🏾"",
    ""palms_up_together_medium-light_skin_tone"": ""🤲🏼"",
    ""palms_up_together_medium_skin_tone"": ""🤲🏽"",
    ""pancakes"": ""🥞"",
    ""panda_face"": ""🐼"",
    ""paperclip"": ""📎"",
    ""parrot"": ""🦜"",
    ""part_alternation_mark"": ""〽"",
    ""party_popper"": ""🎉"",
    ""partying_face"": ""🥳"",
    ""passenger_ship"": ""🛳"",
    ""passport_control"": ""🛂"",
    ""pause_button"": ""⏸"",
    ""paw_prints"": ""🐾"",
    ""peace_symbol"": ""☮"",
    ""peach"": ""🍑"",
    ""peacock"": ""🦚"",
    ""peanuts"": ""🥜"",
    ""pear"": ""🍐"",
    ""pen"": ""🖊"",
    ""pencil"": ""📝"",
    ""penguin"": ""🐧"",
    ""pensive_face"": ""😔"",
    ""people_holding_hands"": ""🧑\u200d🤝\u200d🧑"",
    ""people_with_bunny_ears"": ""👯"",
    ""people_wrestling"": ""🤼"",
    ""performing_arts"": ""🎭"",
    ""persevering_face"": ""😣"",
    ""person_biking"": ""🚴"",
    ""person_biking_dark_skin_tone"": ""🚴🏿"",
    ""person_biking_light_skin_tone"": ""🚴🏻"",
    ""person_biking_medium-dark_skin_tone"": ""🚴🏾"",
    ""person_biking_medium-light_skin_tone"": ""🚴🏼"",
    ""person_biking_medium_skin_tone"": ""🚴🏽"",
    ""person_bouncing_ball"": ""⛹"",
    ""person_bouncing_ball_dark_skin_tone"": ""⛹🏿"",
    ""person_bouncing_ball_light_skin_tone"": ""⛹🏻"",
    ""person_bouncing_ball_medium-dark_skin_tone"": ""⛹🏾"",
    ""person_bouncing_ball_medium-light_skin_tone"": ""⛹🏼"",
    ""person_bouncing_ball_medium_skin_tone"": ""⛹🏽"",
    ""person_bowing"": ""🙇"",
    ""person_bowing_dark_skin_tone"": ""🙇🏿"",
    ""person_bowing_light_skin_tone"": ""🙇🏻"",
    ""person_bowing_medium-dark_skin_tone"": ""🙇🏾"",
    ""person_bowing_medium-light_skin_tone"": ""🙇🏼"",
    ""person_bowing_medium_skin_tone"": ""🙇🏽"",
    ""person_cartwheeling"": ""🤸"",
    ""person_cartwheeling_dark_skin_tone"": ""🤸🏿"",
    ""person_cartwheeling_light_skin_tone"": ""🤸🏻"",
    ""person_cartwheeling_medium-dark_skin_tone"": ""🤸🏾"",
    ""person_cartwheeling_medium-light_skin_tone"": ""🤸🏼"",
    ""person_cartwheeling_medium_skin_tone"": ""🤸🏽"",
    ""person_climbing"": ""🧗"",
    ""person_climbing_dark_skin_tone"": ""🧗🏿"",
    ""person_climbing_light_skin_tone"": ""🧗🏻"",
    ""person_climbing_medium-dark_skin_tone"": ""🧗🏾"",
    ""person_climbing_medium-light_skin_tone"": ""🧗🏼"",
    ""person_climbing_medium_skin_tone"": ""🧗🏽"",
    ""person_facepalming"": ""🤦"",
    ""person_facepalming_dark_skin_tone"": ""🤦🏿"",
    ""person_facepalming_light_skin_tone"": ""🤦🏻"",
    ""person_facepalming_medium-dark_skin_tone"": ""🤦🏾"",
    ""person_facepalming_medium-light_skin_tone"": ""🤦🏼"",
    ""person_facepalming_medium_skin_tone"": ""🤦🏽"",
    ""person_fencing"": ""🤺"",
    ""person_frowning"": ""🙍"",
    ""person_frowning_dark_skin_tone"": ""🙍🏿"",
    ""person_frowning_light_skin_tone"": ""🙍🏻"",
    ""person_frowning_medium-dark_skin_tone"": ""🙍🏾"",
    ""person_frowning_medium-light_skin_tone"": ""🙍🏼"",
    ""person_frowning_medium_skin_tone"": ""🙍🏽"",
    ""person_gesturing_no"": ""🙅"",
    ""person_gesturing_no_dark_skin_tone"": ""🙅🏿"",
    ""person_gesturing_no_light_skin_tone"": ""🙅🏻"",
    ""person_gesturing_no_medium-dark_skin_tone"": ""🙅🏾"",
    ""person_gesturing_no_medium-light_skin_tone"": ""🙅🏼"",
    ""person_gesturing_no_medium_skin_tone"": ""🙅🏽"",
    ""person_gesturing_ok"": ""🙆"",
    ""person_gesturing_ok_dark_skin_tone"": ""🙆🏿"",
    ""person_gesturing_ok_light_skin_tone"": ""🙆🏻"",
    ""person_gesturing_ok_medium-dark_skin_tone"": ""🙆🏾"",
    ""person_gesturing_ok_medium-light_skin_tone"": ""🙆🏼"",
    ""person_gesturing_ok_medium_skin_tone"": ""🙆🏽"",
    ""person_getting_haircut"": ""💇"",
    ""person_getting_haircut_dark_skin_tone"": ""💇🏿"",
    ""person_getting_haircut_light_skin_tone"": ""💇🏻"",
    ""person_getting_haircut_medium-dark_skin_tone"": ""💇🏾"",
    ""person_getting_haircut_medium-light_skin_tone"": ""💇🏼"",
    ""person_getting_haircut_medium_skin_tone"": ""💇🏽"",
    ""person_getting_massage"": ""💆"",
    ""person_getting_massage_dark_skin_tone"": ""💆🏿"",
    ""person_getting_massage_light_skin_tone"": ""💆🏻"",
    ""person_getting_massage_medium-dark_skin_tone"": ""💆🏾"",
    ""person_getting_massage_medium-light_skin_tone"": ""💆🏼"",
    ""person_getting_massage_medium_skin_tone"": ""💆🏽"",
    ""person_golfing"": ""🏌"",
    ""person_golfing_dark_skin_tone"": ""🏌🏿"",
    ""person_golfing_light_skin_tone"": ""🏌🏻"",
    ""person_golfing_medium-dark_skin_tone"": ""🏌🏾"",
    ""person_golfing_medium-light_skin_tone"": ""🏌🏼"",
    ""person_golfing_medium_skin_tone"": ""🏌🏽"",
    ""person_in_bed"": ""🛌"",
    ""person_in_bed_dark_skin_tone"": ""🛌🏿"",
    ""person_in_bed_light_skin_tone"": ""🛌🏻"",
    ""person_in_bed_medium-dark_skin_tone"": ""🛌🏾"",
    ""person_in_bed_medium-light_skin_tone"": ""🛌🏼"",
    ""person_in_bed_medium_skin_tone"": ""🛌🏽"",
    ""person_in_lotus_position"": ""🧘"",
    ""person_in_lotus_position_dark_skin_tone"": ""🧘🏿"",
    ""person_in_lotus_position_light_skin_tone"": ""🧘🏻"",
    ""person_in_lotus_position_medium-dark_skin_tone"": ""🧘🏾"",
    ""person_in_lotus_position_medium-light_skin_tone"": ""🧘🏼"",
    ""person_in_lotus_position_medium_skin_tone"": ""🧘🏽"",
    ""person_in_steamy_room"": ""🧖"",
    ""person_in_steamy_room_dark_skin_tone"": ""🧖🏿"",
    ""person_in_steamy_room_light_skin_tone"": ""🧖🏻"",
    ""person_in_steamy_room_medium-dark_skin_tone"": ""🧖🏾"",
    ""person_in_steamy_room_medium-light_skin_tone"": ""🧖🏼"",
    ""person_in_steamy_room_medium_skin_tone"": ""🧖🏽"",
    ""person_juggling"": ""🤹"",
    ""person_juggling_dark_skin_tone"": ""🤹🏿"",
    ""person_juggling_light_skin_tone"": ""🤹🏻"",
    ""person_juggling_medium-dark_skin_tone"": ""🤹🏾"",
    ""person_juggling_medium-light_skin_tone"": ""🤹🏼"",
    ""person_juggling_medium_skin_tone"": ""🤹🏽"",
    ""person_kneeling"": ""🧎"",
    ""person_lifting_weights"": ""🏋"",
    ""person_lifting_weights_dark_skin_tone"": ""🏋🏿"",
    ""person_lifting_weights_light_skin_tone"": ""🏋🏻"",
    ""person_lifting_weights_medium-dark_skin_tone"": ""🏋🏾"",
    ""person_lifting_weights_medium-light_skin_tone"": ""🏋🏼"",
    ""person_lifting_weights_medium_skin_tone"": ""🏋🏽"",
    ""person_mountain_biking"": ""🚵"",
    ""person_mountain_biking_dark_skin_tone"": ""🚵🏿"",
    ""person_mountain_biking_light_skin_tone"": ""🚵🏻"",
    ""person_mountain_biking_medium-dark_skin_tone"": ""🚵🏾"",
    ""person_mountain_biking_medium-light_skin_tone"": ""🚵🏼"",
    ""person_mountain_biking_medium_skin_tone"": ""🚵🏽"",
    ""person_playing_handball"": ""🤾"",
    ""person_playing_handball_dark_skin_tone"": ""🤾🏿"",
    ""person_playing_handball_light_skin_tone"": ""🤾🏻"",
    ""person_playing_handball_medium-dark_skin_tone"": ""🤾🏾"",
    ""person_playing_handball_medium-light_skin_tone"": ""🤾🏼"",
    ""person_playing_handball_medium_skin_tone"": ""🤾🏽"",
    ""person_playing_water_polo"": ""🤽"",
    ""person_playing_water_polo_dark_skin_tone"": ""🤽🏿"",
    ""person_playing_water_polo_light_skin_tone"": ""🤽🏻"",
    ""person_playing_water_polo_medium-dark_skin_tone"": ""🤽🏾"",
    ""person_playing_water_polo_medium-light_skin_tone"": ""🤽🏼"",
    ""person_playing_water_polo_medium_skin_tone"": ""🤽🏽"",
    ""person_pouting"": ""🙎"",
    ""person_pouting_dark_skin_tone"": ""🙎🏿"",
    ""person_pouting_light_skin_tone"": ""🙎🏻"",
    ""person_pouting_medium-dark_skin_tone"": ""🙎🏾"",
    ""person_pouting_medium-light_skin_tone"": ""🙎🏼"",
    ""person_pouting_medium_skin_tone"": ""🙎🏽"",
    ""person_raising_hand"": ""🙋"",
    ""person_raising_hand_dark_skin_tone"": ""🙋🏿"",
    ""person_raising_hand_light_skin_tone"": ""🙋🏻"",
    ""person_raising_hand_medium-dark_skin_tone"": ""🙋🏾"",
    ""person_raising_hand_medium-light_skin_tone"": ""🙋🏼"",
    ""person_raising_hand_medium_skin_tone"": ""🙋🏽"",
    ""person_rowing_boat"": ""🚣"",
    ""person_rowing_boat_dark_skin_tone"": ""🚣🏿"",
    ""person_rowing_boat_light_skin_tone"": ""🚣🏻"",
    ""person_rowing_boat_medium-dark_skin_tone"": ""🚣🏾"",
    ""person_rowing_boat_medium-light_skin_tone"": ""🚣🏼"",
    ""person_rowing_boat_medium_skin_tone"": ""🚣🏽"",
    ""person_running"": ""🏃"",
    ""person_running_dark_skin_tone"": ""🏃🏿"",
    ""person_running_light_skin_tone"": ""🏃🏻"",
    ""person_running_medium-dark_skin_tone"": ""🏃🏾"",
    ""person_running_medium-light_skin_tone"": ""🏃🏼"",
    ""person_running_medium_skin_tone"": ""🏃🏽"",
    ""person_shrugging"": ""🤷"",
    ""person_shrugging_dark_skin_tone"": ""🤷🏿"",
    ""person_shrugging_light_skin_tone"": ""🤷🏻"",
    ""person_shrugging_medium-dark_skin_tone"": ""🤷🏾"",
    ""person_shrugging_medium-light_skin_tone"": ""🤷🏼"",
    ""person_shrugging_medium_skin_tone"": ""🤷🏽"",
    ""person_standing"": ""🧍"",
    ""person_surfing"": ""🏄"",
    ""person_surfing_dark_skin_tone"": ""🏄🏿"",
    ""person_surfing_light_skin_tone"": ""🏄🏻"",
    ""person_surfing_medium-dark_skin_tone"": ""🏄🏾"",
    ""person_surfing_medium-light_skin_tone"": ""🏄🏼"",
    ""person_surfing_medium_skin_tone"": ""🏄🏽"",
    ""person_swimming"": ""🏊"",
    ""person_swimming_dark_skin_tone"": ""🏊🏿"",
    ""person_swimming_light_skin_tone"": ""🏊🏻"",
    ""person_swimming_medium-dark_skin_tone"": ""🏊🏾"",
    ""person_swimming_medium-light_skin_tone"": ""🏊🏼"",
    ""person_swimming_medium_skin_tone"": ""🏊🏽"",
    ""person_taking_bath"": ""🛀"",
    ""person_taking_bath_dark_skin_tone"": ""🛀🏿"",
    ""person_taking_bath_light_skin_tone"": ""🛀🏻"",
    ""person_taking_bath_medium-dark_skin_tone"": ""🛀🏾"",
    ""person_taking_bath_medium-light_skin_tone"": ""🛀🏼"",
    ""person_taking_bath_medium_skin_tone"": ""🛀🏽"",
    ""person_tipping_hand"": ""💁"",
    ""person_tipping_hand_dark_skin_tone"": ""💁🏿"",
    ""person_tipping_hand_light_skin_tone"": ""💁🏻"",
    ""person_tipping_hand_medium-dark_skin_tone"": ""💁🏾"",
    ""person_tipping_hand_medium-light_skin_tone"": ""💁🏼"",
    ""person_tipping_hand_medium_skin_tone"": ""💁🏽"",
    ""person_walking"": ""🚶"",
    ""person_walking_dark_skin_tone"": ""🚶🏿"",
    ""person_walking_light_skin_tone"": ""🚶🏻"",
    ""person_walking_medium-dark_skin_tone"": ""🚶🏾"",
    ""person_walking_medium-light_skin_tone"": ""🚶🏼"",
    ""person_walking_medium_skin_tone"": ""🚶🏽"",
    ""person_wearing_turban"": ""👳"",
    ""person_wearing_turban_dark_skin_tone"": ""👳🏿"",
    ""person_wearing_turban_light_skin_tone"": ""👳🏻"",
    ""person_wearing_turban_medium-dark_skin_tone"": ""👳🏾"",
    ""person_wearing_turban_medium-light_skin_tone"": ""👳🏼"",
    ""person_wearing_turban_medium_skin_tone"": ""👳🏽"",
    ""petri_dish"": ""🧫"",
    ""pick"": ""⛏"",
    ""pie"": ""🥧"",
    ""pig"": ""🐷"",
    ""pig_face"": ""🐷"",
    ""pig_nose"": ""🐽"",
    ""pile_of_poo"": ""💩"",
    ""pill"": ""💊"",
    ""pinching_hand"": ""🤏"",
    ""pine_decoration"": ""🎍"",
    ""pineapple"": ""🍍"",
    ""ping_pong"": ""🏓"",
    ""pirate_flag"": ""🏴\u200d☠️"",
    ""pistol"": ""🔫"",
    ""pizza"": ""🍕"",
    ""place_of_worship"": ""🛐"",
    ""play_button"": ""▶"",
    ""play_or_pause_button"": ""⏯"",
    ""pleading_face"": ""🥺"",
    ""police_car"": ""🚓"",
    ""police_car_light"": ""🚨"",
    ""police_officer"": ""👮"",
    ""police_officer_dark_skin_tone"": ""👮🏿"",
    ""police_officer_light_skin_tone"": ""👮🏻"",
    ""police_officer_medium-dark_skin_tone"": ""👮🏾"",
    ""police_officer_medium-light_skin_tone"": ""👮🏼"",
    ""police_officer_medium_skin_tone"": ""👮🏽"",
    ""poodle"": ""🐩"",
    ""pool_8_ball"": ""🎱"",
    ""popcorn"": ""🍿"",
    ""post_office"": ""🏣"",
    ""postal_horn"": ""📯"",
    ""postbox"": ""📮"",
    ""pot_of_food"": ""🍲"",
    ""potable_water"": ""🚰"",
    ""potato"": ""🥔"",
    ""poultry_leg"": ""🍗"",
    ""pound_banknote"": ""💷"",
    ""pouting_cat_face"": ""😾"",
    ""pouting_face"": ""😡"",
    ""prayer_beads"": ""📿"",
    ""pregnant_woman"": ""🤰"",
    ""pregnant_woman_dark_skin_tone"": ""🤰🏿"",
    ""pregnant_woman_light_skin_tone"": ""🤰🏻"",
    ""pregnant_woman_medium-dark_skin_tone"": ""🤰🏾"",
    ""pregnant_woman_medium-light_skin_tone"": ""🤰🏼"",
    ""pregnant_woman_medium_skin_tone"": ""🤰🏽"",
    ""pretzel"": ""🥨"",
    ""probing_cane"": ""🦯"",
    ""prince"": ""🤴"",
    ""prince_dark_skin_tone"": ""🤴🏿"",
    ""prince_light_skin_tone"": ""🤴🏻"",
    ""prince_medium-dark_skin_tone"": ""🤴🏾"",
    ""prince_medium-light_skin_tone"": ""🤴🏼"",
    ""prince_medium_skin_tone"": ""🤴🏽"",
    ""princess"": ""👸"",
    ""princess_dark_skin_tone"": ""👸🏿"",
    ""princess_light_skin_tone"": ""👸🏻"",
    ""princess_medium-dark_skin_tone"": ""👸🏾"",
    ""princess_medium-light_skin_tone"": ""👸🏼"",
    ""princess_medium_skin_tone"": ""👸🏽"",
    ""printer"": ""🖨"",
    ""prohibited"": ""🚫"",
    ""purple_circle"": ""🟣"",
    ""purple_heart"": ""💜"",
    ""purple_square"": ""🟪"",
    ""purse"": ""👛"",
    ""pushpin"": ""📌"",
    ""question_mark"": ""❓"",
    ""rabbit"": ""🐰"",
    ""rabbit_face"": ""🐰"",
    ""raccoon"": ""🦝"",
    ""racing_car"": ""🏎"",
    ""radio"": ""📻"",
    ""radio_button"": ""🔘"",
    ""radioactive"": ""☢"",
    ""railway_car"": ""🚃"",
    ""railway_track"": ""🛤"",
    ""rainbow"": ""🌈"",
    ""rainbow_flag"": ""🏳️\u200d🌈"",
    ""raised_back_of_hand"": ""🤚"",
    ""raised_back_of_hand_dark_skin_tone"": ""🤚🏿"",
    ""raised_back_of_hand_light_skin_tone"": ""🤚🏻"",
    ""raised_back_of_hand_medium-dark_skin_tone"": ""🤚🏾"",
    ""raised_back_of_hand_medium-light_skin_tone"": ""🤚🏼"",
    ""raised_back_of_hand_medium_skin_tone"": ""🤚🏽"",
    ""raised_fist"": ""✊"",
    ""raised_fist_dark_skin_tone"": ""✊🏿"",
    ""raised_fist_light_skin_tone"": ""✊🏻"",
    ""raised_fist_medium-dark_skin_tone"": ""✊🏾"",
    ""raised_fist_medium-light_skin_tone"": ""✊🏼"",
    ""raised_fist_medium_skin_tone"": ""✊🏽"",
    ""raised_hand"": ""✋"",
    ""raised_hand_dark_skin_tone"": ""✋🏿"",
    ""raised_hand_light_skin_tone"": ""✋🏻"",
    ""raised_hand_medium-dark_skin_tone"": ""✋🏾"",
    ""raised_hand_medium-light_skin_tone"": ""✋🏼"",
    ""raised_hand_medium_skin_tone"": ""✋🏽"",
    ""raising_hands"": ""🙌"",
    ""raising_hands_dark_skin_tone"": ""🙌🏿"",
    ""raising_hands_light_skin_tone"": ""🙌🏻"",
    ""raising_hands_medium-dark_skin_tone"": ""🙌🏾"",
    ""raising_hands_medium-light_skin_tone"": ""🙌🏼"",
    ""raising_hands_medium_skin_tone"": ""🙌🏽"",
    ""ram"": ""🐏"",
    ""rat"": ""🐀"",
    ""razor"": ""🪒"",
    ""ringed_planet"": ""🪐"",
    ""receipt"": ""🧾"",
    ""record_button"": ""⏺"",
    ""recycling_symbol"": ""♻"",
    ""red_apple"": ""🍎"",
    ""red_circle"": ""🔴"",
    ""red_envelope"": ""🧧"",
    ""red_hair"": ""🦰"",
    ""red-haired_man"": ""👨\u200d🦰"",
    ""red-haired_woman"": ""👩\u200d🦰"",
    ""red_heart"": ""❤"",
    ""red_paper_lantern"": ""🏮"",
    ""red_square"": ""🟥"",
    ""red_triangle_pointed_down"": ""🔻"",
    ""red_triangle_pointed_up"": ""🔺"",
    ""registered"": ""®"",
    ""relieved_face"": ""😌"",
    ""reminder_ribbon"": ""🎗"",
    ""repeat_button"": ""🔁"",
    ""repeat_single_button"": ""🔂"",
    ""rescue_worker’s_helmet"": ""⛑"",
    ""restroom"": ""🚻"",
    ""reverse_button"": ""◀"",
    ""revolving_hearts"": ""💞"",
    ""rhinoceros"": ""🦏"",
    ""ribbon"": ""🎀"",
    ""rice_ball"": ""🍙"",
    ""rice_cracker"": ""🍘"",
    ""right-facing_fist"": ""🤜"",
    ""right-facing_fist_dark_skin_tone"": ""🤜🏿"",
    ""right-facing_fist_light_skin_tone"": ""🤜🏻"",
    ""right-facing_fist_medium-dark_skin_tone"": ""🤜🏾"",
    ""right-facing_fist_medium-light_skin_tone"": ""🤜🏼"",
    ""right-facing_fist_medium_skin_tone"": ""🤜🏽"",
    ""right_anger_bubble"": ""🗯"",
    ""right_arrow"": ""➡"",
    ""right_arrow_curving_down"": ""⤵"",
    ""right_arrow_curving_left"": ""↩"",
    ""right_arrow_curving_up"": ""⤴"",
    ""ring"": ""💍"",
    ""roasted_sweet_potato"": ""🍠"",
    ""robot_face"": ""🤖"",
    ""rocket"": ""🚀"",
    ""roll_of_paper"": ""🧻"",
    ""rolled-up_newspaper"": ""🗞"",
    ""roller_coaster"": ""🎢"",
    ""rolling_on_the_floor_laughing"": ""🤣"",
    ""rooster"": ""🐓"",
    ""rose"": ""🌹"",
    ""rosette"": ""🏵"",
    ""round_pushpin"": ""📍"",
    ""rugby_football"": ""🏉"",
    ""running_shirt"": ""🎽"",
    ""running_shoe"": ""👟"",
    ""sad_but_relieved_face"": ""😥"",
    ""safety_pin"": ""🧷"",
    ""safety_vest"": ""🦺"",
    ""salt"": ""🧂"",
    ""sailboat"": ""⛵"",
    ""sake"": ""🍶"",
    ""sandwich"": ""🥪"",
    ""sari"": ""🥻"",
    ""satellite"": ""📡"",
    ""satellite_antenna"": ""📡"",
    ""sauropod"": ""🦕"",
    ""saxophone"": ""🎷"",
    ""scarf"": ""🧣"",
    ""school"": ""🏫"",
    ""school_backpack"": ""🎒"",
    ""scissors"": ""✂"",
    ""scorpion"": ""🦂"",
    ""scroll"": ""📜"",
    ""seat"": ""💺"",
    ""see-no-evil_monkey"": ""🙈"",
    ""seedling"": ""🌱"",
    ""selfie"": ""🤳"",
    ""selfie_dark_skin_tone"": ""🤳🏿"",
    ""selfie_light_skin_tone"": ""🤳🏻"",
    ""selfie_medium-dark_skin_tone"": ""🤳🏾"",
    ""selfie_medium-light_skin_tone"": ""🤳🏼"",
    ""selfie_medium_skin_tone"": ""🤳🏽"",
    ""service_dog"": ""🐕\u200d🦺"",
    ""seven-thirty"": ""🕢"",
    ""seven_o’clock"": ""🕖"",
    ""shallow_pan_of_food"": ""🥘"",
    ""shamrock"": ""☘"",
    ""shark"": ""🦈"",
    ""shaved_ice"": ""🍧"",
    ""sheaf_of_rice"": ""🌾"",
    ""shield"": ""🛡"",
    ""shinto_shrine"": ""⛩"",
    ""ship"": ""🚢"",
    ""shooting_star"": ""🌠"",
    ""shopping_bags"": ""🛍"",
    ""shopping_cart"": ""🛒"",
    ""shortcake"": ""🍰"",
    ""shorts"": ""🩳"",
    ""shower"": ""🚿"",
    ""shrimp"": ""🦐"",
    ""shuffle_tracks_button"": ""🔀"",
    ""shushing_face"": ""🤫"",
    ""sign_of_the_horns"": ""🤘"",
    ""sign_of_the_horns_dark_skin_tone"": ""🤘🏿"",
    ""sign_of_the_horns_light_skin_tone"": ""🤘🏻"",
    ""sign_of_the_horns_medium-dark_skin_tone"": ""🤘🏾"",
    ""sign_of_the_horns_medium-light_skin_tone"": ""🤘🏼"",
    ""sign_of_the_horns_medium_skin_tone"": ""🤘🏽"",
    ""six-thirty"": ""🕡"",
    ""six_o’clock"": ""🕕"",
    ""skateboard"": ""🛹"",
    ""skier"": ""⛷"",
    ""skis"": ""🎿"",
    ""skull"": ""💀"",
    ""skull_and_crossbones"": ""☠"",
    ""skunk"": ""🦨"",
    ""sled"": ""🛷"",
    ""sleeping_face"": ""😴"",
    ""sleepy_face"": ""😪"",
    ""slightly_frowning_face"": ""🙁"",
    ""slightly_smiling_face"": ""🙂"",
    ""slot_machine"": ""🎰"",
    ""sloth"": ""🦥"",
    ""small_airplane"": ""🛩"",
    ""small_blue_diamond"": ""🔹"",
    ""small_orange_diamond"": ""🔸"",
    ""smiling_cat_face_with_heart-eyes"": ""😻"",
    ""smiling_face"": ""☺"",
    ""smiling_face_with_halo"": ""😇"",
    ""smiling_face_with_3_hearts"": ""🥰"",
    ""smiling_face_with_heart-eyes"": ""😍"",
    ""smiling_face_with_horns"": ""😈"",
    ""smiling_face_with_smiling_eyes"": ""😊"",
    ""smiling_face_with_sunglasses"": ""😎"",
    ""smirking_face"": ""😏"",
    ""snail"": ""🐌"",
    ""snake"": ""🐍"",
    ""sneezing_face"": ""🤧"",
    ""snow-capped_mountain"": ""🏔"",
    ""snowboarder"": ""🏂"",
    ""snowboarder_dark_skin_tone"": ""🏂🏿"",
    ""snowboarder_light_skin_tone"": ""🏂🏻"",
    ""snowboarder_medium-dark_skin_tone"": ""🏂🏾"",
    ""snowboarder_medium-light_skin_tone"": ""🏂🏼"",
    ""snowboarder_medium_skin_tone"": ""🏂🏽"",
    ""snowflake"": ""❄"",
    ""snowman"": ""☃"",
    ""snowman_without_snow"": ""⛄"",
    ""soap"": ""🧼"",
    ""soccer_ball"": ""⚽"",
    ""socks"": ""🧦"",
    ""softball"": ""🥎"",
    ""soft_ice_cream"": ""🍦"",
    ""spade_suit"": ""♠"",
    ""spaghetti"": ""🍝"",
    ""sparkle"": ""❇"",
    ""sparkler"": ""🎇"",
    ""sparkles"": ""✨"",
    ""sparkling_heart"": ""💖"",
    ""speak-no-evil_monkey"": ""🙊"",
    ""speaker_high_volume"": ""🔊"",
    ""speaker_low_volume"": ""🔈"",
    ""speaker_medium_volume"": ""🔉"",
    ""speaking_head"": ""🗣"",
    ""speech_balloon"": ""💬"",
    ""speedboat"": ""🚤"",
    ""spider"": ""🕷"",
    ""spider_web"": ""🕸"",
    ""spiral_calendar"": ""🗓"",
    ""spiral_notepad"": ""🗒"",
    ""spiral_shell"": ""🐚"",
    ""spoon"": ""🥄"",
    ""sponge"": ""🧽"",
    ""sport_utility_vehicle"": ""🚙"",
    ""sports_medal"": ""🏅"",
    ""spouting_whale"": ""🐳"",
    ""squid"": ""🦑"",
    ""squinting_face_with_tongue"": ""😝"",
    ""stadium"": ""🏟"",
    ""star-struck"": ""🤩"",
    ""star_and_crescent"": ""☪"",
    ""star_of_david"": ""✡"",
    ""station"": ""🚉"",
    ""steaming_bowl"": ""🍜"",
    ""stethoscope"": ""🩺"",
    ""stop_button"": ""⏹"",
    ""stop_sign"": ""🛑"",
    ""stopwatch"": ""⏱"",
    ""straight_ruler"": ""📏"",
    ""strawberry"": ""🍓"",
    ""studio_microphone"": ""🎙"",
    ""stuffed_flatbread"": ""🥙"",
    ""sun"": ""☀"",
    ""sun_behind_cloud"": ""⛅"",
    ""sun_behind_large_cloud"": ""🌥"",
    ""sun_behind_rain_cloud"": ""🌦"",
    ""sun_behind_small_cloud"": ""🌤"",
    ""sun_with_face"": ""🌞"",
    ""sunflower"": ""🌻"",
    ""sunglasses"": ""😎"",
    ""sunrise"": ""🌅"",
    ""sunrise_over_mountains"": ""🌄"",
    ""sunset"": ""🌇"",
    ""superhero"": ""🦸"",
    ""supervillain"": ""🦹"",
    ""sushi"": ""🍣"",
    ""suspension_railway"": ""🚟"",
    ""swan"": ""🦢"",
    ""sweat_droplets"": ""💦"",
    ""synagogue"": ""🕍"",
    ""syringe"": ""💉"",
    ""t-shirt"": ""👕"",
    ""taco"": ""🌮"",
    ""takeout_box"": ""🥡"",
    ""tanabata_tree"": ""🎋"",
    ""tangerine"": ""🍊"",
    ""taxi"": ""🚕"",
    ""teacup_without_handle"": ""🍵"",
    ""tear-off_calendar"": ""📆"",
    ""teddy_bear"": ""🧸"",
    ""telephone"": ""☎"",
    ""telephone_receiver"": ""📞"",
    ""telescope"": ""🔭"",
    ""television"": ""📺"",
    ""ten-thirty"": ""🕥"",
    ""ten_o’clock"": ""🕙"",
    ""tennis"": ""🎾"",
    ""tent"": ""⛺"",
    ""test_tube"": ""🧪"",
    ""thermometer"": ""🌡"",
    ""thinking_face"": ""🤔"",
    ""thought_balloon"": ""💭"",
    ""thread"": ""🧵"",
    ""three-thirty"": ""🕞"",
    ""three_o’clock"": ""🕒"",
    ""thumbs_down"": ""👎"",
    ""thumbs_down_dark_skin_tone"": ""👎🏿"",
    ""thumbs_down_light_skin_tone"": ""👎🏻"",
    ""thumbs_down_medium-dark_skin_tone"": ""👎🏾"",
    ""thumbs_down_medium-light_skin_tone"": ""👎🏼"",
    ""thumbs_down_medium_skin_tone"": ""👎🏽"",
    ""thumbs_up"": ""👍"",
    ""thumbs_up_dark_skin_tone"": ""👍🏿"",
    ""thumbs_up_light_skin_tone"": ""👍🏻"",
    ""thumbs_up_medium-dark_skin_tone"": ""👍🏾"",
    ""thumbs_up_medium-light_skin_tone"": ""👍🏼"",
    ""thumbs_up_medium_skin_tone"": ""👍🏽"",
    ""ticket"": ""🎫"",
    ""tiger"": ""🐯"",
    ""tiger_face"": ""🐯"",
    ""timer_clock"": ""⏲"",
    ""tired_face"": ""😫"",
    ""toolbox"": ""🧰"",
    ""toilet"": ""🚽"",
    ""tomato"": ""🍅"",
    ""tongue"": ""👅"",
    ""tooth"": ""🦷"",
    ""top_hat"": ""🎩"",
    ""tornado"": ""🌪"",
    ""trackball"": ""🖲"",
    ""tractor"": ""🚜"",
    ""trade_mark"": ""™"",
    ""train"": ""🚋"",
    ""tram"": ""🚊"",
    ""tram_car"": ""🚋"",
    ""triangular_flag"": ""🚩"",
    ""triangular_ruler"": ""📐"",
    ""trident_emblem"": ""🔱"",
    ""trolleybus"": ""🚎"",
    ""trophy"": ""🏆"",
    ""tropical_drink"": ""🍹"",
    ""tropical_fish"": ""🐠"",
    ""trumpet"": ""🎺"",
    ""tulip"": ""🌷"",
    ""tumbler_glass"": ""🥃"",
    ""turtle"": ""🐢"",
    ""twelve-thirty"": ""🕧"",
    ""twelve_o’clock"": ""🕛"",
    ""two-hump_camel"": ""🐫"",
    ""two-thirty"": ""🕝"",
    ""two_hearts"": ""💕"",
    ""two_men_holding_hands"": ""👬"",
    ""two_o’clock"": ""🕑"",
    ""two_women_holding_hands"": ""👭"",
    ""umbrella"": ""☂"",
    ""umbrella_on_ground"": ""⛱"",
    ""umbrella_with_rain_drops"": ""☔"",
    ""unamused_face"": ""😒"",
    ""unicorn_face"": ""🦄"",
    ""unlocked"": ""🔓"",
    ""up-down_arrow"": ""↕"",
    ""up-left_arrow"": ""↖"",
    ""up-right_arrow"": ""↗"",
    ""up_arrow"": ""⬆"",
    ""upside-down_face"": ""🙃"",
    ""upwards_button"": ""🔼"",
    ""vampire"": ""🧛"",
    ""vampire_dark_skin_tone"": ""🧛🏿"",
    ""vampire_light_skin_tone"": ""🧛🏻"",
    ""vampire_medium-dark_skin_tone"": ""🧛🏾"",
    ""vampire_medium-light_skin_tone"": ""🧛🏼"",
    ""vampire_medium_skin_tone"": ""🧛🏽"",
    ""vertical_traffic_light"": ""🚦"",
    ""vibration_mode"": ""📳"",
    ""victory_hand"": ""✌"",
    ""victory_hand_dark_skin_tone"": ""✌🏿"",
    ""victory_hand_light_skin_tone"": ""✌🏻"",
    ""victory_hand_medium-dark_skin_tone"": ""✌🏾"",
    ""victory_hand_medium-light_skin_tone"": ""✌🏼"",
    ""victory_hand_medium_skin_tone"": ""✌🏽"",
    ""video_camera"": ""📹"",
    ""video_game"": ""🎮"",
    ""videocassette"": ""📼"",
    ""violin"": ""🎻"",
    ""volcano"": ""🌋"",
    ""volleyball"": ""🏐"",
    ""vulcan_salute"": ""🖖"",
    ""vulcan_salute_dark_skin_tone"": ""🖖🏿"",
    ""vulcan_salute_light_skin_tone"": ""🖖🏻"",
    ""vulcan_salute_medium-dark_skin_tone"": ""🖖🏾"",
    ""vulcan_salute_medium-light_skin_tone"": ""🖖🏼"",
    ""vulcan_salute_medium_skin_tone"": ""🖖🏽"",
    ""waffle"": ""🧇"",
    ""waning_crescent_moon"": ""🌘"",
    ""waning_gibbous_moon"": ""🌖"",
    ""warning"": ""⚠"",
    ""wastebasket"": ""🗑"",
    ""watch"": ""⌚"",
    ""water_buffalo"": ""🐃"",
    ""water_closet"": ""🚾"",
    ""water_wave"": ""🌊"",
    ""watermelon"": ""🍉"",
    ""waving_hand"": ""👋"",
    ""waving_hand_dark_skin_tone"": ""👋🏿"",
    ""waving_hand_light_skin_tone"": ""👋🏻"",
    ""waving_hand_medium-dark_skin_tone"": ""👋🏾"",
    ""waving_hand_medium-light_skin_tone"": ""👋🏼"",
    ""waving_hand_medium_skin_tone"": ""👋🏽"",
    ""wavy_dash"": ""〰"",
    ""waxing_crescent_moon"": ""🌒"",
    ""waxing_gibbous_moon"": ""🌔"",
    ""weary_cat_face"": ""🙀"",
    ""weary_face"": ""😩"",
    ""wedding"": ""💒"",
    ""whale"": ""🐳"",
    ""wheel_of_dharma"": ""☸"",
    ""wheelchair_symbol"": ""♿"",
    ""white_circle"": ""⚪"",
    ""white_exclamation_mark"": ""❕"",
    ""white_flag"": ""🏳"",
    ""white_flower"": ""💮"",
    ""white_hair"": ""🦳"",
    ""white-haired_man"": ""👨\u200d🦳"",
    ""white-haired_woman"": ""👩\u200d🦳"",
    ""white_heart"": ""🤍"",
    ""white_heavy_check_mark"": ""✅"",
    ""white_large_square"": ""⬜"",
    ""white_medium-small_square"": ""◽"",
    ""white_medium_square"": ""◻"",
    ""white_medium_star"": ""⭐"",
    ""white_question_mark"": ""❔"",
    ""white_small_square"": ""▫"",
    ""white_square_button"": ""🔳"",
    ""wilted_flower"": ""🥀"",
    ""wind_chime"": ""🎐"",
    ""wind_face"": ""🌬"",
    ""wine_glass"": ""🍷"",
    ""winking_face"": ""😉"",
    ""winking_face_with_tongue"": ""😜"",
    ""wolf_face"": ""🐺"",
    ""woman"": ""👩"",
    ""woman_artist"": ""👩\u200d🎨"",
    ""woman_artist_dark_skin_tone"": ""👩🏿\u200d🎨"",
    ""woman_artist_light_skin_tone"": ""👩🏻\u200d🎨"",
    ""woman_artist_medium-dark_skin_tone"": ""👩🏾\u200d🎨"",
    ""woman_artist_medium-light_skin_tone"": ""👩🏼\u200d🎨"",
    ""woman_artist_medium_skin_tone"": ""👩🏽\u200d🎨"",
    ""woman_astronaut"": ""👩\u200d🚀"",
    ""woman_astronaut_dark_skin_tone"": ""👩🏿\u200d🚀"",
    ""woman_astronaut_light_skin_tone"": ""👩🏻\u200d🚀"",
    ""woman_astronaut_medium-dark_skin_tone"": ""👩🏾\u200d🚀"",
    ""woman_astronaut_medium-light_skin_tone"": ""👩🏼\u200d🚀"",
    ""woman_astronaut_medium_skin_tone"": ""👩🏽\u200d🚀"",
    ""woman_biking"": ""🚴\u200d♀️"",
    ""woman_biking_dark_skin_tone"": ""🚴🏿\u200d♀️"",
    ""woman_biking_light_skin_tone"": ""🚴🏻\u200d♀️"",
    ""woman_biking_medium-dark_skin_tone"": ""🚴🏾\u200d♀️"",
    ""woman_biking_medium-light_skin_tone"": ""🚴🏼\u200d♀️"",
    ""woman_biking_medium_skin_tone"": ""🚴🏽\u200d♀️"",
    ""woman_bouncing_ball"": ""⛹️\u200d♀️"",
    ""woman_bouncing_ball_dark_skin_tone"": ""⛹🏿\u200d♀️"",
    ""woman_bouncing_ball_light_skin_tone"": ""⛹🏻\u200d♀️"",
    ""woman_bouncing_ball_medium-dark_skin_tone"": ""⛹🏾\u200d♀️"",
    ""woman_bouncing_ball_medium-light_skin_tone"": ""⛹🏼\u200d♀️"",
    ""woman_bouncing_ball_medium_skin_tone"": ""⛹🏽\u200d♀️"",
    ""woman_bowing"": ""🙇\u200d♀️"",
    ""woman_bowing_dark_skin_tone"": ""🙇🏿\u200d♀️"",
    ""woman_bowing_light_skin_tone"": ""🙇🏻\u200d♀️"",
    ""woman_bowing_medium-dark_skin_tone"": ""🙇🏾\u200d♀️"",
    ""woman_bowing_medium-light_skin_tone"": ""🙇🏼\u200d♀️"",
    ""woman_bowing_medium_skin_tone"": ""🙇🏽\u200d♀️"",
    ""woman_cartwheeling"": ""🤸\u200d♀️"",
    ""woman_cartwheeling_dark_skin_tone"": ""🤸🏿\u200d♀️"",
    ""woman_cartwheeling_light_skin_tone"": ""🤸🏻\u200d♀️"",
    ""woman_cartwheeling_medium-dark_skin_tone"": ""🤸🏾\u200d♀️"",
    ""woman_cartwheeling_medium-light_skin_tone"": ""🤸🏼\u200d♀️"",
    ""woman_cartwheeling_medium_skin_tone"": ""🤸🏽\u200d♀️"",
    ""woman_climbing"": ""🧗\u200d♀️"",
    ""woman_climbing_dark_skin_tone"": ""🧗🏿\u200d♀️"",
    ""woman_climbing_light_skin_tone"": ""🧗🏻\u200d♀️"",
    ""woman_climbing_medium-dark_skin_tone"": ""🧗🏾\u200d♀️"",
    ""woman_climbing_medium-light_skin_tone"": ""🧗🏼\u200d♀️"",
    ""woman_climbing_medium_skin_tone"": ""🧗🏽\u200d♀️"",
    ""woman_construction_worker"": ""👷\u200d♀️"",
    ""woman_construction_worker_dark_skin_tone"": ""👷🏿\u200d♀️"",
    ""woman_construction_worker_light_skin_tone"": ""👷🏻\u200d♀️"",
    ""woman_construction_worker_medium-dark_skin_tone"": ""👷🏾\u200d♀️"",
    ""woman_construction_worker_medium-light_skin_tone"": ""👷🏼\u200d♀️"",
    ""woman_construction_worker_medium_skin_tone"": ""👷🏽\u200d♀️"",
    ""woman_cook"": ""👩\u200d🍳"",
    ""woman_cook_dark_skin_tone"": ""👩🏿\u200d🍳"",
    ""woman_cook_light_skin_tone"": ""👩🏻\u200d🍳"",
    ""woman_cook_medium-dark_skin_tone"": ""👩🏾\u200d🍳"",
    ""woman_cook_medium-light_skin_tone"": ""👩🏼\u200d🍳"",
    ""woman_cook_medium_skin_tone"": ""👩🏽\u200d🍳"",
    ""woman_dancing"": ""💃"",
    ""woman_dancing_dark_skin_tone"": ""💃🏿"",
    ""woman_dancing_light_skin_tone"": ""💃🏻"",
    ""woman_dancing_medium-dark_skin_tone"": ""💃🏾"",
    ""woman_dancing_medium-light_skin_tone"": ""💃🏼"",
    ""woman_dancing_medium_skin_tone"": ""💃🏽"",
    ""woman_dark_skin_tone"": ""👩🏿"",
    ""woman_detective"": ""🕵️\u200d♀️"",
    ""woman_detective_dark_skin_tone"": ""🕵🏿\u200d♀️"",
    ""woman_detective_light_skin_tone"": ""🕵🏻\u200d♀️"",
    ""woman_detective_medium-dark_skin_tone"": ""🕵🏾\u200d♀️"",
    ""woman_detective_medium-light_skin_tone"": ""🕵🏼\u200d♀️"",
    ""woman_detective_medium_skin_tone"": ""🕵🏽\u200d♀️"",
    ""woman_elf"": ""🧝\u200d♀️"",
    ""woman_elf_dark_skin_tone"": ""🧝🏿\u200d♀️"",
    ""woman_elf_light_skin_tone"": ""🧝🏻\u200d♀️"",
    ""woman_elf_medium-dark_skin_tone"": ""🧝🏾\u200d♀️"",
    ""woman_elf_medium-light_skin_tone"": ""🧝🏼\u200d♀️"",
    ""woman_elf_medium_skin_tone"": ""🧝🏽\u200d♀️"",
    ""woman_facepalming"": ""🤦\u200d♀️"",
    ""woman_facepalming_dark_skin_tone"": ""🤦🏿\u200d♀️"",
    ""woman_facepalming_light_skin_tone"": ""🤦🏻\u200d♀️"",
    ""woman_facepalming_medium-dark_skin_tone"": ""🤦🏾\u200d♀️"",
    ""woman_facepalming_medium-light_skin_tone"": ""🤦🏼\u200d♀️"",
    ""woman_facepalming_medium_skin_tone"": ""🤦🏽\u200d♀️"",
    ""woman_factory_worker"": ""👩\u200d🏭"",
    ""woman_factory_worker_dark_skin_tone"": ""👩🏿\u200d🏭"",
    ""woman_factory_worker_light_skin_tone"": ""👩🏻\u200d🏭"",
    ""woman_factory_worker_medium-dark_skin_tone"": ""👩🏾\u200d🏭"",
    ""woman_factory_worker_medium-light_skin_tone"": ""👩🏼\u200d🏭"",
    ""woman_factory_worker_medium_skin_tone"": ""👩🏽\u200d🏭"",
    ""woman_fairy"": ""🧚\u200d♀️"",
    ""woman_fairy_dark_skin_tone"": ""🧚🏿\u200d♀️"",
    ""woman_fairy_light_skin_tone"": ""🧚🏻\u200d♀️"",
    ""woman_fairy_medium-dark_skin_tone"": ""🧚🏾\u200d♀️"",
    ""woman_fairy_medium-light_skin_tone"": ""🧚🏼\u200d♀️"",
    ""woman_fairy_medium_skin_tone"": ""🧚🏽\u200d♀️"",
    ""woman_farmer"": ""👩\u200d🌾"",
    ""woman_farmer_dark_skin_tone"": ""👩🏿\u200d🌾"",
    ""woman_farmer_light_skin_tone"": ""👩🏻\u200d🌾"",
    ""woman_farmer_medium-dark_skin_tone"": ""👩🏾\u200d🌾"",
    ""woman_farmer_medium-light_skin_tone"": ""👩🏼\u200d🌾"",
    ""woman_farmer_medium_skin_tone"": ""👩🏽\u200d🌾"",
    ""woman_firefighter"": ""👩\u200d🚒"",
    ""woman_firefighter_dark_skin_tone"": ""👩🏿\u200d🚒"",
    ""woman_firefighter_light_skin_tone"": ""👩🏻\u200d🚒"",
    ""woman_firefighter_medium-dark_skin_tone"": ""👩🏾\u200d🚒"",
    ""woman_firefighter_medium-light_skin_tone"": ""👩🏼\u200d🚒"",
    ""woman_firefighter_medium_skin_tone"": ""👩🏽\u200d🚒"",
    ""woman_frowning"": ""🙍\u200d♀️"",
    ""woman_frowning_dark_skin_tone"": ""🙍🏿\u200d♀️"",
    ""woman_frowning_light_skin_tone"": ""🙍🏻\u200d♀️"",
    ""woman_frowning_medium-dark_skin_tone"": ""🙍🏾\u200d♀️"",
    ""woman_frowning_medium-light_skin_tone"": ""🙍🏼\u200d♀️"",
    ""woman_frowning_medium_skin_tone"": ""🙍🏽\u200d♀️"",
    ""woman_genie"": ""🧞\u200d♀️"",
    ""woman_gesturing_no"": ""🙅\u200d♀️"",
    ""woman_gesturing_no_dark_skin_tone"": ""🙅🏿\u200d♀️"",
    ""woman_gesturing_no_light_skin_tone"": ""🙅🏻\u200d♀️"",
    ""woman_gesturing_no_medium-dark_skin_tone"": ""🙅🏾\u200d♀️"",
    ""woman_gesturing_no_medium-light_skin_tone"": ""🙅🏼\u200d♀️"",
    ""woman_gesturing_no_medium_skin_tone"": ""🙅🏽\u200d♀️"",
    ""woman_gesturing_ok"": ""🙆\u200d♀️"",
    ""woman_gesturing_ok_dark_skin_tone"": ""🙆🏿\u200d♀️"",
    ""woman_gesturing_ok_light_skin_tone"": ""🙆🏻\u200d♀️"",
    ""woman_gesturing_ok_medium-dark_skin_tone"": ""🙆🏾\u200d♀️"",
    ""woman_gesturing_ok_medium-light_skin_tone"": ""🙆🏼\u200d♀️"",
    ""woman_gesturing_ok_medium_skin_tone"": ""🙆🏽\u200d♀️"",
    ""woman_getting_haircut"": ""💇\u200d♀️"",
    ""woman_getting_haircut_dark_skin_tone"": ""💇🏿\u200d♀️"",
    ""woman_getting_haircut_light_skin_tone"": ""💇🏻\u200d♀️"",
    ""woman_getting_haircut_medium-dark_skin_tone"": ""💇🏾\u200d♀️"",
    ""woman_getting_haircut_medium-light_skin_tone"": ""💇🏼\u200d♀️"",
    ""woman_getting_haircut_medium_skin_tone"": ""💇🏽\u200d♀️"",
    ""woman_getting_massage"": ""💆\u200d♀️"",
    ""woman_getting_massage_dark_skin_tone"": ""💆🏿\u200d♀️"",
    ""woman_getting_massage_light_skin_tone"": ""💆🏻\u200d♀️"",
    ""woman_getting_massage_medium-dark_skin_tone"": ""💆🏾\u200d♀️"",
    ""woman_getting_massage_medium-light_skin_tone"": ""💆🏼\u200d♀️"",
    ""woman_getting_massage_medium_skin_tone"": ""💆🏽\u200d♀️"",
    ""woman_golfing"": ""🏌️\u200d♀️"",
    ""woman_golfing_dark_skin_tone"": ""🏌🏿\u200d♀️"",
    ""woman_golfing_light_skin_tone"": ""🏌🏻\u200d♀️"",
    ""woman_golfing_medium-dark_skin_tone"": ""🏌🏾\u200d♀️"",
    ""woman_golfing_medium-light_skin_tone"": ""🏌🏼\u200d♀️"",
    ""woman_golfing_medium_skin_tone"": ""🏌🏽\u200d♀️"",
    ""woman_guard"": ""💂\u200d♀️"",
    ""woman_guard_dark_skin_tone"": ""💂🏿\u200d♀️"",
    ""woman_guard_light_skin_tone"": ""💂🏻\u200d♀️"",
    ""woman_guard_medium-dark_skin_tone"": ""💂🏾\u200d♀️"",
    ""woman_guard_medium-light_skin_tone"": ""💂🏼\u200d♀️"",
    ""woman_guard_medium_skin_tone"": ""💂🏽\u200d♀️"",
    ""woman_health_worker"": ""👩\u200d⚕️"",
    ""woman_health_worker_dark_skin_tone"": ""👩🏿\u200d⚕️"",
    ""woman_health_worker_light_skin_tone"": ""👩🏻\u200d⚕️"",
    ""woman_health_worker_medium-dark_skin_tone"": ""👩🏾\u200d⚕️"",
    ""woman_health_worker_medium-light_skin_tone"": ""👩🏼\u200d⚕️"",
    ""woman_health_worker_medium_skin_tone"": ""👩🏽\u200d⚕️"",
    ""woman_in_lotus_position"": ""🧘\u200d♀️"",
    ""woman_in_lotus_position_dark_skin_tone"": ""🧘🏿\u200d♀️"",
    ""woman_in_lotus_position_light_skin_tone"": ""🧘🏻\u200d♀️"",
    ""woman_in_lotus_position_medium-dark_skin_tone"": ""🧘🏾\u200d♀️"",
    ""woman_in_lotus_position_medium-light_skin_tone"": ""🧘🏼\u200d♀️"",
    ""woman_in_lotus_position_medium_skin_tone"": ""🧘🏽\u200d♀️"",
    ""woman_in_manual_wheelchair"": ""👩\u200d🦽"",
    ""woman_in_motorized_wheelchair"": ""👩\u200d🦼"",
    ""woman_in_steamy_room"": ""🧖\u200d♀️"",
    ""woman_in_steamy_room_dark_skin_tone"": ""🧖🏿\u200d♀️"",
    ""woman_in_steamy_room_light_skin_tone"": ""🧖🏻\u200d♀️"",
    ""woman_in_steamy_room_medium-dark_skin_tone"": ""🧖🏾\u200d♀️"",
    ""woman_in_steamy_room_medium-light_skin_tone"": ""🧖🏼\u200d♀️"",
    ""woman_in_steamy_room_medium_skin_tone"": ""🧖🏽\u200d♀️"",
    ""woman_judge"": ""👩\u200d⚖️"",
    ""woman_judge_dark_skin_tone"": ""👩🏿\u200d⚖️"",
    ""woman_judge_light_skin_tone"": ""👩🏻\u200d⚖️"",
    ""woman_judge_medium-dark_skin_tone"": ""👩🏾\u200d⚖️"",
    ""woman_judge_medium-light_skin_tone"": ""👩🏼\u200d⚖️"",
    ""woman_judge_medium_skin_tone"": ""👩🏽\u200d⚖️"",
    ""woman_juggling"": ""🤹\u200d♀️"",
    ""woman_juggling_dark_skin_tone"": ""🤹🏿\u200d♀️"",
    ""woman_juggling_light_skin_tone"": ""🤹🏻\u200d♀️"",
    ""woman_juggling_medium-dark_skin_tone"": ""🤹🏾\u200d♀️"",
    ""woman_juggling_medium-light_skin_tone"": ""🤹🏼\u200d♀️"",
    ""woman_juggling_medium_skin_tone"": ""🤹🏽\u200d♀️"",
    ""woman_lifting_weights"": ""🏋️\u200d♀️"",
    ""woman_lifting_weights_dark_skin_tone"": ""🏋🏿\u200d♀️"",
    ""woman_lifting_weights_light_skin_tone"": ""🏋🏻\u200d♀️"",
    ""woman_lifting_weights_medium-dark_skin_tone"": ""🏋🏾\u200d♀️"",
    ""woman_lifting_weights_medium-light_skin_tone"": ""🏋🏼\u200d♀️"",
    ""woman_lifting_weights_medium_skin_tone"": ""🏋🏽\u200d♀️"",
    ""woman_light_skin_tone"": ""👩🏻"",
    ""woman_mage"": ""🧙\u200d♀️"",
    ""woman_mage_dark_skin_tone"": ""🧙🏿\u200d♀️"",
    ""woman_mage_light_skin_tone"": ""🧙🏻\u200d♀️"",
    ""woman_mage_medium-dark_skin_tone"": ""🧙🏾\u200d♀️"",
    ""woman_mage_medium-light_skin_tone"": ""🧙🏼\u200d♀️"",
    ""woman_mage_medium_skin_tone"": ""🧙🏽\u200d♀️"",
    ""woman_mechanic"": ""👩\u200d🔧"",
    ""woman_mechanic_dark_skin_tone"": ""👩🏿\u200d🔧"",
    ""woman_mechanic_light_skin_tone"": ""👩🏻\u200d🔧"",
    ""woman_mechanic_medium-dark_skin_tone"": ""👩🏾\u200d🔧"",
    ""woman_mechanic_medium-light_skin_tone"": ""👩🏼\u200d🔧"",
    ""woman_mechanic_medium_skin_tone"": ""👩🏽\u200d🔧"",
    ""woman_medium-dark_skin_tone"": ""👩🏾"",
    ""woman_medium-light_skin_tone"": ""👩🏼"",
    ""woman_medium_skin_tone"": ""👩🏽"",
    ""woman_mountain_biking"": ""🚵\u200d♀️"",
    ""woman_mountain_biking_dark_skin_tone"": ""🚵🏿\u200d♀️"",
    ""woman_mountain_biking_light_skin_tone"": ""🚵🏻\u200d♀️"",
    ""woman_mountain_biking_medium-dark_skin_tone"": ""🚵🏾\u200d♀️"",
    ""woman_mountain_biking_medium-light_skin_tone"": ""🚵🏼\u200d♀️"",
    ""woman_mountain_biking_medium_skin_tone"": ""🚵🏽\u200d♀️"",
    ""woman_office_worker"": ""👩\u200d💼"",
    ""woman_office_worker_dark_skin_tone"": ""👩🏿\u200d💼"",
    ""woman_office_worker_light_skin_tone"": ""👩🏻\u200d💼"",
    ""woman_office_worker_medium-dark_skin_tone"": ""👩🏾\u200d💼"",
    ""woman_office_worker_medium-light_skin_tone"": ""👩🏼\u200d💼"",
    ""woman_office_worker_medium_skin_tone"": ""👩🏽\u200d💼"",
    ""woman_pilot"": ""👩\u200d✈️"",
    ""woman_pilot_dark_skin_tone"": ""👩🏿\u200d✈️"",
    ""woman_pilot_light_skin_tone"": ""👩🏻\u200d✈️"",
    ""woman_pilot_medium-dark_skin_tone"": ""👩🏾\u200d✈️"",
    ""woman_pilot_medium-light_skin_tone"": ""👩🏼\u200d✈️"",
    ""woman_pilot_medium_skin_tone"": ""👩🏽\u200d✈️"",
    ""woman_playing_handball"": ""🤾\u200d♀️"",
    ""woman_playing_handball_dark_skin_tone"": ""🤾🏿\u200d♀️"",
    ""woman_playing_handball_light_skin_tone"": ""🤾🏻\u200d♀️"",
    ""woman_playing_handball_medium-dark_skin_tone"": ""🤾🏾\u200d♀️"",
    ""woman_playing_handball_medium-light_skin_tone"": ""🤾🏼\u200d♀️"",
    ""woman_playing_handball_medium_skin_tone"": ""🤾🏽\u200d♀️"",
    ""woman_playing_water_polo"": ""🤽\u200d♀️"",
    ""woman_playing_water_polo_dark_skin_tone"": ""🤽🏿\u200d♀️"",
    ""woman_playing_water_polo_light_skin_tone"": ""🤽🏻\u200d♀️"",
    ""woman_playing_water_polo_medium-dark_skin_tone"": ""🤽🏾\u200d♀️"",
    ""woman_playing_water_polo_medium-light_skin_tone"": ""🤽🏼\u200d♀️"",
    ""woman_playing_water_polo_medium_skin_tone"": ""🤽🏽\u200d♀️"",
    ""woman_police_officer"": ""👮\u200d♀️"",
    ""woman_police_officer_dark_skin_tone"": ""👮🏿\u200d♀️"",
    ""woman_police_officer_light_skin_tone"": ""👮🏻\u200d♀️"",
    ""woman_police_officer_medium-dark_skin_tone"": ""👮🏾\u200d♀️"",
    ""woman_police_officer_medium-light_skin_tone"": ""👮🏼\u200d♀️"",
    ""woman_police_officer_medium_skin_tone"": ""👮🏽\u200d♀️"",
    ""woman_pouting"": ""🙎\u200d♀️"",
    ""woman_pouting_dark_skin_tone"": ""🙎🏿\u200d♀️"",
    ""woman_pouting_light_skin_tone"": ""🙎🏻\u200d♀️"",
    ""woman_pouting_medium-dark_skin_tone"": ""🙎🏾\u200d♀️"",
    ""woman_pouting_medium-light_skin_tone"": ""🙎🏼\u200d♀️"",
    ""woman_pouting_medium_skin_tone"": ""🙎🏽\u200d♀️"",
    ""woman_raising_hand"": ""🙋\u200d♀️"",
    ""woman_raising_hand_dark_skin_tone"": ""🙋🏿\u200d♀️"",
    ""woman_raising_hand_light_skin_tone"": ""🙋🏻\u200d♀️"",
    ""woman_raising_hand_medium-dark_skin_tone"": ""🙋🏾\u200d♀️"",
    ""woman_raising_hand_medium-light_skin_tone"": ""🙋🏼\u200d♀️"",
    ""woman_raising_hand_medium_skin_tone"": ""🙋🏽\u200d♀️"",
    ""woman_rowing_boat"": ""🚣\u200d♀️"",
    ""woman_rowing_boat_dark_skin_tone"": ""🚣🏿\u200d♀️"",
    ""woman_rowing_boat_light_skin_tone"": ""🚣🏻\u200d♀️"",
    ""woman_rowing_boat_medium-dark_skin_tone"": ""🚣🏾\u200d♀️"",
    ""woman_rowing_boat_medium-light_skin_tone"": ""🚣🏼\u200d♀️"",
    ""woman_rowing_boat_medium_skin_tone"": ""🚣🏽\u200d♀️"",
    ""woman_running"": ""🏃\u200d♀️"",
    ""woman_running_dark_skin_tone"": ""🏃🏿\u200d♀️"",
    ""woman_running_light_skin_tone"": ""🏃🏻\u200d♀️"",
    ""woman_running_medium-dark_skin_tone"": ""🏃🏾\u200d♀️"",
    ""woman_running_medium-light_skin_tone"": ""🏃🏼\u200d♀️"",
    ""woman_running_medium_skin_tone"": ""🏃🏽\u200d♀️"",
    ""woman_scientist"": ""👩\u200d🔬"",
    ""woman_scientist_dark_skin_tone"": ""👩🏿\u200d🔬"",
    ""woman_scientist_light_skin_tone"": ""👩🏻\u200d🔬"",
    ""woman_scientist_medium-dark_skin_tone"": ""👩🏾\u200d🔬"",
    ""woman_scientist_medium-light_skin_tone"": ""👩🏼\u200d🔬"",
    ""woman_scientist_medium_skin_tone"": ""👩🏽\u200d🔬"",
    ""woman_shrugging"": ""🤷\u200d♀️"",
    ""woman_shrugging_dark_skin_tone"": ""🤷🏿\u200d♀️"",
    ""woman_shrugging_light_skin_tone"": ""🤷🏻\u200d♀️"",
    ""woman_shrugging_medium-dark_skin_tone"": ""🤷🏾\u200d♀️"",
    ""woman_shrugging_medium-light_skin_tone"": ""🤷🏼\u200d♀️"",
    ""woman_shrugging_medium_skin_tone"": ""🤷🏽\u200d♀️"",
    ""woman_singer"": ""👩\u200d🎤"",
    ""woman_singer_dark_skin_tone"": ""👩🏿\u200d🎤"",
    ""woman_singer_light_skin_tone"": ""👩🏻\u200d🎤"",
    ""woman_singer_medium-dark_skin_tone"": ""👩🏾\u200d🎤"",
    ""woman_singer_medium-light_skin_tone"": ""👩🏼\u200d🎤"",
    ""woman_singer_medium_skin_tone"": ""👩🏽\u200d🎤"",
    ""woman_student"": ""👩\u200d🎓"",
    ""woman_student_dark_skin_tone"": ""👩🏿\u200d🎓"",
    ""woman_student_light_skin_tone"": ""👩🏻\u200d🎓"",
    ""woman_student_medium-dark_skin_tone"": ""👩🏾\u200d🎓"",
    ""woman_student_medium-light_skin_tone"": ""👩🏼\u200d🎓"",
    ""woman_student_medium_skin_tone"": ""👩🏽\u200d🎓"",
    ""woman_surfing"": ""🏄\u200d♀️"",
    ""woman_surfing_dark_skin_tone"": ""🏄🏿\u200d♀️"",
    ""woman_surfing_light_skin_tone"": ""🏄🏻\u200d♀️"",
    ""woman_surfing_medium-dark_skin_tone"": ""🏄🏾\u200d♀️"",
    ""woman_surfing_medium-light_skin_tone"": ""🏄🏼\u200d♀️"",
    ""woman_surfing_medium_skin_tone"": ""🏄🏽\u200d♀️"",
    ""woman_swimming"": ""🏊\u200d♀️"",
    ""woman_swimming_dark_skin_tone"": ""🏊🏿\u200d♀️"",
    ""woman_swimming_light_skin_tone"": ""🏊🏻\u200d♀️"",
    ""woman_swimming_medium-dark_skin_tone"": ""🏊🏾\u200d♀️"",
    ""woman_swimming_medium-light_skin_tone"": ""🏊🏼\u200d♀️"",
    ""woman_swimming_medium_skin_tone"": ""🏊🏽\u200d♀️"",
    ""woman_teacher"": ""👩\u200d🏫"",
    ""woman_teacher_dark_skin_tone"": ""👩🏿\u200d🏫"",
    ""woman_teacher_light_skin_tone"": ""👩🏻\u200d🏫"",
    ""woman_teacher_medium-dark_skin_tone"": ""👩🏾\u200d🏫"",
    ""woman_teacher_medium-light_skin_tone"": ""👩🏼\u200d🏫"",
    ""woman_teacher_medium_skin_tone"": ""👩🏽\u200d🏫"",
    ""woman_technologist"": ""👩\u200d💻"",
    ""woman_technologist_dark_skin_tone"": ""👩🏿\u200d💻"",
    ""woman_technologist_light_skin_tone"": ""👩🏻\u200d💻"",
    ""woman_technologist_medium-dark_skin_tone"": ""👩🏾\u200d💻"",
    ""woman_technologist_medium-light_skin_tone"": ""👩🏼\u200d💻"",
    ""woman_technologist_medium_skin_tone"": ""👩🏽\u200d💻"",
    ""woman_tipping_hand"": ""💁\u200d♀️"",
    ""woman_tipping_hand_dark_skin_tone"": ""💁🏿\u200d♀️"",
    ""woman_tipping_hand_light_skin_tone"": ""💁🏻\u200d♀️"",
    ""woman_tipping_hand_medium-dark_skin_tone"": ""💁🏾\u200d♀️"",
    ""woman_tipping_hand_medium-light_skin_tone"": ""💁🏼\u200d♀️"",
    ""woman_tipping_hand_medium_skin_tone"": ""💁🏽\u200d♀️"",
    ""woman_vampire"": ""🧛\u200d♀️"",
    ""woman_vampire_dark_skin_tone"": ""🧛🏿\u200d♀️"",
    ""woman_vampire_light_skin_tone"": ""🧛🏻\u200d♀️"",
    ""woman_vampire_medium-dark_skin_tone"": ""🧛🏾\u200d♀️"",
    ""woman_vampire_medium-light_skin_tone"": ""🧛🏼\u200d♀️"",
    ""woman_vampire_medium_skin_tone"": ""🧛🏽\u200d♀️"",
    ""woman_walking"": ""🚶\u200d♀️"",
    ""woman_walking_dark_skin_tone"": ""🚶🏿\u200d♀️"",
    ""woman_walking_light_skin_tone"": ""🚶🏻\u200d♀️"",
    ""woman_walking_medium-dark_skin_tone"": ""🚶🏾\u200d♀️"",
    ""woman_walking_medium-light_skin_tone"": ""🚶🏼\u200d♀️"",
    ""woman_walking_medium_skin_tone"": ""🚶🏽\u200d♀️"",
    ""woman_wearing_turban"": ""👳\u200d♀️"",
    ""woman_wearing_turban_dark_skin_tone"": ""👳🏿\u200d♀️"",
    ""woman_wearing_turban_light_skin_tone"": ""👳🏻\u200d♀️"",
    ""woman_wearing_turban_medium-dark_skin_tone"": ""👳🏾\u200d♀️"",
    ""woman_wearing_turban_medium-light_skin_tone"": ""👳🏼\u200d♀️"",
    ""woman_wearing_turban_medium_skin_tone"": ""👳🏽\u200d♀️"",
    ""woman_with_headscarf"": ""🧕"",
    ""woman_with_headscarf_dark_skin_tone"": ""🧕🏿"",
    ""woman_with_headscarf_light_skin_tone"": ""🧕🏻"",
    ""woman_with_headscarf_medium-dark_skin_tone"": ""🧕🏾"",
    ""woman_with_headscarf_medium-light_skin_tone"": ""🧕🏼"",
    ""woman_with_headscarf_medium_skin_tone"": ""🧕🏽"",
    ""woman_with_probing_cane"": ""👩\u200d🦯"",
    ""woman_zombie"": ""🧟\u200d♀️"",
    ""woman’s_boot"": ""👢"",
    ""woman’s_clothes"": ""👚"",
    ""woman’s_hat"": ""👒"",
    ""woman’s_sandal"": ""👡"",
    ""women_with_bunny_ears"": ""👯\u200d♀️"",
    ""women_wrestling"": ""🤼\u200d♀️"",
    ""women’s_room"": ""🚺"",
    ""woozy_face"": ""🥴"",
    ""world_map"": ""🗺"",
    ""worried_face"": ""😟"",
    ""wrapped_gift"": ""🎁"",
    ""wrench"": ""🔧"",
    ""writing_hand"": ""✍"",
    ""writing_hand_dark_skin_tone"": ""✍🏿"",
    ""writing_hand_light_skin_tone"": ""✍🏻"",
    ""writing_hand_medium-dark_skin_tone"": ""✍🏾"",
    ""writing_hand_medium-light_skin_tone"": ""✍🏼"",
    ""writing_hand_medium_skin_tone"": ""✍🏽"",
    ""yarn"": ""🧶"",
    ""yawning_face"": ""🥱"",
    ""yellow_circle"": ""🟡"",
    ""yellow_heart"": ""💛"",
    ""yellow_square"": ""🟨"",
    ""yen_banknote"": ""💴"",
    ""yo-yo"": ""🪀"",
    ""yin_yang"": ""☯"",
    ""zany_face"": ""🤪"",
    ""zebra"": ""🦓"",
    ""zipper-mouth_face"": ""🤐"",
    ""zombie"": ""🧟"",
    ""zzz"": ""💤"",
    ""åland_islands"": ""🇦🇽"",
    ""keycap_asterisk"": ""*⃣"",
    ""keycap_digit_eight"": ""8⃣"",
    ""keycap_digit_five"": ""5⃣"",
    ""keycap_digit_four"": ""4⃣"",
    ""keycap_digit_nine"": ""9⃣"",
    ""keycap_digit_one"": ""1⃣"",
    ""keycap_digit_seven"": ""7⃣"",
    ""keycap_digit_six"": ""6⃣"",
    ""keycap_digit_three"": ""3⃣"",
    ""keycap_digit_two"": ""2⃣"",
    ""keycap_digit_zero"": ""0⃣"",
    ""keycap_number_sign"": ""
    ""light_skin_tone"": ""🏻"",
    ""medium_light_skin_tone"": ""🏼"",
    ""medium_skin_tone"": ""🏽"",
    ""medium_dark_skin_tone"": ""🏾"",
    ""dark_skin_tone"": ""🏿"",
    ""regional_indicator_symbol_letter_a"": ""🇦"",
    ""regional_indicator_symbol_letter_b"": ""🇧"",
    ""regional_indicator_symbol_letter_c"": ""🇨"",
    ""regional_indicator_symbol_letter_d"": ""🇩"",
    ""regional_indicator_symbol_letter_e"": ""🇪"",
    ""regional_indicator_symbol_letter_f"": ""🇫"",
    ""regional_indicator_symbol_letter_g"": ""🇬"",
    ""regional_indicator_symbol_letter_h"": ""🇭"",
    ""regional_indicator_symbol_letter_i"": ""🇮"",
    ""regional_indicator_symbol_letter_j"": ""🇯"",
    ""regional_indicator_symbol_letter_k"": ""🇰"",
    ""regional_indicator_symbol_letter_l"": ""🇱"",
    ""regional_indicator_symbol_letter_m"": ""🇲"",
    ""regional_indicator_symbol_letter_n"": ""🇳"",
    ""regional_indicator_symbol_letter_o"": ""🇴"",
    ""regional_indicator_symbol_letter_p"": ""🇵"",
    ""regional_indicator_symbol_letter_q"": ""🇶"",
    ""regional_indicator_symbol_letter_r"": ""🇷"",
    ""regional_indicator_symbol_letter_s"": ""🇸"",
    ""regional_indicator_symbol_letter_t"": ""🇹"",
    ""regional_indicator_symbol_letter_u"": ""🇺"",
    ""regional_indicator_symbol_letter_v"": ""🇻"",
    ""regional_indicator_symbol_letter_w"": ""🇼"",
    ""regional_indicator_symbol_letter_x"": ""🇽"",
    ""regional_indicator_symbol_letter_y"": ""🇾"",
    ""regional_indicator_symbol_letter_z"": ""🇿"",
    ""airplane_arriving"": ""🛬"",
    ""space_invader"": ""👾"",
    ""football"": ""🏈"",
    ""anger"": ""💢"",
    ""angry"": ""😠"",
    ""anguished"": ""😧"",
    ""signal_strength"": ""📶"",
    ""arrows_counterclockwise"": ""🔄"",
    ""arrow_heading_down"": ""⤵"",
    ""arrow_heading_up"": ""⤴"",
    ""art"": ""🎨"",
    ""astonished"": ""😲"",
    ""athletic_shoe"": ""👟"",
    ""atm"": ""🏧"",
    ""car"": ""🚗"",
    ""red_car"": ""🚗"",
    ""angel"": ""👼"",
    ""back"": ""🔙"",
    ""badminton_racquet_and_shuttlecock"": ""🏸"",
    ""dollar"": ""💵"",
    ""euro"": ""💶"",
    ""pound"": ""💷"",
    ""yen"": ""💴"",
    ""barber"": ""💈"",
    ""bath"": ""🛀"",
    ""bear"": ""🐻"",
    ""heartbeat"": ""💓"",
    ""beer"": ""🍺"",
    ""no_bell"": ""🔕"",
    ""bento"": ""🍱"",
    ""bike"": ""🚲"",
    ""bicyclist"": ""🚴"",
    ""8ball"": ""🎱"",
    ""biohazard_sign"": ""☣"",
    ""birthday"": ""🎂"",
    ""black_circle_for_record"": ""⏺"",
    ""clubs"": ""♣"",
    ""diamonds"": ""♦"",
    ""arrow_double_down"": ""⏬"",
    ""hearts"": ""♥"",
    ""rewind"": ""⏪"",
    ""black_left__pointing_double_triangle_with_vertical_bar"": ""⏮"",
    ""arrow_backward"": ""◀"",
    ""black_medium_small_square"": ""◾"",
    ""question"": ""❓"",
    ""fast_forward"": ""⏩"",
    ""black_right__pointing_double_triangle_with_vertical_bar"": ""⏭"",
    ""arrow_forward"": ""▶"",
    ""black_right__pointing_triangle_with_double_vertical_bar"": ""⏯"",
    ""arrow_right"": ""➡"",
    ""spades"": ""♠"",
    ""black_square_for_stop"": ""⏹"",
    ""sunny"": ""☀"",
    ""phone"": ""☎"",
    ""recycle"": ""♻"",
    ""arrow_double_up"": ""⏫"",
    ""busstop"": ""🚏"",
    ""date"": ""📅"",
    ""flags"": ""🎏"",
    ""cat2"": ""🐈"",
    ""joy_cat"": ""😹"",
    ""smirk_cat"": ""😼"",
    ""chart_with_downwards_trend"": ""📉"",
    ""chart_with_upwards_trend"": ""📈"",
    ""chart"": ""💹"",
    ""mega"": ""📣"",
    ""checkered_flag"": ""🏁"",
    ""accept"": ""🉑"",
    ""ideograph_advantage"": ""🉐"",
    ""congratulations"": ""㊗"",
    ""secret"": ""㊙"",
    ""m"": ""Ⓜ"",
    ""city_sunset"": ""🌆"",
    ""clapper"": ""🎬"",
    ""clap"": ""👏"",
    ""beers"": ""🍻"",
    ""clock830"": ""🕣"",
    ""clock8"": ""🕗"",
    ""clock1130"": ""🕦"",
    ""clock11"": ""🕚"",
    ""clock530"": ""🕠"",
    ""clock5"": ""🕔"",
    ""clock430"": ""🕟"",
    ""clock4"": ""🕓"",
    ""clock930"": ""🕤"",
    ""clock9"": ""🕘"",
    ""clock130"": ""🕜"",
    ""clock1"": ""🕐"",
    ""clock730"": ""🕢"",
    ""clock7"": ""🕖"",
    ""clock630"": ""🕡"",
    ""clock6"": ""🕕"",
    ""clock1030"": ""🕥"",
    ""clock10"": ""🕙"",
    ""clock330"": ""🕞"",
    ""clock3"": ""🕒"",
    ""clock1230"": ""🕧"",
    ""clock12"": ""🕛"",
    ""clock230"": ""🕝"",
    ""clock2"": ""🕑"",
    ""arrows_clockwise"": ""🔃"",
    ""repeat"": ""🔁"",
    ""repeat_one"": ""🔂"",
    ""closed_lock_with_key"": ""🔐"",
    ""mailbox_closed"": ""📪"",
    ""mailbox"": ""📫"",
    ""cloud_with_tornado"": ""🌪"",
    ""cocktail"": ""🍸"",
    ""boom"": ""💥"",
    ""compression"": ""🗜"",
    ""confounded"": ""😖"",
    ""confused"": ""😕"",
    ""rice"": ""🍚"",
    ""cow2"": ""🐄"",
    ""cricket_bat_and_ball"": ""🏏"",
    ""x"": ""❌"",
    ""cry"": ""😢"",
    ""curry"": ""🍛"",
    ""dagger_knife"": ""🗡"",
    ""dancer"": ""💃"",
    ""dark_sunglasses"": ""🕶"",
    ""dash"": ""💨"",
    ""truck"": ""🚚"",
    ""derelict_house_building"": ""🏚"",
    ""diamond_shape_with_a_dot_inside"": ""💠"",
    ""dart"": ""🎯"",
    ""disappointed_relieved"": ""😥"",
    ""disappointed"": ""😞"",
    ""do_not_litter"": ""🚯"",
    ""dog2"": ""🐕"",
    ""flipper"": ""🐬"",
    ""loop"": ""➿"",
    ""bangbang"": ""‼"",
    ""double_vertical_bar"": ""⏸"",
    ""dove_of_peace"": ""🕊"",
    ""small_red_triangle_down"": ""🔻"",
    ""arrow_down_small"": ""🔽"",
    ""arrow_down"": ""⬇"",
    ""dromedary_camel"": ""🐪"",
    ""e__mail"": ""📧"",
    ""corn"": ""🌽"",
    ""ear_of_rice"": ""🌾"",
    ""earth_americas"": ""🌎"",
    ""earth_asia"": ""🌏"",
    ""earth_africa"": ""🌍"",
    ""eight_pointed_black_star"": ""✴"",
    ""eight_spoked_asterisk"": ""✳"",
    ""eject_symbol"": ""⏏"",
    ""bulb"": ""💡"",
    ""emoji_modifier_fitzpatrick_type__1__2"": ""🏻"",
    ""emoji_modifier_fitzpatrick_type__3"": ""🏼"",
    ""emoji_modifier_fitzpatrick_type__4"": ""🏽"",
    ""emoji_modifier_fitzpatrick_type__5"": ""🏾"",
    ""emoji_modifier_fitzpatrick_type__6"": ""🏿"",
    ""end"": ""🔚"",
    ""email"": ""✉"",
    ""european_castle"": ""🏰"",
    ""european_post_office"": ""🏤"",
    ""interrobang"": ""⁉"",
    ""expressionless"": ""😑"",
    ""eyeglasses"": ""👓"",
    ""massage"": ""💆"",
    ""yum"": ""😋"",
    ""scream"": ""😱"",
    ""kissing_heart"": ""😘"",
    ""sweat"": ""😓"",
    ""face_with_head__bandage"": ""🤕"",
    ""triumph"": ""😤"",
    ""mask"": ""😷"",
    ""no_good"": ""🙅"",
    ""ok_woman"": ""🙆"",
    ""open_mouth"": ""😮"",
    ""cold_sweat"": ""😰"",
    ""stuck_out_tongue"": ""😛"",
    ""stuck_out_tongue_closed_eyes"": ""😝"",
    ""stuck_out_tongue_winking_eye"": ""😜"",
    ""joy"": ""😂"",
    ""no_mouth"": ""😶"",
    ""santa"": ""🎅"",
    ""fax"": ""📠"",
    ""fearful"": ""😨"",
    ""field_hockey_stick_and_ball"": ""🏑"",
    ""first_quarter_moon_with_face"": ""🌛"",
    ""fish_cake"": ""🍥"",
    ""fishing_pole_and_fish"": ""🎣"",
    ""facepunch"": ""👊"",
    ""punch"": ""👊"",
    ""flag_for_afghanistan"": ""🇦🇫"",
    ""flag_for_albania"": ""🇦🇱"",
    ""flag_for_algeria"": ""🇩🇿"",
    ""flag_for_american_samoa"": ""🇦🇸"",
    ""flag_for_andorra"": ""🇦🇩"",
    ""flag_for_angola"": ""🇦🇴"",
    ""flag_for_anguilla"": ""🇦🇮"",
    ""flag_for_antarctica"": ""🇦🇶"",
    ""flag_for_antigua_&_barbuda"": ""🇦🇬"",
    ""flag_for_argentina"": ""🇦🇷"",
    ""flag_for_armenia"": ""🇦🇲"",
    ""flag_for_aruba"": ""🇦🇼"",
    ""flag_for_ascension_island"": ""🇦🇨"",
    ""flag_for_australia"": ""🇦🇺"",
    ""flag_for_austria"": ""🇦🇹"",
    ""flag_for_azerbaijan"": ""🇦🇿"",
    ""flag_for_bahamas"": ""🇧🇸"",
    ""flag_for_bahrain"": ""🇧🇭"",
    ""flag_for_bangladesh"": ""🇧🇩"",
    ""flag_for_barbados"": ""🇧🇧"",
    ""flag_for_belarus"": ""🇧🇾"",
    ""flag_for_belgium"": ""🇧🇪"",
    ""flag_for_belize"": ""🇧🇿"",
    ""flag_for_benin"": ""🇧🇯"",
    ""flag_for_bermuda"": ""🇧🇲"",
    ""flag_for_bhutan"": ""🇧🇹"",
    ""flag_for_bolivia"": ""🇧🇴"",
    ""flag_for_bosnia_&_herzegovina"": ""🇧🇦"",
    ""flag_for_botswana"": ""🇧🇼"",
    ""flag_for_bouvet_island"": ""🇧🇻"",
    ""flag_for_brazil"": ""🇧🇷"",
    ""flag_for_british_indian_ocean_territory"": ""🇮🇴"",
    ""flag_for_british_virgin_islands"": ""🇻🇬"",
    ""flag_for_brunei"": ""🇧🇳"",
    ""flag_for_bulgaria"": ""🇧🇬"",
    ""flag_for_burkina_faso"": ""🇧🇫"",
    ""flag_for_burundi"": ""🇧🇮"",
    ""flag_for_cambodia"": ""🇰🇭"",
    ""flag_for_cameroon"": ""🇨🇲"",
    ""flag_for_canada"": ""🇨🇦"",
    ""flag_for_canary_islands"": ""🇮🇨"",
    ""flag_for_cape_verde"": ""🇨🇻"",
    ""flag_for_caribbean_netherlands"": ""🇧🇶"",
    ""flag_for_cayman_islands"": ""🇰🇾"",
    ""flag_for_central_african_republic"": ""🇨🇫"",
    ""flag_for_ceuta_&_melilla"": ""🇪🇦"",
    ""flag_for_chad"": ""🇹🇩"",
    ""flag_for_chile"": ""🇨🇱"",
    ""flag_for_china"": ""🇨🇳"",
    ""flag_for_christmas_island"": ""🇨🇽"",
    ""flag_for_clipperton_island"": ""🇨🇵"",
    ""flag_for_cocos__islands"": ""🇨🇨"",
    ""flag_for_colombia"": ""🇨🇴"",
    ""flag_for_comoros"": ""🇰🇲"",
    ""flag_for_congo____brazzaville"": ""🇨🇬"",
    ""flag_for_congo____kinshasa"": ""🇨🇩"",
    ""flag_for_cook_islands"": ""🇨🇰"",
    ""flag_for_costa_rica"": ""🇨🇷"",
    ""flag_for_croatia"": ""🇭🇷"",
    ""flag_for_cuba"": ""🇨🇺"",
    ""flag_for_curaçao"": ""🇨🇼"",
    ""flag_for_cyprus"": ""🇨🇾"",
    ""flag_for_czech_republic"": ""🇨🇿"",
    ""flag_for_côte_d’ivoire"": ""🇨🇮"",
    ""flag_for_denmark"": ""🇩🇰"",
    ""flag_for_diego_garcia"": ""🇩🇬"",
    ""flag_for_djibouti"": ""🇩🇯"",
    ""flag_for_dominica"": ""🇩🇲"",
    ""flag_for_dominican_republic"": ""🇩🇴"",
    ""flag_for_ecuador"": ""🇪🇨"",
    ""flag_for_egypt"": ""🇪🇬"",
    ""flag_for_el_salvador"": ""🇸🇻"",
    ""flag_for_equatorial_guinea"": ""🇬🇶"",
    ""flag_for_eritrea"": ""🇪🇷"",
    ""flag_for_estonia"": ""🇪🇪"",
    ""flag_for_ethiopia"": ""🇪🇹"",
    ""flag_for_european_union"": ""🇪🇺"",
    ""flag_for_falkland_islands"": ""🇫🇰"",
    ""flag_for_faroe_islands"": ""🇫🇴"",
    ""flag_for_fiji"": ""🇫🇯"",
    ""flag_for_finland"": ""🇫🇮"",
    ""flag_for_france"": ""🇫🇷"",
    ""flag_for_french_guiana"": ""🇬🇫"",
    ""flag_for_french_polynesia"": ""🇵🇫"",
    ""flag_for_french_southern_territories"": ""🇹🇫"",
    ""flag_for_gabon"": ""🇬🇦"",
    ""flag_for_gambia"": ""🇬🇲"",
    ""flag_for_georgia"": ""🇬🇪"",
    ""flag_for_germany"": ""🇩🇪"",
    ""flag_for_ghana"": ""🇬🇭"",
    ""flag_for_gibraltar"": ""🇬🇮"",
    ""flag_for_greece"": ""🇬🇷"",
    ""flag_for_greenland"": ""🇬🇱"",
    ""flag_for_grenada"": ""🇬🇩"",
    ""flag_for_guadeloupe"": ""🇬🇵"",
    ""flag_for_guam"": ""🇬🇺"",
    ""flag_for_guatemala"": ""🇬🇹"",
    ""flag_for_guernsey"": ""🇬🇬"",
    ""flag_for_guinea"": ""🇬🇳"",
    ""flag_for_guinea__bissau"": ""🇬🇼"",
    ""flag_for_guyana"": ""🇬🇾"",
    ""flag_for_haiti"": ""🇭🇹"",
    ""flag_for_heard_&_mcdonald_islands"": ""🇭🇲"",
    ""flag_for_honduras"": ""🇭🇳"",
    ""flag_for_hong_kong"": ""🇭🇰"",
    ""flag_for_hungary"": ""🇭🇺"",
    ""flag_for_iceland"": ""🇮🇸"",
    ""flag_for_india"": ""🇮🇳"",
    ""flag_for_indonesia"": ""🇮🇩"",
    ""flag_for_iran"": ""🇮🇷"",
    ""flag_for_iraq"": ""🇮🇶"",
    ""flag_for_ireland"": ""🇮🇪"",
    ""flag_for_isle_of_man"": ""🇮🇲"",
    ""flag_for_israel"": ""🇮🇱"",
    ""flag_for_italy"": ""🇮🇹"",
    ""flag_for_jamaica"": ""🇯🇲"",
    ""flag_for_japan"": ""🇯🇵"",
    ""flag_for_jersey"": ""🇯🇪"",
    ""flag_for_jordan"": ""🇯🇴"",
    ""flag_for_kazakhstan"": ""🇰🇿"",
    ""flag_for_kenya"": ""🇰🇪"",
    ""flag_for_kiribati"": ""🇰🇮"",
    ""flag_for_kosovo"": ""🇽🇰"",
    ""flag_for_kuwait"": ""🇰🇼"",
    ""flag_for_kyrgyzstan"": ""🇰🇬"",
    ""flag_for_laos"": ""🇱🇦"",
    ""flag_for_latvia"": ""🇱🇻"",
    ""flag_for_lebanon"": ""🇱🇧"",
    ""flag_for_lesotho"": ""🇱🇸"",
    ""flag_for_liberia"": ""🇱🇷"",
    ""flag_for_libya"": ""🇱🇾"",
    ""flag_for_liechtenstein"": ""🇱🇮"",
    ""flag_for_lithuania"": ""🇱🇹"",
    ""flag_for_luxembourg"": ""🇱🇺"",
    ""flag_for_macau"": ""🇲🇴"",
    ""flag_for_macedonia"": ""🇲🇰"",
    ""flag_for_madagascar"": ""🇲🇬"",
    ""flag_for_malawi"": ""🇲🇼"",
    ""flag_for_malaysia"": ""🇲🇾"",
    ""flag_for_maldives"": ""🇲🇻"",
    ""flag_for_mali"": ""🇲🇱"",
    ""flag_for_malta"": ""🇲🇹"",
    ""flag_for_marshall_islands"": ""🇲🇭"",
    ""flag_for_martinique"": ""🇲🇶"",
    ""flag_for_mauritania"": ""🇲🇷"",
    ""flag_for_mauritius"": ""🇲🇺"",
    ""flag_for_mayotte"": ""🇾🇹"",
    ""flag_for_mexico"": ""🇲🇽"",
    ""flag_for_micronesia"": ""🇫🇲"",
    ""flag_for_moldova"": ""🇲🇩"",
    ""flag_for_monaco"": ""🇲🇨"",
    ""flag_for_mongolia"": ""🇲🇳"",
    ""flag_for_montenegro"": ""🇲🇪"",
    ""flag_for_montserrat"": ""🇲🇸"",
    ""flag_for_morocco"": ""🇲🇦"",
    ""flag_for_mozambique"": ""🇲🇿"",
    ""flag_for_myanmar"": ""🇲🇲"",
    ""flag_for_namibia"": ""🇳🇦"",
    ""flag_for_nauru"": ""🇳🇷"",
    ""flag_for_nepal"": ""🇳🇵"",
    ""flag_for_netherlands"": ""🇳🇱"",
    ""flag_for_new_caledonia"": ""🇳🇨"",
    ""flag_for_new_zealand"": ""🇳🇿"",
    ""flag_for_nicaragua"": ""🇳🇮"",
    ""flag_for_niger"": ""🇳🇪"",
    ""flag_for_nigeria"": ""🇳🇬"",
    ""flag_for_niue"": ""🇳🇺"",
    ""flag_for_norfolk_island"": ""🇳🇫"",
    ""flag_for_north_korea"": ""🇰🇵"",
    ""flag_for_northern_mariana_islands"": ""🇲🇵"",
    ""flag_for_norway"": ""🇳🇴"",
    ""flag_for_oman"": ""🇴🇲"",
    ""flag_for_pakistan"": ""🇵🇰"",
    ""flag_for_palau"": ""🇵🇼"",
    ""flag_for_palestinian_territories"": ""🇵🇸"",
    ""flag_for_panama"": ""🇵🇦"",
    ""flag_for_papua_new_guinea"": ""🇵🇬"",
    ""flag_for_paraguay"": ""🇵🇾"",
    ""flag_for_peru"": ""🇵🇪"",
    ""flag_for_philippines"": ""🇵🇭"",
    ""flag_for_pitcairn_islands"": ""🇵🇳"",
    ""flag_for_poland"": ""🇵🇱"",
    ""flag_for_portugal"": ""🇵🇹"",
    ""flag_for_puerto_rico"": ""🇵🇷"",
    ""flag_for_qatar"": ""🇶🇦"",
    ""flag_for_romania"": ""🇷🇴"",
    ""flag_for_russia"": ""🇷🇺"",
    ""flag_for_rwanda"": ""🇷🇼"",
    ""flag_for_réunion"": ""🇷🇪"",
    ""flag_for_samoa"": ""🇼🇸"",
    ""flag_for_san_marino"": ""🇸🇲"",
    ""flag_for_saudi_arabia"": ""🇸🇦"",
    ""flag_for_senegal"": ""🇸🇳"",
    ""flag_for_serbia"": ""🇷🇸"",
    ""flag_for_seychelles"": ""🇸🇨"",
    ""flag_for_sierra_leone"": ""🇸🇱"",
    ""flag_for_singapore"": ""🇸🇬"",
    ""flag_for_sint_maarten"": ""🇸🇽"",
    ""flag_for_slovakia"": ""🇸🇰"",
    ""flag_for_slovenia"": ""🇸🇮"",
    ""flag_for_solomon_islands"": ""🇸🇧"",
    ""flag_for_somalia"": ""🇸🇴"",
    ""flag_for_south_africa"": ""🇿🇦"",
    ""flag_for_south_georgia_&_south_sandwich_islands"": ""🇬🇸"",
    ""flag_for_south_korea"": ""🇰🇷"",
    ""flag_for_south_sudan"": ""🇸🇸"",
    ""flag_for_spain"": ""🇪🇸"",
    ""flag_for_sri_lanka"": ""🇱🇰"",
    ""flag_for_st._barthélemy"": ""🇧🇱"",
    ""flag_for_st._helena"": ""🇸🇭"",
    ""flag_for_st._kitts_&_nevis"": ""🇰🇳"",
    ""flag_for_st._lucia"": ""🇱🇨"",
    ""flag_for_st._martin"": ""🇲🇫"",
    ""flag_for_st._pierre_&_miquelon"": ""🇵🇲"",
    ""flag_for_st._vincent_&_grenadines"": ""🇻🇨"",
    ""flag_for_sudan"": ""🇸🇩"",
    ""flag_for_suriname"": ""🇸🇷"",
    ""flag_for_svalbard_&_jan_mayen"": ""🇸🇯"",
    ""flag_for_swaziland"": ""🇸🇿"",
    ""flag_for_sweden"": ""🇸🇪"",
    ""flag_for_switzerland"": ""🇨🇭"",
    ""flag_for_syria"": ""🇸🇾"",
    ""flag_for_são_tomé_&_príncipe"": ""🇸🇹"",
    ""flag_for_taiwan"": ""🇹🇼"",
    ""flag_for_tajikistan"": ""🇹🇯"",
    ""flag_for_tanzania"": ""🇹🇿"",
    ""flag_for_thailand"": ""🇹🇭"",
    ""flag_for_timor__leste"": ""🇹🇱"",
    ""flag_for_togo"": ""🇹🇬"",
    ""flag_for_tokelau"": ""🇹🇰"",
    ""flag_for_tonga"": ""🇹🇴"",
    ""flag_for_trinidad_&_tobago"": ""🇹🇹"",
    ""flag_for_tristan_da_cunha"": ""🇹🇦"",
    ""flag_for_tunisia"": ""🇹🇳"",
    ""flag_for_turkey"": ""🇹🇷"",
    ""flag_for_turkmenistan"": ""🇹🇲"",
    ""flag_for_turks_&_caicos_islands"": ""🇹🇨"",
    ""flag_for_tuvalu"": ""🇹🇻"",
    ""flag_for_u.s._outlying_islands"": ""🇺🇲"",
    ""flag_for_u.s._virgin_islands"": ""🇻🇮"",
    ""flag_for_uganda"": ""🇺🇬"",
    ""flag_for_ukraine"": ""🇺🇦"",
    ""flag_for_united_arab_emirates"": ""🇦🇪"",
    ""flag_for_united_kingdom"": ""🇬🇧"",
    ""flag_for_united_states"": ""🇺🇸"",
    ""flag_for_uruguay"": ""🇺🇾"",
    ""flag_for_uzbekistan"": ""🇺🇿"",
    ""flag_for_vanuatu"": ""🇻🇺"",
    ""flag_for_vatican_city"": ""🇻🇦"",
    ""flag_for_venezuela"": ""🇻🇪"",
    ""flag_for_vietnam"": ""🇻🇳"",
    ""flag_for_wallis_&_futuna"": ""🇼🇫"",
    ""flag_for_western_sahara"": ""🇪🇭"",
    ""flag_for_yemen"": ""🇾🇪"",
    ""flag_for_zambia"": ""🇿🇲"",
    ""flag_for_zimbabwe"": ""🇿🇼"",
    ""flag_for_åland_islands"": ""🇦🇽"",
    ""golf"": ""⛳"",
    ""fleur__de__lis"": ""⚜"",
    ""muscle"": ""💪"",
    ""flushed"": ""😳"",
    ""frame_with_picture"": ""🖼"",
    ""fries"": ""🍟"",
    ""frog"": ""🐸"",
    ""hatched_chick"": ""🐥"",
    ""frowning"": ""😦"",
    ""fuelpump"": ""⛽"",
    ""full_moon_with_face"": ""🌝"",
    ""gem"": ""💎"",
    ""star2"": ""🌟"",
    ""golfer"": ""🏌"",
    ""mortar_board"": ""🎓"",
    ""grimacing"": ""😬"",
    ""smile_cat"": ""😸"",
    ""grinning"": ""😀"",
    ""grin"": ""😁"",
    ""heartpulse"": ""💗"",
    ""guardsman"": ""💂"",
    ""haircut"": ""💇"",
    ""hamster"": ""🐹"",
    ""raising_hand"": ""🙋"",
    ""headphones"": ""🎧"",
    ""hear_no_evil"": ""🙉"",
    ""cupid"": ""💘"",
    ""gift_heart"": ""💝"",
    ""heart"": ""❤"",
    ""exclamation"": ""❗"",
    ""heavy_exclamation_mark"": ""❗"",
    ""heavy_heart_exclamation_mark_ornament"": ""❣"",
    ""o"": ""⭕"",
    ""helm_symbol"": ""⎈"",
    ""helmet_with_white_cross"": ""⛑"",
    ""high_heel"": ""👠"",
    ""bullettrain_side"": ""🚄"",
    ""bullettrain_front"": ""🚅"",
    ""high_brightness"": ""🔆"",
    ""zap"": ""⚡"",
    ""hocho"": ""🔪"",
    ""knife"": ""🔪"",
    ""bee"": ""🐝"",
    ""traffic_light"": ""🚥"",
    ""racehorse"": ""🐎"",
    ""coffee"": ""☕"",
    ""hotsprings"": ""♨"",
    ""hourglass"": ""⌛"",
    ""hourglass_flowing_sand"": ""⏳"",
    ""house_buildings"": ""🏘"",
    ""100"": ""💯"",
    ""hushed"": ""😯"",
    ""ice_hockey_stick_and_puck"": ""🏒"",
    ""imp"": ""👿"",
    ""information_desk_person"": ""💁"",
    ""information_source"": ""ℹ"",
    ""capital_abcd"": ""🔠"",
    ""abc"": ""🔤"",
    ""abcd"": ""🔡"",
    ""1234"": ""🔢"",
    ""symbols"": ""🔣"",
    ""izakaya_lantern"": ""🏮"",
    ""lantern"": ""🏮"",
    ""jack_o_lantern"": ""🎃"",
    ""dolls"": ""🎎"",
    ""japanese_goblin"": ""👺"",
    ""japanese_ogre"": ""👹"",
    ""beginner"": ""🔰"",
    ""zero"": ""0️⃣"",
    ""one"": ""1️⃣"",
    ""ten"": ""🔟"",
    ""two"": ""2️⃣"",
    ""three"": ""3️⃣"",
    ""four"": ""4️⃣"",
    ""five"": ""5️⃣"",
    ""six"": ""6️⃣"",
    ""seven"": ""7️⃣"",
    ""eight"": ""8️⃣"",
    ""nine"": ""9️⃣"",
    ""couplekiss"": ""💏"",
    ""kissing_cat"": ""😽"",
    ""kissing"": ""😗"",
    ""kissing_closed_eyes"": ""😚"",
    ""kissing_smiling_eyes"": ""😙"",
    ""beetle"": ""🐞"",
    ""large_blue_circle"": ""🔵"",
    ""last_quarter_moon_with_face"": ""🌜"",
    ""leaves"": ""🍃"",
    ""mag"": ""🔍"",
    ""left_right_arrow"": ""↔"",
    ""leftwards_arrow_with_hook"": ""↩"",
    ""arrow_left"": ""⬅"",
    ""lock"": ""🔒"",
    ""lock_with_ink_pen"": ""🔏"",
    ""sob"": ""😭"",
    ""low_brightness"": ""🔅"",
    ""lower_left_ballpoint_pen"": ""🖊"",
    ""lower_left_crayon"": ""🖍"",
    ""lower_left_fountain_pen"": ""🖋"",
    ""lower_left_paintbrush"": ""🖌"",
    ""mahjong"": ""🀄"",
    ""couple"": ""👫"",
    ""man_in_business_suit_levitating"": ""🕴"",
    ""man_with_gua_pi_mao"": ""👲"",
    ""man_with_turban"": ""👳"",
    ""mans_shoe"": ""👞"",
    ""shoe"": ""👞"",
    ""menorah_with_nine_branches"": ""🕎"",
    ""mens"": ""🚹"",
    ""minidisc"": ""💽"",
    ""iphone"": ""📱"",
    ""calling"": ""📲"",
    ""money__mouth_face"": ""🤑"",
    ""moneybag"": ""💰"",
    ""rice_scene"": ""🎑"",
    ""mountain_bicyclist"": ""🚵"",
    ""mouse2"": ""🐁"",
    ""lips"": ""👄"",
    ""moyai"": ""🗿"",
    ""notes"": ""🎶"",
    ""nail_care"": ""💅"",
    ""ab"": ""🆎"",
    ""negative_squared_cross_mark"": ""❎"",
    ""a"": ""🅰"",
    ""b"": ""🅱"",
    ""o2"": ""🅾"",
    ""parking"": ""🅿"",
    ""new_moon_with_face"": ""🌚"",
    ""no_entry_sign"": ""🚫"",
    ""underage"": ""🔞"",
    ""non__potable_water"": ""🚱"",
    ""arrow_upper_right"": ""↗"",
    ""arrow_upper_left"": ""↖"",
    ""office"": ""🏢"",
    ""older_man"": ""👴"",
    ""older_woman"": ""👵"",
    ""om_symbol"": ""🕉"",
    ""on"": ""🔛"",
    ""book"": ""📖"",
    ""unlock"": ""🔓"",
    ""mailbox_with_no_mail"": ""📭"",
    ""mailbox_with_mail"": ""📬"",
    ""cd"": ""💿"",
    ""tada"": ""🎉"",
    ""feet"": ""🐾"",
    ""walking"": ""🚶"",
    ""pencil2"": ""✏"",
    ""pensive"": ""😔"",
    ""persevere"": ""😣"",
    ""bow"": ""🙇"",
    ""raised_hands"": ""🙌"",
    ""person_with_ball"": ""⛹"",
    ""person_with_blond_hair"": ""👱"",
    ""pray"": ""🙏"",
    ""person_with_pouting_face"": ""🙎"",
    ""computer"": ""💻"",
    ""pig2"": ""🐖"",
    ""hankey"": ""💩"",
    ""poop"": ""💩"",
    ""shit"": ""💩"",
    ""bamboo"": ""🎍"",
    ""gun"": ""🔫"",
    ""black_joker"": ""🃏"",
    ""rotating_light"": ""🚨"",
    ""cop"": ""👮"",
    ""stew"": ""🍲"",
    ""pouch"": ""👝"",
    ""pouting_cat"": ""😾"",
    ""rage"": ""😡"",
    ""put_litter_in_its_place"": ""🚮"",
    ""rabbit2"": ""🐇"",
    ""racing_motorcycle"": ""🏍"",
    ""radioactive_sign"": ""☢"",
    ""fist"": ""✊"",
    ""hand"": ""✋"",
    ""raised_hand_with_fingers_splayed"": ""🖐"",
    ""raised_hand_with_part_between_middle_and_ring_fingers"": ""🖖"",
    ""blue_car"": ""🚙"",
    ""apple"": ""🍎"",
    ""relieved"": ""😌"",
    ""reversed_hand_with_middle_finger_extended"": ""🖕"",
    ""mag_right"": ""🔎"",
    ""arrow_right_hook"": ""↪"",
    ""sweet_potato"": ""🍠"",
    ""robot"": ""🤖"",
    ""rolled__up_newspaper"": ""🗞"",
    ""rowboat"": ""🚣"",
    ""runner"": ""🏃"",
    ""running"": ""🏃"",
    ""running_shirt_with_sash"": ""🎽"",
    ""boat"": ""⛵"",
    ""scales"": ""⚖"",
    ""school_satchel"": ""🎒"",
    ""scorpius"": ""♏"",
    ""see_no_evil"": ""🙈"",
    ""sheep"": ""🐑"",
    ""stars"": ""🌠"",
    ""cake"": ""🍰"",
    ""six_pointed_star"": ""🔯"",
    ""ski"": ""🎿"",
    ""sleeping_accommodation"": ""🛌"",
    ""sleeping"": ""😴"",
    ""sleepy"": ""😪"",
    ""sleuth_or_spy"": ""🕵"",
    ""heart_eyes_cat"": ""😻"",
    ""smiley_cat"": ""😺"",
    ""innocent"": ""😇"",
    ""heart_eyes"": ""😍"",
    ""smiling_imp"": ""😈"",
    ""smiley"": ""😃"",
    ""sweat_smile"": ""😅"",
    ""smile"": ""😄"",
    ""laughing"": ""😆"",
    ""satisfied"": ""😆"",
    ""blush"": ""😊"",
    ""smirk"": ""😏"",
    ""smoking"": ""🚬"",
    ""snow_capped_mountain"": ""🏔"",
    ""soccer"": ""⚽"",
    ""icecream"": ""🍦"",
    ""soon"": ""🔜"",
    ""arrow_lower_right"": ""↘"",
    ""arrow_lower_left"": ""↙"",
    ""speak_no_evil"": ""🙊"",
    ""speaker"": ""🔈"",
    ""mute"": ""🔇"",
    ""sound"": ""🔉"",
    ""loud_sound"": ""🔊"",
    ""speaking_head_in_silhouette"": ""🗣"",
    ""spiral_calendar_pad"": ""🗓"",
    ""spiral_note_pad"": ""🗒"",
    ""shell"": ""🐚"",
    ""sweat_drops"": ""💦"",
    ""u5272"": ""🈹"",
    ""u5408"": ""🈴"",
    ""u55b6"": ""🈺"",
    ""u6307"": ""🈯"",
    ""u6708"": ""🈷"",
    ""u6709"": ""🈶"",
    ""u6e80"": ""🈵"",
    ""u7121"": ""🈚"",
    ""u7533"": ""🈸"",
    ""u7981"": ""🈲"",
    ""u7a7a"": ""🈳"",
    ""cl"": ""🆑"",
    ""cool"": ""🆒"",
    ""free"": ""🆓"",
    ""id"": ""🆔"",
    ""koko"": ""🈁"",
    ""sa"": ""🈂"",
    ""new"": ""🆕"",
    ""ng"": ""🆖"",
    ""ok"": ""🆗"",
    ""sos"": ""🆘"",
    ""up"": ""🆙"",
    ""vs"": ""🆚"",
    ""steam_locomotive"": ""🚂"",
    ""ramen"": ""🍜"",
    ""partly_sunny"": ""⛅"",
    ""city_sunrise"": ""🌇"",
    ""surfer"": ""🏄"",
    ""swimmer"": ""🏊"",
    ""shirt"": ""👕"",
    ""tshirt"": ""👕"",
    ""table_tennis_paddle_and_ball"": ""🏓"",
    ""tea"": ""🍵"",
    ""tv"": ""📺"",
    ""three_button_mouse"": ""🖱"",
    ""+1"": ""👍"",
    ""thumbsup"": ""👍"",
    ""__1"": ""👎"",
    ""-1"": ""👎"",
    ""thumbsdown"": ""👎"",
    ""thunder_cloud_and_rain"": ""⛈"",
    ""tiger2"": ""🐅"",
    ""tophat"": ""🎩"",
    ""top"": ""🔝"",
    ""tm"": ""™"",
    ""train2"": ""🚆"",
    ""triangular_flag_on_post"": ""🚩"",
    ""trident"": ""🔱"",
    ""twisted_rightwards_arrows"": ""🔀"",
    ""unamused"": ""😒"",
    ""small_red_triangle"": ""🔺"",
    ""arrow_up_small"": ""🔼"",
    ""arrow_up_down"": ""↕"",
    ""upside__down_face"": ""🙃"",
    ""arrow_up"": ""⬆"",
    ""v"": ""✌"",
    ""vhs"": ""📼"",
    ""wc"": ""🚾"",
    ""ocean"": ""🌊"",
    ""waving_black_flag"": ""🏴"",
    ""wave"": ""👋"",
    ""waving_white_flag"": ""🏳"",
    ""moon"": ""🌔"",
    ""scream_cat"": ""🙀"",
    ""weary"": ""😩"",
    ""weight_lifter"": ""🏋"",
    ""whale2"": ""🐋"",
    ""wheelchair"": ""♿"",
    ""point_down"": ""👇"",
    ""grey_exclamation"": ""❕"",
    ""white_frowning_face"": ""☹"",
    ""white_check_mark"": ""✅"",
    ""point_left"": ""👈"",
    ""white_medium_small_square"": ""◽"",
    ""star"": ""⭐"",
    ""grey_question"": ""❔"",
    ""point_right"": ""👉"",
    ""relaxed"": ""☺"",
    ""white_sun_behind_cloud"": ""🌥"",
    ""white_sun_behind_cloud_with_rain"": ""🌦"",
    ""white_sun_with_small_cloud"": ""🌤"",
    ""point_up_2"": ""👆"",
    ""point_up"": ""☝"",
    ""wind_blowing_face"": ""🌬"",
    ""wink"": ""😉"",
    ""wolf"": ""🐺"",
    ""dancers"": ""👯"",
    ""boot"": ""👢"",
    ""womans_clothes"": ""👚"",
    ""womans_hat"": ""👒"",
    ""sandal"": ""👡"",
    ""womens"": ""🚺"",
    ""worried"": ""😟"",
    ""gift"": ""🎁"",
    ""zipper__mouth_face"": ""🤐"",
    ""regional_indicator_a"": ""🇦"",
    ""regional_indicator_b"": ""🇧"",
    ""regional_indicator_c"": ""🇨"",
    ""regional_indicator_d"": ""🇩"",
    ""regional_indicator_e"": ""🇪"",
    ""regional_indicator_f"": ""🇫"",
    ""regional_indicator_g"": ""🇬"",
    ""regional_indicator_h"": ""🇭"",
    ""regional_indicator_i"": ""🇮"",
    ""regional_indicator_j"": ""🇯"",
    ""regional_indicator_k"": ""🇰"",
    ""regional_indicator_l"": ""🇱"",
    ""regional_indicator_m"": ""🇲"",
    ""regional_indicator_n"": ""🇳"",
    ""regional_indicator_o"": ""🇴"",
    ""regional_indicator_p"": ""🇵"",
    ""regional_indicator_q"": ""🇶"",
    ""regional_indicator_r"": ""🇷"",
    ""regional_indicator_s"": ""🇸"",
    ""regional_indicator_t"": ""🇹"",
    ""regional_indicator_u"": ""🇺"",
    ""regional_indicator_v"": ""🇻"",
    ""regional_indicator_w"": ""🇼"",
    ""regional_indicator_x"": ""🇽"",
    ""regional_indicator_y"": ""🇾"",
    ""regional_indicator_z"": ""🇿"",
}

from typing import Callable, Match, Optional
import re

from ._emoji_codes import EMOJI


_ReStringMatch = Match[str]  
_ReSubCallable = Callable[[_ReStringMatch], str]  
_EmojiSubMethod = Callable[[_ReSubCallable, str], str]  


def _emoji_replace(
    text: str,
    default_variant: Optional[str] = None,
    _emoji_sub: _EmojiSubMethod = re.compile(r""(:(\S*?)(?:(?:\-)(emoji|text))?:)"").sub,
) -> str:
    
    get_emoji = EMOJI.__getitem__
    variants = {""text"": ""\uFE0E"", ""emoji"": ""\uFE0F""}
    get_variant = variants.get
    default_variant_code = variants.get(default_variant, """") if default_variant else """"

    def do_replace(match: Match[str]) -> str:
        emoji_code, emoji_name, variant = match.groups()
        try:
            return get_emoji(emoji_name.lower()) + get_variant(
                variant, default_variant_code
            )
        except KeyError:
            return emoji_code

    return _emoji_sub(do_replace, text)

CONSOLE_HTML_FORMAT = 

CONSOLE_SVG_FORMAT = 

_SVG_FONT_FAMILY = ""Rich Fira Code""
_SVG_CLASSES_PREFIX = ""rich-svg""

from typing import Any


def load_ipython_extension(ip: Any) -> None:  
    
    from pip._vendor.rich.pretty import install
    from pip._vendor.rich.traceback import install as tr_install

    install()
    tr_install()

from __future__ import annotations

from typing import IO, Callable


def get_fileno(file_like: IO[str]) -> int | None:
    
    fileno: Callable[[], int] | None = getattr(file_like, ""fileno"", None)
    if fileno is not None:
        try:
            return fileno()
        except Exception:
            
            
            
            return None
    return None

import inspect
from inspect import cleandoc, getdoc, getfile, isclass, ismodule, signature
from typing import Any, Collection, Iterable, Optional, Tuple, Type, Union

from .console import Group, RenderableType
from .control import escape_control_codes
from .highlighter import ReprHighlighter
from .jupyter import JupyterMixin
from .panel import Panel
from .pretty import Pretty
from .table import Table
from .text import Text, TextType


def _first_paragraph(doc: str) -> str:
    
    paragraph, _, _ = doc.partition(""\n\n"")
    return paragraph


class Inspect(JupyterMixin):
    

    def __init__(
        self,
        obj: Any,
        *,
        title: Optional[TextType] = None,
        help: bool = False,
        methods: bool = False,
        docs: bool = True,
        private: bool = False,
        dunder: bool = False,
        sort: bool = True,
        all: bool = True,
        value: bool = True,
    ) -> None:
        self.highlighter = ReprHighlighter()
        self.obj = obj
        self.title = title or self._make_title(obj)
        if all:
            methods = private = dunder = True
        self.help = help
        self.methods = methods
        self.docs = docs or help
        self.private = private or dunder
        self.dunder = dunder
        self.sort = sort
        self.value = value

    def _make_title(self, obj: Any) -> Text:
        
        title_str = (
            str(obj)
            if (isclass(obj) or callable(obj) or ismodule(obj))
            else str(type(obj))
        )
        title_text = self.highlighter(title_str)
        return title_text

    def __rich__(self) -> Panel:
        return Panel.fit(
            Group(*self._render()),
            title=self.title,
            border_style=""scope.border"",
            padding=(0, 1),
        )

    def _get_signature(self, name: str, obj: Any) -> Optional[Text]:
        
        try:
            _signature = str(signature(obj)) + "":""
        except ValueError:
            _signature = ""(...)""
        except TypeError:
            return None

        source_filename: Optional[str] = None
        try:
            source_filename = getfile(obj)
        except (OSError, TypeError):
            
            pass

        callable_name = Text(name, style=""inspect.callable"")
        if source_filename:
            callable_name.stylize(f""link file://{source_filename}"")
        signature_text = self.highlighter(_signature)

        qualname = name or getattr(obj, ""__qualname__"", name)

        
        if inspect.isclass(obj):
            prefix = ""class""
        elif inspect.iscoroutinefunction(obj):
            prefix = ""async def""
        else:
            prefix = ""def""

        qual_signature = Text.assemble(
            (f""{prefix} "", f""inspect.{prefix.replace(' ', '_')}""),
            (qualname, ""inspect.callable""),
            signature_text,
        )

        return qual_signature

    def _render(self) -> Iterable[RenderableType]:
        

        def sort_items(item: Tuple[str, Any]) -> Tuple[bool, str]:
            key, (_error, value) = item
            return (callable(value), key.strip(""_"").lower())

        def safe_getattr(attr_name: str) -> Tuple[Any, Any]:
            
            try:
                return (None, getattr(obj, attr_name))
            except Exception as error:
                return (error, None)

        obj = self.obj
        keys = dir(obj)
        total_items = len(keys)
        if not self.dunder:
            keys = [key for key in keys if not key.startswith(""__"")]
        if not self.private:
            keys = [key for key in keys if not key.startswith(""_"")]
        not_shown_count = total_items - len(keys)
        items = [(key, safe_getattr(key)) for key in keys]
        if self.sort:
            items.sort(key=sort_items)

        items_table = Table.grid(padding=(0, 1), expand=False)
        items_table.add_column(justify=""right"")
        add_row = items_table.add_row
        highlighter = self.highlighter

        if callable(obj):
            signature = self._get_signature("""", obj)
            if signature is not None:
                yield signature
                yield """"

        if self.docs:
            _doc = self._get_formatted_doc(obj)
            if _doc is not None:
                doc_text = Text(_doc, style=""inspect.help"")
                doc_text = highlighter(doc_text)
                yield doc_text
                yield """"

        if self.value and not (isclass(obj) or callable(obj) or ismodule(obj)):
            yield Panel(
                Pretty(obj, indent_guides=True, max_length=10, max_string=60),
                border_style=""inspect.value.border"",
            )
            yield """"

        for key, (error, value) in items:
            key_text = Text.assemble(
                (
                    key,
                    ""inspect.attr.dunder"" if key.startswith(""__"") else ""inspect.attr"",
                ),
                ("" ="", ""inspect.equals""),
            )
            if error is not None:
                warning = key_text.copy()
                warning.stylize(""inspect.error"")
                add_row(warning, highlighter(repr(error)))
                continue

            if callable(value):
                if not self.methods:
                    continue

                _signature_text = self._get_signature(key, value)
                if _signature_text is None:
                    add_row(key_text, Pretty(value, highlighter=highlighter))
                else:
                    if self.docs:
                        docs = self._get_formatted_doc(value)
                        if docs is not None:
                            _signature_text.append(""\n"" if ""\n"" in docs else "" "")
                            doc = highlighter(docs)
                            doc.stylize(""inspect.doc"")
                            _signature_text.append(doc)

                    add_row(key_text, _signature_text)
            else:
                add_row(key_text, Pretty(value, highlighter=highlighter))
        if items_table.row_count:
            yield items_table
        elif not_shown_count:
            yield Text.from_markup(
                f""[b cyan]{not_shown_count}[/][i] attribute(s) not shown.[/i] ""
                f""Run [b][magenta]inspect[/]([not b]inspect[/])[/b] for options.""
            )

    def _get_formatted_doc(self, object_: Any) -> Optional[str]:
        
        docs = getdoc(object_)
        if docs is None:
            return None
        docs = cleandoc(docs).strip()
        if not self.help:
            docs = _first_paragraph(docs)
        return escape_control_codes(docs)


def get_object_types_mro(obj: Union[object, Type[Any]]) -> Tuple[type, ...]:
    
    if not hasattr(obj, ""__mro__""):
        
        
        obj = type(obj)
    return getattr(obj, ""__mro__"", ())


def get_object_types_mro_as_strings(obj: object) -> Collection[str]:
    
    return [
        f'{getattr(type_, ""__module__"", """")}.{getattr(type_, ""__qualname__"", """")}'
        for type_ in get_object_types_mro(obj)
    ]


def is_object_one_of_types(
    obj: object, fully_qualified_types_names: Collection[str]
) -> bool:
    
    for type_name in get_object_types_mro_as_strings(obj):
        if type_name in fully_qualified_types_names:
            return True
    return False

from datetime import datetime
from typing import Iterable, List, Optional, TYPE_CHECKING, Union, Callable


from .text import Text, TextType

if TYPE_CHECKING:
    from .console import Console, ConsoleRenderable, RenderableType
    from .table import Table

FormatTimeCallable = Callable[[datetime], Text]


class LogRender:
    def __init__(
        self,
        show_time: bool = True,
        show_level: bool = False,
        show_path: bool = True,
        time_format: Union[str, FormatTimeCallable] = ""[%x %X]"",
        omit_repeated_times: bool = True,
        level_width: Optional[int] = 8,
    ) -> None:
        self.show_time = show_time
        self.show_level = show_level
        self.show_path = show_path
        self.time_format = time_format
        self.omit_repeated_times = omit_repeated_times
        self.level_width = level_width
        self._last_time: Optional[Text] = None

    def __call__(
        self,
        console: ""Console"",
        renderables: Iterable[""ConsoleRenderable""],
        log_time: Optional[datetime] = None,
        time_format: Optional[Union[str, FormatTimeCallable]] = None,
        level: TextType = """",
        path: Optional[str] = None,
        line_no: Optional[int] = None,
        link_path: Optional[str] = None,
    ) -> ""Table"":
        from .containers import Renderables
        from .table import Table

        output = Table.grid(padding=(0, 1))
        output.expand = True
        if self.show_time:
            output.add_column(style=""log.time"")
        if self.show_level:
            output.add_column(style=""log.level"", width=self.level_width)
        output.add_column(ratio=1, style=""log.message"", overflow=""fold"")
        if self.show_path and path:
            output.add_column(style=""log.path"")
        row: List[""RenderableType""] = []
        if self.show_time:
            log_time = log_time or console.get_datetime()
            time_format = time_format or self.time_format
            if callable(time_format):
                log_time_display = time_format(log_time)
            else:
                log_time_display = Text(log_time.strftime(time_format))
            if log_time_display == self._last_time and self.omit_repeated_times:
                row.append(Text("" "" * len(log_time_display)))
            else:
                row.append(log_time_display)
                self._last_time = log_time_display
        if self.show_level:
            row.append(level)

        row.append(Renderables(renderables))
        if self.show_path and path:
            path_text = Text()
            path_text.append(
                path, style=f""link file://{link_path}"" if link_path else """"
            )
            if line_no:
                path_text.append("":"")
                path_text.append(
                    f""{line_no}"",
                    style=f""link file://{link_path}
                )
            row.append(path_text)

        output.add_row(*row)
        return output


if __name__ == ""__main__"":  
    from pip._vendor.rich.console import Console

    c = Console()
    c.print(""[on blue]Hello"", justify=""right"")
    c.log(""[on blue]hello"", justify=""right"")

from typing import Iterable, Tuple, TypeVar

T = TypeVar(""T"")


def loop_first(values: Iterable[T]) -> Iterable[Tuple[bool, T]]:
    
    iter_values = iter(values)
    try:
        value = next(iter_values)
    except StopIteration:
        return
    yield True, value
    for value in iter_values:
        yield False, value


def loop_last(values: Iterable[T]) -> Iterable[Tuple[bool, T]]:
    
    iter_values = iter(values)
    try:
        previous_value = next(iter_values)
    except StopIteration:
        return
    for value in iter_values:
        yield False, previous_value
        previous_value = value
    yield True, previous_value


def loop_first_last(values: Iterable[T]) -> Iterable[Tuple[bool, bool, T]]:
    
    iter_values = iter(values)
    try:
        previous_value = next(iter_values)
    except StopIteration:
        return
    first = True
    for value in iter_values:
        yield first, False, previous_value
        first = False
        previous_value = value
    yield first, True, previous_value

from types import TracebackType
from typing import IO, Iterable, Iterator, List, Optional, Type


class NullFile(IO[str]):
    def close(self) -> None:
        pass

    def isatty(self) -> bool:
        return False

    def read(self, __n: int = 1) -> str:
        return """"

    def readable(self) -> bool:
        return False

    def readline(self, __limit: int = 1) -> str:
        return """"

    def readlines(self, __hint: int = 1) -> List[str]:
        return []

    def seek(self, __offset: int, __whence: int = 1) -> int:
        return 0

    def seekable(self) -> bool:
        return False

    def tell(self) -> int:
        return 0

    def truncate(self, __size: Optional[int] = 1) -> int:
        return 0

    def writable(self) -> bool:
        return False

    def writelines(self, __lines: Iterable[str]) -> None:
        pass

    def __next__(self) -> str:
        return """"

    def __iter__(self) -> Iterator[str]:
        return iter([""""])

    def __enter__(self) -> IO[str]:
        return self

    def __exit__(
        self,
        __t: Optional[Type[BaseException]],
        __value: Optional[BaseException],
        __traceback: Optional[TracebackType],
    ) -> None:
        pass

    def write(self, text: str) -> int:
        return 0

    def flush(self) -> None:
        pass

    def fileno(self) -> int:
        return -1


NULL_FILE = NullFile()

from .palette import Palette



WINDOWS_PALETTE = Palette(
    [
        (12, 12, 12),
        (197, 15, 31),
        (19, 161, 14),
        (193, 156, 0),
        (0, 55, 218),
        (136, 23, 152),
        (58, 150, 221),
        (204, 204, 204),
        (118, 118, 118),
        (231, 72, 86),
        (22, 198, 12),
        (249, 241, 165),
        (59, 120, 255),
        (180, 0, 158),
        (97, 214, 214),
        (242, 242, 242),
    ]
)


STANDARD_PALETTE = Palette(
    [
        (0, 0, 0),
        (170, 0, 0),
        (0, 170, 0),
        (170, 85, 0),
        (0, 0, 170),
        (170, 0, 170),
        (0, 170, 170),
        (170, 170, 170),
        (85, 85, 85),
        (255, 85, 85),
        (85, 255, 85),
        (255, 255, 85),
        (85, 85, 255),
        (255, 85, 255),
        (85, 255, 255),
        (255, 255, 255),
    ]
)



EIGHT_BIT_PALETTE = Palette(
    [
        (0, 0, 0),
        (128, 0, 0),
        (0, 128, 0),
        (128, 128, 0),
        (0, 0, 128),
        (128, 0, 128),
        (0, 128, 128),
        (192, 192, 192),
        (128, 128, 128),
        (255, 0, 0),
        (0, 255, 0),
        (255, 255, 0),
        (0, 0, 255),
        (255, 0, 255),
        (0, 255, 255),
        (255, 255, 255),
        (0, 0, 0),
        (0, 0, 95),
        (0, 0, 135),
        (0, 0, 175),
        (0, 0, 215),
        (0, 0, 255),
        (0, 95, 0),
        (0, 95, 95),
        (0, 95, 135),
        (0, 95, 175),
        (0, 95, 215),
        (0, 95, 255),
        (0, 135, 0),
        (0, 135, 95),
        (0, 135, 135),
        (0, 135, 175),
        (0, 135, 215),
        (0, 135, 255),
        (0, 175, 0),
        (0, 175, 95),
        (0, 175, 135),
        (0, 175, 175),
        (0, 175, 215),
        (0, 175, 255),
        (0, 215, 0),
        (0, 215, 95),
        (0, 215, 135),
        (0, 215, 175),
        (0, 215, 215),
        (0, 215, 255),
        (0, 255, 0),
        (0, 255, 95),
        (0, 255, 135),
        (0, 255, 175),
        (0, 255, 215),
        (0, 255, 255),
        (95, 0, 0),
        (95, 0, 95),
        (95, 0, 135),
        (95, 0, 175),
        (95, 0, 215),
        (95, 0, 255),
        (95, 95, 0),
        (95, 95, 95),
        (95, 95, 135),
        (95, 95, 175),
        (95, 95, 215),
        (95, 95, 255),
        (95, 135, 0),
        (95, 135, 95),
        (95, 135, 135),
        (95, 135, 175),
        (95, 135, 215),
        (95, 135, 255),
        (95, 175, 0),
        (95, 175, 95),
        (95, 175, 135),
        (95, 175, 175),
        (95, 175, 215),
        (95, 175, 255),
        (95, 215, 0),
        (95, 215, 95),
        (95, 215, 135),
        (95, 215, 175),
        (95, 215, 215),
        (95, 215, 255),
        (95, 255, 0),
        (95, 255, 95),
        (95, 255, 135),
        (95, 255, 175),
        (95, 255, 215),
        (95, 255, 255),
        (135, 0, 0),
        (135, 0, 95),
        (135, 0, 135),
        (135, 0, 175),
        (135, 0, 215),
        (135, 0, 255),
        (135, 95, 0),
        (135, 95, 95),
        (135, 95, 135),
        (135, 95, 175),
        (135, 95, 215),
        (135, 95, 255),
        (135, 135, 0),
        (135, 135, 95),
        (135, 135, 135),
        (135, 135, 175),
        (135, 135, 215),
        (135, 135, 255),
        (135, 175, 0),
        (135, 175, 95),
        (135, 175, 135),
        (135, 175, 175),
        (135, 175, 215),
        (135, 175, 255),
        (135, 215, 0),
        (135, 215, 95),
        (135, 215, 135),
        (135, 215, 175),
        (135, 215, 215),
        (135, 215, 255),
        (135, 255, 0),
        (135, 255, 95),
        (135, 255, 135),
        (135, 255, 175),
        (135, 255, 215),
        (135, 255, 255),
        (175, 0, 0),
        (175, 0, 95),
        (175, 0, 135),
        (175, 0, 175),
        (175, 0, 215),
        (175, 0, 255),
        (175, 95, 0),
        (175, 95, 95),
        (175, 95, 135),
        (175, 95, 175),
        (175, 95, 215),
        (175, 95, 255),
        (175, 135, 0),
        (175, 135, 95),
        (175, 135, 135),
        (175, 135, 175),
        (175, 135, 215),
        (175, 135, 255),
        (175, 175, 0),
        (175, 175, 95),
        (175, 175, 135),
        (175, 175, 175),
        (175, 175, 215),
        (175, 175, 255),
        (175, 215, 0),
        (175, 215, 95),
        (175, 215, 135),
        (175, 215, 175),
        (175, 215, 215),
        (175, 215, 255),
        (175, 255, 0),
        (175, 255, 95),
        (175, 255, 135),
        (175, 255, 175),
        (175, 255, 215),
        (175, 255, 255),
        (215, 0, 0),
        (215, 0, 95),
        (215, 0, 135),
        (215, 0, 175),
        (215, 0, 215),
        (215, 0, 255),
        (215, 95, 0),
        (215, 95, 95),
        (215, 95, 135),
        (215, 95, 175),
        (215, 95, 215),
        (215, 95, 255),
        (215, 135, 0),
        (215, 135, 95),
        (215, 135, 135),
        (215, 135, 175),
        (215, 135, 215),
        (215, 135, 255),
        (215, 175, 0),
        (215, 175, 95),
        (215, 175, 135),
        (215, 175, 175),
        (215, 175, 215),
        (215, 175, 255),
        (215, 215, 0),
        (215, 215, 95),
        (215, 215, 135),
        (215, 215, 175),
        (215, 215, 215),
        (215, 215, 255),
        (215, 255, 0),
        (215, 255, 95),
        (215, 255, 135),
        (215, 255, 175),
        (215, 255, 215),
        (215, 255, 255),
        (255, 0, 0),
        (255, 0, 95),
        (255, 0, 135),
        (255, 0, 175),
        (255, 0, 215),
        (255, 0, 255),
        (255, 95, 0),
        (255, 95, 95),
        (255, 95, 135),
        (255, 95, 175),
        (255, 95, 215),
        (255, 95, 255),
        (255, 135, 0),
        (255, 135, 95),
        (255, 135, 135),
        (255, 135, 175),
        (255, 135, 215),
        (255, 135, 255),
        (255, 175, 0),
        (255, 175, 95),
        (255, 175, 135),
        (255, 175, 175),
        (255, 175, 215),
        (255, 175, 255),
        (255, 215, 0),
        (255, 215, 95),
        (255, 215, 135),
        (255, 215, 175),
        (255, 215, 215),
        (255, 215, 255),
        (255, 255, 0),
        (255, 255, 95),
        (255, 255, 135),
        (255, 255, 175),
        (255, 255, 215),
        (255, 255, 255),
        (8, 8, 8),
        (18, 18, 18),
        (28, 28, 28),
        (38, 38, 38),
        (48, 48, 48),
        (58, 58, 58),
        (68, 68, 68),
        (78, 78, 78),
        (88, 88, 88),
        (98, 98, 98),
        (108, 108, 108),
        (118, 118, 118),
        (128, 128, 128),
        (138, 138, 138),
        (148, 148, 148),
        (158, 158, 158),
        (168, 168, 168),
        (178, 178, 178),
        (188, 188, 188),
        (198, 198, 198),
        (208, 208, 208),
        (218, 218, 218),
        (228, 228, 228),
        (238, 238, 238),
    ]
)

from typing import Optional


def pick_bool(*values: Optional[bool]) -> bool:
    
    assert values, ""1 or more values required""
    for value in values:
        if value is not None:
            return value
    return bool(value)

from fractions import Fraction
from math import ceil
from typing import cast, List, Optional, Sequence, Protocol


class Edge(Protocol):
    

    size: Optional[int] = None
    ratio: int = 1
    minimum_size: int = 1


def ratio_resolve(total: int, edges: Sequence[Edge]) -> List[int]:
    
    
    sizes = [(edge.size or None) for edge in edges]

    _Fraction = Fraction

    
    while None in sizes:
        
        flexible_edges = [
            (index, edge)
            for index, (size, edge) in enumerate(zip(sizes, edges))
            if size is None
        ]
        
        remaining = total - sum(size or 0 for size in sizes)
        if remaining <= 0:
            
            return [
                ((edge.minimum_size or 1) if size is None else size)
                for size, edge in zip(sizes, edges)
            ]
        
        portion = _Fraction(
            remaining, sum((edge.ratio or 1) for _, edge in flexible_edges)
        )

        
        for index, edge in flexible_edges:
            if portion * edge.ratio <= edge.minimum_size:
                sizes[index] = edge.minimum_size
                
                break
        else:
            
            
            
            remainder = _Fraction(0)
            for index, edge in flexible_edges:
                size, remainder = divmod(portion * edge.ratio + remainder, 1)
                sizes[index] = size
            break
    
    return cast(List[int], sizes)


def ratio_reduce(
    total: int, ratios: List[int], maximums: List[int], values: List[int]
) -> List[int]:
    
    ratios = [ratio if _max else 0 for ratio, _max in zip(ratios, maximums)]
    total_ratio = sum(ratios)
    if not total_ratio:
        return values[:]
    total_remaining = total
    result: List[int] = []
    append = result.append
    for ratio, maximum, value in zip(ratios, maximums, values):
        if ratio and total_ratio > 0:
            distributed = min(maximum, round(ratio * total_remaining / total_ratio))
            append(value - distributed)
            total_remaining -= distributed
            total_ratio -= ratio
        else:
            append(value)
    return result


def ratio_distribute(
    total: int, ratios: List[int], minimums: Optional[List[int]] = None
) -> List[int]:
    
    if minimums:
        ratios = [ratio if _min else 0 for ratio, _min in zip(ratios, minimums)]
    total_ratio = sum(ratios)
    assert total_ratio > 0, ""Sum of ratios must be > 0""

    total_remaining = total
    distributed_total: List[int] = []
    append = distributed_total.append
    if minimums is None:
        _minimums = [0] * len(ratios)
    else:
        _minimums = minimums
    for ratio, minimum in zip(ratios, _minimums):
        if total_ratio > 0:
            distributed = max(minimum, ceil(ratio * total_remaining / total_ratio))
        else:
            distributed = total_remaining
        append(distributed)
        total_ratio -= ratio
        total_remaining -= distributed
    return distributed_total


if __name__ == ""__main__"":
    from dataclasses import dataclass

    @dataclass
    class E:
        size: Optional[int] = None
        ratio: int = 1
        minimum_size: int = 1

    resolved = ratio_resolve(110, [E(None, 1, 1), E(None, 1, 1), E(None, 1, 1)])
    print(sum(resolved))



SPINNERS = {
    ""dots"": {
        ""interval"": 80,
        ""frames"": ""⠋⠙⠹⠸⠼⠴⠦⠧⠇⠏"",
    },
    ""dots2"": {""interval"": 80, ""frames"": ""⣾⣽⣻⢿⡿⣟⣯⣷""},
    ""dots3"": {
        ""interval"": 80,
        ""frames"": ""⠋⠙⠚⠞⠖⠦⠴⠲⠳⠓"",
    },
    ""dots4"": {
        ""interval"": 80,
        ""frames"": ""⠄⠆⠇⠋⠙⠸⠰⠠⠰⠸⠙⠋⠇⠆"",
    },
    ""dots5"": {
        ""interval"": 80,
        ""frames"": ""⠋⠙⠚⠒⠂⠂⠒⠲⠴⠦⠖⠒⠐⠐⠒⠓⠋"",
    },
    ""dots6"": {
        ""interval"": 80,
        ""frames"": ""⠁⠉⠙⠚⠒⠂⠂⠒⠲⠴⠤⠄⠄⠤⠴⠲⠒⠂⠂⠒⠚⠙⠉⠁"",
    },
    ""dots7"": {
        ""interval"": 80,
        ""frames"": ""⠈⠉⠋⠓⠒⠐⠐⠒⠖⠦⠤⠠⠠⠤⠦⠖⠒⠐⠐⠒⠓⠋⠉⠈"",
    },
    ""dots8"": {
        ""interval"": 80,
        ""frames"": ""⠁⠁⠉⠙⠚⠒⠂⠂⠒⠲⠴⠤⠄⠄⠤⠠⠠⠤⠦⠖⠒⠐⠐⠒⠓⠋⠉⠈⠈"",
    },
    ""dots9"": {""interval"": 80, ""frames"": ""⢹⢺⢼⣸⣇⡧⡗⡏""},
    ""dots10"": {""interval"": 80, ""frames"": ""⢄⢂⢁⡁⡈⡐⡠""},
    ""dots11"": {""interval"": 100, ""frames"": ""⠁⠂⠄⡀⢀⠠⠐⠈""},
    ""dots12"": {
        ""interval"": 80,
        ""frames"": [
            ""⢀⠀"",
            ""⡀⠀"",
            ""⠄⠀"",
            ""⢂⠀"",
            ""⡂⠀"",
            ""⠅⠀"",
            ""⢃⠀"",
            ""⡃⠀"",
            ""⠍⠀"",
            ""⢋⠀"",
            ""⡋⠀"",
            ""⠍⠁"",
            ""⢋⠁"",
            ""⡋⠁"",
            ""⠍⠉"",
            ""⠋⠉"",
            ""⠋⠉"",
            ""⠉⠙"",
            ""⠉⠙"",
            ""⠉⠩"",
            ""⠈⢙"",
            ""⠈⡙"",
            ""⢈⠩"",
            ""⡀⢙"",
            ""⠄⡙"",
            ""⢂⠩"",
            ""⡂⢘"",
            ""⠅⡘"",
            ""⢃⠨"",
            ""⡃⢐"",
            ""⠍⡐"",
            ""⢋⠠"",
            ""⡋⢀"",
            ""⠍⡁"",
            ""⢋⠁"",
            ""⡋⠁"",
            ""⠍⠉"",
            ""⠋⠉"",
            ""⠋⠉"",
            ""⠉⠙"",
            ""⠉⠙"",
            ""⠉⠩"",
            ""⠈⢙"",
            ""⠈⡙"",
            ""⠈⠩"",
            ""⠀⢙"",
            ""⠀⡙"",
            ""⠀⠩"",
            ""⠀⢘"",
            ""⠀⡘"",
            ""⠀⠨"",
            ""⠀⢐"",
            ""⠀⡐"",
            ""⠀⠠"",
            ""⠀⢀"",
            ""⠀⡀"",
        ],
    },
    ""dots8Bit"": {
        ""interval"": 80,
        ""frames"": ""⠀⠁⠂⠃⠄⠅⠆⠇⡀⡁⡂⡃⡄⡅⡆⡇⠈⠉⠊⠋⠌⠍⠎⠏⡈⡉⡊⡋⡌⡍⡎⡏⠐⠑⠒⠓⠔⠕⠖⠗⡐⡑⡒⡓⡔⡕⡖⡗⠘⠙⠚⠛⠜⠝⠞⠟⡘⡙""
        ""⡚⡛⡜⡝⡞⡟⠠⠡⠢⠣⠤⠥⠦⠧⡠⡡⡢⡣⡤⡥⡦⡧⠨⠩⠪⠫⠬⠭⠮⠯⡨⡩⡪⡫⡬⡭⡮⡯⠰⠱⠲⠳⠴⠵⠶⠷⡰⡱⡲⡳⡴⡵⡶⡷⠸⠹⠺⠻""
        ""⠼⠽⠾⠿⡸⡹⡺⡻⡼⡽⡾⡿⢀⢁⢂⢃⢄⢅⢆⢇⣀⣁⣂⣃⣄⣅⣆⣇⢈⢉⢊⢋⢌⢍⢎⢏⣈⣉⣊⣋⣌⣍⣎⣏⢐⢑⢒⢓⢔⢕⢖⢗⣐⣑⣒⣓⣔⣕""
        ""⣖⣗⢘⢙⢚⢛⢜⢝⢞⢟⣘⣙⣚⣛⣜⣝⣞⣟⢠⢡⢢⢣⢤⢥⢦⢧⣠⣡⣢⣣⣤⣥⣦⣧⢨⢩⢪⢫⢬⢭⢮⢯⣨⣩⣪⣫⣬⣭⣮⣯⢰⢱⢲⢳⢴⢵⢶⢷""
        ""⣰⣱⣲⣳⣴⣵⣶⣷⢸⢹⢺⢻⢼⢽⢾⢿⣸⣹⣺⣻⣼⣽⣾⣿"",
    },
    ""line"": {""interval"": 130, ""frames"": [""-"", ""\\"", ""|"", ""/""]},
    ""line2"": {""interval"": 100, ""frames"": ""⠂-–—–-""},
    ""pipe"": {""interval"": 100, ""frames"": ""┤┘┴└├┌┬┐""},
    ""simpleDots"": {""interval"": 400, ""frames"": ["".  "", "".. "", ""..."", ""   ""]},
    ""simpleDotsScrolling"": {
        ""interval"": 200,
        ""frames"": ["".  "", "".. "", ""..."", "" .."", ""  ."", ""   ""],
    },
    ""star"": {""interval"": 70, ""frames"": ""✶✸✹✺✹✷""},
    ""star2"": {""interval"": 80, ""frames"": ""+x*""},
    ""flip"": {
        ""interval"": 70,
        ""frames"": ""___-``'´-___"",
    },
    ""hamburger"": {""interval"": 100, ""frames"": ""☱☲☴""},
    ""growVertical"": {
        ""interval"": 120,
        ""frames"": ""▁▃▄▅▆▇▆▅▄▃"",
    },
    ""growHorizontal"": {
        ""interval"": 120,
        ""frames"": ""▏▎▍▌▋▊▉▊▋▌▍▎"",
    },
    ""balloon"": {""interval"": 140, ""frames"": "" .oO@* ""},
    ""balloon2"": {""interval"": 120, ""frames"": "".oO°Oo.""},
    ""noise"": {""interval"": 100, ""frames"": ""▓▒░""},
    ""bounce"": {""interval"": 120, ""frames"": ""⠁⠂⠄⠂""},
    ""boxBounce"": {""interval"": 120, ""frames"": ""▖▘▝▗""},
    ""boxBounce2"": {""interval"": 100, ""frames"": ""▌▀▐▄""},
    ""triangle"": {""interval"": 50, ""frames"": ""◢◣◤◥""},
    ""arc"": {""interval"": 100, ""frames"": ""◜◠◝◞◡◟""},
    ""circle"": {""interval"": 120, ""frames"": ""◡⊙◠""},
    ""squareCorners"": {""interval"": 180, ""frames"": ""◰◳◲◱""},
    ""circleQuarters"": {""interval"": 120, ""frames"": ""◴◷◶◵""},
    ""circleHalves"": {""interval"": 50, ""frames"": ""◐◓◑◒""},
    ""squish"": {""interval"": 100, ""frames"": ""╫╪""},
    ""toggle"": {""interval"": 250, ""frames"": ""⊶⊷""},
    ""toggle2"": {""interval"": 80, ""frames"": ""▫▪""},
    ""toggle3"": {""interval"": 120, ""frames"": ""□■""},
    ""toggle4"": {""interval"": 100, ""frames"": ""■□▪▫""},
    ""toggle5"": {""interval"": 100, ""frames"": ""▮▯""},
    ""toggle6"": {""interval"": 300, ""frames"": ""ဝ၀""},
    ""toggle7"": {""interval"": 80, ""frames"": ""⦾⦿""},
    ""toggle8"": {""interval"": 100, ""frames"": ""◍◌""},
    ""toggle9"": {""interval"": 100, ""frames"": ""◉◎""},
    ""toggle10"": {""interval"": 100, ""frames"": ""㊂㊀㊁""},
    ""toggle11"": {""interval"": 50, ""frames"": ""⧇⧆""},
    ""toggle12"": {""interval"": 120, ""frames"": ""☗☖""},
    ""toggle13"": {""interval"": 80, ""frames"": ""=*-""},
    ""arrow"": {""interval"": 100, ""frames"": ""←↖↑↗→↘↓↙""},
    ""arrow2"": {
        ""interval"": 80,
        ""frames"": [""⬆️ "", ""↗️ "", ""➡️ "", ""↘️ "", ""⬇️ "", ""↙️ "", ""⬅️ "", ""↖️ ""],
    },
    ""arrow3"": {
        ""interval"": 120,
        ""frames"": [""▹▹▹▹▹"", ""▸▹▹▹▹"", ""▹▸▹▹▹"", ""▹▹▸▹▹"", ""▹▹▹▸▹"", ""▹▹▹▹▸""],
    },
    ""bouncingBar"": {
        ""interval"": 80,
        ""frames"": [
            ""[    ]"",
            ""[=   ]"",
            ""[==  ]"",
            ""[=== ]"",
            ""[ ===]"",
            ""[  ==]"",
            ""[   =]"",
            ""[    ]"",
            ""[   =]"",
            ""[  ==]"",
            ""[ ===]"",
            ""[====]"",
            ""[=== ]"",
            ""[==  ]"",
            ""[=   ]"",
        ],
    },
    ""bouncingBall"": {
        ""interval"": 80,
        ""frames"": [
            ""( ●    )"",
            ""(  ●   )"",
            ""(   ●  )"",
            ""(    ● )"",
            ""(     ●)"",
            ""(    ● )"",
            ""(   ●  )"",
            ""(  ●   )"",
            ""( ●    )"",
            ""(●     )"",
        ],
    },
    ""smiley"": {""interval"": 200, ""frames"": [""😄 "", ""😝 ""]},
    ""monkey"": {""interval"": 300, ""frames"": [""🙈 "", ""🙈 "", ""🙉 "", ""🙊 ""]},
    ""hearts"": {""interval"": 100, ""frames"": [""💛 "", ""💙 "", ""💜 "", ""💚 "", ""❤️ ""]},
    ""clock"": {
        ""interval"": 100,
        ""frames"": [
            ""🕛 "",
            ""🕐 "",
            ""🕑 "",
            ""🕒 "",
            ""🕓 "",
            ""🕔 "",
            ""🕕 "",
            ""🕖 "",
            ""🕗 "",
            ""🕘 "",
            ""🕙 "",
            ""🕚 "",
        ],
    },
    ""earth"": {""interval"": 180, ""frames"": [""🌍 "", ""🌎 "", ""🌏 ""]},
    ""material"": {
        ""interval"": 17,
        ""frames"": [
            ""█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁"",
            ""██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁"",
            ""███▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁"",
            ""████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁"",
            ""██████▁▁▁▁▁▁▁▁▁▁▁▁▁▁"",
            ""██████▁▁▁▁▁▁▁▁▁▁▁▁▁▁"",
            ""███████▁▁▁▁▁▁▁▁▁▁▁▁▁"",
            ""████████▁▁▁▁▁▁▁▁▁▁▁▁"",
            ""█████████▁▁▁▁▁▁▁▁▁▁▁"",
            ""█████████▁▁▁▁▁▁▁▁▁▁▁"",
            ""██████████▁▁▁▁▁▁▁▁▁▁"",
            ""███████████▁▁▁▁▁▁▁▁▁"",
            ""█████████████▁▁▁▁▁▁▁"",
            ""██████████████▁▁▁▁▁▁"",
            ""██████████████▁▁▁▁▁▁"",
            ""▁██████████████▁▁▁▁▁"",
            ""▁██████████████▁▁▁▁▁"",
            ""▁██████████████▁▁▁▁▁"",
            ""▁▁██████████████▁▁▁▁"",
            ""▁▁▁██████████████▁▁▁"",
            ""▁▁▁▁█████████████▁▁▁"",
            ""▁▁▁▁██████████████▁▁"",
            ""▁▁▁▁██████████████▁▁"",
            ""▁▁▁▁▁██████████████▁"",
            ""▁▁▁▁▁██████████████▁"",
            ""▁▁▁▁▁██████████████▁"",
            ""▁▁▁▁▁▁██████████████"",
            ""▁▁▁▁▁▁██████████████"",
            ""▁▁▁▁▁▁▁█████████████"",
            ""▁▁▁▁▁▁▁█████████████"",
            ""▁▁▁▁▁▁▁▁████████████"",
            ""▁▁▁▁▁▁▁▁████████████"",
            ""▁▁▁▁▁▁▁▁▁███████████"",
            ""▁▁▁▁▁▁▁▁▁███████████"",
            ""▁▁▁▁▁▁▁▁▁▁██████████"",
            ""▁▁▁▁▁▁▁▁▁▁██████████"",
            ""▁▁▁▁▁▁▁▁▁▁▁▁████████"",
            ""▁▁▁▁▁▁▁▁▁▁▁▁▁███████"",
            ""▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████"",
            ""▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█████"",
            ""▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█████"",
            ""█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████"",
            ""██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███"",
            ""██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███"",
            ""███▁▁▁▁▁▁▁▁▁▁▁▁▁▁███"",
            ""████▁▁▁▁▁▁▁▁▁▁▁▁▁▁██"",
            ""█████▁▁▁▁▁▁▁▁▁▁▁▁▁▁█"",
            ""█████▁▁▁▁▁▁▁▁▁▁▁▁▁▁█"",
            ""██████▁▁▁▁▁▁▁▁▁▁▁▁▁█"",
            ""████████▁▁▁▁▁▁▁▁▁▁▁▁"",
            ""█████████▁▁▁▁▁▁▁▁▁▁▁"",
            ""█████████▁▁▁▁▁▁▁▁▁▁▁"",
            ""█████████▁▁▁▁▁▁▁▁▁▁▁"",
            ""█████████▁▁▁▁▁▁▁▁▁▁▁"",
            ""███████████▁▁▁▁▁▁▁▁▁"",
            ""████████████▁▁▁▁▁▁▁▁"",
            ""████████████▁▁▁▁▁▁▁▁"",
            ""██████████████▁▁▁▁▁▁"",
            ""██████████████▁▁▁▁▁▁"",
            ""▁██████████████▁▁▁▁▁"",
            ""▁██████████████▁▁▁▁▁"",
            ""▁▁▁█████████████▁▁▁▁"",
            ""▁▁▁▁▁████████████▁▁▁"",
            ""▁▁▁▁▁████████████▁▁▁"",
            ""▁▁▁▁▁▁███████████▁▁▁"",
            ""▁▁▁▁▁▁▁▁█████████▁▁▁"",
            ""▁▁▁▁▁▁▁▁█████████▁▁▁"",
            ""▁▁▁▁▁▁▁▁▁█████████▁▁"",
            ""▁▁▁▁▁▁▁▁▁█████████▁▁"",
            ""▁▁▁▁▁▁▁▁▁▁█████████▁"",
            ""▁▁▁▁▁▁▁▁▁▁▁████████▁"",
            ""▁▁▁▁▁▁▁▁▁▁▁████████▁"",
            ""▁▁▁▁▁▁▁▁▁▁▁▁███████▁"",
            ""▁▁▁▁▁▁▁▁▁▁▁▁███████▁"",
            ""▁▁▁▁▁▁▁▁▁▁▁▁▁███████"",
            ""▁▁▁▁▁▁▁▁▁▁▁▁▁███████"",
            ""▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█████"",
            ""▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████"",
            ""▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████"",
            ""▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████"",
            ""▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███"",
            ""▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███"",
            ""▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██"",
            ""▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██"",
            ""▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██"",
            ""▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█"",
            ""▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█"",
            ""▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█"",
            ""▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁"",
            ""▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁"",
            ""▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁"",
            ""▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁"",
        ],
    },
    ""moon"": {
        ""interval"": 80,
        ""frames"": [""🌑 "", ""🌒 "", ""🌓 "", ""🌔 "", ""🌕 "", ""🌖 "", ""🌗 "", ""🌘 ""],
    },
    ""runner"": {""interval"": 140, ""frames"": [""🚶 "", ""🏃 ""]},
    ""pong"": {
        ""interval"": 80,
        ""frames"": [
            ""▐⠂       ▌"",
            ""▐⠈       ▌"",
            ""▐ ⠂      ▌"",
            ""▐ ⠠      ▌"",
            ""▐  ⡀     ▌"",
            ""▐  ⠠     ▌"",
            ""▐   ⠂    ▌"",
            ""▐   ⠈    ▌"",
            ""▐    ⠂   ▌"",
            ""▐    ⠠   ▌"",
            ""▐     ⡀  ▌"",
            ""▐     ⠠  ▌"",
            ""▐      ⠂ ▌"",
            ""▐      ⠈ ▌"",
            ""▐       ⠂▌"",
            ""▐       ⠠▌"",
            ""▐       ⡀▌"",
            ""▐      ⠠ ▌"",
            ""▐      ⠂ ▌"",
            ""▐     ⠈  ▌"",
            ""▐     ⠂  ▌"",
            ""▐    ⠠   ▌"",
            ""▐    ⡀   ▌"",
            ""▐   ⠠    ▌"",
            ""▐   ⠂    ▌"",
            ""▐  ⠈     ▌"",
            ""▐  ⠂     ▌"",
            ""▐ ⠠      ▌"",
            ""▐ ⡀      ▌"",
            ""▐⠠       ▌"",
        ],
    },
    ""shark"": {
        ""interval"": 120,
        ""frames"": [
            ""▐|\\____________▌"",
            ""▐_|\\___________▌"",
            ""▐__|\\__________▌"",
            ""▐___|\\_________▌"",
            ""▐____|\\________▌"",
            ""▐_____|\\_______▌"",
            ""▐______|\\______▌"",
            ""▐_______|\\_____▌"",
            ""▐________|\\____▌"",
            ""▐_________|\\___▌"",
            ""▐__________|\\__▌"",
            ""▐___________|\\_▌"",
            ""▐____________|\\▌"",
            ""▐____________/|▌"",
            ""▐___________/|_▌"",
            ""▐__________/|__▌"",
            ""▐_________/|___▌"",
            ""▐________/|____▌"",
            ""▐_______/|_____▌"",
            ""▐______/|______▌"",
            ""▐_____/|_______▌"",
            ""▐____/|________▌"",
            ""▐___/|_________▌"",
            ""▐__/|__________▌"",
            ""▐_/|___________▌"",
            ""▐/|____________▌"",
        ],
    },
    ""dqpb"": {""interval"": 100, ""frames"": ""dqpb""},
    ""weather"": {
        ""interval"": 100,
        ""frames"": [
            ""☀️ "",
            ""☀️ "",
            ""☀️ "",
            ""🌤 "",
            ""⛅️ "",
            ""🌥 "",
            ""☁️ "",
            ""🌧 "",
            ""🌨 "",
            ""🌧 "",
            ""🌨 "",
            ""🌧 "",
            ""🌨 "",
            ""⛈ "",
            ""🌨 "",
            ""🌧 "",
            ""🌨 "",
            ""☁️ "",
            ""🌥 "",
            ""⛅️ "",
            ""🌤 "",
            ""☀️ "",
            ""☀️ "",
        ],
    },
    ""christmas"": {""interval"": 400, ""frames"": ""🌲🎄""},
    ""grenade"": {
        ""interval"": 80,
        ""frames"": [
            ""،   "",
            ""′   "",
            "" ´ "",
            "" ‾ "",
            ""  ⸌"",
            ""  ⸊"",
            ""  |"",
            ""  ⁎"",
            ""  ⁕"",
            "" ෴ "",
            ""  ⁓"",
            ""   "",
            ""   "",
            ""   "",
        ],
    },
    ""point"": {""interval"": 125, ""frames"": [""∙∙∙"", ""●∙∙"", ""∙●∙"", ""∙∙●"", ""∙∙∙""]},
    ""layer"": {""interval"": 150, ""frames"": ""-=≡""},
    ""betaWave"": {
        ""interval"": 80,
        ""frames"": [
            ""ρββββββ"",
            ""βρβββββ"",
            ""ββρββββ"",
            ""βββρβββ"",
            ""ββββρββ"",
            ""βββββρβ"",
            ""ββββββρ"",
        ],
    },
    ""aesthetic"": {
        ""interval"": 80,
        ""frames"": [
            ""▰▱▱▱▱▱▱"",
            ""▰▰▱▱▱▱▱"",
            ""▰▰▰▱▱▱▱"",
            ""▰▰▰▰▱▱▱"",
            ""▰▰▰▰▰▱▱"",
            ""▰▰▰▰▰▰▱"",
            ""▰▰▰▰▰▰▰"",
            ""▰▱▱▱▱▱▱"",
        ],
    },
}

from typing import List, TypeVar

T = TypeVar(""T"")


class Stack(List[T]):
    

    @property
    def top(self) -> T:
        
        return self[-1]

    def push(self, item: T) -> None:
        
        self.append(item)



from time import time

import contextlib
from typing import Generator


@contextlib.contextmanager
def timer(subject: str = ""time"") -> Generator[None, None, None]:
    
    start = time()
    yield
    elapsed = time() - start
    elapsed_ms = elapsed * 1000
    print(f""{subject} elapsed {elapsed_ms:.1f}ms"")



import ctypes
import sys
from typing import Any

windll: Any = None
if sys.platform == ""win32"":
    windll = ctypes.LibraryLoader(ctypes.WinDLL)
else:
    raise ImportError(f""{__name__} can only be imported on Windows"")

import time
from ctypes import Structure, byref, wintypes
from typing import IO, NamedTuple, Type, cast

from pip._vendor.rich.color import ColorSystem
from pip._vendor.rich.style import Style

STDOUT = -11
ENABLE_VIRTUAL_TERMINAL_PROCESSING = 4

COORD = wintypes._COORD


class LegacyWindowsError(Exception):
    pass


class WindowsCoordinates(NamedTuple):
    

    row: int
    col: int

    @classmethod
    def from_param(cls, value: ""WindowsCoordinates"") -> COORD:
        
        return COORD(value.col, value.row)


class CONSOLE_SCREEN_BUFFER_INFO(Structure):
    _fields_ = [
        (""dwSize"", COORD),
        (""dwCursorPosition"", COORD),
        (""wAttributes"", wintypes.WORD),
        (""srWindow"", wintypes.SMALL_RECT),
        (""dwMaximumWindowSize"", COORD),
    ]


class CONSOLE_CURSOR_INFO(ctypes.Structure):
    _fields_ = [(""dwSize"", wintypes.DWORD), (""bVisible"", wintypes.BOOL)]


_GetStdHandle = windll.kernel32.GetStdHandle
_GetStdHandle.argtypes = [
    wintypes.DWORD,
]
_GetStdHandle.restype = wintypes.HANDLE


def GetStdHandle(handle: int = STDOUT) -> wintypes.HANDLE:
    
    return cast(wintypes.HANDLE, _GetStdHandle(handle))


_GetConsoleMode = windll.kernel32.GetConsoleMode
_GetConsoleMode.argtypes = [wintypes.HANDLE, wintypes.LPDWORD]
_GetConsoleMode.restype = wintypes.BOOL


def GetConsoleMode(std_handle: wintypes.HANDLE) -> int:
    

    console_mode = wintypes.DWORD()
    success = bool(_GetConsoleMode(std_handle, console_mode))
    if not success:
        raise LegacyWindowsError(""Unable to get legacy Windows Console Mode"")
    return console_mode.value


_FillConsoleOutputCharacterW = windll.kernel32.FillConsoleOutputCharacterW
_FillConsoleOutputCharacterW.argtypes = [
    wintypes.HANDLE,
    ctypes.c_char,
    wintypes.DWORD,
    cast(Type[COORD], WindowsCoordinates),
    ctypes.POINTER(wintypes.DWORD),
]
_FillConsoleOutputCharacterW.restype = wintypes.BOOL


def FillConsoleOutputCharacter(
    std_handle: wintypes.HANDLE,
    char: str,
    length: int,
    start: WindowsCoordinates,
) -> int:
    
    character = ctypes.c_char(char.encode())
    num_characters = wintypes.DWORD(length)
    num_written = wintypes.DWORD(0)
    _FillConsoleOutputCharacterW(
        std_handle,
        character,
        num_characters,
        start,
        byref(num_written),
    )
    return num_written.value


_FillConsoleOutputAttribute = windll.kernel32.FillConsoleOutputAttribute
_FillConsoleOutputAttribute.argtypes = [
    wintypes.HANDLE,
    wintypes.WORD,
    wintypes.DWORD,
    cast(Type[COORD], WindowsCoordinates),
    ctypes.POINTER(wintypes.DWORD),
]
_FillConsoleOutputAttribute.restype = wintypes.BOOL


def FillConsoleOutputAttribute(
    std_handle: wintypes.HANDLE,
    attributes: int,
    length: int,
    start: WindowsCoordinates,
) -> int:
    
    num_cells = wintypes.DWORD(length)
    style_attrs = wintypes.WORD(attributes)
    num_written = wintypes.DWORD(0)
    _FillConsoleOutputAttribute(
        std_handle, style_attrs, num_cells, start, byref(num_written)
    )
    return num_written.value


_SetConsoleTextAttribute = windll.kernel32.SetConsoleTextAttribute
_SetConsoleTextAttribute.argtypes = [
    wintypes.HANDLE,
    wintypes.WORD,
]
_SetConsoleTextAttribute.restype = wintypes.BOOL


def SetConsoleTextAttribute(
    std_handle: wintypes.HANDLE, attributes: wintypes.WORD
) -> bool:
    
    return bool(_SetConsoleTextAttribute(std_handle, attributes))


_GetConsoleScreenBufferInfo = windll.kernel32.GetConsoleScreenBufferInfo
_GetConsoleScreenBufferInfo.argtypes = [
    wintypes.HANDLE,
    ctypes.POINTER(CONSOLE_SCREEN_BUFFER_INFO),
]
_GetConsoleScreenBufferInfo.restype = wintypes.BOOL


def GetConsoleScreenBufferInfo(
    std_handle: wintypes.HANDLE,
) -> CONSOLE_SCREEN_BUFFER_INFO:
    
    console_screen_buffer_info = CONSOLE_SCREEN_BUFFER_INFO()
    _GetConsoleScreenBufferInfo(std_handle, byref(console_screen_buffer_info))
    return console_screen_buffer_info


_SetConsoleCursorPosition = windll.kernel32.SetConsoleCursorPosition
_SetConsoleCursorPosition.argtypes = [
    wintypes.HANDLE,
    cast(Type[COORD], WindowsCoordinates),
]
_SetConsoleCursorPosition.restype = wintypes.BOOL


def SetConsoleCursorPosition(
    std_handle: wintypes.HANDLE, coords: WindowsCoordinates
) -> bool:
    
    return bool(_SetConsoleCursorPosition(std_handle, coords))


_GetConsoleCursorInfo = windll.kernel32.GetConsoleCursorInfo
_GetConsoleCursorInfo.argtypes = [
    wintypes.HANDLE,
    ctypes.POINTER(CONSOLE_CURSOR_INFO),
]
_GetConsoleCursorInfo.restype = wintypes.BOOL


def GetConsoleCursorInfo(
    std_handle: wintypes.HANDLE, cursor_info: CONSOLE_CURSOR_INFO
) -> bool:
    
    return bool(_GetConsoleCursorInfo(std_handle, byref(cursor_info)))


_SetConsoleCursorInfo = windll.kernel32.SetConsoleCursorInfo
_SetConsoleCursorInfo.argtypes = [
    wintypes.HANDLE,
    ctypes.POINTER(CONSOLE_CURSOR_INFO),
]
_SetConsoleCursorInfo.restype = wintypes.BOOL


def SetConsoleCursorInfo(
    std_handle: wintypes.HANDLE, cursor_info: CONSOLE_CURSOR_INFO
) -> bool:
    
    return bool(_SetConsoleCursorInfo(std_handle, byref(cursor_info)))


_SetConsoleTitle = windll.kernel32.SetConsoleTitleW
_SetConsoleTitle.argtypes = [wintypes.LPCWSTR]
_SetConsoleTitle.restype = wintypes.BOOL


def SetConsoleTitle(title: str) -> bool:
    
    return bool(_SetConsoleTitle(title))


class LegacyWindowsTerm:
    

    BRIGHT_BIT = 8

    
    ANSI_TO_WINDOWS = [
        0,  
        4,  
        2,  
        6,  
        1,  
        5,  
        3,  
        7,  
        8,  
        12,  
        10,  
        14,  
        9,  
        13,  
        11,  
        15,  
    ]

    def __init__(self, file: ""IO[str]"") -> None:
        handle = GetStdHandle(STDOUT)
        self._handle = handle
        default_text = GetConsoleScreenBufferInfo(handle).wAttributes
        self._default_text = default_text

        self._default_fore = default_text & 7
        self._default_back = (default_text >> 4) & 7
        self._default_attrs = self._default_fore | (self._default_back << 4)

        self._file = file
        self.write = file.write
        self.flush = file.flush

    @property
    def cursor_position(self) -> WindowsCoordinates:
        
        coord: COORD = GetConsoleScreenBufferInfo(self._handle).dwCursorPosition
        return WindowsCoordinates(row=coord.Y, col=coord.X)

    @property
    def screen_size(self) -> WindowsCoordinates:
        
        screen_size: COORD = GetConsoleScreenBufferInfo(self._handle).dwSize
        return WindowsCoordinates(row=screen_size.Y, col=screen_size.X)

    def write_text(self, text: str) -> None:
        
        self.write(text)
        self.flush()

    def write_styled(self, text: str, style: Style) -> None:
        
        color = style.color
        bgcolor = style.bgcolor
        if style.reverse:
            color, bgcolor = bgcolor, color

        if color:
            fore = color.downgrade(ColorSystem.WINDOWS).number
            fore = fore if fore is not None else 7  
            if style.bold:
                fore = fore | self.BRIGHT_BIT
            if style.dim:
                fore = fore & ~self.BRIGHT_BIT
            fore = self.ANSI_TO_WINDOWS[fore]
        else:
            fore = self._default_fore

        if bgcolor:
            back = bgcolor.downgrade(ColorSystem.WINDOWS).number
            back = back if back is not None else 0  
            back = self.ANSI_TO_WINDOWS[back]
        else:
            back = self._default_back

        assert fore is not None
        assert back is not None

        SetConsoleTextAttribute(
            self._handle, attributes=ctypes.c_ushort(fore | (back << 4))
        )
        self.write_text(text)
        SetConsoleTextAttribute(self._handle, attributes=self._default_text)

    def move_cursor_to(self, new_position: WindowsCoordinates) -> None:
        
        if new_position.col < 0 or new_position.row < 0:
            return
        SetConsoleCursorPosition(self._handle, coords=new_position)

    def erase_line(self) -> None:
        
        screen_size = self.screen_size
        cursor_position = self.cursor_position
        cells_to_erase = screen_size.col
        start_coordinates = WindowsCoordinates(row=cursor_position.row, col=0)
        FillConsoleOutputCharacter(
            self._handle, "" "", length=cells_to_erase, start=start_coordinates
        )
        FillConsoleOutputAttribute(
            self._handle,
            self._default_attrs,
            length=cells_to_erase,
            start=start_coordinates,
        )

    def erase_end_of_line(self) -> None:
        
        cursor_position = self.cursor_position
        cells_to_erase = self.screen_size.col - cursor_position.col
        FillConsoleOutputCharacter(
            self._handle, "" "", length=cells_to_erase, start=cursor_position
        )
        FillConsoleOutputAttribute(
            self._handle,
            self._default_attrs,
            length=cells_to_erase,
            start=cursor_position,
        )

    def erase_start_of_line(self) -> None:
        
        row, col = self.cursor_position
        start = WindowsCoordinates(row, 0)
        FillConsoleOutputCharacter(self._handle, "" "", length=col, start=start)
        FillConsoleOutputAttribute(
            self._handle, self._default_attrs, length=col, start=start
        )

    def move_cursor_up(self) -> None:
        
        cursor_position = self.cursor_position
        SetConsoleCursorPosition(
            self._handle,
            coords=WindowsCoordinates(
                row=cursor_position.row - 1, col=cursor_position.col
            ),
        )

    def move_cursor_down(self) -> None:
        
        cursor_position = self.cursor_position
        SetConsoleCursorPosition(
            self._handle,
            coords=WindowsCoordinates(
                row=cursor_position.row + 1,
                col=cursor_position.col,
            ),
        )

    def move_cursor_forward(self) -> None:
        
        row, col = self.cursor_position
        if col == self.screen_size.col - 1:
            row += 1
            col = 0
        else:
            col += 1
        SetConsoleCursorPosition(
            self._handle, coords=WindowsCoordinates(row=row, col=col)
        )

    def move_cursor_to_column(self, column: int) -> None:
        
        row, _ = self.cursor_position
        SetConsoleCursorPosition(self._handle, coords=WindowsCoordinates(row, column))

    def move_cursor_backward(self) -> None:
        
        row, col = self.cursor_position
        if col == 0:
            row -= 1
            col = self.screen_size.col - 1
        else:
            col -= 1
        SetConsoleCursorPosition(
            self._handle, coords=WindowsCoordinates(row=row, col=col)
        )

    def hide_cursor(self) -> None:
        
        current_cursor_size = self._get_cursor_size()
        invisible_cursor = CONSOLE_CURSOR_INFO(dwSize=current_cursor_size, bVisible=0)
        SetConsoleCursorInfo(self._handle, cursor_info=invisible_cursor)

    def show_cursor(self) -> None:
        
        current_cursor_size = self._get_cursor_size()
        visible_cursor = CONSOLE_CURSOR_INFO(dwSize=current_cursor_size, bVisible=1)
        SetConsoleCursorInfo(self._handle, cursor_info=visible_cursor)

    def set_title(self, title: str) -> None:
        
        assert len(title) < 255, ""Console title must be less than 255 characters""
        SetConsoleTitle(title)

    def _get_cursor_size(self) -> int:
        
        cursor_info = CONSOLE_CURSOR_INFO()
        GetConsoleCursorInfo(self._handle, cursor_info=cursor_info)
        return int(cursor_info.dwSize)


if __name__ == ""__main__"":
    handle = GetStdHandle()

    from pip._vendor.rich.console import Console

    console = Console()

    term = LegacyWindowsTerm(sys.stdout)
    term.set_title(""Win32 Console Examples"")

    style = Style(color=""black"", bgcolor=""red"")

    heading = Style.parse(""black on green"")

    
    console.rule(""Checking colour output"")
    console.print(""[on red]on red!"")
    console.print(""[blue]blue!"")
    console.print(""[yellow]yellow!"")
    console.print(""[bold yellow]bold yellow!"")
    console.print(""[bright_yellow]bright_yellow!"")
    console.print(""[dim bright_yellow]dim bright_yellow!"")
    console.print(""[italic cyan]italic cyan!"")
    console.print(""[bold white on blue]bold white on blue!"")
    console.print(""[reverse bold white on blue]reverse bold white on blue!"")
    console.print(""[bold black on cyan]bold black on cyan!"")
    console.print(""[black on green]black on green!"")
    console.print(""[blue on green]blue on green!"")
    console.print(""[white on black]white on black!"")
    console.print(""[black on white]black on white!"")
    console.print(""[

    
    console.rule(""Checking cursor movement"")
    console.print()
    term.move_cursor_backward()
    term.move_cursor_backward()
    term.write_text(""went back and wrapped to prev line"")
    time.sleep(1)
    term.move_cursor_up()
    term.write_text(""we go up"")
    time.sleep(1)
    term.move_cursor_down()
    term.write_text(""and down"")
    time.sleep(1)
    term.move_cursor_up()
    term.move_cursor_backward()
    term.move_cursor_backward()
    term.write_text(""we went up and back 2"")
    time.sleep(1)
    term.move_cursor_down()
    term.move_cursor_backward()
    term.move_cursor_backward()
    term.write_text(""we went down and back 2"")
    time.sleep(1)

    
    term.hide_cursor()
    console.print()
    console.rule(""Checking line erasing"")
    console.print(""\n...Deleting to the start of the line..."")
    term.write_text(""The red arrow shows the cursor location, and direction of erase"")
    time.sleep(1)
    term.move_cursor_to_column(16)
    term.write_styled(""<"", Style.parse(""black on red""))
    term.move_cursor_backward()
    time.sleep(1)
    term.erase_start_of_line()
    time.sleep(1)

    console.print(""\n\n...And to the end of the line..."")
    term.write_text(""The red arrow shows the cursor location, and direction of erase"")
    time.sleep(1)

    term.move_cursor_to_column(16)
    term.write_styled("">"", Style.parse(""black on red""))
    time.sleep(1)
    term.erase_end_of_line()
    time.sleep(1)

    console.print(""\n\n...Now the whole line will be erased..."")
    term.write_styled(""I'm going to disappear!"", style=Style.parse(""black on cyan""))
    time.sleep(1)
    term.erase_line()

    term.show_cursor()
    print(""\n"")

import sys
from dataclasses import dataclass


@dataclass
class WindowsConsoleFeatures:
    

    vt: bool = False
    
    truecolor: bool = False
    


try:
    import ctypes
    from ctypes import LibraryLoader

    if sys.platform == ""win32"":
        windll = LibraryLoader(ctypes.WinDLL)
    else:
        windll = None
        raise ImportError(""Not windows"")

    from pip._vendor.rich._win32_console import (
        ENABLE_VIRTUAL_TERMINAL_PROCESSING,
        GetConsoleMode,
        GetStdHandle,
        LegacyWindowsError,
    )

except (AttributeError, ImportError, ValueError):
    
    def get_windows_console_features() -> WindowsConsoleFeatures:
        features = WindowsConsoleFeatures()
        return features

else:

    def get_windows_console_features() -> WindowsConsoleFeatures:
        
        handle = GetStdHandle()
        try:
            console_mode = GetConsoleMode(handle)
            success = True
        except LegacyWindowsError:
            console_mode = 0
            success = False
        vt = bool(success and console_mode & ENABLE_VIRTUAL_TERMINAL_PROCESSING)
        truecolor = False
        if vt:
            win_version = sys.getwindowsversion()
            truecolor = win_version.major > 10 or (
                win_version.major == 10 and win_version.build >= 15063
            )
        features = WindowsConsoleFeatures(vt=vt, truecolor=truecolor)
        return features


if __name__ == ""__main__"":
    import platform

    features = get_windows_console_features()
    from pip._vendor.rich import print

    print(f'platform=""{platform.system()}""')
    print(repr(features))

from typing import Iterable, Sequence, Tuple, cast

from pip._vendor.rich._win32_console import LegacyWindowsTerm, WindowsCoordinates
from pip._vendor.rich.segment import ControlCode, ControlType, Segment


def legacy_windows_render(buffer: Iterable[Segment], term: LegacyWindowsTerm) -> None:
    
    for text, style, control in buffer:
        if not control:
            if style:
                term.write_styled(text, style)
            else:
                term.write_text(text)
        else:
            control_codes: Sequence[ControlCode] = control
            for control_code in control_codes:
                control_type = control_code[0]
                if control_type == ControlType.CURSOR_MOVE_TO:
                    _, x, y = cast(Tuple[ControlType, int, int], control_code)
                    term.move_cursor_to(WindowsCoordinates(row=y - 1, col=x - 1))
                elif control_type == ControlType.CARRIAGE_RETURN:
                    term.write_text(""\r"")
                elif control_type == ControlType.HOME:
                    term.move_cursor_to(WindowsCoordinates(0, 0))
                elif control_type == ControlType.CURSOR_UP:
                    term.move_cursor_up()
                elif control_type == ControlType.CURSOR_DOWN:
                    term.move_cursor_down()
                elif control_type == ControlType.CURSOR_FORWARD:
                    term.move_cursor_forward()
                elif control_type == ControlType.CURSOR_BACKWARD:
                    term.move_cursor_backward()
                elif control_type == ControlType.CURSOR_MOVE_TO_COLUMN:
                    _, column = cast(Tuple[ControlType, int], control_code)
                    term.move_cursor_to_column(column - 1)
                elif control_type == ControlType.HIDE_CURSOR:
                    term.hide_cursor()
                elif control_type == ControlType.SHOW_CURSOR:
                    term.show_cursor()
                elif control_type == ControlType.ERASE_IN_LINE:
                    _, mode = cast(Tuple[ControlType, int], control_code)
                    if mode == 0:
                        term.erase_end_of_line()
                    elif mode == 1:
                        term.erase_start_of_line()
                    elif mode == 2:
                        term.erase_line()
                elif control_type == ControlType.SET_WINDOW_TITLE:
                    _, title = cast(Tuple[ControlType, str], control_code)
                    term.set_title(title)

from __future__ import annotations

import re
from typing import Iterable

from ._loop import loop_last
from .cells import cell_len, chop_cells

re_word = re.compile(r""\s*\S+\s*"")


def words(text: str) -> Iterable[tuple[int, int, str]]:
    
    position = 0
    word_match = re_word.match(text, position)
    while word_match is not None:
        start, end = word_match.span()
        word = word_match.group(0)
        yield start, end, word
        word_match = re_word.match(text, end)


def divide_line(text: str, width: int, fold: bool = True) -> list[int]:
    
    break_positions: list[int] = []  
    append = break_positions.append
    cell_offset = 0
    _cell_len = cell_len

    for start, _end, word in words(text):
        word_length = _cell_len(word.rstrip())
        remaining_space = width - cell_offset
        word_fits_remaining_space = remaining_space >= word_length

        if word_fits_remaining_space:
            
            cell_offset += _cell_len(word)
        else:
            
            if word_length > width:
                
                
                if fold:
                    
                    folded_word = chop_cells(word, width=width)
                    for last, line in loop_last(folded_word):
                        if start:
                            append(start)
                        if last:
                            cell_offset = _cell_len(line)
                        else:
                            start += len(line)
                else:
                    
                    if start:
                        append(start)
                    cell_offset = _cell_len(word)
            elif cell_offset and start:
                
                
                append(start)
                cell_offset = _cell_len(word)

    return break_positions


if __name__ == ""__main__"":  
    from .console import Console

    console = Console(width=10)
    console.print(""12345 abcdefghijklmnopqrstuvwyxzABCDEFGHIJKLMNOPQRSTUVWXYZ 12345"")
    print(chop_cells(""abcdefghijklmnopqrstuvwxyz"", 10))

    console = Console(width=20)
    console.rule()
    console.print(""TextualはPythonの高速アプリケーション開発フレームワークです"")

    console.rule()
    console.print(""アプリケーションは1670万色を使用でき"")



import os
from typing import IO, TYPE_CHECKING, Any, Callable, Optional, Union

from ._extension import load_ipython_extension  

__all__ = [""get_console"", ""reconfigure"", ""print"", ""inspect"", ""print_json""]

if TYPE_CHECKING:
    from .console import Console


_console: Optional[""Console""] = None

try:
    _IMPORT_CWD = os.path.abspath(os.getcwd())
except FileNotFoundError:
    
    _IMPORT_CWD = """"


def get_console() -> ""Console"":
    
    global _console
    if _console is None:
        from .console import Console

        _console = Console()

    return _console


def reconfigure(*args: Any, **kwargs: Any) -> None:
    
    from pip._vendor.rich.console import Console

    new_console = Console(*args, **kwargs)
    _console = get_console()
    _console.__dict__ = new_console.__dict__


def print(
    *objects: Any,
    sep: str = "" "",
    end: str = ""\n"",
    file: Optional[IO[str]] = None,
    flush: bool = False,
) -> None:
    r
    from .console import Console

    write_console = get_console() if file is None else Console(file=file)
    return write_console.print(*objects, sep=sep, end=end)


def print_json(
    json: Optional[str] = None,
    *,
    data: Any = None,
    indent: Union[None, int, str] = 2,
    highlight: bool = True,
    skip_keys: bool = False,
    ensure_ascii: bool = False,
    check_circular: bool = True,
    allow_nan: bool = True,
    default: Optional[Callable[[Any], Any]] = None,
    sort_keys: bool = False,
) -> None:
    

    get_console().print_json(
        json,
        data=data,
        indent=indent,
        highlight=highlight,
        skip_keys=skip_keys,
        ensure_ascii=ensure_ascii,
        check_circular=check_circular,
        allow_nan=allow_nan,
        default=default,
        sort_keys=sort_keys,
    )


def inspect(
    obj: Any,
    *,
    console: Optional[""Console""] = None,
    title: Optional[str] = None,
    help: bool = False,
    methods: bool = False,
    docs: bool = True,
    private: bool = False,
    dunder: bool = False,
    sort: bool = True,
    all: bool = False,
    value: bool = True,
) -> None:
    
    _console = console or get_console()
    from pip._vendor.rich._inspect import Inspect

    
    is_inspect = obj is inspect

    _inspect = Inspect(
        obj,
        title=title,
        help=is_inspect or help,
        methods=is_inspect or methods,
        docs=is_inspect or docs,
        private=private,
        dunder=dunder,
        sort=sort,
        all=all,
        value=value,
    )
    _console.print(_inspect)


if __name__ == ""__main__"":  
    print(""Hello, **World**"")

import colorsys
import io
from time import process_time

from pip._vendor.rich import box
from pip._vendor.rich.color import Color
from pip._vendor.rich.console import Console, ConsoleOptions, Group, RenderableType, RenderResult
from pip._vendor.rich.markdown import Markdown
from pip._vendor.rich.measure import Measurement
from pip._vendor.rich.pretty import Pretty
from pip._vendor.rich.segment import Segment
from pip._vendor.rich.style import Style
from pip._vendor.rich.syntax import Syntax
from pip._vendor.rich.table import Table
from pip._vendor.rich.text import Text


class ColorBox:
    def __rich_console__(
        self, console: Console, options: ConsoleOptions
    ) -> RenderResult:
        for y in range(0, 5):
            for x in range(options.max_width):
                h = x / options.max_width
                l = 0.1 + ((y / 5) * 0.7)
                r1, g1, b1 = colorsys.hls_to_rgb(h, l, 1.0)
                r2, g2, b2 = colorsys.hls_to_rgb(h, l + 0.7 / 10, 1.0)
                bgcolor = Color.from_rgb(r1 * 255, g1 * 255, b1 * 255)
                color = Color.from_rgb(r2 * 255, g2 * 255, b2 * 255)
                yield Segment(""▄"", Style(color=color, bgcolor=bgcolor))
            yield Segment.line()

    def __rich_measure__(
        self, console: ""Console"", options: ConsoleOptions
    ) -> Measurement:
        return Measurement(1, options.max_width)


def make_test_card() -> Table:
    
    table = Table.grid(padding=1, pad_edge=True)
    table.title = ""Rich features""
    table.add_column(""Feature"", no_wrap=True, justify=""center"", style=""bold red"")
    table.add_column(""Demonstration"")

    color_table = Table(
        box=None,
        expand=False,
        show_header=False,
        show_edge=False,
        pad_edge=False,
    )
    color_table.add_row(
        (
            ""✓ [bold green]4-bit color[/]\n""
            ""✓ [bold blue]8-bit color[/]\n""
            ""✓ [bold magenta]Truecolor (16.7 million)[/]\n""
            ""✓ [bold yellow]Dumb terminals[/]\n""
            ""✓ [bold cyan]Automatic color conversion""
        ),
        ColorBox(),
    )

    table.add_row(""Colors"", color_table)

    table.add_row(
        ""Styles"",
        ""All ansi styles: [bold]bold[/], [dim]dim[/], [italic]italic[/italic], [underline]underline[/], [strike]strikethrough[/], [reverse]reverse[/], and even [blink]blink[/]."",
    )

    lorem = ""Lorem ipsum dolor sit amet, consectetur adipiscing elit. Quisque in metus sed sapien ultricies pretium a at justo. Maecenas luctus velit et auctor maximus.""
    lorem_table = Table.grid(padding=1, collapse_padding=True)
    lorem_table.pad_edge = False
    lorem_table.add_row(
        Text(lorem, justify=""left"", style=""green""),
        Text(lorem, justify=""center"", style=""yellow""),
        Text(lorem, justify=""right"", style=""blue""),
        Text(lorem, justify=""full"", style=""red""),
    )
    table.add_row(
        ""Text"",
        Group(
            Text.from_markup(
                
            ),
            lorem_table,
        ),
    )

    def comparison(renderable1: RenderableType, renderable2: RenderableType) -> Table:
        table = Table(show_header=False, pad_edge=False, box=None, expand=True)
        table.add_column(""1"", ratio=1)
        table.add_column(""2"", ratio=1)
        table.add_row(renderable1, renderable2)
        return table

    table.add_row(
        ""Asian\nlanguage\nsupport"",
        "":flag_for_china:  该库支持中文，日文和韩文文本！\n:flag_for_japan:  ライブラリは中国語、日本語、韓国語のテキストをサポートしています\n:flag_for_south_korea:  이 라이브러리는 중국어, 일본어 및 한국어 텍스트를 지원합니다"",
    )

    markup_example = (
        ""[bold magenta]Rich[/] supports a simple [i]bbcode[/i]-like [b]markup[/b] for [yellow]color[/], [underline]style[/], and emoji! ""
        "":+1: :apple: :ant: :bear: :baguette_bread: :bus: ""
    )
    table.add_row(""Markup"", markup_example)

    example_table = Table(
        show_edge=False,
        show_header=True,
        expand=False,
        row_styles=[""none"", ""dim""],
        box=box.SIMPLE,
    )
    example_table.add_column(""[green]Date"", style=""green"", no_wrap=True)
    example_table.add_column(""[blue]Title"", style=""blue"")
    example_table.add_column(
        ""[cyan]Production Budget"",
        style=""cyan"",
        justify=""right"",
        no_wrap=True,
    )
    example_table.add_column(
        ""[magenta]Box Office"",
        style=""magenta"",
        justify=""right"",
        no_wrap=True,
    )
    example_table.add_row(
        ""Dec 20, 2019"",
        ""Star Wars: The Rise of Skywalker"",
        ""$275,000,000"",
        ""$375,126,118"",
    )
    example_table.add_row(
        ""May 25, 2018"",
        ""[b]Solo[/]: A Star Wars Story"",
        ""$275,000,000"",
        ""$393,151,347"",
    )
    example_table.add_row(
        ""Dec 15, 2017"",
        ""Star Wars Ep. VIII: The Last Jedi"",
        ""$262,000,000"",
        ""[bold]$1,332,539,889[/bold]"",
    )
    example_table.add_row(
        ""May 19, 1999"",
        ""Star Wars Ep. [b]I[/b]: [i]The phantom Menace"",
        ""$115,000,000"",
        ""$1,027,044,677"",
    )

    table.add_row(""Tables"", example_table)

    code = 

    pretty_data = {
        ""foo"": [
            3.1427,
            (
                ""Paul Atreides"",
                ""Vladimir Harkonnen"",
                ""Thufir Hawat"",
            ),
        ],
        ""atomic"": (False, True, None),
    }
    table.add_row(
        ""Syntax\nhighlighting\n&\npretty\nprinting"",
        comparison(
            Syntax(code, ""python3"", line_numbers=True, indent_guides=True),
            Pretty(pretty_data, indent_guides=True),
        ),
    )

    markdown_example = 
    table.add_row(
        ""Markdown"", comparison(""[cyan]"" + markdown_example, Markdown(markdown_example))
    )

    table.add_row(
        ""+more!"",
        ,
    )
    return table


if __name__ == ""__main__"":  
    from pip._vendor.rich.panel import Panel

    console = Console(
        file=io.StringIO(),
        force_terminal=True,
    )
    test_card = make_test_card()

    
    start = process_time()
    console.print(test_card)
    pre_cache_taken = round((process_time() - start) * 1000.0, 1)

    console.file = io.StringIO()

    start = process_time()
    console.print(test_card)
    taken = round((process_time() - start) * 1000.0, 1)

    c = Console(record=True)
    c.print(test_card)

    console = Console()
    console.print(f""[dim]rendered in [not dim]{pre_cache_taken}ms[/] (cold cache)"")
    console.print(f""[dim]rendered in [not dim]{taken}ms[/] (warm cache)"")
    console.print()
    console.print(
        Panel.fit(
            ""[b magenta]Hope you enjoy using Rich![/]\n\n""
            ""Please consider sponsoring me if you get value from my work.\n\n""
            ""Even the price of a ☕ can brighten my day!\n\n""
            ""https://github.com/sponsors/willmcgugan"",
            border_style=""red"",
            title=""Help ensure Rich is maintained"",
        )
    )





from __future__ import annotations

from collections.abc import Iterable
import string
import sys
from types import MappingProxyType
from typing import IO, Any, Final, NamedTuple
import warnings

from ._re import (
    RE_DATETIME,
    RE_LOCALTIME,
    RE_NUMBER,
    match_to_datetime,
    match_to_localtime,
    match_to_number,
)
from ._types import Key, ParseFloat, Pos










MAX_INLINE_NESTING: Final = sys.getrecursionlimit()

ASCII_CTRL: Final = frozenset(chr(i) for i in range(32)) | frozenset(chr(127))



ILLEGAL_BASIC_STR_CHARS: Final = ASCII_CTRL - frozenset(""\t"")
ILLEGAL_MULTILINE_BASIC_STR_CHARS: Final = ASCII_CTRL - frozenset(""\t\n"")

ILLEGAL_LITERAL_STR_CHARS: Final = ILLEGAL_BASIC_STR_CHARS
ILLEGAL_MULTILINE_LITERAL_STR_CHARS: Final = ILLEGAL_MULTILINE_BASIC_STR_CHARS

ILLEGAL_COMMENT_CHARS: Final = ILLEGAL_BASIC_STR_CHARS

TOML_WS: Final = frozenset("" \t"")
TOML_WS_AND_NEWLINE: Final = TOML_WS | frozenset(""\n"")
BARE_KEY_CHARS: Final = frozenset(string.ascii_letters + string.digits + ""-_"")
KEY_INITIAL_CHARS: Final = BARE_KEY_CHARS | frozenset(""\""'"")
HEXDIGIT_CHARS: Final = frozenset(string.hexdigits)

BASIC_STR_ESCAPE_REPLACEMENTS: Final = MappingProxyType(
    {
        ""\\b"": ""\u0008"",  
        ""\\t"": ""\u0009"",  
        ""\\n"": ""\u000A"",  
        ""\\f"": ""\u000C"",  
        ""\\r"": ""\u000D"",  
        '\\""': ""\u0022"",  
        ""\\\\"": ""\u005C"",  
    }
)


class DEPRECATED_DEFAULT:
    


class TOMLDecodeError(ValueError):
    

    def __init__(
        self,
        msg: str | type[DEPRECATED_DEFAULT] = DEPRECATED_DEFAULT,
        doc: str | type[DEPRECATED_DEFAULT] = DEPRECATED_DEFAULT,
        pos: Pos | type[DEPRECATED_DEFAULT] = DEPRECATED_DEFAULT,
        *args: Any,
    ):
        if (
            args
            or not isinstance(msg, str)
            or not isinstance(doc, str)
            or not isinstance(pos, int)
        ):
            warnings.warn(
                ""Free-form arguments for TOMLDecodeError are deprecated. ""
                ""Please set 'msg' (str), 'doc' (str) and 'pos' (int) arguments only."",
                DeprecationWarning,
                stacklevel=2,
            )
            if pos is not DEPRECATED_DEFAULT:
                args = pos, *args
            if doc is not DEPRECATED_DEFAULT:
                args = doc, *args
            if msg is not DEPRECATED_DEFAULT:
                args = msg, *args
            ValueError.__init__(self, *args)
            return

        lineno = doc.count(""\n"", 0, pos) + 1
        if lineno == 1:
            colno = pos + 1
        else:
            colno = pos - doc.rindex(""\n"", 0, pos)

        if pos >= len(doc):
            coord_repr = ""end of document""
        else:
            coord_repr = f""line {lineno}, column {colno}""
        errmsg = f""{msg} (at {coord_repr})""
        ValueError.__init__(self, errmsg)

        self.msg = msg
        self.doc = doc
        self.pos = pos
        self.lineno = lineno
        self.colno = colno


def load(__fp: IO[bytes], *, parse_float: ParseFloat = float) -> dict[str, Any]:
    
    b = __fp.read()
    try:
        s = b.decode()
    except AttributeError:
        raise TypeError(
            ""File must be opened in binary mode, e.g. use `open('foo.toml', 'rb')`""
        ) from None
    return loads(s, parse_float=parse_float)


def loads(__s: str, *, parse_float: ParseFloat = float) -> dict[str, Any]:  
    

    
    
    try:
        src = __s.replace(""\r\n"", ""\n"")
    except (AttributeError, TypeError):
        raise TypeError(
            f""Expected str object, not '{type(__s).__qualname__}'""
        ) from None
    pos = 0
    out = Output(NestedDict(), Flags())
    header: Key = ()
    parse_float = make_safe_parse_float(parse_float)

    
    
    while True:
        
        pos = skip_chars(src, pos, TOML_WS)

        
        
        
        
        
        
        
        
        try:
            char = src[pos]
        except IndexError:
            break
        if char == ""\n"":
            pos += 1
            continue
        if char in KEY_INITIAL_CHARS:
            pos = key_value_rule(src, pos, out, header, parse_float)
            pos = skip_chars(src, pos, TOML_WS)
        elif char == ""["":
            try:
                second_char: str | None = src[pos + 1]
            except IndexError:
                second_char = None
            out.flags.finalize_pending()
            if second_char == ""["":
                pos, header = create_list_rule(src, pos, out)
            else:
                pos, header = create_dict_rule(src, pos, out)
            pos = skip_chars(src, pos, TOML_WS)
        elif char != ""
            raise TOMLDecodeError(""Invalid statement"", src, pos)

        
        pos = skip_comment(src, pos)

        
        try:
            char = src[pos]
        except IndexError:
            break
        if char != ""\n"":
            raise TOMLDecodeError(
                ""Expected newline or end of document after a statement"", src, pos
            )
        pos += 1

    return out.data.dict


class Flags:
    

    
    FROZEN: Final = 0
    
    
    EXPLICIT_NEST: Final = 1

    def __init__(self) -> None:
        self._flags: dict[str, dict] = {}
        self._pending_flags: set[tuple[Key, int]] = set()

    def add_pending(self, key: Key, flag: int) -> None:
        self._pending_flags.add((key, flag))

    def finalize_pending(self) -> None:
        for key, flag in self._pending_flags:
            self.set(key, flag, recursive=False)
        self._pending_flags.clear()

    def unset_all(self, key: Key) -> None:
        cont = self._flags
        for k in key[:-1]:
            if k not in cont:
                return
            cont = cont[k][""nested""]
        cont.pop(key[-1], None)

    def set(self, key: Key, flag: int, *, recursive: bool) -> None:  
        cont = self._flags
        key_parent, key_stem = key[:-1], key[-1]
        for k in key_parent:
            if k not in cont:
                cont[k] = {""flags"": set(), ""recursive_flags"": set(), ""nested"": {}}
            cont = cont[k][""nested""]
        if key_stem not in cont:
            cont[key_stem] = {""flags"": set(), ""recursive_flags"": set(), ""nested"": {}}
        cont[key_stem][""recursive_flags"" if recursive else ""flags""].add(flag)

    def is_(self, key: Key, flag: int) -> bool:
        if not key:
            return False  
        cont = self._flags
        for k in key[:-1]:
            if k not in cont:
                return False
            inner_cont = cont[k]
            if flag in inner_cont[""recursive_flags""]:
                return True
            cont = inner_cont[""nested""]
        key_stem = key[-1]
        if key_stem in cont:
            inner_cont = cont[key_stem]
            return flag in inner_cont[""flags""] or flag in inner_cont[""recursive_flags""]
        return False


class NestedDict:
    def __init__(self) -> None:
        
        self.dict: dict[str, Any] = {}

    def get_or_create_nest(
        self,
        key: Key,
        *,
        access_lists: bool = True,
    ) -> dict:
        cont: Any = self.dict
        for k in key:
            if k not in cont:
                cont[k] = {}
            cont = cont[k]
            if access_lists and isinstance(cont, list):
                cont = cont[-1]
            if not isinstance(cont, dict):
                raise KeyError(""There is no nest behind this key"")
        return cont

    def append_nest_to_list(self, key: Key) -> None:
        cont = self.get_or_create_nest(key[:-1])
        last_key = key[-1]
        if last_key in cont:
            list_ = cont[last_key]
            if not isinstance(list_, list):
                raise KeyError(""An object other than list found behind this key"")
            list_.append({})
        else:
            cont[last_key] = [{}]


class Output(NamedTuple):
    data: NestedDict
    flags: Flags


def skip_chars(src: str, pos: Pos, chars: Iterable[str]) -> Pos:
    try:
        while src[pos] in chars:
            pos += 1
    except IndexError:
        pass
    return pos


def skip_until(
    src: str,
    pos: Pos,
    expect: str,
    *,
    error_on: frozenset[str],
    error_on_eof: bool,
) -> Pos:
    try:
        new_pos = src.index(expect, pos)
    except ValueError:
        new_pos = len(src)
        if error_on_eof:
            raise TOMLDecodeError(f""Expected {expect!r}"", src, new_pos) from None

    if not error_on.isdisjoint(src[pos:new_pos]):
        while src[pos] not in error_on:
            pos += 1
        raise TOMLDecodeError(f""Found invalid character {src[pos]!r}"", src, pos)
    return new_pos


def skip_comment(src: str, pos: Pos) -> Pos:
    try:
        char: str | None = src[pos]
    except IndexError:
        char = None
    if char == ""
        return skip_until(
            src, pos + 1, ""\n"", error_on=ILLEGAL_COMMENT_CHARS, error_on_eof=False
        )
    return pos


def skip_comments_and_array_ws(src: str, pos: Pos) -> Pos:
    while True:
        pos_before_skip = pos
        pos = skip_chars(src, pos, TOML_WS_AND_NEWLINE)
        pos = skip_comment(src, pos)
        if pos == pos_before_skip:
            return pos


def create_dict_rule(src: str, pos: Pos, out: Output) -> tuple[Pos, Key]:
    pos += 1  
    pos = skip_chars(src, pos, TOML_WS)
    pos, key = parse_key(src, pos)

    if out.flags.is_(key, Flags.EXPLICIT_NEST) or out.flags.is_(key, Flags.FROZEN):
        raise TOMLDecodeError(f""Cannot declare {key} twice"", src, pos)
    out.flags.set(key, Flags.EXPLICIT_NEST, recursive=False)
    try:
        out.data.get_or_create_nest(key)
    except KeyError:
        raise TOMLDecodeError(""Cannot overwrite a value"", src, pos) from None

    if not src.startswith(""]"", pos):
        raise TOMLDecodeError(
            ""Expected ']' at the end of a table declaration"", src, pos
        )
    return pos + 1, key


def create_list_rule(src: str, pos: Pos, out: Output) -> tuple[Pos, Key]:
    pos += 2  
    pos = skip_chars(src, pos, TOML_WS)
    pos, key = parse_key(src, pos)

    if out.flags.is_(key, Flags.FROZEN):
        raise TOMLDecodeError(f""Cannot mutate immutable namespace {key}"", src, pos)
    
    out.flags.unset_all(key)
    
    out.flags.set(key, Flags.EXPLICIT_NEST, recursive=False)
    try:
        out.data.append_nest_to_list(key)
    except KeyError:
        raise TOMLDecodeError(""Cannot overwrite a value"", src, pos) from None

    if not src.startswith(""]]"", pos):
        raise TOMLDecodeError(
            ""Expected ']]' at the end of an array declaration"", src, pos
        )
    return pos + 2, key


def key_value_rule(
    src: str, pos: Pos, out: Output, header: Key, parse_float: ParseFloat
) -> Pos:
    pos, key, value = parse_key_value_pair(src, pos, parse_float, nest_lvl=0)
    key_parent, key_stem = key[:-1], key[-1]
    abs_key_parent = header + key_parent

    relative_path_cont_keys = (header + key[:i] for i in range(1, len(key)))
    for cont_key in relative_path_cont_keys:
        
        if out.flags.is_(cont_key, Flags.EXPLICIT_NEST):
            raise TOMLDecodeError(f""Cannot redefine namespace {cont_key}"", src, pos)
        
        
        out.flags.add_pending(cont_key, Flags.EXPLICIT_NEST)

    if out.flags.is_(abs_key_parent, Flags.FROZEN):
        raise TOMLDecodeError(
            f""Cannot mutate immutable namespace {abs_key_parent}"", src, pos
        )

    try:
        nest = out.data.get_or_create_nest(abs_key_parent)
    except KeyError:
        raise TOMLDecodeError(""Cannot overwrite a value"", src, pos) from None
    if key_stem in nest:
        raise TOMLDecodeError(""Cannot overwrite a value"", src, pos)
    
    if isinstance(value, (dict, list)):
        out.flags.set(header + key, Flags.FROZEN, recursive=True)
    nest[key_stem] = value
    return pos


def parse_key_value_pair(
    src: str, pos: Pos, parse_float: ParseFloat, nest_lvl: int
) -> tuple[Pos, Key, Any]:
    pos, key = parse_key(src, pos)
    try:
        char: str | None = src[pos]
    except IndexError:
        char = None
    if char != ""="":
        raise TOMLDecodeError(""Expected '=' after a key in a key/value pair"", src, pos)
    pos += 1
    pos = skip_chars(src, pos, TOML_WS)
    pos, value = parse_value(src, pos, parse_float, nest_lvl)
    return pos, key, value


def parse_key(src: str, pos: Pos) -> tuple[Pos, Key]:
    pos, key_part = parse_key_part(src, pos)
    key: Key = (key_part,)
    pos = skip_chars(src, pos, TOML_WS)
    while True:
        try:
            char: str | None = src[pos]
        except IndexError:
            char = None
        if char != ""."":
            return pos, key
        pos += 1
        pos = skip_chars(src, pos, TOML_WS)
        pos, key_part = parse_key_part(src, pos)
        key += (key_part,)
        pos = skip_chars(src, pos, TOML_WS)


def parse_key_part(src: str, pos: Pos) -> tuple[Pos, str]:
    try:
        char: str | None = src[pos]
    except IndexError:
        char = None
    if char in BARE_KEY_CHARS:
        start_pos = pos
        pos = skip_chars(src, pos, BARE_KEY_CHARS)
        return pos, src[start_pos:pos]
    if char == ""'"":
        return parse_literal_str(src, pos)
    if char == '""':
        return parse_one_line_basic_str(src, pos)
    raise TOMLDecodeError(""Invalid initial character for a key part"", src, pos)


def parse_one_line_basic_str(src: str, pos: Pos) -> tuple[Pos, str]:
    pos += 1
    return parse_basic_str(src, pos, multiline=False)


def parse_array(
    src: str, pos: Pos, parse_float: ParseFloat, nest_lvl: int
) -> tuple[Pos, list]:
    pos += 1
    array: list = []

    pos = skip_comments_and_array_ws(src, pos)
    if src.startswith(""]"", pos):
        return pos + 1, array
    while True:
        pos, val = parse_value(src, pos, parse_float, nest_lvl)
        array.append(val)
        pos = skip_comments_and_array_ws(src, pos)

        c = src[pos : pos + 1]
        if c == ""]"":
            return pos + 1, array
        if c != "","":
            raise TOMLDecodeError(""Unclosed array"", src, pos)
        pos += 1

        pos = skip_comments_and_array_ws(src, pos)
        if src.startswith(""]"", pos):
            return pos + 1, array


def parse_inline_table(
    src: str, pos: Pos, parse_float: ParseFloat, nest_lvl: int
) -> tuple[Pos, dict]:
    pos += 1
    nested_dict = NestedDict()
    flags = Flags()

    pos = skip_chars(src, pos, TOML_WS)
    if src.startswith(""}"", pos):
        return pos + 1, nested_dict.dict
    while True:
        pos, key, value = parse_key_value_pair(src, pos, parse_float, nest_lvl)
        key_parent, key_stem = key[:-1], key[-1]
        if flags.is_(key, Flags.FROZEN):
            raise TOMLDecodeError(f""Cannot mutate immutable namespace {key}"", src, pos)
        try:
            nest = nested_dict.get_or_create_nest(key_parent, access_lists=False)
        except KeyError:
            raise TOMLDecodeError(""Cannot overwrite a value"", src, pos) from None
        if key_stem in nest:
            raise TOMLDecodeError(f""Duplicate inline table key {key_stem!r}"", src, pos)
        nest[key_stem] = value
        pos = skip_chars(src, pos, TOML_WS)
        c = src[pos : pos + 1]
        if c == ""}"":
            return pos + 1, nested_dict.dict
        if c != "","":
            raise TOMLDecodeError(""Unclosed inline table"", src, pos)
        if isinstance(value, (dict, list)):
            flags.set(key, Flags.FROZEN, recursive=True)
        pos += 1
        pos = skip_chars(src, pos, TOML_WS)


def parse_basic_str_escape(
    src: str, pos: Pos, *, multiline: bool = False
) -> tuple[Pos, str]:
    escape_id = src[pos : pos + 2]
    pos += 2
    if multiline and escape_id in {""\\ "", ""\\\t"", ""\\\n""}:
        
        
        if escape_id != ""\\\n"":
            pos = skip_chars(src, pos, TOML_WS)
            try:
                char = src[pos]
            except IndexError:
                return pos, """"
            if char != ""\n"":
                raise TOMLDecodeError(""Unescaped '\\' in a string"", src, pos)
            pos += 1
        pos = skip_chars(src, pos, TOML_WS_AND_NEWLINE)
        return pos, """"
    if escape_id == ""\\u"":
        return parse_hex_char(src, pos, 4)
    if escape_id == ""\\U"":
        return parse_hex_char(src, pos, 8)
    try:
        return pos, BASIC_STR_ESCAPE_REPLACEMENTS[escape_id]
    except KeyError:
        raise TOMLDecodeError(""Unescaped '\\' in a string"", src, pos) from None


def parse_basic_str_escape_multiline(src: str, pos: Pos) -> tuple[Pos, str]:
    return parse_basic_str_escape(src, pos, multiline=True)


def parse_hex_char(src: str, pos: Pos, hex_len: int) -> tuple[Pos, str]:
    hex_str = src[pos : pos + hex_len]
    if len(hex_str) != hex_len or not HEXDIGIT_CHARS.issuperset(hex_str):
        raise TOMLDecodeError(""Invalid hex value"", src, pos)
    pos += hex_len
    hex_int = int(hex_str, 16)
    if not is_unicode_scalar_value(hex_int):
        raise TOMLDecodeError(
            ""Escaped character is not a Unicode scalar value"", src, pos
        )
    return pos, chr(hex_int)


def parse_literal_str(src: str, pos: Pos) -> tuple[Pos, str]:
    pos += 1  
    start_pos = pos
    pos = skip_until(
        src, pos, ""'"", error_on=ILLEGAL_LITERAL_STR_CHARS, error_on_eof=True
    )
    return pos + 1, src[start_pos:pos]  


def parse_multiline_str(src: str, pos: Pos, *, literal: bool) -> tuple[Pos, str]:
    pos += 3
    if src.startswith(""\n"", pos):
        pos += 1

    if literal:
        delim = ""'""
        end_pos = skip_until(
            src,
            pos,
            """", pos):
            return parse_multiline_str(src, pos, literal=True)
        return parse_literal_str(src, pos)

    
    if char == ""t"":
        if src.startswith(""true"", pos):
            return pos + 4, True
    if char == ""f"":
        if src.startswith(""false"", pos):
            return pos + 5, False

    
    if char == ""["":
        return parse_array(src, pos, parse_float, nest_lvl + 1)

    
    if char == ""{"":
        return parse_inline_table(src, pos, parse_float, nest_lvl + 1)

    
    datetime_match = RE_DATETIME.match(src, pos)
    if datetime_match:
        try:
            datetime_obj = match_to_datetime(datetime_match)
        except ValueError as e:
            raise TOMLDecodeError(""Invalid date or datetime"", src, pos) from e
        return datetime_match.end(), datetime_obj
    localtime_match = RE_LOCALTIME.match(src, pos)
    if localtime_match:
        return localtime_match.end(), match_to_localtime(localtime_match)

    
    
    
    number_match = RE_NUMBER.match(src, pos)
    if number_match:
        return number_match.end(), match_to_number(number_match, parse_float)

    
    first_three = src[pos : pos + 3]
    if first_three in {""inf"", ""nan""}:
        return pos + 3, parse_float(first_three)
    first_four = src[pos : pos + 4]
    if first_four in {""-inf"", ""+inf"", ""-nan"", ""+nan""}:
        return pos + 4, parse_float(first_four)

    raise TOMLDecodeError(""Invalid value"", src, pos)


def is_unicode_scalar_value(codepoint: int) -> bool:
    return (0 <= codepoint <= 55295) or (57344 <= codepoint <= 1114111)


def make_safe_parse_float(parse_float: ParseFloat) -> ParseFloat:
    
    
    if parse_float is float:
        return float

    def safe_parse_float(float_str: str) -> Any:
        float_value = parse_float(float_str)
        if isinstance(float_value, (dict, list)):
            raise ValueError(""parse_float must not return dicts or lists"")
        return float_value

    return safe_parse_float





from __future__ import annotations

from datetime import date, datetime, time, timedelta, timezone, tzinfo
from functools import lru_cache
import re
from typing import Any, Final

from ._types import ParseFloat




_TIME_RE_STR: Final = (
    r""([01][0-9]|2[0-3]):([0-5][0-9]):([0-5][0-9])(?:\.([0-9]{1,6})[0-9]*)?""
)

RE_NUMBER: Final = re.compile(
    r,
    flags=re.VERBOSE,
)
RE_LOCALTIME: Final = re.compile(_TIME_RE_STR)
RE_DATETIME: Final = re.compile(
    rf,
    flags=re.VERBOSE,
)


def match_to_datetime(match: re.Match) -> datetime | date:
    
    (
        year_str,
        month_str,
        day_str,
        hour_str,
        minute_str,
        sec_str,
        micros_str,
        zulu_time,
        offset_sign_str,
        offset_hour_str,
        offset_minute_str,
    ) = match.groups()
    year, month, day = int(year_str), int(month_str), int(day_str)
    if hour_str is None:
        return date(year, month, day)
    hour, minute, sec = int(hour_str), int(minute_str), int(sec_str)
    micros = int(micros_str.ljust(6, ""0"")) if micros_str else 0
    if offset_sign_str:
        tz: tzinfo | None = cached_tz(
            offset_hour_str, offset_minute_str, offset_sign_str
        )
    elif zulu_time:
        tz = timezone.utc
    else:  
        tz = None
    return datetime(year, month, day, hour, minute, sec, micros, tzinfo=tz)





@lru_cache(maxsize=None)
def cached_tz(hour_str: str, minute_str: str, sign_str: str) -> timezone:
    sign = 1 if sign_str == ""+"" else -1
    return timezone(
        timedelta(
            hours=sign * int(hour_str),
            minutes=sign * int(minute_str),
        )
    )


def match_to_localtime(match: re.Match) -> time:
    hour_str, minute_str, sec_str, micros_str = match.groups()
    micros = int(micros_str.ljust(6, ""0"")) if micros_str else 0
    return time(int(hour_str), int(minute_str), int(sec_str), micros)


def match_to_number(match: re.Match, parse_float: ParseFloat) -> Any:
    if match.group(""floatpart""):
        return parse_float(match.group())
    return int(match.group(), 0)





from typing import Any, Callable, Tuple


ParseFloat = Callable[[str], Any]
Key = Tuple[str, ...]
Pos = int





__all__ = (""loads"", ""load"", ""TOMLDecodeError"")
__version__ = ""2.2.1""  

from ._parser import TOMLDecodeError, load, loads

from __future__ import annotations

from collections.abc import Mapping
from datetime import date, datetime, time
from types import MappingProxyType

TYPE_CHECKING = False
if TYPE_CHECKING:
    from collections.abc import Generator
    from decimal import Decimal
    from typing import IO, Any, Final

ASCII_CTRL = frozenset(chr(i) for i in range(32)) | frozenset(chr(127))
ILLEGAL_BASIC_STR_CHARS = frozenset('""\\') | ASCII_CTRL - frozenset(""\t"")
BARE_KEY_CHARS = frozenset(
    ""abcdefghijklmnopqrstuvwxyz"" ""ABCDEFGHIJKLMNOPQRSTUVWXYZ"" ""0123456789"" ""-_""
)
ARRAY_TYPES = (list, tuple)
MAX_LINE_LENGTH = 100

COMPACT_ESCAPES = MappingProxyType(
    {
        ""\u0008"": ""\\b"",  
        ""\u000A"": ""\\n"",  
        ""\u000C"": ""\\f"",  
        ""\u000D"": ""\\r"",  
        ""\u0022"": '\\""',  
        ""\u005C"": ""\\\\"",  
    }
)


class Context:
    def __init__(self, allow_multiline: bool, indent: int):
        if indent < 0:
            raise ValueError(""Indent width must be non-negative"")
        self.allow_multiline: Final = allow_multiline
        
        self.inline_table_cache: Final[dict[int, str]] = {}
        self.indent_str: Final = "" "" * indent


def dump(
    obj: Mapping[str, Any],
    fp: IO[bytes],
    /,
    *,
    multiline_strings: bool = False,
    indent: int = 4,
) -> None:
    ctx = Context(multiline_strings, indent)
    for chunk in gen_table_chunks(obj, ctx, name=""""):
        fp.write(chunk.encode())


def dumps(
    obj: Mapping[str, Any], /, *, multiline_strings: bool = False, indent: int = 4
) -> str:
    ctx = Context(multiline_strings, indent)
    return """".join(gen_table_chunks(obj, ctx, name=""""))


def gen_table_chunks(
    table: Mapping[str, Any],
    ctx: Context,
    *,
    name: str,
    inside_aot: bool = False,
) -> Generator[str, None, None]:
    yielded = False
    literals = []
    tables: list[tuple[str, Any, bool]] = []  
    for k, v in table.items():
        if isinstance(v, Mapping):
            tables.append((k, v, False))
        elif is_aot(v) and not all(is_suitable_inline_table(t, ctx) for t in v):
            tables.extend((k, t, True) for t in v)
        else:
            literals.append((k, v))

    if inside_aot or name and (literals or not tables):
        yielded = True
        yield f""[[{name}]]\n"" if inside_aot else f""[{name}]\n""

    if literals:
        yielded = True
        for k, v in literals:
            yield f""{format_key_part(k)} = {format_literal(v, ctx)}\n""

    for k, v, in_aot in tables:
        if yielded:
            yield ""\n""
        else:
            yielded = True
        key_part = format_key_part(k)
        display_name = f""{name}.{key_part}"" if name else key_part
        yield from gen_table_chunks(v, ctx, name=display_name, inside_aot=in_aot)


def format_literal(obj: object, ctx: Context, *, nest_level: int = 0) -> str:
    if isinstance(obj, bool):
        return ""true"" if obj else ""false""
    if isinstance(obj, (int, float, date, datetime)):
        return str(obj)
    if isinstance(obj, time):
        if obj.tzinfo:
            raise ValueError(""TOML does not support offset times"")
        return str(obj)
    if isinstance(obj, str):
        return format_string(obj, allow_multiline=ctx.allow_multiline)
    if isinstance(obj, ARRAY_TYPES):
        return format_inline_array(obj, ctx, nest_level)
    if isinstance(obj, Mapping):
        return format_inline_table(obj, ctx)

    
    from decimal import Decimal

    if isinstance(obj, Decimal):
        return format_decimal(obj)
    raise TypeError(
        f""Object of type '{type(obj).__qualname__}' is not TOML serializable""
    )


def format_decimal(obj: Decimal) -> str:
    if obj.is_nan():
        return ""nan""
    if obj.is_infinite():
        return ""-inf"" if obj.is_signed() else ""inf""
    dec_str = str(obj).lower()
    return dec_str if ""."" in dec_str or ""e"" in dec_str else dec_str + "".0""


def format_inline_table(obj: Mapping, ctx: Context) -> str:
    
    obj_id = id(obj)
    if obj_id in ctx.inline_table_cache:
        return ctx.inline_table_cache[obj_id]

    if not obj:
        rendered = ""{}""
    else:
        rendered = (
            ""{ ""
            + "", "".join(
                f""{format_key_part(k)} = {format_literal(v, ctx)}""
                for k, v in obj.items()
            )
            + "" }""
        )
    ctx.inline_table_cache[obj_id] = rendered
    return rendered


def format_inline_array(obj: tuple | list, ctx: Context, nest_level: int) -> str:
    if not obj:
        return ""[]""
    item_indent = ctx.indent_str * (1 + nest_level)
    closing_bracket_indent = ctx.indent_str * nest_level
    return (
        ""[\n""
        + "",\n"".join(
            item_indent + format_literal(item, ctx, nest_level=nest_level + 1)
            for item in obj
        )
        + f"",\n{closing_bracket_indent}]""
    )


def format_key_part(part: str) -> str:
    try:
        only_bare_key_chars = BARE_KEY_CHARS.issuperset(part)
    except TypeError:
        raise TypeError(
            f""Invalid mapping key '{part}' of type '{type(part).__qualname__}'.""
            "" A string is required.""
        ) from None

    if part and only_bare_key_chars:
        return part
    return format_string(part, allow_multiline=False)


def format_string(s: str, *, allow_multiline: bool) -> str:
    do_multiline = allow_multiline and ""\n"" in s
    if do_multiline:
        result = ''
            return result + '""'
        if char in ILLEGAL_BASIC_STR_CHARS:
            result += s[seq_start:pos]
            if char in COMPACT_ESCAPES:
                if do_multiline and char == ""\n"":
                    result += ""\n""
                else:
                    result += COMPACT_ESCAPES[char]
            else:
                result += ""\\u"" + hex(ord(char))[2:].rjust(4, ""0"")
            seq_start = pos + 1
        pos += 1


def is_aot(obj: Any) -> bool:
    
    return bool(
        isinstance(obj, ARRAY_TYPES)
        and obj
        and all(isinstance(v, Mapping) for v in obj)
    )


def is_suitable_inline_table(obj: Mapping, ctx: Context) -> bool:
    
    rendered_inline = f""{ctx.indent_str}{format_inline_table(obj, ctx)},""
    return len(rendered_inline) <= MAX_LINE_LENGTH and ""\n"" not in rendered_inline

__all__ = (""dumps"", ""dump"")
__version__ = ""1.2.0""  

from pip._vendor.tomli_w._writer import dump, dumps

import os
import platform
import socket
import ssl
import sys
import typing

import _ssl

from ._ssl_constants import (
    _original_SSLContext,
    _original_super_SSLContext,
    _truststore_SSLContext_dunder_class,
    _truststore_SSLContext_super_class,
)

if platform.system() == ""Windows"":
    from ._windows import _configure_context, _verify_peercerts_impl
elif platform.system() == ""Darwin"":
    from ._macos import _configure_context, _verify_peercerts_impl
else:
    from ._openssl import _configure_context, _verify_peercerts_impl

if typing.TYPE_CHECKING:
    from typing_extensions import Buffer


_StrOrBytesPath: typing.TypeAlias = str | bytes | os.PathLike[str] | os.PathLike[bytes]
_PasswordType: typing.TypeAlias = str | bytes | typing.Callable[[], str | bytes]


def inject_into_ssl() -> None:
    
    setattr(ssl, ""SSLContext"", SSLContext)
    
    
    try:
        import pip._vendor.urllib3.util.ssl_ as urllib3_ssl

        setattr(urllib3_ssl, ""SSLContext"", SSLContext)
    except ImportError:
        pass

    
    
    
    
    try:
        from pip._vendor.requests import adapters as requests_adapters

        preloaded_context = getattr(requests_adapters, ""_preloaded_ssl_context"", None)
        if preloaded_context is not None:
            setattr(
                requests_adapters,
                ""_preloaded_ssl_context"",
                SSLContext(ssl.PROTOCOL_TLS_CLIENT),
            )
    except ImportError:
        pass


def extract_from_ssl() -> None:
    
    setattr(ssl, ""SSLContext"", _original_SSLContext)
    try:
        import pip._vendor.urllib3.util.ssl_ as urllib3_ssl

        urllib3_ssl.SSLContext = _original_SSLContext  
    except ImportError:
        pass


class SSLContext(_truststore_SSLContext_super_class):  
    

    @property  
    def __class__(self) -> type:
        
        
        
        return _truststore_SSLContext_dunder_class or SSLContext

    def __init__(self, protocol: int = None) -> None:  
        self._ctx = _original_SSLContext(protocol)

        class TruststoreSSLObject(ssl.SSLObject):
            
            
            

            def do_handshake(self) -> None:
                ret = super().do_handshake()
                _verify_peercerts(self, server_hostname=self.server_hostname)
                return ret

        self._ctx.sslobject_class = TruststoreSSLObject

    def wrap_socket(
        self,
        sock: socket.socket,
        server_side: bool = False,
        do_handshake_on_connect: bool = True,
        suppress_ragged_eofs: bool = True,
        server_hostname: str | None = None,
        session: ssl.SSLSession | None = None,
    ) -> ssl.SSLSocket:
        
        
        
        with _configure_context(self._ctx):
            ssl_sock = self._ctx.wrap_socket(
                sock,
                server_side=server_side,
                server_hostname=server_hostname,
                do_handshake_on_connect=do_handshake_on_connect,
                suppress_ragged_eofs=suppress_ragged_eofs,
                session=session,
            )
        try:
            _verify_peercerts(ssl_sock, server_hostname=server_hostname)
        except Exception:
            ssl_sock.close()
            raise
        return ssl_sock

    def wrap_bio(
        self,
        incoming: ssl.MemoryBIO,
        outgoing: ssl.MemoryBIO,
        server_side: bool = False,
        server_hostname: str | None = None,
        session: ssl.SSLSession | None = None,
    ) -> ssl.SSLObject:
        with _configure_context(self._ctx):
            ssl_obj = self._ctx.wrap_bio(
                incoming,
                outgoing,
                server_hostname=server_hostname,
                server_side=server_side,
                session=session,
            )
        return ssl_obj

    def load_verify_locations(
        self,
        cafile: str | bytes | os.PathLike[str] | os.PathLike[bytes] | None = None,
        capath: str | bytes | os.PathLike[str] | os.PathLike[bytes] | None = None,
        cadata: typing.Union[str, ""Buffer"", None] = None,
    ) -> None:
        return self._ctx.load_verify_locations(
            cafile=cafile, capath=capath, cadata=cadata
        )

    def load_cert_chain(
        self,
        certfile: _StrOrBytesPath,
        keyfile: _StrOrBytesPath | None = None,
        password: _PasswordType | None = None,
    ) -> None:
        return self._ctx.load_cert_chain(
            certfile=certfile, keyfile=keyfile, password=password
        )

    def load_default_certs(
        self, purpose: ssl.Purpose = ssl.Purpose.SERVER_AUTH
    ) -> None:
        return self._ctx.load_default_certs(purpose)

    def set_alpn_protocols(self, alpn_protocols: typing.Iterable[str]) -> None:
        return self._ctx.set_alpn_protocols(alpn_protocols)

    def set_npn_protocols(self, npn_protocols: typing.Iterable[str]) -> None:
        return self._ctx.set_npn_protocols(npn_protocols)

    def set_ciphers(self, __cipherlist: str) -> None:
        return self._ctx.set_ciphers(__cipherlist)

    def get_ciphers(self) -> typing.Any:
        return self._ctx.get_ciphers()

    def session_stats(self) -> dict[str, int]:
        return self._ctx.session_stats()

    def cert_store_stats(self) -> dict[str, int]:
        raise NotImplementedError()

    def set_default_verify_paths(self) -> None:
        self._ctx.set_default_verify_paths()

    @typing.overload
    def get_ca_certs(
        self, binary_form: typing.Literal[False] = ...
    ) -> list[typing.Any]: ...

    @typing.overload
    def get_ca_certs(self, binary_form: typing.Literal[True] = ...) -> list[bytes]: ...

    @typing.overload
    def get_ca_certs(self, binary_form: bool = ...) -> typing.Any: ...

    def get_ca_certs(self, binary_form: bool = False) -> list[typing.Any] | list[bytes]:
        raise NotImplementedError()

    @property
    def check_hostname(self) -> bool:
        return self._ctx.check_hostname

    @check_hostname.setter
    def check_hostname(self, value: bool) -> None:
        self._ctx.check_hostname = value

    @property
    def hostname_checks_common_name(self) -> bool:
        return self._ctx.hostname_checks_common_name

    @hostname_checks_common_name.setter
    def hostname_checks_common_name(self, value: bool) -> None:
        self._ctx.hostname_checks_common_name = value

    @property
    def keylog_filename(self) -> str:
        return self._ctx.keylog_filename

    @keylog_filename.setter
    def keylog_filename(self, value: str) -> None:
        self._ctx.keylog_filename = value

    @property
    def maximum_version(self) -> ssl.TLSVersion:
        return self._ctx.maximum_version

    @maximum_version.setter
    def maximum_version(self, value: ssl.TLSVersion) -> None:
        _original_super_SSLContext.maximum_version.__set__(  
            self._ctx, value
        )

    @property
    def minimum_version(self) -> ssl.TLSVersion:
        return self._ctx.minimum_version

    @minimum_version.setter
    def minimum_version(self, value: ssl.TLSVersion) -> None:
        _original_super_SSLContext.minimum_version.__set__(  
            self._ctx, value
        )

    @property
    def options(self) -> ssl.Options:
        return self._ctx.options

    @options.setter
    def options(self, value: ssl.Options) -> None:
        _original_super_SSLContext.options.__set__(  
            self._ctx, value
        )

    @property
    def post_handshake_auth(self) -> bool:
        return self._ctx.post_handshake_auth

    @post_handshake_auth.setter
    def post_handshake_auth(self, value: bool) -> None:
        self._ctx.post_handshake_auth = value

    @property
    def protocol(self) -> ssl._SSLMethod:
        return self._ctx.protocol

    @property
    def security_level(self) -> int:
        return self._ctx.security_level

    @property
    def verify_flags(self) -> ssl.VerifyFlags:
        return self._ctx.verify_flags

    @verify_flags.setter
    def verify_flags(self, value: ssl.VerifyFlags) -> None:
        _original_super_SSLContext.verify_flags.__set__(  
            self._ctx, value
        )

    @property
    def verify_mode(self) -> ssl.VerifyMode:
        return self._ctx.verify_mode

    @verify_mode.setter
    def verify_mode(self, value: ssl.VerifyMode) -> None:
        _original_super_SSLContext.verify_mode.__set__(  
            self._ctx, value
        )





if sys.version_info >= (3, 13):

    def _get_unverified_chain_bytes(sslobj: ssl.SSLObject) -> list[bytes]:
        unverified_chain = sslobj.get_unverified_chain() or ()  
        return [
            cert if isinstance(cert, bytes) else cert.public_bytes(_ssl.ENCODING_DER)
            for cert in unverified_chain
        ]

else:

    def _get_unverified_chain_bytes(sslobj: ssl.SSLObject) -> list[bytes]:
        unverified_chain = sslobj.get_unverified_chain() or ()  
        return [cert.public_bytes(_ssl.ENCODING_DER) for cert in unverified_chain]


def _verify_peercerts(
    sock_or_sslobj: ssl.SSLSocket | ssl.SSLObject, server_hostname: str | None
) -> None:
    
    sslobj: ssl.SSLObject = sock_or_sslobj  
    try:
        while not hasattr(sslobj, ""get_unverified_chain""):
            sslobj = sslobj._sslobj  
    except AttributeError:
        pass

    cert_bytes = _get_unverified_chain_bytes(sslobj)
    _verify_peercerts_impl(
        sock_or_sslobj.context, cert_bytes, server_hostname=server_hostname
    )

import contextlib
import ctypes
import platform
import ssl
import typing
from ctypes import (
    CDLL,
    POINTER,
    c_bool,
    c_char_p,
    c_int32,
    c_long,
    c_uint32,
    c_ulong,
    c_void_p,
)
from ctypes.util import find_library

from ._ssl_constants import _set_ssl_context_verify_mode

_mac_version = platform.mac_ver()[0]
_mac_version_info = tuple(map(int, _mac_version.split(""."")))
if _mac_version_info < (10, 8):
    raise ImportError(
        f""Only OS X 10.8 and newer are supported, not {_mac_version_info[0]}.{_mac_version_info[1]}""
    )

_is_macos_version_10_14_or_later = _mac_version_info >= (10, 14)


def _load_cdll(name: str, macos10_16_path: str) -> CDLL:
    
    try:
        
        
        path: str | None
        if _mac_version_info >= (10, 16):
            path = macos10_16_path
        else:
            path = find_library(name)
        if not path:
            raise OSError  
        return CDLL(path, use_errno=True)
    except OSError:
        raise ImportError(f""The library {name} failed to load"") from None


Security = _load_cdll(
    ""Security"", ""/System/Library/Frameworks/Security.framework/Security""
)
CoreFoundation = _load_cdll(
    ""CoreFoundation"",
    ""/System/Library/Frameworks/CoreFoundation.framework/CoreFoundation"",
)

Boolean = c_bool
CFIndex = c_long
CFStringEncoding = c_uint32
CFData = c_void_p
CFString = c_void_p
CFArray = c_void_p
CFMutableArray = c_void_p
CFError = c_void_p
CFType = c_void_p
CFTypeID = c_ulong
CFTypeRef = POINTER(CFType)
CFAllocatorRef = c_void_p

OSStatus = c_int32

CFErrorRef = POINTER(CFError)
CFDataRef = POINTER(CFData)
CFStringRef = POINTER(CFString)
CFArrayRef = POINTER(CFArray)
CFMutableArrayRef = POINTER(CFMutableArray)
CFArrayCallBacks = c_void_p
CFOptionFlags = c_uint32

SecCertificateRef = POINTER(c_void_p)
SecPolicyRef = POINTER(c_void_p)
SecTrustRef = POINTER(c_void_p)
SecTrustResultType = c_uint32
SecTrustOptionFlags = c_uint32

try:
    Security.SecCertificateCreateWithData.argtypes = [CFAllocatorRef, CFDataRef]
    Security.SecCertificateCreateWithData.restype = SecCertificateRef

    Security.SecCertificateCopyData.argtypes = [SecCertificateRef]
    Security.SecCertificateCopyData.restype = CFDataRef

    Security.SecCopyErrorMessageString.argtypes = [OSStatus, c_void_p]
    Security.SecCopyErrorMessageString.restype = CFStringRef

    Security.SecTrustSetAnchorCertificates.argtypes = [SecTrustRef, CFArrayRef]
    Security.SecTrustSetAnchorCertificates.restype = OSStatus

    Security.SecTrustSetAnchorCertificatesOnly.argtypes = [SecTrustRef, Boolean]
    Security.SecTrustSetAnchorCertificatesOnly.restype = OSStatus

    Security.SecPolicyCreateRevocation.argtypes = [CFOptionFlags]
    Security.SecPolicyCreateRevocation.restype = SecPolicyRef

    Security.SecPolicyCreateSSL.argtypes = [Boolean, CFStringRef]
    Security.SecPolicyCreateSSL.restype = SecPolicyRef

    Security.SecTrustCreateWithCertificates.argtypes = [
        CFTypeRef,
        CFTypeRef,
        POINTER(SecTrustRef),
    ]
    Security.SecTrustCreateWithCertificates.restype = OSStatus

    Security.SecTrustGetTrustResult.argtypes = [
        SecTrustRef,
        POINTER(SecTrustResultType),
    ]
    Security.SecTrustGetTrustResult.restype = OSStatus

    Security.SecTrustEvaluate.argtypes = [
        SecTrustRef,
        POINTER(SecTrustResultType),
    ]
    Security.SecTrustEvaluate.restype = OSStatus

    Security.SecTrustRef = SecTrustRef  
    Security.SecTrustResultType = SecTrustResultType  
    Security.OSStatus = OSStatus  

    kSecRevocationUseAnyAvailableMethod = 3
    kSecRevocationRequirePositiveResponse = 8

    CoreFoundation.CFRelease.argtypes = [CFTypeRef]
    CoreFoundation.CFRelease.restype = None

    CoreFoundation.CFGetTypeID.argtypes = [CFTypeRef]
    CoreFoundation.CFGetTypeID.restype = CFTypeID

    CoreFoundation.CFStringCreateWithCString.argtypes = [
        CFAllocatorRef,
        c_char_p,
        CFStringEncoding,
    ]
    CoreFoundation.CFStringCreateWithCString.restype = CFStringRef

    CoreFoundation.CFStringGetCStringPtr.argtypes = [CFStringRef, CFStringEncoding]
    CoreFoundation.CFStringGetCStringPtr.restype = c_char_p

    CoreFoundation.CFStringGetCString.argtypes = [
        CFStringRef,
        c_char_p,
        CFIndex,
        CFStringEncoding,
    ]
    CoreFoundation.CFStringGetCString.restype = c_bool

    CoreFoundation.CFDataCreate.argtypes = [CFAllocatorRef, c_char_p, CFIndex]
    CoreFoundation.CFDataCreate.restype = CFDataRef

    CoreFoundation.CFDataGetLength.argtypes = [CFDataRef]
    CoreFoundation.CFDataGetLength.restype = CFIndex

    CoreFoundation.CFDataGetBytePtr.argtypes = [CFDataRef]
    CoreFoundation.CFDataGetBytePtr.restype = c_void_p

    CoreFoundation.CFArrayCreate.argtypes = [
        CFAllocatorRef,
        POINTER(CFTypeRef),
        CFIndex,
        CFArrayCallBacks,
    ]
    CoreFoundation.CFArrayCreate.restype = CFArrayRef

    CoreFoundation.CFArrayCreateMutable.argtypes = [
        CFAllocatorRef,
        CFIndex,
        CFArrayCallBacks,
    ]
    CoreFoundation.CFArrayCreateMutable.restype = CFMutableArrayRef

    CoreFoundation.CFArrayAppendValue.argtypes = [CFMutableArrayRef, c_void_p]
    CoreFoundation.CFArrayAppendValue.restype = None

    CoreFoundation.CFArrayGetCount.argtypes = [CFArrayRef]
    CoreFoundation.CFArrayGetCount.restype = CFIndex

    CoreFoundation.CFArrayGetValueAtIndex.argtypes = [CFArrayRef, CFIndex]
    CoreFoundation.CFArrayGetValueAtIndex.restype = c_void_p

    CoreFoundation.CFErrorGetCode.argtypes = [CFErrorRef]
    CoreFoundation.CFErrorGetCode.restype = CFIndex

    CoreFoundation.CFErrorCopyDescription.argtypes = [CFErrorRef]
    CoreFoundation.CFErrorCopyDescription.restype = CFStringRef

    CoreFoundation.kCFAllocatorDefault = CFAllocatorRef.in_dll(  
        CoreFoundation, ""kCFAllocatorDefault""
    )
    CoreFoundation.kCFTypeArrayCallBacks = c_void_p.in_dll(  
        CoreFoundation, ""kCFTypeArrayCallBacks""
    )

    CoreFoundation.CFTypeRef = CFTypeRef  
    CoreFoundation.CFArrayRef = CFArrayRef  
    CoreFoundation.CFStringRef = CFStringRef  
    CoreFoundation.CFErrorRef = CFErrorRef  

except AttributeError as e:
    raise ImportError(f""Error initializing ctypes: {e}"") from None


if _is_macos_version_10_14_or_later:
    try:
        Security.SecTrustEvaluateWithError.argtypes = [
            SecTrustRef,
            POINTER(CFErrorRef),
        ]
        Security.SecTrustEvaluateWithError.restype = c_bool
    except AttributeError as e:
        raise ImportError(f""Error initializing ctypes: {e}"") from None


def _handle_osstatus(result: OSStatus, _: typing.Any, args: typing.Any) -> typing.Any:
    
    if int(result) == 0:
        return args

    
    
    error_message_cfstring = None
    try:
        error_message_cfstring = Security.SecCopyErrorMessageString(result, None)

        
        
        error_message_cfstring_c_void_p = ctypes.cast(
            error_message_cfstring, ctypes.POINTER(ctypes.c_void_p)
        )
        message = CoreFoundation.CFStringGetCStringPtr(
            error_message_cfstring_c_void_p, CFConst.kCFStringEncodingUTF8
        )

        
        
        
        
        
        
        
        if message is None:
            buffer = ctypes.create_string_buffer(1024)
            result = CoreFoundation.CFStringGetCString(
                error_message_cfstring_c_void_p,
                buffer,
                1024,
                CFConst.kCFStringEncodingUTF8,
            )
            if not result:
                raise OSError(""Error copying C string from CFStringRef"")
            message = buffer.value

    finally:
        if error_message_cfstring is not None:
            CoreFoundation.CFRelease(error_message_cfstring)

    
    
    if message is None or message == """":
        message = f""SecureTransport operation returned a non-zero OSStatus: {result}""

    raise ssl.SSLError(message)


Security.SecTrustCreateWithCertificates.errcheck = _handle_osstatus  
Security.SecTrustSetAnchorCertificates.errcheck = _handle_osstatus  
Security.SecTrustSetAnchorCertificatesOnly.errcheck = _handle_osstatus  
Security.SecTrustGetTrustResult.errcheck = _handle_osstatus  
Security.SecTrustEvaluate.errcheck = _handle_osstatus  


class CFConst:
    

    kCFStringEncodingUTF8 = CFStringEncoding(0x08000100)

    errSecIncompleteCertRevocationCheck = -67635
    errSecHostNameMismatch = -67602
    errSecCertificateExpired = -67818
    errSecNotTrusted = -67843


def _bytes_to_cf_data_ref(value: bytes) -> CFDataRef:  
    return CoreFoundation.CFDataCreate(  
        CoreFoundation.kCFAllocatorDefault, value, len(value)
    )


def _bytes_to_cf_string(value: bytes) -> CFString:
    
    c_str = ctypes.c_char_p(value)
    cf_str = CoreFoundation.CFStringCreateWithCString(
        CoreFoundation.kCFAllocatorDefault,
        c_str,
        CFConst.kCFStringEncodingUTF8,
    )
    return cf_str  


def _cf_string_ref_to_str(cf_string_ref: CFStringRef) -> str | None:  
    

    string = CoreFoundation.CFStringGetCStringPtr(
        cf_string_ref, CFConst.kCFStringEncodingUTF8
    )
    if string is None:
        buffer = ctypes.create_string_buffer(1024)
        result = CoreFoundation.CFStringGetCString(
            cf_string_ref, buffer, 1024, CFConst.kCFStringEncodingUTF8
        )
        if not result:
            raise OSError(""Error copying C string from CFStringRef"")
        string = buffer.value
    if string is not None:
        string = string.decode(""utf-8"")
    return string  


def _der_certs_to_cf_cert_array(certs: list[bytes]) -> CFMutableArrayRef:  
    
    cf_array = CoreFoundation.CFArrayCreateMutable(
        CoreFoundation.kCFAllocatorDefault,
        0,
        ctypes.byref(CoreFoundation.kCFTypeArrayCallBacks),
    )
    if not cf_array:
        raise MemoryError(""Unable to allocate memory!"")

    for cert_data in certs:
        cf_data = None
        sec_cert_ref = None
        try:
            cf_data = _bytes_to_cf_data_ref(cert_data)
            sec_cert_ref = Security.SecCertificateCreateWithData(
                CoreFoundation.kCFAllocatorDefault, cf_data
            )
            CoreFoundation.CFArrayAppendValue(cf_array, sec_cert_ref)
        finally:
            if cf_data:
                CoreFoundation.CFRelease(cf_data)
            if sec_cert_ref:
                CoreFoundation.CFRelease(sec_cert_ref)

    return cf_array  


@contextlib.contextmanager
def _configure_context(ctx: ssl.SSLContext) -> typing.Iterator[None]:
    check_hostname = ctx.check_hostname
    verify_mode = ctx.verify_mode
    ctx.check_hostname = False
    _set_ssl_context_verify_mode(ctx, ssl.CERT_NONE)
    try:
        yield
    finally:
        ctx.check_hostname = check_hostname
        _set_ssl_context_verify_mode(ctx, verify_mode)


def _verify_peercerts_impl(
    ssl_context: ssl.SSLContext,
    cert_chain: list[bytes],
    server_hostname: str | None = None,
) -> None:
    certs = None
    policies = None
    trust = None
    try:
        
        
        if server_hostname is not None and ssl_context.check_hostname:
            cf_str_hostname = None
            try:
                cf_str_hostname = _bytes_to_cf_string(server_hostname.encode(""ascii""))
                ssl_policy = Security.SecPolicyCreateSSL(True, cf_str_hostname)
            finally:
                if cf_str_hostname:
                    CoreFoundation.CFRelease(cf_str_hostname)
        else:
            ssl_policy = Security.SecPolicyCreateSSL(True, None)

        policies = ssl_policy
        if ssl_context.verify_flags & ssl.VERIFY_CRL_CHECK_CHAIN:
            
            policies = CoreFoundation.CFArrayCreateMutable(
                CoreFoundation.kCFAllocatorDefault,
                0,
                ctypes.byref(CoreFoundation.kCFTypeArrayCallBacks),
            )
            CoreFoundation.CFArrayAppendValue(policies, ssl_policy)
            CoreFoundation.CFRelease(ssl_policy)
            revocation_policy = Security.SecPolicyCreateRevocation(
                kSecRevocationUseAnyAvailableMethod
                | kSecRevocationRequirePositiveResponse
            )
            CoreFoundation.CFArrayAppendValue(policies, revocation_policy)
            CoreFoundation.CFRelease(revocation_policy)
        elif ssl_context.verify_flags & ssl.VERIFY_CRL_CHECK_LEAF:
            raise NotImplementedError(""VERIFY_CRL_CHECK_LEAF not implemented for macOS"")

        certs = None
        try:
            certs = _der_certs_to_cf_cert_array(cert_chain)

            
            
            trust = Security.SecTrustRef()
            Security.SecTrustCreateWithCertificates(
                certs, policies, ctypes.byref(trust)
            )

        finally:
            
            
            if certs:
                CoreFoundation.CFRelease(certs)

        
        
        ctx_ca_certs_der: list[bytes] | None = ssl_context.get_ca_certs(
            binary_form=True
        )
        if ctx_ca_certs_der:
            ctx_ca_certs = None
            try:
                ctx_ca_certs = _der_certs_to_cf_cert_array(ctx_ca_certs_der)
                Security.SecTrustSetAnchorCertificates(trust, ctx_ca_certs)
            finally:
                if ctx_ca_certs:
                    CoreFoundation.CFRelease(ctx_ca_certs)

        
        Security.SecTrustSetAnchorCertificatesOnly(trust, False)

        
        
        
        if _is_macos_version_10_14_or_later:
            _verify_peercerts_impl_macos_10_14(ssl_context, trust)
        else:
            _verify_peercerts_impl_macos_10_13(ssl_context, trust)
    finally:
        if policies:
            CoreFoundation.CFRelease(policies)
        if trust:
            CoreFoundation.CFRelease(trust)


def _verify_peercerts_impl_macos_10_13(
    ssl_context: ssl.SSLContext, sec_trust_ref: typing.Any
) -> None:
    
    sec_trust_result_type = Security.SecTrustResultType()
    Security.SecTrustEvaluate(sec_trust_ref, ctypes.byref(sec_trust_result_type))

    try:
        sec_trust_result_type_as_int = int(sec_trust_result_type.value)
    except (ValueError, TypeError):
        sec_trust_result_type_as_int = -1

    
    
    if (
        ssl_context.verify_mode == ssl.CERT_REQUIRED
        and sec_trust_result_type_as_int not in (1, 4)
    ):
        
        
        
        sec_trust_result_type_to_message = {
            0: ""Invalid trust result type"",
            
            2: ""User confirmation required"",
            3: ""User specified that certificate is not trusted"",
            
            5: ""Recoverable trust failure occurred"",
            6: ""Fatal trust failure occurred"",
            7: ""Other error occurred, certificate may be revoked"",
        }
        error_message = sec_trust_result_type_to_message.get(
            sec_trust_result_type_as_int,
            f""Unknown trust result: {sec_trust_result_type_as_int}"",
        )

        err = ssl.SSLCertVerificationError(error_message)
        err.verify_message = error_message
        err.verify_code = sec_trust_result_type_as_int
        raise err


def _verify_peercerts_impl_macos_10_14(
    ssl_context: ssl.SSLContext, sec_trust_ref: typing.Any
) -> None:
    
    cf_error = CoreFoundation.CFErrorRef()
    sec_trust_eval_result = Security.SecTrustEvaluateWithError(
        sec_trust_ref, ctypes.byref(cf_error)
    )
    
    
    if sec_trust_eval_result == 1:
        is_trusted = True
    elif sec_trust_eval_result == 0:
        is_trusted = False
    else:
        raise ssl.SSLError(
            f""Unknown result from Security.SecTrustEvaluateWithError: {sec_trust_eval_result!r}""
        )

    cf_error_code = 0
    if not is_trusted:
        cf_error_code = CoreFoundation.CFErrorGetCode(cf_error)

        
        
        
        if ssl_context.verify_mode != ssl.CERT_REQUIRED and (
            cf_error_code == CFConst.errSecNotTrusted
            or cf_error_code == CFConst.errSecCertificateExpired
        ):
            is_trusted = True

    
    
    if not is_trusted:
        cf_error_string_ref = None
        try:
            cf_error_string_ref = CoreFoundation.CFErrorCopyDescription(cf_error)

            
            cf_error_message = (
                _cf_string_ref_to_str(cf_error_string_ref)
                or ""Certificate verification failed""
            )

            
            
            sec_trust_result_type = Security.SecTrustResultType()
            Security.SecTrustGetTrustResult(
                sec_trust_ref, ctypes.byref(sec_trust_result_type)
            )

            err = ssl.SSLCertVerificationError(cf_error_message)
            err.verify_message = cf_error_message
            err.verify_code = cf_error_code
            raise err
        finally:
            if cf_error_string_ref:
                CoreFoundation.CFRelease(cf_error_string_ref)

import contextlib
import os
import re
import ssl
import typing


_CA_FILE_CANDIDATES = [
    
    ""/etc/ssl/cert.pem"",
    
    ""/etc/pki/tls/cert.pem"",
    
    ""/etc/ssl/certs/ca-certificates.crt"",
    
    ""/etc/ssl/ca-bundle.pem"",
]

_HASHED_CERT_FILENAME_RE = re.compile(r""^[0-9a-fA-F]{8}\.[0-9]$"")


@contextlib.contextmanager
def _configure_context(ctx: ssl.SSLContext) -> typing.Iterator[None]:
    
    
    
    
    
    
    
    
    
    
    defaults = ssl.get_default_verify_paths()
    if defaults.cafile or (defaults.capath and _capath_contains_certs(defaults.capath)):
        ctx.set_default_verify_paths()
    else:
        
        
        
        for cafile in _CA_FILE_CANDIDATES:
            if os.path.isfile(cafile):
                ctx.load_verify_locations(cafile=cafile)
                break

    yield


def _capath_contains_certs(capath: str) -> bool:
    
    if not os.path.isdir(capath):
        return False
    for name in os.listdir(capath):
        if _HASHED_CERT_FILENAME_RE.match(name):
            return True
    return False


def _verify_peercerts_impl(
    ssl_context: ssl.SSLContext,
    cert_chain: list[bytes],
    server_hostname: str | None = None,
) -> None:
    
    
    pass

import ssl
import sys
import typing



_original_SSLContext = ssl.SSLContext
_original_super_SSLContext = super(_original_SSLContext, _original_SSLContext)






_truststore_SSLContext_dunder_class: typing.Optional[type]


_truststore_SSLContext_super_class: type

if sys.implementation.name == ""cpython"":
    _truststore_SSLContext_super_class = _original_SSLContext
    _truststore_SSLContext_dunder_class = None
else:
    _truststore_SSLContext_super_class = object
    _truststore_SSLContext_dunder_class = _original_SSLContext


def _set_ssl_context_verify_mode(
    ssl_context: ssl.SSLContext, verify_mode: ssl.VerifyMode
) -> None:
    _original_super_SSLContext.verify_mode.__set__(ssl_context, verify_mode)  

import contextlib
import ssl
import typing
from ctypes import WinDLL  
from ctypes import WinError  
from ctypes import (
    POINTER,
    Structure,
    c_char_p,
    c_ulong,
    c_void_p,
    c_wchar_p,
    cast,
    create_unicode_buffer,
    pointer,
    sizeof,
)
from ctypes.wintypes import (
    BOOL,
    DWORD,
    HANDLE,
    LONG,
    LPCSTR,
    LPCVOID,
    LPCWSTR,
    LPFILETIME,
    LPSTR,
    LPWSTR,
)
from typing import TYPE_CHECKING, Any

from ._ssl_constants import _set_ssl_context_verify_mode

HCERTCHAINENGINE = HANDLE
HCERTSTORE = HANDLE
HCRYPTPROV_LEGACY = HANDLE


class CERT_CONTEXT(Structure):
    _fields_ = (
        (""dwCertEncodingType"", DWORD),
        (""pbCertEncoded"", c_void_p),
        (""cbCertEncoded"", DWORD),
        (""pCertInfo"", c_void_p),
        (""hCertStore"", HCERTSTORE),
    )


PCERT_CONTEXT = POINTER(CERT_CONTEXT)
PCCERT_CONTEXT = POINTER(PCERT_CONTEXT)


class CERT_ENHKEY_USAGE(Structure):
    _fields_ = (
        (""cUsageIdentifier"", DWORD),
        (""rgpszUsageIdentifier"", POINTER(LPSTR)),
    )


PCERT_ENHKEY_USAGE = POINTER(CERT_ENHKEY_USAGE)


class CERT_USAGE_MATCH(Structure):
    _fields_ = (
        (""dwType"", DWORD),
        (""Usage"", CERT_ENHKEY_USAGE),
    )


class CERT_CHAIN_PARA(Structure):
    _fields_ = (
        (""cbSize"", DWORD),
        (""RequestedUsage"", CERT_USAGE_MATCH),
        (""RequestedIssuancePolicy"", CERT_USAGE_MATCH),
        (""dwUrlRetrievalTimeout"", DWORD),
        (""fCheckRevocationFreshnessTime"", BOOL),
        (""dwRevocationFreshnessTime"", DWORD),
        (""pftCacheResync"", LPFILETIME),
        (""pStrongSignPara"", c_void_p),
        (""dwStrongSignFlags"", DWORD),
    )


if TYPE_CHECKING:
    PCERT_CHAIN_PARA = pointer[CERT_CHAIN_PARA]  
else:
    PCERT_CHAIN_PARA = POINTER(CERT_CHAIN_PARA)


class CERT_TRUST_STATUS(Structure):
    _fields_ = (
        (""dwErrorStatus"", DWORD),
        (""dwInfoStatus"", DWORD),
    )


class CERT_CHAIN_ELEMENT(Structure):
    _fields_ = (
        (""cbSize"", DWORD),
        (""pCertContext"", PCERT_CONTEXT),
        (""TrustStatus"", CERT_TRUST_STATUS),
        (""pRevocationInfo"", c_void_p),
        (""pIssuanceUsage"", PCERT_ENHKEY_USAGE),
        (""pApplicationUsage"", PCERT_ENHKEY_USAGE),
        (""pwszExtendedErrorInfo"", LPCWSTR),
    )


PCERT_CHAIN_ELEMENT = POINTER(CERT_CHAIN_ELEMENT)


class CERT_SIMPLE_CHAIN(Structure):
    _fields_ = (
        (""cbSize"", DWORD),
        (""TrustStatus"", CERT_TRUST_STATUS),
        (""cElement"", DWORD),
        (""rgpElement"", POINTER(PCERT_CHAIN_ELEMENT)),
        (""pTrustListInfo"", c_void_p),
        (""fHasRevocationFreshnessTime"", BOOL),
        (""dwRevocationFreshnessTime"", DWORD),
    )


PCERT_SIMPLE_CHAIN = POINTER(CERT_SIMPLE_CHAIN)


class CERT_CHAIN_CONTEXT(Structure):
    _fields_ = (
        (""cbSize"", DWORD),
        (""TrustStatus"", CERT_TRUST_STATUS),
        (""cChain"", DWORD),
        (""rgpChain"", POINTER(PCERT_SIMPLE_CHAIN)),
        (""cLowerQualityChainContext"", DWORD),
        (""rgpLowerQualityChainContext"", c_void_p),
        (""fHasRevocationFreshnessTime"", BOOL),
        (""dwRevocationFreshnessTime"", DWORD),
    )


PCERT_CHAIN_CONTEXT = POINTER(CERT_CHAIN_CONTEXT)
PCCERT_CHAIN_CONTEXT = POINTER(PCERT_CHAIN_CONTEXT)


class SSL_EXTRA_CERT_CHAIN_POLICY_PARA(Structure):
    _fields_ = (
        (""cbSize"", DWORD),
        (""dwAuthType"", DWORD),
        (""fdwChecks"", DWORD),
        (""pwszServerName"", LPCWSTR),
    )


class CERT_CHAIN_POLICY_PARA(Structure):
    _fields_ = (
        (""cbSize"", DWORD),
        (""dwFlags"", DWORD),
        (""pvExtraPolicyPara"", c_void_p),
    )


PCERT_CHAIN_POLICY_PARA = POINTER(CERT_CHAIN_POLICY_PARA)


class CERT_CHAIN_POLICY_STATUS(Structure):
    _fields_ = (
        (""cbSize"", DWORD),
        (""dwError"", DWORD),
        (""lChainIndex"", LONG),
        (""lElementIndex"", LONG),
        (""pvExtraPolicyStatus"", c_void_p),
    )


PCERT_CHAIN_POLICY_STATUS = POINTER(CERT_CHAIN_POLICY_STATUS)


class CERT_CHAIN_ENGINE_CONFIG(Structure):
    _fields_ = (
        (""cbSize"", DWORD),
        (""hRestrictedRoot"", HCERTSTORE),
        (""hRestrictedTrust"", HCERTSTORE),
        (""hRestrictedOther"", HCERTSTORE),
        (""cAdditionalStore"", DWORD),
        (""rghAdditionalStore"", c_void_p),
        (""dwFlags"", DWORD),
        (""dwUrlRetrievalTimeout"", DWORD),
        (""MaximumCachedCertificates"", DWORD),
        (""CycleDetectionModulus"", DWORD),
        (""hExclusiveRoot"", HCERTSTORE),
        (""hExclusiveTrustedPeople"", HCERTSTORE),
        (""dwExclusiveFlags"", DWORD),
    )


PCERT_CHAIN_ENGINE_CONFIG = POINTER(CERT_CHAIN_ENGINE_CONFIG)
PHCERTCHAINENGINE = POINTER(HCERTCHAINENGINE)

X509_ASN_ENCODING = 0x00000001
PKCS_7_ASN_ENCODING = 0x00010000
CERT_STORE_PROV_MEMORY = b""Memory""
CERT_STORE_ADD_USE_EXISTING = 2
USAGE_MATCH_TYPE_OR = 1
OID_PKIX_KP_SERVER_AUTH = c_char_p(b""1.3.6.1.5.5.7.3.1"")
CERT_CHAIN_REVOCATION_CHECK_END_CERT = 0x10000000
CERT_CHAIN_REVOCATION_CHECK_CHAIN = 0x20000000
CERT_CHAIN_POLICY_IGNORE_ALL_NOT_TIME_VALID_FLAGS = 0x00000007
CERT_CHAIN_POLICY_IGNORE_INVALID_BASIC_CONSTRAINTS_FLAG = 0x00000008
CERT_CHAIN_POLICY_ALLOW_UNKNOWN_CA_FLAG = 0x00000010
CERT_CHAIN_POLICY_IGNORE_INVALID_NAME_FLAG = 0x00000040
CERT_CHAIN_POLICY_IGNORE_WRONG_USAGE_FLAG = 0x00000020
CERT_CHAIN_POLICY_IGNORE_INVALID_POLICY_FLAG = 0x00000080
CERT_CHAIN_POLICY_IGNORE_ALL_REV_UNKNOWN_FLAGS = 0x00000F00
CERT_CHAIN_POLICY_ALLOW_TESTROOT_FLAG = 0x00008000
CERT_CHAIN_POLICY_TRUST_TESTROOT_FLAG = 0x00004000
SECURITY_FLAG_IGNORE_CERT_CN_INVALID = 0x00001000
AUTHTYPE_SERVER = 2
CERT_CHAIN_POLICY_SSL = 4
FORMAT_MESSAGE_FROM_SYSTEM = 0x00001000
FORMAT_MESSAGE_IGNORE_INSERTS = 0x00000200


CERT_CHAIN_POLICY_VERIFY_MODE_NONE_FLAGS = (
    CERT_CHAIN_POLICY_IGNORE_ALL_NOT_TIME_VALID_FLAGS
    | CERT_CHAIN_POLICY_IGNORE_INVALID_BASIC_CONSTRAINTS_FLAG
    | CERT_CHAIN_POLICY_ALLOW_UNKNOWN_CA_FLAG
    | CERT_CHAIN_POLICY_IGNORE_INVALID_NAME_FLAG
    | CERT_CHAIN_POLICY_IGNORE_WRONG_USAGE_FLAG
    | CERT_CHAIN_POLICY_IGNORE_INVALID_POLICY_FLAG
    | CERT_CHAIN_POLICY_IGNORE_ALL_REV_UNKNOWN_FLAGS
    | CERT_CHAIN_POLICY_ALLOW_TESTROOT_FLAG
    | CERT_CHAIN_POLICY_TRUST_TESTROOT_FLAG
)

wincrypt = WinDLL(""crypt32.dll"")
kernel32 = WinDLL(""kernel32.dll"")


def _handle_win_error(result: bool, _: Any, args: Any) -> Any:
    if not result:
        
        raise WinError()
    return args


CertCreateCertificateChainEngine = wincrypt.CertCreateCertificateChainEngine
CertCreateCertificateChainEngine.argtypes = (
    PCERT_CHAIN_ENGINE_CONFIG,
    PHCERTCHAINENGINE,
)
CertCreateCertificateChainEngine.errcheck = _handle_win_error

CertOpenStore = wincrypt.CertOpenStore
CertOpenStore.argtypes = (LPCSTR, DWORD, HCRYPTPROV_LEGACY, DWORD, c_void_p)
CertOpenStore.restype = HCERTSTORE
CertOpenStore.errcheck = _handle_win_error

CertAddEncodedCertificateToStore = wincrypt.CertAddEncodedCertificateToStore
CertAddEncodedCertificateToStore.argtypes = (
    HCERTSTORE,
    DWORD,
    c_char_p,
    DWORD,
    DWORD,
    PCCERT_CONTEXT,
)
CertAddEncodedCertificateToStore.restype = BOOL

CertCreateCertificateContext = wincrypt.CertCreateCertificateContext
CertCreateCertificateContext.argtypes = (DWORD, c_char_p, DWORD)
CertCreateCertificateContext.restype = PCERT_CONTEXT
CertCreateCertificateContext.errcheck = _handle_win_error

CertGetCertificateChain = wincrypt.CertGetCertificateChain
CertGetCertificateChain.argtypes = (
    HCERTCHAINENGINE,
    PCERT_CONTEXT,
    LPFILETIME,
    HCERTSTORE,
    PCERT_CHAIN_PARA,
    DWORD,
    c_void_p,
    PCCERT_CHAIN_CONTEXT,
)
CertGetCertificateChain.restype = BOOL
CertGetCertificateChain.errcheck = _handle_win_error

CertVerifyCertificateChainPolicy = wincrypt.CertVerifyCertificateChainPolicy
CertVerifyCertificateChainPolicy.argtypes = (
    c_ulong,
    PCERT_CHAIN_CONTEXT,
    PCERT_CHAIN_POLICY_PARA,
    PCERT_CHAIN_POLICY_STATUS,
)
CertVerifyCertificateChainPolicy.restype = BOOL

CertCloseStore = wincrypt.CertCloseStore
CertCloseStore.argtypes = (HCERTSTORE, DWORD)
CertCloseStore.restype = BOOL
CertCloseStore.errcheck = _handle_win_error

CertFreeCertificateChain = wincrypt.CertFreeCertificateChain
CertFreeCertificateChain.argtypes = (PCERT_CHAIN_CONTEXT,)

CertFreeCertificateContext = wincrypt.CertFreeCertificateContext
CertFreeCertificateContext.argtypes = (PCERT_CONTEXT,)

CertFreeCertificateChainEngine = wincrypt.CertFreeCertificateChainEngine
CertFreeCertificateChainEngine.argtypes = (HCERTCHAINENGINE,)

FormatMessageW = kernel32.FormatMessageW
FormatMessageW.argtypes = (
    DWORD,
    LPCVOID,
    DWORD,
    DWORD,
    LPWSTR,
    DWORD,
    c_void_p,
)
FormatMessageW.restype = DWORD


def _verify_peercerts_impl(
    ssl_context: ssl.SSLContext,
    cert_chain: list[bytes],
    server_hostname: str | None = None,
) -> None:
    

    
    
    if not cert_chain:
        raise ssl.SSLCertVerificationError(""Peer sent no certificates to verify"")

    pCertContext = None
    hIntermediateCertStore = CertOpenStore(CERT_STORE_PROV_MEMORY, 0, None, 0, None)
    try:
        
        for cert_bytes in cert_chain[1:]:
            CertAddEncodedCertificateToStore(
                hIntermediateCertStore,
                X509_ASN_ENCODING | PKCS_7_ASN_ENCODING,
                cert_bytes,
                len(cert_bytes),
                CERT_STORE_ADD_USE_EXISTING,
                None,
            )

        
        leaf_cert = cert_chain[0]
        pCertContext = CertCreateCertificateContext(
            X509_ASN_ENCODING | PKCS_7_ASN_ENCODING, leaf_cert, len(leaf_cert)
        )

        
        cert_enhkey_usage = CERT_ENHKEY_USAGE()
        cert_enhkey_usage.cUsageIdentifier = 1
        cert_enhkey_usage.rgpszUsageIdentifier = (c_char_p * 1)(OID_PKIX_KP_SERVER_AUTH)
        cert_usage_match = CERT_USAGE_MATCH()
        cert_usage_match.Usage = cert_enhkey_usage
        chain_params = CERT_CHAIN_PARA()
        chain_params.RequestedUsage = cert_usage_match
        chain_params.cbSize = sizeof(chain_params)
        pChainPara = pointer(chain_params)

        if ssl_context.verify_flags & ssl.VERIFY_CRL_CHECK_CHAIN:
            chain_flags = CERT_CHAIN_REVOCATION_CHECK_CHAIN
        elif ssl_context.verify_flags & ssl.VERIFY_CRL_CHECK_LEAF:
            chain_flags = CERT_CHAIN_REVOCATION_CHECK_END_CERT
        else:
            chain_flags = 0

        try:
            
            
            _get_and_verify_cert_chain(
                ssl_context,
                None,
                hIntermediateCertStore,
                pCertContext,
                pChainPara,
                server_hostname,
                chain_flags=chain_flags,
            )
        except ssl.SSLCertVerificationError as e:
            
            
            
            
            custom_ca_certs: list[bytes] | None = ssl_context.get_ca_certs(
                binary_form=True
            )
            if custom_ca_certs:
                try:
                    _verify_using_custom_ca_certs(
                        ssl_context,
                        custom_ca_certs,
                        hIntermediateCertStore,
                        pCertContext,
                        pChainPara,
                        server_hostname,
                        chain_flags=chain_flags,
                    )
                
                except ssl.SSLCertVerificationError:
                    raise e from None
            else:
                raise
    finally:
        CertCloseStore(hIntermediateCertStore, 0)
        if pCertContext:
            CertFreeCertificateContext(pCertContext)


def _get_and_verify_cert_chain(
    ssl_context: ssl.SSLContext,
    hChainEngine: HCERTCHAINENGINE | None,
    hIntermediateCertStore: HCERTSTORE,
    pPeerCertContext: c_void_p,
    pChainPara: PCERT_CHAIN_PARA,  
    server_hostname: str | None,
    chain_flags: int,
) -> None:
    ppChainContext = None
    try:
        
        ppChainContext = pointer(PCERT_CHAIN_CONTEXT())
        CertGetCertificateChain(
            hChainEngine,  
            pPeerCertContext,  
            None,  
            hIntermediateCertStore,  
            pChainPara,  
            chain_flags,
            None,  
            ppChainContext,  
        )
        pChainContext = ppChainContext.contents

        
        ssl_extra_cert_chain_policy_para = SSL_EXTRA_CERT_CHAIN_POLICY_PARA()
        ssl_extra_cert_chain_policy_para.cbSize = sizeof(
            ssl_extra_cert_chain_policy_para
        )
        ssl_extra_cert_chain_policy_para.dwAuthType = AUTHTYPE_SERVER
        ssl_extra_cert_chain_policy_para.fdwChecks = 0
        if ssl_context.check_hostname is False:
            ssl_extra_cert_chain_policy_para.fdwChecks = (
                SECURITY_FLAG_IGNORE_CERT_CN_INVALID
            )
        if server_hostname:
            ssl_extra_cert_chain_policy_para.pwszServerName = c_wchar_p(server_hostname)

        chain_policy = CERT_CHAIN_POLICY_PARA()
        chain_policy.pvExtraPolicyPara = cast(
            pointer(ssl_extra_cert_chain_policy_para), c_void_p
        )
        if ssl_context.verify_mode == ssl.CERT_NONE:
            chain_policy.dwFlags |= CERT_CHAIN_POLICY_VERIFY_MODE_NONE_FLAGS
        chain_policy.cbSize = sizeof(chain_policy)

        pPolicyPara = pointer(chain_policy)
        policy_status = CERT_CHAIN_POLICY_STATUS()
        policy_status.cbSize = sizeof(policy_status)
        pPolicyStatus = pointer(policy_status)
        CertVerifyCertificateChainPolicy(
            CERT_CHAIN_POLICY_SSL,
            pChainContext,
            pPolicyPara,
            pPolicyStatus,
        )

        
        error_code = policy_status.dwError
        if error_code:
            
            error_message_buf = create_unicode_buffer(1024)
            error_message_chars = FormatMessageW(
                FORMAT_MESSAGE_FROM_SYSTEM | FORMAT_MESSAGE_IGNORE_INSERTS,
                None,
                error_code,
                0,
                error_message_buf,
                sizeof(error_message_buf),
                None,
            )

            
            
            
            if error_message_chars <= 0:
                error_message = f""Certificate chain policy error {error_code:
            else:
                error_message = error_message_buf.value.strip()

            err = ssl.SSLCertVerificationError(error_message)
            err.verify_message = error_message
            err.verify_code = error_code
            raise err from None
    finally:
        if ppChainContext:
            CertFreeCertificateChain(ppChainContext.contents)


def _verify_using_custom_ca_certs(
    ssl_context: ssl.SSLContext,
    custom_ca_certs: list[bytes],
    hIntermediateCertStore: HCERTSTORE,
    pPeerCertContext: c_void_p,
    pChainPara: PCERT_CHAIN_PARA,  
    server_hostname: str | None,
    chain_flags: int,
) -> None:
    hChainEngine = None
    hRootCertStore = CertOpenStore(CERT_STORE_PROV_MEMORY, 0, None, 0, None)
    try:
        
        for cert_bytes in custom_ca_certs:
            CertAddEncodedCertificateToStore(
                hRootCertStore,
                X509_ASN_ENCODING | PKCS_7_ASN_ENCODING,
                cert_bytes,
                len(cert_bytes),
                CERT_STORE_ADD_USE_EXISTING,
                None,
            )

        
        
        cert_chain_engine_config = CERT_CHAIN_ENGINE_CONFIG()
        cert_chain_engine_config.cbSize = sizeof(cert_chain_engine_config)
        cert_chain_engine_config.hExclusiveRoot = hRootCertStore
        pConfig = pointer(cert_chain_engine_config)
        phChainEngine = pointer(HCERTCHAINENGINE())
        CertCreateCertificateChainEngine(
            pConfig,
            phChainEngine,
        )
        hChainEngine = phChainEngine.contents

        
        _get_and_verify_cert_chain(
            ssl_context,
            hChainEngine,
            hIntermediateCertStore,
            pPeerCertContext,
            pChainPara,
            server_hostname,
            chain_flags,
        )
    finally:
        if hChainEngine:
            CertFreeCertificateChainEngine(hChainEngine)
        CertCloseStore(hRootCertStore, 0)


@contextlib.contextmanager
def _configure_context(ctx: ssl.SSLContext) -> typing.Iterator[None]:
    check_hostname = ctx.check_hostname
    verify_mode = ctx.verify_mode
    ctx.check_hostname = False
    _set_ssl_context_verify_mode(ctx, ssl.CERT_NONE)
    try:
        yield
    finally:
        ctx.check_hostname = check_hostname
        _set_ssl_context_verify_mode(ctx, verify_mode)



import sys as _sys

if _sys.version_info < (3, 10):
    raise ImportError(""truststore requires Python 3.10 or later"")



if _sys.version_info < (3, 13) and _sys.implementation.name not in (""cpython"", ""pypy""):
    try:
        import ssl as _ssl
    except ImportError:
        raise ImportError(""truststore requires the 'ssl' module"")
    else:
        _sslmem = _ssl.MemoryBIO()
        _sslobj = _ssl.create_default_context().wrap_bio(
            _sslmem,
            _sslmem,
        )
        try:
            while not hasattr(_sslobj, ""get_unverified_chain""):
                _sslobj = _sslobj._sslobj  
        except AttributeError:
            raise ImportError(
                ""truststore requires peer certificate chain APIs to be available""
            ) from None

        del _ssl, _sslobj, _sslmem  

from ._api import SSLContext, extract_from_ssl, inject_into_ssl  

del _api, _sys  

__all__ = [""SSLContext"", ""inject_into_ssl"", ""extract_from_ssl""]
__version__ = ""0.10.1""

from __future__ import absolute_import

import datetime
import logging
import os
import re
import socket
import warnings
from socket import error as SocketError
from socket import timeout as SocketTimeout

from .packages import six
from .packages.six.moves.http_client import HTTPConnection as _HTTPConnection
from .packages.six.moves.http_client import HTTPException  
from .util.proxy import create_proxy_ssl_context

try:  
    import ssl

    BaseSSLError = ssl.SSLError
except (ImportError, AttributeError):  
    ssl = None

    class BaseSSLError(BaseException):
        pass


try:
    
    ConnectionError = ConnectionError
except NameError:
    
    class ConnectionError(Exception):
        pass


try:  
    
    BrokenPipeError = BrokenPipeError
except NameError:  

    class BrokenPipeError(Exception):
        pass


from ._collections import HTTPHeaderDict  
from ._version import __version__
from .exceptions import (
    ConnectTimeoutError,
    NewConnectionError,
    SubjectAltNameWarning,
    SystemTimeWarning,
)
from .util import SKIP_HEADER, SKIPPABLE_HEADERS, connection
from .util.ssl_ import (
    assert_fingerprint,
    create_urllib3_context,
    is_ipaddress,
    resolve_cert_reqs,
    resolve_ssl_version,
    ssl_wrap_socket,
)
from .util.ssl_match_hostname import CertificateError, match_hostname

log = logging.getLogger(__name__)

port_by_scheme = {""http"": 80, ""https"": 443}



RECENT_DATE = datetime.date(2024, 1, 1)

_CONTAINS_CONTROL_CHAR_RE = re.compile(r""[^-!


class HTTPConnection(_HTTPConnection, object):
    

    default_port = port_by_scheme[""http""]

    
    
    default_socket_options = [(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)]

    
    is_verified = False

    
    
    proxy_is_verified = None

    def __init__(self, *args, **kw):
        if not six.PY2:
            kw.pop(""strict"", None)

        
        self.source_address = kw.get(""source_address"")

        
        
        self.socket_options = kw.pop(""socket_options"", self.default_socket_options)

        
        self.proxy = kw.pop(""proxy"", None)
        self.proxy_config = kw.pop(""proxy_config"", None)

        _HTTPConnection.__init__(self, *args, **kw)

    @property
    def host(self):
        
        return self._dns_host.rstrip(""."")

    @host.setter
    def host(self, value):
        
        self._dns_host = value

    def _new_conn(self):
        
        extra_kw = {}
        if self.source_address:
            extra_kw[""source_address""] = self.source_address

        if self.socket_options:
            extra_kw[""socket_options""] = self.socket_options

        try:
            conn = connection.create_connection(
                (self._dns_host, self.port), self.timeout, **extra_kw
            )

        except SocketTimeout:
            raise ConnectTimeoutError(
                self,
                ""Connection to %s timed out. (connect timeout=%s)""
                % (self.host, self.timeout),
            )

        except SocketError as e:
            raise NewConnectionError(
                self, ""Failed to establish a new connection: %s"" % e
            )

        return conn

    def _is_using_tunnel(self):
        
        return getattr(self, ""_tunnel_host"", None)

    def _prepare_conn(self, conn):
        self.sock = conn
        if self._is_using_tunnel():
            
            self._tunnel()
            
            self.auto_open = 0

    def connect(self):
        conn = self._new_conn()
        self._prepare_conn(conn)

    def putrequest(self, method, url, *args, **kwargs):
        
        
        
        match = _CONTAINS_CONTROL_CHAR_RE.search(method)
        if match:
            raise ValueError(
                ""Method cannot contain non-token characters %r (found at least %r)""
                % (method, match.group())
            )

        return _HTTPConnection.putrequest(self, method, url, *args, **kwargs)

    def putheader(self, header, *values):
        
        if not any(isinstance(v, str) and v == SKIP_HEADER for v in values):
            _HTTPConnection.putheader(self, header, *values)
        elif six.ensure_str(header.lower()) not in SKIPPABLE_HEADERS:
            raise ValueError(
                ""urllib3.util.SKIP_HEADER only supports '%s'""
                % (""', '"".join(map(str.title, sorted(SKIPPABLE_HEADERS))),)
            )

    def request(self, method, url, body=None, headers=None):
        
        
        if getattr(self, ""sock"", None) is not None:
            self.sock.settimeout(self.timeout)

        if headers is None:
            headers = {}
        else:
            
            headers = headers.copy()
        if ""user-agent"" not in (six.ensure_str(k.lower()) for k in headers):
            headers[""User-Agent""] = _get_default_user_agent()
        super(HTTPConnection, self).request(method, url, body=body, headers=headers)

    def request_chunked(self, method, url, body=None, headers=None):
        
        headers = headers or {}
        header_keys = set([six.ensure_str(k.lower()) for k in headers])
        skip_accept_encoding = ""accept-encoding"" in header_keys
        skip_host = ""host"" in header_keys
        self.putrequest(
            method, url, skip_accept_encoding=skip_accept_encoding, skip_host=skip_host
        )
        if ""user-agent"" not in header_keys:
            self.putheader(""User-Agent"", _get_default_user_agent())
        for header, value in headers.items():
            self.putheader(header, value)
        if ""transfer-encoding"" not in header_keys:
            self.putheader(""Transfer-Encoding"", ""chunked"")
        self.endheaders()

        if body is not None:
            stringish_types = six.string_types + (bytes,)
            if isinstance(body, stringish_types):
                body = (body,)
            for chunk in body:
                if not chunk:
                    continue
                if not isinstance(chunk, bytes):
                    chunk = chunk.encode(""utf8"")
                len_str = hex(len(chunk))[2:]
                to_send = bytearray(len_str.encode())
                to_send += b""\r\n""
                to_send += chunk
                to_send += b""\r\n""
                self.send(to_send)

        
        self.send(b""0\r\n\r\n"")


class HTTPSConnection(HTTPConnection):
    

    default_port = port_by_scheme[""https""]

    cert_reqs = None
    ca_certs = None
    ca_cert_dir = None
    ca_cert_data = None
    ssl_version = None
    assert_fingerprint = None
    tls_in_tls_required = False

    def __init__(
        self,
        host,
        port=None,
        key_file=None,
        cert_file=None,
        key_password=None,
        strict=None,
        timeout=socket._GLOBAL_DEFAULT_TIMEOUT,
        ssl_context=None,
        server_hostname=None,
        **kw
    ):

        HTTPConnection.__init__(self, host, port, strict=strict, timeout=timeout, **kw)

        self.key_file = key_file
        self.cert_file = cert_file
        self.key_password = key_password
        self.ssl_context = ssl_context
        self.server_hostname = server_hostname

        
        
        self._protocol = ""https""

    def set_cert(
        self,
        key_file=None,
        cert_file=None,
        cert_reqs=None,
        key_password=None,
        ca_certs=None,
        assert_hostname=None,
        assert_fingerprint=None,
        ca_cert_dir=None,
        ca_cert_data=None,
    ):
        
        
        
        if cert_reqs is None:
            if self.ssl_context is not None:
                cert_reqs = self.ssl_context.verify_mode
            else:
                cert_reqs = resolve_cert_reqs(None)

        self.key_file = key_file
        self.cert_file = cert_file
        self.cert_reqs = cert_reqs
        self.key_password = key_password
        self.assert_hostname = assert_hostname
        self.assert_fingerprint = assert_fingerprint
        self.ca_certs = ca_certs and os.path.expanduser(ca_certs)
        self.ca_cert_dir = ca_cert_dir and os.path.expanduser(ca_cert_dir)
        self.ca_cert_data = ca_cert_data

    def connect(self):
        
        self.sock = conn = self._new_conn()
        hostname = self.host
        tls_in_tls = False

        if self._is_using_tunnel():
            if self.tls_in_tls_required:
                self.sock = conn = self._connect_tls_proxy(hostname, conn)
                tls_in_tls = True

            
            
            self._tunnel()
            
            self.auto_open = 0

            
            hostname = self._tunnel_host

        server_hostname = hostname
        if self.server_hostname is not None:
            server_hostname = self.server_hostname

        is_time_off = datetime.date.today() < RECENT_DATE
        if is_time_off:
            warnings.warn(
                (
                    ""System time is way off (before {0}). This will probably ""
                    ""lead to SSL verification errors""
                ).format(RECENT_DATE),
                SystemTimeWarning,
            )

        
        
        default_ssl_context = False
        if self.ssl_context is None:
            default_ssl_context = True
            self.ssl_context = create_urllib3_context(
                ssl_version=resolve_ssl_version(self.ssl_version),
                cert_reqs=resolve_cert_reqs(self.cert_reqs),
            )

        context = self.ssl_context
        context.verify_mode = resolve_cert_reqs(self.cert_reqs)

        
        
        if (
            not self.ca_certs
            and not self.ca_cert_dir
            and not self.ca_cert_data
            and default_ssl_context
            and hasattr(context, ""load_default_certs"")
        ):
            context.load_default_certs()

        self.sock = ssl_wrap_socket(
            sock=conn,
            keyfile=self.key_file,
            certfile=self.cert_file,
            key_password=self.key_password,
            ca_certs=self.ca_certs,
            ca_cert_dir=self.ca_cert_dir,
            ca_cert_data=self.ca_cert_data,
            server_hostname=server_hostname,
            ssl_context=context,
            tls_in_tls=tls_in_tls,
        )

        
        
        
        if (
            default_ssl_context
            and self.ssl_version is None
            and hasattr(self.sock, ""version"")
            and self.sock.version() in {""TLSv1"", ""TLSv1.1""}
        ):  
            warnings.warn(
                ""Negotiating TLSv1/TLSv1.1 by default is deprecated ""
                ""and will be disabled in urllib3 v2.0.0. Connecting to ""
                ""'%s' with '%s' can be enabled by explicitly opting-in ""
                ""with 'ssl_version'"" % (self.host, self.sock.version()),
                DeprecationWarning,
            )

        if self.assert_fingerprint:
            assert_fingerprint(
                self.sock.getpeercert(binary_form=True), self.assert_fingerprint
            )
        elif (
            context.verify_mode != ssl.CERT_NONE
            and not getattr(context, ""check_hostname"", False)
            and self.assert_hostname is not False
        ):
            
            
            
            cert = self.sock.getpeercert()
            if not cert.get(""subjectAltName"", ()):
                warnings.warn(
                    (
                        ""Certificate for {0} has no `subjectAltName`, falling back to check for a ""
                        ""`commonName` for now. This feature is being removed by major browsers and ""
                        ""deprecated by RFC 2818. (See https://github.com/urllib3/urllib3/issues/497 ""
                        ""for details.)"".format(hostname)
                    ),
                    SubjectAltNameWarning,
                )
            _match_hostname(cert, self.assert_hostname or server_hostname)

        self.is_verified = (
            context.verify_mode == ssl.CERT_REQUIRED
            or self.assert_fingerprint is not None
        )

    def _connect_tls_proxy(self, hostname, conn):
        
        proxy_config = self.proxy_config
        ssl_context = proxy_config.ssl_context
        if ssl_context:
            
            
            return ssl_wrap_socket(
                sock=conn,
                server_hostname=hostname,
                ssl_context=ssl_context,
            )

        ssl_context = create_proxy_ssl_context(
            self.ssl_version,
            self.cert_reqs,
            self.ca_certs,
            self.ca_cert_dir,
            self.ca_cert_data,
        )

        
        
        socket = ssl_wrap_socket(
            sock=conn,
            ca_certs=self.ca_certs,
            ca_cert_dir=self.ca_cert_dir,
            ca_cert_data=self.ca_cert_data,
            server_hostname=hostname,
            ssl_context=ssl_context,
        )

        if ssl_context.verify_mode != ssl.CERT_NONE and not getattr(
            ssl_context, ""check_hostname"", False
        ):
            
            
            
            cert = socket.getpeercert()
            if not cert.get(""subjectAltName"", ()):
                warnings.warn(
                    (
                        ""Certificate for {0} has no `subjectAltName`, falling back to check for a ""
                        ""`commonName` for now. This feature is being removed by major browsers and ""
                        ""deprecated by RFC 2818. (See https://github.com/urllib3/urllib3/issues/497 ""
                        ""for details.)"".format(hostname)
                    ),
                    SubjectAltNameWarning,
                )
            _match_hostname(cert, hostname)

        self.proxy_is_verified = ssl_context.verify_mode == ssl.CERT_REQUIRED
        return socket


def _match_hostname(cert, asserted_hostname):
    
    
    
    stripped_hostname = asserted_hostname.strip(""u[]"")
    if is_ipaddress(stripped_hostname):
        asserted_hostname = stripped_hostname

    try:
        match_hostname(cert, asserted_hostname)
    except CertificateError as e:
        log.warning(
            ""Certificate did not match expected hostname: %s. Certificate: %s"",
            asserted_hostname,
            cert,
        )
        
        
        e._peer_cert = cert
        raise


def _get_default_user_agent():
    return ""python-urllib3/%s"" % __version__


class DummyConnection(object):
    

    pass


if not ssl:
    HTTPSConnection = DummyConnection  


VerifiedHTTPSConnection = HTTPSConnection

from __future__ import absolute_import

import errno
import logging
import re
import socket
import sys
import warnings
from socket import error as SocketError
from socket import timeout as SocketTimeout

from ._collections import HTTPHeaderDict
from .connection import (
    BaseSSLError,
    BrokenPipeError,
    DummyConnection,
    HTTPConnection,
    HTTPException,
    HTTPSConnection,
    VerifiedHTTPSConnection,
    port_by_scheme,
)
from .exceptions import (
    ClosedPoolError,
    EmptyPoolError,
    HeaderParsingError,
    HostChangedError,
    InsecureRequestWarning,
    LocationValueError,
    MaxRetryError,
    NewConnectionError,
    ProtocolError,
    ProxyError,
    ReadTimeoutError,
    SSLError,
    TimeoutError,
)
from .packages import six
from .packages.six.moves import queue
from .request import RequestMethods
from .response import HTTPResponse
from .util.connection import is_connection_dropped
from .util.proxy import connection_requires_http_tunnel
from .util.queue import LifoQueue
from .util.request import set_file_position
from .util.response import assert_header_parsing
from .util.retry import Retry
from .util.ssl_match_hostname import CertificateError
from .util.timeout import Timeout
from .util.url import Url, _encode_target
from .util.url import _normalize_host as normalize_host
from .util.url import get_host, parse_url

try:  
    import weakref

    weakref_finalize = weakref.finalize
except AttributeError:  
    from .packages.backports.weakref_finalize import weakref_finalize

xrange = six.moves.xrange

log = logging.getLogger(__name__)

_Default = object()



class ConnectionPool(object):
    

    scheme = None
    QueueCls = LifoQueue

    def __init__(self, host, port=None):
        if not host:
            raise LocationValueError(""No host specified."")

        self.host = _normalize_host(host, scheme=self.scheme)
        self._proxy_host = host.lower()
        self.port = port

    def __str__(self):
        return ""%s(host=%r, port=%r)"" % (type(self).__name__, self.host, self.port)

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()
        
        return False

    def close(self):
        
        pass



_blocking_errnos = {errno.EAGAIN, errno.EWOULDBLOCK}


class HTTPConnectionPool(ConnectionPool, RequestMethods):
    

    scheme = ""http""
    ConnectionCls = HTTPConnection
    ResponseCls = HTTPResponse

    def __init__(
        self,
        host,
        port=None,
        strict=False,
        timeout=Timeout.DEFAULT_TIMEOUT,
        maxsize=1,
        block=False,
        headers=None,
        retries=None,
        _proxy=None,
        _proxy_headers=None,
        _proxy_config=None,
        **conn_kw
    ):
        ConnectionPool.__init__(self, host, port)
        RequestMethods.__init__(self, headers)

        self.strict = strict

        if not isinstance(timeout, Timeout):
            timeout = Timeout.from_float(timeout)

        if retries is None:
            retries = Retry.DEFAULT

        self.timeout = timeout
        self.retries = retries

        self.pool = self.QueueCls(maxsize)
        self.block = block

        self.proxy = _proxy
        self.proxy_headers = _proxy_headers or {}
        self.proxy_config = _proxy_config

        
        for _ in xrange(maxsize):
            self.pool.put(None)

        
        self.num_connections = 0
        self.num_requests = 0
        self.conn_kw = conn_kw

        if self.proxy:
            
            
            
            self.conn_kw.setdefault(""socket_options"", [])

            self.conn_kw[""proxy""] = self.proxy
            self.conn_kw[""proxy_config""] = self.proxy_config

        
        
        
        
        pool = self.pool

        
        
        weakref_finalize(self, _close_pool_connections, pool)

    def _new_conn(self):
        
        self.num_connections += 1
        log.debug(
            ""Starting new HTTP connection (%d): %s:%s"",
            self.num_connections,
            self.host,
            self.port or ""80"",
        )

        conn = self.ConnectionCls(
            host=self.host,
            port=self.port,
            timeout=self.timeout.connect_timeout,
            strict=self.strict,
            **self.conn_kw
        )
        return conn

    def _get_conn(self, timeout=None):
        
        conn = None
        try:
            conn = self.pool.get(block=self.block, timeout=timeout)

        except AttributeError:  
            raise ClosedPoolError(self, ""Pool is closed."")

        except queue.Empty:
            if self.block:
                raise EmptyPoolError(
                    self,
                    ""Pool reached maximum size and no more connections are allowed."",
                )
            pass  

        
        if conn and is_connection_dropped(conn):
            log.debug(""Resetting dropped connection: %s"", self.host)
            conn.close()
            if getattr(conn, ""auto_open"", 1) == 0:
                
                
                
                conn = None

        return conn or self._new_conn()

    def _put_conn(self, conn):
        
        try:
            self.pool.put(conn, block=False)
            return  
        except AttributeError:
            
            pass
        except queue.Full:
            
            log.warning(
                ""Connection pool is full, discarding connection: %s. Connection pool size: %s"",
                self.host,
                self.pool.qsize(),
            )
        
        if conn:
            conn.close()

    def _validate_conn(self, conn):
        
        pass

    def _prepare_proxy(self, conn):
        
        pass

    def _get_timeout(self, timeout):
        
        if timeout is _Default:
            return self.timeout.clone()

        if isinstance(timeout, Timeout):
            return timeout.clone()
        else:
            
            
            return Timeout.from_float(timeout)

    def _raise_timeout(self, err, url, timeout_value):
        

        if isinstance(err, SocketTimeout):
            raise ReadTimeoutError(
                self, url, ""Read timed out. (read timeout=%s)"" % timeout_value
            )

        
        
        if hasattr(err, ""errno"") and err.errno in _blocking_errnos:
            raise ReadTimeoutError(
                self, url, ""Read timed out. (read timeout=%s)"" % timeout_value
            )

        
        
        
        if ""timed out"" in str(err) or ""did not complete (read)"" in str(
            err
        ):  
            raise ReadTimeoutError(
                self, url, ""Read timed out. (read timeout=%s)"" % timeout_value
            )

    def _make_request(
        self, conn, method, url, timeout=_Default, chunked=False, **httplib_request_kw
    ):
        
        self.num_requests += 1

        timeout_obj = self._get_timeout(timeout)
        timeout_obj.start_connect()
        conn.timeout = Timeout.resolve_default_timeout(timeout_obj.connect_timeout)

        
        try:
            self._validate_conn(conn)
        except (SocketTimeout, BaseSSLError) as e:
            
            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)
            raise

        
        
        try:
            if chunked:
                conn.request_chunked(method, url, **httplib_request_kw)
            else:
                conn.request(method, url, **httplib_request_kw)

        
        
        
        except BrokenPipeError:
            
            pass
        except IOError as e:
            
            
            
            if e.errno not in {
                errno.EPIPE,
                errno.ESHUTDOWN,
                errno.EPROTOTYPE,
                errno.ECONNRESET,
            }:
                raise

        
        read_timeout = timeout_obj.read_timeout

        
        if getattr(conn, ""sock"", None):
            
            
            
            
            
            if read_timeout == 0:
                raise ReadTimeoutError(
                    self, url, ""Read timed out. (read timeout=%s)"" % read_timeout
                )
            if read_timeout is Timeout.DEFAULT_TIMEOUT:
                conn.sock.settimeout(socket.getdefaulttimeout())
            else:  
                conn.sock.settimeout(read_timeout)

        
        try:
            try:
                
                httplib_response = conn.getresponse(buffering=True)
            except TypeError:
                
                try:
                    httplib_response = conn.getresponse()
                except BaseException as e:
                    
                    
                    
                    six.raise_from(e, None)
        except (SocketTimeout, BaseSSLError, SocketError) as e:
            self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
            raise

        
        http_version = getattr(conn, ""_http_vsn_str"", ""HTTP/?"")
        log.debug(
            '%s://%s:%s ""%s %s %s"" %s %s',
            self.scheme,
            self.host,
            self.port,
            method,
            url,
            http_version,
            httplib_response.status,
            httplib_response.length,
        )

        try:
            assert_header_parsing(httplib_response.msg)
        except (HeaderParsingError, TypeError) as hpe:  
            log.warning(
                ""Failed to parse headers (url=%s): %s"",
                self._absolute_url(url),
                hpe,
                exc_info=True,
            )

        return httplib_response

    def _absolute_url(self, path):
        return Url(scheme=self.scheme, host=self.host, port=self.port, path=path).url

    def close(self):
        
        if self.pool is None:
            return
        
        old_pool, self.pool = self.pool, None

        
        _close_pool_connections(old_pool)

    def is_same_host(self, url):
        
        if url.startswith(""/""):
            return True

        
        scheme, host, port = get_host(url)
        if host is not None:
            host = _normalize_host(host, scheme=scheme)

        
        if self.port and not port:
            port = port_by_scheme.get(scheme)
        elif not self.port and port == port_by_scheme.get(scheme):
            port = None

        return (scheme, host, port) == (self.scheme, self.host, self.port)

    def urlopen(
        self,
        method,
        url,
        body=None,
        headers=None,
        retries=None,
        redirect=True,
        assert_same_host=True,
        timeout=_Default,
        pool_timeout=None,
        release_conn=None,
        chunked=False,
        body_pos=None,
        **response_kw
    ):
        

        parsed_url = parse_url(url)
        destination_scheme = parsed_url.scheme

        if headers is None:
            headers = self.headers

        if not isinstance(retries, Retry):
            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)

        if release_conn is None:
            release_conn = response_kw.get(""preload_content"", True)

        
        if assert_same_host and not self.is_same_host(url):
            raise HostChangedError(self, url, retries)

        
        if url.startswith(""/""):
            url = six.ensure_str(_encode_target(url))
        else:
            url = six.ensure_str(parsed_url.url)

        conn = None

        
        
        
        
        
        
        
        
        
        release_this_conn = release_conn

        http_tunnel_required = connection_requires_http_tunnel(
            self.proxy, self.proxy_config, destination_scheme
        )

        
        
        
        if not http_tunnel_required:
            headers = headers.copy()
            headers.update(self.proxy_headers)

        
        
        err = None

        
        
        clean_exit = False

        
        
        body_pos = set_file_position(body, body_pos)

        try:
            
            timeout_obj = self._get_timeout(timeout)
            conn = self._get_conn(timeout=pool_timeout)

            conn.timeout = timeout_obj.connect_timeout

            is_new_proxy_conn = self.proxy is not None and not getattr(
                conn, ""sock"", None
            )
            if is_new_proxy_conn and http_tunnel_required:
                self._prepare_proxy(conn)

            
            httplib_response = self._make_request(
                conn,
                method,
                url,
                timeout=timeout_obj,
                body=body,
                headers=headers,
                chunked=chunked,
            )

            
            
            
            
            response_conn = conn if not release_conn else None

            
            response_kw[""request_method""] = method

            
            response = self.ResponseCls.from_httplib(
                httplib_response,
                pool=self,
                connection=response_conn,
                retries=retries,
                **response_kw
            )

            
            clean_exit = True

        except EmptyPoolError:
            
            clean_exit = True
            release_this_conn = False
            raise

        except (
            TimeoutError,
            HTTPException,
            SocketError,
            ProtocolError,
            BaseSSLError,
            SSLError,
            CertificateError,
        ) as e:
            
            
            clean_exit = False

            def _is_ssl_error_message_from_http_proxy(ssl_error):
                
                
                
                message = "" "".join(re.split(""[^a-z]"", str(ssl_error).lower()))
                return (
                    ""wrong version number"" in message
                    or ""unknown protocol"" in message
                    or ""record layer failure"" in message
                )

            
            
            
            
            if (
                isinstance(e, BaseSSLError)
                and self.proxy
                and _is_ssl_error_message_from_http_proxy(e)
                and conn.proxy
                and conn.proxy.scheme == ""https""
            ):
                e = ProxyError(
                    ""Your proxy appears to only use HTTP and not HTTPS, ""
                    ""try changing your proxy URL to be HTTP. See: ""
                    ""https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html""
                    ""
                    SSLError(e),
                )
            elif isinstance(e, (BaseSSLError, CertificateError)):
                e = SSLError(e)
            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:
                e = ProxyError(""Cannot connect to proxy."", e)
            elif isinstance(e, (SocketError, HTTPException)):
                e = ProtocolError(""Connection aborted."", e)

            retries = retries.increment(
                method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
            )
            retries.sleep()

            
            err = e

        finally:
            if not clean_exit:
                
                
                
                
                conn = conn and conn.close()
                release_this_conn = True

            if release_this_conn:
                
                
                
                self._put_conn(conn)

        if not conn:
            
            log.warning(
                ""Retrying (%r) after connection broken by '%r': %s"", retries, err, url
            )
            return self.urlopen(
                method,
                url,
                body,
                headers,
                retries,
                redirect,
                assert_same_host,
                timeout=timeout,
                pool_timeout=pool_timeout,
                release_conn=release_conn,
                chunked=chunked,
                body_pos=body_pos,
                **response_kw
            )

        
        redirect_location = redirect and response.get_redirect_location()
        if redirect_location:
            if response.status == 303:
                
                method = ""GET""
                
                body = None
                headers = HTTPHeaderDict(headers)._prepare_for_method_change()

            try:
                retries = retries.increment(method, url, response=response, _pool=self)
            except MaxRetryError:
                if retries.raise_on_redirect:
                    response.drain_conn()
                    raise
                return response

            response.drain_conn()
            retries.sleep_for_retry(response)
            log.debug(""Redirecting %s -> %s"", url, redirect_location)
            return self.urlopen(
                method,
                redirect_location,
                body,
                headers,
                retries=retries,
                redirect=redirect,
                assert_same_host=assert_same_host,
                timeout=timeout,
                pool_timeout=pool_timeout,
                release_conn=release_conn,
                chunked=chunked,
                body_pos=body_pos,
                **response_kw
            )

        
        has_retry_after = bool(response.headers.get(""Retry-After""))
        if retries.is_retry(method, response.status, has_retry_after):
            try:
                retries = retries.increment(method, url, response=response, _pool=self)
            except MaxRetryError:
                if retries.raise_on_status:
                    response.drain_conn()
                    raise
                return response

            response.drain_conn()
            retries.sleep(response)
            log.debug(""Retry: %s"", url)
            return self.urlopen(
                method,
                url,
                body,
                headers,
                retries=retries,
                redirect=redirect,
                assert_same_host=assert_same_host,
                timeout=timeout,
                pool_timeout=pool_timeout,
                release_conn=release_conn,
                chunked=chunked,
                body_pos=body_pos,
                **response_kw
            )

        return response


class HTTPSConnectionPool(HTTPConnectionPool):
    

    scheme = ""https""
    ConnectionCls = HTTPSConnection

    def __init__(
        self,
        host,
        port=None,
        strict=False,
        timeout=Timeout.DEFAULT_TIMEOUT,
        maxsize=1,
        block=False,
        headers=None,
        retries=None,
        _proxy=None,
        _proxy_headers=None,
        key_file=None,
        cert_file=None,
        cert_reqs=None,
        key_password=None,
        ca_certs=None,
        ssl_version=None,
        assert_hostname=None,
        assert_fingerprint=None,
        ca_cert_dir=None,
        **conn_kw
    ):

        HTTPConnectionPool.__init__(
            self,
            host,
            port,
            strict,
            timeout,
            maxsize,
            block,
            headers,
            retries,
            _proxy,
            _proxy_headers,
            **conn_kw
        )

        self.key_file = key_file
        self.cert_file = cert_file
        self.cert_reqs = cert_reqs
        self.key_password = key_password
        self.ca_certs = ca_certs
        self.ca_cert_dir = ca_cert_dir
        self.ssl_version = ssl_version
        self.assert_hostname = assert_hostname
        self.assert_fingerprint = assert_fingerprint

    def _prepare_conn(self, conn):
        

        if isinstance(conn, VerifiedHTTPSConnection):
            conn.set_cert(
                key_file=self.key_file,
                key_password=self.key_password,
                cert_file=self.cert_file,
                cert_reqs=self.cert_reqs,
                ca_certs=self.ca_certs,
                ca_cert_dir=self.ca_cert_dir,
                assert_hostname=self.assert_hostname,
                assert_fingerprint=self.assert_fingerprint,
            )
            conn.ssl_version = self.ssl_version
        return conn

    def _prepare_proxy(self, conn):
        

        conn.set_tunnel(self._proxy_host, self.port, self.proxy_headers)

        if self.proxy.scheme == ""https"":
            conn.tls_in_tls_required = True

        conn.connect()

    def _new_conn(self):
        
        self.num_connections += 1
        log.debug(
            ""Starting new HTTPS connection (%d): %s:%s"",
            self.num_connections,
            self.host,
            self.port or ""443"",
        )

        if not self.ConnectionCls or self.ConnectionCls is DummyConnection:
            raise SSLError(
                ""Can't connect to HTTPS URL because the SSL module is not available.""
            )

        actual_host = self.host
        actual_port = self.port
        if self.proxy is not None:
            actual_host = self.proxy.host
            actual_port = self.proxy.port

        conn = self.ConnectionCls(
            host=actual_host,
            port=actual_port,
            timeout=self.timeout.connect_timeout,
            strict=self.strict,
            cert_file=self.cert_file,
            key_file=self.key_file,
            key_password=self.key_password,
            **self.conn_kw
        )

        return self._prepare_conn(conn)

    def _validate_conn(self, conn):
        
        super(HTTPSConnectionPool, self)._validate_conn(conn)

        
        if not getattr(conn, ""sock"", None):  
            conn.connect()

        if not conn.is_verified:
            warnings.warn(
                (
                    ""Unverified HTTPS request is being made to host '%s'. ""
                    ""Adding certificate verification is strongly advised. See: ""
                    ""https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html""
                    ""
                ),
                InsecureRequestWarning,
            )

        if getattr(conn, ""proxy_is_verified"", None) is False:
            warnings.warn(
                (
                    ""Unverified HTTPS connection done to an HTTPS proxy. ""
                    ""Adding certificate verification is strongly advised. See: ""
                    ""https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html""
                    ""
                ),
                InsecureRequestWarning,
            )


def connection_from_url(url, **kw):
    
    scheme, host, port = get_host(url)
    port = port or port_by_scheme.get(scheme, 80)
    if scheme == ""https"":
        return HTTPSConnectionPool(host, port=port, **kw)
    else:
        return HTTPConnectionPool(host, port=port, **kw)


def _normalize_host(host, scheme):
    

    host = normalize_host(host, scheme)

    
    
    
    
    
    
    if host.startswith(""["") and host.endswith(""]""):
        host = host[1:-1]
    return host


def _close_pool_connections(pool):
    
    try:
        while True:
            conn = pool.get(block=False)
            if conn:
                conn.close()
    except queue.Empty:
        pass  

from __future__ import absolute_import

from .packages.six.moves.http_client import IncompleteRead as httplib_IncompleteRead




class HTTPError(Exception):
    

    pass


class HTTPWarning(Warning):
    

    pass


class PoolError(HTTPError):
    

    def __init__(self, pool, message):
        self.pool = pool
        HTTPError.__init__(self, ""%s: %s"" % (pool, message))

    def __reduce__(self):
        
        return self.__class__, (None, None)


class RequestError(PoolError):
    

    def __init__(self, pool, url, message):
        self.url = url
        PoolError.__init__(self, pool, message)

    def __reduce__(self):
        
        return self.__class__, (None, self.url, None)


class SSLError(HTTPError):
    

    pass


class ProxyError(HTTPError):
    

    def __init__(self, message, error, *args):
        super(ProxyError, self).__init__(message, error, *args)
        self.original_error = error


class DecodeError(HTTPError):
    

    pass


class ProtocolError(HTTPError):
    

    pass



ConnectionError = ProtocolError





class MaxRetryError(RequestError):
    

    def __init__(self, pool, url, reason=None):
        self.reason = reason

        message = ""Max retries exceeded with url: %s (Caused by %r)"" % (url, reason)

        RequestError.__init__(self, pool, url, message)


class HostChangedError(RequestError):
    

    def __init__(self, pool, url, retries=3):
        message = ""Tried to open a foreign host with url: %s"" % url
        RequestError.__init__(self, pool, url, message)
        self.retries = retries


class TimeoutStateError(HTTPError):
    

    pass


class TimeoutError(HTTPError):
    

    pass


class ReadTimeoutError(TimeoutError, RequestError):
    

    pass




class ConnectTimeoutError(TimeoutError):
    

    pass


class NewConnectionError(ConnectTimeoutError, PoolError):
    

    pass


class EmptyPoolError(PoolError):
    

    pass


class ClosedPoolError(PoolError):
    

    pass


class LocationValueError(ValueError, HTTPError):
    

    pass


class LocationParseError(LocationValueError):
    

    def __init__(self, location):
        message = ""Failed to parse: %s"" % location
        HTTPError.__init__(self, message)

        self.location = location


class URLSchemeUnknown(LocationValueError):
    

    def __init__(self, scheme):
        message = ""Not supported URL scheme %s"" % scheme
        super(URLSchemeUnknown, self).__init__(message)

        self.scheme = scheme


class ResponseError(HTTPError):
    

    GENERIC_ERROR = ""too many error responses""
    SPECIFIC_ERROR = ""too many {status_code} error responses""


class SecurityWarning(HTTPWarning):
    

    pass


class SubjectAltNameWarning(SecurityWarning):
    

    pass


class InsecureRequestWarning(SecurityWarning):
    

    pass


class SystemTimeWarning(SecurityWarning):
    

    pass


class InsecurePlatformWarning(SecurityWarning):
    

    pass


class SNIMissingWarning(HTTPWarning):
    

    pass


class DependencyWarning(HTTPWarning):
    

    pass


class ResponseNotChunked(ProtocolError, ValueError):
    

    pass


class BodyNotHttplibCompatible(HTTPError):
    

    pass


class IncompleteRead(HTTPError, httplib_IncompleteRead):
    

    def __init__(self, partial, expected):
        super(IncompleteRead, self).__init__(partial, expected)

    def __repr__(self):
        return ""IncompleteRead(%i bytes read, %i more expected)"" % (
            self.partial,
            self.expected,
        )


class InvalidChunkLength(HTTPError, httplib_IncompleteRead):
    

    def __init__(self, response, length):
        super(InvalidChunkLength, self).__init__(
            response.tell(), response.length_remaining
        )
        self.response = response
        self.length = length

    def __repr__(self):
        return ""InvalidChunkLength(got length %r, %i bytes read)"" % (
            self.length,
            self.partial,
        )


class InvalidHeader(HTTPError):
    

    pass


class ProxySchemeUnknown(AssertionError, URLSchemeUnknown):
    

    

    def __init__(self, scheme):
        
        
        if scheme == ""localhost"":
            scheme = None
        if scheme is None:
            message = ""Proxy URL had no scheme, should start with http:// or https://""
        else:
            message = (
                ""Proxy URL had unsupported scheme %s, should use http:// or https://""
                % scheme
            )
        super(ProxySchemeUnknown, self).__init__(message)


class ProxySchemeUnsupported(ValueError):
    

    pass


class HeaderParsingError(HTTPError):
    

    def __init__(self, defects, unparsed_data):
        message = ""%s, unparsed data: %r"" % (defects or ""Unknown"", unparsed_data)
        super(HeaderParsingError, self).__init__(message)


class UnrewindableBodyError(HTTPError):
    

    pass

from __future__ import absolute_import

import email.utils
import mimetypes
import re

from .packages import six


def guess_content_type(filename, default=""application/octet-stream""):
    
    if filename:
        return mimetypes.guess_type(filename)[0] or default
    return default


def format_header_param_rfc2231(name, value):
    
    if isinstance(value, six.binary_type):
        value = value.decode(""utf-8"")

    if not any(ch in value for ch in '""\\\r\n'):
        result = u'%s=""%s""' % (name, value)
        try:
            result.encode(""ascii"")
        except (UnicodeEncodeError, UnicodeDecodeError):
            pass
        else:
            return result

    if six.PY2:  
        value = value.encode(""utf-8"")

    
    
    value = email.utils.encode_rfc2231(value, ""utf-8"")
    value = ""%s*=%s"" % (name, value)

    if six.PY2:  
        value = value.decode(""utf-8"")

    return value


_HTML5_REPLACEMENTS = {
    u""\u0022"": u""%22"",
    
    u""\u005C"": u""\u005C\u005C"",
}


_HTML5_REPLACEMENTS.update(
    {
        six.unichr(cc): u""%{:02X}"".format(cc)
        for cc in range(0x00, 0x1F + 1)
        if cc not in (0x1B,)
    }
)


def _replace_multiple(value, needles_and_replacements):
    def replacer(match):
        return needles_and_replacements[match.group(0)]

    pattern = re.compile(
        r""|"".join([re.escape(needle) for needle in needles_and_replacements.keys()])
    )

    result = pattern.sub(replacer, value)

    return result


def format_header_param_html5(name, value):
    
    if isinstance(value, six.binary_type):
        value = value.decode(""utf-8"")

    value = _replace_multiple(value, _HTML5_REPLACEMENTS)

    return u'%s=""%s""' % (name, value)



format_header_param = format_header_param_html5


class RequestField(object):
    

    def __init__(
        self,
        name,
        data,
        filename=None,
        headers=None,
        header_formatter=format_header_param_html5,
    ):
        self._name = name
        self._filename = filename
        self.data = data
        self.headers = {}
        if headers:
            self.headers = dict(headers)
        self.header_formatter = header_formatter

    @classmethod
    def from_tuples(cls, fieldname, value, header_formatter=format_header_param_html5):
        
        if isinstance(value, tuple):
            if len(value) == 3:
                filename, data, content_type = value
            else:
                filename, data = value
                content_type = guess_content_type(filename)
        else:
            filename = None
            content_type = None
            data = value

        request_param = cls(
            fieldname, data, filename=filename, header_formatter=header_formatter
        )
        request_param.make_multipart(content_type=content_type)

        return request_param

    def _render_part(self, name, value):
        

        return self.header_formatter(name, value)

    def _render_parts(self, header_parts):
        
        parts = []
        iterable = header_parts
        if isinstance(header_parts, dict):
            iterable = header_parts.items()

        for name, value in iterable:
            if value is not None:
                parts.append(self._render_part(name, value))

        return u""; "".join(parts)

    def render_headers(self):
        
        lines = []

        sort_keys = [""Content-Disposition"", ""Content-Type"", ""Content-Location""]
        for sort_key in sort_keys:
            if self.headers.get(sort_key, False):
                lines.append(u""%s: %s"" % (sort_key, self.headers[sort_key]))

        for header_name, header_value in self.headers.items():
            if header_name not in sort_keys:
                if header_value:
                    lines.append(u""%s: %s"" % (header_name, header_value))

        lines.append(u""\r\n"")
        return u""\r\n"".join(lines)

    def make_multipart(
        self, content_disposition=None, content_type=None, content_location=None
    ):
        
        self.headers[""Content-Disposition""] = content_disposition or u""form-data""
        self.headers[""Content-Disposition""] += u""; "".join(
            [
                u"""",
                self._render_parts(
                    ((u""name"", self._name), (u""filename"", self._filename))
                ),
            ]
        )
        self.headers[""Content-Type""] = content_type
        self.headers[""Content-Location""] = content_location

from __future__ import absolute_import

import binascii
import codecs
import os
from io import BytesIO

from .fields import RequestField
from .packages import six
from .packages.six import b

writer = codecs.lookup(""utf-8"")[3]


def choose_boundary():
    
    boundary = binascii.hexlify(os.urandom(16))
    if not six.PY2:
        boundary = boundary.decode(""ascii"")
    return boundary


def iter_field_objects(fields):
    
    if isinstance(fields, dict):
        i = six.iteritems(fields)
    else:
        i = iter(fields)

    for field in i:
        if isinstance(field, RequestField):
            yield field
        else:
            yield RequestField.from_tuples(*field)


def iter_fields(fields):
    
    if isinstance(fields, dict):
        return ((k, v) for k, v in six.iteritems(fields))

    return ((k, v) for k, v in fields)


def encode_multipart_formdata(fields, boundary=None):
    
    body = BytesIO()
    if boundary is None:
        boundary = choose_boundary()

    for field in iter_field_objects(fields):
        body.write(b(""--%s\r\n"" % (boundary)))

        writer(body).write(field.render_headers())
        data = field.data

        if isinstance(data, int):
            data = str(data)  

        if isinstance(data, six.text_type):
            writer(body).write(data)
        else:
            body.write(data)

        body.write(b""\r\n"")

    body.write(b(""--%s--\r\n"" % (boundary)))

    content_type = str(""multipart/form-data; boundary=%s"" % boundary)

    return body.getvalue(), content_type

from __future__ import absolute_import

import collections
import functools
import logging

from ._collections import HTTPHeaderDict, RecentlyUsedContainer
from .connectionpool import HTTPConnectionPool, HTTPSConnectionPool, port_by_scheme
from .exceptions import (
    LocationValueError,
    MaxRetryError,
    ProxySchemeUnknown,
    ProxySchemeUnsupported,
    URLSchemeUnknown,
)
from .packages import six
from .packages.six.moves.urllib.parse import urljoin
from .request import RequestMethods
from .util.proxy import connection_requires_http_tunnel
from .util.retry import Retry
from .util.url import parse_url

__all__ = [""PoolManager"", ""ProxyManager"", ""proxy_from_url""]


log = logging.getLogger(__name__)

SSL_KEYWORDS = (
    ""key_file"",
    ""cert_file"",
    ""cert_reqs"",
    ""ca_certs"",
    ""ssl_version"",
    ""ca_cert_dir"",
    ""ssl_context"",
    ""key_password"",
    ""server_hostname"",
)



_key_fields = (
    ""key_scheme"",  
    ""key_host"",  
    ""key_port"",  
    ""key_timeout"",  
    ""key_retries"",  
    ""key_strict"",  
    ""key_block"",  
    ""key_source_address"",  
    ""key_key_file"",  
    ""key_key_password"",  
    ""key_cert_file"",  
    ""key_cert_reqs"",  
    ""key_ca_certs"",  
    ""key_ssl_version"",  
    ""key_ca_cert_dir"",  
    ""key_ssl_context"",  
    ""key_maxsize"",  
    ""key_headers"",  
    ""key__proxy"",  
    ""key__proxy_headers"",  
    ""key__proxy_config"",  
    ""key_socket_options"",  
    ""key__socks_options"",  
    ""key_assert_hostname"",  
    ""key_assert_fingerprint"",  
    ""key_server_hostname"",  
)



PoolKey = collections.namedtuple(""PoolKey"", _key_fields)

_proxy_config_fields = (""ssl_context"", ""use_forwarding_for_https"")
ProxyConfig = collections.namedtuple(""ProxyConfig"", _proxy_config_fields)


def _default_key_normalizer(key_class, request_context):
    
    
    context = request_context.copy()
    context[""scheme""] = context[""scheme""].lower()
    context[""host""] = context[""host""].lower()

    
    for key in (""headers"", ""_proxy_headers"", ""_socks_options""):
        if key in context and context[key] is not None:
            context[key] = frozenset(context[key].items())

    
    
    socket_opts = context.get(""socket_options"")
    if socket_opts is not None:
        context[""socket_options""] = tuple(socket_opts)

    
    
    for key in list(context.keys()):
        context[""key_"" + key] = context.pop(key)

    
    for field in key_class._fields:
        if field not in context:
            context[field] = None

    return key_class(**context)






key_fn_by_scheme = {
    ""http"": functools.partial(_default_key_normalizer, PoolKey),
    ""https"": functools.partial(_default_key_normalizer, PoolKey),
}

pool_classes_by_scheme = {""http"": HTTPConnectionPool, ""https"": HTTPSConnectionPool}


class PoolManager(RequestMethods):
    

    proxy = None
    proxy_config = None

    def __init__(self, num_pools=10, headers=None, **connection_pool_kw):
        RequestMethods.__init__(self, headers)
        self.connection_pool_kw = connection_pool_kw
        self.pools = RecentlyUsedContainer(num_pools)

        
        
        self.pool_classes_by_scheme = pool_classes_by_scheme
        self.key_fn_by_scheme = key_fn_by_scheme.copy()

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.clear()
        
        return False

    def _new_pool(self, scheme, host, port, request_context=None):
        
        pool_cls = self.pool_classes_by_scheme[scheme]
        if request_context is None:
            request_context = self.connection_pool_kw.copy()

        
        
        
        
        for key in (""scheme"", ""host"", ""port""):
            request_context.pop(key, None)

        if scheme == ""http"":
            for kw in SSL_KEYWORDS:
                request_context.pop(kw, None)

        return pool_cls(host, port, **request_context)

    def clear(self):
        
        self.pools.clear()

    def connection_from_host(self, host, port=None, scheme=""http"", pool_kwargs=None):
        

        if not host:
            raise LocationValueError(""No host specified."")

        request_context = self._merge_pool_kwargs(pool_kwargs)
        request_context[""scheme""] = scheme or ""http""
        if not port:
            port = port_by_scheme.get(request_context[""scheme""].lower(), 80)
        request_context[""port""] = port
        request_context[""host""] = host

        return self.connection_from_context(request_context)

    def connection_from_context(self, request_context):
        
        scheme = request_context[""scheme""].lower()
        pool_key_constructor = self.key_fn_by_scheme.get(scheme)
        if not pool_key_constructor:
            raise URLSchemeUnknown(scheme)
        pool_key = pool_key_constructor(request_context)

        return self.connection_from_pool_key(pool_key, request_context=request_context)

    def connection_from_pool_key(self, pool_key, request_context=None):
        
        with self.pools.lock:
            
            
            pool = self.pools.get(pool_key)
            if pool:
                return pool

            
            scheme = request_context[""scheme""]
            host = request_context[""host""]
            port = request_context[""port""]
            pool = self._new_pool(scheme, host, port, request_context=request_context)
            self.pools[pool_key] = pool

        return pool

    def connection_from_url(self, url, pool_kwargs=None):
        
        u = parse_url(url)
        return self.connection_from_host(
            u.host, port=u.port, scheme=u.scheme, pool_kwargs=pool_kwargs
        )

    def _merge_pool_kwargs(self, override):
        
        base_pool_kwargs = self.connection_pool_kw.copy()
        if override:
            for key, value in override.items():
                if value is None:
                    try:
                        del base_pool_kwargs[key]
                    except KeyError:
                        pass
                else:
                    base_pool_kwargs[key] = value
        return base_pool_kwargs

    def _proxy_requires_url_absolute_form(self, parsed_url):
        
        if self.proxy is None:
            return False

        return not connection_requires_http_tunnel(
            self.proxy, self.proxy_config, parsed_url.scheme
        )

    def _validate_proxy_scheme_url_selection(self, url_scheme):
        
        if self.proxy is None or url_scheme != ""https"":
            return

        if self.proxy.scheme != ""https"":
            return

        if six.PY2 and not self.proxy_config.use_forwarding_for_https:
            raise ProxySchemeUnsupported(
                ""Contacting HTTPS destinations through HTTPS proxies ""
                ""'via CONNECT tunnels' is not supported in Python 2""
            )

    def urlopen(self, method, url, redirect=True, **kw):
        
        u = parse_url(url)
        self._validate_proxy_scheme_url_selection(u.scheme)

        conn = self.connection_from_host(u.host, port=u.port, scheme=u.scheme)

        kw[""assert_same_host""] = False
        kw[""redirect""] = False

        if ""headers"" not in kw:
            kw[""headers""] = self.headers.copy()

        if self._proxy_requires_url_absolute_form(u):
            response = conn.urlopen(method, url, **kw)
        else:
            response = conn.urlopen(method, u.request_uri, **kw)

        redirect_location = redirect and response.get_redirect_location()
        if not redirect_location:
            return response

        
        redirect_location = urljoin(url, redirect_location)

        if response.status == 303:
            
            method = ""GET""
            
            kw[""body""] = None
            kw[""headers""] = HTTPHeaderDict(kw[""headers""])._prepare_for_method_change()

        retries = kw.get(""retries"")
        if not isinstance(retries, Retry):
            retries = Retry.from_int(retries, redirect=redirect)

        
        
        
        if retries.remove_headers_on_redirect and not conn.is_same_host(
            redirect_location
        ):
            headers = list(six.iterkeys(kw[""headers""]))
            for header in headers:
                if header.lower() in retries.remove_headers_on_redirect:
                    kw[""headers""].pop(header, None)

        try:
            retries = retries.increment(method, url, response=response, _pool=conn)
        except MaxRetryError:
            if retries.raise_on_redirect:
                response.drain_conn()
                raise
            return response

        kw[""retries""] = retries
        kw[""redirect""] = redirect

        log.info(""Redirecting %s -> %s"", url, redirect_location)

        response.drain_conn()
        return self.urlopen(method, redirect_location, **kw)


class ProxyManager(PoolManager):
    

    def __init__(
        self,
        proxy_url,
        num_pools=10,
        headers=None,
        proxy_headers=None,
        proxy_ssl_context=None,
        use_forwarding_for_https=False,
        **connection_pool_kw
    ):

        if isinstance(proxy_url, HTTPConnectionPool):
            proxy_url = ""%s://%s:%i"" % (
                proxy_url.scheme,
                proxy_url.host,
                proxy_url.port,
            )
        proxy = parse_url(proxy_url)

        if proxy.scheme not in (""http"", ""https""):
            raise ProxySchemeUnknown(proxy.scheme)

        if not proxy.port:
            port = port_by_scheme.get(proxy.scheme, 80)
            proxy = proxy._replace(port=port)

        self.proxy = proxy
        self.proxy_headers = proxy_headers or {}
        self.proxy_ssl_context = proxy_ssl_context
        self.proxy_config = ProxyConfig(proxy_ssl_context, use_forwarding_for_https)

        connection_pool_kw[""_proxy""] = self.proxy
        connection_pool_kw[""_proxy_headers""] = self.proxy_headers
        connection_pool_kw[""_proxy_config""] = self.proxy_config

        super(ProxyManager, self).__init__(num_pools, headers, **connection_pool_kw)

    def connection_from_host(self, host, port=None, scheme=""http"", pool_kwargs=None):
        if scheme == ""https"":
            return super(ProxyManager, self).connection_from_host(
                host, port, scheme, pool_kwargs=pool_kwargs
            )

        return super(ProxyManager, self).connection_from_host(
            self.proxy.host, self.proxy.port, self.proxy.scheme, pool_kwargs=pool_kwargs
        )

    def _set_proxy_headers(self, url, headers=None):
        
        headers_ = {""Accept"": ""*/*""}

        netloc = parse_url(url).netloc
        if netloc:
            headers_[""Host""] = netloc

        if headers:
            headers_.update(headers)
        return headers_

    def urlopen(self, method, url, redirect=True, **kw):
        ""Same as HTTP(S)ConnectionPool.urlopen, ``url`` must be absolute.""
        u = parse_url(url)
        if not connection_requires_http_tunnel(self.proxy, self.proxy_config, u.scheme):
            
            
            
            headers = kw.get(""headers"", self.headers)
            kw[""headers""] = self._set_proxy_headers(url, headers)

        return super(ProxyManager, self).urlopen(method, url, redirect=redirect, **kw)


def proxy_from_url(url, **kw):
    return ProxyManager(proxy_url=url, **kw)

from __future__ import absolute_import

import sys

from .filepost import encode_multipart_formdata
from .packages import six
from .packages.six.moves.urllib.parse import urlencode

__all__ = [""RequestMethods""]


class RequestMethods(object):
    

    _encode_url_methods = {""DELETE"", ""GET"", ""HEAD"", ""OPTIONS""}

    def __init__(self, headers=None):
        self.headers = headers or {}

    def urlopen(
        self,
        method,
        url,
        body=None,
        headers=None,
        encode_multipart=True,
        multipart_boundary=None,
        **kw
    ):  
        raise NotImplementedError(
            ""Classes extending RequestMethods must implement ""
            ""their own ``urlopen`` method.""
        )

    def request(self, method, url, fields=None, headers=None, **urlopen_kw):
        
        method = method.upper()

        urlopen_kw[""request_url""] = url

        if method in self._encode_url_methods:
            return self.request_encode_url(
                method, url, fields=fields, headers=headers, **urlopen_kw
            )
        else:
            return self.request_encode_body(
                method, url, fields=fields, headers=headers, **urlopen_kw
            )

    def request_encode_url(self, method, url, fields=None, headers=None, **urlopen_kw):
        
        if headers is None:
            headers = self.headers

        extra_kw = {""headers"": headers}
        extra_kw.update(urlopen_kw)

        if fields:
            url += ""?"" + urlencode(fields)

        return self.urlopen(method, url, **extra_kw)

    def request_encode_body(
        self,
        method,
        url,
        fields=None,
        headers=None,
        encode_multipart=True,
        multipart_boundary=None,
        **urlopen_kw
    ):
        
        if headers is None:
            headers = self.headers

        extra_kw = {""headers"": {}}

        if fields:
            if ""body"" in urlopen_kw:
                raise TypeError(
                    ""request got values for both 'fields' and 'body', can only specify one.""
                )

            if encode_multipart:
                body, content_type = encode_multipart_formdata(
                    fields, boundary=multipart_boundary
                )
            else:
                body, content_type = (
                    urlencode(fields),
                    ""application/x-www-form-urlencoded"",
                )

            extra_kw[""body""] = body
            extra_kw[""headers""] = {""Content-Type"": content_type}

        extra_kw[""headers""].update(headers)
        extra_kw.update(urlopen_kw)

        return self.urlopen(method, url, **extra_kw)


if not six.PY2:

    class RequestModule(sys.modules[__name__].__class__):
        def __call__(self, *args, **kwargs):
            
            raise TypeError(
                ""'module' object is not callable\n""
                ""urllib3.request() method is not supported in this release, ""
                ""upgrade to urllib3 v2 to use it\n""
                ""see https://urllib3.readthedocs.io/en/stable/v2-migration-guide.html""
            )

    sys.modules[__name__].__class__ = RequestModule

from __future__ import absolute_import

import io
import logging
import sys
import warnings
import zlib
from contextlib import contextmanager
from socket import error as SocketError
from socket import timeout as SocketTimeout

brotli = None

from . import util
from ._collections import HTTPHeaderDict
from .connection import BaseSSLError, HTTPException
from .exceptions import (
    BodyNotHttplibCompatible,
    DecodeError,
    HTTPError,
    IncompleteRead,
    InvalidChunkLength,
    InvalidHeader,
    ProtocolError,
    ReadTimeoutError,
    ResponseNotChunked,
    SSLError,
)
from .packages import six
from .util.response import is_fp_closed, is_response_to_head

log = logging.getLogger(__name__)


class DeflateDecoder(object):
    def __init__(self):
        self._first_try = True
        self._data = b""""
        self._obj = zlib.decompressobj()

    def __getattr__(self, name):
        return getattr(self._obj, name)

    def decompress(self, data):
        if not data:
            return data

        if not self._first_try:
            return self._obj.decompress(data)

        self._data += data
        try:
            decompressed = self._obj.decompress(data)
            if decompressed:
                self._first_try = False
                self._data = None
            return decompressed
        except zlib.error:
            self._first_try = False
            self._obj = zlib.decompressobj(-zlib.MAX_WBITS)
            try:
                return self.decompress(self._data)
            finally:
                self._data = None


class GzipDecoderState(object):

    FIRST_MEMBER = 0
    OTHER_MEMBERS = 1
    SWALLOW_DATA = 2


class GzipDecoder(object):
    def __init__(self):
        self._obj = zlib.decompressobj(16 + zlib.MAX_WBITS)
        self._state = GzipDecoderState.FIRST_MEMBER

    def __getattr__(self, name):
        return getattr(self._obj, name)

    def decompress(self, data):
        ret = bytearray()
        if self._state == GzipDecoderState.SWALLOW_DATA or not data:
            return bytes(ret)
        while True:
            try:
                ret += self._obj.decompress(data)
            except zlib.error:
                previous_state = self._state
                
                self._state = GzipDecoderState.SWALLOW_DATA
                if previous_state == GzipDecoderState.OTHER_MEMBERS:
                    
                    return bytes(ret)
                raise
            data = self._obj.unused_data
            if not data:
                return bytes(ret)
            self._state = GzipDecoderState.OTHER_MEMBERS
            self._obj = zlib.decompressobj(16 + zlib.MAX_WBITS)


if brotli is not None:

    class BrotliDecoder(object):
        
        
        
        def __init__(self):
            self._obj = brotli.Decompressor()
            if hasattr(self._obj, ""decompress""):
                self.decompress = self._obj.decompress
            else:
                self.decompress = self._obj.process

        def flush(self):
            if hasattr(self._obj, ""flush""):
                return self._obj.flush()
            return b""""


class MultiDecoder(object):
    

    def __init__(self, modes):
        self._decoders = [_get_decoder(m.strip()) for m in modes.split("","")]

    def flush(self):
        return self._decoders[0].flush()

    def decompress(self, data):
        for d in reversed(self._decoders):
            data = d.decompress(data)
        return data


def _get_decoder(mode):
    if "","" in mode:
        return MultiDecoder(mode)

    if mode == ""gzip"":
        return GzipDecoder()

    if brotli is not None and mode == ""br"":
        return BrotliDecoder()

    return DeflateDecoder()


class HTTPResponse(io.IOBase):
    

    CONTENT_DECODERS = [""gzip"", ""deflate""]
    if brotli is not None:
        CONTENT_DECODERS += [""br""]
    REDIRECT_STATUSES = [301, 302, 303, 307, 308]

    def __init__(
        self,
        body="""",
        headers=None,
        status=0,
        version=0,
        reason=None,
        strict=0,
        preload_content=True,
        decode_content=True,
        original_response=None,
        pool=None,
        connection=None,
        msg=None,
        retries=None,
        enforce_content_length=False,
        request_method=None,
        request_url=None,
        auto_close=True,
    ):

        if isinstance(headers, HTTPHeaderDict):
            self.headers = headers
        else:
            self.headers = HTTPHeaderDict(headers)
        self.status = status
        self.version = version
        self.reason = reason
        self.strict = strict
        self.decode_content = decode_content
        self.retries = retries
        self.enforce_content_length = enforce_content_length
        self.auto_close = auto_close

        self._decoder = None
        self._body = None
        self._fp = None
        self._original_response = original_response
        self._fp_bytes_read = 0
        self.msg = msg
        self._request_url = request_url

        if body and isinstance(body, (six.string_types, bytes)):
            self._body = body

        self._pool = pool
        self._connection = connection

        if hasattr(body, ""read""):
            self._fp = body

        
        self.chunked = False
        self.chunk_left = None
        tr_enc = self.headers.get(""transfer-encoding"", """").lower()
        
        encodings = (enc.strip() for enc in tr_enc.split("",""))
        if ""chunked"" in encodings:
            self.chunked = True

        
        self.length_remaining = self._init_length(request_method)

        
        if preload_content and not self._body:
            self._body = self.read(decode_content=decode_content)

    def get_redirect_location(self):
        
        if self.status in self.REDIRECT_STATUSES:
            return self.headers.get(""location"")

        return False

    def release_conn(self):
        if not self._pool or not self._connection:
            return

        self._pool._put_conn(self._connection)
        self._connection = None

    def drain_conn(self):
        
        try:
            self.read()
        except (HTTPError, SocketError, BaseSSLError, HTTPException):
            pass

    @property
    def data(self):
        
        if self._body:
            return self._body

        if self._fp:
            return self.read(cache_content=True)

    @property
    def connection(self):
        return self._connection

    def isclosed(self):
        return is_fp_closed(self._fp)

    def tell(self):
        
        return self._fp_bytes_read

    def _init_length(self, request_method):
        
        length = self.headers.get(""content-length"")

        if length is not None:
            if self.chunked:
                
                
                
                log.warning(
                    ""Received response with both Content-Length and ""
                    ""Transfer-Encoding set. This is expressly forbidden ""
                    ""by RFC 7230 sec 3.3.2. Ignoring Content-Length and ""
                    ""attempting to process response as Transfer-Encoding: ""
                    ""chunked.""
                )
                return None

            try:
                
                
                
                
                
                lengths = set([int(val) for val in length.split("","")])
                if len(lengths) > 1:
                    raise InvalidHeader(
                        ""Content-Length contained multiple ""
                        ""unmatching values (%s)"" % length
                    )
                length = lengths.pop()
            except ValueError:
                length = None
            else:
                if length < 0:
                    length = None

        
        
        try:
            status = int(self.status)
        except ValueError:
            status = 0

        
        if status in (204, 304) or 100 <= status < 200 or request_method == ""HEAD"":
            length = 0

        return length

    def _init_decoder(self):
        
        
        
        content_encoding = self.headers.get(""content-encoding"", """").lower()
        if self._decoder is None:
            if content_encoding in self.CONTENT_DECODERS:
                self._decoder = _get_decoder(content_encoding)
            elif "","" in content_encoding:
                encodings = [
                    e.strip()
                    for e in content_encoding.split("","")
                    if e.strip() in self.CONTENT_DECODERS
                ]
                if len(encodings):
                    self._decoder = _get_decoder(content_encoding)

    DECODER_ERROR_CLASSES = (IOError, zlib.error)
    if brotli is not None:
        DECODER_ERROR_CLASSES += (brotli.error,)

    def _decode(self, data, decode_content, flush_decoder):
        
        if not decode_content:
            return data

        try:
            if self._decoder:
                data = self._decoder.decompress(data)
        except self.DECODER_ERROR_CLASSES as e:
            content_encoding = self.headers.get(""content-encoding"", """").lower()
            raise DecodeError(
                ""Received response with content-encoding: %s, but ""
                ""failed to decode it."" % content_encoding,
                e,
            )
        if flush_decoder:
            data += self._flush_decoder()

        return data

    def _flush_decoder(self):
        
        if self._decoder:
            buf = self._decoder.decompress(b"""")
            return buf + self._decoder.flush()

        return b""""

    @contextmanager
    def _error_catcher(self):
        
        clean_exit = False

        try:
            try:
                yield

            except SocketTimeout:
                
                
                raise ReadTimeoutError(self._pool, None, ""Read timed out."")

            except BaseSSLError as e:
                
                if ""read operation timed out"" not in str(e):
                    
                    raise SSLError(e)

                raise ReadTimeoutError(self._pool, None, ""Read timed out."")

            except (HTTPException, SocketError) as e:
                
                raise ProtocolError(""Connection broken: %r"" % e, e)

            
            
            clean_exit = True
        finally:
            
            
            if not clean_exit:
                
                
                
                if self._original_response:
                    self._original_response.close()

                
                
                
                if self._connection:
                    self._connection.close()

            
            
            if self._original_response and self._original_response.isclosed():
                self.release_conn()

    def _fp_read(self, amt):
        
        assert self._fp
        c_int_max = 2 ** 31 - 1
        if (
            (
                (amt and amt > c_int_max)
                or (self.length_remaining and self.length_remaining > c_int_max)
            )
            and not util.IS_SECURETRANSPORT
            and (util.IS_PYOPENSSL or sys.version_info < (3, 10))
        ):
            buffer = io.BytesIO()
            
            
            
            
            
            
            max_chunk_amt = 2 ** 28
            while amt is None or amt != 0:
                if amt is not None:
                    chunk_amt = min(amt, max_chunk_amt)
                    amt -= chunk_amt
                else:
                    chunk_amt = max_chunk_amt
                data = self._fp.read(chunk_amt)
                if not data:
                    break
                buffer.write(data)
                del data  
            return buffer.getvalue()
        else:
            
            return self._fp.read(amt) if amt is not None else self._fp.read()

    def read(self, amt=None, decode_content=None, cache_content=False):
        
        self._init_decoder()
        if decode_content is None:
            decode_content = self.decode_content

        if self._fp is None:
            return

        flush_decoder = False
        fp_closed = getattr(self._fp, ""closed"", False)

        with self._error_catcher():
            data = self._fp_read(amt) if not fp_closed else b""""
            if amt is None:
                flush_decoder = True
            else:
                cache_content = False
                if (
                    amt != 0 and not data
                ):  
                    
                    
                    
                    
                    
                    
                    
                    self._fp.close()
                    flush_decoder = True
                    if self.enforce_content_length and self.length_remaining not in (
                        0,
                        None,
                    ):
                        
                        
                        
                        
                        
                        raise IncompleteRead(self._fp_bytes_read, self.length_remaining)

        if data:
            self._fp_bytes_read += len(data)
            if self.length_remaining is not None:
                self.length_remaining -= len(data)

            data = self._decode(data, decode_content, flush_decoder)

            if cache_content:
                self._body = data

        return data

    def stream(self, amt=2 ** 16, decode_content=None):
        
        if self.chunked and self.supports_chunked_reads():
            for line in self.read_chunked(amt, decode_content=decode_content):
                yield line
        else:
            while not is_fp_closed(self._fp):
                data = self.read(amt=amt, decode_content=decode_content)

                if data:
                    yield data

    @classmethod
    def from_httplib(ResponseCls, r, **response_kw):
        
        headers = r.msg

        if not isinstance(headers, HTTPHeaderDict):
            if six.PY2:
                
                headers = HTTPHeaderDict.from_httplib(headers)
            else:
                headers = HTTPHeaderDict(headers.items())

        
        strict = getattr(r, ""strict"", 0)
        resp = ResponseCls(
            body=r,
            headers=headers,
            status=r.status,
            version=r.version,
            reason=r.reason,
            strict=strict,
            original_response=r,
            **response_kw
        )
        return resp

    
    def getheaders(self):
        warnings.warn(
            ""HTTPResponse.getheaders() is deprecated and will be removed ""
            ""in urllib3 v2.1.0. Instead access HTTPResponse.headers directly."",
            category=DeprecationWarning,
            stacklevel=2,
        )
        return self.headers

    def getheader(self, name, default=None):
        warnings.warn(
            ""HTTPResponse.getheader() is deprecated and will be removed ""
            ""in urllib3 v2.1.0. Instead use HTTPResponse.headers.get(name, default)."",
            category=DeprecationWarning,
            stacklevel=2,
        )
        return self.headers.get(name, default)

    
    def info(self):
        return self.headers

    
    def close(self):
        if not self.closed:
            self._fp.close()

        if self._connection:
            self._connection.close()

        if not self.auto_close:
            io.IOBase.close(self)

    @property
    def closed(self):
        if not self.auto_close:
            return io.IOBase.closed.__get__(self)
        elif self._fp is None:
            return True
        elif hasattr(self._fp, ""isclosed""):
            return self._fp.isclosed()
        elif hasattr(self._fp, ""closed""):
            return self._fp.closed
        else:
            return True

    def fileno(self):
        if self._fp is None:
            raise IOError(""HTTPResponse has no file to get a fileno from"")
        elif hasattr(self._fp, ""fileno""):
            return self._fp.fileno()
        else:
            raise IOError(
                ""The file-like object this HTTPResponse is wrapped ""
                ""around has no file descriptor""
            )

    def flush(self):
        if (
            self._fp is not None
            and hasattr(self._fp, ""flush"")
            and not getattr(self._fp, ""closed"", False)
        ):
            return self._fp.flush()

    def readable(self):
        
        return True

    def readinto(self, b):
        
        temp = self.read(len(b))
        if len(temp) == 0:
            return 0
        else:
            b[: len(temp)] = temp
            return len(temp)

    def supports_chunked_reads(self):
        
        return hasattr(self._fp, ""fp"")

    def _update_chunk_length(self):
        
        
        if self.chunk_left is not None:
            return
        line = self._fp.fp.readline()
        line = line.split(b"";"", 1)[0]
        try:
            self.chunk_left = int(line, 16)
        except ValueError:
            
            self.close()
            raise InvalidChunkLength(self, line)

    def _handle_chunk(self, amt):
        returned_chunk = None
        if amt is None:
            chunk = self._fp._safe_read(self.chunk_left)
            returned_chunk = chunk
            self._fp._safe_read(2)  
            self.chunk_left = None
        elif amt < self.chunk_left:
            value = self._fp._safe_read(amt)
            self.chunk_left = self.chunk_left - amt
            returned_chunk = value
        elif amt == self.chunk_left:
            value = self._fp._safe_read(amt)
            self._fp._safe_read(2)  
            self.chunk_left = None
            returned_chunk = value
        else:  
            returned_chunk = self._fp._safe_read(self.chunk_left)
            self._fp._safe_read(2)  
            self.chunk_left = None
        return returned_chunk

    def read_chunked(self, amt=None, decode_content=None):
        
        self._init_decoder()
        
        if not self.chunked:
            raise ResponseNotChunked(
                ""Response is not chunked. ""
                ""Header 'transfer-encoding: chunked' is missing.""
            )
        if not self.supports_chunked_reads():
            raise BodyNotHttplibCompatible(
                ""Body should be http.client.HTTPResponse like. ""
                ""It should have have an fp attribute which returns raw chunks.""
            )

        with self._error_catcher():
            
            if self._original_response and is_response_to_head(self._original_response):
                self._original_response.close()
                return

            
            
            if self._fp.fp is None:
                return

            while True:
                self._update_chunk_length()
                if self.chunk_left == 0:
                    break
                chunk = self._handle_chunk(amt)
                decoded = self._decode(
                    chunk, decode_content=decode_content, flush_decoder=False
                )
                if decoded:
                    yield decoded

            if decode_content:
                
                
                
                decoded = self._flush_decoder()
                if decoded:  
                    yield decoded

            
            while True:
                line = self._fp.fp.readline()
                if not line:
                    
                    break
                if line == b""\r\n"":
                    break

            
            if self._original_response:
                self._original_response.close()

    def geturl(self):
        
        if self.retries is not None and len(self.retries.history):
            return self.retries.history[-1].redirect_location
        else:
            return self._request_url

    def __iter__(self):
        buffer = []
        for chunk in self.stream(decode_content=True):
            if b""\n"" in chunk:
                chunk = chunk.split(b""\n"")
                yield b"""".join(buffer) + chunk[0] + b""\n""
                for x in chunk[1:-1]:
                    yield x + b""\n""
                if chunk[-1]:
                    buffer = [chunk[-1]]
                else:
                    buffer = []
            else:
                buffer.append(chunk)
        if buffer:
            yield b"""".join(buffer)

from __future__ import absolute_import

try:
    from collections.abc import Mapping, MutableMapping
except ImportError:
    from collections import Mapping, MutableMapping
try:
    from threading import RLock
except ImportError:  

    class RLock:
        def __enter__(self):
            pass

        def __exit__(self, exc_type, exc_value, traceback):
            pass


from collections import OrderedDict

from .exceptions import InvalidHeader
from .packages import six
from .packages.six import iterkeys, itervalues

__all__ = [""RecentlyUsedContainer"", ""HTTPHeaderDict""]


_Null = object()


class RecentlyUsedContainer(MutableMapping):
    

    ContainerCls = OrderedDict

    def __init__(self, maxsize=10, dispose_func=None):
        self._maxsize = maxsize
        self.dispose_func = dispose_func

        self._container = self.ContainerCls()
        self.lock = RLock()

    def __getitem__(self, key):
        
        with self.lock:
            item = self._container.pop(key)
            self._container[key] = item
            return item

    def __setitem__(self, key, value):
        evicted_value = _Null
        with self.lock:
            
            evicted_value = self._container.get(key, _Null)
            self._container[key] = value

            
            
            if len(self._container) > self._maxsize:
                _key, evicted_value = self._container.popitem(last=False)

        if self.dispose_func and evicted_value is not _Null:
            self.dispose_func(evicted_value)

    def __delitem__(self, key):
        with self.lock:
            value = self._container.pop(key)

        if self.dispose_func:
            self.dispose_func(value)

    def __len__(self):
        with self.lock:
            return len(self._container)

    def __iter__(self):
        raise NotImplementedError(
            ""Iteration over this class is unlikely to be threadsafe.""
        )

    def clear(self):
        with self.lock:
            
            values = list(itervalues(self._container))
            self._container.clear()

        if self.dispose_func:
            for value in values:
                self.dispose_func(value)

    def keys(self):
        with self.lock:
            return list(iterkeys(self._container))


class HTTPHeaderDict(MutableMapping):
    

    def __init__(self, headers=None, **kwargs):
        super(HTTPHeaderDict, self).__init__()
        self._container = OrderedDict()
        if headers is not None:
            if isinstance(headers, HTTPHeaderDict):
                self._copy_from(headers)
            else:
                self.extend(headers)
        if kwargs:
            self.extend(kwargs)

    def __setitem__(self, key, val):
        self._container[key.lower()] = [key, val]
        return self._container[key.lower()]

    def __getitem__(self, key):
        val = self._container[key.lower()]
        return "", "".join(val[1:])

    def __delitem__(self, key):
        del self._container[key.lower()]

    def __contains__(self, key):
        return key.lower() in self._container

    def __eq__(self, other):
        if not isinstance(other, Mapping) and not hasattr(other, ""keys""):
            return False
        if not isinstance(other, type(self)):
            other = type(self)(other)
        return dict((k.lower(), v) for k, v in self.itermerged()) == dict(
            (k.lower(), v) for k, v in other.itermerged()
        )

    def __ne__(self, other):
        return not self.__eq__(other)

    if six.PY2:  
        iterkeys = MutableMapping.iterkeys
        itervalues = MutableMapping.itervalues

    __marker = object()

    def __len__(self):
        return len(self._container)

    def __iter__(self):
        
        for vals in self._container.values():
            yield vals[0]

    def pop(self, key, default=__marker):
        
        
        
        
        try:
            value = self[key]
        except KeyError:
            if default is self.__marker:
                raise
            return default
        else:
            del self[key]
            return value

    def discard(self, key):
        try:
            del self[key]
        except KeyError:
            pass

    def add(self, key, val):
        
        key_lower = key.lower()
        new_vals = [key, val]
        
        vals = self._container.setdefault(key_lower, new_vals)
        if new_vals is not vals:
            vals.append(val)

    def extend(self, *args, **kwargs):
        
        if len(args) > 1:
            raise TypeError(
                ""extend() takes at most 1 positional ""
                ""arguments ({0} given)"".format(len(args))
            )
        other = args[0] if len(args) >= 1 else ()

        if isinstance(other, HTTPHeaderDict):
            for key, val in other.iteritems():
                self.add(key, val)
        elif isinstance(other, Mapping):
            for key in other:
                self.add(key, other[key])
        elif hasattr(other, ""keys""):
            for key in other.keys():
                self.add(key, other[key])
        else:
            for key, value in other:
                self.add(key, value)

        for key, value in kwargs.items():
            self.add(key, value)

    def getlist(self, key, default=__marker):
        
        try:
            vals = self._container[key.lower()]
        except KeyError:
            if default is self.__marker:
                return []
            return default
        else:
            return vals[1:]

    def _prepare_for_method_change(self):
        
        content_specific_headers = [
            ""Content-Encoding"",
            ""Content-Language"",
            ""Content-Location"",
            ""Content-Type"",
            ""Content-Length"",
            ""Digest"",
            ""Last-Modified"",
        ]
        for header in content_specific_headers:
            self.discard(header)
        return self

    
    getheaders = getlist
    getallmatchingheaders = getlist
    iget = getlist

    
    get_all = getlist

    def __repr__(self):
        return ""%s(%s)"" % (type(self).__name__, dict(self.itermerged()))

    def _copy_from(self, other):
        for key in other:
            val = other.getlist(key)
            if isinstance(val, list):
                
                val = list(val)
            self._container[key.lower()] = [key] + val

    def copy(self):
        clone = type(self)()
        clone._copy_from(self)
        return clone

    def iteritems(self):
        
        for key in self:
            vals = self._container[key.lower()]
            for val in vals[1:]:
                yield vals[0], val

    def itermerged(self):
        
        for key in self:
            val = self._container[key.lower()]
            yield val[0], "", "".join(val[1:])

    def items(self):
        return list(self.iteritems())

    @classmethod
    def from_httplib(cls, message):  
        
        
        
        
        obs_fold_continued_leaders = ("" "", ""\t"")
        headers = []

        for line in message.headers:
            if line.startswith(obs_fold_continued_leaders):
                if not headers:
                    
                    
                    
                    raise InvalidHeader(
                        ""Header continuation with no previous header: %s"" % line
                    )
                else:
                    key, value = headers[-1]
                    headers[-1] = (key, value + "" "" + line.strip())
                    continue

            key, value = line.split("":"", 1)
            headers.append((key, value.strip()))

        return cls(headers)


__version__ = ""1.26.20""


from __future__ import absolute_import


import logging
import warnings
from logging import NullHandler

from . import exceptions
from ._version import __version__
from .connectionpool import HTTPConnectionPool, HTTPSConnectionPool, connection_from_url
from .filepost import encode_multipart_formdata
from .poolmanager import PoolManager, ProxyManager, proxy_from_url
from .response import HTTPResponse
from .util.request import make_headers
from .util.retry import Retry
from .util.timeout import Timeout
from .util.url import get_host





try:
    import urllib3_secure_extra  
except ImportError:
    pass
else:
    warnings.warn(
        ""'urllib3[secure]' extra is deprecated and will be removed ""
        ""in a future release of urllib3 2.x. Read more in this issue: ""
        ""https://github.com/urllib3/urllib3/issues/2680"",
        category=DeprecationWarning,
        stacklevel=2,
    )

__author__ = ""Andrey Petrov (andrey.petrov@shazow.net)""
__license__ = ""MIT""
__version__ = __version__

__all__ = (
    ""HTTPConnectionPool"",
    ""HTTPSConnectionPool"",
    ""PoolManager"",
    ""ProxyManager"",
    ""HTTPResponse"",
    ""Retry"",
    ""Timeout"",
    ""add_stderr_logger"",
    ""connection_from_url"",
    ""disable_warnings"",
    ""encode_multipart_formdata"",
    ""get_host"",
    ""make_headers"",
    ""proxy_from_url"",
)

logging.getLogger(__name__).addHandler(NullHandler())


def add_stderr_logger(level=logging.DEBUG):
    
    
    
    logger = logging.getLogger(__name__)
    handler = logging.StreamHandler()
    handler.setFormatter(logging.Formatter(""%(asctime)s %(levelname)s %(message)s""))
    logger.addHandler(handler)
    logger.setLevel(level)
    logger.debug(""Added a stderr logging handler to logger: %s"", __name__)
    return handler



del NullHandler






warnings.simplefilter(""always"", exceptions.SecurityWarning, append=True)

warnings.simplefilter(""default"", exceptions.SubjectAltNameWarning, append=True)

warnings.simplefilter(""default"", exceptions.InsecurePlatformWarning, append=True)

warnings.simplefilter(""default"", exceptions.SNIMissingWarning, append=True)


def disable_warnings(category=exceptions.HTTPWarning):
    
    warnings.simplefilter(""ignore"", category)



from __future__ import absolute_import

import io
import logging
import warnings

from ..exceptions import (
    HTTPError,
    HTTPWarning,
    MaxRetryError,
    ProtocolError,
    SSLError,
    TimeoutError,
)
from ..packages.six.moves.urllib.parse import urljoin
from ..request import RequestMethods
from ..response import HTTPResponse
from ..util.retry import Retry
from ..util.timeout import Timeout
from . import _appengine_environ

try:
    from google.appengine.api import urlfetch
except ImportError:
    urlfetch = None


log = logging.getLogger(__name__)


class AppEnginePlatformWarning(HTTPWarning):
    pass


class AppEnginePlatformError(HTTPError):
    pass


class AppEngineManager(RequestMethods):
    

    def __init__(
        self,
        headers=None,
        retries=None,
        validate_certificate=True,
        urlfetch_retries=True,
    ):
        if not urlfetch:
            raise AppEnginePlatformError(
                ""URLFetch is not available in this environment.""
            )

        warnings.warn(
            ""urllib3 is using URLFetch on Google App Engine sandbox instead ""
            ""of sockets. To use sockets directly instead of URLFetch see ""
            ""https://urllib3.readthedocs.io/en/1.26.x/reference/urllib3.contrib.html."",
            AppEnginePlatformWarning,
        )

        RequestMethods.__init__(self, headers)
        self.validate_certificate = validate_certificate
        self.urlfetch_retries = urlfetch_retries

        self.retries = retries or Retry.DEFAULT

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        
        return False

    def urlopen(
        self,
        method,
        url,
        body=None,
        headers=None,
        retries=None,
        redirect=True,
        timeout=Timeout.DEFAULT_TIMEOUT,
        **response_kw
    ):

        retries = self._get_retries(retries, redirect)

        try:
            follow_redirects = redirect and retries.redirect != 0 and retries.total
            response = urlfetch.fetch(
                url,
                payload=body,
                method=method,
                headers=headers or {},
                allow_truncated=False,
                follow_redirects=self.urlfetch_retries and follow_redirects,
                deadline=self._get_absolute_timeout(timeout),
                validate_certificate=self.validate_certificate,
            )
        except urlfetch.DeadlineExceededError as e:
            raise TimeoutError(self, e)

        except urlfetch.InvalidURLError as e:
            if ""too large"" in str(e):
                raise AppEnginePlatformError(
                    ""URLFetch request too large, URLFetch only ""
                    ""supports requests up to 10mb in size."",
                    e,
                )
            raise ProtocolError(e)

        except urlfetch.DownloadError as e:
            if ""Too many redirects"" in str(e):
                raise MaxRetryError(self, url, reason=e)
            raise ProtocolError(e)

        except urlfetch.ResponseTooLargeError as e:
            raise AppEnginePlatformError(
                ""URLFetch response too large, URLFetch only supports""
                ""responses up to 32mb in size."",
                e,
            )

        except urlfetch.SSLCertificateError as e:
            raise SSLError(e)

        except urlfetch.InvalidMethodError as e:
            raise AppEnginePlatformError(
                ""URLFetch does not support method: %s"" % method, e
            )

        http_response = self._urlfetch_response_to_http_response(
            response, retries=retries, **response_kw
        )

        
        redirect_location = redirect and http_response.get_redirect_location()
        if redirect_location:
            
            if self.urlfetch_retries and retries.raise_on_redirect:
                raise MaxRetryError(self, url, ""too many redirects"")
            else:
                if http_response.status == 303:
                    method = ""GET""

                try:
                    retries = retries.increment(
                        method, url, response=http_response, _pool=self
                    )
                except MaxRetryError:
                    if retries.raise_on_redirect:
                        raise MaxRetryError(self, url, ""too many redirects"")
                    return http_response

                retries.sleep_for_retry(http_response)
                log.debug(""Redirecting %s -> %s"", url, redirect_location)
                redirect_url = urljoin(url, redirect_location)
                return self.urlopen(
                    method,
                    redirect_url,
                    body,
                    headers,
                    retries=retries,
                    redirect=redirect,
                    timeout=timeout,
                    **response_kw
                )

        
        has_retry_after = bool(http_response.headers.get(""Retry-After""))
        if retries.is_retry(method, http_response.status, has_retry_after):
            retries = retries.increment(method, url, response=http_response, _pool=self)
            log.debug(""Retry: %s"", url)
            retries.sleep(http_response)
            return self.urlopen(
                method,
                url,
                body=body,
                headers=headers,
                retries=retries,
                redirect=redirect,
                timeout=timeout,
                **response_kw
            )

        return http_response

    def _urlfetch_response_to_http_response(self, urlfetch_resp, **response_kw):

        if is_prod_appengine():
            
            
            content_encoding = urlfetch_resp.headers.get(""content-encoding"")

            if content_encoding == ""deflate"":
                del urlfetch_resp.headers[""content-encoding""]

        transfer_encoding = urlfetch_resp.headers.get(""transfer-encoding"")
        
        
        if transfer_encoding == ""chunked"":
            encodings = transfer_encoding.split("","")
            encodings.remove(""chunked"")
            urlfetch_resp.headers[""transfer-encoding""] = "","".join(encodings)

        original_response = HTTPResponse(
            
            
            body=io.BytesIO(urlfetch_resp.content),
            msg=urlfetch_resp.header_msg,
            headers=urlfetch_resp.headers,
            status=urlfetch_resp.status_code,
            **response_kw
        )

        return HTTPResponse(
            body=io.BytesIO(urlfetch_resp.content),
            headers=urlfetch_resp.headers,
            status=urlfetch_resp.status_code,
            original_response=original_response,
            **response_kw
        )

    def _get_absolute_timeout(self, timeout):
        if timeout is Timeout.DEFAULT_TIMEOUT:
            return None  
        if isinstance(timeout, Timeout):
            if timeout._read is not None or timeout._connect is not None:
                warnings.warn(
                    ""URLFetch does not support granular timeout settings, ""
                    ""reverting to total or default URLFetch timeout."",
                    AppEnginePlatformWarning,
                )
            return timeout.total
        return timeout

    def _get_retries(self, retries, redirect):
        if not isinstance(retries, Retry):
            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)

        if retries.connect or retries.read or retries.redirect:
            warnings.warn(
                ""URLFetch only supports total retries and does not ""
                ""recognize connect, read, or redirect retry parameters."",
                AppEnginePlatformWarning,
            )

        return retries




is_appengine = _appengine_environ.is_appengine
is_appengine_sandbox = _appengine_environ.is_appengine_sandbox
is_local_appengine = _appengine_environ.is_local_appengine
is_prod_appengine = _appengine_environ.is_prod_appengine
is_prod_appengine_mvms = _appengine_environ.is_prod_appengine_mvms


from __future__ import absolute_import

import warnings
from logging import getLogger

from ntlm import ntlm

from .. import HTTPSConnectionPool
from ..packages.six.moves.http_client import HTTPSConnection

warnings.warn(
    ""The 'urllib3.contrib.ntlmpool' module is deprecated and will be removed ""
    ""in urllib3 v2.0 release, urllib3 is not able to support it properly due ""
    ""to reasons listed in issue: https://github.com/urllib3/urllib3/issues/2282. ""
    ""If you are a user of this module please comment in the mentioned issue."",
    DeprecationWarning,
)

log = getLogger(__name__)


class NTLMConnectionPool(HTTPSConnectionPool):
    

    scheme = ""https""

    def __init__(self, user, pw, authurl, *args, **kwargs):
        
        super(NTLMConnectionPool, self).__init__(*args, **kwargs)
        self.authurl = authurl
        self.rawuser = user
        user_parts = user.split(""\\"", 1)
        self.domain = user_parts[0].upper()
        self.user = user_parts[1]
        self.pw = pw

    def _new_conn(self):
        
        
        self.num_connections += 1
        log.debug(
            ""Starting NTLM HTTPS connection no. %d: https://%s%s"",
            self.num_connections,
            self.host,
            self.authurl,
        )

        headers = {""Connection"": ""Keep-Alive""}
        req_header = ""Authorization""
        resp_header = ""www-authenticate""

        conn = HTTPSConnection(host=self.host, port=self.port)

        
        headers[req_header] = ""NTLM %s"" % ntlm.create_NTLM_NEGOTIATE_MESSAGE(
            self.rawuser
        )
        log.debug(""Request headers: %s"", headers)
        conn.request(""GET"", self.authurl, None, headers)
        res = conn.getresponse()
        reshdr = dict(res.headers)
        log.debug(""Response status: %s %s"", res.status, res.reason)
        log.debug(""Response headers: %s"", reshdr)
        log.debug(""Response data: %s [...]"", res.read(100))

        
        
        res.fp = None

        
        auth_header_values = reshdr[resp_header].split("", "")
        auth_header_value = None
        for s in auth_header_values:
            if s[:5] == ""NTLM "":
                auth_header_value = s[5:]
        if auth_header_value is None:
            raise Exception(
                ""Unexpected %s response header: %s"" % (resp_header, reshdr[resp_header])
            )

        
        ServerChallenge, NegotiateFlags = ntlm.parse_NTLM_CHALLENGE_MESSAGE(
            auth_header_value
        )
        auth_msg = ntlm.create_NTLM_AUTHENTICATE_MESSAGE(
            ServerChallenge, self.user, self.domain, self.pw, NegotiateFlags
        )
        headers[req_header] = ""NTLM %s"" % auth_msg
        log.debug(""Request headers: %s"", headers)
        conn.request(""GET"", self.authurl, None, headers)
        res = conn.getresponse()
        log.debug(""Response status: %s %s"", res.status, res.reason)
        log.debug(""Response headers: %s"", dict(res.headers))
        log.debug(""Response data: %s [...]"", res.read()[:100])
        if res.status != 200:
            if res.status == 401:
                raise Exception(""Server rejected request: wrong username or password"")
            raise Exception(""Wrong server response: %s %s"" % (res.status, res.reason))

        res.fp = None
        log.debug(""Connection established"")
        return conn

    def urlopen(
        self,
        method,
        url,
        body=None,
        headers=None,
        retries=3,
        redirect=True,
        assert_same_host=True,
    ):
        if headers is None:
            headers = {}
        headers[""Connection""] = ""Keep-Alive""
        return super(NTLMConnectionPool, self).urlopen(
            method, url, body, headers, retries, redirect, assert_same_host
        )


from __future__ import absolute_import

import OpenSSL.crypto
import OpenSSL.SSL
from cryptography import x509
from cryptography.hazmat.backends.openssl import backend as openssl_backend

try:
    from cryptography.x509 import UnsupportedExtension
except ImportError:
    
    class UnsupportedExtension(Exception):
        pass


from io import BytesIO
from socket import error as SocketError
from socket import timeout

try:  
    from socket import _fileobject
except ImportError:  
    _fileobject = None
    from ..packages.backports.makefile import backport_makefile

import logging
import ssl
import sys
import warnings

from .. import util
from ..packages import six
from ..util.ssl_ import PROTOCOL_TLS_CLIENT

warnings.warn(
    ""'urllib3.contrib.pyopenssl' module is deprecated and will be removed ""
    ""in a future release of urllib3 2.x. Read more in this issue: ""
    ""https://github.com/urllib3/urllib3/issues/2680"",
    category=DeprecationWarning,
    stacklevel=2,
)

__all__ = [""inject_into_urllib3"", ""extract_from_urllib3""]


HAS_SNI = True


_openssl_versions = {
    util.PROTOCOL_TLS: OpenSSL.SSL.SSLv23_METHOD,
    PROTOCOL_TLS_CLIENT: OpenSSL.SSL.SSLv23_METHOD,
    ssl.PROTOCOL_TLSv1: OpenSSL.SSL.TLSv1_METHOD,
}

if hasattr(ssl, ""PROTOCOL_SSLv3"") and hasattr(OpenSSL.SSL, ""SSLv3_METHOD""):
    _openssl_versions[ssl.PROTOCOL_SSLv3] = OpenSSL.SSL.SSLv3_METHOD

if hasattr(ssl, ""PROTOCOL_TLSv1_1"") and hasattr(OpenSSL.SSL, ""TLSv1_1_METHOD""):
    _openssl_versions[ssl.PROTOCOL_TLSv1_1] = OpenSSL.SSL.TLSv1_1_METHOD

if hasattr(ssl, ""PROTOCOL_TLSv1_2"") and hasattr(OpenSSL.SSL, ""TLSv1_2_METHOD""):
    _openssl_versions[ssl.PROTOCOL_TLSv1_2] = OpenSSL.SSL.TLSv1_2_METHOD


_stdlib_to_openssl_verify = {
    ssl.CERT_NONE: OpenSSL.SSL.VERIFY_NONE,
    ssl.CERT_OPTIONAL: OpenSSL.SSL.VERIFY_PEER,
    ssl.CERT_REQUIRED: OpenSSL.SSL.VERIFY_PEER
    + OpenSSL.SSL.VERIFY_FAIL_IF_NO_PEER_CERT,
}
_openssl_to_stdlib_verify = dict((v, k) for k, v in _stdlib_to_openssl_verify.items())


SSL_WRITE_BLOCKSIZE = 16384

orig_util_HAS_SNI = util.HAS_SNI
orig_util_SSLContext = util.ssl_.SSLContext


log = logging.getLogger(__name__)


def inject_into_urllib3():
    ""Monkey-patch urllib3 with PyOpenSSL-backed SSL-support.""

    _validate_dependencies_met()

    util.SSLContext = PyOpenSSLContext
    util.ssl_.SSLContext = PyOpenSSLContext
    util.HAS_SNI = HAS_SNI
    util.ssl_.HAS_SNI = HAS_SNI
    util.IS_PYOPENSSL = True
    util.ssl_.IS_PYOPENSSL = True


def extract_from_urllib3():
    ""Undo monkey-patching by :func:`inject_into_urllib3`.""

    util.SSLContext = orig_util_SSLContext
    util.ssl_.SSLContext = orig_util_SSLContext
    util.HAS_SNI = orig_util_HAS_SNI
    util.ssl_.HAS_SNI = orig_util_HAS_SNI
    util.IS_PYOPENSSL = False
    util.ssl_.IS_PYOPENSSL = False


def _validate_dependencies_met():
    
    
    from cryptography.x509.extensions import Extensions

    if getattr(Extensions, ""get_extension_for_class"", None) is None:
        raise ImportError(
            ""'cryptography' module missing required functionality.  ""
            ""Try upgrading to v1.3.4 or newer.""
        )

    
    
    from OpenSSL.crypto import X509

    x509 = X509()
    if getattr(x509, ""_x509"", None) is None:
        raise ImportError(
            ""'pyOpenSSL' module missing required functionality. ""
            ""Try upgrading to v0.14 or newer.""
        )


def _dnsname_to_stdlib(name):
    

    def idna_encode(name):
        
        from pip._vendor import idna

        try:
            for prefix in [u""*."", u"".""]:
                if name.startswith(prefix):
                    name = name[len(prefix) :]
                    return prefix.encode(""ascii"") + idna.encode(name)
            return idna.encode(name)
        except idna.core.IDNAError:
            return None

    
    if "":"" in name:
        return name

    name = idna_encode(name)
    if name is None:
        return None
    elif sys.version_info >= (3, 0):
        name = name.decode(""utf-8"")
    return name


def get_subj_alt_name(peer_cert):
    
    
    if hasattr(peer_cert, ""to_cryptography""):
        cert = peer_cert.to_cryptography()
    else:
        der = OpenSSL.crypto.dump_certificate(OpenSSL.crypto.FILETYPE_ASN1, peer_cert)
        cert = x509.load_der_x509_certificate(der, openssl_backend)

    
    
    try:
        ext = cert.extensions.get_extension_for_class(x509.SubjectAlternativeName).value
    except x509.ExtensionNotFound:
        
        return []
    except (
        x509.DuplicateExtension,
        UnsupportedExtension,
        x509.UnsupportedGeneralNameType,
        UnicodeError,
    ) as e:
        
        
        log.warning(
            ""A problem was encountered with the certificate that prevented ""
            ""urllib3 from finding the SubjectAlternativeName field. This can ""
            ""affect certificate validation. The error was %s"",
            e,
        )
        return []

    
    
    
    
    
    
    
    names = [
        (""DNS"", name)
        for name in map(_dnsname_to_stdlib, ext.get_values_for_type(x509.DNSName))
        if name is not None
    ]
    names.extend(
        (""IP Address"", str(name)) for name in ext.get_values_for_type(x509.IPAddress)
    )

    return names


class WrappedSocket(object):
    

    def __init__(self, connection, socket, suppress_ragged_eofs=True):
        self.connection = connection
        self.socket = socket
        self.suppress_ragged_eofs = suppress_ragged_eofs
        self._makefile_refs = 0
        self._closed = False

    def fileno(self):
        return self.socket.fileno()

    
    def _decref_socketios(self):
        if self._makefile_refs > 0:
            self._makefile_refs -= 1
        if self._closed:
            self.close()

    def recv(self, *args, **kwargs):
        try:
            data = self.connection.recv(*args, **kwargs)
        except OpenSSL.SSL.SysCallError as e:
            if self.suppress_ragged_eofs and e.args == (-1, ""Unexpected EOF""):
                return b""""
            else:
                raise SocketError(str(e))
        except OpenSSL.SSL.ZeroReturnError:
            if self.connection.get_shutdown() == OpenSSL.SSL.RECEIVED_SHUTDOWN:
                return b""""
            else:
                raise
        except OpenSSL.SSL.WantReadError:
            if not util.wait_for_read(self.socket, self.socket.gettimeout()):
                raise timeout(""The read operation timed out"")
            else:
                return self.recv(*args, **kwargs)

        
        except OpenSSL.SSL.Error as e:
            raise ssl.SSLError(""read error: %r"" % e)
        else:
            return data

    def recv_into(self, *args, **kwargs):
        try:
            return self.connection.recv_into(*args, **kwargs)
        except OpenSSL.SSL.SysCallError as e:
            if self.suppress_ragged_eofs and e.args == (-1, ""Unexpected EOF""):
                return 0
            else:
                raise SocketError(str(e))
        except OpenSSL.SSL.ZeroReturnError:
            if self.connection.get_shutdown() == OpenSSL.SSL.RECEIVED_SHUTDOWN:
                return 0
            else:
                raise
        except OpenSSL.SSL.WantReadError:
            if not util.wait_for_read(self.socket, self.socket.gettimeout()):
                raise timeout(""The read operation timed out"")
            else:
                return self.recv_into(*args, **kwargs)

        
        except OpenSSL.SSL.Error as e:
            raise ssl.SSLError(""read error: %r"" % e)

    def settimeout(self, timeout):
        return self.socket.settimeout(timeout)

    def _send_until_done(self, data):
        while True:
            try:
                return self.connection.send(data)
            except OpenSSL.SSL.WantWriteError:
                if not util.wait_for_write(self.socket, self.socket.gettimeout()):
                    raise timeout()
                continue
            except OpenSSL.SSL.SysCallError as e:
                raise SocketError(str(e))

    def sendall(self, data):
        total_sent = 0
        while total_sent < len(data):
            sent = self._send_until_done(
                data[total_sent : total_sent + SSL_WRITE_BLOCKSIZE]
            )
            total_sent += sent

    def shutdown(self):
        
        self.connection.shutdown()

    def close(self):
        if self._makefile_refs < 1:
            try:
                self._closed = True
                return self.connection.close()
            except OpenSSL.SSL.Error:
                return
        else:
            self._makefile_refs -= 1

    def getpeercert(self, binary_form=False):
        x509 = self.connection.get_peer_certificate()

        if not x509:
            return x509

        if binary_form:
            return OpenSSL.crypto.dump_certificate(OpenSSL.crypto.FILETYPE_ASN1, x509)

        return {
            ""subject"": (((""commonName"", x509.get_subject().CN),),),
            ""subjectAltName"": get_subj_alt_name(x509),
        }

    def version(self):
        return self.connection.get_protocol_version_name()

    def _reuse(self):
        self._makefile_refs += 1

    def _drop(self):
        if self._makefile_refs < 1:
            self.close()
        else:
            self._makefile_refs -= 1


if _fileobject:  

    def makefile(self, mode, bufsize=-1):
        self._makefile_refs += 1
        return _fileobject(self, mode, bufsize, close=True)

else:  
    makefile = backport_makefile

WrappedSocket.makefile = makefile


class PyOpenSSLContext(object):
    

    def __init__(self, protocol):
        self.protocol = _openssl_versions[protocol]
        self._ctx = OpenSSL.SSL.Context(self.protocol)
        self._options = 0
        self.check_hostname = False

    @property
    def options(self):
        return self._options

    @options.setter
    def options(self, value):
        self._options = value
        self._ctx.set_options(value)

    @property
    def verify_mode(self):
        return _openssl_to_stdlib_verify[self._ctx.get_verify_mode()]

    @verify_mode.setter
    def verify_mode(self, value):
        self._ctx.set_verify(_stdlib_to_openssl_verify[value], _verify_callback)

    def set_default_verify_paths(self):
        self._ctx.set_default_verify_paths()

    def set_ciphers(self, ciphers):
        if isinstance(ciphers, six.text_type):
            ciphers = ciphers.encode(""utf-8"")
        self._ctx.set_cipher_list(ciphers)

    def load_verify_locations(self, cafile=None, capath=None, cadata=None):
        if cafile is not None:
            cafile = cafile.encode(""utf-8"")
        if capath is not None:
            capath = capath.encode(""utf-8"")
        try:
            self._ctx.load_verify_locations(cafile, capath)
            if cadata is not None:
                self._ctx.load_verify_locations(BytesIO(cadata))
        except OpenSSL.SSL.Error as e:
            raise ssl.SSLError(""unable to load trusted certificates: %r"" % e)

    def load_cert_chain(self, certfile, keyfile=None, password=None):
        self._ctx.use_certificate_chain_file(certfile)
        if password is not None:
            if not isinstance(password, six.binary_type):
                password = password.encode(""utf-8"")
            self._ctx.set_passwd_cb(lambda *_: password)
        self._ctx.use_privatekey_file(keyfile or certfile)

    def set_alpn_protocols(self, protocols):
        protocols = [six.ensure_binary(p) for p in protocols]
        return self._ctx.set_alpn_protos(protocols)

    def wrap_socket(
        self,
        sock,
        server_side=False,
        do_handshake_on_connect=True,
        suppress_ragged_eofs=True,
        server_hostname=None,
    ):
        cnx = OpenSSL.SSL.Connection(self._ctx, sock)

        if isinstance(server_hostname, six.text_type):  
            server_hostname = server_hostname.encode(""utf-8"")

        if server_hostname is not None:
            cnx.set_tlsext_host_name(server_hostname)

        cnx.set_connect_state()

        while True:
            try:
                cnx.do_handshake()
            except OpenSSL.SSL.WantReadError:
                if not util.wait_for_read(sock, sock.gettimeout()):
                    raise timeout(""select timed out"")
                continue
            except OpenSSL.SSL.Error as e:
                raise ssl.SSLError(""bad handshake: %r"" % e)
            break

        return WrappedSocket(cnx, sock)


def _verify_callback(cnx, x509, err_no, err_depth, return_code):
    return err_no == 0


from __future__ import absolute_import

import contextlib
import ctypes
import errno
import os.path
import shutil
import socket
import ssl
import struct
import threading
import weakref

from .. import util
from ..packages import six
from ..util.ssl_ import PROTOCOL_TLS_CLIENT
from ._securetransport.bindings import CoreFoundation, Security, SecurityConst
from ._securetransport.low_level import (
    _assert_no_error,
    _build_tls_unknown_ca_alert,
    _cert_array_from_pem,
    _create_cfstring_array,
    _load_client_cert_chain,
    _temporary_keychain,
)

try:  
    from socket import _fileobject
except ImportError:  
    _fileobject = None
    from ..packages.backports.makefile import backport_makefile

__all__ = [""inject_into_urllib3"", ""extract_from_urllib3""]


HAS_SNI = True

orig_util_HAS_SNI = util.HAS_SNI
orig_util_SSLContext = util.ssl_.SSLContext

















_connection_refs = weakref.WeakValueDictionary()
_connection_ref_lock = threading.Lock()



SSL_WRITE_BLOCKSIZE = 16384




CIPHER_SUITES = [
    SecurityConst.TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,
    SecurityConst.TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,
    SecurityConst.TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,
    SecurityConst.TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,
    SecurityConst.TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,
    SecurityConst.TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256,
    SecurityConst.TLS_DHE_RSA_WITH_AES_256_GCM_SHA384,
    SecurityConst.TLS_DHE_RSA_WITH_AES_128_GCM_SHA256,
    SecurityConst.TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384,
    SecurityConst.TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA,
    SecurityConst.TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,
    SecurityConst.TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA,
    SecurityConst.TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384,
    SecurityConst.TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA,
    SecurityConst.TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256,
    SecurityConst.TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,
    SecurityConst.TLS_DHE_RSA_WITH_AES_256_CBC_SHA256,
    SecurityConst.TLS_DHE_RSA_WITH_AES_256_CBC_SHA,
    SecurityConst.TLS_DHE_RSA_WITH_AES_128_CBC_SHA256,
    SecurityConst.TLS_DHE_RSA_WITH_AES_128_CBC_SHA,
    SecurityConst.TLS_AES_256_GCM_SHA384,
    SecurityConst.TLS_AES_128_GCM_SHA256,
    SecurityConst.TLS_RSA_WITH_AES_256_GCM_SHA384,
    SecurityConst.TLS_RSA_WITH_AES_128_GCM_SHA256,
    SecurityConst.TLS_AES_128_CCM_8_SHA256,
    SecurityConst.TLS_AES_128_CCM_SHA256,
    SecurityConst.TLS_RSA_WITH_AES_256_CBC_SHA256,
    SecurityConst.TLS_RSA_WITH_AES_128_CBC_SHA256,
    SecurityConst.TLS_RSA_WITH_AES_256_CBC_SHA,
    SecurityConst.TLS_RSA_WITH_AES_128_CBC_SHA,
]




_protocol_to_min_max = {
    util.PROTOCOL_TLS: (SecurityConst.kTLSProtocol1, SecurityConst.kTLSProtocol12),
    PROTOCOL_TLS_CLIENT: (SecurityConst.kTLSProtocol1, SecurityConst.kTLSProtocol12),
}

if hasattr(ssl, ""PROTOCOL_SSLv2""):
    _protocol_to_min_max[ssl.PROTOCOL_SSLv2] = (
        SecurityConst.kSSLProtocol2,
        SecurityConst.kSSLProtocol2,
    )
if hasattr(ssl, ""PROTOCOL_SSLv3""):
    _protocol_to_min_max[ssl.PROTOCOL_SSLv3] = (
        SecurityConst.kSSLProtocol3,
        SecurityConst.kSSLProtocol3,
    )
if hasattr(ssl, ""PROTOCOL_TLSv1""):
    _protocol_to_min_max[ssl.PROTOCOL_TLSv1] = (
        SecurityConst.kTLSProtocol1,
        SecurityConst.kTLSProtocol1,
    )
if hasattr(ssl, ""PROTOCOL_TLSv1_1""):
    _protocol_to_min_max[ssl.PROTOCOL_TLSv1_1] = (
        SecurityConst.kTLSProtocol11,
        SecurityConst.kTLSProtocol11,
    )
if hasattr(ssl, ""PROTOCOL_TLSv1_2""):
    _protocol_to_min_max[ssl.PROTOCOL_TLSv1_2] = (
        SecurityConst.kTLSProtocol12,
        SecurityConst.kTLSProtocol12,
    )


def inject_into_urllib3():
    
    util.SSLContext = SecureTransportContext
    util.ssl_.SSLContext = SecureTransportContext
    util.HAS_SNI = HAS_SNI
    util.ssl_.HAS_SNI = HAS_SNI
    util.IS_SECURETRANSPORT = True
    util.ssl_.IS_SECURETRANSPORT = True


def extract_from_urllib3():
    
    util.SSLContext = orig_util_SSLContext
    util.ssl_.SSLContext = orig_util_SSLContext
    util.HAS_SNI = orig_util_HAS_SNI
    util.ssl_.HAS_SNI = orig_util_HAS_SNI
    util.IS_SECURETRANSPORT = False
    util.ssl_.IS_SECURETRANSPORT = False


def _read_callback(connection_id, data_buffer, data_length_pointer):
    
    wrapped_socket = None
    try:
        wrapped_socket = _connection_refs.get(connection_id)
        if wrapped_socket is None:
            return SecurityConst.errSSLInternal
        base_socket = wrapped_socket.socket

        requested_length = data_length_pointer[0]

        timeout = wrapped_socket.gettimeout()
        error = None
        read_count = 0

        try:
            while read_count < requested_length:
                if timeout is None or timeout >= 0:
                    if not util.wait_for_read(base_socket, timeout):
                        raise socket.error(errno.EAGAIN, ""timed out"")

                remaining = requested_length - read_count
                buffer = (ctypes.c_char * remaining).from_address(
                    data_buffer + read_count
                )
                chunk_size = base_socket.recv_into(buffer, remaining)
                read_count += chunk_size
                if not chunk_size:
                    if not read_count:
                        return SecurityConst.errSSLClosedGraceful
                    break
        except (socket.error) as e:
            error = e.errno

            if error is not None and error != errno.EAGAIN:
                data_length_pointer[0] = read_count
                if error == errno.ECONNRESET or error == errno.EPIPE:
                    return SecurityConst.errSSLClosedAbort
                raise

        data_length_pointer[0] = read_count

        if read_count != requested_length:
            return SecurityConst.errSSLWouldBlock

        return 0
    except Exception as e:
        if wrapped_socket is not None:
            wrapped_socket._exception = e
        return SecurityConst.errSSLInternal


def _write_callback(connection_id, data_buffer, data_length_pointer):
    
    wrapped_socket = None
    try:
        wrapped_socket = _connection_refs.get(connection_id)
        if wrapped_socket is None:
            return SecurityConst.errSSLInternal
        base_socket = wrapped_socket.socket

        bytes_to_write = data_length_pointer[0]
        data = ctypes.string_at(data_buffer, bytes_to_write)

        timeout = wrapped_socket.gettimeout()
        error = None
        sent = 0

        try:
            while sent < bytes_to_write:
                if timeout is None or timeout >= 0:
                    if not util.wait_for_write(base_socket, timeout):
                        raise socket.error(errno.EAGAIN, ""timed out"")
                chunk_sent = base_socket.send(data)
                sent += chunk_sent

                
                
                data = data[chunk_sent:]
        except (socket.error) as e:
            error = e.errno

            if error is not None and error != errno.EAGAIN:
                data_length_pointer[0] = sent
                if error == errno.ECONNRESET or error == errno.EPIPE:
                    return SecurityConst.errSSLClosedAbort
                raise

        data_length_pointer[0] = sent

        if sent != bytes_to_write:
            return SecurityConst.errSSLWouldBlock

        return 0
    except Exception as e:
        if wrapped_socket is not None:
            wrapped_socket._exception = e
        return SecurityConst.errSSLInternal





_read_callback_pointer = Security.SSLReadFunc(_read_callback)
_write_callback_pointer = Security.SSLWriteFunc(_write_callback)


class WrappedSocket(object):
    

    def __init__(self, socket):
        self.socket = socket
        self.context = None
        self._makefile_refs = 0
        self._closed = False
        self._exception = None
        self._keychain = None
        self._keychain_dir = None
        self._client_cert_chain = None

        
        
        
        
        
        self._timeout = self.socket.gettimeout()
        self.socket.settimeout(0)

    @contextlib.contextmanager
    def _raise_on_error(self):
        
        self._exception = None

        
        
        
        yield
        if self._exception is not None:
            exception, self._exception = self._exception, None
            self.close()
            raise exception

    def _set_ciphers(self):
        
        ciphers = (Security.SSLCipherSuite * len(CIPHER_SUITES))(*CIPHER_SUITES)
        result = Security.SSLSetEnabledCiphers(
            self.context, ciphers, len(CIPHER_SUITES)
        )
        _assert_no_error(result)

    def _set_alpn_protocols(self, protocols):
        
        if not protocols:
            return
        protocols_arr = _create_cfstring_array(protocols)
        try:
            result = Security.SSLSetALPNProtocols(self.context, protocols_arr)
            _assert_no_error(result)
        finally:
            CoreFoundation.CFRelease(protocols_arr)

    def _custom_validate(self, verify, trust_bundle):
        
        
        if not verify:
            return

        successes = (
            SecurityConst.kSecTrustResultUnspecified,
            SecurityConst.kSecTrustResultProceed,
        )
        try:
            trust_result = self._evaluate_trust(trust_bundle)
            if trust_result in successes:
                return
            reason = ""error code: %d"" % (trust_result,)
        except Exception as e:
            
            reason = ""exception: %r"" % (e,)

        
        rec = _build_tls_unknown_ca_alert(self.version())
        self.socket.sendall(rec)
        
        
        
        opts = struct.pack(""ii"", 1, 0)
        self.socket.setsockopt(socket.SOL_SOCKET, socket.SO_LINGER, opts)
        self.close()
        raise ssl.SSLError(""certificate verify failed, %s"" % reason)

    def _evaluate_trust(self, trust_bundle):
        
        if os.path.isfile(trust_bundle):
            with open(trust_bundle, ""rb"") as f:
                trust_bundle = f.read()

        cert_array = None
        trust = Security.SecTrustRef()

        try:
            
            cert_array = _cert_array_from_pem(trust_bundle)

            
            
            
            
            result = Security.SSLCopyPeerTrust(self.context, ctypes.byref(trust))
            _assert_no_error(result)
            if not trust:
                raise ssl.SSLError(""Failed to copy trust reference"")

            result = Security.SecTrustSetAnchorCertificates(trust, cert_array)
            _assert_no_error(result)

            result = Security.SecTrustSetAnchorCertificatesOnly(trust, True)
            _assert_no_error(result)

            trust_result = Security.SecTrustResultType()
            result = Security.SecTrustEvaluate(trust, ctypes.byref(trust_result))
            _assert_no_error(result)
        finally:
            if trust:
                CoreFoundation.CFRelease(trust)

            if cert_array is not None:
                CoreFoundation.CFRelease(cert_array)

        return trust_result.value

    def handshake(
        self,
        server_hostname,
        verify,
        trust_bundle,
        min_version,
        max_version,
        client_cert,
        client_key,
        client_key_passphrase,
        alpn_protocols,
    ):
        
        
        
        self.context = Security.SSLCreateContext(
            None, SecurityConst.kSSLClientSide, SecurityConst.kSSLStreamType
        )
        result = Security.SSLSetIOFuncs(
            self.context, _read_callback_pointer, _write_callback_pointer
        )
        _assert_no_error(result)

        
        
        
        with _connection_ref_lock:
            handle = id(self) % 2147483647
            while handle in _connection_refs:
                handle = (handle + 1) % 2147483647
            _connection_refs[handle] = self

        result = Security.SSLSetConnection(self.context, handle)
        _assert_no_error(result)

        
        if server_hostname:
            if not isinstance(server_hostname, bytes):
                server_hostname = server_hostname.encode(""utf-8"")

            result = Security.SSLSetPeerDomainName(
                self.context, server_hostname, len(server_hostname)
            )
            _assert_no_error(result)

        
        self._set_ciphers()

        
        self._set_alpn_protocols(alpn_protocols)

        
        result = Security.SSLSetProtocolVersionMin(self.context, min_version)
        _assert_no_error(result)

        result = Security.SSLSetProtocolVersionMax(self.context, max_version)
        _assert_no_error(result)

        
        
        
        
        if not verify or trust_bundle is not None:
            result = Security.SSLSetSessionOption(
                self.context, SecurityConst.kSSLSessionOptionBreakOnServerAuth, True
            )
            _assert_no_error(result)

        
        if client_cert:
            self._keychain, self._keychain_dir = _temporary_keychain()
            self._client_cert_chain = _load_client_cert_chain(
                self._keychain, client_cert, client_key
            )
            result = Security.SSLSetCertificate(self.context, self._client_cert_chain)
            _assert_no_error(result)

        while True:
            with self._raise_on_error():
                result = Security.SSLHandshake(self.context)

                if result == SecurityConst.errSSLWouldBlock:
                    raise socket.timeout(""handshake timed out"")
                elif result == SecurityConst.errSSLServerAuthCompleted:
                    self._custom_validate(verify, trust_bundle)
                    continue
                else:
                    _assert_no_error(result)
                    break

    def fileno(self):
        return self.socket.fileno()

    
    def _decref_socketios(self):
        if self._makefile_refs > 0:
            self._makefile_refs -= 1
        if self._closed:
            self.close()

    def recv(self, bufsiz):
        buffer = ctypes.create_string_buffer(bufsiz)
        bytes_read = self.recv_into(buffer, bufsiz)
        data = buffer[:bytes_read]
        return data

    def recv_into(self, buffer, nbytes=None):
        
        if self._closed:
            return 0

        if nbytes is None:
            nbytes = len(buffer)

        buffer = (ctypes.c_char * nbytes).from_buffer(buffer)
        processed_bytes = ctypes.c_size_t(0)

        with self._raise_on_error():
            result = Security.SSLRead(
                self.context, buffer, nbytes, ctypes.byref(processed_bytes)
            )

        
        
        
        if result == SecurityConst.errSSLWouldBlock:
            
            
            
            
            if processed_bytes.value == 0:
                
                raise socket.timeout(""recv timed out"")
        elif result in (
            SecurityConst.errSSLClosedGraceful,
            SecurityConst.errSSLClosedNoNotify,
        ):
            
            
            
            
            self.close()
        else:
            _assert_no_error(result)

        
        
        return processed_bytes.value

    def settimeout(self, timeout):
        self._timeout = timeout

    def gettimeout(self):
        return self._timeout

    def send(self, data):
        processed_bytes = ctypes.c_size_t(0)

        with self._raise_on_error():
            result = Security.SSLWrite(
                self.context, data, len(data), ctypes.byref(processed_bytes)
            )

        if result == SecurityConst.errSSLWouldBlock and processed_bytes.value == 0:
            
            raise socket.timeout(""send timed out"")
        else:
            _assert_no_error(result)

        
        return processed_bytes.value

    def sendall(self, data):
        total_sent = 0
        while total_sent < len(data):
            sent = self.send(data[total_sent : total_sent + SSL_WRITE_BLOCKSIZE])
            total_sent += sent

    def shutdown(self):
        with self._raise_on_error():
            Security.SSLClose(self.context)

    def close(self):
        
        if self._makefile_refs < 1:
            self._closed = True
            if self.context:
                CoreFoundation.CFRelease(self.context)
                self.context = None
            if self._client_cert_chain:
                CoreFoundation.CFRelease(self._client_cert_chain)
                self._client_cert_chain = None
            if self._keychain:
                Security.SecKeychainDelete(self._keychain)
                CoreFoundation.CFRelease(self._keychain)
                shutil.rmtree(self._keychain_dir)
                self._keychain = self._keychain_dir = None
            return self.socket.close()
        else:
            self._makefile_refs -= 1

    def getpeercert(self, binary_form=False):
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        if not binary_form:
            raise ValueError(""SecureTransport only supports dumping binary certs"")
        trust = Security.SecTrustRef()
        certdata = None
        der_bytes = None

        try:
            
            result = Security.SSLCopyPeerTrust(self.context, ctypes.byref(trust))
            _assert_no_error(result)
            if not trust:
                
                return None

            cert_count = Security.SecTrustGetCertificateCount(trust)
            if not cert_count:
                
                
                return None

            leaf = Security.SecTrustGetCertificateAtIndex(trust, 0)
            assert leaf

            
            certdata = Security.SecCertificateCopyData(leaf)
            assert certdata

            data_length = CoreFoundation.CFDataGetLength(certdata)
            data_buffer = CoreFoundation.CFDataGetBytePtr(certdata)
            der_bytes = ctypes.string_at(data_buffer, data_length)
        finally:
            if certdata:
                CoreFoundation.CFRelease(certdata)
            if trust:
                CoreFoundation.CFRelease(trust)

        return der_bytes

    def version(self):
        protocol = Security.SSLProtocol()
        result = Security.SSLGetNegotiatedProtocolVersion(
            self.context, ctypes.byref(protocol)
        )
        _assert_no_error(result)
        if protocol.value == SecurityConst.kTLSProtocol13:
            raise ssl.SSLError(""SecureTransport does not support TLS 1.3"")
        elif protocol.value == SecurityConst.kTLSProtocol12:
            return ""TLSv1.2""
        elif protocol.value == SecurityConst.kTLSProtocol11:
            return ""TLSv1.1""
        elif protocol.value == SecurityConst.kTLSProtocol1:
            return ""TLSv1""
        elif protocol.value == SecurityConst.kSSLProtocol3:
            return ""SSLv3""
        elif protocol.value == SecurityConst.kSSLProtocol2:
            return ""SSLv2""
        else:
            raise ssl.SSLError(""Unknown TLS version: %r"" % protocol)

    def _reuse(self):
        self._makefile_refs += 1

    def _drop(self):
        if self._makefile_refs < 1:
            self.close()
        else:
            self._makefile_refs -= 1


if _fileobject:  

    def makefile(self, mode, bufsize=-1):
        self._makefile_refs += 1
        return _fileobject(self, mode, bufsize, close=True)

else:  

    def makefile(self, mode=""r"", buffering=None, *args, **kwargs):
        
        
        buffering = 0
        return backport_makefile(self, mode, buffering, *args, **kwargs)


WrappedSocket.makefile = makefile


class SecureTransportContext(object):
    

    def __init__(self, protocol):
        self._min_version, self._max_version = _protocol_to_min_max[protocol]
        self._options = 0
        self._verify = False
        self._trust_bundle = None
        self._client_cert = None
        self._client_key = None
        self._client_key_passphrase = None
        self._alpn_protocols = None

    @property
    def check_hostname(self):
        
        return True

    @check_hostname.setter
    def check_hostname(self, value):
        
        pass

    @property
    def options(self):
        
        
        
        
        
        
        return self._options

    @options.setter
    def options(self, value):
        
        self._options = value

    @property
    def verify_mode(self):
        return ssl.CERT_REQUIRED if self._verify else ssl.CERT_NONE

    @verify_mode.setter
    def verify_mode(self, value):
        self._verify = True if value == ssl.CERT_REQUIRED else False

    def set_default_verify_paths(self):
        
        
        
        
        
        
        
        
        
        pass

    def load_default_certs(self):
        return self.set_default_verify_paths()

    def set_ciphers(self, ciphers):
        
        if ciphers != util.ssl_.DEFAULT_CIPHERS:
            raise ValueError(""SecureTransport doesn't support custom cipher strings"")

    def load_verify_locations(self, cafile=None, capath=None, cadata=None):
        
        if capath is not None:
            raise ValueError(""SecureTransport does not support cert directories"")

        
        if cafile is not None:
            with open(cafile):
                pass

        self._trust_bundle = cafile or cadata

    def load_cert_chain(self, certfile, keyfile=None, password=None):
        self._client_cert = certfile
        self._client_key = keyfile
        self._client_cert_passphrase = password

    def set_alpn_protocols(self, protocols):
        
        if not hasattr(Security, ""SSLSetALPNProtocols""):
            raise NotImplementedError(
                ""SecureTransport supports ALPN only in macOS 10.12+""
            )
        self._alpn_protocols = [six.ensure_binary(p) for p in protocols]

    def wrap_socket(
        self,
        sock,
        server_side=False,
        do_handshake_on_connect=True,
        suppress_ragged_eofs=True,
        server_hostname=None,
    ):
        
        
        
        assert not server_side
        assert do_handshake_on_connect
        assert suppress_ragged_eofs

        
        
        wrapped_socket = WrappedSocket(sock)

        
        wrapped_socket.handshake(
            server_hostname,
            self._verify,
            self._trust_bundle,
            self._min_version,
            self._max_version,
            self._client_cert,
            self._client_key,
            self._client_key_passphrase,
            self._alpn_protocols,
        )
        return wrapped_socket



from __future__ import absolute_import

try:
    import socks
except ImportError:
    import warnings

    from ..exceptions import DependencyWarning

    warnings.warn(
        (
            ""SOCKS support in urllib3 requires the installation of optional ""
            ""dependencies: specifically, PySocks.  For more information, see ""
            ""https://urllib3.readthedocs.io/en/1.26.x/contrib.html
        ),
        DependencyWarning,
    )
    raise

from socket import error as SocketError
from socket import timeout as SocketTimeout

from ..connection import HTTPConnection, HTTPSConnection
from ..connectionpool import HTTPConnectionPool, HTTPSConnectionPool
from ..exceptions import ConnectTimeoutError, NewConnectionError
from ..poolmanager import PoolManager
from ..util.url import parse_url

try:
    import ssl
except ImportError:
    ssl = None


class SOCKSConnection(HTTPConnection):
    

    def __init__(self, *args, **kwargs):
        self._socks_options = kwargs.pop(""_socks_options"")
        super(SOCKSConnection, self).__init__(*args, **kwargs)

    def _new_conn(self):
        
        extra_kw = {}
        if self.source_address:
            extra_kw[""source_address""] = self.source_address

        if self.socket_options:
            extra_kw[""socket_options""] = self.socket_options

        try:
            conn = socks.create_connection(
                (self.host, self.port),
                proxy_type=self._socks_options[""socks_version""],
                proxy_addr=self._socks_options[""proxy_host""],
                proxy_port=self._socks_options[""proxy_port""],
                proxy_username=self._socks_options[""username""],
                proxy_password=self._socks_options[""password""],
                proxy_rdns=self._socks_options[""rdns""],
                timeout=self.timeout,
                **extra_kw
            )

        except SocketTimeout:
            raise ConnectTimeoutError(
                self,
                ""Connection to %s timed out. (connect timeout=%s)""
                % (self.host, self.timeout),
            )

        except socks.ProxyError as e:
            
            
            if e.socket_err:
                error = e.socket_err
                if isinstance(error, SocketTimeout):
                    raise ConnectTimeoutError(
                        self,
                        ""Connection to %s timed out. (connect timeout=%s)""
                        % (self.host, self.timeout),
                    )
                else:
                    raise NewConnectionError(
                        self, ""Failed to establish a new connection: %s"" % error
                    )
            else:
                raise NewConnectionError(
                    self, ""Failed to establish a new connection: %s"" % e
                )

        except SocketError as e:  
            raise NewConnectionError(
                self, ""Failed to establish a new connection: %s"" % e
            )

        return conn






class SOCKSHTTPSConnection(SOCKSConnection, HTTPSConnection):
    pass


class SOCKSHTTPConnectionPool(HTTPConnectionPool):
    ConnectionCls = SOCKSConnection


class SOCKSHTTPSConnectionPool(HTTPSConnectionPool):
    ConnectionCls = SOCKSHTTPSConnection


class SOCKSProxyManager(PoolManager):
    

    pool_classes_by_scheme = {
        ""http"": SOCKSHTTPConnectionPool,
        ""https"": SOCKSHTTPSConnectionPool,
    }

    def __init__(
        self,
        proxy_url,
        username=None,
        password=None,
        num_pools=10,
        headers=None,
        **connection_pool_kw
    ):
        parsed = parse_url(proxy_url)

        if username is None and password is None and parsed.auth is not None:
            split = parsed.auth.split("":"")
            if len(split) == 2:
                username, password = split
        if parsed.scheme == ""socks5"":
            socks_version = socks.PROXY_TYPE_SOCKS5
            rdns = False
        elif parsed.scheme == ""socks5h"":
            socks_version = socks.PROXY_TYPE_SOCKS5
            rdns = True
        elif parsed.scheme == ""socks4"":
            socks_version = socks.PROXY_TYPE_SOCKS4
            rdns = False
        elif parsed.scheme == ""socks4a"":
            socks_version = socks.PROXY_TYPE_SOCKS4
            rdns = True
        else:
            raise ValueError(""Unable to determine SOCKS version from %s"" % proxy_url)

        self.proxy_url = proxy_url

        socks_options = {
            ""socks_version"": socks_version,
            ""proxy_host"": parsed.host,
            ""proxy_port"": parsed.port,
            ""username"": username,
            ""password"": password,
            ""rdns"": rdns,
        }
        connection_pool_kw[""_socks_options""] = socks_options

        super(SOCKSProxyManager, self).__init__(
            num_pools, headers, **connection_pool_kw
        )

        self.pool_classes_by_scheme = SOCKSProxyManager.pool_classes_by_scheme



import os


def is_appengine():
    return is_local_appengine() or is_prod_appengine()


def is_appengine_sandbox():
    
    return is_appengine() and os.environ[""APPENGINE_RUNTIME""] == ""python27""


def is_local_appengine():
    return ""APPENGINE_RUNTIME"" in os.environ and os.environ.get(
        ""SERVER_SOFTWARE"", """"
    ).startswith(""Development/"")


def is_prod_appengine():
    return ""APPENGINE_RUNTIME"" in os.environ and os.environ.get(
        ""SERVER_SOFTWARE"", """"
    ).startswith(""Google App Engine/"")


def is_prod_appengine_mvms():
    
    return False



from __future__ import absolute_import

import platform
from ctypes import (
    CDLL,
    CFUNCTYPE,
    POINTER,
    c_bool,
    c_byte,
    c_char_p,
    c_int32,
    c_long,
    c_size_t,
    c_uint32,
    c_ulong,
    c_void_p,
)
from ctypes.util import find_library

from ...packages.six import raise_from

if platform.system() != ""Darwin"":
    raise ImportError(""Only macOS is supported"")

version = platform.mac_ver()[0]
version_info = tuple(map(int, version.split(""."")))
if version_info < (10, 8):
    raise OSError(
        ""Only OS X 10.8 and newer are supported, not %s.%s""
        % (version_info[0], version_info[1])
    )


def load_cdll(name, macos10_16_path):
    
    try:
        
        
        if version_info >= (10, 16):
            path = macos10_16_path
        else:
            path = find_library(name)
        if not path:
            raise OSError  
        return CDLL(path, use_errno=True)
    except OSError:
        raise_from(ImportError(""The library %s failed to load"" % name), None)


Security = load_cdll(
    ""Security"", ""/System/Library/Frameworks/Security.framework/Security""
)
CoreFoundation = load_cdll(
    ""CoreFoundation"",
    ""/System/Library/Frameworks/CoreFoundation.framework/CoreFoundation"",
)


Boolean = c_bool
CFIndex = c_long
CFStringEncoding = c_uint32
CFData = c_void_p
CFString = c_void_p
CFArray = c_void_p
CFMutableArray = c_void_p
CFDictionary = c_void_p
CFError = c_void_p
CFType = c_void_p
CFTypeID = c_ulong

CFTypeRef = POINTER(CFType)
CFAllocatorRef = c_void_p

OSStatus = c_int32

CFDataRef = POINTER(CFData)
CFStringRef = POINTER(CFString)
CFArrayRef = POINTER(CFArray)
CFMutableArrayRef = POINTER(CFMutableArray)
CFDictionaryRef = POINTER(CFDictionary)
CFArrayCallBacks = c_void_p
CFDictionaryKeyCallBacks = c_void_p
CFDictionaryValueCallBacks = c_void_p

SecCertificateRef = POINTER(c_void_p)
SecExternalFormat = c_uint32
SecExternalItemType = c_uint32
SecIdentityRef = POINTER(c_void_p)
SecItemImportExportFlags = c_uint32
SecItemImportExportKeyParameters = c_void_p
SecKeychainRef = POINTER(c_void_p)
SSLProtocol = c_uint32
SSLCipherSuite = c_uint32
SSLContextRef = POINTER(c_void_p)
SecTrustRef = POINTER(c_void_p)
SSLConnectionRef = c_uint32
SecTrustResultType = c_uint32
SecTrustOptionFlags = c_uint32
SSLProtocolSide = c_uint32
SSLConnectionType = c_uint32
SSLSessionOption = c_uint32


try:
    Security.SecItemImport.argtypes = [
        CFDataRef,
        CFStringRef,
        POINTER(SecExternalFormat),
        POINTER(SecExternalItemType),
        SecItemImportExportFlags,
        POINTER(SecItemImportExportKeyParameters),
        SecKeychainRef,
        POINTER(CFArrayRef),
    ]
    Security.SecItemImport.restype = OSStatus

    Security.SecCertificateGetTypeID.argtypes = []
    Security.SecCertificateGetTypeID.restype = CFTypeID

    Security.SecIdentityGetTypeID.argtypes = []
    Security.SecIdentityGetTypeID.restype = CFTypeID

    Security.SecKeyGetTypeID.argtypes = []
    Security.SecKeyGetTypeID.restype = CFTypeID

    Security.SecCertificateCreateWithData.argtypes = [CFAllocatorRef, CFDataRef]
    Security.SecCertificateCreateWithData.restype = SecCertificateRef

    Security.SecCertificateCopyData.argtypes = [SecCertificateRef]
    Security.SecCertificateCopyData.restype = CFDataRef

    Security.SecCopyErrorMessageString.argtypes = [OSStatus, c_void_p]
    Security.SecCopyErrorMessageString.restype = CFStringRef

    Security.SecIdentityCreateWithCertificate.argtypes = [
        CFTypeRef,
        SecCertificateRef,
        POINTER(SecIdentityRef),
    ]
    Security.SecIdentityCreateWithCertificate.restype = OSStatus

    Security.SecKeychainCreate.argtypes = [
        c_char_p,
        c_uint32,
        c_void_p,
        Boolean,
        c_void_p,
        POINTER(SecKeychainRef),
    ]
    Security.SecKeychainCreate.restype = OSStatus

    Security.SecKeychainDelete.argtypes = [SecKeychainRef]
    Security.SecKeychainDelete.restype = OSStatus

    Security.SecPKCS12Import.argtypes = [
        CFDataRef,
        CFDictionaryRef,
        POINTER(CFArrayRef),
    ]
    Security.SecPKCS12Import.restype = OSStatus

    SSLReadFunc = CFUNCTYPE(OSStatus, SSLConnectionRef, c_void_p, POINTER(c_size_t))
    SSLWriteFunc = CFUNCTYPE(
        OSStatus, SSLConnectionRef, POINTER(c_byte), POINTER(c_size_t)
    )

    Security.SSLSetIOFuncs.argtypes = [SSLContextRef, SSLReadFunc, SSLWriteFunc]
    Security.SSLSetIOFuncs.restype = OSStatus

    Security.SSLSetPeerID.argtypes = [SSLContextRef, c_char_p, c_size_t]
    Security.SSLSetPeerID.restype = OSStatus

    Security.SSLSetCertificate.argtypes = [SSLContextRef, CFArrayRef]
    Security.SSLSetCertificate.restype = OSStatus

    Security.SSLSetCertificateAuthorities.argtypes = [SSLContextRef, CFTypeRef, Boolean]
    Security.SSLSetCertificateAuthorities.restype = OSStatus

    Security.SSLSetConnection.argtypes = [SSLContextRef, SSLConnectionRef]
    Security.SSLSetConnection.restype = OSStatus

    Security.SSLSetPeerDomainName.argtypes = [SSLContextRef, c_char_p, c_size_t]
    Security.SSLSetPeerDomainName.restype = OSStatus

    Security.SSLHandshake.argtypes = [SSLContextRef]
    Security.SSLHandshake.restype = OSStatus

    Security.SSLRead.argtypes = [SSLContextRef, c_char_p, c_size_t, POINTER(c_size_t)]
    Security.SSLRead.restype = OSStatus

    Security.SSLWrite.argtypes = [SSLContextRef, c_char_p, c_size_t, POINTER(c_size_t)]
    Security.SSLWrite.restype = OSStatus

    Security.SSLClose.argtypes = [SSLContextRef]
    Security.SSLClose.restype = OSStatus

    Security.SSLGetNumberSupportedCiphers.argtypes = [SSLContextRef, POINTER(c_size_t)]
    Security.SSLGetNumberSupportedCiphers.restype = OSStatus

    Security.SSLGetSupportedCiphers.argtypes = [
        SSLContextRef,
        POINTER(SSLCipherSuite),
        POINTER(c_size_t),
    ]
    Security.SSLGetSupportedCiphers.restype = OSStatus

    Security.SSLSetEnabledCiphers.argtypes = [
        SSLContextRef,
        POINTER(SSLCipherSuite),
        c_size_t,
    ]
    Security.SSLSetEnabledCiphers.restype = OSStatus

    Security.SSLGetNumberEnabledCiphers.argtype = [SSLContextRef, POINTER(c_size_t)]
    Security.SSLGetNumberEnabledCiphers.restype = OSStatus

    Security.SSLGetEnabledCiphers.argtypes = [
        SSLContextRef,
        POINTER(SSLCipherSuite),
        POINTER(c_size_t),
    ]
    Security.SSLGetEnabledCiphers.restype = OSStatus

    Security.SSLGetNegotiatedCipher.argtypes = [SSLContextRef, POINTER(SSLCipherSuite)]
    Security.SSLGetNegotiatedCipher.restype = OSStatus

    Security.SSLGetNegotiatedProtocolVersion.argtypes = [
        SSLContextRef,
        POINTER(SSLProtocol),
    ]
    Security.SSLGetNegotiatedProtocolVersion.restype = OSStatus

    Security.SSLCopyPeerTrust.argtypes = [SSLContextRef, POINTER(SecTrustRef)]
    Security.SSLCopyPeerTrust.restype = OSStatus

    Security.SecTrustSetAnchorCertificates.argtypes = [SecTrustRef, CFArrayRef]
    Security.SecTrustSetAnchorCertificates.restype = OSStatus

    Security.SecTrustSetAnchorCertificatesOnly.argstypes = [SecTrustRef, Boolean]
    Security.SecTrustSetAnchorCertificatesOnly.restype = OSStatus

    Security.SecTrustEvaluate.argtypes = [SecTrustRef, POINTER(SecTrustResultType)]
    Security.SecTrustEvaluate.restype = OSStatus

    Security.SecTrustGetCertificateCount.argtypes = [SecTrustRef]
    Security.SecTrustGetCertificateCount.restype = CFIndex

    Security.SecTrustGetCertificateAtIndex.argtypes = [SecTrustRef, CFIndex]
    Security.SecTrustGetCertificateAtIndex.restype = SecCertificateRef

    Security.SSLCreateContext.argtypes = [
        CFAllocatorRef,
        SSLProtocolSide,
        SSLConnectionType,
    ]
    Security.SSLCreateContext.restype = SSLContextRef

    Security.SSLSetSessionOption.argtypes = [SSLContextRef, SSLSessionOption, Boolean]
    Security.SSLSetSessionOption.restype = OSStatus

    Security.SSLSetProtocolVersionMin.argtypes = [SSLContextRef, SSLProtocol]
    Security.SSLSetProtocolVersionMin.restype = OSStatus

    Security.SSLSetProtocolVersionMax.argtypes = [SSLContextRef, SSLProtocol]
    Security.SSLSetProtocolVersionMax.restype = OSStatus

    try:
        Security.SSLSetALPNProtocols.argtypes = [SSLContextRef, CFArrayRef]
        Security.SSLSetALPNProtocols.restype = OSStatus
    except AttributeError:
        
        pass

    Security.SecCopyErrorMessageString.argtypes = [OSStatus, c_void_p]
    Security.SecCopyErrorMessageString.restype = CFStringRef

    Security.SSLReadFunc = SSLReadFunc
    Security.SSLWriteFunc = SSLWriteFunc
    Security.SSLContextRef = SSLContextRef
    Security.SSLProtocol = SSLProtocol
    Security.SSLCipherSuite = SSLCipherSuite
    Security.SecIdentityRef = SecIdentityRef
    Security.SecKeychainRef = SecKeychainRef
    Security.SecTrustRef = SecTrustRef
    Security.SecTrustResultType = SecTrustResultType
    Security.SecExternalFormat = SecExternalFormat
    Security.OSStatus = OSStatus

    Security.kSecImportExportPassphrase = CFStringRef.in_dll(
        Security, ""kSecImportExportPassphrase""
    )
    Security.kSecImportItemIdentity = CFStringRef.in_dll(
        Security, ""kSecImportItemIdentity""
    )

    
    CoreFoundation.CFRetain.argtypes = [CFTypeRef]
    CoreFoundation.CFRetain.restype = CFTypeRef

    CoreFoundation.CFRelease.argtypes = [CFTypeRef]
    CoreFoundation.CFRelease.restype = None

    CoreFoundation.CFGetTypeID.argtypes = [CFTypeRef]
    CoreFoundation.CFGetTypeID.restype = CFTypeID

    CoreFoundation.CFStringCreateWithCString.argtypes = [
        CFAllocatorRef,
        c_char_p,
        CFStringEncoding,
    ]
    CoreFoundation.CFStringCreateWithCString.restype = CFStringRef

    CoreFoundation.CFStringGetCStringPtr.argtypes = [CFStringRef, CFStringEncoding]
    CoreFoundation.CFStringGetCStringPtr.restype = c_char_p

    CoreFoundation.CFStringGetCString.argtypes = [
        CFStringRef,
        c_char_p,
        CFIndex,
        CFStringEncoding,
    ]
    CoreFoundation.CFStringGetCString.restype = c_bool

    CoreFoundation.CFDataCreate.argtypes = [CFAllocatorRef, c_char_p, CFIndex]
    CoreFoundation.CFDataCreate.restype = CFDataRef

    CoreFoundation.CFDataGetLength.argtypes = [CFDataRef]
    CoreFoundation.CFDataGetLength.restype = CFIndex

    CoreFoundation.CFDataGetBytePtr.argtypes = [CFDataRef]
    CoreFoundation.CFDataGetBytePtr.restype = c_void_p

    CoreFoundation.CFDictionaryCreate.argtypes = [
        CFAllocatorRef,
        POINTER(CFTypeRef),
        POINTER(CFTypeRef),
        CFIndex,
        CFDictionaryKeyCallBacks,
        CFDictionaryValueCallBacks,
    ]
    CoreFoundation.CFDictionaryCreate.restype = CFDictionaryRef

    CoreFoundation.CFDictionaryGetValue.argtypes = [CFDictionaryRef, CFTypeRef]
    CoreFoundation.CFDictionaryGetValue.restype = CFTypeRef

    CoreFoundation.CFArrayCreate.argtypes = [
        CFAllocatorRef,
        POINTER(CFTypeRef),
        CFIndex,
        CFArrayCallBacks,
    ]
    CoreFoundation.CFArrayCreate.restype = CFArrayRef

    CoreFoundation.CFArrayCreateMutable.argtypes = [
        CFAllocatorRef,
        CFIndex,
        CFArrayCallBacks,
    ]
    CoreFoundation.CFArrayCreateMutable.restype = CFMutableArrayRef

    CoreFoundation.CFArrayAppendValue.argtypes = [CFMutableArrayRef, c_void_p]
    CoreFoundation.CFArrayAppendValue.restype = None

    CoreFoundation.CFArrayGetCount.argtypes = [CFArrayRef]
    CoreFoundation.CFArrayGetCount.restype = CFIndex

    CoreFoundation.CFArrayGetValueAtIndex.argtypes = [CFArrayRef, CFIndex]
    CoreFoundation.CFArrayGetValueAtIndex.restype = c_void_p

    CoreFoundation.kCFAllocatorDefault = CFAllocatorRef.in_dll(
        CoreFoundation, ""kCFAllocatorDefault""
    )
    CoreFoundation.kCFTypeArrayCallBacks = c_void_p.in_dll(
        CoreFoundation, ""kCFTypeArrayCallBacks""
    )
    CoreFoundation.kCFTypeDictionaryKeyCallBacks = c_void_p.in_dll(
        CoreFoundation, ""kCFTypeDictionaryKeyCallBacks""
    )
    CoreFoundation.kCFTypeDictionaryValueCallBacks = c_void_p.in_dll(
        CoreFoundation, ""kCFTypeDictionaryValueCallBacks""
    )

    CoreFoundation.CFTypeRef = CFTypeRef
    CoreFoundation.CFArrayRef = CFArrayRef
    CoreFoundation.CFStringRef = CFStringRef
    CoreFoundation.CFDictionaryRef = CFDictionaryRef

except (AttributeError):
    raise ImportError(""Error initializing ctypes"")


class CFConst(object):
    

    kCFStringEncodingUTF8 = CFStringEncoding(0x08000100)


class SecurityConst(object):
    

    kSSLSessionOptionBreakOnServerAuth = 0

    kSSLProtocol2 = 1
    kSSLProtocol3 = 2
    kTLSProtocol1 = 4
    kTLSProtocol11 = 7
    kTLSProtocol12 = 8
    
    kTLSProtocol13 = 10
    kTLSProtocolMaxSupported = 999

    kSSLClientSide = 1
    kSSLStreamType = 0

    kSecFormatPEMSequence = 10

    kSecTrustResultInvalid = 0
    kSecTrustResultProceed = 1
    
    
    kSecTrustResultDeny = 3
    kSecTrustResultUnspecified = 4
    kSecTrustResultRecoverableTrustFailure = 5
    kSecTrustResultFatalTrustFailure = 6
    kSecTrustResultOtherError = 7

    errSSLProtocol = -9800
    errSSLWouldBlock = -9803
    errSSLClosedGraceful = -9805
    errSSLClosedNoNotify = -9816
    errSSLClosedAbort = -9806

    errSSLXCertChainInvalid = -9807
    errSSLCrypto = -9809
    errSSLInternal = -9810
    errSSLCertExpired = -9814
    errSSLCertNotYetValid = -9815
    errSSLUnknownRootCert = -9812
    errSSLNoRootCert = -9813
    errSSLHostNameMismatch = -9843
    errSSLPeerHandshakeFail = -9824
    errSSLPeerUserCancelled = -9839
    errSSLWeakPeerEphemeralDHKey = -9850
    errSSLServerAuthCompleted = -9841
    errSSLRecordOverflow = -9847

    errSecVerifyFailed = -67808
    errSecNoTrustSettings = -25263
    errSecItemNotFound = -25300
    errSecInvalidTrustSettings = -25262

    
    
    TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384 = 0xC02C
    TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 = 0xC030
    TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256 = 0xC02B
    TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 = 0xC02F
    TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256 = 0xCCA9
    TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256 = 0xCCA8
    TLS_DHE_RSA_WITH_AES_256_GCM_SHA384 = 0x009F
    TLS_DHE_RSA_WITH_AES_128_GCM_SHA256 = 0x009E
    TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384 = 0xC024
    TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384 = 0xC028
    TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA = 0xC00A
    TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA = 0xC014
    TLS_DHE_RSA_WITH_AES_256_CBC_SHA256 = 0x006B
    TLS_DHE_RSA_WITH_AES_256_CBC_SHA = 0x0039
    TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256 = 0xC023
    TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 = 0xC027
    TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA = 0xC009
    TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA = 0xC013
    TLS_DHE_RSA_WITH_AES_128_CBC_SHA256 = 0x0067
    TLS_DHE_RSA_WITH_AES_128_CBC_SHA = 0x0033
    TLS_RSA_WITH_AES_256_GCM_SHA384 = 0x009D
    TLS_RSA_WITH_AES_128_GCM_SHA256 = 0x009C
    TLS_RSA_WITH_AES_256_CBC_SHA256 = 0x003D
    TLS_RSA_WITH_AES_128_CBC_SHA256 = 0x003C
    TLS_RSA_WITH_AES_256_CBC_SHA = 0x0035
    TLS_RSA_WITH_AES_128_CBC_SHA = 0x002F
    TLS_AES_128_GCM_SHA256 = 0x1301
    TLS_AES_256_GCM_SHA384 = 0x1302
    TLS_AES_128_CCM_8_SHA256 = 0x1305
    TLS_AES_128_CCM_SHA256 = 0x1304


import base64
import ctypes
import itertools
import os
import re
import ssl
import struct
import tempfile

from .bindings import CFConst, CoreFoundation, Security


_PEM_CERTS_RE = re.compile(
    b""-----BEGIN CERTIFICATE-----\n(.*?)\n-----END CERTIFICATE-----"", re.DOTALL
)


def _cf_data_from_bytes(bytestring):
    
    return CoreFoundation.CFDataCreate(
        CoreFoundation.kCFAllocatorDefault, bytestring, len(bytestring)
    )


def _cf_dictionary_from_tuples(tuples):
    
    dictionary_size = len(tuples)

    
    keys = (t[0] for t in tuples)
    values = (t[1] for t in tuples)
    cf_keys = (CoreFoundation.CFTypeRef * dictionary_size)(*keys)
    cf_values = (CoreFoundation.CFTypeRef * dictionary_size)(*values)

    return CoreFoundation.CFDictionaryCreate(
        CoreFoundation.kCFAllocatorDefault,
        cf_keys,
        cf_values,
        dictionary_size,
        CoreFoundation.kCFTypeDictionaryKeyCallBacks,
        CoreFoundation.kCFTypeDictionaryValueCallBacks,
    )


def _cfstr(py_bstr):
    
    c_str = ctypes.c_char_p(py_bstr)
    cf_str = CoreFoundation.CFStringCreateWithCString(
        CoreFoundation.kCFAllocatorDefault,
        c_str,
        CFConst.kCFStringEncodingUTF8,
    )
    return cf_str


def _create_cfstring_array(lst):
    
    cf_arr = None
    try:
        cf_arr = CoreFoundation.CFArrayCreateMutable(
            CoreFoundation.kCFAllocatorDefault,
            0,
            ctypes.byref(CoreFoundation.kCFTypeArrayCallBacks),
        )
        if not cf_arr:
            raise MemoryError(""Unable to allocate memory!"")
        for item in lst:
            cf_str = _cfstr(item)
            if not cf_str:
                raise MemoryError(""Unable to allocate memory!"")
            try:
                CoreFoundation.CFArrayAppendValue(cf_arr, cf_str)
            finally:
                CoreFoundation.CFRelease(cf_str)
    except BaseException as e:
        if cf_arr:
            CoreFoundation.CFRelease(cf_arr)
        raise ssl.SSLError(""Unable to allocate array: %s"" % (e,))
    return cf_arr


def _cf_string_to_unicode(value):
    
    value_as_void_p = ctypes.cast(value, ctypes.POINTER(ctypes.c_void_p))

    string = CoreFoundation.CFStringGetCStringPtr(
        value_as_void_p, CFConst.kCFStringEncodingUTF8
    )
    if string is None:
        buffer = ctypes.create_string_buffer(1024)
        result = CoreFoundation.CFStringGetCString(
            value_as_void_p, buffer, 1024, CFConst.kCFStringEncodingUTF8
        )
        if not result:
            raise OSError(""Error copying C string from CFStringRef"")
        string = buffer.value
    if string is not None:
        string = string.decode(""utf-8"")
    return string


def _assert_no_error(error, exception_class=None):
    
    if error == 0:
        return

    cf_error_string = Security.SecCopyErrorMessageString(error, None)
    output = _cf_string_to_unicode(cf_error_string)
    CoreFoundation.CFRelease(cf_error_string)

    if output is None or output == u"""":
        output = u""OSStatus %s"" % error

    if exception_class is None:
        exception_class = ssl.SSLError

    raise exception_class(output)


def _cert_array_from_pem(pem_bundle):
    
    
    pem_bundle = pem_bundle.replace(b""\r\n"", b""\n"")

    der_certs = [
        base64.b64decode(match.group(1)) for match in _PEM_CERTS_RE.finditer(pem_bundle)
    ]
    if not der_certs:
        raise ssl.SSLError(""No root certificates specified"")

    cert_array = CoreFoundation.CFArrayCreateMutable(
        CoreFoundation.kCFAllocatorDefault,
        0,
        ctypes.byref(CoreFoundation.kCFTypeArrayCallBacks),
    )
    if not cert_array:
        raise ssl.SSLError(""Unable to allocate memory!"")

    try:
        for der_bytes in der_certs:
            certdata = _cf_data_from_bytes(der_bytes)
            if not certdata:
                raise ssl.SSLError(""Unable to allocate memory!"")
            cert = Security.SecCertificateCreateWithData(
                CoreFoundation.kCFAllocatorDefault, certdata
            )
            CoreFoundation.CFRelease(certdata)
            if not cert:
                raise ssl.SSLError(""Unable to build cert object!"")

            CoreFoundation.CFArrayAppendValue(cert_array, cert)
            CoreFoundation.CFRelease(cert)
    except Exception:
        
        
        
        CoreFoundation.CFRelease(cert_array)
        raise

    return cert_array


def _is_cert(item):
    
    expected = Security.SecCertificateGetTypeID()
    return CoreFoundation.CFGetTypeID(item) == expected


def _is_identity(item):
    
    expected = Security.SecIdentityGetTypeID()
    return CoreFoundation.CFGetTypeID(item) == expected


def _temporary_keychain():
    
    
    
    
    
    
    
    random_bytes = os.urandom(40)
    filename = base64.b16encode(random_bytes[:8]).decode(""utf-8"")
    password = base64.b16encode(random_bytes[8:])  
    tempdirectory = tempfile.mkdtemp()

    keychain_path = os.path.join(tempdirectory, filename).encode(""utf-8"")

    
    keychain = Security.SecKeychainRef()
    status = Security.SecKeychainCreate(
        keychain_path, len(password), password, False, None, ctypes.byref(keychain)
    )
    _assert_no_error(status)

    
    return keychain, tempdirectory


def _load_items_from_file(keychain, path):
    
    certificates = []
    identities = []
    result_array = None

    with open(path, ""rb"") as f:
        raw_filedata = f.read()

    try:
        filedata = CoreFoundation.CFDataCreate(
            CoreFoundation.kCFAllocatorDefault, raw_filedata, len(raw_filedata)
        )
        result_array = CoreFoundation.CFArrayRef()
        result = Security.SecItemImport(
            filedata,  
            None,  
            None,  
            None,  
            0,  
            None,  
            keychain,  
            ctypes.byref(result_array),  
        )
        _assert_no_error(result)

        
        
        
        
        result_count = CoreFoundation.CFArrayGetCount(result_array)
        for index in range(result_count):
            item = CoreFoundation.CFArrayGetValueAtIndex(result_array, index)
            item = ctypes.cast(item, CoreFoundation.CFTypeRef)

            if _is_cert(item):
                CoreFoundation.CFRetain(item)
                certificates.append(item)
            elif _is_identity(item):
                CoreFoundation.CFRetain(item)
                identities.append(item)
    finally:
        if result_array:
            CoreFoundation.CFRelease(result_array)

        CoreFoundation.CFRelease(filedata)

    return (identities, certificates)


def _load_client_cert_chain(keychain, *paths):
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    certificates = []
    identities = []

    
    paths = (path for path in paths if path)

    try:
        for file_path in paths:
            new_identities, new_certs = _load_items_from_file(keychain, file_path)
            identities.extend(new_identities)
            certificates.extend(new_certs)

        
        
        if not identities:
            new_identity = Security.SecIdentityRef()
            status = Security.SecIdentityCreateWithCertificate(
                keychain, certificates[0], ctypes.byref(new_identity)
            )
            _assert_no_error(status)
            identities.append(new_identity)

            
            
            CoreFoundation.CFRelease(certificates.pop(0))

        
        trust_chain = CoreFoundation.CFArrayCreateMutable(
            CoreFoundation.kCFAllocatorDefault,
            0,
            ctypes.byref(CoreFoundation.kCFTypeArrayCallBacks),
        )
        for item in itertools.chain(identities, certificates):
            
            
            CoreFoundation.CFArrayAppendValue(trust_chain, item)

        return trust_chain
    finally:
        for obj in itertools.chain(identities, certificates):
            CoreFoundation.CFRelease(obj)


TLS_PROTOCOL_VERSIONS = {
    ""SSLv2"": (0, 2),
    ""SSLv3"": (3, 0),
    ""TLSv1"": (3, 1),
    ""TLSv1.1"": (3, 2),
    ""TLSv1.2"": (3, 3),
}


def _build_tls_unknown_ca_alert(version):
    
    ver_maj, ver_min = TLS_PROTOCOL_VERSIONS[version]
    severity_fatal = 0x02
    description_unknown_ca = 0x30
    msg = struct.pack("">BB"", severity_fatal, description_unknown_ca)
    msg_len = len(msg)
    record_type_alert = 0x15
    record = struct.pack("">BBBH"", record_type_alert, ver_maj, ver_min, msg_len) + msg
    return record
























from __future__ import absolute_import

import functools
import itertools
import operator
import sys
import types

__author__ = ""Benjamin Peterson <benjamin@python.org>""
__version__ = ""1.16.0""



PY2 = sys.version_info[0] == 2
PY3 = sys.version_info[0] == 3
PY34 = sys.version_info[0:2] >= (3, 4)

if PY3:
    string_types = (str,)
    integer_types = (int,)
    class_types = (type,)
    text_type = str
    binary_type = bytes

    MAXSIZE = sys.maxsize
else:
    string_types = (basestring,)
    integer_types = (int, long)
    class_types = (type, types.ClassType)
    text_type = unicode
    binary_type = str

    if sys.platform.startswith(""java""):
        
        MAXSIZE = int((1 << 31) - 1)
    else:
        
        class X(object):
            def __len__(self):
                return 1 << 31

        try:
            len(X())
        except OverflowError:
            
            MAXSIZE = int((1 << 31) - 1)
        else:
            
            MAXSIZE = int((1 << 63) - 1)
        del X

if PY34:
    from importlib.util import spec_from_loader
else:
    spec_from_loader = None


def _add_doc(func, doc):
    
    func.__doc__ = doc


def _import_module(name):
    
    __import__(name)
    return sys.modules[name]


class _LazyDescr(object):
    def __init__(self, name):
        self.name = name

    def __get__(self, obj, tp):
        result = self._resolve()
        setattr(obj, self.name, result)  
        try:
            
            
            delattr(obj.__class__, self.name)
        except AttributeError:
            pass
        return result


class MovedModule(_LazyDescr):
    def __init__(self, name, old, new=None):
        super(MovedModule, self).__init__(name)
        if PY3:
            if new is None:
                new = name
            self.mod = new
        else:
            self.mod = old

    def _resolve(self):
        return _import_module(self.mod)

    def __getattr__(self, attr):
        _module = self._resolve()
        value = getattr(_module, attr)
        setattr(self, attr, value)
        return value


class _LazyModule(types.ModuleType):
    def __init__(self, name):
        super(_LazyModule, self).__init__(name)
        self.__doc__ = self.__class__.__doc__

    def __dir__(self):
        attrs = [""__doc__"", ""__name__""]
        attrs += [attr.name for attr in self._moved_attributes]
        return attrs

    
    _moved_attributes = []


class MovedAttribute(_LazyDescr):
    def __init__(self, name, old_mod, new_mod, old_attr=None, new_attr=None):
        super(MovedAttribute, self).__init__(name)
        if PY3:
            if new_mod is None:
                new_mod = name
            self.mod = new_mod
            if new_attr is None:
                if old_attr is None:
                    new_attr = name
                else:
                    new_attr = old_attr
            self.attr = new_attr
        else:
            self.mod = old_mod
            if old_attr is None:
                old_attr = name
            self.attr = old_attr

    def _resolve(self):
        module = _import_module(self.mod)
        return getattr(module, self.attr)


class _SixMetaPathImporter(object):

    

    def __init__(self, six_module_name):
        self.name = six_module_name
        self.known_modules = {}

    def _add_module(self, mod, *fullnames):
        for fullname in fullnames:
            self.known_modules[self.name + ""."" + fullname] = mod

    def _get_module(self, fullname):
        return self.known_modules[self.name + ""."" + fullname]

    def find_module(self, fullname, path=None):
        if fullname in self.known_modules:
            return self
        return None

    def find_spec(self, fullname, path, target=None):
        if fullname in self.known_modules:
            return spec_from_loader(fullname, self)
        return None

    def __get_module(self, fullname):
        try:
            return self.known_modules[fullname]
        except KeyError:
            raise ImportError(""This loader does not know module "" + fullname)

    def load_module(self, fullname):
        try:
            
            return sys.modules[fullname]
        except KeyError:
            pass
        mod = self.__get_module(fullname)
        if isinstance(mod, MovedModule):
            mod = mod._resolve()
        else:
            mod.__loader__ = self
        sys.modules[fullname] = mod
        return mod

    def is_package(self, fullname):
        
        return hasattr(self.__get_module(fullname), ""__path__"")

    def get_code(self, fullname):
        
        self.__get_module(fullname)  
        return None

    get_source = get_code  

    def create_module(self, spec):
        return self.load_module(spec.name)

    def exec_module(self, module):
        pass


_importer = _SixMetaPathImporter(__name__)


class _MovedItems(_LazyModule):

    

    __path__ = []  


_moved_attributes = [
    MovedAttribute(""cStringIO"", ""cStringIO"", ""io"", ""StringIO""),
    MovedAttribute(""filter"", ""itertools"", ""builtins"", ""ifilter"", ""filter""),
    MovedAttribute(
        ""filterfalse"", ""itertools"", ""itertools"", ""ifilterfalse"", ""filterfalse""
    ),
    MovedAttribute(""input"", ""__builtin__"", ""builtins"", ""raw_input"", ""input""),
    MovedAttribute(""intern"", ""__builtin__"", ""sys""),
    MovedAttribute(""map"", ""itertools"", ""builtins"", ""imap"", ""map""),
    MovedAttribute(""getcwd"", ""os"", ""os"", ""getcwdu"", ""getcwd""),
    MovedAttribute(""getcwdb"", ""os"", ""os"", ""getcwd"", ""getcwdb""),
    MovedAttribute(""getoutput"", ""commands"", ""subprocess""),
    MovedAttribute(""range"", ""__builtin__"", ""builtins"", ""xrange"", ""range""),
    MovedAttribute(
        ""reload_module"", ""__builtin__"", ""importlib"" if PY34 else ""imp"", ""reload""
    ),
    MovedAttribute(""reduce"", ""__builtin__"", ""functools""),
    MovedAttribute(""shlex_quote"", ""pipes"", ""shlex"", ""quote""),
    MovedAttribute(""StringIO"", ""StringIO"", ""io""),
    MovedAttribute(""UserDict"", ""UserDict"", ""collections""),
    MovedAttribute(""UserList"", ""UserList"", ""collections""),
    MovedAttribute(""UserString"", ""UserString"", ""collections""),
    MovedAttribute(""xrange"", ""__builtin__"", ""builtins"", ""xrange"", ""range""),
    MovedAttribute(""zip"", ""itertools"", ""builtins"", ""izip"", ""zip""),
    MovedAttribute(
        ""zip_longest"", ""itertools"", ""itertools"", ""izip_longest"", ""zip_longest""
    ),
    MovedModule(""builtins"", ""__builtin__""),
    MovedModule(""configparser"", ""ConfigParser""),
    MovedModule(
        ""collections_abc"",
        ""collections"",
        ""collections.abc"" if sys.version_info >= (3, 3) else ""collections"",
    ),
    MovedModule(""copyreg"", ""copy_reg""),
    MovedModule(""dbm_gnu"", ""gdbm"", ""dbm.gnu""),
    MovedModule(""dbm_ndbm"", ""dbm"", ""dbm.ndbm""),
    MovedModule(
        ""_dummy_thread"",
        ""dummy_thread"",
        ""_dummy_thread"" if sys.version_info < (3, 9) else ""_thread"",
    ),
    MovedModule(""http_cookiejar"", ""cookielib"", ""http.cookiejar""),
    MovedModule(""http_cookies"", ""Cookie"", ""http.cookies""),
    MovedModule(""html_entities"", ""htmlentitydefs"", ""html.entities""),
    MovedModule(""html_parser"", ""HTMLParser"", ""html.parser""),
    MovedModule(""http_client"", ""httplib"", ""http.client""),
    MovedModule(""email_mime_base"", ""email.MIMEBase"", ""email.mime.base""),
    MovedModule(""email_mime_image"", ""email.MIMEImage"", ""email.mime.image""),
    MovedModule(""email_mime_multipart"", ""email.MIMEMultipart"", ""email.mime.multipart""),
    MovedModule(
        ""email_mime_nonmultipart"", ""email.MIMENonMultipart"", ""email.mime.nonmultipart""
    ),
    MovedModule(""email_mime_text"", ""email.MIMEText"", ""email.mime.text""),
    MovedModule(""BaseHTTPServer"", ""BaseHTTPServer"", ""http.server""),
    MovedModule(""CGIHTTPServer"", ""CGIHTTPServer"", ""http.server""),
    MovedModule(""SimpleHTTPServer"", ""SimpleHTTPServer"", ""http.server""),
    MovedModule(""cPickle"", ""cPickle"", ""pickle""),
    MovedModule(""queue"", ""Queue""),
    MovedModule(""reprlib"", ""repr""),
    MovedModule(""socketserver"", ""SocketServer""),
    MovedModule(""_thread"", ""thread"", ""_thread""),
    MovedModule(""tkinter"", ""Tkinter""),
    MovedModule(""tkinter_dialog"", ""Dialog"", ""tkinter.dialog""),
    MovedModule(""tkinter_filedialog"", ""FileDialog"", ""tkinter.filedialog""),
    MovedModule(""tkinter_scrolledtext"", ""ScrolledText"", ""tkinter.scrolledtext""),
    MovedModule(""tkinter_simpledialog"", ""SimpleDialog"", ""tkinter.simpledialog""),
    MovedModule(""tkinter_tix"", ""Tix"", ""tkinter.tix""),
    MovedModule(""tkinter_ttk"", ""ttk"", ""tkinter.ttk""),
    MovedModule(""tkinter_constants"", ""Tkconstants"", ""tkinter.constants""),
    MovedModule(""tkinter_dnd"", ""Tkdnd"", ""tkinter.dnd""),
    MovedModule(""tkinter_colorchooser"", ""tkColorChooser"", ""tkinter.colorchooser""),
    MovedModule(""tkinter_commondialog"", ""tkCommonDialog"", ""tkinter.commondialog""),
    MovedModule(""tkinter_tkfiledialog"", ""tkFileDialog"", ""tkinter.filedialog""),
    MovedModule(""tkinter_font"", ""tkFont"", ""tkinter.font""),
    MovedModule(""tkinter_messagebox"", ""tkMessageBox"", ""tkinter.messagebox""),
    MovedModule(""tkinter_tksimpledialog"", ""tkSimpleDialog"", ""tkinter.simpledialog""),
    MovedModule(""urllib_parse"", __name__ + "".moves.urllib_parse"", ""urllib.parse""),
    MovedModule(""urllib_error"", __name__ + "".moves.urllib_error"", ""urllib.error""),
    MovedModule(""urllib"", __name__ + "".moves.urllib"", __name__ + "".moves.urllib""),
    MovedModule(""urllib_robotparser"", ""robotparser"", ""urllib.robotparser""),
    MovedModule(""xmlrpc_client"", ""xmlrpclib"", ""xmlrpc.client""),
    MovedModule(""xmlrpc_server"", ""SimpleXMLRPCServer"", ""xmlrpc.server""),
]

if sys.platform == ""win32"":
    _moved_attributes += [
        MovedModule(""winreg"", ""_winreg""),
    ]

for attr in _moved_attributes:
    setattr(_MovedItems, attr.name, attr)
    if isinstance(attr, MovedModule):
        _importer._add_module(attr, ""moves."" + attr.name)
del attr

_MovedItems._moved_attributes = _moved_attributes

moves = _MovedItems(__name__ + "".moves"")
_importer._add_module(moves, ""moves"")


class Module_six_moves_urllib_parse(_LazyModule):

    


_urllib_parse_moved_attributes = [
    MovedAttribute(""ParseResult"", ""urlparse"", ""urllib.parse""),
    MovedAttribute(""SplitResult"", ""urlparse"", ""urllib.parse""),
    MovedAttribute(""parse_qs"", ""urlparse"", ""urllib.parse""),
    MovedAttribute(""parse_qsl"", ""urlparse"", ""urllib.parse""),
    MovedAttribute(""urldefrag"", ""urlparse"", ""urllib.parse""),
    MovedAttribute(""urljoin"", ""urlparse"", ""urllib.parse""),
    MovedAttribute(""urlparse"", ""urlparse"", ""urllib.parse""),
    MovedAttribute(""urlsplit"", ""urlparse"", ""urllib.parse""),
    MovedAttribute(""urlunparse"", ""urlparse"", ""urllib.parse""),
    MovedAttribute(""urlunsplit"", ""urlparse"", ""urllib.parse""),
    MovedAttribute(""quote"", ""urllib"", ""urllib.parse""),
    MovedAttribute(""quote_plus"", ""urllib"", ""urllib.parse""),
    MovedAttribute(""unquote"", ""urllib"", ""urllib.parse""),
    MovedAttribute(""unquote_plus"", ""urllib"", ""urllib.parse""),
    MovedAttribute(
        ""unquote_to_bytes"", ""urllib"", ""urllib.parse"", ""unquote"", ""unquote_to_bytes""
    ),
    MovedAttribute(""urlencode"", ""urllib"", ""urllib.parse""),
    MovedAttribute(""splitquery"", ""urllib"", ""urllib.parse""),
    MovedAttribute(""splittag"", ""urllib"", ""urllib.parse""),
    MovedAttribute(""splituser"", ""urllib"", ""urllib.parse""),
    MovedAttribute(""splitvalue"", ""urllib"", ""urllib.parse""),
    MovedAttribute(""uses_fragment"", ""urlparse"", ""urllib.parse""),
    MovedAttribute(""uses_netloc"", ""urlparse"", ""urllib.parse""),
    MovedAttribute(""uses_params"", ""urlparse"", ""urllib.parse""),
    MovedAttribute(""uses_query"", ""urlparse"", ""urllib.parse""),
    MovedAttribute(""uses_relative"", ""urlparse"", ""urllib.parse""),
]
for attr in _urllib_parse_moved_attributes:
    setattr(Module_six_moves_urllib_parse, attr.name, attr)
del attr

Module_six_moves_urllib_parse._moved_attributes = _urllib_parse_moved_attributes

_importer._add_module(
    Module_six_moves_urllib_parse(__name__ + "".moves.urllib_parse""),
    ""moves.urllib_parse"",
    ""moves.urllib.parse"",
)


class Module_six_moves_urllib_error(_LazyModule):

    


_urllib_error_moved_attributes = [
    MovedAttribute(""URLError"", ""urllib2"", ""urllib.error""),
    MovedAttribute(""HTTPError"", ""urllib2"", ""urllib.error""),
    MovedAttribute(""ContentTooShortError"", ""urllib"", ""urllib.error""),
]
for attr in _urllib_error_moved_attributes:
    setattr(Module_six_moves_urllib_error, attr.name, attr)
del attr

Module_six_moves_urllib_error._moved_attributes = _urllib_error_moved_attributes

_importer._add_module(
    Module_six_moves_urllib_error(__name__ + "".moves.urllib.error""),
    ""moves.urllib_error"",
    ""moves.urllib.error"",
)


class Module_six_moves_urllib_request(_LazyModule):

    


_urllib_request_moved_attributes = [
    MovedAttribute(""urlopen"", ""urllib2"", ""urllib.request""),
    MovedAttribute(""install_opener"", ""urllib2"", ""urllib.request""),
    MovedAttribute(""build_opener"", ""urllib2"", ""urllib.request""),
    MovedAttribute(""pathname2url"", ""urllib"", ""urllib.request""),
    MovedAttribute(""url2pathname"", ""urllib"", ""urllib.request""),
    MovedAttribute(""getproxies"", ""urllib"", ""urllib.request""),
    MovedAttribute(""Request"", ""urllib2"", ""urllib.request""),
    MovedAttribute(""OpenerDirector"", ""urllib2"", ""urllib.request""),
    MovedAttribute(""HTTPDefaultErrorHandler"", ""urllib2"", ""urllib.request""),
    MovedAttribute(""HTTPRedirectHandler"", ""urllib2"", ""urllib.request""),
    MovedAttribute(""HTTPCookieProcessor"", ""urllib2"", ""urllib.request""),
    MovedAttribute(""ProxyHandler"", ""urllib2"", ""urllib.request""),
    MovedAttribute(""BaseHandler"", ""urllib2"", ""urllib.request""),
    MovedAttribute(""HTTPPasswordMgr"", ""urllib2"", ""urllib.request""),
    MovedAttribute(""HTTPPasswordMgrWithDefaultRealm"", ""urllib2"", ""urllib.request""),
    MovedAttribute(""AbstractBasicAuthHandler"", ""urllib2"", ""urllib.request""),
    MovedAttribute(""HTTPBasicAuthHandler"", ""urllib2"", ""urllib.request""),
    MovedAttribute(""ProxyBasicAuthHandler"", ""urllib2"", ""urllib.request""),
    MovedAttribute(""AbstractDigestAuthHandler"", ""urllib2"", ""urllib.request""),
    MovedAttribute(""HTTPDigestAuthHandler"", ""urllib2"", ""urllib.request""),
    MovedAttribute(""ProxyDigestAuthHandler"", ""urllib2"", ""urllib.request""),
    MovedAttribute(""HTTPHandler"", ""urllib2"", ""urllib.request""),
    MovedAttribute(""HTTPSHandler"", ""urllib2"", ""urllib.request""),
    MovedAttribute(""FileHandler"", ""urllib2"", ""urllib.request""),
    MovedAttribute(""FTPHandler"", ""urllib2"", ""urllib.request""),
    MovedAttribute(""CacheFTPHandler"", ""urllib2"", ""urllib.request""),
    MovedAttribute(""UnknownHandler"", ""urllib2"", ""urllib.request""),
    MovedAttribute(""HTTPErrorProcessor"", ""urllib2"", ""urllib.request""),
    MovedAttribute(""urlretrieve"", ""urllib"", ""urllib.request""),
    MovedAttribute(""urlcleanup"", ""urllib"", ""urllib.request""),
    MovedAttribute(""URLopener"", ""urllib"", ""urllib.request""),
    MovedAttribute(""FancyURLopener"", ""urllib"", ""urllib.request""),
    MovedAttribute(""proxy_bypass"", ""urllib"", ""urllib.request""),
    MovedAttribute(""parse_http_list"", ""urllib2"", ""urllib.request""),
    MovedAttribute(""parse_keqv_list"", ""urllib2"", ""urllib.request""),
]
for attr in _urllib_request_moved_attributes:
    setattr(Module_six_moves_urllib_request, attr.name, attr)
del attr

Module_six_moves_urllib_request._moved_attributes = _urllib_request_moved_attributes

_importer._add_module(
    Module_six_moves_urllib_request(__name__ + "".moves.urllib.request""),
    ""moves.urllib_request"",
    ""moves.urllib.request"",
)


class Module_six_moves_urllib_response(_LazyModule):

    


_urllib_response_moved_attributes = [
    MovedAttribute(""addbase"", ""urllib"", ""urllib.response""),
    MovedAttribute(""addclosehook"", ""urllib"", ""urllib.response""),
    MovedAttribute(""addinfo"", ""urllib"", ""urllib.response""),
    MovedAttribute(""addinfourl"", ""urllib"", ""urllib.response""),
]
for attr in _urllib_response_moved_attributes:
    setattr(Module_six_moves_urllib_response, attr.name, attr)
del attr

Module_six_moves_urllib_response._moved_attributes = _urllib_response_moved_attributes

_importer._add_module(
    Module_six_moves_urllib_response(__name__ + "".moves.urllib.response""),
    ""moves.urllib_response"",
    ""moves.urllib.response"",
)


class Module_six_moves_urllib_robotparser(_LazyModule):

    


_urllib_robotparser_moved_attributes = [
    MovedAttribute(""RobotFileParser"", ""robotparser"", ""urllib.robotparser""),
]
for attr in _urllib_robotparser_moved_attributes:
    setattr(Module_six_moves_urllib_robotparser, attr.name, attr)
del attr

Module_six_moves_urllib_robotparser._moved_attributes = (
    _urllib_robotparser_moved_attributes
)

_importer._add_module(
    Module_six_moves_urllib_robotparser(__name__ + "".moves.urllib.robotparser""),
    ""moves.urllib_robotparser"",
    ""moves.urllib.robotparser"",
)


class Module_six_moves_urllib(types.ModuleType):

    

    __path__ = []  
    parse = _importer._get_module(""moves.urllib_parse"")
    error = _importer._get_module(""moves.urllib_error"")
    request = _importer._get_module(""moves.urllib_request"")
    response = _importer._get_module(""moves.urllib_response"")
    robotparser = _importer._get_module(""moves.urllib_robotparser"")

    def __dir__(self):
        return [""parse"", ""error"", ""request"", ""response"", ""robotparser""]


_importer._add_module(
    Module_six_moves_urllib(__name__ + "".moves.urllib""), ""moves.urllib""
)


def add_move(move):
    
    setattr(_MovedItems, move.name, move)


def remove_move(name):
    
    try:
        delattr(_MovedItems, name)
    except AttributeError:
        try:
            del moves.__dict__[name]
        except KeyError:
            raise AttributeError(""no such move, %r"" % (name,))


if PY3:
    _meth_func = ""__func__""
    _meth_self = ""__self__""

    _func_closure = ""__closure__""
    _func_code = ""__code__""
    _func_defaults = ""__defaults__""
    _func_globals = ""__globals__""
else:
    _meth_func = ""im_func""
    _meth_self = ""im_self""

    _func_closure = ""func_closure""
    _func_code = ""func_code""
    _func_defaults = ""func_defaults""
    _func_globals = ""func_globals""


try:
    advance_iterator = next
except NameError:

    def advance_iterator(it):
        return it.next()


next = advance_iterator


try:
    callable = callable
except NameError:

    def callable(obj):
        return any(""__call__"" in klass.__dict__ for klass in type(obj).__mro__)


if PY3:

    def get_unbound_function(unbound):
        return unbound

    create_bound_method = types.MethodType

    def create_unbound_method(func, cls):
        return func

    Iterator = object
else:

    def get_unbound_function(unbound):
        return unbound.im_func

    def create_bound_method(func, obj):
        return types.MethodType(func, obj, obj.__class__)

    def create_unbound_method(func, cls):
        return types.MethodType(func, None, cls)

    class Iterator(object):
        def next(self):
            return type(self).__next__(self)

    callable = callable
_add_doc(
    get_unbound_function, 
)


get_method_function = operator.attrgetter(_meth_func)
get_method_self = operator.attrgetter(_meth_self)
get_function_closure = operator.attrgetter(_func_closure)
get_function_code = operator.attrgetter(_func_code)
get_function_defaults = operator.attrgetter(_func_defaults)
get_function_globals = operator.attrgetter(_func_globals)


if PY3:

    def iterkeys(d, **kw):
        return iter(d.keys(**kw))

    def itervalues(d, **kw):
        return iter(d.values(**kw))

    def iteritems(d, **kw):
        return iter(d.items(**kw))

    def iterlists(d, **kw):
        return iter(d.lists(**kw))

    viewkeys = operator.methodcaller(""keys"")

    viewvalues = operator.methodcaller(""values"")

    viewitems = operator.methodcaller(""items"")
else:

    def iterkeys(d, **kw):
        return d.iterkeys(**kw)

    def itervalues(d, **kw):
        return d.itervalues(**kw)

    def iteritems(d, **kw):
        return d.iteritems(**kw)

    def iterlists(d, **kw):
        return d.iterlists(**kw)

    viewkeys = operator.methodcaller(""viewkeys"")

    viewvalues = operator.methodcaller(""viewvalues"")

    viewitems = operator.methodcaller(""viewitems"")

_add_doc(iterkeys, ""Return an iterator over the keys of a dictionary."")
_add_doc(itervalues, ""Return an iterator over the values of a dictionary."")
_add_doc(iteritems, ""Return an iterator over the (key, value) pairs of a dictionary."")
_add_doc(
    iterlists, ""Return an iterator over the (key, [values]) pairs of a dictionary.""
)


if PY3:

    def b(s):
        return s.encode(""latin-1"")

    def u(s):
        return s

    unichr = chr
    import struct

    int2byte = struct.Struct("">B"").pack
    del struct
    byte2int = operator.itemgetter(0)
    indexbytes = operator.getitem
    iterbytes = iter
    import io

    StringIO = io.StringIO
    BytesIO = io.BytesIO
    del io
    _assertCountEqual = ""assertCountEqual""
    if sys.version_info[1] <= 1:
        _assertRaisesRegex = ""assertRaisesRegexp""
        _assertRegex = ""assertRegexpMatches""
        _assertNotRegex = ""assertNotRegexpMatches""
    else:
        _assertRaisesRegex = ""assertRaisesRegex""
        _assertRegex = ""assertRegex""
        _assertNotRegex = ""assertNotRegex""
else:

    def b(s):
        return s

    

    def u(s):
        return unicode(s.replace(r""\\"", r""\\\\""), ""unicode_escape"")

    unichr = unichr
    int2byte = chr

    def byte2int(bs):
        return ord(bs[0])

    def indexbytes(buf, i):
        return ord(buf[i])

    iterbytes = functools.partial(itertools.imap, ord)
    import StringIO

    StringIO = BytesIO = StringIO.StringIO
    _assertCountEqual = ""assertItemsEqual""
    _assertRaisesRegex = ""assertRaisesRegexp""
    _assertRegex = ""assertRegexpMatches""
    _assertNotRegex = ""assertNotRegexpMatches""
_add_doc(b, )
_add_doc(u, )


def assertCountEqual(self, *args, **kwargs):
    return getattr(self, _assertCountEqual)(*args, **kwargs)


def assertRaisesRegex(self, *args, **kwargs):
    return getattr(self, _assertRaisesRegex)(*args, **kwargs)


def assertRegex(self, *args, **kwargs):
    return getattr(self, _assertRegex)(*args, **kwargs)


def assertNotRegex(self, *args, **kwargs):
    return getattr(self, _assertNotRegex)(*args, **kwargs)


if PY3:
    exec_ = getattr(moves.builtins, ""exec"")

    def reraise(tp, value, tb=None):
        try:
            if value is None:
                value = tp()
            if value.__traceback__ is not tb:
                raise value.with_traceback(tb)
            raise value
        finally:
            value = None
            tb = None

else:

    def exec_(_code_, _globs_=None, _locs_=None):
        
        if _globs_ is None:
            frame = sys._getframe(1)
            _globs_ = frame.f_globals
            if _locs_ is None:
                _locs_ = frame.f_locals
            del frame
        elif _locs_ is None:
            _locs_ = _globs_
        exec ()

    exec_(
        
    )


if sys.version_info[:2] > (3,):
    exec_(
        
    )
else:

    def raise_from(value, from_value):
        raise value


print_ = getattr(moves.builtins, ""print"", None)
if print_ is None:

    def print_(*args, **kwargs):
        
        fp = kwargs.pop(""file"", sys.stdout)
        if fp is None:
            return

        def write(data):
            if not isinstance(data, basestring):
                data = str(data)
            
            if (
                isinstance(fp, file)
                and isinstance(data, unicode)
                and fp.encoding is not None
            ):
                errors = getattr(fp, ""errors"", None)
                if errors is None:
                    errors = ""strict""
                data = data.encode(fp.encoding, errors)
            fp.write(data)

        want_unicode = False
        sep = kwargs.pop(""sep"", None)
        if sep is not None:
            if isinstance(sep, unicode):
                want_unicode = True
            elif not isinstance(sep, str):
                raise TypeError(""sep must be None or a string"")
        end = kwargs.pop(""end"", None)
        if end is not None:
            if isinstance(end, unicode):
                want_unicode = True
            elif not isinstance(end, str):
                raise TypeError(""end must be None or a string"")
        if kwargs:
            raise TypeError(""invalid keyword arguments to print()"")
        if not want_unicode:
            for arg in args:
                if isinstance(arg, unicode):
                    want_unicode = True
                    break
        if want_unicode:
            newline = unicode(""\n"")
            space = unicode("" "")
        else:
            newline = ""\n""
            space = "" ""
        if sep is None:
            sep = space
        if end is None:
            end = newline
        for i, arg in enumerate(args):
            if i:
                write(sep)
            write(arg)
        write(end)


if sys.version_info[:2] < (3, 3):
    _print = print_

    def print_(*args, **kwargs):
        fp = kwargs.get(""file"", sys.stdout)
        flush = kwargs.pop(""flush"", False)
        _print(*args, **kwargs)
        if flush and fp is not None:
            fp.flush()


_add_doc(reraise, )

if sys.version_info[0:2] < (3, 4):
    
    
    
    
    
    def _update_wrapper(
        wrapper,
        wrapped,
        assigned=functools.WRAPPER_ASSIGNMENTS,
        updated=functools.WRAPPER_UPDATES,
    ):
        for attr in assigned:
            try:
                value = getattr(wrapped, attr)
            except AttributeError:
                continue
            else:
                setattr(wrapper, attr, value)
        for attr in updated:
            getattr(wrapper, attr).update(getattr(wrapped, attr, {}))
        wrapper.__wrapped__ = wrapped
        return wrapper

    _update_wrapper.__doc__ = functools.update_wrapper.__doc__

    def wraps(
        wrapped,
        assigned=functools.WRAPPER_ASSIGNMENTS,
        updated=functools.WRAPPER_UPDATES,
    ):
        return functools.partial(
            _update_wrapper, wrapped=wrapped, assigned=assigned, updated=updated
        )

    wraps.__doc__ = functools.wraps.__doc__

else:
    wraps = functools.wraps


def with_metaclass(meta, *bases):
    
    
    
    
    class metaclass(type):
        def __new__(cls, name, this_bases, d):
            if sys.version_info[:2] >= (3, 7):
                
                
                resolved_bases = types.resolve_bases(bases)
                if resolved_bases is not bases:
                    d[""__orig_bases__""] = bases
            else:
                resolved_bases = bases
            return meta(name, resolved_bases, d)

        @classmethod
        def __prepare__(cls, name, this_bases):
            return meta.__prepare__(name, bases)

    return type.__new__(metaclass, ""temporary_class"", (), {})


def add_metaclass(metaclass):
    

    def wrapper(cls):
        orig_vars = cls.__dict__.copy()
        slots = orig_vars.get(""__slots__"")
        if slots is not None:
            if isinstance(slots, str):
                slots = [slots]
            for slots_var in slots:
                orig_vars.pop(slots_var)
        orig_vars.pop(""__dict__"", None)
        orig_vars.pop(""__weakref__"", None)
        if hasattr(cls, ""__qualname__""):
            orig_vars[""__qualname__""] = cls.__qualname__
        return metaclass(cls.__name__, cls.__bases__, orig_vars)

    return wrapper


def ensure_binary(s, encoding=""utf-8"", errors=""strict""):
    
    if isinstance(s, binary_type):
        return s
    if isinstance(s, text_type):
        return s.encode(encoding, errors)
    raise TypeError(""not expecting type '%s'"" % type(s))


def ensure_str(s, encoding=""utf-8"", errors=""strict""):
    
    
    if type(s) is str:
        return s
    if PY2 and isinstance(s, text_type):
        return s.encode(encoding, errors)
    elif PY3 and isinstance(s, binary_type):
        return s.decode(encoding, errors)
    elif not isinstance(s, (text_type, binary_type)):
        raise TypeError(""not expecting type '%s'"" % type(s))
    return s


def ensure_text(s, encoding=""utf-8"", errors=""strict""):
    
    if isinstance(s, binary_type):
        return s.decode(encoding, errors)
    elif isinstance(s, text_type):
        return s
    else:
        raise TypeError(""not expecting type '%s'"" % type(s))


def python_2_unicode_compatible(klass):
    
    if PY2:
        if ""__str__"" not in klass.__dict__:
            raise ValueError(
                ""@python_2_unicode_compatible cannot be applied ""
                ""to %s because it doesn't define __str__()."" % klass.__name__
            )
        klass.__unicode__ = klass.__str__
        klass.__str__ = lambda self: self.__unicode__().encode(""utf-8"")
    return klass





__path__ = []  
__package__ = __name__  
if globals().get(""__spec__"") is not None:
    __spec__.submodule_search_locations = []  



if sys.meta_path:
    for i, importer in enumerate(sys.meta_path):
        
        
        
        
        if (
            type(importer).__name__ == ""_SixMetaPathImporter""
            and importer.name == __name__
        ):
            del sys.meta_path[i]
            break
    del i, importer

sys.meta_path.append(_importer)




import io
from socket import SocketIO


def backport_makefile(
    self, mode=""r"", buffering=None, encoding=None, errors=None, newline=None
):
    
    if not set(mode) <= {""r"", ""w"", ""b""}:
        raise ValueError(""invalid mode %r (only r, w, b allowed)"" % (mode,))
    writing = ""w"" in mode
    reading = ""r"" in mode or not writing
    assert reading or writing
    binary = ""b"" in mode
    rawmode = """"
    if reading:
        rawmode += ""r""
    if writing:
        rawmode += ""w""
    raw = SocketIO(self, rawmode)
    self._makefile_refs += 1
    if buffering is None:
        buffering = -1
    if buffering < 0:
        buffering = io.DEFAULT_BUFFER_SIZE
    if buffering == 0:
        if not binary:
            raise ValueError(""unbuffered streams must be binary"")
        return raw
    if reading and writing:
        buffer = io.BufferedRWPair(raw, raw, buffering)
    elif reading:
        buffer = io.BufferedReader(raw, buffering)
    else:
        assert writing
        buffer = io.BufferedWriter(raw, buffering)
    if binary:
        return buffer
    text = io.TextIOWrapper(buffer, encoding, errors, newline)
    text.mode = mode
    return text



from __future__ import absolute_import

import itertools
import sys
from weakref import ref

__all__ = [""weakref_finalize""]


class weakref_finalize(object):
    

    
    
    

    __slots__ = ()
    _registry = {}
    _shutdown = False
    _index_iter = itertools.count()
    _dirty = False
    _registered_with_atexit = False

    class _Info(object):
        __slots__ = (""weakref"", ""func"", ""args"", ""kwargs"", ""atexit"", ""index"")

    def __init__(self, obj, func, *args, **kwargs):
        if not self._registered_with_atexit:
            
            
            import atexit

            atexit.register(self._exitfunc)
            weakref_finalize._registered_with_atexit = True
        info = self._Info()
        info.weakref = ref(obj, self)
        info.func = func
        info.args = args
        info.kwargs = kwargs or None
        info.atexit = True
        info.index = next(self._index_iter)
        self._registry[self] = info
        weakref_finalize._dirty = True

    def __call__(self, _=None):
        
        info = self._registry.pop(self, None)
        if info and not self._shutdown:
            return info.func(*info.args, **(info.kwargs or {}))

    def detach(self):
        
        info = self._registry.get(self)
        obj = info and info.weakref()
        if obj is not None and self._registry.pop(self, None):
            return (obj, info.func, info.args, info.kwargs or {})

    def peek(self):
        
        info = self._registry.get(self)
        obj = info and info.weakref()
        if obj is not None:
            return (obj, info.func, info.args, info.kwargs or {})

    @property
    def alive(self):
        
        return self in self._registry

    @property
    def atexit(self):
        
        info = self._registry.get(self)
        return bool(info) and info.atexit

    @atexit.setter
    def atexit(self, value):
        info = self._registry.get(self)
        if info:
            info.atexit = bool(value)

    def __repr__(self):
        info = self._registry.get(self)
        obj = info and info.weakref()
        if obj is None:
            return ""<%s object at %
        else:
            return ""<%s object at %
                type(self).__name__,
                id(self),
                type(obj).__name__,
                id(obj),
            )

    @classmethod
    def _select_for_exit(cls):
        
        L = [(f, i) for (f, i) in cls._registry.items() if i.atexit]
        L.sort(key=lambda item: item[1].index)
        return [f for (f, i) in L]

    @classmethod
    def _exitfunc(cls):
        
        
        
        reenable_gc = False
        try:
            if cls._registry:
                import gc

                if gc.isenabled():
                    reenable_gc = True
                    gc.disable()
                pending = None
                while True:
                    if pending is None or weakref_finalize._dirty:
                        pending = cls._select_for_exit()
                        weakref_finalize._dirty = False
                    if not pending:
                        break
                    f = pending.pop()
                    try:
                        
                        
                        
                        
                        f()
                    except Exception:
                        sys.excepthook(*sys.exc_info())
                    assert f not in cls._registry
        finally:
            
            weakref_finalize._shutdown = True
            if reenable_gc:
                gc.enable()


from __future__ import absolute_import

import socket

from ..contrib import _appengine_environ
from ..exceptions import LocationParseError
from ..packages import six
from .wait import NoWayToWaitForSocketError, wait_for_read


def is_connection_dropped(conn):  
    
    sock = getattr(conn, ""sock"", False)
    if sock is False:  
        return False
    if sock is None:  
        return True
    try:
        
        return wait_for_read(sock, timeout=0.0)
    except NoWayToWaitForSocketError:  
        return False






def create_connection(
    address,
    timeout=socket._GLOBAL_DEFAULT_TIMEOUT,
    source_address=None,
    socket_options=None,
):
    

    host, port = address
    if host.startswith(""[""):
        host = host.strip(""[]"")
    err = None

    
    
    
    family = allowed_gai_family()

    try:
        host.encode(""idna"")
    except UnicodeError:
        return six.raise_from(
            LocationParseError(u""'%s', label empty or too long"" % host), None
        )

    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
        af, socktype, proto, canonname, sa = res
        sock = None
        try:
            sock = socket.socket(af, socktype, proto)

            
            _set_socket_options(sock, socket_options)

            if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:
                sock.settimeout(timeout)
            if source_address:
                sock.bind(source_address)
            sock.connect(sa)
            return sock

        except socket.error as e:
            err = e
            if sock is not None:
                sock.close()
                sock = None

    if err is not None:
        raise err

    raise socket.error(""getaddrinfo returns an empty list"")


def _set_socket_options(sock, options):
    if options is None:
        return

    for opt in options:
        sock.setsockopt(*opt)


def allowed_gai_family():
    

    family = socket.AF_INET
    if HAS_IPV6:
        family = socket.AF_UNSPEC
    return family


def _has_ipv6(host):
    
    sock = None
    has_ipv6 = False

    
    
    
    
    if _appengine_environ.is_appengine_sandbox():
        return False

    if socket.has_ipv6:
        
        
        
        
        
        try:
            sock = socket.socket(socket.AF_INET6)
            sock.bind((host, 0))
            has_ipv6 = True
        except Exception:
            pass

    if sock:
        sock.close()
    return has_ipv6


HAS_IPV6 = _has_ipv6(""::1"")

from .ssl_ import create_urllib3_context, resolve_cert_reqs, resolve_ssl_version


def connection_requires_http_tunnel(
    proxy_url=None, proxy_config=None, destination_scheme=None
):
    
    
    if proxy_url is None:
        return False

    
    if destination_scheme == ""http"":
        return False

    
    if (
        proxy_url.scheme == ""https""
        and proxy_config
        and proxy_config.use_forwarding_for_https
    ):
        return False

    
    return True


def create_proxy_ssl_context(
    ssl_version, cert_reqs, ca_certs=None, ca_cert_dir=None, ca_cert_data=None
):
    
    ssl_context = create_urllib3_context(
        ssl_version=resolve_ssl_version(ssl_version),
        cert_reqs=resolve_cert_reqs(cert_reqs),
    )

    if (
        not ca_certs
        and not ca_cert_dir
        and not ca_cert_data
        and hasattr(ssl_context, ""load_default_certs"")
    ):
        ssl_context.load_default_certs()

    return ssl_context

import collections

from ..packages import six
from ..packages.six.moves import queue

if six.PY2:
    
    import Queue as _unused_module_Queue  


class LifoQueue(queue.Queue):
    def _init(self, _):
        self.queue = collections.deque()

    def _qsize(self, len=len):
        return len(self.queue)

    def _put(self, item):
        self.queue.append(item)

    def _get(self):
        return self.queue.pop()

from __future__ import absolute_import

from base64 import b64encode

from ..exceptions import UnrewindableBodyError
from ..packages.six import b, integer_types





SKIP_HEADER = ""@@@SKIP_HEADER@@@""
SKIPPABLE_HEADERS = frozenset([""accept-encoding"", ""host"", ""user-agent""])

ACCEPT_ENCODING = ""gzip,deflate""

_FAILEDTELL = object()


def make_headers(
    keep_alive=None,
    accept_encoding=None,
    user_agent=None,
    basic_auth=None,
    proxy_basic_auth=None,
    disable_cache=None,
):
    
    headers = {}
    if accept_encoding:
        if isinstance(accept_encoding, str):
            pass
        elif isinstance(accept_encoding, list):
            accept_encoding = "","".join(accept_encoding)
        else:
            accept_encoding = ACCEPT_ENCODING
        headers[""accept-encoding""] = accept_encoding

    if user_agent:
        headers[""user-agent""] = user_agent

    if keep_alive:
        headers[""connection""] = ""keep-alive""

    if basic_auth:
        headers[""authorization""] = ""Basic "" + b64encode(b(basic_auth)).decode(""utf-8"")

    if proxy_basic_auth:
        headers[""proxy-authorization""] = ""Basic "" + b64encode(
            b(proxy_basic_auth)
        ).decode(""utf-8"")

    if disable_cache:
        headers[""cache-control""] = ""no-cache""

    return headers


def set_file_position(body, pos):
    
    if pos is not None:
        rewind_body(body, pos)
    elif getattr(body, ""tell"", None) is not None:
        try:
            pos = body.tell()
        except (IOError, OSError):
            
            
            pos = _FAILEDTELL

    return pos


def rewind_body(body, body_pos):
    
    body_seek = getattr(body, ""seek"", None)
    if body_seek is not None and isinstance(body_pos, integer_types):
        try:
            body_seek(body_pos)
        except (IOError, OSError):
            raise UnrewindableBodyError(
                ""An error occurred when rewinding request body for redirect/retry.""
            )
    elif body_pos is _FAILEDTELL:
        raise UnrewindableBodyError(
            ""Unable to record file position for rewinding ""
            ""request body during a redirect/retry.""
        )
    else:
        raise ValueError(
            ""body_pos must be of type integer, instead it was %s."" % type(body_pos)
        )

from __future__ import absolute_import

from email.errors import MultipartInvariantViolationDefect, StartBoundaryNotFoundDefect

from ..exceptions import HeaderParsingError
from ..packages.six.moves import http_client as httplib


def is_fp_closed(obj):
    

    try:
        
        
        return obj.isclosed()
    except AttributeError:
        pass

    try:
        
        return obj.closed
    except AttributeError:
        pass

    try:
        
        
        return obj.fp is None
    except AttributeError:
        pass

    raise ValueError(""Unable to determine whether fp is closed."")


def assert_header_parsing(headers):
    

    
    
    if not isinstance(headers, httplib.HTTPMessage):
        raise TypeError(""expected httplib.Message, got {0}."".format(type(headers)))

    defects = getattr(headers, ""defects"", None)
    get_payload = getattr(headers, ""get_payload"", None)

    unparsed_data = None
    if get_payload:
        
        
        if not headers.is_multipart():
            payload = get_payload()

            if isinstance(payload, (bytes, str)):
                unparsed_data = payload
    if defects:
        
        
        
        
        

        
        
        
        
        
        defects = [
            defect
            for defect in defects
            if not isinstance(
                defect, (StartBoundaryNotFoundDefect, MultipartInvariantViolationDefect)
            )
        ]

    if defects or unparsed_data:
        raise HeaderParsingError(defects=defects, unparsed_data=unparsed_data)


def is_response_to_head(response):
    
    
    method = response._method
    if isinstance(method, int):  
        return method == 3
    return method.upper() == ""HEAD""

from __future__ import absolute_import

import email
import logging
import re
import time
import warnings
from collections import namedtuple
from itertools import takewhile

from ..exceptions import (
    ConnectTimeoutError,
    InvalidHeader,
    MaxRetryError,
    ProtocolError,
    ProxyError,
    ReadTimeoutError,
    ResponseError,
)
from ..packages import six

log = logging.getLogger(__name__)



RequestHistory = namedtuple(
    ""RequestHistory"", [""method"", ""url"", ""error"", ""status"", ""redirect_location""]
)



_Default = object()


class _RetryMeta(type):
    @property
    def DEFAULT_METHOD_WHITELIST(cls):
        warnings.warn(
            ""Using 'Retry.DEFAULT_METHOD_WHITELIST' is deprecated and ""
            ""will be removed in v2.0. Use 'Retry.DEFAULT_ALLOWED_METHODS' instead"",
            DeprecationWarning,
        )
        return cls.DEFAULT_ALLOWED_METHODS

    @DEFAULT_METHOD_WHITELIST.setter
    def DEFAULT_METHOD_WHITELIST(cls, value):
        warnings.warn(
            ""Using 'Retry.DEFAULT_METHOD_WHITELIST' is deprecated and ""
            ""will be removed in v2.0. Use 'Retry.DEFAULT_ALLOWED_METHODS' instead"",
            DeprecationWarning,
        )
        cls.DEFAULT_ALLOWED_METHODS = value

    @property
    def DEFAULT_REDIRECT_HEADERS_BLACKLIST(cls):
        warnings.warn(
            ""Using 'Retry.DEFAULT_REDIRECT_HEADERS_BLACKLIST' is deprecated and ""
            ""will be removed in v2.0. Use 'Retry.DEFAULT_REMOVE_HEADERS_ON_REDIRECT' instead"",
            DeprecationWarning,
        )
        return cls.DEFAULT_REMOVE_HEADERS_ON_REDIRECT

    @DEFAULT_REDIRECT_HEADERS_BLACKLIST.setter
    def DEFAULT_REDIRECT_HEADERS_BLACKLIST(cls, value):
        warnings.warn(
            ""Using 'Retry.DEFAULT_REDIRECT_HEADERS_BLACKLIST' is deprecated and ""
            ""will be removed in v2.0. Use 'Retry.DEFAULT_REMOVE_HEADERS_ON_REDIRECT' instead"",
            DeprecationWarning,
        )
        cls.DEFAULT_REMOVE_HEADERS_ON_REDIRECT = value

    @property
    def BACKOFF_MAX(cls):
        warnings.warn(
            ""Using 'Retry.BACKOFF_MAX' is deprecated and ""
            ""will be removed in v2.0. Use 'Retry.DEFAULT_BACKOFF_MAX' instead"",
            DeprecationWarning,
        )
        return cls.DEFAULT_BACKOFF_MAX

    @BACKOFF_MAX.setter
    def BACKOFF_MAX(cls, value):
        warnings.warn(
            ""Using 'Retry.BACKOFF_MAX' is deprecated and ""
            ""will be removed in v2.0. Use 'Retry.DEFAULT_BACKOFF_MAX' instead"",
            DeprecationWarning,
        )
        cls.DEFAULT_BACKOFF_MAX = value


@six.add_metaclass(_RetryMeta)
class Retry(object):
    

    
    DEFAULT_ALLOWED_METHODS = frozenset(
        [""HEAD"", ""GET"", ""PUT"", ""DELETE"", ""OPTIONS"", ""TRACE""]
    )

    
    RETRY_AFTER_STATUS_CODES = frozenset([413, 429, 503])

    
    DEFAULT_REMOVE_HEADERS_ON_REDIRECT = frozenset(
        [""Cookie"", ""Authorization"", ""Proxy-Authorization""]
    )

    
    DEFAULT_BACKOFF_MAX = 120

    def __init__(
        self,
        total=10,
        connect=None,
        read=None,
        redirect=None,
        status=None,
        other=None,
        allowed_methods=_Default,
        status_forcelist=None,
        backoff_factor=0,
        raise_on_redirect=True,
        raise_on_status=True,
        history=None,
        respect_retry_after_header=True,
        remove_headers_on_redirect=_Default,
        
        method_whitelist=_Default,
    ):

        if method_whitelist is not _Default:
            if allowed_methods is not _Default:
                raise ValueError(
                    ""Using both 'allowed_methods' and ""
                    ""'method_whitelist' together is not allowed. ""
                    ""Instead only use 'allowed_methods'""
                )
            warnings.warn(
                ""Using 'method_whitelist' with Retry is deprecated and ""
                ""will be removed in v2.0. Use 'allowed_methods' instead"",
                DeprecationWarning,
                stacklevel=2,
            )
            allowed_methods = method_whitelist
        if allowed_methods is _Default:
            allowed_methods = self.DEFAULT_ALLOWED_METHODS
        if remove_headers_on_redirect is _Default:
            remove_headers_on_redirect = self.DEFAULT_REMOVE_HEADERS_ON_REDIRECT

        self.total = total
        self.connect = connect
        self.read = read
        self.status = status
        self.other = other

        if redirect is False or total is False:
            redirect = 0
            raise_on_redirect = False

        self.redirect = redirect
        self.status_forcelist = status_forcelist or set()
        self.allowed_methods = allowed_methods
        self.backoff_factor = backoff_factor
        self.raise_on_redirect = raise_on_redirect
        self.raise_on_status = raise_on_status
        self.history = history or tuple()
        self.respect_retry_after_header = respect_retry_after_header
        self.remove_headers_on_redirect = frozenset(
            [h.lower() for h in remove_headers_on_redirect]
        )

    def new(self, **kw):
        params = dict(
            total=self.total,
            connect=self.connect,
            read=self.read,
            redirect=self.redirect,
            status=self.status,
            other=self.other,
            status_forcelist=self.status_forcelist,
            backoff_factor=self.backoff_factor,
            raise_on_redirect=self.raise_on_redirect,
            raise_on_status=self.raise_on_status,
            history=self.history,
            remove_headers_on_redirect=self.remove_headers_on_redirect,
            respect_retry_after_header=self.respect_retry_after_header,
        )

        
        
        
        
        
        if ""method_whitelist"" not in kw and ""allowed_methods"" not in kw:
            if ""method_whitelist"" in self.__dict__:
                warnings.warn(
                    ""Using 'method_whitelist' with Retry is deprecated and ""
                    ""will be removed in v2.0. Use 'allowed_methods' instead"",
                    DeprecationWarning,
                )
                params[""method_whitelist""] = self.allowed_methods
            else:
                params[""allowed_methods""] = self.allowed_methods

        params.update(kw)
        return type(self)(**params)

    @classmethod
    def from_int(cls, retries, redirect=True, default=None):
        
        if retries is None:
            retries = default if default is not None else cls.DEFAULT

        if isinstance(retries, Retry):
            return retries

        redirect = bool(redirect) and None
        new_retries = cls(retries, redirect=redirect)
        log.debug(""Converted retries value: %r -> %r"", retries, new_retries)
        return new_retries

    def get_backoff_time(self):
        
        
        consecutive_errors_len = len(
            list(
                takewhile(lambda x: x.redirect_location is None, reversed(self.history))
            )
        )
        if consecutive_errors_len <= 1:
            return 0

        backoff_value = self.backoff_factor * (2 ** (consecutive_errors_len - 1))
        return min(self.DEFAULT_BACKOFF_MAX, backoff_value)

    def parse_retry_after(self, retry_after):
        
        if re.match(r""^\s*[0-9]+\s*$"", retry_after):
            seconds = int(retry_after)
        else:
            retry_date_tuple = email.utils.parsedate_tz(retry_after)
            if retry_date_tuple is None:
                raise InvalidHeader(""Invalid Retry-After header: %s"" % retry_after)
            if retry_date_tuple[9] is None:  
                
                
                
                
                retry_date_tuple = retry_date_tuple[:9] + (0,) + retry_date_tuple[10:]

            retry_date = email.utils.mktime_tz(retry_date_tuple)
            seconds = retry_date - time.time()

        if seconds < 0:
            seconds = 0

        return seconds

    def get_retry_after(self, response):
        

        retry_after = response.headers.get(""Retry-After"")

        if retry_after is None:
            return None

        return self.parse_retry_after(retry_after)

    def sleep_for_retry(self, response=None):
        retry_after = self.get_retry_after(response)
        if retry_after:
            time.sleep(retry_after)
            return True

        return False

    def _sleep_backoff(self):
        backoff = self.get_backoff_time()
        if backoff <= 0:
            return
        time.sleep(backoff)

    def sleep(self, response=None):
        

        if self.respect_retry_after_header and response:
            slept = self.sleep_for_retry(response)
            if slept:
                return

        self._sleep_backoff()

    def _is_connection_error(self, err):
        
        if isinstance(err, ProxyError):
            err = err.original_error
        return isinstance(err, ConnectTimeoutError)

    def _is_read_error(self, err):
        
        return isinstance(err, (ReadTimeoutError, ProtocolError))

    def _is_method_retryable(self, method):
        
        
        
        if ""method_whitelist"" in self.__dict__:
            warnings.warn(
                ""Using 'method_whitelist' with Retry is deprecated and ""
                ""will be removed in v2.0. Use 'allowed_methods' instead"",
                DeprecationWarning,
            )
            allowed_methods = self.method_whitelist
        else:
            allowed_methods = self.allowed_methods

        if allowed_methods and method.upper() not in allowed_methods:
            return False
        return True

    def is_retry(self, method, status_code, has_retry_after=False):
        
        if not self._is_method_retryable(method):
            return False

        if self.status_forcelist and status_code in self.status_forcelist:
            return True

        return (
            self.total
            and self.respect_retry_after_header
            and has_retry_after
            and (status_code in self.RETRY_AFTER_STATUS_CODES)
        )

    def is_exhausted(self):
        
        retry_counts = (
            self.total,
            self.connect,
            self.read,
            self.redirect,
            self.status,
            self.other,
        )
        retry_counts = list(filter(None, retry_counts))
        if not retry_counts:
            return False

        return min(retry_counts) < 0

    def increment(
        self,
        method=None,
        url=None,
        response=None,
        error=None,
        _pool=None,
        _stacktrace=None,
    ):
        
        if self.total is False and error:
            
            raise six.reraise(type(error), error, _stacktrace)

        total = self.total
        if total is not None:
            total -= 1

        connect = self.connect
        read = self.read
        redirect = self.redirect
        status_count = self.status
        other = self.other
        cause = ""unknown""
        status = None
        redirect_location = None

        if error and self._is_connection_error(error):
            
            if connect is False:
                raise six.reraise(type(error), error, _stacktrace)
            elif connect is not None:
                connect -= 1

        elif error and self._is_read_error(error):
            
            if read is False or not self._is_method_retryable(method):
                raise six.reraise(type(error), error, _stacktrace)
            elif read is not None:
                read -= 1

        elif error:
            
            if other is not None:
                other -= 1

        elif response and response.get_redirect_location():
            
            if redirect is not None:
                redirect -= 1
            cause = ""too many redirects""
            redirect_location = response.get_redirect_location()
            status = response.status

        else:
            
            
            cause = ResponseError.GENERIC_ERROR
            if response and response.status:
                if status_count is not None:
                    status_count -= 1
                cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)
                status = response.status

        history = self.history + (
            RequestHistory(method, url, error, status, redirect_location),
        )

        new_retry = self.new(
            total=total,
            connect=connect,
            read=read,
            redirect=redirect,
            status=status_count,
            other=other,
            history=history,
        )

        if new_retry.is_exhausted():
            raise MaxRetryError(_pool, url, error or ResponseError(cause))

        log.debug(""Incremented Retry for (url='%s'): %r"", url, new_retry)

        return new_retry

    def __repr__(self):
        return (
            ""{cls.__name__}(total={self.total}, connect={self.connect}, ""
            ""read={self.read}, redirect={self.redirect}, status={self.status})""
        ).format(cls=type(self), self=self)

    def __getattr__(self, item):
        if item == ""method_whitelist"":
            
            warnings.warn(
                ""Using 'method_whitelist' with Retry is deprecated and ""
                ""will be removed in v2.0. Use 'allowed_methods' instead"",
                DeprecationWarning,
            )
            return self.allowed_methods
        try:
            return getattr(super(Retry, self), item)
        except AttributeError:
            return getattr(Retry, item)



Retry.DEFAULT = Retry(3)

import io
import socket
import ssl

from ..exceptions import ProxySchemeUnsupported
from ..packages import six

SSL_BLOCKSIZE = 16384


class SSLTransport:
    

    @staticmethod
    def _validate_ssl_context_for_tls_in_tls(ssl_context):
        

        if not hasattr(ssl_context, ""wrap_bio""):
            if six.PY2:
                raise ProxySchemeUnsupported(
                    ""TLS in TLS requires SSLContext.wrap_bio() which isn't ""
                    ""supported on Python 2""
                )
            else:
                raise ProxySchemeUnsupported(
                    ""TLS in TLS requires SSLContext.wrap_bio() which isn't ""
                    ""available on non-native SSLContext""
                )

    def __init__(
        self, socket, ssl_context, server_hostname=None, suppress_ragged_eofs=True
    ):
        
        self.incoming = ssl.MemoryBIO()
        self.outgoing = ssl.MemoryBIO()

        self.suppress_ragged_eofs = suppress_ragged_eofs
        self.socket = socket

        self.sslobj = ssl_context.wrap_bio(
            self.incoming, self.outgoing, server_hostname=server_hostname
        )

        
        self._ssl_io_loop(self.sslobj.do_handshake)

    def __enter__(self):
        return self

    def __exit__(self, *_):
        self.close()

    def fileno(self):
        return self.socket.fileno()

    def read(self, len=1024, buffer=None):
        return self._wrap_ssl_read(len, buffer)

    def recv(self, len=1024, flags=0):
        if flags != 0:
            raise ValueError(""non-zero flags not allowed in calls to recv"")
        return self._wrap_ssl_read(len)

    def recv_into(self, buffer, nbytes=None, flags=0):
        if flags != 0:
            raise ValueError(""non-zero flags not allowed in calls to recv_into"")
        if buffer and (nbytes is None):
            nbytes = len(buffer)
        elif nbytes is None:
            nbytes = 1024
        return self.read(nbytes, buffer)

    def sendall(self, data, flags=0):
        if flags != 0:
            raise ValueError(""non-zero flags not allowed in calls to sendall"")
        count = 0
        with memoryview(data) as view, view.cast(""B"") as byte_view:
            amount = len(byte_view)
            while count < amount:
                v = self.send(byte_view[count:])
                count += v

    def send(self, data, flags=0):
        if flags != 0:
            raise ValueError(""non-zero flags not allowed in calls to send"")
        response = self._ssl_io_loop(self.sslobj.write, data)
        return response

    def makefile(
        self, mode=""r"", buffering=None, encoding=None, errors=None, newline=None
    ):
        
        if not set(mode) <= {""r"", ""w"", ""b""}:
            raise ValueError(""invalid mode %r (only r, w, b allowed)"" % (mode,))

        writing = ""w"" in mode
        reading = ""r"" in mode or not writing
        assert reading or writing
        binary = ""b"" in mode
        rawmode = """"
        if reading:
            rawmode += ""r""
        if writing:
            rawmode += ""w""
        raw = socket.SocketIO(self, rawmode)
        self.socket._io_refs += 1
        if buffering is None:
            buffering = -1
        if buffering < 0:
            buffering = io.DEFAULT_BUFFER_SIZE
        if buffering == 0:
            if not binary:
                raise ValueError(""unbuffered streams must be binary"")
            return raw
        if reading and writing:
            buffer = io.BufferedRWPair(raw, raw, buffering)
        elif reading:
            buffer = io.BufferedReader(raw, buffering)
        else:
            assert writing
            buffer = io.BufferedWriter(raw, buffering)
        if binary:
            return buffer
        text = io.TextIOWrapper(buffer, encoding, errors, newline)
        text.mode = mode
        return text

    def unwrap(self):
        self._ssl_io_loop(self.sslobj.unwrap)

    def close(self):
        self.socket.close()

    def getpeercert(self, binary_form=False):
        return self.sslobj.getpeercert(binary_form)

    def version(self):
        return self.sslobj.version()

    def cipher(self):
        return self.sslobj.cipher()

    def selected_alpn_protocol(self):
        return self.sslobj.selected_alpn_protocol()

    def selected_npn_protocol(self):
        return self.sslobj.selected_npn_protocol()

    def shared_ciphers(self):
        return self.sslobj.shared_ciphers()

    def compression(self):
        return self.sslobj.compression()

    def settimeout(self, value):
        self.socket.settimeout(value)

    def gettimeout(self):
        return self.socket.gettimeout()

    def _decref_socketios(self):
        self.socket._decref_socketios()

    def _wrap_ssl_read(self, len, buffer=None):
        try:
            return self._ssl_io_loop(self.sslobj.read, len, buffer)
        except ssl.SSLError as e:
            if e.errno == ssl.SSL_ERROR_EOF and self.suppress_ragged_eofs:
                return 0  
            else:
                raise

    def _ssl_io_loop(self, func, *args):
        
        should_loop = True
        ret = None

        while should_loop:
            errno = None
            try:
                ret = func(*args)
            except ssl.SSLError as e:
                if e.errno not in (ssl.SSL_ERROR_WANT_READ, ssl.SSL_ERROR_WANT_WRITE):
                    
                    raise e
                errno = e.errno

            buf = self.outgoing.read()
            self.socket.sendall(buf)

            if errno is None:
                should_loop = False
            elif errno == ssl.SSL_ERROR_WANT_READ:
                buf = self.socket.recv(SSL_BLOCKSIZE)
                if buf:
                    self.incoming.write(buf)
                else:
                    self.incoming.write_eof()
        return ret

from __future__ import absolute_import

import hashlib
import hmac
import os
import sys
import warnings
from binascii import hexlify, unhexlify

from ..exceptions import (
    InsecurePlatformWarning,
    ProxySchemeUnsupported,
    SNIMissingWarning,
    SSLError,
)
from ..packages import six
from .url import BRACELESS_IPV6_ADDRZ_RE, IPV4_RE

SSLContext = None
SSLTransport = None
HAS_SNI = False
IS_PYOPENSSL = False
IS_SECURETRANSPORT = False
ALPN_PROTOCOLS = [""http/1.1""]


HASHFUNC_MAP = {
    length: getattr(hashlib, algorithm, None)
    for length, algorithm in ((32, ""md5""), (40, ""sha1""), (64, ""sha256""))
}


def _const_compare_digest_backport(a, b):
    
    result = abs(len(a) - len(b))
    for left, right in zip(bytearray(a), bytearray(b)):
        result |= left ^ right
    return result == 0


_const_compare_digest = getattr(hmac, ""compare_digest"", _const_compare_digest_backport)

try:  
    import ssl
    from ssl import CERT_REQUIRED, wrap_socket
except ImportError:
    pass

try:
    from ssl import HAS_SNI  
except ImportError:
    pass

try:
    from .ssltransport import SSLTransport
except ImportError:
    pass


try:  
    from ssl import PROTOCOL_TLS

    PROTOCOL_SSLv23 = PROTOCOL_TLS
except ImportError:
    try:
        from ssl import PROTOCOL_SSLv23 as PROTOCOL_TLS

        PROTOCOL_SSLv23 = PROTOCOL_TLS
    except ImportError:
        PROTOCOL_SSLv23 = PROTOCOL_TLS = 2

try:
    from ssl import PROTOCOL_TLS_CLIENT
except ImportError:
    PROTOCOL_TLS_CLIENT = PROTOCOL_TLS


try:
    from ssl import OP_NO_COMPRESSION, OP_NO_SSLv2, OP_NO_SSLv3
except ImportError:
    OP_NO_SSLv2, OP_NO_SSLv3 = 0x1000000, 0x2000000
    OP_NO_COMPRESSION = 0x20000


try:  
    from ssl import OP_NO_TICKET
except ImportError:
    OP_NO_TICKET = 0x4000



















DEFAULT_CIPHERS = "":"".join(
    [
        ""ECDHE+AESGCM"",
        ""ECDHE+CHACHA20"",
        ""DHE+AESGCM"",
        ""DHE+CHACHA20"",
        ""ECDH+AESGCM"",
        ""DH+AESGCM"",
        ""ECDH+AES"",
        ""DH+AES"",
        ""RSA+AESGCM"",
        ""RSA+AES"",
        ""!aNULL"",
        ""!eNULL"",
        ""!MD5"",
        ""!DSS"",
    ]
)

try:
    from ssl import SSLContext  
except ImportError:

    class SSLContext(object):  
        def __init__(self, protocol_version):
            self.protocol = protocol_version
            
            self.check_hostname = False
            self.verify_mode = ssl.CERT_NONE
            self.ca_certs = None
            self.options = 0
            self.certfile = None
            self.keyfile = None
            self.ciphers = None

        def load_cert_chain(self, certfile, keyfile):
            self.certfile = certfile
            self.keyfile = keyfile

        def load_verify_locations(self, cafile=None, capath=None, cadata=None):
            self.ca_certs = cafile

            if capath is not None:
                raise SSLError(""CA directories not supported in older Pythons"")

            if cadata is not None:
                raise SSLError(""CA data not supported in older Pythons"")

        def set_ciphers(self, cipher_suite):
            self.ciphers = cipher_suite

        def wrap_socket(self, socket, server_hostname=None, server_side=False):
            warnings.warn(
                ""A true SSLContext object is not available. This prevents ""
                ""urllib3 from configuring SSL appropriately and may cause ""
                ""certain SSL connections to fail. You can upgrade to a newer ""
                ""version of Python to solve this. For more information, see ""
                ""https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html""
                ""
                InsecurePlatformWarning,
            )
            kwargs = {
                ""keyfile"": self.keyfile,
                ""certfile"": self.certfile,
                ""ca_certs"": self.ca_certs,
                ""cert_reqs"": self.verify_mode,
                ""ssl_version"": self.protocol,
                ""server_side"": server_side,
            }
            return wrap_socket(socket, ciphers=self.ciphers, **kwargs)


def assert_fingerprint(cert, fingerprint):
    

    fingerprint = fingerprint.replace("":"", """").lower()
    digest_length = len(fingerprint)
    if digest_length not in HASHFUNC_MAP:
        raise SSLError(""Fingerprint of invalid length: {0}"".format(fingerprint))
    hashfunc = HASHFUNC_MAP.get(digest_length)
    if hashfunc is None:
        raise SSLError(
            ""Hash function implementation unavailable for fingerprint length: {0}"".format(
                digest_length
            )
        )

    
    fingerprint_bytes = unhexlify(fingerprint.encode())

    cert_digest = hashfunc(cert).digest()

    if not _const_compare_digest(cert_digest, fingerprint_bytes):
        raise SSLError(
            'Fingerprints did not match. Expected ""{0}"", got ""{1}"".'.format(
                fingerprint, hexlify(cert_digest)
            )
        )


def resolve_cert_reqs(candidate):
    
    if candidate is None:
        return CERT_REQUIRED

    if isinstance(candidate, str):
        res = getattr(ssl, candidate, None)
        if res is None:
            res = getattr(ssl, ""CERT_"" + candidate)
        return res

    return candidate


def resolve_ssl_version(candidate):
    
    if candidate is None:
        return PROTOCOL_TLS

    if isinstance(candidate, str):
        res = getattr(ssl, candidate, None)
        if res is None:
            res = getattr(ssl, ""PROTOCOL_"" + candidate)
        return res

    return candidate


def create_urllib3_context(
    ssl_version=None, cert_reqs=None, options=None, ciphers=None
):
    
    
    if not ssl_version or ssl_version == PROTOCOL_TLS:
        ssl_version = PROTOCOL_TLS_CLIENT

    context = SSLContext(ssl_version)

    context.set_ciphers(ciphers or DEFAULT_CIPHERS)

    
    cert_reqs = ssl.CERT_REQUIRED if cert_reqs is None else cert_reqs

    if options is None:
        options = 0
        
        options |= OP_NO_SSLv2
        
        options |= OP_NO_SSLv3
        
        
        options |= OP_NO_COMPRESSION
        
        
        
        
        options |= OP_NO_TICKET

    context.options |= options

    
    
    
    
    
    
    if (cert_reqs == ssl.CERT_REQUIRED or sys.version_info >= (3, 7, 4)) and getattr(
        context, ""post_handshake_auth"", None
    ) is not None:
        context.post_handshake_auth = True

    def disable_check_hostname():
        if (
            getattr(context, ""check_hostname"", None) is not None
        ):  
            
            
            context.check_hostname = False

    
    
    
    
    
    if cert_reqs == ssl.CERT_REQUIRED:
        context.verify_mode = cert_reqs
        disable_check_hostname()
    else:
        disable_check_hostname()
        context.verify_mode = cert_reqs

    
    
    if hasattr(context, ""keylog_filename""):
        sslkeylogfile = os.environ.get(""SSLKEYLOGFILE"")
        if sslkeylogfile:
            context.keylog_filename = sslkeylogfile

    return context


def ssl_wrap_socket(
    sock,
    keyfile=None,
    certfile=None,
    cert_reqs=None,
    ca_certs=None,
    server_hostname=None,
    ssl_version=None,
    ciphers=None,
    ssl_context=None,
    ca_cert_dir=None,
    key_password=None,
    ca_cert_data=None,
    tls_in_tls=False,
):
    
    context = ssl_context
    if context is None:
        
        
        
        context = create_urllib3_context(ssl_version, cert_reqs, ciphers=ciphers)

    if ca_certs or ca_cert_dir or ca_cert_data:
        try:
            context.load_verify_locations(ca_certs, ca_cert_dir, ca_cert_data)
        except (IOError, OSError) as e:
            raise SSLError(e)

    elif ssl_context is None and hasattr(context, ""load_default_certs""):
        
        context.load_default_certs()

    
    
    
    if keyfile and key_password is None and _is_key_file_encrypted(keyfile):
        raise SSLError(""Client private key is encrypted, password is required"")

    if certfile:
        if key_password is None:
            context.load_cert_chain(certfile, keyfile)
        else:
            context.load_cert_chain(certfile, keyfile, key_password)

    try:
        if hasattr(context, ""set_alpn_protocols""):
            context.set_alpn_protocols(ALPN_PROTOCOLS)
    except NotImplementedError:  
        pass

    
    
    use_sni_hostname = server_hostname and not is_ipaddress(server_hostname)
    
    send_sni = (use_sni_hostname and HAS_SNI) or (
        IS_SECURETRANSPORT and server_hostname
    )
    
    if not HAS_SNI and use_sni_hostname:
        warnings.warn(
            ""An HTTPS request has been made, but the SNI (Server Name ""
            ""Indication) extension to TLS is not available on this platform. ""
            ""This may cause the server to present an incorrect TLS ""
            ""certificate, which can cause validation failures. You can upgrade to ""
            ""a newer version of Python to solve this. For more information, see ""
            ""https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html""
            ""
            SNIMissingWarning,
        )

    if send_sni:
        ssl_sock = _ssl_wrap_socket_impl(
            sock, context, tls_in_tls, server_hostname=server_hostname
        )
    else:
        ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls)
    return ssl_sock


def is_ipaddress(hostname):
    
    if not six.PY2 and isinstance(hostname, bytes):
        
        hostname = hostname.decode(""ascii"")
    return bool(IPV4_RE.match(hostname) or BRACELESS_IPV6_ADDRZ_RE.match(hostname))


def _is_key_file_encrypted(key_file):
    
    with open(key_file, ""r"") as f:
        for line in f:
            
            if ""ENCRYPTED"" in line:
                return True

    return False


def _ssl_wrap_socket_impl(sock, ssl_context, tls_in_tls, server_hostname=None):
    if tls_in_tls:
        if not SSLTransport:
            
            raise ProxySchemeUnsupported(
                ""TLS in TLS requires support for the 'ssl' module""
            )

        SSLTransport._validate_ssl_context_for_tls_in_tls(ssl_context)
        return SSLTransport(sock, ssl_context, server_hostname)

    if server_hostname:
        return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
    else:
        return ssl_context.wrap_socket(sock)






import re
import sys





try:
    import ipaddress
except ImportError:
    ipaddress = None

__version__ = ""3.5.0.1""


class CertificateError(ValueError):
    pass


def _dnsname_match(dn, hostname, max_wildcards=1):
    
    pats = []
    if not dn:
        return False

    
    
    parts = dn.split(r""."")
    leftmost = parts[0]
    remainder = parts[1:]

    wildcards = leftmost.count(""*"")
    if wildcards > max_wildcards:
        
        
        
        
        raise CertificateError(
            ""too many wildcards in certificate DNS name: "" + repr(dn)
        )

    
    if not wildcards:
        return dn.lower() == hostname.lower()

    
    
    
    if leftmost == ""*"":
        
        
        pats.append(""[^.]+"")
    elif leftmost.startswith(""xn--"") or hostname.startswith(""xn--""):
        
        
        
        
        pats.append(re.escape(leftmost))
    else:
        
        pats.append(re.escape(leftmost).replace(r""\*"", ""[^.]*""))

    
    for frag in remainder:
        pats.append(re.escape(frag))

    pat = re.compile(r""\A"" + r""\."".join(pats) + r""\Z"", re.IGNORECASE)
    return pat.match(hostname)


def _to_unicode(obj):
    if isinstance(obj, str) and sys.version_info < (3,):
        
        obj = unicode(obj, encoding=""ascii"", errors=""strict"")  
    return obj


def _ipaddress_match(ipname, host_ip):
    
    
    
    ip = ipaddress.ip_address(_to_unicode(ipname).rstrip())
    return ip == host_ip


def match_hostname(cert, hostname):
    
    if not cert:
        raise ValueError(
            ""empty or no certificate, match_hostname needs a ""
            ""SSL socket or SSL context with either ""
            ""CERT_OPTIONAL or CERT_REQUIRED""
        )
    try:
        
        host_ip = ipaddress.ip_address(_to_unicode(hostname))
    except (UnicodeError, ValueError):
        
        
        
        
        host_ip = None
    except AttributeError:
        
        if ipaddress is None:
            host_ip = None
        else:  
            raise
    dnsnames = []
    san = cert.get(""subjectAltName"", ())
    for key, value in san:
        if key == ""DNS"":
            if host_ip is None and _dnsname_match(value, hostname):
                return
            dnsnames.append(value)
        elif key == ""IP Address"":
            if host_ip is not None and _ipaddress_match(value, host_ip):
                return
            dnsnames.append(value)
    if not dnsnames:
        
        
        for sub in cert.get(""subject"", ()):
            for key, value in sub:
                
                
                if key == ""commonName"":
                    if _dnsname_match(value, hostname):
                        return
                    dnsnames.append(value)
    if len(dnsnames) > 1:
        raise CertificateError(
            ""hostname %r ""
            ""doesn't match either of %s"" % (hostname, "", "".join(map(repr, dnsnames)))
        )
    elif len(dnsnames) == 1:
        raise CertificateError(""hostname %r doesn't match %r"" % (hostname, dnsnames[0]))
    else:
        raise CertificateError(
            ""no appropriate commonName or subjectAltName fields were found""
        )

from __future__ import absolute_import

import time


from socket import _GLOBAL_DEFAULT_TIMEOUT, getdefaulttimeout

from ..exceptions import TimeoutStateError



_Default = object()



current_time = getattr(time, ""monotonic"", time.time)


class Timeout(object):
    

    
    DEFAULT_TIMEOUT = _GLOBAL_DEFAULT_TIMEOUT

    def __init__(self, total=None, connect=_Default, read=_Default):
        self._connect = self._validate_timeout(connect, ""connect"")
        self._read = self._validate_timeout(read, ""read"")
        self.total = self._validate_timeout(total, ""total"")
        self._start_connect = None

    def __repr__(self):
        return ""%s(connect=%r, read=%r, total=%r)"" % (
            type(self).__name__,
            self._connect,
            self._read,
            self.total,
        )

    
    __str__ = __repr__

    @classmethod
    def resolve_default_timeout(cls, timeout):
        return getdefaulttimeout() if timeout is cls.DEFAULT_TIMEOUT else timeout

    @classmethod
    def _validate_timeout(cls, value, name):
        
        if value is _Default:
            return cls.DEFAULT_TIMEOUT

        if value is None or value is cls.DEFAULT_TIMEOUT:
            return value

        if isinstance(value, bool):
            raise ValueError(
                ""Timeout cannot be a boolean value. It must ""
                ""be an int, float or None.""
            )
        try:
            float(value)
        except (TypeError, ValueError):
            raise ValueError(
                ""Timeout value %s was %s, but it must be an ""
                ""int, float or None."" % (name, value)
            )

        try:
            if value <= 0:
                raise ValueError(
                    ""Attempted to set %s timeout to %s, but the ""
                    ""timeout cannot be set to a value less ""
                    ""than or equal to 0."" % (name, value)
                )
        except TypeError:
            
            raise ValueError(
                ""Timeout value %s was %s, but it must be an ""
                ""int, float or None."" % (name, value)
            )

        return value

    @classmethod
    def from_float(cls, timeout):
        
        return Timeout(read=timeout, connect=timeout)

    def clone(self):
        
        
        
        
        return Timeout(connect=self._connect, read=self._read, total=self.total)

    def start_connect(self):
        
        if self._start_connect is not None:
            raise TimeoutStateError(""Timeout timer has already been started."")
        self._start_connect = current_time()
        return self._start_connect

    def get_connect_duration(self):
        
        if self._start_connect is None:
            raise TimeoutStateError(
                ""Can't get connect duration for timer that has not started.""
            )
        return current_time() - self._start_connect

    @property
    def connect_timeout(self):
        
        if self.total is None:
            return self._connect

        if self._connect is None or self._connect is self.DEFAULT_TIMEOUT:
            return self.total

        return min(self._connect, self.total)

    @property
    def read_timeout(self):
        
        if (
            self.total is not None
            and self.total is not self.DEFAULT_TIMEOUT
            and self._read is not None
            and self._read is not self.DEFAULT_TIMEOUT
        ):
            
            if self._start_connect is None:
                return self._read
            return max(0, min(self.total - self.get_connect_duration(), self._read))
        elif self.total is not None and self.total is not self.DEFAULT_TIMEOUT:
            return max(0, self.total - self.get_connect_duration())
        else:
            return self._read

from __future__ import absolute_import

import re
from collections import namedtuple

from ..exceptions import LocationParseError
from ..packages import six

url_attrs = [""scheme"", ""auth"", ""host"", ""port"", ""path"", ""query"", ""fragment""]



NORMALIZABLE_SCHEMES = (""http"", ""https"", None)



PERCENT_RE = re.compile(r""%[a-fA-F0-9]{2}"")
SCHEME_RE = re.compile(r""^(?:[a-zA-Z][a-zA-Z0-9+-]*:|/)"")
URI_RE = re.compile(
    r""^(?:([a-zA-Z][a-zA-Z0-9+.-]*):)?""
    r""(?://([^\\/?
    r""([^?
    r""(?:\?([^
    r""(?:
    re.UNICODE | re.DOTALL,
)

IPV4_PAT = r""(?:[0-9]{1,3}\.){3}[0-9]{1,3}""
HEX_PAT = ""[0-9A-Fa-f]{1,4}""
LS32_PAT = ""(?:{hex}:{hex}|{ipv4})"".format(hex=HEX_PAT, ipv4=IPV4_PAT)
_subs = {""hex"": HEX_PAT, ""ls32"": LS32_PAT}
_variations = [
    
    ""(?:%(hex)s:){6}%(ls32)s"",
    
    ""::(?:%(hex)s:){5}%(ls32)s"",
    
    ""(?:%(hex)s)?::(?:%(hex)s:){4}%(ls32)s"",
    
    ""(?:(?:%(hex)s:)?%(hex)s)?::(?:%(hex)s:){3}%(ls32)s"",
    
    ""(?:(?:%(hex)s:){0,2}%(hex)s)?::(?:%(hex)s:){2}%(ls32)s"",
    
    ""(?:(?:%(hex)s:){0,3}%(hex)s)?::%(hex)s:%(ls32)s"",
    
    ""(?:(?:%(hex)s:){0,4}%(hex)s)?::%(ls32)s"",
    
    ""(?:(?:%(hex)s:){0,5}%(hex)s)?::%(hex)s"",
    
    ""(?:(?:%(hex)s:){0,6}%(hex)s)?::"",
]

UNRESERVED_PAT = r""ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789._\-~""
IPV6_PAT = ""(?:"" + ""|"".join([x % _subs for x in _variations]) + "")""
ZONE_ID_PAT = ""(?:%25|%)(?:["" + UNRESERVED_PAT + ""]|%[a-fA-F0-9]{2})+""
IPV6_ADDRZ_PAT = r""\["" + IPV6_PAT + r""(?:"" + ZONE_ID_PAT + r"")?\]""
REG_NAME_PAT = r""(?:[^\[\]%:/?
TARGET_RE = re.compile(r""^(/[^?

IPV4_RE = re.compile(""^"" + IPV4_PAT + ""$"")
IPV6_RE = re.compile(""^"" + IPV6_PAT + ""$"")
IPV6_ADDRZ_RE = re.compile(""^"" + IPV6_ADDRZ_PAT + ""$"")
BRACELESS_IPV6_ADDRZ_RE = re.compile(""^"" + IPV6_ADDRZ_PAT[2:-2] + ""$"")
ZONE_ID_RE = re.compile(""("" + ZONE_ID_PAT + r"")\]$"")

_HOST_PORT_PAT = (""^(%s|%s|%s)(?::0*?(|0|[1-9][0-9]{0,4}))?$"") % (
    REG_NAME_PAT,
    IPV4_PAT,
    IPV6_ADDRZ_PAT,
)
_HOST_PORT_RE = re.compile(_HOST_PORT_PAT, re.UNICODE | re.DOTALL)

UNRESERVED_CHARS = set(
    ""ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789._-~""
)
SUB_DELIM_CHARS = set(""!$&'()*+,;="")
USERINFO_CHARS = UNRESERVED_CHARS | SUB_DELIM_CHARS | {"":""}
PATH_CHARS = USERINFO_CHARS | {""@"", ""/""}
QUERY_CHARS = FRAGMENT_CHARS = PATH_CHARS | {""?""}


class Url(namedtuple(""Url"", url_attrs)):
    

    __slots__ = ()

    def __new__(
        cls,
        scheme=None,
        auth=None,
        host=None,
        port=None,
        path=None,
        query=None,
        fragment=None,
    ):
        if path and not path.startswith(""/""):
            path = ""/"" + path
        if scheme is not None:
            scheme = scheme.lower()
        return super(Url, cls).__new__(
            cls, scheme, auth, host, port, path, query, fragment
        )

    @property
    def hostname(self):
        
        return self.host

    @property
    def request_uri(self):
        
        uri = self.path or ""/""

        if self.query is not None:
            uri += ""?"" + self.query

        return uri

    @property
    def netloc(self):
        
        if self.port:
            return ""%s:%d"" % (self.host, self.port)
        return self.host

    @property
    def url(self):
        
        scheme, auth, host, port, path, query, fragment = self
        url = u""""

        
        if scheme is not None:
            url += scheme + u""://""
        if auth is not None:
            url += auth + u""@""
        if host is not None:
            url += host
        if port is not None:
            url += u"":"" + str(port)
        if path is not None:
            url += path
        if query is not None:
            url += u""?"" + query
        if fragment is not None:
            url += u""

        return url

    def __str__(self):
        return self.url


def split_first(s, delims):
    
    min_idx = None
    min_delim = None
    for d in delims:
        idx = s.find(d)
        if idx < 0:
            continue

        if min_idx is None or idx < min_idx:
            min_idx = idx
            min_delim = d

    if min_idx is None or min_idx < 0:
        return s, """", None

    return s[:min_idx], s[min_idx + 1 :], min_delim


def _encode_invalid_chars(component, allowed_chars, encoding=""utf-8""):
    
    if component is None:
        return component

    component = six.ensure_text(component)

    
    
    
    component, percent_encodings = PERCENT_RE.subn(
        lambda match: match.group(0).upper(), component
    )

    uri_bytes = component.encode(""utf-8"", ""surrogatepass"")
    is_percent_encoded = percent_encodings == uri_bytes.count(b""%"")
    encoded_component = bytearray()

    for i in range(0, len(uri_bytes)):
        
        byte = uri_bytes[i : i + 1]
        byte_ord = ord(byte)
        if (is_percent_encoded and byte == b""%"") or (
            byte_ord < 128 and byte.decode() in allowed_chars
        ):
            encoded_component += byte
            continue
        encoded_component.extend(b""%"" + (hex(byte_ord)[2:].encode().zfill(2).upper()))

    return encoded_component.decode(encoding)


def _remove_path_dot_segments(path):
    
    segments = path.split(""/"")  
    output = []  

    for segment in segments:
        
        if segment == ""."":
            continue
        
        elif segment != "".."":
            output.append(segment)
        
        
        elif output:
            output.pop()

    
    
    if path.startswith(""/"") and (not output or output[0]):
        output.insert(0, """")

    
    
    if path.endswith((""/."", ""/.."")):
        output.append("""")

    return ""/"".join(output)


def _normalize_host(host, scheme):
    if host:
        if isinstance(host, six.binary_type):
            host = six.ensure_str(host)

        if scheme in NORMALIZABLE_SCHEMES:
            is_ipv6 = IPV6_ADDRZ_RE.match(host)
            if is_ipv6:
                
                
                
                match = ZONE_ID_RE.search(host)
                if match:
                    start, end = match.span(1)
                    zone_id = host[start:end]

                    if zone_id.startswith(""%25"") and zone_id != ""%25"":
                        zone_id = zone_id[3:]
                    else:
                        zone_id = zone_id[1:]
                    zone_id = ""%"" + _encode_invalid_chars(zone_id, UNRESERVED_CHARS)
                    return host[:start].lower() + zone_id + host[end:]
                else:
                    return host.lower()
            elif not IPV4_RE.match(host):
                return six.ensure_str(
                    b""."".join([_idna_encode(label) for label in host.split(""."")])
                )
    return host


def _idna_encode(name):
    if name and any(ord(x) >= 128 for x in name):
        try:
            from pip._vendor import idna
        except ImportError:
            six.raise_from(
                LocationParseError(""Unable to parse URL without the 'idna' module""),
                None,
            )
        try:
            return idna.encode(name.lower(), strict=True, std3_rules=True)
        except idna.IDNAError:
            six.raise_from(
                LocationParseError(u""Name '%s' is not a valid IDNA label"" % name), None
            )
    return name.lower().encode(""ascii"")


def _encode_target(target):
    
    path, query = TARGET_RE.match(target).groups()
    target = _encode_invalid_chars(path, PATH_CHARS)
    query = _encode_invalid_chars(query, QUERY_CHARS)
    if query is not None:
        target += ""?"" + query
    return target


def parse_url(url):
    
    if not url:
        
        return Url()

    source_url = url
    if not SCHEME_RE.search(url):
        url = ""//"" + url

    try:
        scheme, authority, path, query, fragment = URI_RE.match(url).groups()
        normalize_uri = scheme is None or scheme.lower() in NORMALIZABLE_SCHEMES

        if scheme:
            scheme = scheme.lower()

        if authority:
            auth, _, host_port = authority.rpartition(""@"")
            auth = auth or None
            host, port = _HOST_PORT_RE.match(host_port).groups()
            if auth and normalize_uri:
                auth = _encode_invalid_chars(auth, USERINFO_CHARS)
            if port == """":
                port = None
        else:
            auth, host, port = None, None, None

        if port is not None:
            port = int(port)
            if not (0 <= port <= 65535):
                raise LocationParseError(url)

        host = _normalize_host(host, scheme)

        if normalize_uri and path:
            path = _remove_path_dot_segments(path)
            path = _encode_invalid_chars(path, PATH_CHARS)
        if normalize_uri and query:
            query = _encode_invalid_chars(query, QUERY_CHARS)
        if normalize_uri and fragment:
            fragment = _encode_invalid_chars(fragment, FRAGMENT_CHARS)

    except (ValueError, AttributeError):
        return six.raise_from(LocationParseError(source_url), None)

    
    
    
    
    if not path:
        if query is not None or fragment is not None:
            path = """"
        else:
            path = None

    
    
    if isinstance(url, six.text_type):
        ensure_func = six.ensure_text
    else:
        ensure_func = six.ensure_str

    def ensure_type(x):
        return x if x is None else ensure_func(x)

    return Url(
        scheme=ensure_type(scheme),
        auth=ensure_type(auth),
        host=ensure_type(host),
        port=port,
        path=ensure_type(path),
        query=ensure_type(query),
        fragment=ensure_type(fragment),
    )


def get_host(url):
    
    p = parse_url(url)
    return p.scheme or ""http"", p.hostname, p.port

import errno
import select
import sys
from functools import partial

try:
    from time import monotonic
except ImportError:
    from time import time as monotonic

__all__ = [""NoWayToWaitForSocketError"", ""wait_for_read"", ""wait_for_write""]


class NoWayToWaitForSocketError(Exception):
    pass
























if sys.version_info >= (3, 5):
    
    def _retry_on_intr(fn, timeout):
        return fn(timeout)

else:
    
    def _retry_on_intr(fn, timeout):
        if timeout is None:
            deadline = float(""inf"")
        else:
            deadline = monotonic() + timeout

        while True:
            try:
                return fn(timeout)
            
            except (OSError, select.error) as e:
                
                if e.args[0] != errno.EINTR:
                    raise
                else:
                    timeout = deadline - monotonic()
                    if timeout < 0:
                        timeout = 0
                    if timeout == float(""inf""):
                        timeout = None
                    continue


def select_wait_for_socket(sock, read=False, write=False, timeout=None):
    if not read and not write:
        raise RuntimeError(""must specify at least one of read=True, write=True"")
    rcheck = []
    wcheck = []
    if read:
        rcheck.append(sock)
    if write:
        wcheck.append(sock)
    
    
    
    
    
    fn = partial(select.select, rcheck, wcheck, wcheck)
    rready, wready, xready = _retry_on_intr(fn, timeout)
    return bool(rready or wready or xready)


def poll_wait_for_socket(sock, read=False, write=False, timeout=None):
    if not read and not write:
        raise RuntimeError(""must specify at least one of read=True, write=True"")
    mask = 0
    if read:
        mask |= select.POLLIN
    if write:
        mask |= select.POLLOUT
    poll_obj = select.poll()
    poll_obj.register(sock, mask)

    
    def do_poll(t):
        if t is not None:
            t *= 1000
        return poll_obj.poll(t)

    return bool(_retry_on_intr(do_poll, timeout))


def null_wait_for_socket(*args, **kwargs):
    raise NoWayToWaitForSocketError(""no select-equivalent available"")


def _have_working_poll():
    
    
    
    try:
        poll_obj = select.poll()
        _retry_on_intr(poll_obj.poll, 0)
    except (AttributeError, OSError):
        return False
    else:
        return True


def wait_for_socket(*args, **kwargs):
    
    
    
    
    global wait_for_socket
    if _have_working_poll():
        wait_for_socket = poll_wait_for_socket
    elif hasattr(select, ""select""):
        wait_for_socket = select_wait_for_socket
    else:  
        wait_for_socket = null_wait_for_socket
    return wait_for_socket(*args, **kwargs)


def wait_for_read(sock, timeout=None):
    
    return wait_for_socket(sock, read=True, timeout=timeout)


def wait_for_write(sock, timeout=None):
    
    return wait_for_socket(sock, write=True, timeout=timeout)

from __future__ import absolute_import


from .connection import is_connection_dropped
from .request import SKIP_HEADER, SKIPPABLE_HEADERS, make_headers
from .response import is_fp_closed
from .retry import Retry
from .ssl_ import (
    ALPN_PROTOCOLS,
    HAS_SNI,
    IS_PYOPENSSL,
    IS_SECURETRANSPORT,
    PROTOCOL_TLS,
    SSLContext,
    assert_fingerprint,
    resolve_cert_reqs,
    resolve_ssl_version,
    ssl_wrap_socket,
)
from .timeout import Timeout, current_time
from .url import Url, get_host, parse_url, split_first
from .wait import wait_for_read, wait_for_write

__all__ = (
    ""HAS_SNI"",
    ""IS_PYOPENSSL"",
    ""IS_SECURETRANSPORT"",
    ""SSLContext"",
    ""PROTOCOL_TLS"",
    ""ALPN_PROTOCOLS"",
    ""Retry"",
    ""Timeout"",
    ""Url"",
    ""assert_fingerprint"",
    ""current_time"",
    ""is_connection_dropped"",
    ""is_fp_closed"",
    ""get_host"",
    ""parse_url"",
    ""make_headers"",
    ""resolve_cert_reqs"",
    ""resolve_ssl_version"",
    ""split_first"",
    ""ssl_wrap_socket"",
    ""wait_for_read"",
    ""wait_for_write"",
    ""SKIP_HEADER"",
    ""SKIPPABLE_HEADERS"",
)"
uv,"from __future__ import annotations

import os
import sys
import sysconfig


class UvNotFound(FileNotFoundError): ...


def find_uv_bin() -> str:
    

    uv_exe = ""uv"" + sysconfig.get_config_var(""EXE"")

    targets = [
        
        sysconfig.get_path(""scripts""),
        
        sysconfig.get_path(""scripts"", vars={""base"": sys.base_prefix}),
        
        (
            
            _join(_matching_parents(_module_path(), ""Lib/site-packages/uv""), ""Scripts"")
            if sys.platform == ""win32""
            
            else _join(
                _matching_parents(_module_path(), ""lib/python*/site-packages/uv""), ""bin""
            )
        ),
        
        
        _join(_matching_parents(_module_path(), ""uv""), ""bin""),
        
        sysconfig.get_path(""scripts"", scheme=_user_scheme()),
    ]

    seen = []
    for target in targets:
        if not target:
            continue
        if target in seen:
            continue
        seen.append(target)
        path = os.path.join(target, uv_exe)
        if os.path.isfile(path):
            return path

    locations = ""\n"".join(f"" - {target}"" for target in seen)
    raise UvNotFound(
        f""Could not find the uv binary in any of the following locations:\n{locations}\n""
    )


def _module_path() -> str | None:
    path = os.path.dirname(__file__)
    return path


def _matching_parents(path: str | None, match: str) -> str | None:
    
    from fnmatch import fnmatch

    if not path:
        return None
    parts = path.split(os.sep)
    match_parts = match.split(""/"")
    if len(parts) < len(match_parts):
        return None

    if not all(
        fnmatch(part, match_part)
        for part, match_part in zip(reversed(parts), reversed(match_parts))
    ):
        return None

    return os.sep.join(parts[: -len(match_parts)])


def _join(path: str | None, *parts: str) -> str | None:
    if not path:
        return None
    return os.path.join(path, *parts)


def _user_scheme() -> str:
    if sys.version_info >= (3, 10):
        user_scheme = sysconfig.get_preferred_scheme(""user"")
    elif os.name == ""nt"":
        user_scheme = ""nt_user""
    elif sys.platform == ""darwin"" and sys._framework:
        user_scheme = ""osx_framework_user""
    else:
        user_scheme = ""posix_user""
    return user_scheme

from __future__ import annotations

from ._find_uv import find_uv_bin

__all__ = [""find_uv_bin""]


def __getattr__(attr_name: str) -> object:
    if attr_name in {
        ""build_sdist"",
        ""build_wheel"",
        ""build_editable"",
        ""get_requires_for_build_sdist"",
        ""get_requires_for_build_wheel"",
        ""prepare_metadata_for_build_wheel"",
        ""get_requires_for_build_editable"",
        ""prepare_metadata_for_build_editable"",
    }:
        err = (
            f""Using `uv.{attr_name}` is not allowed; build backend functionality is in the `uv_build` package. ""
            f""Did you mean to use `uv_build` as your build system?""
        )
        raise AttributeError(err)
    raise AttributeError(f""module `{__name__}` has no attribute `{attr_name}`"")

import os
import sys

from uv import find_uv_bin


def _detect_virtualenv() -> str:
    

    
    value = os.getenv(""VIRTUAL_ENV"")
    if value:
        return value

    
    venv_marker = os.path.join(sys.prefix, ""pyvenv.cfg"")

    if os.path.exists(venv_marker):
        return sys.prefix

    return """"


def _run() -> None:
    uv = os.fsdecode(find_uv_bin())

    env = os.environ.copy()
    venv = _detect_virtualenv()
    if venv:
        env.setdefault(""VIRTUAL_ENV"", venv)

    
    env[""UV_INTERNAL__PARENT_INTERPRETER""] = sys.executable

    if sys.platform == ""win32"":
        import subprocess

        
        try:
            completed_process = subprocess.run([uv, *sys.argv[1:]], env=env)
        except KeyboardInterrupt:
            sys.exit(2)

        sys.exit(completed_process.returncode)
    else:
        os.execvpe(uv, [uv, *sys.argv[1:]], env=env)


if __name__ == ""__main__"":
    _run()"
