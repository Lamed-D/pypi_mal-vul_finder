"""
í†µí•© LSTM ë¶„ì„ê¸° - AI ê¸°ë°˜ Python ì½”ë“œ ë³´ì•ˆ ë¶„ì„
=================================================

ì´ ëª¨ë“ˆì€ LSTM ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ Python ì½”ë“œì˜ ì·¨ì•½ì ê³¼ ì•…ì„±ì½”ë“œë¥¼ íƒì§€í•˜ëŠ” ë¶„ì„ ì—”ì§„ì…ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- ì·¨ì•½ì  íŒ¨í„´ íƒì§€ (LSTM ëª¨ë¸)
- ì•…ì„±ì½”ë“œ íŒ¨í„´ íƒì§€ (LSTM ëª¨ë¸)
- ë‹¤ì¤‘ í”„ë¡œì„¸ìŠ¤ ë³‘ë ¬ ë¶„ì„
- Word2Vec ê¸°ë°˜ ì½”ë“œ í† í° ì„ë² ë”©

ë¶„ì„ í”„ë¡œì„¸ìŠ¤:
1. Python ì½”ë“œ í† í°í™” ë° ì „ì²˜ë¦¬
2. Word2Vec ëª¨ë¸ë¡œ í† í° ì„ë² ë”©
3. LSTM ëª¨ë¸ë¡œ ì·¨ì•½ì /ì•…ì„±ì½”ë“œ ë¶„ë¥˜
4. ê²°ê³¼ í›„ì²˜ë¦¬ ë° í™•ë¥  ê³„ì‚°

ì„±ëŠ¥ ìµœì í™”:
- 3ê°œ ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ë¡œ ë³‘ë ¬ ì²˜ë¦¬
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë°°ì¹˜ ì²˜ë¦¬
- ëª¨ë¸ ìºì‹± ë° ì¬ì‚¬ìš©
"""
import asyncio
import pickle
import os
import numpy as np
import pandas as pd
import time
from concurrent.futures import ProcessPoolExecutor, as_completed
from typing import Dict, Any, List, Tuple
from pathlib import Path
import re
from gensim.models import Word2Vec

# í”„ë¡œì„¸ìŠ¤ í’€ í¬ê¸° ì œí•œ
MAX_WORKERS = 3

class IntegratedLSTMAnalyzer:
    """í†µí•© LSTM ë¶„ì„ê¸° - ì·¨ì•½ì  + ì•…ì„± ì½”ë“œ ë¶„ì„"""
    
    def __init__(self, models_dir: str = None):
        self.models_dir = Path(models_dir) if models_dir else Path(__file__).parents[1] / "models"
        self.lstm_dir = self.models_dir / "lstm"
        self.w2v_dir = self.models_dir / "w2v"
        
        # ê³µí†µ ëª¨ë¸ë“¤
        self.w2v_model = None
        self.max_sequence_length = 100
        
        # ì·¨ì•½ì  ë¶„ì„ ëª¨ë¸ë“¤ (safepy_3)
        self.vul_model_final = None  # ì´ì§„ ë¶„ë¥˜ ëª¨ë¸
        self.vul_model_full = None   # ë‹¤ì¤‘ ë¶„ë¥˜ ëª¨ë¸
        self.vul_label_encoder_final = None
        self.vul_label_encoder_full = None
        
        # ì•…ì„± ì½”ë“œ ë¶„ì„ ëª¨ë¸ë“¤ (safepy_3_malicious)
        self.mal_model = None
        self.mal_label_encoder = None
        
        # í”„ë¡œì„¸ìŠ¤ í’€
        self.executor = None
        self.active_tasks = {}
        
        # ëª¨ë¸ ë¡œë“œ
        self._load_models()
    
    def _load_models(self):
        """ëª¨ë“  ëª¨ë¸ ë¡œë“œ"""
        try:
            # Word2Vec ëª¨ë¸ ë¡œë“œ (ê³µí†µ)
            w2v_path = self.w2v_dir / "word2vec_withString10-6-100.model"
            if w2v_path.exists():
                self.w2v_model = Word2Vec.load(str(w2v_path))
                print("âœ… Word2Vec model loaded successfully")
            else:
                print(f"âŒ Word2Vec model not found: {w2v_path}")
            
            # ì·¨ì•½ì  ë¶„ì„ ëª¨ë¸ ë¡œë“œ (í‰ë©´ êµ¬ì¡°)
            vul_model_path = self.lstm_dir / "model_vul.pkl"
            vul_label_path = self.lstm_dir / "label_encoder_vul.pkl"
            
            if vul_model_path.exists() and vul_label_path.exists():
                with open(vul_model_path, 'rb') as f:
                    self.vul_model_final = pickle.load(f)
                with open(vul_label_path, 'rb') as f:
                    self.vul_label_encoder_final = pickle.load(f)
                print("âœ… Vulnerability model loaded successfully")
            else:
                print(f"âŒ Vulnerability model not found: {vul_model_path}, {vul_label_path}")
            
            # CWE ë¶„ì„ ëª¨ë¸ ë¡œë“œ (ë‹¤ì¤‘ ë¶„ë¥˜ìš©)
            cwe_model_path = self.lstm_dir / "model_cwe.pkl"
            cwe_label_path = self.lstm_dir / "label_encoder_cwe.pkl"
            
            if cwe_model_path.exists() and cwe_label_path.exists():
                with open(cwe_model_path, 'rb') as f:
                    self.vul_model_full = pickle.load(f)
                with open(cwe_label_path, 'rb') as f:
                    self.vul_label_encoder_full = pickle.load(f)
                print("âœ… CWE model loaded successfully")
            else:
                print(f"âŒ CWE model not found: {cwe_model_path}, {cwe_label_path}")
            
            # ì•…ì„± ì½”ë“œ ë¶„ì„ ëª¨ë¸ ë¡œë“œ (í‰ë©´ êµ¬ì¡°)
            mal_model_path = self.lstm_dir / "model_mal.pkl"
            mal_label_path = self.lstm_dir / "label_encoder_mal.pkl"
            
            if mal_model_path.exists() and mal_label_path.exists():
                with open(mal_model_path, 'rb') as f:
                    self.mal_model = pickle.load(f)
                with open(mal_label_path, 'rb') as f:
                    self.mal_label_encoder = pickle.load(f)
                print("âœ… Malicious models loaded successfully")
            else:
                print(f"âŒ Malicious models not found: {mal_model_path}, {mal_label_path}")
                
        except Exception as e:
            print(f"âŒ Error loading models: {e}")
    
    def tokenize_python(self, code: str) -> List[str]:
        """Python ì½”ë“œ í† í°í™” (ê³µí†µ í•¨ìˆ˜)"""
        # ê°„ë‹¨í•œ í† í°í™” - ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ì „ì²˜ë¦¬ í•„ìš”
        tokens = re.findall(r'\b\w+\b', code)
        return tokens
    
    def embed_sequences(self, sequences: List[List[str]]) -> List[np.ndarray]:
        """ì‹œí€€ìŠ¤ ì„ë² ë”© (ê³µí†µ í•¨ìˆ˜)"""
        if not self.w2v_model:
            return []
        
        embedded_sequences = []
        for sequence in sequences:
            embedded_sequence = []
            for token in sequence:
                if token in self.w2v_model.wv:
                    embedded_sequence.append(self.w2v_model.wv[token])
            if embedded_sequence:
                embedded_sequences.append(np.array(embedded_sequence))
        return embedded_sequences
    
    def pad_sequence(self, embedded_sequence: np.ndarray) -> np.ndarray:
        """ì‹œí€€ìŠ¤ íŒ¨ë”© (ê³µí†µ í•¨ìˆ˜)"""
        embedding_dim = self.w2v_model.vector_size
        padded_code = np.zeros((self.max_sequence_length, embedding_dim))
        
        if embedded_sequence.shape[0] > 0:
            padding_length = self.max_sequence_length - embedded_sequence.shape[0]
            if padding_length > 0:
                padding = np.zeros((padding_length, embedding_dim))
                padded_code = np.concatenate((embedded_sequence, padding), axis=0)
            else:
                padded_code = embedded_sequence[:self.max_sequence_length]
        
        return padded_code
    
    def analyze_vulnerability(self, content: str, file_path: str) -> Dict[str, Any]:
        """ì·¨ì•½ì  ë¶„ì„ (safepy_3) - ì´ì§„ ë¶„ë¥˜ + ë‹¤ì¤‘ ë¶„ë¥˜"""
        try:
            if not all([self.vul_model_final, self.vul_label_encoder_final, self.w2v_model]):
                return {"is_vulnerable": False, "error": "Models not loaded"}
            
            # ì „ì²˜ë¦¬ (ê³µí†µ)
            tokenized_code = self.tokenize_python(content)
            embedded_code = self.embed_sequences([tokenized_code])
            
            if not embedded_code or len(embedded_code) == 0 or embedded_code[0].size == 0:
                return {"is_vulnerable": False, "error": "Could not embed code"}
            
            # íŒ¨ë”© (ê³µí†µ)
            padded_code = self.pad_sequence(embedded_code[0])
            padded_code = np.expand_dims(padded_code, axis=0)
            
            # 1) ì´ì§„ ë¶„ë¥˜ (ì·¨ì•½/ì •ìƒ)
            prediction_final = self.vul_model_final.predict(padded_code)
            predicted_label = (prediction_final > 0.5).astype(int)[0][0]
            predicted_vulnerability_status = self.vul_label_encoder_final.inverse_transform([predicted_label])[0]
            
            # 2) ì·¨ì•½ ì‹œ ë‹¤ì¤‘ë¶„ë¥˜ë¡œ CWE ë¼ë²¨ ì¶”ì •
            if predicted_vulnerability_status == 1 and self.vul_model_full and self.vul_label_encoder_full:
                prediction_full = self.vul_model_full.predict(padded_code)
                predicted_cwe_index = np.argmax(prediction_full, axis=1)[0]
                predicted_cwe = self.vul_label_encoder_full.inverse_transform([predicted_cwe_index])[0]
                cwe_label = predicted_cwe
            else:
                cwe_label = 'Safe'
            
            is_vulnerable = predicted_vulnerability_status == 1
            
            result = {
                "is_vulnerable": is_vulnerable,
                "vulnerability_probability": float(prediction_final[0][0]),
                "vulnerability_status": "Vulnerable" if is_vulnerable else "Safe",
                "vulnerability_label": "Vulnerable" if predicted_vulnerability_status == 1 else "Safe",
                "cwe_label": cwe_label
            }
            
            return result
            
        except Exception as e:
            return {"is_vulnerable": False, "error": str(e)}
    
    def analyze_malicious(self, content: str, file_path: str) -> Dict[str, Any]:
        """ì•…ì„± ì½”ë“œ ë¶„ì„ (safepy_3_malicious)"""
        try:
            if not all([self.mal_model, self.mal_label_encoder, self.w2v_model]):
                return {"is_malicious": False, "error": "Models not loaded"}
            
            # ì „ì²˜ë¦¬ (ê³µí†µ)
            tokenized_code = self.tokenize_python(content)
            embedded_code = self.embed_sequences([tokenized_code])
            
            if not embedded_code or len(embedded_code) == 0 or embedded_code[0].size == 0:
                return {"is_malicious": False, "error": "Could not embed code"}
            
            # íŒ¨ë”© (ê³µí†µ)
            padded_code = self.pad_sequence(embedded_code[0])
            padded_code = np.expand_dims(padded_code, axis=0)
            
            # ì•…ì„± ì½”ë“œ ì˜ˆì¸¡
            prediction = self.mal_model.predict(padded_code)
            
            if prediction.ndim == 2 and prediction.shape[1] == 1:
                # Binary sigmoid
                malicious_probability = float(prediction[0][0])
                predicted_index = int((prediction > 0.5).astype(int)[0][0])
            else:
                # Multiclass softmax
                predicted_index = int(np.argmax(prediction, axis=1)[0])
                malicious_probability = float(prediction[0][predicted_index])
            
            decoded_label = self.mal_label_encoder.inverse_transform([predicted_index])[0]
            
            # ì•…ì„± ì—¬ë¶€ íŒë‹¨
            safe_aliases = {"Benign", "benign", "Not Vulnerable", "Normal", "Safe", "0", 0}
            is_safe = decoded_label in safe_aliases
            
            result = {
                "is_malicious": not is_safe,
                "malicious_probability": malicious_probability,
                "malicious_status": "malicious" if not is_safe else "Safe",
                "malicious_label": decoded_label
            }
            
            return result
            
        except Exception as e:
            return {"is_malicious": False, "error": str(e)}
    
    def analyze_single_file(self, content: str, file_path: str, mode: str = "both") -> Dict[str, Any]:
        """ë‹¨ì¼ íŒŒì¼ ë¶„ì„ - modeì— ë”°ë¼ ì·¨ì•½/ì•…ì„±/ë‘˜ë‹¤ ìˆ˜í–‰

        Args:
            content: íŒŒì¼ ë‚´ìš©
            file_path: íŒŒì¼ ê²½ë¡œ
            mode: 'both' | 'mal' | 'vul'
        """
        start_time = time.time()
        
        # ì·¨ì•½ì  ë¶„ì„ (safepy_3)
        vul_result = self.analyze_vulnerability(content, file_path) if mode in ("both", "vul") else {"is_vulnerable": False}
        
        # ì•…ì„± ì½”ë“œ ë¶„ì„ (safepy_3_malicious)
        mal_result = self.analyze_malicious(content, file_path) if mode in ("both", "mal") else {"is_malicious": False}
        
        analysis_time = time.time() - start_time
        
        return {
            "file_path": file_path,
            "analysis_time": analysis_time,
            "vulnerability_analysis": vul_result,
            "malicious_analysis": mal_result,
            "is_safe": not (vul_result.get("is_vulnerable", False) or mal_result.get("is_malicious", False))
        }
    
    async def analyze_files_multiprocess(self, session_id: str, files: List[Dict[str, Any]], mode: str = "both") -> Dict[str, Any]:
        """ë‹¤ì¤‘ í”„ë¡œì„¸ìŠ¤ë¡œ íŒŒì¼ë“¤ ë¶„ì„ (3ê°œ í”„ë¡œì„¸ìŠ¤ ì œí•œ)"""
        return await asyncio.to_thread(self._analyze_files_multiprocess_sync, session_id, files, mode)

    def _analyze_files_multiprocess_sync(self, session_id: str, files: List[Dict[str, Any]], mode: str = "both") -> Dict[str, Any]:
        """ì‹¤ì œ ë‹¤ì¤‘ í”„ë¡œì„¸ìŠ¤ ë¶„ì„ì„ ë™ê¸°ì ìœ¼ë¡œ ìˆ˜í–‰í•œë‹¤."""
        try:
            # í”„ë¡œì„¸ìŠ¤ í’€ ì´ˆê¸°í™”
            if self.executor is None:
                self.executor = ProcessPoolExecutor(max_workers=MAX_WORKERS)

            # íŒŒì¼ë“¤ì„ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ë³‘ë ¬ ì²˜ë¦¬
            chunk_size = max(1, len(files) // MAX_WORKERS)
            file_chunks = [files[i:i + chunk_size] for i in range(0, len(files), chunk_size)]

            print(f"ğŸš€ Starting multiprocess analysis for session {session_id}")
            print(f"ğŸ“Š Processing {len(files)} files in {len(file_chunks)} chunks with {MAX_WORKERS} workers")

            # ë³‘ë ¬ ë¶„ì„ ì‹¤í–‰
            futures = []
            for i, chunk in enumerate(file_chunks):
                future = self.executor.submit(analyze_file_chunk_worker, chunk, session_id, i, str(self.models_dir), mode)
                futures.append(future)
                self.active_tasks[session_id] = self.active_tasks.get(session_id, []) + [future]

            # ê²°ê³¼ ìˆ˜ì§‘
            all_results: List[Dict[str, Any]] = []
            for future in as_completed(futures):
                try:
                    chunk_results = future.result()
                    all_results.extend(chunk_results)
                except Exception as e:
                    print(f"âŒ Chunk analysis failed: {e}")
                    continue

            # í™œì„± ì‘ì—…ì—ì„œ ì œê±°
            if session_id in self.active_tasks:
                del self.active_tasks[session_id]

            print(f"âœ… Analysis completed for session {session_id}: {len(all_results)} files processed")
            return {
                "session_id": session_id,
                "total_files": len(files),
                "processed_files": len(all_results),
                "results": all_results,
                "status": "completed"
            }

        except Exception as e:
            print(f"âŒ Multiprocess analysis failed for session {session_id}: {e}")
            return {
                "session_id": session_id,
                "total_files": len(files),
                "processed_files": 0,
                "results": [],
                "status": "failed",
                "error": str(e)
            }
    
    def get_active_tasks_count(self) -> int:
        """í˜„ì¬ í™œì„± ì‘ì—… ìˆ˜ ë°˜í™˜"""
        return sum(len(tasks) for tasks in self.active_tasks.values())
    
    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (ì„œë²„ ì¢…ë£Œ ì‹œì—ë§Œ í˜¸ì¶œ)"""
        if self.executor:
            self.executor.shutdown(wait=True)
            self.executor = None
    
    def shutdown_executor(self):
        """í”„ë¡œì„¸ìŠ¤ í’€ ì¢…ë£Œ (ì„œë²„ ì¢…ë£Œ ì‹œì—ë§Œ í˜¸ì¶œ)"""
        if self.executor:
            self.executor.shutdown(wait=True)
            self.executor = None

def analyze_file_chunk_worker(files: List[Dict[str, Any]], session_id: str, chunk_id: int, models_dir: str, mode: str = "both") -> List[Dict[str, Any]]:
    """íŒŒì¼ ì²­í¬ ë¶„ì„ ì›Œì»¤ (ë³„ë„ í”„ë¡œì„¸ìŠ¤ì—ì„œ ì‹¤í–‰)

    mode: 'both' | 'mal' | 'vul'
    """
    results = []
    
    try:
        # ê° í”„ë¡œì„¸ìŠ¤ì—ì„œ ë¶„ì„ê¸° ìƒì„±
        analyzer = IntegratedLSTMAnalyzer(models_dir)
        
        print(f"ğŸ” Worker {chunk_id} processing {len(files)} files")
        
        for file_info in files:
            try:
                # íŒŒì¼ ë‚´ìš©ì´ ìˆëŠ”ì§€ í™•ì¸
                if not file_info.get("content"):
                    print(f"âš ï¸ Empty content for file {file_info['path']}")
                    continue
                
                result = analyzer.analyze_single_file(file_info["content"], file_info["path"], mode=mode)
                result["session_id"] = session_id
                result["file_name"] = file_info["name"]
                result["file_size"] = file_info["size"]
                results.append(result)
                
            except Exception as e:
                print(f"âŒ Error analyzing file {file_info['path']}: {e}")
                # ì˜¤ë¥˜ ì‹œì—ë„ ê¸°ë³¸ ê²°ê³¼ ìƒì„±
                results.append({
                    "session_id": session_id,
                    "file_path": file_info["path"],
                    "file_name": file_info["name"],
                    "file_size": file_info["size"],
                    "analysis_time": 0.0,
                    "vulnerability_analysis": {"is_vulnerable": False, "error": str(e)},
                    "malicious_analysis": {"is_malicious": False, "error": str(e)},
                    "is_safe": True
                })
        
        print(f"âœ… Worker {chunk_id} completed: {len(results)} files analyzed")
        return results
        
    except Exception as e:
        print(f"âŒ Worker {chunk_id} failed: {e}")
        return []

# ì „ì—­ ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤ (í˜¸í™˜ì„±ìš©)
_global_analyzer = None

def get_global_analyzer():
    """ì „ì—­ ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _global_analyzer
    if _global_analyzer is None:
        _global_analyzer = IntegratedLSTMAnalyzer()
    return _global_analyzer
